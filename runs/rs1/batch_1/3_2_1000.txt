Run # 1
Initial state: 0 0.594173 0.815712 0.314861 0.584668 0.546172 0.891896 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226295 episodes
GETTING ACTION FROM:
action 3, numVisits=226287, meanQ=6.237484, numObservations: 4
action 2, numVisits=5, meanQ=0.998020, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.594173 0.815712 0.314861 0.584668 0.546172 0.891896 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 2
Initial state: 0 0.522142 0.81281 0.312367 0.710048 0.632114 0.821697 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241136 episodes
GETTING ACTION FROM:
action 3, numVisits=241108, meanQ=6.232699, numObservations: 4
action 2, numVisits=15, meanQ=4.398673, numObservations: 3
action 1, numVisits=11, meanQ=2.725464, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.522142 0.81281 0.312367 0.710048 0.632114 0.821697 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 3
Initial state: 0 0.576055 0.807609 0.475369 0.787212 0.515625 0.831297 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 243869 episodes
GETTING ACTION FROM:
action 2, numVisits=243854, meanQ=6.219110, numObservations: 3
action 1, numVisits=12, meanQ=4.165000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.576055 0.807609 0.475369 0.787212 0.515625 0.831297 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=39521, meanQ=8.857208, numObservations: 5
action 3, numVisits=15, meanQ=7.131340, numObservations: 3
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 292931 episodes
GETTING ACTION FROM:
action 1, numVisits=332039, meanQ=6.514057, numObservations: 5
action 3, numVisits=427, meanQ=6.165738, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 1
Next state: 1 0.576055 0.807609 0.475369 0.787212 0.515625 0.831297 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 4
Initial state: 0 0.558225 0.850324 0.564837 0.881989 0.632704 0.719253 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240503 episodes
GETTING ACTION FROM:
action 1, numVisits=220813, meanQ=6.242238, numObservations: 4
action 3, numVisits=19674, meanQ=6.133672, numObservations: 3
action 2, numVisits=14, meanQ=4.070007, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.558225 0.850324 0.564837 0.881989 0.632704 0.719253 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 5
Initial state: 0 0.548104 0.80162 0.610644 0.848579 0.259897 0.0882042 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238589 episodes
GETTING ACTION FROM:
action 1, numVisits=238556, meanQ=6.234553, numObservations: 5
action 2, numVisits=29, meanQ=4.817586, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.548104 0.80162 0.610644 0.848579 0.259897 0.0882042 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 6
Initial state: 0 0.574443 0.806894 0.168357 0.340728 0.578535 0.892987 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240797 episodes
GETTING ACTION FROM:
action 3, numVisits=240792, meanQ=6.151762, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.574443 0.806894 0.168357 0.340728 0.578535 0.892987 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 7
Initial state: 0 0.5463 0.857022 0.65165 0.884672 0.25788 0.498045 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239486 episodes
GETTING ACTION FROM:
action 2, numVisits=239466, meanQ=6.249891, numObservations: 5
action 3, numVisits=11, meanQ=3.723655, numObservations: 4
action 1, numVisits=7, meanQ=3.568571, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.5463 0.857022 0.65165 0.884672 0.25788 0.498045 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 8
Initial state: 0 0.679785 0.810476 0.8813 0.915636 0.531445 0.892974 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240150 episodes
GETTING ACTION FROM:
action 3, numVisits=240100, meanQ=6.161614, numObservations: 4
action 2, numVisits=45, meanQ=4.997338, numObservations: 4
action 1, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.679785 0.810476 0.8813 0.915636 0.531445 0.892974 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 9
Initial state: 0 0.680981 0.898411 0.638822 0.806357 0.588121 0.721703 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 237453 episodes
GETTING ACTION FROM:
action 1, numVisits=237446, meanQ=6.222933, numObservations: 5
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.680981 0.898411 0.638822 0.806357 0.588121 0.721703 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 10
Initial state: 0 0.224209 0.957302 0.532521 0.886377 0.52561 0.890228 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239962 episodes
GETTING ACTION FROM:
action 3, numVisits=239956, meanQ=6.202293, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 3
Next state: 1 0.224209 0.957302 0.532521 0.886377 0.52561 0.890228 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 11
Initial state: 0 0.489441 0.880784 0.579247 0.877146 0.602617 0.84425 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241221 episodes
GETTING ACTION FROM:
action 1, numVisits=241212, meanQ=6.230565, numObservations: 4
action 2, numVisits=5, meanQ=-0.802000, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 0 0.489441 0.880784 0.579247 0.877146 0.602617 0.84425 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=8168, meanQ=8.736980, numObservations: 4
action 3, numVisits=6586, meanQ=8.724486, numObservations: 4
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 295313 episodes
GETTING ACTION FROM:
action 2, numVisits=242674, meanQ=6.692273, numObservations: 4
action 3, numVisits=67366, meanQ=6.678841, numObservations: 4
action 1, numVisits=28, meanQ=5.031439, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.489441 0.880784 0.579247 0.877146 0.602617 0.84425 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 12
Initial state: 0 0.527909 0.853968 0.644354 0.89111 0.693547 0.126735 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 237441 episodes
GETTING ACTION FROM:
action 3, numVisits=237430, meanQ=6.229186, numObservations: 5
action 2, numVisits=7, meanQ=3.568571, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 2 0.527909 0.853968 0.644354 0.89111 0.693547 0.126735 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 13
Initial state: 0 0.00481063 0.82102 0.502199 0.851968 0.600999 0.896792 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238918 episodes
GETTING ACTION FROM:
action 2, numVisits=238887, meanQ=6.230342, numObservations: 5
action 1, numVisits=28, meanQ=4.426796, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.00481063 0.82102 0.502199 0.851968 0.600999 0.896792 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 14
Initial state: 0 0.515568 0.655353 0.601477 0.84546 0.604289 0.861242 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238480 episodes
GETTING ACTION FROM:
action 2, numVisits=238474, meanQ=6.248536, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.515568 0.655353 0.601477 0.84546 0.604289 0.861242 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 15
Initial state: 0 0.217804 0.491641 0.698616 0.824228 0.691335 0.830934 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240582 episodes
GETTING ACTION FROM:
action 2, numVisits=240578, meanQ=6.222290, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.217804 0.491641 0.698616 0.824228 0.691335 0.830934 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 16
Initial state: 0 0.0235429 0.70528 0.516938 0.824287 0.513566 0.855974 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 242918 episodes
GETTING ACTION FROM:
action 2, numVisits=242855, meanQ=6.308534, numObservations: 4
action 3, numVisits=55, meanQ=5.339642, numObservations: 5
action 1, numVisits=6, meanQ=0.831667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.0235429 0.70528 0.516938 0.824287 0.513566 0.855974 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 17
Initial state: 0 0.934731 0.25784 0.507789 0.88375 0.604864 0.844641 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240778 episodes
GETTING ACTION FROM:
action 3, numVisits=86658, meanQ=6.272730, numObservations: 3
action 2, numVisits=154100, meanQ=6.270879, numObservations: 4
action 1, numVisits=18, meanQ=4.544444, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.934731 0.25784 0.507789 0.88375 0.604864 0.844641 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 18
Initial state: 0 0.628872 0.869218 0.683821 0.800483 0.428069 0.0889829 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 246348 episodes
GETTING ACTION FROM:
action 2, numVisits=246339, meanQ=6.237883, numObservations: 3
action 1, numVisits=5, meanQ=1.396000, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.628872 0.869218 0.683821 0.800483 0.428069 0.0889829 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 19
Initial state: 0 0.669908 0.835683 0.372928 0.381423 0.691765 0.84749 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239516 episodes
GETTING ACTION FROM:
action 1, numVisits=239506, meanQ=6.250313, numObservations: 4
action 3, numVisits=7, meanQ=1.854314, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.669908 0.835683 0.372928 0.381423 0.691765 0.84749 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 20
Initial state: 0 0.698448 0.89083 0.327339 0.659662 0.686384 0.820092 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238679 episodes
GETTING ACTION FROM:
action 3, numVisits=238671, meanQ=6.223743, numObservations: 5
action 2, numVisits=3, meanQ=-0.670000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.698448 0.89083 0.327339 0.659662 0.686384 0.820092 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 21
Initial state: 0 0.586023 0.86736 0.854447 0.346376 0.672794 0.847739 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 242089 episodes
GETTING ACTION FROM:
action 2, numVisits=242050, meanQ=6.247489, numObservations: 4
action 3, numVisits=30, meanQ=4.920667, numObservations: 3
action 1, numVisits=7, meanQ=3.284300, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 2 0.586023 0.86736 0.854447 0.346376 0.672794 0.847739 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 22
Initial state: 0 0.660116 0.839226 0.670624 0.805939 0.169917 0.631615 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 244471 episodes
GETTING ACTION FROM:
action 1, numVisits=244454, meanQ=6.173525, numObservations: 3
action 3, numVisits=9, meanQ=3.663344, numObservations: 4
action 2, numVisits=6, meanQ=2.663333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.660116 0.839226 0.670624 0.805939 0.169917 0.631615 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 23
Initial state: 0 0.570672 0.892711 0.610121 0.609238 0.684608 0.898171 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 242887 episodes
GETTING ACTION FROM:
action 2, numVisits=242880, meanQ=6.241496, numObservations: 4
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 2 0.570672 0.892711 0.610121 0.609238 0.684608 0.898171 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 24
Initial state: 0 0.583005 0.846219 0.140119 0.0234138 0.605112 0.824503 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238792 episodes
GETTING ACTION FROM:
action 2, numVisits=238651, meanQ=6.225191, numObservations: 5
action 1, numVisits=127, meanQ=5.590552, numObservations: 4
action 3, numVisits=12, meanQ=4.164175, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.583005 0.846219 0.140119 0.0234138 0.605112 0.824503 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=21655, meanQ=8.884418, numObservations: 5
action 1, numVisits=10811, meanQ=8.866089, numObservations: 4
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 292102 episodes
GETTING ACTION FROM:
action 3, numVisits=201295, meanQ=6.914983, numObservations: 5
action 1, numVisits=123263, meanQ=6.910808, numObservations: 5
action 2, numVisits=11, meanQ=4.346364, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.583005 0.846219 0.140119 0.0234138 0.605112 0.824503 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 25
Initial state: 0 0.618488 0.82631 0.547002 0.8604 0.269917 0.752477 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238649 episodes
GETTING ACTION FROM:
action 1, numVisits=238634, meanQ=6.278620, numObservations: 5
action 2, numVisits=9, meanQ=3.554444, numObservations: 3
action 3, numVisits=4, meanQ=1.745025, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.618488 0.82631 0.547002 0.8604 0.269917 0.752477 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 26
Initial state: 0 0.53552 0.895564 0.880459 0.830285 0.684264 0.80754 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239450 episodes
GETTING ACTION FROM:
action 1, numVisits=108282, meanQ=6.256760, numObservations: 5
action 2, numVisits=131165, meanQ=6.167761, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.53552 0.895564 0.880459 0.830285 0.684264 0.80754 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 27
Initial state: 0 0.659596 0.880306 0.509574 0.854101 0.456503 0.978269 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 243135 episodes
GETTING ACTION FROM:
action 2, numVisits=243130, meanQ=6.179497, numObservations: 4
action 3, numVisits=2, meanQ=-0.509950, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.659596 0.880306 0.509574 0.854101 0.456503 0.978269 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 28
Initial state: 0 0.888544 0.837989 0.541487 0.829044 0.685378 0.899169 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240211 episodes
GETTING ACTION FROM:
action 3, numVisits=240193, meanQ=6.225036, numObservations: 4
action 2, numVisits=10, meanQ=2.998020, numObservations: 4
action 1, numVisits=6, meanQ=2.150017, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.888544 0.837989 0.541487 0.829044 0.685378 0.899169 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 29
Initial state: 0 0.666518 0.890699 0.508289 0.809141 0.646662 0.162119 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238961 episodes
GETTING ACTION FROM:
action 3, numVisits=238956, meanQ=6.279434, numObservations: 5
action 1, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.666518 0.890699 0.508289 0.809141 0.646662 0.162119 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=14454, meanQ=8.688370, numObservations: 3
action 2, numVisits=12, meanQ=6.582500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 295871 episodes
GETTING ACTION FROM:
action 2, numVisits=201914, meanQ=6.545428, numObservations: 4
action 1, numVisits=108423, meanQ=6.480705, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.666518 0.890699 0.508289 0.809141 0.646662 0.162119 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 30
Initial state: 0 0.613512 0.00265414 0.61145 0.896416 0.580202 0.80007 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241200 episodes
GETTING ACTION FROM:
action 1, numVisits=241154, meanQ=6.247738, numObservations: 4
action 2, numVisits=34, meanQ=3.937659, numObservations: 4
action 3, numVisits=10, meanQ=2.999010, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 2 0.613512 0.00265414 0.61145 0.896416 0.580202 0.80007 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 31
Initial state: 0 0.686763 0.840197 0.627446 0.690778 0.503284 0.820435 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238774 episodes
GETTING ACTION FROM:
action 1, numVisits=238756, meanQ=6.221217, numObservations: 5
action 2, numVisits=14, meanQ=3.284300, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.686763 0.840197 0.627446 0.690778 0.503284 0.820435 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 32
Initial state: 0 0.672888 0.841441 0.24581 0.0716035 0.551014 0.871252 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240867 episodes
GETTING ACTION FROM:
action 1, numVisits=240848, meanQ=6.218607, numObservations: 4
action 3, numVisits=15, meanQ=4.398673, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.672888 0.841441 0.24581 0.0716035 0.551014 0.871252 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 33
Initial state: 0 0.523526 0.86818 0.623817 0.823951 0.999861 0.241479 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241956 episodes
GETTING ACTION FROM:
action 1, numVisits=241950, meanQ=6.329274, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.523526 0.86818 0.623817 0.823951 0.999861 0.241479 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 34
Initial state: 0 0.146918 0.667929 0.565179 0.803459 0.624524 0.8721 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238706 episodes
GETTING ACTION FROM:
action 2, numVisits=238486, meanQ=6.248949, numObservations: 5
action 3, numVisits=211, meanQ=4.724581, numObservations: 4
action 1, numVisits=7, meanQ=3.285714, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.146918 0.667929 0.565179 0.803459 0.624524 0.8721 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 35
Initial state: 0 0.262367 0.0961887 0.593516 0.839276 0.57622 0.895463 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240631 episodes
GETTING ACTION FROM:
action 2, numVisits=150561, meanQ=6.222231, numObservations: 5
action 3, numVisits=90066, meanQ=6.194520, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.262367 0.0961887 0.593516 0.839276 0.57622 0.895463 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 36
Initial state: 0 0.599856 0.806484 0.568744 0.820048 0.876598 0.918273 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 242413 episodes
GETTING ACTION FROM:
action 2, numVisits=242400, meanQ=6.225122, numObservations: 4
action 3, numVisits=10, meanQ=2.188000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.599856 0.806484 0.568744 0.820048 0.876598 0.918273 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 37
Initial state: 0 0.554386 0.816317 0.751673 0.78036 0.534137 0.839005 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 244973 episodes
GETTING ACTION FROM:
action 2, numVisits=244864, meanQ=6.230432, numObservations: 3
action 3, numVisits=94, meanQ=5.298091, numObservations: 5
action 1, numVisits=13, meanQ=3.766931, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 2 0.554386 0.816317 0.751673 0.78036 0.534137 0.839005 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 38
Initial state: 0 0.621161 0.856403 0.57101 0.189 0.695656 0.814105 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239117 episodes
GETTING ACTION FROM:
action 2, numVisits=239090, meanQ=6.231419, numObservations: 5
action 1, numVisits=13, meanQ=3.843846, numObservations: 3
action 3, numVisits=12, meanQ=3.249167, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 2 0.621161 0.856403 0.57101 0.189 0.695656 0.814105 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 39
Initial state: 0 0.629606 0.836145 0.435939 0.55986 0.644154 0.871317 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241857 episodes
GETTING ACTION FROM:
action 2, numVisits=241839, meanQ=6.219081, numObservations: 4
action 3, numVisits=13, meanQ=0.460785, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.629606 0.836145 0.435939 0.55986 0.644154 0.871317 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=26296, meanQ=8.870105, numObservations: 4
action 3, numVisits=7224, meanQ=8.842776, numObservations: 4
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 294609 episodes
GETTING ACTION FROM:
action 1, numVisits=277499, meanQ=6.914307, numObservations: 4
action 3, numVisits=50564, meanQ=6.895393, numObservations: 5
action 2, numVisits=67, meanQ=5.960149, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.629606 0.836145 0.435939 0.55986 0.644154 0.871317 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 40
Initial state: 0 0.548983 0.802734 0.860638 0.811592 0.605863 0.873788 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 244553 episodes
GETTING ACTION FROM:
action 1, numVisits=244548, meanQ=6.184742, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.548983 0.802734 0.860638 0.811592 0.605863 0.873788 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 41
Initial state: 0 0.547429 0.843477 0.533807 0.856913 0.392652 0.333225 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239664 episodes
GETTING ACTION FROM:
action 3, numVisits=239660, meanQ=6.231924, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.547429 0.843477 0.533807 0.856913 0.392652 0.333225 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=32894, meanQ=8.886236, numObservations: 4
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 293837 episodes
GETTING ACTION FROM:
action 1, numVisits=326544, meanQ=6.950657, numObservations: 4
action 3, numVisits=111, meanQ=6.197849, numObservations: 3
action 2, numVisits=78, meanQ=5.935642, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.547429 0.843477 0.533807 0.856913 0.392652 0.333225 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 42
Initial state: 0 0.221681 0.695738 0.698835 0.820758 0.540419 0.873566 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238862 episodes
GETTING ACTION FROM:
action 1, numVisits=234902, meanQ=6.311335, numObservations: 5
action 2, numVisits=3926, meanQ=6.202955, numObservations: 4
action 3, numVisits=32, meanQ=4.685947, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 0 0.221681 0.695738 0.698835 0.820758 0.540419 0.873566 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=13656, meanQ=8.933728, numObservations: 3
action 3, numVisits=11776, meanQ=8.932016, numObservations: 3
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 296156 episodes
GETTING ACTION FROM:
action 2, numVisits=213988, meanQ=6.916043, numObservations: 4
action 3, numVisits=107597, meanQ=6.909227, numObservations: 3
action 1, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.221681 0.695738 0.698835 0.820758 0.540419 0.873566 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 43
Initial state: 0 0.488396 0.660736 0.604685 0.823999 0.555281 0.886904 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239567 episodes
GETTING ACTION FROM:
action 3, numVisits=239238, meanQ=6.246247, numObservations: 4
action 2, numVisits=325, meanQ=5.747988, numObservations: 5
action 1, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.488396 0.660736 0.604685 0.823999 0.555281 0.886904 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 44
Initial state: 0 0.555495 0.870113 0.287644 0.629807 0.687196 0.835839 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241569 episodes
GETTING ACTION FROM:
action 2, numVisits=241563, meanQ=6.235777, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.555495 0.870113 0.287644 0.629807 0.687196 0.835839 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=18077, meanQ=8.859802, numObservations: 4
action 3, numVisits=15456, meanQ=8.855684, numObservations: 5
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 293571 episodes
GETTING ACTION FROM:
action 3, numVisits=244273, meanQ=6.895767, numObservations: 5
action 1, numVisits=82827, meanQ=6.885152, numObservations: 4
action 2, numVisits=5, meanQ=3.198000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.555495 0.870113 0.287644 0.629807 0.687196 0.835839 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 45
Initial state: 0 0.513872 0.862557 0.659416 0.841358 0.176976 0.599433 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238519 episodes
GETTING ACTION FROM:
action 1, numVisits=238490, meanQ=6.239825, numObservations: 5
action 2, numVisits=20, meanQ=4.596525, numObservations: 5
action 3, numVisits=7, meanQ=1.998571, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.513872 0.862557 0.659416 0.841358 0.176976 0.599433 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 46
Initial state: 0 0.544977 0.878539 0.602053 0.883765 0.742675 0.484079 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238719 episodes
GETTING ACTION FROM:
action 1, numVisits=238701, meanQ=6.208157, numObservations: 5
action 3, numVisits=15, meanQ=4.399333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.544977 0.878539 0.602053 0.883765 0.742675 0.484079 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 47
Initial state: 0 0.545083 0.800533 0.518237 0.716073 0.629419 0.838083 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241475 episodes
GETTING ACTION FROM:
action 3, numVisits=241457, meanQ=6.258584, numObservations: 4
action 1, numVisits=12, meanQ=4.081675, numObservations: 2
action 2, numVisits=4, meanQ=1.747500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.545083 0.800533 0.518237 0.716073 0.629419 0.838083 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 48
Initial state: 0 0.598477 0.834843 0.612308 0.824956 0.97075 0.760804 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241539 episodes
GETTING ACTION FROM:
action 2, numVisits=241526, meanQ=6.229504, numObservations: 4
action 1, numVisits=7, meanQ=3.568571, numObservations: 4
action 3, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.598477 0.834843 0.612308 0.824956 0.97075 0.760804 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 49
Initial state: 0 0.53281 0.861206 0.650565 0.855977 0.0785928 0.625827 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240197 episodes
GETTING ACTION FROM:
action 1, numVisits=239337, meanQ=6.251929, numObservations: 4
action 2, numVisits=846, meanQ=6.017643, numObservations: 3
action 3, numVisits=12, meanQ=3.999175, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.53281 0.861206 0.650565 0.855977 0.0785928 0.625827 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 50
Initial state: 0 0.195733 0.153444 0.510975 0.84684 0.568322 0.806645 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 234198 episodes
GETTING ACTION FROM:
action 3, numVisits=234186, meanQ=6.160750, numObservations: 4
action 2, numVisits=8, meanQ=3.120012, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 3
Next state: 1 0.195733 0.153444 0.510975 0.84684 0.568322 0.806645 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 51
Initial state: 0 0.529653 0.837106 0.674079 0.818384 0.979778 0.989165 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239940 episodes
GETTING ACTION FROM:
action 2, numVisits=239751, meanQ=6.234617, numObservations: 5
action 3, numVisits=185, meanQ=5.674649, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.529653 0.837106 0.674079 0.818384 0.979778 0.989165 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 52
Initial state: 0 0.807626 0.011125 0.550106 0.878795 0.576674 0.810154 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241726 episodes
GETTING ACTION FROM:
action 1, numVisits=241721, meanQ=6.237184, numObservations: 4
action 3, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.807626 0.011125 0.550106 0.878795 0.576674 0.810154 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 53
Initial state: 0 0.503125 0.850879 0.258537 0.00921309 0.542084 0.85166 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238157 episodes
GETTING ACTION FROM:
action 1, numVisits=238150, meanQ=6.241456, numObservations: 5
action 2, numVisits=3, meanQ=-0.670000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.503125 0.850879 0.258537 0.00921309 0.542084 0.85166 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 54
Initial state: 0 0.547305 0.875255 0.556538 0.87824 0.619875 0.425678 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240974 episodes
GETTING ACTION FROM:
action 3, numVisits=240655, meanQ=6.200903, numObservations: 4
action 2, numVisits=315, meanQ=5.798192, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.547305 0.875255 0.556538 0.87824 0.619875 0.425678 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=12797, meanQ=8.640487, numObservations: 4
action 1, numVisits=5, meanQ=5.196020, numObservations: 2
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 297291 episodes
GETTING ACTION FROM:
action 2, numVisits=310081, meanQ=6.607020, numObservations: 4
action 1, numVisits=8, meanQ=2.996263, numObservations: 2
action 3, numVisits=5, meanQ=2.980000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.547305 0.875255 0.556538 0.87824 0.619875 0.425678 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 55
Initial state: 0 0.634814 0.870343 0.667083 0.862593 0.32913 0.636129 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239717 episodes
GETTING ACTION FROM:
action 1, numVisits=233184, meanQ=6.219670, numObservations: 4
action 2, numVisits=6515, meanQ=6.136426, numObservations: 4
action 3, numVisits=16, meanQ=3.491263, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.634814 0.870343 0.667083 0.862593 0.32913 0.636129 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 56
Initial state: 0 0.582904 0.842374 0.527139 0.837887 0.500268 0.391173 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 232271 episodes
GETTING ACTION FROM:
action 3, numVisits=232259, meanQ=6.102070, numObservations: 5
action 2, numVisits=3, meanQ=-0.010000, numObservations: 3
action 1, numVisits=5, meanQ=-0.802000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.582904 0.842374 0.527139 0.837887 0.500268 0.391173 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 57
Initial state: 0 0.514068 0.824687 0.00379608 0.548161 0.526802 0.850189 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240207 episodes
GETTING ACTION FROM:
action 1, numVisits=240131, meanQ=6.232850, numObservations: 4
action 2, numVisits=71, meanQ=5.352821, numObservations: 4
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.514068 0.824687 0.00379608 0.548161 0.526802 0.850189 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 58
Initial state: 0 0.60574 0.898385 0.31255 0.252105 0.641258 0.846557 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241189 episodes
GETTING ACTION FROM:
action 1, numVisits=241182, meanQ=6.233054, numObservations: 4
action 2, numVisits=3, meanQ=-0.670000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 0 0.60574 0.898385 0.31255 0.252105 0.641258 0.846557 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=9953, meanQ=5.995368, numObservations: 5
action 2, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 292290 episodes
GETTING ACTION FROM:
action 3, numVisits=302243, meanQ=6.368492, numObservations: 5
action 2, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.60574 0.898385 0.31255 0.252105 0.641258 0.846557 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 59
Initial state: 0 0.806092 0.847667 0.525714 0.854281 0.62587 0.823074 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 237274 episodes
GETTING ACTION FROM:
action 2, numVisits=237106, meanQ=6.247938, numObservations: 5
action 1, numVisits=162, meanQ=5.620435, numObservations: 4
action 3, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.806092 0.847667 0.525714 0.854281 0.62587 0.823074 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 60
Initial state: 0 0.631379 0.800702 0.515654 0.858085 0.364197 0.247476 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 237739 episodes
GETTING ACTION FROM:
action 3, numVisits=237730, meanQ=6.231733, numObservations: 5
action 2, numVisits=5, meanQ=2.980000, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.631379 0.800702 0.515654 0.858085 0.364197 0.247476 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=32545, meanQ=8.862862, numObservations: 3
action 2, numVisits=35, meanQ=7.599714, numObservations: 3
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 299649 episodes
GETTING ACTION FROM:
action 1, numVisits=332121, meanQ=6.599936, numObservations: 3
action 2, numVisits=85, meanQ=5.752471, numObservations: 4
action 3, numVisits=24, meanQ=4.874171, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.631379 0.800702 0.515654 0.858085 0.364197 0.247476 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 61
Initial state: 0 0.623679 0.832679 0.553052 0.00368495 0.670513 0.88974 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 243502 episodes
GETTING ACTION FROM:
action 2, numVisits=243485, meanQ=6.207259, numObservations: 3
action 1, numVisits=13, meanQ=2.305385, numObservations: 5
action 3, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 2 0.623679 0.832679 0.553052 0.00368495 0.670513 0.88974 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 62
Initial state: 0 0.668329 0.878559 0.645602 0.844774 0.0319606 0.884689 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240201 episodes
GETTING ACTION FROM:
action 3, numVisits=240193, meanQ=6.243253, numObservations: 4
action 2, numVisits=4, meanQ=1.747500, numObservations: 3
action 1, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.668329 0.878559 0.645602 0.844774 0.0319606 0.884689 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=10689, meanQ=6.535059, numObservations: 5
action 3, numVisits=52, meanQ=5.298462, numObservations: 3
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 293094 episodes
GETTING ACTION FROM:
action 1, numVisits=303734, meanQ=6.644093, numObservations: 5
action 2, numVisits=50, meanQ=5.439600, numObservations: 3
action 3, numVisits=52, meanQ=5.298462, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.668329 0.878559 0.645602 0.844774 0.0319606 0.884689 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 63
Initial state: 0 0.558568 0.236811 0.675072 0.815557 0.610864 0.802617 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 243622 episodes
GETTING ACTION FROM:
action 2, numVisits=243617, meanQ=6.241583, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.558568 0.236811 0.675072 0.815557 0.610864 0.802617 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 64
Initial state: 0 0.515248 0.832726 0.666256 0.885197 0.998074 0.189909 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241798 episodes
GETTING ACTION FROM:
action 2, numVisits=241768, meanQ=6.211839, numObservations: 4
action 3, numVisits=21, meanQ=4.553338, numObservations: 4
action 1, numVisits=7, meanQ=3.285714, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.515248 0.832726 0.666256 0.885197 0.998074 0.189909 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 65
Initial state: 0 0.506082 0.871324 0.415411 0.672259 0.569195 0.890934 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239737 episodes
GETTING ACTION FROM:
action 1, numVisits=239727, meanQ=6.236698, numObservations: 4
action 2, numVisits=7, meanQ=3.568571, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.506082 0.871324 0.415411 0.672259 0.569195 0.890934 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 66
Initial state: 0 0.673423 0.868497 0.595477 0.802586 0.985724 0.524985 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238668 episodes
GETTING ACTION FROM:
action 2, numVisits=238346, meanQ=6.229180, numObservations: 5
action 3, numVisits=313, meanQ=5.817140, numObservations: 5
action 1, numVisits=7, meanQ=3.284300, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.673423 0.868497 0.595477 0.802586 0.985724 0.524985 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 67
Initial state: 0 0.639936 0.867093 0.51966 0.814499 0.449589 0.525983 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241054 episodes
GETTING ACTION FROM:
action 1, numVisits=240367, meanQ=6.247109, numObservations: 4
action 2, numVisits=684, meanQ=5.984714, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.639936 0.867093 0.51966 0.814499 0.449589 0.525983 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 68
Initial state: 0 0.647188 0.828944 0.991374 0.188112 0.643035 0.800826 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238114 episodes
GETTING ACTION FROM:
action 3, numVisits=238096, meanQ=6.169404, numObservations: 5
action 1, numVisits=11, meanQ=1.907273, numObservations: 4
action 2, numVisits=5, meanQ=1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.647188 0.828944 0.991374 0.188112 0.643035 0.800826 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 69
Initial state: 0 0.680944 0.866481 0.742961 0.500595 0.669623 0.83296 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 237774 episodes
GETTING ACTION FROM:
action 3, numVisits=237593, meanQ=6.227267, numObservations: 5
action 2, numVisits=178, meanQ=5.679501, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.680944 0.866481 0.742961 0.500595 0.669623 0.83296 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 70
Initial state: 0 0.678083 0.832603 0.697913 0.817378 0.220258 0.568776 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 237591 episodes
GETTING ACTION FROM:
action 1, numVisits=237535, meanQ=6.225646, numObservations: 5
action 3, numVisits=28, meanQ=4.833932, numObservations: 3
action 2, numVisits=26, meanQ=2.494246, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.678083 0.832603 0.697913 0.817378 0.220258 0.568776 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 71
Initial state: 0 0.633345 0.820264 0.634046 0.824436 0.141487 0.158623 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241164 episodes
GETTING ACTION FROM:
action 1, numVisits=241154, meanQ=6.222894, numObservations: 4
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action 3, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.633345 0.820264 0.634046 0.824436 0.141487 0.158623 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 72
Initial state: 0 0.561002 0.811857 0.596125 0.894794 0.94416 0.668095 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239215 episodes
GETTING ACTION FROM:
action 1, numVisits=239204, meanQ=6.226886, numObservations: 5
action 3, numVisits=7, meanQ=2.138586, numObservations: 3
action 2, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.561002 0.811857 0.596125 0.894794 0.94416 0.668095 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 73
Initial state: 0 0.512085 0.858822 0.634846 0.85677 0.933832 0.681547 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161510 episodes
GETTING ACTION FROM:
action 0, numVisits=161498, meanQ=4.253173, numObservations: 2
action 3, numVisits=7, meanQ=0.427157, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-5.505000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.512085 0.858822 0.634846 0.85677 0.933832 0.681547 w: 1
Observation: 0 0 0.913624 0 0.917765 0 0.647832 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=123193, meanQ=5.548541, numObservations: 4
action 2, numVisits=11, meanQ=2.726364, numObservations: 3
action 3, numVisits=12, meanQ=2.498333, numObservations: 3
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 258581 episodes
GETTING ACTION FROM:
action 1, numVisits=381774, meanQ=6.218664, numObservations: 4
action 2, numVisits=11, meanQ=2.726364, numObservations: 3
action 3, numVisits=12, meanQ=2.498333, numObservations: 3
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.512085 0.858822 0.634846 0.85677 0.933832 0.681547 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 74
Initial state: 0 0.530025 0.83504 0.672214 0.855213 0.0650348 0.104406 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238158 episodes
GETTING ACTION FROM:
action 3, numVisits=238139, meanQ=6.158742, numObservations: 5
action 2, numVisits=14, meanQ=4.140721, numObservations: 3
action 1, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.530025 0.83504 0.672214 0.855213 0.0650348 0.104406 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=32761, meanQ=8.878689, numObservations: 5
action 2, numVisits=6, meanQ=5.665017, numObservations: 2
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 292276 episodes
GETTING ACTION FROM:
action 1, numVisits=324969, meanQ=6.493650, numObservations: 5
action 2, numVisits=61, meanQ=5.393118, numObservations: 4
action 3, numVisits=14, meanQ=3.927871, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.530025 0.83504 0.672214 0.855213 0.0650348 0.104406 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 75
Initial state: 0 0.524031 0.825236 0.602965 0.877415 0.751113 0.181084 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239210 episodes
GETTING ACTION FROM:
action 2, numVisits=239144, meanQ=6.224696, numObservations: 5
action 3, numVisits=57, meanQ=5.118953, numObservations: 4
action 1, numVisits=7, meanQ=3.568571, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.524031 0.825236 0.602965 0.877415 0.751113 0.181084 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=10719, meanQ=6.448331, numObservations: 5
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 291693 episodes
GETTING ACTION FROM:
action 1, numVisits=302398, meanQ=6.359589, numObservations: 5
action 2, numVisits=15, meanQ=4.399333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.524031 0.825236 0.602965 0.877415 0.751113 0.181084 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=452, meanQ=8.176733, numObservations: 3
action 1, numVisits=12, meanQ=4.825000, numObservations: 3
action 2, numVisits=3, meanQ=2.333333, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 303250 episodes
GETTING ACTION FROM:
action 3, numVisits=303702, meanQ=7.109195, numObservations: 3
action 1, numVisits=12, meanQ=4.825000, numObservations: 3
action 2, numVisits=3, meanQ=2.333333, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 2 0.524031 0.825236 0.602965 0.877415 0.751113 0.181084 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.7711
Run # 76
Initial state: 0 0.657776 0.81013 0.841945 0.793104 0.642189 0.83088 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 242532 episodes
GETTING ACTION FROM:
action 2, numVisits=242527, meanQ=6.236811, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.657776 0.81013 0.841945 0.793104 0.642189 0.83088 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 77
Initial state: 0 0.433967 0.868603 0.61683 0.895738 0.659648 0.856459 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240709 episodes
GETTING ACTION FROM:
action 1, numVisits=240691, meanQ=6.245724, numObservations: 4
action 2, numVisits=15, meanQ=3.798667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.433967 0.868603 0.61683 0.895738 0.659648 0.856459 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=30168, meanQ=8.868085, numObservations: 4
action 2, numVisits=8769, meanQ=8.838274, numObservations: 5
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 293006 episodes
GETTING ACTION FROM:
action 3, numVisits=266935, meanQ=6.803986, numObservations: 4
action 2, numVisits=65006, meanQ=6.789346, numObservations: 5
action 1, numVisits=3, meanQ=-0.670000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.433967 0.868603 0.61683 0.895738 0.659648 0.856459 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 78
Initial state: 0 0.541286 0.88802 0.679756 0.877235 0.756559 0.478753 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241011 episodes
GETTING ACTION FROM:
action 2, numVisits=241004, meanQ=6.219199, numObservations: 5
action 1, numVisits=4, meanQ=1.747500, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.541286 0.88802 0.679756 0.877235 0.756559 0.478753 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 79
Initial state: 0 0.622896 0.896983 0.281195 0.223014 0.560711 0.877771 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 243228 episodes
GETTING ACTION FROM:
action 2, numVisits=243152, meanQ=6.227337, numObservations: 3
action 1, numVisits=73, meanQ=5.302888, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.622896 0.896983 0.281195 0.223014 0.560711 0.877771 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=39290, meanQ=8.859271, numObservations: 5
action 3, numVisits=16, meanQ=7.248131, numObservations: 3
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 292170 episodes
GETTING ACTION FROM:
action 1, numVisits=330012, meanQ=6.766306, numObservations: 5
action 3, numVisits=1437, meanQ=6.586175, numObservations: 3
action 2, numVisits=28, meanQ=5.070014, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.622896 0.896983 0.281195 0.223014 0.560711 0.877771 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 80
Initial state: 0 0.671631 0.871967 0.584399 0.751019 0.625275 0.889238 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240200 episodes
GETTING ACTION FROM:
action 1, numVisits=240176, meanQ=6.217012, numObservations: 4
action 2, numVisits=12, meanQ=4.000000, numObservations: 3
action 3, numVisits=10, meanQ=3.989010, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.671631 0.871967 0.584399 0.751019 0.625275 0.889238 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 81
Initial state: 0 0.564533 0.872019 0.775476 0.832935 0.593778 0.802661 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241002 episodes
GETTING ACTION FROM:
action 1, numVisits=237416, meanQ=6.210956, numObservations: 4
action 2, numVisits=3576, meanQ=6.096745, numObservations: 3
action 3, numVisits=8, meanQ=2.873750, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.564533 0.872019 0.775476 0.832935 0.593778 0.802661 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 82
Initial state: 0 0.588159 0.805565 0.568673 0.838561 0.919964 0.0611659 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241427 episodes
GETTING ACTION FROM:
action 2, numVisits=241407, meanQ=6.185230, numObservations: 4
action 1, numVisits=12, meanQ=3.990017, numObservations: 3
action 3, numVisits=6, meanQ=2.663333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.588159 0.805565 0.568673 0.838561 0.919964 0.0611659 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 83
Initial state: 0 0.675546 0.824093 0.690913 0.870522 0.806158 0.389948 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240813 episodes
GETTING ACTION FROM:
action 1, numVisits=240783, meanQ=6.234912, numObservations: 4
action 2, numVisits=22, meanQ=3.535914, numObservations: 4
action 3, numVisits=6, meanQ=2.331683, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.675546 0.824093 0.690913 0.870522 0.806158 0.389948 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 84
Initial state: 0 0.570304 0.898527 0.666777 0.883015 0.643821 0.939762 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240571 episodes
GETTING ACTION FROM:
action 3, numVisits=240562, meanQ=6.248308, numObservations: 4
action 1, numVisits=5, meanQ=1.000000, numObservations: 3
action 2, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.570304 0.898527 0.666777 0.883015 0.643821 0.939762 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 85
Initial state: 0 0.510771 0.880899 0.681138 0.893244 0.944617 0.428704 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162392 episodes
GETTING ACTION FROM:
action -1, numVisits=162386, meanQ=4.167250, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.510771 0.880899 0.681138 0.893244 0.944617 0.428704 w: 1
Observation: 0 0.470108 0 0.67514 0 0.88545 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=162343, meanQ=6.230978, numObservations: 5
action 3, numVisits=36, meanQ=4.854453, numObservations: 4
action 1, numVisits=4, meanQ=1.992525, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 258897 episodes
GETTING ACTION FROM:
action 2, numVisits=421222, meanQ=5.991075, numObservations: 5
action 3, numVisits=52, meanQ=4.934237, numObservations: 5
action 1, numVisits=4, meanQ=1.992525, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.510771 0.880899 0.681138 0.893244 0.944617 0.428704 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 86
Initial state: 0 0.602643 0.82845 0.663864 0.811934 0.493076 0.0263572 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239775 episodes
GETTING ACTION FROM:
action 2, numVisits=239721, meanQ=6.262412, numObservations: 5
action 3, numVisits=40, meanQ=5.083753, numObservations: 3
action 1, numVisits=12, meanQ=3.414167, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.602643 0.82845 0.663864 0.811934 0.493076 0.0263572 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 87
Initial state: 0 0.559536 0.823325 0.562228 0.800056 0.269013 0.914387 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 233405 episodes
GETTING ACTION FROM:
action 3, numVisits=233379, meanQ=6.145409, numObservations: 5
action 1, numVisits=12, meanQ=2.498333, numObservations: 3
action 2, numVisits=12, meanQ=2.332508, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.559536 0.823325 0.562228 0.800056 0.269013 0.914387 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=5760, meanQ=8.726870, numObservations: 3
action 3, numVisits=2, meanQ=4.495000, numObservations: 2
action 2, numVisits=3, meanQ=2.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 300740 episodes
GETTING ACTION FROM:
action 1, numVisits=306497, meanQ=6.642909, numObservations: 3
action 2, numVisits=3, meanQ=2.333333, numObservations: 3
action 3, numVisits=5, meanQ=0.998020, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.559536 0.823325 0.562228 0.800056 0.269013 0.914387 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 88
Initial state: 0 0.848454 0.872927 0.577567 0.851523 0.511244 0.892779 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238202 episodes
GETTING ACTION FROM:
action 1, numVisits=238184, meanQ=6.235042, numObservations: 5
action 3, numVisits=9, meanQ=3.554444, numObservations: 2
action 2, numVisits=7, meanQ=1.998571, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.848454 0.872927 0.577567 0.851523 0.511244 0.892779 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 89
Initial state: 0 0.648139 0.828046 0.601609 0.844725 0.948111 0.337589 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 242568 episodes
GETTING ACTION FROM:
action 3, numVisits=242550, meanQ=6.216866, numObservations: 4
action 1, numVisits=12, meanQ=4.081675, numObservations: 3
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 2 0.648139 0.828046 0.601609 0.844725 0.948111 0.337589 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 90
Initial state: 0 0.17771 0.0226978 0.611472 0.808768 0.640473 0.837495 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238158 episodes
GETTING ACTION FROM:
action 1, numVisits=238133, meanQ=6.128640, numObservations: 3
action 3, numVisits=19, meanQ=4.419474, numObservations: 4
action 2, numVisits=4, meanQ=1.747500, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 0 0.17771 0.0226978 0.611472 0.808768 0.640473 0.837495 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=20852, meanQ=8.869740, numObservations: 4
action 2, numVisits=17679, meanQ=8.866374, numObservations: 4
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 293740 episodes
GETTING ACTION FROM:
action 2, numVisits=196855, meanQ=6.739775, numObservations: 4
action 3, numVisits=135406, meanQ=6.736725, numObservations: 4
action 1, numVisits=11, meanQ=4.526364, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.17771 0.0226978 0.611472 0.808768 0.640473 0.837495 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 91
Initial state: 0 0.508497 0.844496 0.618842 0.881272 0.94763 0.323896 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 243888 episodes
GETTING ACTION FROM:
action 2, numVisits=243880, meanQ=6.300745, numObservations: 4
action 1, numVisits=4, meanQ=1.525000, numObservations: 2
action 3, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.508497 0.844496 0.618842 0.881272 0.94763 0.323896 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 92
Initial state: 0 0.695086 0.80206 0.683825 0.880202 0.101607 0.0454797 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241525 episodes
GETTING ACTION FROM:
action 3, numVisits=241518, meanQ=6.232783, numObservations: 4
action 1, numVisits=3, meanQ=-0.670000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.695086 0.80206 0.683825 0.880202 0.101607 0.0454797 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=39014, meanQ=8.858651, numObservations: 4
action 2, numVisits=17, meanQ=7.293529, numObservations: 3
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 296235 episodes
GETTING ACTION FROM:
action 1, numVisits=334306, meanQ=6.771885, numObservations: 4
action 2, numVisits=947, meanQ=6.542028, numObservations: 3
action 3, numVisits=14, meanQ=4.139307, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.695086 0.80206 0.683825 0.880202 0.101607 0.0454797 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 93
Initial state: 0 0.179766 0.0779451 0.660193 0.806188 0.635194 0.839391 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 242830 episodes
GETTING ACTION FROM:
action 2, numVisits=242823, meanQ=6.214812, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-5.505000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.179766 0.0779451 0.660193 0.806188 0.635194 0.839391 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 94
Initial state: 0 0.64121 0.897189 0.642851 0.835572 0.00075485 0.437638 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238256 episodes
GETTING ACTION FROM:
action 1, numVisits=238177, meanQ=6.209713, numObservations: 5
action 2, numVisits=62, meanQ=4.304839, numObservations: 4
action 3, numVisits=15, meanQ=3.726000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.64121 0.897189 0.642851 0.835572 0.00075485 0.437638 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 95
Initial state: 0 0.618551 0.343681 0.576281 0.817337 0.592427 0.885707 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 242216 episodes
GETTING ACTION FROM:
action 1, numVisits=242193, meanQ=6.200330, numObservations: 4
action 2, numVisits=20, meanQ=4.549005, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.618551 0.343681 0.576281 0.817337 0.592427 0.885707 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 96
Initial state: 0 0.673471 0.807907 0.752572 0.0475316 0.544846 0.841859 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241233 episodes
GETTING ACTION FROM:
action 3, numVisits=241207, meanQ=6.217096, numObservations: 4
action 2, numVisits=12, meanQ=3.158333, numObservations: 2
action 1, numVisits=12, meanQ=3.082517, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.673471 0.807907 0.752572 0.0475316 0.544846 0.841859 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 97
Initial state: 0 0.90256 0.712892 0.575161 0.817973 0.596301 0.838389 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239462 episodes
GETTING ACTION FROM:
action 2, numVisits=239457, meanQ=6.229922, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.90256 0.712892 0.575161 0.817973 0.596301 0.838389 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 98
Initial state: 0 0.515317 0.886666 0.628408 0.675246 0.502944 0.874994 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241263 episodes
GETTING ACTION FROM:
action 3, numVisits=241241, meanQ=6.235731, numObservations: 4
action 1, numVisits=18, meanQ=2.993333, numObservations: 4
action 2, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.515317 0.886666 0.628408 0.675246 0.502944 0.874994 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 99
Initial state: 0 0.559985 0.92092 0.586146 0.875777 0.516903 0.807348 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 237963 episodes
GETTING ACTION FROM:
action 3, numVisits=237958, meanQ=6.254198, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.559985 0.92092 0.586146 0.875777 0.516903 0.807348 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 100
Initial state: 0 0.596866 0.889052 0.783525 0.0525103 0.556617 0.866324 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240278 episodes
GETTING ACTION FROM:
action 2, numVisits=240251, meanQ=6.231768, numObservations: 4
action 1, numVisits=19, meanQ=4.315263, numObservations: 2
action 3, numVisits=6, meanQ=2.663333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 2 0.596866 0.889052 0.783525 0.0525103 0.556617 0.866324 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 101
Initial state: 0 0.658347 0.839855 0.518566 0.505019 0.589594 0.865591 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239349 episodes
GETTING ACTION FROM:
action 2, numVisits=234320, meanQ=6.254896, numObservations: 4
action 3, numVisits=5014, meanQ=6.168702, numObservations: 5
action 1, numVisits=13, meanQ=3.683085, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 2 0.658347 0.839855 0.518566 0.505019 0.589594 0.865591 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 102
Initial state: 0 0.437714 0.769172 0.621483 0.850529 0.636709 0.835331 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 243980 episodes
GETTING ACTION FROM:
action 2, numVisits=243953, meanQ=6.202622, numObservations: 3
action 1, numVisits=23, meanQ=4.690439, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.437714 0.769172 0.621483 0.850529 0.636709 0.835331 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 103
Initial state: 0 0.642778 0.824483 0.667117 0.756684 0.635305 0.844952 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240264 episodes
GETTING ACTION FROM:
action 1, numVisits=239425, meanQ=6.234002, numObservations: 4
action 2, numVisits=835, meanQ=5.994943, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 1
Next state: 1 0.642778 0.824483 0.667117 0.756684 0.635305 0.844952 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 104
Initial state: 0 0.521108 0.183793 0.597789 0.879288 0.537406 0.806926 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 244150 episodes
GETTING ACTION FROM:
action 2, numVisits=244136, meanQ=6.204753, numObservations: 3
action 3, numVisits=11, meanQ=2.627273, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.521108 0.183793 0.597789 0.879288 0.537406 0.806926 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 105
Initial state: 0 0.0540979 0.00947282 0.645939 0.818726 0.686684 0.830098 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239389 episodes
GETTING ACTION FROM:
action 1, numVisits=239349, meanQ=6.222650, numObservations: 4
action 2, numVisits=15, meanQ=4.319340, numObservations: 4
action 3, numVisits=23, meanQ=4.213043, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 0 0.0540979 0.00947282 0.645939 0.818726 0.686684 0.830098 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=18506, meanQ=8.852018, numObservations: 3
action 3, numVisits=20503, meanQ=8.847822, numObservations: 5
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 292253 episodes
GETTING ACTION FROM:
action 3, numVisits=226496, meanQ=6.815301, numObservations: 5
action 2, numVisits=104690, meanQ=6.807175, numObservations: 3
action 1, numVisits=77, meanQ=5.912469, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.0540979 0.00947282 0.645939 0.818726 0.686684 0.830098 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 106
Initial state: 0 0.489125 0.279191 0.547743 0.856187 0.548422 0.811564 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 244470 episodes
GETTING ACTION FROM:
action 1, numVisits=244460, meanQ=6.224853, numObservations: 3
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action 3, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 0 0.489125 0.279191 0.547743 0.856187 0.548422 0.811564 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=23565, meanQ=8.858382, numObservations: 3
action 2, numVisits=16076, meanQ=8.850404, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 298976 episodes
GETTING ACTION FROM:
action 3, numVisits=191081, meanQ=6.826011, numObservations: 3
action 2, numVisits=147536, meanQ=6.823391, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.489125 0.279191 0.547743 0.856187 0.548422 0.811564 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 107
Initial state: 0 0.654056 0.829935 0.102537 0.740634 0.658312 0.820082 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241325 episodes
GETTING ACTION FROM:
action 3, numVisits=241320, meanQ=6.221587, numObservations: 4
action 1, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.654056 0.829935 0.102537 0.740634 0.658312 0.820082 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 108
Initial state: 0 0.680424 0.899972 0.561049 0.839121 0.618633 0.945564 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 242577 episodes
GETTING ACTION FROM:
action 3, numVisits=242552, meanQ=6.243829, numObservations: 3
action 2, numVisits=15, meanQ=3.798667, numObservations: 3
action 1, numVisits=8, meanQ=2.873750, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.680424 0.899972 0.561049 0.839121 0.618633 0.945564 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 109
Initial state: 0 0.648261 0.856368 0.421904 0.655631 0.635748 0.86191 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 237940 episodes
GETTING ACTION FROM:
action 3, numVisits=237930, meanQ=6.213665, numObservations: 5
action 1, numVisits=5, meanQ=1.396000, numObservations: 3
action 2, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.648261 0.856368 0.421904 0.655631 0.635748 0.86191 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 110
Initial state: 0 0.0365975 0.479976 0.535596 0.818954 0.534442 0.827716 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241185 episodes
GETTING ACTION FROM:
action 2, numVisits=241180, meanQ=6.210592, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.0365975 0.479976 0.535596 0.818954 0.534442 0.827716 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 111
Initial state: 0 0.694314 0.535572 0.584505 0.800402 0.66427 0.866121 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239295 episodes
GETTING ACTION FROM:
action 2, numVisits=239284, meanQ=6.212656, numObservations: 5
action 1, numVisits=6, meanQ=0.831667, numObservations: 2
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.694314 0.535572 0.584505 0.800402 0.66427 0.866121 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 112
Initial state: 0 0.56216 0.854228 0.973704 0.837007 0.530881 0.866185 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239332 episodes
GETTING ACTION FROM:
action 3, numVisits=239292, meanQ=6.246425, numObservations: 5
action 1, numVisits=17, meanQ=4.410006, numObservations: 4
action 2, numVisits=21, meanQ=3.808576, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.56216 0.854228 0.973704 0.837007 0.530881 0.866185 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 113
Initial state: 0 0.593302 0.737293 0.567757 0.870718 0.669977 0.808214 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239907 episodes
GETTING ACTION FROM:
action 2, numVisits=239891, meanQ=6.199713, numObservations: 5
action 3, numVisits=12, meanQ=3.330842, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.593302 0.737293 0.567757 0.870718 0.669977 0.808214 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 114
Initial state: 0 0.663369 0.875014 0.755934 0.788086 0.696592 0.830979 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240144 episodes
GETTING ACTION FROM:
action 3, numVisits=232332, meanQ=6.210098, numObservations: 4
action 2, numVisits=7808, meanQ=6.138499, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.663369 0.875014 0.755934 0.788086 0.696592 0.830979 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 115
Initial state: 0 0.618857 0.844422 0.94222 0.241815 0.552763 0.883697 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238999 episodes
GETTING ACTION FROM:
action 1, numVisits=238964, meanQ=6.251217, numObservations: 5
action 3, numVisits=21, meanQ=4.712871, numObservations: 2
action 2, numVisits=12, meanQ=4.165000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.618857 0.844422 0.94222 0.241815 0.552763 0.883697 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 116
Initial state: 0 0.639761 0.858458 0.451922 0.902263 0.659234 0.870884 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238855 episodes
GETTING ACTION FROM:
action 2, numVisits=238471, meanQ=6.240323, numObservations: 5
action 1, numVisits=380, meanQ=5.881965, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.639761 0.858458 0.451922 0.902263 0.659234 0.870884 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=10854, meanQ=6.542052, numObservations: 5
action 2, numVisits=8, meanQ=1.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 289723 episodes
GETTING ACTION FROM:
action 3, numVisits=300577, meanQ=6.454680, numObservations: 5
action 2, numVisits=8, meanQ=1.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.639761 0.858458 0.451922 0.902263 0.659234 0.870884 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=3009, meanQ=7.990174, numObservations: 4
action 2, numVisits=3, meanQ=2.333333, numObservations: 1
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 300265 episodes
GETTING ACTION FROM:
action 1, numVisits=302981, meanQ=6.705820, numObservations: 4
action 3, numVisits=294, meanQ=6.281939, numObservations: 4
action 2, numVisits=3, meanQ=2.333333, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.639761 0.858458 0.451922 0.902263 0.659234 0.870884 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.8309
Run # 117
Initial state: 0 0.625589 0.867111 0.547272 0.833351 0.910772 0.180559 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239565 episodes
GETTING ACTION FROM:
action 1, numVisits=239392, meanQ=6.226641, numObservations: 5
action 2, numVisits=169, meanQ=5.669705, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 1
Next state: 1 0.625589 0.867111 0.547272 0.833351 0.910772 0.180559 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 118
Initial state: 0 0.514263 0.298438 0.584223 0.8067 0.540564 0.845252 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238897 episodes
GETTING ACTION FROM:
action 3, numVisits=238846, meanQ=6.216340, numObservations: 4
action 2, numVisits=25, meanQ=4.675200, numObservations: 4
action 1, numVisits=24, meanQ=4.498754, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.514263 0.298438 0.584223 0.8067 0.540564 0.845252 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 119
Initial state: 0 0.250242 0.141584 0.652585 0.829742 0.638509 0.869754 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239598 episodes
GETTING ACTION FROM:
action 1, numVisits=239587, meanQ=6.231860, numObservations: 4
action 2, numVisits=8, meanQ=2.873750, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.250242 0.141584 0.652585 0.829742 0.638509 0.869754 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=26614, meanQ=8.867926, numObservations: 5
action 3, numVisits=6484, meanQ=8.826804, numObservations: 4
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 292249 episodes
GETTING ACTION FROM:
action 3, numVisits=202645, meanQ=6.966720, numObservations: 4
action 2, numVisits=122686, meanQ=6.961779, numObservations: 5
action 1, numVisits=17, meanQ=4.940006, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.250242 0.141584 0.652585 0.829742 0.638509 0.869754 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 120
Initial state: 0 0.603405 0.886915 0.681804 0.855134 0.511763 0.141875 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 245065 episodes
GETTING ACTION FROM:
action 2, numVisits=245059, meanQ=6.170056, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 2
Next state: 1 0.603405 0.886915 0.681804 0.855134 0.511763 0.141875 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 121
Initial state: 0 0.685424 0.889624 0.122051 0.659275 0.672569 0.823041 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240023 episodes
GETTING ACTION FROM:
action 1, numVisits=240012, meanQ=6.222720, numObservations: 4
action 3, numVisits=7, meanQ=3.568571, numObservations: 3
action 2, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.685424 0.889624 0.122051 0.659275 0.672569 0.823041 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 122
Initial state: 0 0.633837 0.856141 0.58412 0.896476 0.336114 0.00563586 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 243433 episodes
GETTING ACTION FROM:
action 2, numVisits=243425, meanQ=6.245187, numObservations: 3
action 1, numVisits=5, meanQ=2.980000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.633837 0.856141 0.58412 0.896476 0.336114 0.00563586 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 123
Initial state: 0 0.633814 0.836838 0.534535 0.866581 0.69308 0.562408 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238204 episodes
GETTING ACTION FROM:
action 3, numVisits=238174, meanQ=6.333104, numObservations: 5
action 2, numVisits=27, meanQ=4.665189, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.633814 0.836838 0.534535 0.866581 0.69308 0.562408 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 124
Initial state: 0 0.649956 0.813899 0.307912 0.241714 0.693301 0.88469 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 243224 episodes
GETTING ACTION FROM:
action 3, numVisits=243213, meanQ=6.247676, numObservations: 3
action 2, numVisits=8, meanQ=2.873750, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.649956 0.813899 0.307912 0.241714 0.693301 0.88469 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 125
Initial state: 0 0.693299 0.88788 0.685549 0.858947 0.104112 0.151246 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238617 episodes
GETTING ACTION FROM:
action 3, numVisits=238607, meanQ=6.239419, numObservations: 5
action 1, numVisits=6, meanQ=2.661683, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.693299 0.88788 0.685549 0.858947 0.104112 0.151246 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=19495, meanQ=8.871769, numObservations: 5
action 2, numVisits=13247, meanQ=8.863914, numObservations: 3
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 294600 episodes
GETTING ACTION FROM:
action 1, numVisits=208418, meanQ=6.652367, numObservations: 5
action 2, numVisits=118923, meanQ=6.647032, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 1
action: 1
Next state: 1 0.693299 0.88788 0.685549 0.858947 0.104112 0.151246 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 126
Initial state: 0 0.556683 0.858541 0.980288 0.557185 0.644828 0.827968 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241738 episodes
GETTING ACTION FROM:
action 2, numVisits=241731, meanQ=6.227555, numObservations: 4
action 1, numVisits=3, meanQ=-0.670000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 2 0.556683 0.858541 0.980288 0.557185 0.644828 0.827968 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 127
Initial state: 0 0.535004 0.827828 0.542182 0.806452 0.633434 0.434493 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239473 episodes
GETTING ACTION FROM:
action 1, numVisits=239465, meanQ=6.259257, numObservations: 4
action 2, numVisits=4, meanQ=-0.505000, numObservations: 3
action 3, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.535004 0.827828 0.542182 0.806452 0.633434 0.434493 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 128
Initial state: 0 0.933929 0.66207 0.608798 0.884643 0.546151 0.821114 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241894 episodes
GETTING ACTION FROM:
action 1, numVisits=240985, meanQ=6.197228, numObservations: 4
action 3, numVisits=905, meanQ=5.964185, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 1
action: 1
Next state: 2 0.933929 0.66207 0.608798 0.884643 0.546151 0.821114 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 129
Initial state: 0 0.549078 0.887534 0.200315 0.48383 0.500509 0.864436 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 242137 episodes
GETTING ACTION FROM:
action 2, numVisits=242127, meanQ=6.228795, numObservations: 4
action 1, numVisits=7, meanQ=2.281429, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.549078 0.887534 0.200315 0.48383 0.500509 0.864436 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=33287, meanQ=8.863336, numObservations: 4
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 297364 episodes
GETTING ACTION FROM:
action 3, numVisits=330641, meanQ=7.053142, numObservations: 4
action 1, numVisits=10, meanQ=4.099000, numObservations: 3
action 2, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.549078 0.887534 0.200315 0.48383 0.500509 0.864436 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 130
Initial state: 0 0.261022 0.763331 0.535615 0.809255 0.52219 0.859897 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 236924 episodes
GETTING ACTION FROM:
action 1, numVisits=236633, meanQ=6.216822, numObservations: 5
action 3, numVisits=269, meanQ=5.789052, numObservations: 5
action 2, numVisits=20, meanQ=4.549500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 0 0.261022 0.763331 0.535615 0.809255 0.52219 0.859897 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=18613, meanQ=8.873340, numObservations: 4
action 3, numVisits=13680, meanQ=8.865860, numObservations: 4
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 295336 episodes
GETTING ACTION FROM:
action 2, numVisits=157280, meanQ=6.718682, numObservations: 4
action 3, numVisits=170294, meanQ=6.718462, numObservations: 4
action 1, numVisits=56, meanQ=5.721788, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.261022 0.763331 0.535615 0.809255 0.52219 0.859897 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 131
Initial state: 0 0.596045 0.846562 0.951788 0.757938 0.637515 0.803844 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 242309 episodes
GETTING ACTION FROM:
action 2, numVisits=242299, meanQ=6.214034, numObservations: 4
action 1, numVisits=4, meanQ=1.747500, numObservations: 2
action 3, numVisits=4, meanQ=1.747500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 2 0.596045 0.846562 0.951788 0.757938 0.637515 0.803844 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 132
Initial state: 0 0.590812 0.8542 0.105926 0.220948 0.585349 0.811888 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240238 episodes
GETTING ACTION FROM:
action 3, numVisits=240221, meanQ=6.201858, numObservations: 4
action 1, numVisits=14, meanQ=4.070007, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.590812 0.8542 0.105926 0.220948 0.585349 0.811888 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 133
Initial state: 0 0.69261 0.821251 0.568712 0.860416 0.642668 0.570763 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240772 episodes
GETTING ACTION FROM:
action 1, numVisits=240733, meanQ=6.261833, numObservations: 4
action 2, numVisits=35, meanQ=4.962860, numObservations: 4
action 3, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.69261 0.821251 0.568712 0.860416 0.642668 0.570763 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 134
Initial state: 0 0.608176 0.874305 0.561333 0.864942 0.115318 0.307883 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162278 episodes
GETTING ACTION FROM:
action 0, numVisits=162192, meanQ=4.151577, numObservations: 1
action -1, numVisits=76, meanQ=2.730787, numObservations: 1
action 3, numVisits=8, meanQ=0.373750, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.608176 0.874305 0.561333 0.864942 0.115318 0.307883 w: 1
Observation: 0 0 0.953914 0 0.914971 0 0.303137 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=162179, meanQ=6.226136, numObservations: 4
action 1, numVisits=7, meanQ=3.568571, numObservations: 3
action 2, numVisits=3, meanQ=-0.670000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 259296 episodes
GETTING ACTION FROM:
action 3, numVisits=421472, meanQ=6.263126, numObservations: 4
action 1, numVisits=10, meanQ=3.198000, numObservations: 3
action 2, numVisits=3, meanQ=-0.670000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.608176 0.874305 0.561333 0.864942 0.115318 0.307883 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=70802, meanQ=8.855626, numObservations: 3
action 1, numVisits=36, meanQ=7.638611, numObservations: 4
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 300326 episodes
GETTING ACTION FROM:
action 2, numVisits=371013, meanQ=7.224264, numObservations: 3
action 1, numVisits=151, meanQ=6.614570, numObservations: 5
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.608176 0.874305 0.561333 0.864942 0.115318 0.307883 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 5.8309
Run # 135
Initial state: 0 0.679094 0.84095 0.220013 0.788997 0.649403 0.800356 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226550 episodes
GETTING ACTION FROM:
action 2, numVisits=225155, meanQ=6.219806, numObservations: 5
action 3, numVisits=1391, meanQ=5.947058, numObservations: 5
action 1, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.679094 0.84095 0.220013 0.788997 0.649403 0.800356 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=12443, meanQ=8.932720, numObservations: 3
action 3, numVisits=11854, meanQ=8.931305, numObservations: 3
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 284184 episodes
GETTING ACTION FROM:
action 3, numVisits=227414, meanQ=6.805012, numObservations: 4
action 1, numVisits=81066, meanQ=6.794571, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 1
action: 3
Next state: 1 0.679094 0.84095 0.220013 0.788997 0.649403 0.800356 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 136
Initial state: 0 0.523197 0.821145 0.642795 0.895946 0.641499 0.00280426 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 243748 episodes
GETTING ACTION FROM:
action 1, numVisits=239053, meanQ=6.229791, numObservations: 3
action 2, numVisits=4675, meanQ=6.228050, numObservations: 4
action 3, numVisits=18, meanQ=3.493889, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.523197 0.821145 0.642795 0.895946 0.641499 0.00280426 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 137
Initial state: 0 0.63725 0.87695 0.507805 0.868547 0.00886241 0.0840283 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 244810 episodes
GETTING ACTION FROM:
action 1, numVisits=244804, meanQ=6.246945, numObservations: 3
action 2, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.63725 0.87695 0.507805 0.868547 0.00886241 0.0840283 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 138
Initial state: 0 0.631559 0.834717 0.76017 0.213115 0.651744 0.874654 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 243791 episodes
GETTING ACTION FROM:
action 2, numVisits=243748, meanQ=6.231889, numObservations: 3
action 1, numVisits=35, meanQ=4.932000, numObservations: 5
action 3, numVisits=6, meanQ=2.496683, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.631559 0.834717 0.76017 0.213115 0.651744 0.874654 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=10932, meanQ=6.492307, numObservations: 5
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 291590 episodes
GETTING ACTION FROM:
action 3, numVisits=302469, meanQ=6.371162, numObservations: 5
action 1, numVisits=54, meanQ=5.129444, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.631559 0.834717 0.76017 0.213115 0.651744 0.874654 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 139
Initial state: 0 0.692246 0.832114 0.908197 0.128199 0.598942 0.871679 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240477 episodes
GETTING ACTION FROM:
action 1, numVisits=240447, meanQ=6.241673, numObservations: 4
action 2, numVisits=24, meanQ=4.787092, numObservations: 4
action 3, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.692246 0.832114 0.908197 0.128199 0.598942 0.871679 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 140
Initial state: 0 0.605917 0.801922 0.575738 0.856203 0.236386 0.00134829 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241002 episodes
GETTING ACTION FROM:
action 3, numVisits=236792, meanQ=6.206415, numObservations: 3
action 2, numVisits=4201, meanQ=6.102562, numObservations: 4
action 1, numVisits=7, meanQ=3.284300, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.605917 0.801922 0.575738 0.856203 0.236386 0.00134829 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=38054, meanQ=8.857245, numObservations: 5
action 2, numVisits=208, meanQ=8.432406, numObservations: 4
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 293445 episodes
GETTING ACTION FROM:
action 1, numVisits=329971, meanQ=6.740670, numObservations: 5
action 2, numVisits=1734, meanQ=6.578856, numObservations: 4
action 3, numVisits=3, meanQ=2.330033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.605917 0.801922 0.575738 0.856203 0.236386 0.00134829 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 141
Initial state: 0 0.667253 0.834802 0.0868526 0.466559 0.689474 0.850447 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241843 episodes
GETTING ACTION FROM:
action 3, numVisits=241837, meanQ=6.235566, numObservations: 4
action 1, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.667253 0.834802 0.0868526 0.466559 0.689474 0.850447 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 142
Initial state: 0 0.52248 0.838627 0.184165 0.641425 0.65105 0.806506 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238899 episodes
GETTING ACTION FROM:
action 2, numVisits=238834, meanQ=6.245322, numObservations: 4
action 1, numVisits=58, meanQ=3.041900, numObservations: 4
action 3, numVisits=5, meanQ=1.396000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.52248 0.838627 0.184165 0.641425 0.65105 0.806506 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=27600, meanQ=8.860340, numObservations: 5
action 1, numVisits=11177, meanQ=8.833777, numObservations: 4
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 292869 episodes
GETTING ACTION FROM:
action 3, numVisits=210145, meanQ=6.737119, numObservations: 5
action 1, numVisits=121499, meanQ=6.734541, numObservations: 4
action 2, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.52248 0.838627 0.184165 0.641425 0.65105 0.806506 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 143
Initial state: 0 0.516332 0.832946 0.535134 0.836605 0.654931 0.524035 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241465 episodes
GETTING ACTION FROM:
action 1, numVisits=241447, meanQ=6.330692, numObservations: 4
action 3, numVisits=9, meanQ=3.554444, numObservations: 2
action 2, numVisits=7, meanQ=2.138586, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.516332 0.832946 0.535134 0.836605 0.654931 0.524035 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 144
Initial state: 0 0.874618 0.573763 0.68955 0.820897 0.664608 0.800318 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240653 episodes
GETTING ACTION FROM:
action 2, numVisits=240634, meanQ=6.248457, numObservations: 4
action 3, numVisits=15, meanQ=4.399333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 2
Next state: 1 0.874618 0.573763 0.68955 0.820897 0.664608 0.800318 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 145
Initial state: 0 0.905632 0.734976 0.559 0.854521 0.519444 0.844225 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239212 episodes
GETTING ACTION FROM:
action 3, numVisits=239195, meanQ=6.228059, numObservations: 5
action 1, numVisits=11, meanQ=3.634555, numObservations: 2
action 2, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.905632 0.734976 0.559 0.854521 0.519444 0.844225 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 146
Initial state: 0 0.560189 0.874431 0.264241 0.362791 0.505269 0.804638 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163738 episodes
GETTING ACTION FROM:
action -1, numVisits=163732, meanQ=4.159353, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.560189 0.874431 0.264241 0.362791 0.505269 0.804638 w: 1
Observation: 0 0.621703 0 0.211766 0 0.419454 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=163725, meanQ=6.226143, numObservations: 4
action 2, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 259240 episodes
GETTING ACTION FROM:
action 1, numVisits=422965, meanQ=6.357361, numObservations: 4
action 2, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.560189 0.874431 0.264241 0.362791 0.505269 0.804638 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 147
Initial state: 0 0.12454 0.258709 0.613234 0.826319 0.66638 0.838263 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239409 episodes
GETTING ACTION FROM:
action 1, numVisits=239404, meanQ=6.316225, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.12454 0.258709 0.613234 0.826319 0.66638 0.838263 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=13496, meanQ=8.931294, numObservations: 3
action 3, numVisits=12413, meanQ=8.929069, numObservations: 3
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 293895 episodes
GETTING ACTION FROM:
action 3, numVisits=160356, meanQ=6.695933, numObservations: 4
action 2, numVisits=159442, meanQ=6.694466, numObservations: 4
action 1, numVisits=7, meanQ=3.568571, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.12454 0.258709 0.613234 0.826319 0.66638 0.838263 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 148
Initial state: 0 0.696267 0.838888 0.713663 0.224919 0.553512 0.854638 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239522 episodes
GETTING ACTION FROM:
action 1, numVisits=239409, meanQ=6.194967, numObservations: 5
action 3, numVisits=106, meanQ=5.406323, numObservations: 4
action 2, numVisits=5, meanQ=1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.696267 0.838888 0.713663 0.224919 0.553512 0.854638 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 149
Initial state: 0 0.693439 0.823957 0.533118 0.878466 0.804101 0.390849 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 237282 episodes
GETTING ACTION FROM:
action 2, numVisits=237248, meanQ=6.219583, numObservations: 5
action 3, numVisits=18, meanQ=4.555006, numObservations: 4
action 1, numVisits=14, meanQ=4.070007, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.693439 0.823957 0.533118 0.878466 0.804101 0.390849 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 150
Initial state: 0 0.679205 0.846585 0.586901 0.831402 0.778307 0.119162 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240630 episodes
GETTING ACTION FROM:
action 1, numVisits=240610, meanQ=6.226931, numObservations: 4
action 2, numVisits=12, meanQ=3.925008, numObservations: 3
action 3, numVisits=6, meanQ=2.496683, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.679205 0.846585 0.586901 0.831402 0.778307 0.119162 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 151
Initial state: 0 0.653968 0.870119 0.542718 0.839965 0.631916 0.382065 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 243107 episodes
GETTING ACTION FROM:
action 2, numVisits=243102, meanQ=6.203132, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.653968 0.870119 0.542718 0.839965 0.631916 0.382065 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 152
Initial state: 0 0.590678 0.857627 0.527636 0.819504 0.00190957 0.00471058 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240591 episodes
GETTING ACTION FROM:
action 3, numVisits=240581, meanQ=6.249820, numObservations: 4
action 1, numVisits=6, meanQ=2.496683, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.590678 0.857627 0.527636 0.819504 0.00190957 0.00471058 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=18973, meanQ=8.860713, numObservations: 4
action 1, numVisits=14207, meanQ=8.855049, numObservations: 4
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 294371 episodes
GETTING ACTION FROM:
action 1, numVisits=159645, meanQ=6.766348, numObservations: 4
action 2, numVisits=167905, meanQ=6.766009, numObservations: 4
action 3, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.590678 0.857627 0.527636 0.819504 0.00190957 0.00471058 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 153
Initial state: 0 0.60022 0.868129 0.548169 0.88745 0.262422 0.219135 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 233785 episodes
GETTING ACTION FROM:
action 3, numVisits=233732, meanQ=6.173067, numObservations: 5
action 2, numVisits=49, meanQ=3.923678, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.60022 0.868129 0.548169 0.88745 0.262422 0.219135 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=15936, meanQ=8.876342, numObservations: 5
action 2, numVisits=16364, meanQ=8.851555, numObservations: 5
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 292398 episodes
GETTING ACTION FROM:
action 1, numVisits=197037, meanQ=6.650126, numObservations: 5
action 2, numVisits=127660, meanQ=6.645721, numObservations: 5
action 3, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.60022 0.868129 0.548169 0.88745 0.262422 0.219135 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 154
Initial state: 0 0.522738 0.829316 0.55874 0.992542 0.511745 0.825853 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 237767 episodes
GETTING ACTION FROM:
action 1, numVisits=237755, meanQ=6.227220, numObservations: 5
action 2, numVisits=5, meanQ=1.000000, numObservations: 3
action 3, numVisits=5, meanQ=0.998020, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.522738 0.829316 0.55874 0.992542 0.511745 0.825853 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 155
Initial state: 0 0.583242 0.389526 0.533679 0.820931 0.699422 0.812777 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240889 episodes
GETTING ACTION FROM:
action 1, numVisits=240885, meanQ=6.240539, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.583242 0.389526 0.533679 0.820931 0.699422 0.812777 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=16815, meanQ=8.861104, numObservations: 4
action 2, numVisits=16414, meanQ=8.858116, numObservations: 4
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 295202 episodes
GETTING ACTION FROM:
action 2, numVisits=176637, meanQ=6.747222, numObservations: 4
action 3, numVisits=151792, meanQ=6.745810, numObservations: 4
action 1, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.583242 0.389526 0.533679 0.820931 0.699422 0.812777 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 156
Initial state: 0 0.652844 0.834928 0.872395 0.181676 0.675428 0.880883 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239890 episodes
GETTING ACTION FROM:
action 3, numVisits=238868, meanQ=6.203165, numObservations: 4
action 2, numVisits=999, meanQ=5.981871, numObservations: 5
action 1, numVisits=21, meanQ=4.331910, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.652844 0.834928 0.872395 0.181676 0.675428 0.880883 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 157
Initial state: 0 0.659426 0.854944 0.0517726 0.32902 0.616102 0.822246 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 232968 episodes
GETTING ACTION FROM:
action 1, numVisits=232958, meanQ=6.121960, numObservations: 5
action 3, numVisits=6, meanQ=2.663333, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.659426 0.854944 0.0517726 0.32902 0.616102 0.822246 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 158
Initial state: 0 0.589494 0.419666 0.505648 0.843925 0.655865 0.854543 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240775 episodes
GETTING ACTION FROM:
action 1, numVisits=240771, meanQ=6.255685, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.589494 0.419666 0.505648 0.843925 0.655865 0.854543 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=39313, meanQ=8.864552, numObservations: 4
action 3, numVisits=39, meanQ=7.743079, numObservations: 3
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 297407 episodes
GETTING ACTION FROM:
action 2, numVisits=336677, meanQ=6.726436, numObservations: 4
action 3, numVisits=80, meanQ=5.887251, numObservations: 4
action 1, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.589494 0.419666 0.505648 0.843925 0.655865 0.854543 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 159
Initial state: 0 0.515926 0.857576 0.681644 0.822141 0.97915 0.864124 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241131 episodes
GETTING ACTION FROM:
action 2, numVisits=241114, meanQ=6.307797, numObservations: 4
action 3, numVisits=10, meanQ=3.990000, numObservations: 2
action 1, numVisits=5, meanQ=0.998020, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.515926 0.857576 0.681644 0.822141 0.97915 0.864124 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 160
Initial state: 0 0.649868 0.819797 0.609896 0.877317 0.381583 0.656421 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240365 episodes
GETTING ACTION FROM:
action 3, numVisits=240335, meanQ=6.310320, numObservations: 4
action 1, numVisits=19, meanQ=4.315263, numObservations: 3
action 2, numVisits=9, meanQ=3.554444, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.649868 0.819797 0.609896 0.877317 0.381583 0.656421 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=7110, meanQ=8.815434, numObservations: 4
action 1, numVisits=585, meanQ=8.616762, numObservations: 3
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 294640 episodes
GETTING ACTION FROM:
action 2, numVisits=299205, meanQ=6.660429, numObservations: 4
action 1, numVisits=3118, meanQ=6.544059, numObservations: 4
action 3, numVisits=13, meanQ=3.691538, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.649868 0.819797 0.609896 0.877317 0.381583 0.656421 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 161
Initial state: 0 0.668924 0.875542 0.954336 0.692784 0.610107 0.868811 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239684 episodes
GETTING ACTION FROM:
action 1, numVisits=239680, meanQ=6.262442, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.668924 0.875542 0.954336 0.692784 0.610107 0.868811 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 162
Initial state: 0 0.062818 0.541622 0.695922 0.876716 0.505927 0.823133 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241317 episodes
GETTING ACTION FROM:
action 1, numVisits=241308, meanQ=6.329744, numObservations: 4
action 2, numVisits=3, meanQ=-0.670000, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.062818 0.541622 0.695922 0.876716 0.505927 0.823133 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=14466, meanQ=8.931363, numObservations: 3
action 3, numVisits=11704, meanQ=8.925397, numObservations: 3
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 294097 episodes
GETTING ACTION FROM:
action 2, numVisits=215755, meanQ=6.597350, numObservations: 4
action 3, numVisits=104508, meanQ=6.590851, numObservations: 4
action 1, numVisits=5, meanQ=3.198000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.062818 0.541622 0.695922 0.876716 0.505927 0.823133 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=192, meanQ=8.745208, numObservations: 3
action 3, numVisits=37, meanQ=7.942973, numObservations: 4
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 294864 episodes
GETTING ACTION FROM:
action 3, numVisits=293725, meanQ=6.353424, numObservations: 5
action 2, numVisits=1361, meanQ=6.120823, numObservations: 5
action 1, numVisits=8, meanQ=2.873750, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.062818 0.541622 0.695922 0.876716 0.505927 0.823133 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.8309
Run # 163
Initial state: 0 0.909271 0.489192 0.615742 0.877815 0.64227 0.827152 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241158 episodes
GETTING ACTION FROM:
action 1, numVisits=241153, meanQ=6.240158, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.909271 0.489192 0.615742 0.877815 0.64227 0.827152 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 164
Initial state: 0 0.605532 0.817644 0.688692 0.857547 0.730571 0.771826 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 237445 episodes
GETTING ACTION FROM:
action 1, numVisits=236922, meanQ=6.206858, numObservations: 5
action 3, numVisits=510, meanQ=5.900619, numObservations: 3
action 2, numVisits=11, meanQ=2.726364, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.605532 0.817644 0.688692 0.857547 0.730571 0.771826 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 165
Initial state: 0 0.514391 0.442305 0.525405 0.866272 0.643127 0.851684 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238887 episodes
GETTING ACTION FROM:
action 1, numVisits=238881, meanQ=6.238237, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 1
action: 1
Next state: 0 0.514391 0.442305 0.525405 0.866272 0.643127 0.851684 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=32919, meanQ=8.878909, numObservations: 3
action 2, numVisits=18, meanQ=6.777778, numObservations: 3
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 297604 episodes
GETTING ACTION FROM:
action 2, numVisits=118509, meanQ=6.702424, numObservations: 5
action 3, numVisits=212031, meanQ=6.634808, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 2
Next state: 1 0.514391 0.442305 0.525405 0.866272 0.643127 0.851684 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 166
Initial state: 0 0.667537 0.8784 0.580983 0.806706 0.43454 0.430383 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238335 episodes
GETTING ACTION FROM:
action 3, numVisits=238297, meanQ=6.167974, numObservations: 5
action 2, numVisits=23, meanQ=3.243917, numObservations: 3
action 1, numVisits=13, meanQ=2.844631, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.667537 0.8784 0.580983 0.806706 0.43454 0.430383 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=32927, meanQ=8.875623, numObservations: 5
action 2, numVisits=3, meanQ=2.333333, numObservations: 2
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 292591 episodes
GETTING ACTION FROM:
action 1, numVisits=325503, meanQ=6.567204, numObservations: 5
action 3, numVisits=16, meanQ=4.686256, numObservations: 4
action 2, numVisits=3, meanQ=2.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.667537 0.8784 0.580983 0.806706 0.43454 0.430383 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 167
Initial state: 0 0.654404 0.81707 0.60548 0.821437 0.758364 0.429517 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238791 episodes
GETTING ACTION FROM:
action 1, numVisits=238787, meanQ=6.232204, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.654404 0.81707 0.60548 0.821437 0.758364 0.429517 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 168
Initial state: 0 0.646205 0.878634 0.504945 0.826737 0.185381 0.114169 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 237353 episodes
GETTING ACTION FROM:
action 1, numVisits=237270, meanQ=6.254038, numObservations: 5
action 2, numVisits=73, meanQ=5.422881, numObservations: 3
action 3, numVisits=8, meanQ=2.873750, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.646205 0.878634 0.504945 0.826737 0.185381 0.114169 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 169
Initial state: 0 0.157553 0.528617 0.511125 0.831391 0.649484 0.823789 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238543 episodes
GETTING ACTION FROM:
action 1, numVisits=238506, meanQ=6.219695, numObservations: 5
action 3, numVisits=34, meanQ=3.705300, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.157553 0.528617 0.511125 0.831391 0.649484 0.823789 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=14146, meanQ=8.936932, numObservations: 3
action 3, numVisits=11703, meanQ=8.931704, numObservations: 3
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 295207 episodes
GETTING ACTION FROM:
action 2, numVisits=179574, meanQ=6.591846, numObservations: 4
action 3, numVisits=141479, meanQ=6.589603, numObservations: 4
action 1, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.157553 0.528617 0.511125 0.831391 0.649484 0.823789 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 170
Initial state: 0 0.564847 0.873266 0.689972 0.873016 0.654778 0.834912 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241913 episodes
GETTING ACTION FROM:
action 3, numVisits=241905, meanQ=6.157064, numObservations: 4
action 1, numVisits=4, meanQ=1.747500, numObservations: 3
action 2, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.564847 0.873266 0.689972 0.873016 0.654778 0.834912 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 171
Initial state: 0 0.509183 0.884069 0.674954 0.834446 0.412647 0.952276 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238073 episodes
GETTING ACTION FROM:
action 1, numVisits=238060, meanQ=6.305830, numObservations: 5
action 2, numVisits=9, meanQ=3.433333, numObservations: 3
action 3, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.509183 0.884069 0.674954 0.834446 0.412647 0.952276 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 172
Initial state: 0 0.543583 0.884908 0.626646 0.867148 0.960857 0.266643 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 243312 episodes
GETTING ACTION FROM:
action 2, numVisits=243303, meanQ=6.231423, numObservations: 4
action 3, numVisits=6, meanQ=0.825067, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.543583 0.884908 0.626646 0.867148 0.960857 0.266643 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 173
Initial state: 0 0.762427 0.357387 0.672743 0.8439 0.584689 0.82468 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239702 episodes
GETTING ACTION FROM:
action 2, numVisits=239561, meanQ=6.247643, numObservations: 5
action 1, numVisits=138, meanQ=5.582103, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.762427 0.357387 0.672743 0.8439 0.584689 0.82468 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 174
Initial state: 0 0.609151 0.893845 0.52972 0.883291 0.595005 0.843109 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239206 episodes
GETTING ACTION FROM:
action 1, numVisits=239072, meanQ=6.228485, numObservations: 5
action 3, numVisits=125, meanQ=5.595520, numObservations: 4
action 2, numVisits=7, meanQ=3.285714, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.609151 0.893845 0.52972 0.883291 0.595005 0.843109 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 175
Initial state: 0 0.612468 0.807387 0.116918 0.668183 0.694915 0.813681 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241274 episodes
GETTING ACTION FROM:
action 2, numVisits=241269, meanQ=6.225554, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.612468 0.807387 0.116918 0.668183 0.694915 0.813681 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=18186, meanQ=8.863089, numObservations: 4
action 3, numVisits=14791, meanQ=8.861012, numObservations: 3
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 296406 episodes
GETTING ACTION FROM:
action 1, numVisits=247011, meanQ=6.726852, numObservations: 4
action 3, numVisits=82369, meanQ=6.715457, numObservations: 3
action 2, numVisits=4, meanQ=1.747500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.612468 0.807387 0.116918 0.668183 0.694915 0.813681 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 176
Initial state: 0 0.694338 0.834276 0.928147 0.326014 0.665398 0.837084 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240023 episodes
GETTING ACTION FROM:
action 2, numVisits=240019, meanQ=6.168763, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.694338 0.834276 0.928147 0.326014 0.665398 0.837084 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 177
Initial state: 0 0.689156 0.859169 0.292585 0.665391 0.588767 0.813298 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 242436 episodes
GETTING ACTION FROM:
action 2, numVisits=242432, meanQ=6.261631, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.689156 0.859169 0.292585 0.665391 0.588767 0.813298 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=30554, meanQ=8.859154, numObservations: 3
action 1, numVisits=8736, meanQ=8.823256, numObservations: 4
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 298200 episodes
GETTING ACTION FROM:
action 3, numVisits=251929, meanQ=6.725445, numObservations: 3
action 1, numVisits=85558, meanQ=6.715813, numObservations: 4
action 2, numVisits=4, meanQ=1.747500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.689156 0.859169 0.292585 0.665391 0.588767 0.813298 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 178
Initial state: 0 0.63573 0.822929 0.0697449 0.226088 0.601758 0.899865 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 244820 episodes
GETTING ACTION FROM:
action 2, numVisits=244164, meanQ=6.246258, numObservations: 3
action 1, numVisits=649, meanQ=5.970947, numObservations: 5
action 3, numVisits=5, meanQ=2.980000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.63573 0.822929 0.0697449 0.226088 0.601758 0.899865 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=30240, meanQ=8.855062, numObservations: 4
action 3, numVisits=9542, meanQ=8.824079, numObservations: 3
action 2, numVisits=11, meanQ=6.569091, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 296543 episodes
GETTING ACTION FROM:
action 1, numVisits=260488, meanQ=6.964419, numObservations: 4
action 3, numVisits=75614, meanQ=6.952188, numObservations: 3
action 2, numVisits=234, meanQ=6.442906, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.63573 0.822929 0.0697449 0.226088 0.601758 0.899865 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 179
Initial state: 0 0.667185 0.199553 0.628205 0.809344 0.548597 0.87643 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240854 episodes
GETTING ACTION FROM:
action 1, numVisits=240847, meanQ=6.232480, numObservations: 4
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.667185 0.199553 0.628205 0.809344 0.548597 0.87643 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=19947, meanQ=8.864022, numObservations: 4
action 3, numVisits=13259, meanQ=8.854091, numObservations: 5
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 289696 episodes
GETTING ACTION FROM:
action 3, numVisits=189413, meanQ=6.711524, numObservations: 5
action 2, numVisits=133488, meanQ=6.708849, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 3
Next state: 1 0.667185 0.199553 0.628205 0.809344 0.548597 0.87643 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 180
Initial state: 0 0.587416 0.838424 0.780597 0.195828 0.682229 0.85362 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241041 episodes
GETTING ACTION FROM:
action 1, numVisits=241020, meanQ=6.345325, numObservations: 4
action 3, numVisits=15, meanQ=3.065340, numObservations: 4
action 2, numVisits=4, meanQ=1.747500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.587416 0.838424 0.780597 0.195828 0.682229 0.85362 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 181
Initial state: 0 0.693677 0.89515 0.589207 0.858058 0.859311 0.722335 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240049 episodes
GETTING ACTION FROM:
action 2, numVisits=240044, meanQ=6.242873, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.693677 0.89515 0.589207 0.858058 0.859311 0.722335 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 182
Initial state: 0 0.706712 0.370422 0.51508 0.804572 0.622975 0.890522 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238468 episodes
GETTING ACTION FROM:
action 3, numVisits=238460, meanQ=6.242173, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=4, meanQ=-1.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.706712 0.370422 0.51508 0.804572 0.622975 0.890522 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 183
Initial state: 0 0.522533 0.841537 0.163839 0.96325 0.698031 0.885234 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238178 episodes
GETTING ACTION FROM:
action 1, numVisits=238174, meanQ=6.269276, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.522533 0.841537 0.163839 0.96325 0.698031 0.885234 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 184
Initial state: 0 0.51179 0.811243 0.736338 0.24479 0.666456 0.818541 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239711 episodes
GETTING ACTION FROM:
action 1, numVisits=239696, meanQ=6.235605, numObservations: 4
action 2, numVisits=9, meanQ=2.432222, numObservations: 4
action 3, numVisits=4, meanQ=1.747500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.51179 0.811243 0.736338 0.24479 0.666456 0.818541 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 185
Initial state: 0 0.678349 0.604782 0.581028 0.804668 0.637561 0.834226 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 245087 episodes
GETTING ACTION FROM:
action 2, numVisits=245061, meanQ=6.245807, numObservations: 3
action 1, numVisits=22, meanQ=3.945459, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.678349 0.604782 0.581028 0.804668 0.637561 0.834226 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=11253, meanQ=6.519189, numObservations: 4
action 2, numVisits=8, meanQ=3.998763, numObservations: 3
action 3, numVisits=3, meanQ=2.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 296595 episodes
GETTING ACTION FROM:
action 1, numVisits=306114, meanQ=6.743273, numObservations: 4
action 3, numVisits=1737, meanQ=6.578642, numObservations: 5
action 2, numVisits=8, meanQ=3.998763, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 0 0.678349 0.604782 0.581028 0.804668 0.637561 0.834226 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=4266, meanQ=8.866783, numObservations: 4
action 2, numVisits=2, meanQ=4.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 295388 episodes
GETTING ACTION FROM:
action 3, numVisits=299616, meanQ=6.631450, numObservations: 5
action 2, numVisits=40, meanQ=5.274750, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.678349 0.604782 0.581028 0.804668 0.637561 0.834226 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.8309
Run # 186
Initial state: 0 0.586079 0.890204 0.761038 0.79392 0.648273 0.887022 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 242875 episodes
GETTING ACTION FROM:
action 2, numVisits=194790, meanQ=6.298943, numObservations: 4
action 3, numVisits=48081, meanQ=6.234770, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 2 0.586079 0.890204 0.761038 0.79392 0.648273 0.887022 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 187
Initial state: 0 0.144885 0.0200751 0.51094 0.857928 0.508187 0.822587 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240936 episodes
GETTING ACTION FROM:
action 1, numVisits=240927, meanQ=6.226298, numObservations: 4
action 3, numVisits=6, meanQ=2.663333, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.144885 0.0200751 0.51094 0.857928 0.508187 0.822587 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=19858, meanQ=8.878762, numObservations: 4
action 3, numVisits=13339, meanQ=8.867631, numObservations: 4
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 295750 episodes
GETTING ACTION FROM:
action 2, numVisits=239845, meanQ=6.644034, numObservations: 4
action 3, numVisits=89101, meanQ=6.634281, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=2, meanQ=-5.505000, numObservations: 1
action: 2
Next state: 1 0.144885 0.0200751 0.51094 0.857928 0.508187 0.822587 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 188
Initial state: 0 0.616011 0.872384 0.6983 0.864198 0.0682895 0.106953 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 233262 episodes
GETTING ACTION FROM:
action 3, numVisits=233232, meanQ=6.155900, numObservations: 4
action 2, numVisits=26, meanQ=4.681158, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.616011 0.872384 0.6983 0.864198 0.0682895 0.106953 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=25273, meanQ=8.936470, numObservations: 3
action 2, numVisits=57, meanQ=8.084040, numObservations: 3
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 298849 episodes
GETTING ACTION FROM:
action 1, numVisits=323934, meanQ=6.732110, numObservations: 3
action 2, numVisits=244, meanQ=6.268116, numObservations: 4
action 3, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.616011 0.872384 0.6983 0.864198 0.0682895 0.106953 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 189
Initial state: 0 0.104183 0.48479 0.606523 0.85717 0.621358 0.873367 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 245686 episodes
GETTING ACTION FROM:
action 2, numVisits=245678, meanQ=6.168612, numObservations: 3
action 1, numVisits=3, meanQ=-0.670000, numObservations: 2
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.104183 0.48479 0.606523 0.85717 0.621358 0.873367 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 190
Initial state: 0 0.644115 0.854188 0.574495 0.89193 0.17523 0.980952 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238529 episodes
GETTING ACTION FROM:
action 1, numVisits=238519, meanQ=6.237510, numObservations: 5
action 2, numVisits=6, meanQ=2.663333, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 1
action: 1
Next state: 1 0.644115 0.854188 0.574495 0.89193 0.17523 0.980952 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 191
Initial state: 0 0.559275 0.846402 0.711094 0.0743108 0.607668 0.853341 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239026 episodes
GETTING ACTION FROM:
action 1, numVisits=239010, meanQ=6.250825, numObservations: 5
action 3, numVisits=13, meanQ=3.691538, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.559275 0.846402 0.711094 0.0743108 0.607668 0.853341 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 192
Initial state: 0 0.69373 0.844279 0.656899 0.866536 0.43736 0.357741 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241243 episodes
GETTING ACTION FROM:
action 1, numVisits=241235, meanQ=6.234830, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.69373 0.844279 0.656899 0.866536 0.43736 0.357741 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 193
Initial state: 0 0.564161 0.823501 0.0757088 0.349383 0.620392 0.872676 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 244339 episodes
GETTING ACTION FROM:
action 1, numVisits=244331, meanQ=6.231796, numObservations: 3
action 3, numVisits=2, meanQ=-0.010000, numObservations: 2
action 2, numVisits=4, meanQ=-1.002475, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.564161 0.823501 0.0757088 0.349383 0.620392 0.872676 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 194
Initial state: 0 0.623183 0.830779 0.580221 0.816406 0.205855 0.130075 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 237793 episodes
GETTING ACTION FROM:
action 1, numVisits=237789, meanQ=6.216886, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.623183 0.830779 0.580221 0.816406 0.205855 0.130075 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 195
Initial state: 0 0.451321 0.324978 0.583202 0.870534 0.547923 0.800607 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240247 episodes
GETTING ACTION FROM:
action 3, numVisits=239955, meanQ=6.167279, numObservations: 4
action 1, numVisits=283, meanQ=5.648657, numObservations: 5
action 2, numVisits=7, meanQ=3.285714, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.451321 0.324978 0.583202 0.870534 0.547923 0.800607 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=23103, meanQ=8.853435, numObservations: 4
action 1, numVisits=15803, meanQ=8.843060, numObservations: 4
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 295407 episodes
GETTING ACTION FROM:
action 2, numVisits=192804, meanQ=6.760485, numObservations: 4
action 1, numVisits=141505, meanQ=6.757339, numObservations: 4
action 3, numVisits=5, meanQ=3.194040, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.451321 0.324978 0.583202 0.870534 0.547923 0.800607 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 196
Initial state: 0 0.605425 0.876227 0.549644 0.896918 0.991617 0.512653 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241101 episodes
GETTING ACTION FROM:
action 1, numVisits=241077, meanQ=6.251625, numObservations: 4
action 2, numVisits=11, meanQ=3.725455, numObservations: 3
action 3, numVisits=11, meanQ=2.725464, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.605425 0.876227 0.549644 0.896918 0.991617 0.512653 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 197
Initial state: 0 0.356774 0.282759 0.527009 0.850121 0.658752 0.885915 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238308 episodes
GETTING ACTION FROM:
action 1, numVisits=236970, meanQ=6.218118, numObservations: 5
action 3, numVisits=1334, meanQ=6.031435, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 0 0.356774 0.282759 0.527009 0.850121 0.658752 0.885915 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=32437, meanQ=8.859241, numObservations: 4
action 3, numVisits=25, meanQ=7.439204, numObservations: 3
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 296017 episodes
GETTING ACTION FROM:
action 2, numVisits=328382, meanQ=6.818340, numObservations: 4
action 3, numVisits=86, meanQ=5.962792, numObservations: 3
action 1, numVisits=12, meanQ=4.081675, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.356774 0.282759 0.527009 0.850121 0.658752 0.885915 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 198
Initial state: 0 0.680236 0.874653 0.690297 0.824898 0.84063 0.00606375 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 244413 episodes
GETTING ACTION FROM:
action 3, numVisits=244406, meanQ=6.208487, numObservations: 3
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.680236 0.874653 0.690297 0.824898 0.84063 0.00606375 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 199
Initial state: 0 0.452442 0.897811 0.697378 0.816492 0.520708 0.830434 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162065 episodes
GETTING ACTION FROM:
action -1, numVisits=162058, meanQ=4.175034, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.452442 0.897811 0.697378 0.816492 0.520708 0.830434 w: 1
Observation: 0 0.511753 0 0.794279 0 0.495732 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=162034, meanQ=6.247317, numObservations: 5
action 3, numVisits=20, meanQ=4.044005, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 258675 episodes
GETTING ACTION FROM:
action 1, numVisits=420645, meanQ=6.168930, numObservations: 5
action -1, numVisits=64, meanQ=5.275978, numObservations: 1
action 3, numVisits=20, meanQ=4.044005, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.452442 0.897811 0.697378 0.816492 0.520708 0.830434 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=22502, meanQ=8.676904, numObservations: 4
action 2, numVisits=13, meanQ=6.768462, numObservations: 3
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 296554 episodes
GETTING ACTION FROM:
action 3, numVisits=319004, meanQ=6.335188, numObservations: 4
action 2, numVisits=29, meanQ=4.930345, numObservations: 4
action 1, numVisits=37, meanQ=4.825405, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.452442 0.897811 0.697378 0.816492 0.520708 0.830434 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 5.8309
Run # 200
Initial state: 0 0.667415 0.808653 0.590741 0.881382 0.411696 0.970819 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 236804 episodes
GETTING ACTION FROM:
action 3, numVisits=236794, meanQ=6.244700, numObservations: 5
action 1, numVisits=5, meanQ=1.396000, numObservations: 2
action 2, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.667415 0.808653 0.590741 0.881382 0.411696 0.970819 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 201
Initial state: 0 0.586533 0.813234 0.386003 0.776224 0.669576 0.838572 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240033 episodes
GETTING ACTION FROM:
action 2, numVisits=240027, meanQ=6.300097, numObservations: 5
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.586533 0.813234 0.386003 0.776224 0.669576 0.838572 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=26052, meanQ=8.936799, numObservations: 3
action 1, numVisits=46, meanQ=7.934135, numObservations: 3
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 294443 episodes
GETTING ACTION FROM:
action 3, numVisits=318974, meanQ=6.767640, numObservations: 4
action 2, numVisits=1219, meanQ=6.565590, numObservations: 5
action 1, numVisits=349, meanQ=6.357537, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.586533 0.813234 0.386003 0.776224 0.669576 0.838572 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 202
Initial state: 0 0.828657 0.426513 0.535988 0.805052 0.520568 0.832501 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238290 episodes
GETTING ACTION FROM:
action 3, numVisits=238285, meanQ=6.191809, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.828657 0.426513 0.535988 0.805052 0.520568 0.832501 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 203
Initial state: 0 0.802832 0.0184152 0.644357 0.826522 0.670857 0.879592 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 237642 episodes
GETTING ACTION FROM:
action 3, numVisits=237616, meanQ=6.316054, numObservations: 5
action 1, numVisits=23, meanQ=3.868265, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.802832 0.0184152 0.644357 0.826522 0.670857 0.879592 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 204
Initial state: 0 0.452143 0.833644 0.611571 0.856935 0.510457 0.85236 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 245399 episodes
GETTING ACTION FROM:
action 2, numVisits=245393, meanQ=6.230470, numObservations: 3
action 3, numVisits=2, meanQ=-0.509950, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.452143 0.833644 0.611571 0.856935 0.510457 0.85236 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 205
Initial state: 0 0.0776194 0.287183 0.554525 0.851371 0.554292 0.858502 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241260 episodes
GETTING ACTION FROM:
action 3, numVisits=240863, meanQ=6.204930, numObservations: 4
action 1, numVisits=390, meanQ=5.833960, numObservations: 4
action 2, numVisits=5, meanQ=2.980000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.0776194 0.287183 0.554525 0.851371 0.554292 0.858502 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 206
Initial state: 0 0.571089 0.888284 0.673379 0.860413 0.355922 0.0840661 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238863 episodes
GETTING ACTION FROM:
action 1, numVisits=238809, meanQ=6.227489, numObservations: 5
action 3, numVisits=50, meanQ=5.179408, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.571089 0.888284 0.673379 0.860413 0.355922 0.0840661 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 207
Initial state: 0 0.701225 0.238451 0.695163 0.83511 0.662677 0.868503 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240245 episodes
GETTING ACTION FROM:
action 2, numVisits=240237, meanQ=6.246882, numObservations: 5
action 3, numVisits=5, meanQ=1.396000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.701225 0.238451 0.695163 0.83511 0.662677 0.868503 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1137, meanQ=6.186612, numObservations: 4
action 3, numVisits=16, meanQ=4.686875, numObservations: 4
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 295974 episodes
GETTING ACTION FROM:
action 1, numVisits=297111, meanQ=6.558269, numObservations: 4
action 3, numVisits=16, meanQ=4.686875, numObservations: 4
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 2 0.701225 0.238451 0.695163 0.83511 0.662677 0.868503 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11.89
Run # 208
Initial state: 0 0.0856006 0.501764 0.59264 0.866991 0.543161 0.881144 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 242058 episodes
GETTING ACTION FROM:
action 2, numVisits=242053, meanQ=6.245295, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.0856006 0.501764 0.59264 0.866991 0.543161 0.881144 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 209
Initial state: 0 0.653901 0.803709 0.54749 0.813639 0.752912 0.670227 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241833 episodes
GETTING ACTION FROM:
action 2, numVisits=241795, meanQ=6.217099, numObservations: 4
action 1, numVisits=35, meanQ=4.362863, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.653901 0.803709 0.54749 0.813639 0.752912 0.670227 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 210
Initial state: 0 0.593689 0.879288 0.623407 0.84257 0.566203 0.864842 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 242146 episodes
GETTING ACTION FROM:
action 2, numVisits=242140, meanQ=6.219960, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 2
Next state: 1 0.593689 0.879288 0.623407 0.84257 0.566203 0.864842 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 211
Initial state: 0 0.534167 0.865584 0.55188 0.864307 0.228556 0.0289062 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238693 episodes
GETTING ACTION FROM:
action 1, numVisits=218401, meanQ=6.234334, numObservations: 5
action 2, numVisits=20283, meanQ=6.126206, numObservations: 4
action 3, numVisits=7, meanQ=3.568571, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.534167 0.865584 0.55188 0.864307 0.228556 0.0289062 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 212
Initial state: 0 0.295275 0.0775724 0.510711 0.817056 0.672731 0.894812 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238373 episodes
GETTING ACTION FROM:
action 1, numVisits=238331, meanQ=6.152369, numObservations: 3
action 3, numVisits=38, meanQ=4.434739, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 0 0.295275 0.0775724 0.510711 0.817056 0.672731 0.894812 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=24329, meanQ=8.854569, numObservations: 3
action 3, numVisits=14540, meanQ=8.843132, numObservations: 3
action 1, numVisits=6, meanQ=5.451667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 299292 episodes
GETTING ACTION FROM:
action 2, numVisits=235336, meanQ=6.642190, numObservations: 3
action 3, numVisits=102742, meanQ=6.634546, numObservations: 3
action 1, numVisits=89, meanQ=5.842585, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.295275 0.0775724 0.510711 0.817056 0.672731 0.894812 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 213
Initial state: 0 0.623976 0.835439 0.506207 0.881573 0.732662 0.408088 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241249 episodes
GETTING ACTION FROM:
action 3, numVisits=241231, meanQ=6.198884, numObservations: 4
action 2, numVisits=14, meanQ=3.349286, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 2 0.623976 0.835439 0.506207 0.881573 0.732662 0.408088 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 214
Initial state: 0 0.291419 0.0704689 0.56104 0.823464 0.570248 0.819577 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 242362 episodes
GETTING ACTION FROM:
action 2, numVisits=242358, meanQ=6.221738, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.291419 0.0704689 0.56104 0.823464 0.570248 0.819577 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 215
Initial state: 0 0.0208423 0.7721 0.512721 0.877561 0.694137 0.80908 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239688 episodes
GETTING ACTION FROM:
action 1, numVisits=239681, meanQ=6.216622, numObservations: 4
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 0 0.0208423 0.7721 0.512721 0.877561 0.694137 0.80908 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=32906, meanQ=8.881237, numObservations: 5
action 2, numVisits=6, meanQ=5.666667, numObservations: 2
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 292086 episodes
GETTING ACTION FROM:
action 3, numVisits=324623, meanQ=6.512237, numObservations: 5
action 1, numVisits=369, meanQ=6.116792, numObservations: 4
action 2, numVisits=7, meanQ=3.285714, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.0208423 0.7721 0.512721 0.877561 0.694137 0.80908 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 216
Initial state: 0 0.638329 0.88608 0.66228 0.858852 0.214716 0.804912 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239198 episodes
GETTING ACTION FROM:
action 2, numVisits=239171, meanQ=6.233458, numObservations: 5
action 1, numVisits=22, meanQ=4.589095, numObservations: 4
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.638329 0.88608 0.66228 0.858852 0.214716 0.804912 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 217
Initial state: 0 0.683714 0.864109 0.150649 0.0755251 0.665276 0.846944 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241234 episodes
GETTING ACTION FROM:
action 3, numVisits=241230, meanQ=6.225927, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.683714 0.864109 0.150649 0.0755251 0.665276 0.846944 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 218
Initial state: 0 0.980829 0.970917 0.540786 0.878776 0.559185 0.892385 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238878 episodes
GETTING ACTION FROM:
action 1, numVisits=238874, meanQ=6.226506, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.980829 0.970917 0.540786 0.878776 0.559185 0.892385 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 219
Initial state: 0 0.663696 0.889325 0.00973784 0.889595 0.533207 0.844006 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163092 episodes
GETTING ACTION FROM:
action -1, numVisits=163084, meanQ=4.191359, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 1
action: -1
Next state: 0 0.663696 0.889325 0.00973784 0.889595 0.533207 0.844006 w: 1
Observation: 0 0.683653 0 0 0 0.536918 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=151697, meanQ=6.253981, numObservations: 4
action 1, numVisits=11374, meanQ=6.156238, numObservations: 5
action 2, numVisits=10, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 257859 episodes
GETTING ACTION FROM:
action 1, numVisits=157976, meanQ=6.433109, numObservations: 5
action 3, numVisits=262954, meanQ=6.207127, numObservations: 4
action 2, numVisits=10, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.663696 0.889325 0.00973784 0.889595 0.533207 0.844006 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 220
Initial state: 0 0.320782 0.3649 0.594247 0.806393 0.576253 0.831809 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238650 episodes
GETTING ACTION FROM:
action 1, numVisits=238643, meanQ=6.232368, numObservations: 4
action 2, numVisits=2, meanQ=-0.010000, numObservations: 2
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 0 0.320782 0.3649 0.594247 0.806393 0.576253 0.831809 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=38875, meanQ=8.863065, numObservations: 5
action 3, numVisits=108, meanQ=8.146206, numObservations: 3
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 291678 episodes
GETTING ACTION FROM:
action 2, numVisits=328651, meanQ=6.747848, numObservations: 5
action 3, numVisits=1989, meanQ=6.595567, numObservations: 4
action 1, numVisits=22, meanQ=4.855000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.320782 0.3649 0.594247 0.806393 0.576253 0.831809 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 221
Initial state: 0 0.633988 0.874448 0.676458 0.822298 0.590171 0.148692 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241658 episodes
GETTING ACTION FROM:
action 2, numVisits=241650, meanQ=6.221011, numObservations: 4
action 1, numVisits=3, meanQ=-0.670000, numObservations: 2
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.633988 0.874448 0.676458 0.822298 0.590171 0.148692 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 222
Initial state: 0 0.650504 0.853895 0.513452 0.833224 0.97156 0.877945 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 237851 episodes
GETTING ACTION FROM:
action 1, numVisits=237826, meanQ=6.213525, numObservations: 5
action 2, numVisits=14, meanQ=4.070007, numObservations: 3
action 3, numVisits=9, meanQ=3.554444, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.650504 0.853895 0.513452 0.833224 0.97156 0.877945 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 223
Initial state: 0 0.576253 0.866894 0.532585 0.857201 0.945601 0.802328 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 243495 episodes
GETTING ACTION FROM:
action 3, numVisits=243465, meanQ=6.209481, numObservations: 3
action 2, numVisits=26, meanQ=4.730392, numObservations: 3
action 1, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 2 0.576253 0.866894 0.532585 0.857201 0.945601 0.802328 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 224
Initial state: 0 0.518709 0.882865 0.738097 0.23168 0.55691 0.819148 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 244019 episodes
GETTING ACTION FROM:
action 1, numVisits=244006, meanQ=6.210359, numObservations: 3
action 2, numVisits=9, meanQ=2.441133, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.518709 0.882865 0.738097 0.23168 0.55691 0.819148 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 225
Initial state: 0 0.611551 0.852733 0.54133 0.874833 0.713815 0.636979 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239324 episodes
GETTING ACTION FROM:
action 1, numVisits=239309, meanQ=6.225187, numObservations: 5
action 2, numVisits=12, meanQ=2.240850, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.611551 0.852733 0.54133 0.874833 0.713815 0.636979 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 226
Initial state: 0 0.690666 0.765459 0.535283 0.809347 0.668772 0.810303 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 243740 episodes
GETTING ACTION FROM:
action 2, numVisits=243732, meanQ=6.228074, numObservations: 4
action 1, numVisits=4, meanQ=1.747500, numObservations: 2
action 3, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.690666 0.765459 0.535283 0.809347 0.668772 0.810303 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 227
Initial state: 0 0.501231 0.851427 0.934086 0.219873 0.510639 0.878941 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 243391 episodes
GETTING ACTION FROM:
action 2, numVisits=243353, meanQ=6.158058, numObservations: 4
action 1, numVisits=32, meanQ=3.925625, numObservations: 3
action 3, numVisits=4, meanQ=1.747500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 2 0.501231 0.851427 0.934086 0.219873 0.510639 0.878941 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 228
Initial state: 0 0.543393 0.829108 0.408571 0.202481 0.527189 0.826216 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241034 episodes
GETTING ACTION FROM:
action 1, numVisits=241014, meanQ=6.230745, numObservations: 4
action 2, numVisits=11, meanQ=3.632755, numObservations: 3
action 3, numVisits=7, meanQ=1.998571, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.543393 0.829108 0.408571 0.202481 0.527189 0.826216 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 229
Initial state: 0 0.923263 0.939685 0.634195 0.855023 0.634365 0.811069 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238557 episodes
GETTING ACTION FROM:
action 1, numVisits=238541, meanQ=6.185923, numObservations: 5
action 2, numVisits=12, meanQ=4.000000, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 2 0.923263 0.939685 0.634195 0.855023 0.634365 0.811069 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 230
Initial state: 0 0.576161 0.867966 0.548981 0.16834 0.573985 0.82816 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238130 episodes
GETTING ACTION FROM:
action 3, numVisits=238116, meanQ=6.209781, numObservations: 5
action 2, numVisits=10, meanQ=3.296010, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.576161 0.867966 0.548981 0.16834 0.573985 0.82816 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 231
Initial state: 0 0.523223 0.894331 0.51814 0.846596 0.465749 0.453763 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 244350 episodes
GETTING ACTION FROM:
action 3, numVisits=244278, meanQ=6.226587, numObservations: 3
action 1, numVisits=62, meanQ=5.146292, numObservations: 3
action 2, numVisits=8, meanQ=2.873750, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.523223 0.894331 0.51814 0.846596 0.465749 0.453763 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=28857, meanQ=8.869468, numObservations: 5
action 2, numVisits=10570, meanQ=8.843464, numObservations: 4
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 294148 episodes
GETTING ACTION FROM:
action 1, numVisits=172652, meanQ=6.842027, numObservations: 5
action 2, numVisits=160922, meanQ=6.841832, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 1
Next state: 1 0.523223 0.894331 0.51814 0.846596 0.465749 0.453763 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 232
Initial state: 0 0.676927 0.878664 0.0230789 0.454738 0.674748 0.82782 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240767 episodes
GETTING ACTION FROM:
action 1, numVisits=240743, meanQ=6.236988, numObservations: 4
action 3, numVisits=21, meanQ=3.809048, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.676927 0.878664 0.0230789 0.454738 0.674748 0.82782 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 233
Initial state: 0 0.591305 0.874834 0.595309 0.870646 0.923417 0.239133 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240310 episodes
GETTING ACTION FROM:
action 2, numVisits=226415, meanQ=6.230548, numObservations: 5
action 3, numVisits=13884, meanQ=6.151677, numObservations: 3
action 1, numVisits=9, meanQ=3.433333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.591305 0.874834 0.595309 0.870646 0.923417 0.239133 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 234
Initial state: 0 0.572753 0.84018 0.616327 0.832521 0.186403 0.0423759 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 243605 episodes
GETTING ACTION FROM:
action 1, numVisits=243597, meanQ=6.212336, numObservations: 3
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.572753 0.84018 0.616327 0.832521 0.186403 0.0423759 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 235
Initial state: 0 0.737517 0.843913 0.508705 0.884212 0.587698 0.806703 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 235799 episodes
GETTING ACTION FROM:
action 3, numVisits=235794, meanQ=6.090862, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.737517 0.843913 0.508705 0.884212 0.587698 0.806703 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 236
Initial state: 0 0.625803 0.806513 0.636987 0.893085 0.409582 0.178071 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241795 episodes
GETTING ACTION FROM:
action 3, numVisits=241788, meanQ=6.244385, numObservations: 4
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.625803 0.806513 0.636987 0.893085 0.409582 0.178071 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=39058, meanQ=8.858957, numObservations: 3
action 2, numVisits=7, meanQ=6.142857, numObservations: 2
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 299883 episodes
GETTING ACTION FROM:
action 1, numVisits=337998, meanQ=6.710823, numObservations: 3
action 2, numVisits=835, meanQ=6.470156, numObservations: 3
action 3, numVisits=116, meanQ=6.041381, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.625803 0.806513 0.636987 0.893085 0.409582 0.178071 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 237
Initial state: 0 0.89347 0.808933 0.569387 0.877969 0.646933 0.822465 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 243477 episodes
GETTING ACTION FROM:
action 3, numVisits=243469, meanQ=6.185540, numObservations: 3
action 2, numVisits=5, meanQ=0.998020, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.89347 0.808933 0.569387 0.877969 0.646933 0.822465 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 238
Initial state: 0 0.664869 0.812308 0.553885 0.697983 0.646402 0.877852 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238936 episodes
GETTING ACTION FROM:
action 1, numVisits=238923, meanQ=6.226809, numObservations: 5
action 3, numVisits=9, meanQ=3.554444, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.664869 0.812308 0.553885 0.697983 0.646402 0.877852 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 239
Initial state: 0 0.559808 0.846849 0.551031 0.853162 0.929153 0.877676 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241398 episodes
GETTING ACTION FROM:
action 1, numVisits=241393, meanQ=6.217135, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.559808 0.846849 0.551031 0.853162 0.929153 0.877676 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 240
Initial state: 0 0.656587 0.878264 0.514234 0.231161 0.648461 0.815537 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241358 episodes
GETTING ACTION FROM:
action 2, numVisits=241323, meanQ=6.206692, numObservations: 4
action 1, numVisits=15, meanQ=4.254000, numObservations: 3
action 3, numVisits=18, meanQ=3.493889, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 2 0.656587 0.878264 0.514234 0.231161 0.648461 0.815537 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 241
Initial state: 0 0.606433 0.893078 0.582797 0.372138 0.600718 0.803538 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240816 episodes
GETTING ACTION FROM:
action 3, numVisits=240811, meanQ=6.218913, numObservations: 4
action 2, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.606433 0.893078 0.582797 0.372138 0.600718 0.803538 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 242
Initial state: 0 0.504115 0.881009 0.453445 0.042377 0.57681 0.822637 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240641 episodes
GETTING ACTION FROM:
action 3, numVisits=240591, meanQ=6.236652, numObservations: 4
action 1, numVisits=42, meanQ=3.232867, numObservations: 4
action 2, numVisits=6, meanQ=2.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.504115 0.881009 0.453445 0.042377 0.57681 0.822637 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 243
Initial state: 0 0.674186 0.866317 0.0662523 0.673747 0.508785 0.84332 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240808 episodes
GETTING ACTION FROM:
action 3, numVisits=240768, meanQ=6.307956, numObservations: 4
action 2, numVisits=26, meanQ=4.802319, numObservations: 3
action 1, numVisits=12, meanQ=4.165000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.674186 0.866317 0.0662523 0.673747 0.508785 0.84332 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 244
Initial state: 0 0.580291 0.898978 0.647335 0.828887 0.43029 0.787437 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240899 episodes
GETTING ACTION FROM:
action 3, numVisits=240892, meanQ=6.198147, numObservations: 4
action 1, numVisits=4, meanQ=-1.002475, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.580291 0.898978 0.647335 0.828887 0.43029 0.787437 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=39039, meanQ=8.855324, numObservations: 4
action 2, numVisits=174, meanQ=8.356095, numObservations: 3
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 295746 episodes
GETTING ACTION FROM:
action 1, numVisits=333659, meanQ=6.778150, numObservations: 4
action 2, numVisits=1299, meanQ=6.612264, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 1
Next state: 1 0.580291 0.898978 0.647335 0.828887 0.43029 0.787437 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 245
Initial state: 0 0.582906 0.819692 0.969424 0.49534 0.574636 0.89519 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241145 episodes
GETTING ACTION FROM:
action 2, numVisits=241118, meanQ=6.193606, numObservations: 5
action 1, numVisits=20, meanQ=2.549500, numObservations: 4
action 3, numVisits=5, meanQ=1.396000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 2 0.582906 0.819692 0.969424 0.49534 0.574636 0.89519 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 246
Initial state: 0 0.698856 0.877989 0.436629 0.662676 0.69189 0.899426 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238713 episodes
GETTING ACTION FROM:
action 1, numVisits=238701, meanQ=6.226579, numObservations: 5
action 2, numVisits=7, meanQ=3.568571, numObservations: 2
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.698856 0.877989 0.436629 0.662676 0.69189 0.899426 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 247
Initial state: 0 0.686423 0.837534 0.266353 0.797617 0.634991 0.890121 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240230 episodes
GETTING ACTION FROM:
action 2, numVisits=240223, meanQ=6.226036, numObservations: 5
action 1, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 2
Next state: 0 0.686423 0.837534 0.266353 0.797617 0.634991 0.890121 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=26074, meanQ=8.937742, numObservations: 3
action 1, numVisits=8, meanQ=6.622512, numObservations: 3
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 296783 episodes
GETTING ACTION FROM:
action 3, numVisits=317779, meanQ=6.667740, numObservations: 4
action 1, numVisits=5057, meanQ=6.579521, numObservations: 4
action 2, numVisits=30, meanQ=4.929677, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.686423 0.837534 0.266353 0.797617 0.634991 0.890121 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 248
Initial state: 0 0.392434 0.406507 0.589502 0.877609 0.509307 0.806608 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239199 episodes
GETTING ACTION FROM:
action 2, numVisits=239132, meanQ=6.228749, numObservations: 5
action 1, numVisits=55, meanQ=5.240911, numObservations: 4
action 3, numVisits=10, meanQ=4.010000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.392434 0.406507 0.589502 0.877609 0.509307 0.806608 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 249
Initial state: 0 0.3085 0.241037 0.535039 0.837422 0.623792 0.842942 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241198 episodes
GETTING ACTION FROM:
action 1, numVisits=241157, meanQ=6.326071, numObservations: 4
action 2, numVisits=38, meanQ=5.099213, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.3085 0.241037 0.535039 0.837422 0.623792 0.842942 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=33252, meanQ=8.867687, numObservations: 3
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 300034 episodes
GETTING ACTION FROM:
action 3, numVisits=331331, meanQ=6.564655, numObservations: 3
action 2, numVisits=1952, meanQ=6.414725, numObservations: 4
action 1, numVisits=5, meanQ=3.194040, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.3085 0.241037 0.535039 0.837422 0.623792 0.842942 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 250
Initial state: 0 0.533714 0.24975 0.594278 0.825336 0.596117 0.894613 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238435 episodes
GETTING ACTION FROM:
action 3, numVisits=224686, meanQ=6.213987, numObservations: 5
action 2, numVisits=13725, meanQ=6.110602, numObservations: 5
action 1, numVisits=22, meanQ=3.086364, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.533714 0.24975 0.594278 0.825336 0.596117 0.894613 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 251
Initial state: 0 0.554717 0.896248 0.362881 0.847416 0.51766 0.823355 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239572 episodes
GETTING ACTION FROM:
action 3, numVisits=79218, meanQ=6.272899, numObservations: 5
action 2, numVisits=160338, meanQ=6.261403, numObservations: 5
action 1, numVisits=14, meanQ=3.927871, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.554717 0.896248 0.362881 0.847416 0.51766 0.823355 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 252
Initial state: 0 0.976947 0.738381 0.596661 0.882749 0.508308 0.820172 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239183 episodes
GETTING ACTION FROM:
action 1, numVisits=239152, meanQ=6.302564, numObservations: 5
action 3, numVisits=20, meanQ=4.604000, numObservations: 3
action 2, numVisits=9, meanQ=3.553344, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 2 0.976947 0.738381 0.596661 0.882749 0.508308 0.820172 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 253
Initial state: 0 0.542876 0.0959257 0.657868 0.806464 0.524444 0.834484 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240536 episodes
GETTING ACTION FROM:
action 2, numVisits=239847, meanQ=6.183381, numObservations: 5
action 3, numVisits=676, meanQ=5.908685, numObservations: 4
action 1, numVisits=11, meanQ=2.725464, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.542876 0.0959257 0.657868 0.806464 0.524444 0.834484 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 254
Initial state: 0 0.901103 0.795333 0.55371 0.862768 0.659876 0.832331 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241299 episodes
GETTING ACTION FROM:
action 3, numVisits=241291, meanQ=6.228534, numObservations: 4
action 1, numVisits=4, meanQ=1.747500, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.901103 0.795333 0.55371 0.862768 0.659876 0.832331 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 255
Initial state: 0 0.0334465 0.495933 0.521477 0.887403 0.62237 0.82446 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238414 episodes
GETTING ACTION FROM:
action 3, numVisits=238409, meanQ=6.208527, numObservations: 5
action 2, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.0334465 0.495933 0.521477 0.887403 0.62237 0.82446 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 256
Initial state: 0 0.53287 0.800149 0.635656 0.870699 0.0408645 0.0918096 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240925 episodes
GETTING ACTION FROM:
action 3, numVisits=240920, meanQ=6.229460, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.53287 0.800149 0.635656 0.870699 0.0408645 0.0918096 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=33516, meanQ=8.856906, numObservations: 3
action 1, numVisits=55, meanQ=7.926731, numObservations: 3
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 298090 episodes
GETTING ACTION FROM:
action 2, numVisits=331313, meanQ=6.788802, numObservations: 3
action 1, numVisits=335, meanQ=6.378956, numObservations: 3
action 3, numVisits=14, meanQ=4.712164, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.53287 0.800149 0.635656 0.870699 0.0408645 0.0918096 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 257
Initial state: 0 0.673983 0.993342 0.670344 0.870769 0.576404 0.818613 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240279 episodes
GETTING ACTION FROM:
action 2, numVisits=240269, meanQ=6.236298, numObservations: 5
action 3, numVisits=7, meanQ=3.284300, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.673983 0.993342 0.670344 0.870769 0.576404 0.818613 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 258
Initial state: 0 0.444918 0.806827 0.631902 0.868174 0.519786 0.877357 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 242547 episodes
GETTING ACTION FROM:
action 2, numVisits=242538, meanQ=6.327115, numObservations: 4
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=4, meanQ=-3.252500, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.444918 0.806827 0.631902 0.868174 0.519786 0.877357 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 259
Initial state: 0 0.411473 0.320436 0.50963 0.83541 0.624333 0.831403 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 244136 episodes
GETTING ACTION FROM:
action 1, numVisits=244111, meanQ=6.156620, numObservations: 3
action 3, numVisits=17, meanQ=4.410588, numObservations: 3
action 2, numVisits=6, meanQ=2.331683, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 0 0.411473 0.320436 0.50963 0.83541 0.624333 0.831403 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=39581, meanQ=8.852480, numObservations: 3
action 2, numVisits=5, meanQ=5.000000, numObservations: 1
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 297607 episodes
GETTING ACTION FROM:
action 3, numVisits=337117, meanQ=6.782120, numObservations: 3
action 2, numVisits=74, meanQ=5.905270, numObservations: 4
action 1, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.411473 0.320436 0.50963 0.83541 0.624333 0.831403 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 260
Initial state: 0 0.591569 0.857057 0.451573 0.102072 0.58643 0.856886 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 243891 episodes
GETTING ACTION FROM:
action 1, numVisits=243887, meanQ=6.224985, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.591569 0.857057 0.451573 0.102072 0.58643 0.856886 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 261
Initial state: 0 0.672505 0.872113 0.225863 0.503109 0.626747 0.893078 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 242458 episodes
GETTING ACTION FROM:
action 2, numVisits=242135, meanQ=6.235902, numObservations: 4
action 3, numVisits=320, meanQ=5.833435, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.672505 0.872113 0.225863 0.503109 0.626747 0.893078 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=20320, meanQ=8.873956, numObservations: 4
action 1, numVisits=12777, meanQ=8.862182, numObservations: 4
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 295177 episodes
GETTING ACTION FROM:
action 3, numVisits=240388, meanQ=6.957581, numObservations: 4
action 1, numVisits=87885, meanQ=6.946038, numObservations: 5
action 2, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.672505 0.872113 0.225863 0.503109 0.626747 0.893078 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 262
Initial state: 0 0.140641 0.585405 0.642351 0.87382 0.543342 0.896907 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240762 episodes
GETTING ACTION FROM:
action 1, numVisits=240728, meanQ=6.244569, numObservations: 4
action 3, numVisits=16, meanQ=4.482500, numObservations: 3
action 2, numVisits=16, meanQ=4.061256, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 0 0.140641 0.585405 0.642351 0.87382 0.543342 0.896907 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=23964, meanQ=8.857338, numObservations: 4
action 3, numVisits=15509, meanQ=8.845969, numObservations: 3
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 296582 episodes
GETTING ACTION FROM:
action 2, numVisits=175319, meanQ=6.870636, numObservations: 4
action 3, numVisits=160731, meanQ=6.870522, numObservations: 3
action 1, numVisits=6, meanQ=2.515000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.140641 0.585405 0.642351 0.87382 0.543342 0.896907 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 263
Initial state: 0 0.602586 0.847838 0.512689 0.88302 0.428417 0.872501 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238821 episodes
GETTING ACTION FROM:
action 2, numVisits=238794, meanQ=6.191983, numObservations: 5
action 3, numVisits=23, meanQ=4.596087, numObservations: 3
action 1, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.602586 0.847838 0.512689 0.88302 0.428417 0.872501 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 264
Initial state: 0 0.615541 0.809129 0.535365 0.685257 0.683533 0.823897 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239998 episodes
GETTING ACTION FROM:
action 3, numVisits=239725, meanQ=6.234885, numObservations: 4
action 1, numVisits=258, meanQ=5.744997, numObservations: 3
action 2, numVisits=13, meanQ=3.599238, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.615541 0.809129 0.535365 0.685257 0.683533 0.823897 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 265
Initial state: 0 0.529695 0.879518 0.603426 0.885881 0.702677 0.0872501 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239298 episodes
GETTING ACTION FROM:
action 3, numVisits=220886, meanQ=6.292914, numObservations: 5
action 1, numVisits=18409, meanQ=6.211077, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.529695 0.879518 0.603426 0.885881 0.702677 0.0872501 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 266
Initial state: 0 0.676624 0.865026 0.0520791 0.0526957 0.592169 0.851906 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238102 episodes
GETTING ACTION FROM:
action 3, numVisits=238030, meanQ=6.221137, numObservations: 4
action 2, numVisits=64, meanQ=5.320628, numObservations: 4
action 1, numVisits=6, meanQ=1.161667, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.676624 0.865026 0.0520791 0.0526957 0.592169 0.851906 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 267
Initial state: 0 0.657093 0.892952 0.612285 0.818272 0.991613 0.82443 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 242883 episodes
GETTING ACTION FROM:
action 3, numVisits=242870, meanQ=6.240721, numObservations: 3
action 2, numVisits=7, meanQ=1.841443, numObservations: 2
action 1, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 2 0.657093 0.892952 0.612285 0.818272 0.991613 0.82443 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 268
Initial state: 0 0.597308 0.810098 0.609857 0.892886 0.648936 0.203332 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 234772 episodes
GETTING ACTION FROM:
action 2, numVisits=234734, meanQ=6.144801, numObservations: 5
action 3, numVisits=35, meanQ=4.707440, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.597308 0.810098 0.609857 0.892886 0.648936 0.203332 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 269
Initial state: 0 0.239202 0.849687 0.693021 0.814351 0.596435 0.891972 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238514 episodes
GETTING ACTION FROM:
action 2, numVisits=238435, meanQ=6.199984, numObservations: 5
action 3, numVisits=43, meanQ=5.017916, numObservations: 4
action 1, numVisits=34, meanQ=4.939715, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.239202 0.849687 0.693021 0.814351 0.596435 0.891972 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 270
Initial state: 0 0.814323 0.482984 0.557247 0.843907 0.513176 0.897301 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 242834 episodes
GETTING ACTION FROM:
action 2, numVisits=242828, meanQ=6.235955, numObservations: 4
action 1, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.814323 0.482984 0.557247 0.843907 0.513176 0.897301 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 271
Initial state: 0 0.575239 0.827121 0.575005 0.836134 0.165157 0.508394 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241851 episodes
GETTING ACTION FROM:
action 2, numVisits=241846, meanQ=6.228584, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.575239 0.827121 0.575005 0.836134 0.165157 0.508394 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 272
Initial state: 0 0.637043 0.954108 0.561763 0.882214 0.686189 0.834013 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240780 episodes
GETTING ACTION FROM:
action 1, numVisits=240774, meanQ=6.232698, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 1
Next state: 1 0.637043 0.954108 0.561763 0.882214 0.686189 0.834013 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 273
Initial state: 0 0.693787 0.811578 0.31891 0.30557 0.579308 0.853408 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240675 episodes
GETTING ACTION FROM:
action 3, numVisits=240666, meanQ=6.293825, numObservations: 4
action 1, numVisits=6, meanQ=2.333333, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.693787 0.811578 0.31891 0.30557 0.579308 0.853408 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 274
Initial state: 0 0.264136 0.169329 0.627716 0.851825 0.574066 0.829629 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239278 episodes
GETTING ACTION FROM:
action 1, numVisits=239273, meanQ=6.242309, numObservations: 5
action 3, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.264136 0.169329 0.627716 0.851825 0.574066 0.829629 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=13960, meanQ=8.932029, numObservations: 3
action 2, numVisits=11976, meanQ=8.927775, numObservations: 3
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 295289 episodes
GETTING ACTION FROM:
action 2, numVisits=182729, meanQ=6.526398, numObservations: 4
action 3, numVisits=138495, meanQ=6.523904, numObservations: 5
action 1, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.264136 0.169329 0.627716 0.851825 0.574066 0.829629 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 275
Initial state: 0 0.651313 0.827327 0.00764819 0.827596 0.50105 0.869808 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 244947 episodes
GETTING ACTION FROM:
action 3, numVisits=243193, meanQ=6.234217, numObservations: 3
action 1, numVisits=1741, meanQ=6.071253, numObservations: 4
action 2, numVisits=11, meanQ=1.727273, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.651313 0.827327 0.00764819 0.827596 0.50105 0.869808 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 276
Initial state: 0 0.132493 0.701058 0.623277 0.807364 0.622219 0.873501 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241640 episodes
GETTING ACTION FROM:
action 1, numVisits=241633, meanQ=6.235200, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.132493 0.701058 0.623277 0.807364 0.622219 0.873501 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=38763, meanQ=8.873128, numObservations: 3
action 3, numVisits=392, meanQ=8.572342, numObservations: 4
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 299109 episodes
GETTING ACTION FROM:
action 2, numVisits=319958, meanQ=6.476968, numObservations: 3
action 3, numVisits=18177, meanQ=6.436822, numObservations: 5
action 1, numVisits=130, meanQ=5.753078, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.132493 0.701058 0.623277 0.807364 0.622219 0.873501 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 277
Initial state: 0 0.601025 0.756607 0.61878 0.872905 0.567253 0.80563 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238586 episodes
GETTING ACTION FROM:
action 3, numVisits=238570, meanQ=6.221995, numObservations: 5
action 2, numVisits=12, meanQ=3.999175, numObservations: 3
action 1, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.601025 0.756607 0.61878 0.872905 0.567253 0.80563 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 278
Initial state: 0 0.572306 0.850595 0.581957 0.854143 0.48632 0.665658 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240718 episodes
GETTING ACTION FROM:
action 1, numVisits=240691, meanQ=6.261488, numObservations: 4
action 2, numVisits=17, meanQ=3.880588, numObservations: 4
action 3, numVisits=8, meanQ=2.996263, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.572306 0.850595 0.581957 0.854143 0.48632 0.665658 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 279
Initial state: 0 0.597434 0.809652 0.670079 0.801905 0.709328 0.704 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161828 episodes
GETTING ACTION FROM:
action 0, numVisits=161819, meanQ=4.177562, numObservations: 1
action 2, numVisits=3, meanQ=-0.670000, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 0
Next state: 0 0.597434 0.809652 0.670079 0.801905 0.709328 0.704 w: 1
Observation: 0 0 0.889551 0 0.711921 0 0.701196 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=161762, meanQ=6.244319, numObservations: 4
action 3, numVisits=52, meanQ=5.084621, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 2
Sampled 257952 episodes
GETTING ACTION FROM:
action 1, numVisits=419714, meanQ=6.349934, numObservations: 4
action 3, numVisits=52, meanQ=5.084621, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 1
Next state: 1 0.597434 0.809652 0.670079 0.801905 0.709328 0.704 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 280
Initial state: 0 0.598151 0.838376 0.509926 0.84313 0.464975 0.790446 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 242050 episodes
GETTING ACTION FROM:
action 2, numVisits=242017, meanQ=6.333369, numObservations: 4
action 1, numVisits=29, meanQ=4.510003, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.598151 0.838376 0.509926 0.84313 0.464975 0.790446 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 281
Initial state: 0 0.590127 0.803392 0.386536 0.310289 0.524246 0.816869 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239895 episodes
GETTING ACTION FROM:
action 3, numVisits=239886, meanQ=6.223482, numObservations: 4
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action 1, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.590127 0.803392 0.386536 0.310289 0.524246 0.816869 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 282
Initial state: 0 0.53494 0.842043 0.634316 0.849442 0.368128 0.979049 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240865 episodes
GETTING ACTION FROM:
action 1, numVisits=240849, meanQ=6.242904, numObservations: 4
action 3, numVisits=9, meanQ=3.663344, numObservations: 2
action 2, numVisits=5, meanQ=1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.53494 0.842043 0.634316 0.849442 0.368128 0.979049 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 283
Initial state: 0 0.667764 0.836776 0.718712 0.571397 0.688246 0.865088 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241733 episodes
GETTING ACTION FROM:
action 1, numVisits=226078, meanQ=6.210128, numObservations: 4
action 2, numVisits=15607, meanQ=6.165164, numObservations: 5
action 3, numVisits=46, meanQ=4.970806, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.667764 0.836776 0.718712 0.571397 0.688246 0.865088 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 284
Initial state: 0 0.776373 0.286573 0.574417 0.876194 0.672066 0.836019 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240708 episodes
GETTING ACTION FROM:
action 2, numVisits=240700, meanQ=6.207715, numObservations: 5
action 1, numVisits=3, meanQ=-0.670000, numObservations: 3
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.776373 0.286573 0.574417 0.876194 0.672066 0.836019 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 285
Initial state: 0 0.599245 0.406086 0.561571 0.869309 0.601166 0.826222 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240049 episodes
GETTING ACTION FROM:
action 1, numVisits=240041, meanQ=6.226243, numObservations: 4
action 2, numVisits=5, meanQ=1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.599245 0.406086 0.561571 0.869309 0.601166 0.826222 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 286
Initial state: 0 0.560391 0.872043 0.616833 0.860204 0.347927 0.852958 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 243354 episodes
GETTING ACTION FROM:
action 1, numVisits=243210, meanQ=6.185995, numObservations: 3
action 2, numVisits=135, meanQ=5.489484, numObservations: 4
action 3, numVisits=7, meanQ=3.270014, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.560391 0.872043 0.616833 0.860204 0.347927 0.852958 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 287
Initial state: 0 0.799751 0.44543 0.575155 0.891751 0.59953 0.815788 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 243797 episodes
GETTING ACTION FROM:
action 1, numVisits=243735, meanQ=6.235376, numObservations: 3
action 3, numVisits=27, meanQ=4.513719, numObservations: 4
action 2, numVisits=33, meanQ=3.074242, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 2 0.799751 0.44543 0.575155 0.891751 0.59953 0.815788 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 288
Initial state: 0 0.677079 0.828275 0.438755 0.00732967 0.52574 0.805033 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238144 episodes
GETTING ACTION FROM:
action 2, numVisits=231998, meanQ=6.214668, numObservations: 5
action 1, numVisits=6139, meanQ=6.094958, numObservations: 5
action 3, numVisits=5, meanQ=2.798040, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.677079 0.828275 0.438755 0.00732967 0.52574 0.805033 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=22469, meanQ=8.862023, numObservations: 4
action 1, numVisits=9604, meanQ=8.838672, numObservations: 4
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 296428 episodes
GETTING ACTION FROM:
action 1, numVisits=148423, meanQ=6.854912, numObservations: 4
action 3, numVisits=180076, meanQ=6.854234, numObservations: 4
action 2, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.677079 0.828275 0.438755 0.00732967 0.52574 0.805033 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 289
Initial state: 0 0.553044 0.859261 0.90985 0.332226 0.660813 0.85207 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 244069 episodes
GETTING ACTION FROM:
action 2, numVisits=244063, meanQ=6.228688, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=2, meanQ=-5.505000, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 2
Next state: 2 0.553044 0.859261 0.90985 0.332226 0.660813 0.85207 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 290
Initial state: 0 0.587056 0.804127 0.503731 0.316552 0.584365 0.833553 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240450 episodes
GETTING ACTION FROM:
action 3, numVisits=239966, meanQ=6.245785, numObservations: 4
action 2, numVisits=464, meanQ=5.894893, numObservations: 4
action 1, numVisits=18, meanQ=4.108350, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.587056 0.804127 0.503731 0.316552 0.584365 0.833553 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 291
Initial state: 0 0.646345 0.192502 0.545932 0.801079 0.618387 0.824867 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239814 episodes
GETTING ACTION FROM:
action 1, numVisits=239799, meanQ=6.214091, numObservations: 5
action 3, numVisits=12, meanQ=3.801667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.646345 0.192502 0.545932 0.801079 0.618387 0.824867 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=12742, meanQ=8.715621, numObservations: 3
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 299936 episodes
GETTING ACTION FROM:
action 3, numVisits=312407, meanQ=6.438663, numObservations: 3
action 2, numVisits=271, meanQ=6.009890, numObservations: 5
action 1, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.646345 0.192502 0.545932 0.801079 0.618387 0.824867 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 292
Initial state: 0 0.61194 0.381053 0.590111 0.809842 0.669933 0.846651 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241251 episodes
GETTING ACTION FROM:
action 3, numVisits=241240, meanQ=6.180950, numObservations: 4
action 1, numVisits=8, meanQ=2.873750, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.61194 0.381053 0.590111 0.809842 0.669933 0.846651 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 293
Initial state: 0 0.594914 0.89483 0.504033 0.865644 0.126594 0.928914 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239133 episodes
GETTING ACTION FROM:
action 2, numVisits=233916, meanQ=6.193087, numObservations: 5
action 1, numVisits=5202, meanQ=6.104243, numObservations: 4
action 3, numVisits=13, meanQ=3.523085, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.594914 0.89483 0.504033 0.865644 0.126594 0.928914 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 294
Initial state: 0 0.686455 0.47552 0.530426 0.812924 0.657265 0.836583 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241395 episodes
GETTING ACTION FROM:
action 1, numVisits=241383, meanQ=6.318851, numObservations: 4
action 3, numVisits=6, meanQ=2.333333, numObservations: 1
action 2, numVisits=4, meanQ=1.747500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 2 0.686455 0.47552 0.530426 0.812924 0.657265 0.836583 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 295
Initial state: 0 0.143717 0.702492 0.57886 0.800784 0.611198 0.899926 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 244518 episodes
GETTING ACTION FROM:
action 2, numVisits=244477, meanQ=6.232388, numObservations: 3
action 3, numVisits=18, meanQ=4.555006, numObservations: 4
action 1, numVisits=21, meanQ=3.903333, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.143717 0.702492 0.57886 0.800784 0.611198 0.899926 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 296
Initial state: 0 0.506723 0.832327 0.506412 0.951074 0.567829 0.894076 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 245997 episodes
GETTING ACTION FROM:
action 2, numVisits=245989, meanQ=6.241133, numObservations: 3
action 3, numVisits=4, meanQ=-1.000000, numObservations: 3
action 1, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.506723 0.832327 0.506412 0.951074 0.567829 0.894076 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 297
Initial state: 0 0.543583 0.822196 0.507266 0.890094 0.876491 0.494424 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238083 episodes
GETTING ACTION FROM:
action 3, numVisits=238072, meanQ=6.222379, numObservations: 5
action 2, numVisits=6, meanQ=0.650000, numObservations: 3
action 1, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 2 0.543583 0.822196 0.507266 0.890094 0.876491 0.494424 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 298
Initial state: 0 0.594496 0.858537 0.622715 0.802247 0.885225 0.390448 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 242093 episodes
GETTING ACTION FROM:
action 2, numVisits=242077, meanQ=6.234579, numObservations: 4
action 1, numVisits=12, meanQ=4.074167, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 2
Next state: 1 0.594496 0.858537 0.622715 0.802247 0.885225 0.390448 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 299
Initial state: 0 0.798759 0.9341 0.590239 0.832482 0.556566 0.81612 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240907 episodes
GETTING ACTION FROM:
action 2, numVisits=240896, meanQ=6.220510, numObservations: 4
action 3, numVisits=7, meanQ=3.568571, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.798759 0.9341 0.590239 0.832482 0.556566 0.81612 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=10721, meanQ=6.521824, numObservations: 4
action 3, numVisits=3, meanQ=2.333333, numObservations: 2
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 296865 episodes
GETTING ACTION FROM:
action 1, numVisits=307580, meanQ=6.455449, numObservations: 4
action 3, numVisits=3, meanQ=2.333333, numObservations: 2
action 2, numVisits=7, meanQ=1.997157, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 2 0.798759 0.9341 0.590239 0.832482 0.556566 0.81612 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11.89
Run # 300
Initial state: 0 0.571737 0.886208 0.0180713 0.358542 0.553813 0.837933 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240877 episodes
GETTING ACTION FROM:
action 1, numVisits=218256, meanQ=6.269920, numObservations: 4
action 2, numVisits=22617, meanQ=6.230183, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 1
Next state: 1 0.571737 0.886208 0.0180713 0.358542 0.553813 0.837933 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 301
Initial state: 0 0.501922 0.856104 0.563742 0.89109 0.206682 0.269971 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239182 episodes
GETTING ACTION FROM:
action 1, numVisits=239082, meanQ=6.251735, numObservations: 5
action 2, numVisits=96, meanQ=5.461982, numObservations: 4
action 3, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.501922 0.856104 0.563742 0.89109 0.206682 0.269971 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 302
Initial state: 0 0.530344 0.670696 0.697254 0.893694 0.576154 0.820325 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241320 episodes
GETTING ACTION FROM:
action 1, numVisits=241262, meanQ=6.235220, numObservations: 4
action 3, numVisits=54, meanQ=5.004263, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 1
Next state: 2 0.530344 0.670696 0.697254 0.893694 0.576154 0.820325 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 303
Initial state: 0 0.445403 0.191457 0.685748 0.852842 0.518454 0.893847 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 233774 episodes
GETTING ACTION FROM:
action 3, numVisits=233766, meanQ=6.133172, numObservations: 5
action 2, numVisits=5, meanQ=1.396000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.445403 0.191457 0.685748 0.852842 0.518454 0.893847 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 304
Initial state: 0 0.529102 0.881779 0.628802 0.578856 0.564574 0.829051 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240841 episodes
GETTING ACTION FROM:
action 2, numVisits=240833, meanQ=6.305019, numObservations: 5
action 1, numVisits=5, meanQ=-0.802000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.529102 0.881779 0.628802 0.578856 0.564574 0.829051 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 305
Initial state: 0 0.538336 0.881486 0.653155 0.859489 0.211468 0.364933 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 237823 episodes
GETTING ACTION FROM:
action 3, numVisits=237681, meanQ=6.236113, numObservations: 5
action 1, numVisits=108, meanQ=5.533611, numObservations: 4
action 2, numVisits=32, meanQ=4.655319, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.538336 0.881486 0.653155 0.859489 0.211468 0.364933 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=22122, meanQ=8.869865, numObservations: 4
action 1, numVisits=10957, meanQ=8.849821, numObservations: 4
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 295138 episodes
GETTING ACTION FROM:
action 2, numVisits=190866, meanQ=6.700647, numObservations: 4
action 1, numVisits=137348, meanQ=6.697971, numObservations: 4
action 3, numVisits=4, meanQ=1.747500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.538336 0.881486 0.653155 0.859489 0.211468 0.364933 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 306
Initial state: 0 0.606491 0.883534 0.0176749 0.237932 0.687793 0.893812 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238855 episodes
GETTING ACTION FROM:
action 1, numVisits=238839, meanQ=6.234579, numObservations: 5
action 2, numVisits=10, meanQ=3.990000, numObservations: 3
action 3, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.606491 0.883534 0.0176749 0.237932 0.687793 0.893812 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 307
Initial state: 0 0.55252 0.869068 0.673877 0.802006 0.28024 0.00372279 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 244081 episodes
GETTING ACTION FROM:
action 2, numVisits=243953, meanQ=6.214059, numObservations: 3
action 1, numVisits=119, meanQ=5.509496, numObservations: 4
action 3, numVisits=7, meanQ=3.285714, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.55252 0.869068 0.673877 0.802006 0.28024 0.00372279 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 308
Initial state: 0 0.985287 0.507165 0.620288 0.841793 0.526611 0.896741 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 242753 episodes
GETTING ACTION FROM:
action 3, numVisits=241603, meanQ=6.240037, numObservations: 3
action 2, numVisits=946, meanQ=6.006006, numObservations: 4
action 1, numVisits=202, meanQ=5.720003, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.985287 0.507165 0.620288 0.841793 0.526611 0.896741 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 309
Initial state: 0 0.406748 0.875889 0.526908 0.832509 0.500809 0.814908 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162025 episodes
GETTING ACTION FROM:
action 0, numVisits=161975, meanQ=4.224154, numObservations: 1
action 1, numVisits=25, meanQ=1.985208, numObservations: 3
action 3, numVisits=15, meanQ=1.732007, numObservations: 4
action 2, numVisits=8, meanQ=1.372537, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 0
Next state: 0 0.406748 0.875889 0.526908 0.832509 0.500809 0.814908 w: 1
Observation: 0 0 0.943061 0 0.889919 0 0.829132 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=161964, meanQ=6.305666, numObservations: 5
action 3, numVisits=6, meanQ=2.333333, numObservations: 2
action 1, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 256279 episodes
GETTING ACTION FROM:
action 2, numVisits=418243, meanQ=6.425532, numObservations: 5
action 3, numVisits=6, meanQ=2.333333, numObservations: 2
action 1, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.406748 0.875889 0.526908 0.832509 0.500809 0.814908 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 310
Initial state: 0 0.646982 0.856464 0.657571 0.822648 0.897002 0.662667 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 242695 episodes
GETTING ACTION FROM:
action 2, numVisits=242686, meanQ=6.213662, numObservations: 4
action 1, numVisits=5, meanQ=2.544000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 2
Next state: 1 0.646982 0.856464 0.657571 0.822648 0.897002 0.662667 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 311
Initial state: 0 0.687201 0.888096 0.592598 0.887934 0.560901 0.196424 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 245854 episodes
GETTING ACTION FROM:
action 2, numVisits=245712, meanQ=6.217430, numObservations: 3
action 3, numVisits=137, meanQ=5.578252, numObservations: 4
action 1, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.687201 0.888096 0.592598 0.887934 0.560901 0.196424 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 312
Initial state: 0 0.578861 0.877824 0.608171 0.83635 0.0517415 0.208594 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240177 episodes
GETTING ACTION FROM:
action 3, numVisits=240153, meanQ=6.243490, numObservations: 4
action 1, numVisits=17, meanQ=3.234118, numObservations: 3
action 2, numVisits=5, meanQ=0.998020, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.578861 0.877824 0.608171 0.83635 0.0517415 0.208594 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=38701, meanQ=8.842018, numObservations: 3
action 1, numVisits=15, meanQ=7.065340, numObservations: 3
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 299555 episodes
GETTING ACTION FROM:
action 2, numVisits=338074, meanQ=6.714720, numObservations: 3
action 1, numVisits=192, meanQ=6.175053, numObservations: 4
action 3, numVisits=6, meanQ=3.801667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.578861 0.877824 0.608171 0.83635 0.0517415 0.208594 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 313
Initial state: 0 0.648293 0.850217 0.513964 0.885016 0.684069 0.812984 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240989 episodes
GETTING ACTION FROM:
action 1, numVisits=240971, meanQ=6.230358, numObservations: 4
action 3, numVisits=14, meanQ=3.354307, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 1
action: 1
Next state: 1 0.648293 0.850217 0.513964 0.885016 0.684069 0.812984 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 314
Initial state: 0 0.686356 0.811664 0.109655 0.692857 0.609146 0.845543 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240044 episodes
GETTING ACTION FROM:
action 3, numVisits=240009, meanQ=6.235131, numObservations: 4
action 1, numVisits=18, meanQ=3.998900, numObservations: 3
action 2, numVisits=15, meanQ=3.580667, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.686356 0.811664 0.109655 0.692857 0.609146 0.845543 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 315
Initial state: 0 0.585568 0.856532 0.541169 0.825184 0.356979 0.75351 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 237258 episodes
GETTING ACTION FROM:
action 3, numVisits=237253, meanQ=6.226818, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.585568 0.856532 0.541169 0.825184 0.356979 0.75351 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=18416, meanQ=8.868875, numObservations: 4
action 2, numVisits=14447, meanQ=8.856046, numObservations: 5
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 292788 episodes
GETTING ACTION FROM:
action 2, numVisits=213146, meanQ=6.809698, numObservations: 5
action 1, numVisits=112504, meanQ=6.803739, numObservations: 4
action 3, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.585568 0.856532 0.541169 0.825184 0.356979 0.75351 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 316
Initial state: 0 0.698797 0.803051 0.561494 0.982131 0.635668 0.89672 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 242118 episodes
GETTING ACTION FROM:
action 1, numVisits=242096, meanQ=6.316479, numObservations: 4
action 3, numVisits=19, meanQ=3.673168, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.698797 0.803051 0.561494 0.982131 0.635668 0.89672 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 317
Initial state: 0 0.009302 0.992178 0.541188 0.809786 0.650876 0.857325 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240035 episodes
GETTING ACTION FROM:
action 3, numVisits=240025, meanQ=6.227905, numObservations: 4
action 2, numVisits=7, meanQ=3.284300, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.009302 0.992178 0.541188 0.809786 0.650876 0.857325 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 318
Initial state: 0 0.502577 0.598642 0.545305 0.864044 0.507898 0.870265 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240553 episodes
GETTING ACTION FROM:
action 1, numVisits=240528, meanQ=6.211747, numObservations: 4
action 2, numVisits=21, meanQ=3.379529, numObservations: 4
action 3, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 2 0.502577 0.598642 0.545305 0.864044 0.507898 0.870265 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 319
Initial state: 0 0.571062 0.880979 0.812894 0.358864 0.526655 0.814779 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 243038 episodes
GETTING ACTION FROM:
action 2, numVisits=243018, meanQ=6.243898, numObservations: 4
action 1, numVisits=15, meanQ=1.660000, numObservations: 3
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 2 0.571062 0.880979 0.812894 0.358864 0.526655 0.814779 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 320
Initial state: 0 0.55819 0.922428 0.664721 0.859598 0.693038 0.893196 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240970 episodes
GETTING ACTION FROM:
action 3, numVisits=240962, meanQ=6.239460, numObservations: 4
action 1, numVisits=5, meanQ=-0.802000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.55819 0.922428 0.664721 0.859598 0.693038 0.893196 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=10894, meanQ=6.466811, numObservations: 4
action 3, numVisits=13, meanQ=1.383085, numObservations: 2
action 1, numVisits=3, meanQ=-0.670000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 295967 episodes
GETTING ACTION FROM:
action 2, numVisits=306861, meanQ=6.689732, numObservations: 4
action 3, numVisits=13, meanQ=1.383085, numObservations: 2
action 1, numVisits=3, meanQ=-0.670000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.55819 0.922428 0.664721 0.859598 0.693038 0.893196 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 321
Initial state: 0 0.553756 0.834054 0.500395 0.800501 0.966254 0.712891 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 243255 episodes
GETTING ACTION FROM:
action 2, numVisits=243202, meanQ=6.233934, numObservations: 4
action 3, numVisits=49, meanQ=4.828984, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.553756 0.834054 0.500395 0.800501 0.966254 0.712891 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 322
Initial state: 0 0.557827 0.820104 0.688029 0.819478 0.480947 0.194309 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241580 episodes
GETTING ACTION FROM:
action 1, numVisits=241384, meanQ=6.210236, numObservations: 4
action 2, numVisits=192, meanQ=5.645365, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.557827 0.820104 0.688029 0.819478 0.480947 0.194309 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 323
Initial state: 0 0.688718 0.154393 0.665101 0.899068 0.503525 0.890622 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241117 episodes
GETTING ACTION FROM:
action 3, numVisits=91119, meanQ=6.281796, numObservations: 5
action 2, numVisits=149994, meanQ=6.241810, numObservations: 4
action 1, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.688718 0.154393 0.665101 0.899068 0.503525 0.890622 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 324
Initial state: 0 0.57333 0.810827 0.637721 0.862828 0.684692 0.689891 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241906 episodes
GETTING ACTION FROM:
action 2, numVisits=241894, meanQ=6.245880, numObservations: 4
action 3, numVisits=8, meanQ=2.873750, numObservations: 3
action 1, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.57333 0.810827 0.637721 0.862828 0.684692 0.689891 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 325
Initial state: 0 0.123004 0.914568 0.62575 0.855442 0.510519 0.811693 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239207 episodes
GETTING ACTION FROM:
action 2, numVisits=239201, meanQ=6.189283, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.123004 0.914568 0.62575 0.855442 0.510519 0.811693 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 326
Initial state: 0 0.644903 0.885908 0.604768 0.834166 0.513713 0.870501 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239625 episodes
GETTING ACTION FROM:
action 3, numVisits=175784, meanQ=6.240261, numObservations: 5
action 2, numVisits=63837, meanQ=6.211158, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 3
Next state: 0 0.644903 0.885908 0.604768 0.834166 0.513713 0.870501 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=825, meanQ=6.679238, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 292855 episodes
GETTING ACTION FROM:
action 1, numVisits=293680, meanQ=6.547439, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.644903 0.885908 0.604768 0.834166 0.513713 0.870501 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 327
Initial state: 0 0.426988 0.585405 0.515641 0.892564 0.582478 0.866783 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 242395 episodes
GETTING ACTION FROM:
action 2, numVisits=242388, meanQ=6.246552, numObservations: 4
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 2
Next state: 1 0.426988 0.585405 0.515641 0.892564 0.582478 0.866783 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 328
Initial state: 0 0.50466 0.872549 0.495157 0.79931 0.575155 0.860388 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241314 episodes
GETTING ACTION FROM:
action 3, numVisits=241301, meanQ=6.242312, numObservations: 4
action 2, numVisits=7, meanQ=1.998571, numObservations: 3
action 1, numVisits=4, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.50466 0.872549 0.495157 0.79931 0.575155 0.860388 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 329
Initial state: 0 0.697093 0.883352 0.626018 0.889218 0.649344 0.829732 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 242180 episodes
GETTING ACTION FROM:
action 2, numVisits=242175, meanQ=6.226010, numObservations: 4
action 3, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.697093 0.883352 0.626018 0.889218 0.649344 0.829732 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 330
Initial state: 0 0.638504 0.896141 0.62046 0.872843 0.712938 0.752895 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238242 episodes
GETTING ACTION FROM:
action 1, numVisits=238223, meanQ=6.241568, numObservations: 5
action 2, numVisits=15, meanQ=4.340000, numObservations: 2
action 3, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.638504 0.896141 0.62046 0.872843 0.712938 0.752895 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 331
Initial state: 0 0.609086 0.293508 0.68407 0.884737 0.555754 0.867868 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240278 episodes
GETTING ACTION FROM:
action 1, numVisits=234026, meanQ=6.239225, numObservations: 4
action 3, numVisits=6245, meanQ=6.161257, numObservations: 5
action 2, numVisits=5, meanQ=1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 0 0.609086 0.293508 0.68407 0.884737 0.555754 0.867868 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=18240, meanQ=8.880113, numObservations: 4
action 2, numVisits=13822, meanQ=8.872400, numObservations: 3
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 298535 episodes
GETTING ACTION FROM:
action 2, numVisits=229032, meanQ=6.876581, numObservations: 3
action 3, numVisits=101563, meanQ=6.868811, numObservations: 4
action 1, numVisits=3, meanQ=2.330033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.609086 0.293508 0.68407 0.884737 0.555754 0.867868 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 332
Initial state: 0 0.720414 0.18584 0.501409 0.817999 0.533656 0.856048 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 242687 episodes
GETTING ACTION FROM:
action 2, numVisits=242664, meanQ=6.219790, numObservations: 4
action 3, numVisits=20, meanQ=4.598505, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.720414 0.18584 0.501409 0.817999 0.533656 0.856048 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 333
Initial state: 0 0.544039 0.878235 0.579867 0.808657 0.590609 0.95086 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240697 episodes
GETTING ACTION FROM:
action 1, numVisits=240618, meanQ=6.237230, numObservations: 4
action 3, numVisits=65, meanQ=5.189851, numObservations: 4
action 2, numVisits=12, meanQ=4.165000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.544039 0.878235 0.579867 0.808657 0.590609 0.95086 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 334
Initial state: 0 0.537229 0.888305 0.554159 0.834705 0.0695274 0.0345427 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 242302 episodes
GETTING ACTION FROM:
action 2, numVisits=242297, meanQ=6.221937, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.537229 0.888305 0.554159 0.834705 0.0695274 0.0345427 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 335
Initial state: 0 0.538225 0.860613 0.50235 0.105037 0.628509 0.8186 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238683 episodes
GETTING ACTION FROM:
action 2, numVisits=238632, meanQ=6.234252, numObservations: 5
action 3, numVisits=35, meanQ=4.742006, numObservations: 4
action 1, numVisits=14, meanQ=4.070007, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 2 0.538225 0.860613 0.50235 0.105037 0.628509 0.8186 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 336
Initial state: 0 0.58319 0.823161 0.619287 0.861643 0.667123 0.228379 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240523 episodes
GETTING ACTION FROM:
action 1, numVisits=240334, meanQ=6.232790, numObservations: 4
action 3, numVisits=181, meanQ=5.685907, numObservations: 4
action 2, numVisits=6, meanQ=2.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.58319 0.823161 0.619287 0.861643 0.667123 0.228379 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 337
Initial state: 0 0.584044 0.805628 0.352469 0.52869 0.656407 0.870249 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238165 episodes
GETTING ACTION FROM:
action 3, numVisits=238149, meanQ=6.226180, numObservations: 5
action 1, numVisits=12, meanQ=2.424167, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.584044 0.805628 0.352469 0.52869 0.656407 0.870249 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 338
Initial state: 0 0.382468 0.561626 0.660611 0.888967 0.561189 0.877909 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 242013 episodes
GETTING ACTION FROM:
action 2, numVisits=241611, meanQ=6.245842, numObservations: 4
action 1, numVisits=387, meanQ=5.868100, numObservations: 3
action 3, numVisits=13, meanQ=3.691538, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.382468 0.561626 0.660611 0.888967 0.561189 0.877909 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 339
Initial state: 0 0.635296 0.899231 0.668371 0.889454 0.846988 0.759634 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241086 episodes
GETTING ACTION FROM:
action 2, numVisits=241053, meanQ=6.247683, numObservations: 4
action 3, numVisits=19, meanQ=4.418432, numObservations: 3
action 1, numVisits=12, meanQ=3.999175, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.635296 0.899231 0.668371 0.889454 0.846988 0.759634 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 340
Initial state: 0 0.680488 0.865809 0.965742 0.461656 0.693141 0.895762 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241390 episodes
GETTING ACTION FROM:
action 3, numVisits=241329, meanQ=6.215100, numObservations: 4
action 1, numVisits=41, meanQ=4.848298, numObservations: 4
action 2, numVisits=18, meanQ=4.109450, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.680488 0.865809 0.965742 0.461656 0.693141 0.895762 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 341
Initial state: 0 0.534291 0.870274 0.674335 0.859494 0.130301 0.234953 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239951 episodes
GETTING ACTION FROM:
action 3, numVisits=239945, meanQ=6.209922, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.534291 0.870274 0.674335 0.859494 0.130301 0.234953 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=21893, meanQ=8.852740, numObservations: 4
action 2, numVisits=11030, meanQ=8.837218, numObservations: 5
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 294379 episodes
GETTING ACTION FROM:
action 1, numVisits=279045, meanQ=6.789923, numObservations: 4
action 2, numVisits=48251, meanQ=6.770374, numObservations: 5
action 3, numVisits=7, meanQ=1.998571, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.534291 0.870274 0.674335 0.859494 0.130301 0.234953 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 342
Initial state: 0 0.671814 0.854773 0.366339 0.0566058 0.503437 0.850304 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162274 episodes
GETTING ACTION FROM:
action 0, numVisits=162266, meanQ=4.169519, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 0
Next state: 0 0.671814 0.854773 0.366339 0.0566058 0.503437 0.850304 w: 1
Observation: 0 0 0.787453 0 0.117576 0 0.903601 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=162241, meanQ=6.240705, numObservations: 4
action 2, numVisits=16, meanQ=3.367513, numObservations: 4
action 1, numVisits=6, meanQ=0.831667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 255027 episodes
GETTING ACTION FROM:
action 3, numVisits=417268, meanQ=6.621669, numObservations: 4
action 2, numVisits=16, meanQ=3.367513, numObservations: 4
action 1, numVisits=6, meanQ=0.831667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.671814 0.854773 0.366339 0.0566058 0.503437 0.850304 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 343
Initial state: 0 0.0811717 0.12645 0.682917 0.895912 0.588182 0.829276 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 237974 episodes
GETTING ACTION FROM:
action 1, numVisits=229999, meanQ=6.311627, numObservations: 5
action 3, numVisits=7961, meanQ=6.246897, numObservations: 4
action 2, numVisits=12, meanQ=4.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 0 0.0811717 0.12645 0.682917 0.895912 0.588182 0.829276 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=13572, meanQ=8.937349, numObservations: 3
action 3, numVisits=11218, meanQ=8.931791, numObservations: 3
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 292123 episodes
GETTING ACTION FROM:
action 3, numVisits=180496, meanQ=6.654311, numObservations: 5
action 2, numVisits=136416, meanQ=6.651521, numObservations: 4
action 1, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.0811717 0.12645 0.682917 0.895912 0.588182 0.829276 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 344
Initial state: 0 0.608368 0.802798 0.805502 0.141855 0.551308 0.816394 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 237963 episodes
GETTING ACTION FROM:
action 1, numVisits=93468, meanQ=6.252810, numObservations: 5
action 2, numVisits=144491, meanQ=6.196255, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.608368 0.802798 0.805502 0.141855 0.551308 0.816394 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 345
Initial state: 0 0.64843 0.876693 0.684984 0.891865 0.948774 0.932784 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241395 episodes
GETTING ACTION FROM:
action 3, numVisits=241391, meanQ=6.217430, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.64843 0.876693 0.684984 0.891865 0.948774 0.932784 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 346
Initial state: 0 0.0685983 0.237381 0.511841 0.882446 0.685102 0.840971 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238224 episodes
GETTING ACTION FROM:
action 3, numVisits=238212, meanQ=6.224004, numObservations: 5
action 2, numVisits=7, meanQ=3.568571, numObservations: 3
action 1, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.0685983 0.237381 0.511841 0.882446 0.685102 0.840971 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 347
Initial state: 0 0.516665 0.838426 0.627956 0.0426439 0.673234 0.852709 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239445 episodes
GETTING ACTION FROM:
action 3, numVisits=239387, meanQ=6.231078, numObservations: 4
action 2, numVisits=54, meanQ=5.258713, numObservations: 4
action 1, numVisits=2, meanQ=-0.509950, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.516665 0.838426 0.627956 0.0426439 0.673234 0.852709 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 348
Initial state: 0 0.670294 0.322546 0.601291 0.850056 0.684734 0.841863 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 233919 episodes
GETTING ACTION FROM:
action 3, numVisits=233910, meanQ=6.141106, numObservations: 5
action 2, numVisits=5, meanQ=1.396000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 3
Next state: 1 0.670294 0.322546 0.601291 0.850056 0.684734 0.841863 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 349
Initial state: 0 0.603277 0.835765 0.608215 0.825687 0.21195 0.589213 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 237728 episodes
GETTING ACTION FROM:
action 1, numVisits=236721, meanQ=6.201878, numObservations: 5
action 2, numVisits=998, meanQ=5.975346, numObservations: 4
action 3, numVisits=7, meanQ=2.125714, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.603277 0.835765 0.608215 0.825687 0.21195 0.589213 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 350
Initial state: 0 0.44822 0.298868 0.590544 0.874134 0.687133 0.811647 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241150 episodes
GETTING ACTION FROM:
action 3, numVisits=240986, meanQ=6.209564, numObservations: 4
action 2, numVisits=160, meanQ=5.640251, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.44822 0.298868 0.590544 0.874134 0.687133 0.811647 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 351
Initial state: 0 0.815562 0.309944 0.570974 0.882566 0.697663 0.811377 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238456 episodes
GETTING ACTION FROM:
action 2, numVisits=238451, meanQ=6.251603, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=2, meanQ=-5.505000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.815562 0.309944 0.570974 0.882566 0.697663 0.811377 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=620, meanQ=2.826701, numObservations: 1
action 1, numVisits=3, meanQ=-0.676600, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 1
Sampled 295392 episodes
GETTING ACTION FROM:
action 3, numVisits=295324, meanQ=6.482091, numObservations: 4
action 0, numVisits=690, meanQ=2.422858, numObservations: 1
action 1, numVisits=3, meanQ=-0.676600, numObservations: 1
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 1
action: 3
Next state: 1 0.815562 0.309944 0.570974 0.882566 0.697663 0.811377 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 352
Initial state: 0 0.465016 0.0610613 0.697899 0.84491 0.566827 0.884756 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239046 episodes
GETTING ACTION FROM:
action 3, numVisits=239013, meanQ=6.213632, numObservations: 4
action 2, numVisits=30, meanQ=4.626010, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.465016 0.0610613 0.697899 0.84491 0.566827 0.884756 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 353
Initial state: 0 0.500598 0.869285 0.178654 0.999894 0.573964 0.839622 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 244744 episodes
GETTING ACTION FROM:
action 2, numVisits=244739, meanQ=6.221964, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.500598 0.869285 0.178654 0.999894 0.573964 0.839622 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 354
Initial state: 0 0.63918 0.80432 0.0788746 0.661327 0.633345 0.80793 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 242349 episodes
GETTING ACTION FROM:
action 2, numVisits=242344, meanQ=6.223110, numObservations: 4
action 3, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.63918 0.80432 0.0788746 0.661327 0.633345 0.80793 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=22383, meanQ=8.875830, numObservations: 4
action 3, numVisits=10723, meanQ=8.858516, numObservations: 3
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 297292 episodes
GETTING ACTION FROM:
action 1, numVisits=270789, meanQ=6.893392, numObservations: 4
action 3, numVisits=59606, meanQ=6.877039, numObservations: 3
action 2, numVisits=4, meanQ=1.747500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.63918 0.80432 0.0788746 0.661327 0.633345 0.80793 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 355
Initial state: 0 0.683044 0.800274 0.25208 0.402152 0.50402 0.899216 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 236728 episodes
GETTING ACTION FROM:
action 1, numVisits=236710, meanQ=6.209680, numObservations: 5
action 2, numVisits=14, meanQ=3.285714, numObservations: 2
action 3, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.683044 0.800274 0.25208 0.402152 0.50402 0.899216 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 356
Initial state: 0 0.172309 0.319157 0.630293 0.896377 0.518464 0.85433 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 242401 episodes
GETTING ACTION FROM:
action 3, numVisits=241626, meanQ=6.301751, numObservations: 4
action 1, numVisits=766, meanQ=6.035089, numObservations: 4
action 2, numVisits=7, meanQ=3.568571, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.172309 0.319157 0.630293 0.896377 0.518464 0.85433 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 357
Initial state: 0 0.68621 0.831572 0.990517 0.889723 0.581322 0.895002 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240758 episodes
GETTING ACTION FROM:
action 1, numVisits=240753, meanQ=6.295085, numObservations: 4
action 2, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.68621 0.831572 0.990517 0.889723 0.581322 0.895002 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 358
Initial state: 0 0.693514 0.875675 0.657191 0.871478 0.132359 0.896433 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238401 episodes
GETTING ACTION FROM:
action 1, numVisits=238364, meanQ=6.230096, numObservations: 5
action 2, numVisits=24, meanQ=4.787092, numObservations: 4
action 3, numVisits=11, meanQ=3.725455, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.693514 0.875675 0.657191 0.871478 0.132359 0.896433 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 359
Initial state: 0 0.21083 0.282927 0.652756 0.810022 0.676264 0.857694 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240682 episodes
GETTING ACTION FROM:
action 2, numVisits=240609, meanQ=6.228243, numObservations: 4
action 1, numVisits=49, meanQ=5.211022, numObservations: 5
action 3, numVisits=22, meanQ=4.494550, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.21083 0.282927 0.652756 0.810022 0.676264 0.857694 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 360
Initial state: 0 0.517246 0.805508 0.426488 0.434467 0.598725 0.800282 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239827 episodes
GETTING ACTION FROM:
action 2, numVisits=239806, meanQ=6.222023, numObservations: 5
action 3, numVisits=12, meanQ=4.164175, numObservations: 4
action 1, numVisits=7, meanQ=1.998571, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.517246 0.805508 0.426488 0.434467 0.598725 0.800282 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=33173, meanQ=8.867632, numObservations: 5
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 291884 episodes
GETTING ACTION FROM:
action 1, numVisits=325051, meanQ=6.808345, numObservations: 5
action 2, numVisits=5, meanQ=3.198000, numObservations: 2
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.517246 0.805508 0.426488 0.434467 0.598725 0.800282 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 361
Initial state: 0 0.636978 0.862482 0.517634 0.866035 0.860893 0.0753628 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240577 episodes
GETTING ACTION FROM:
action 1, numVisits=240566, meanQ=6.245672, numObservations: 4
action 3, numVisits=6, meanQ=2.331683, numObservations: 2
action 2, numVisits=3, meanQ=-0.670000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.636978 0.862482 0.517634 0.866035 0.860893 0.0753628 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 362
Initial state: 0 0.645292 0.813969 0.639426 0.881725 0.0455134 0.466635 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238207 episodes
GETTING ACTION FROM:
action 3, numVisits=234863, meanQ=6.181910, numObservations: 5
action 1, numVisits=2997, meanQ=6.063538, numObservations: 4
action 2, numVisits=345, meanQ=5.776593, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.645292 0.813969 0.639426 0.881725 0.0455134 0.466635 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=32287, meanQ=8.873230, numObservations: 5
action 3, numVisits=3, meanQ=2.330033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 293202 episodes
GETTING ACTION FROM:
action 2, numVisits=325489, meanQ=6.576185, numObservations: 5
action 3, numVisits=3, meanQ=2.330033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.645292 0.813969 0.639426 0.881725 0.0455134 0.466635 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 363
Initial state: 0 0.0383093 0.834542 0.507644 0.818689 0.542621 0.896187 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239820 episodes
GETTING ACTION FROM:
action 2, numVisits=239794, meanQ=6.222705, numObservations: 5
action 3, numVisits=16, meanQ=3.436256, numObservations: 3
action 1, numVisits=8, meanQ=2.873750, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.0383093 0.834542 0.507644 0.818689 0.542621 0.896187 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 364
Initial state: 0 0.612738 0.830919 0.303522 0.270146 0.695955 0.870528 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161956 episodes
GETTING ACTION FROM:
action 0, numVisits=161948, meanQ=4.162446, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 0
Next state: 0 0.612738 0.830919 0.303522 0.270146 0.695955 0.870528 w: 1
Observation: 0 0 0.872495 0 0.362064 0 0.79486 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=161920, meanQ=6.229468, numObservations: 4
action 3, numVisits=20, meanQ=2.994010, numObservations: 3
action 2, numVisits=5, meanQ=1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 260021 episodes
GETTING ACTION FROM:
action 1, numVisits=421939, meanQ=6.105201, numObservations: 4
action 3, numVisits=20, meanQ=2.994010, numObservations: 3
action 2, numVisits=5, meanQ=1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.612738 0.830919 0.303522 0.270146 0.695955 0.870528 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 365
Initial state: 0 0.359055 0.387852 0.634313 0.893369 0.659486 0.806484 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239880 episodes
GETTING ACTION FROM:
action 1, numVisits=239640, meanQ=6.310568, numObservations: 4
action 3, numVisits=232, meanQ=5.672923, numObservations: 4
action 2, numVisits=6, meanQ=2.331683, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 0 0.359055 0.387852 0.634313 0.893369 0.659486 0.806484 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=24754, meanQ=8.878163, numObservations: 5
action 3, numVisits=8584, meanQ=8.847317, numObservations: 5
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 289629 episodes
GETTING ACTION FROM:
action 3, numVisits=186084, meanQ=6.735151, numObservations: 5
action 2, numVisits=136881, meanQ=6.732481, numObservations: 5
action 1, numVisits=3, meanQ=2.330033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.359055 0.387852 0.634313 0.893369 0.659486 0.806484 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 366
Initial state: 0 0.71367 0.544557 0.544038 0.802337 0.669727 0.88741 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240501 episodes
GETTING ACTION FROM:
action 3, numVisits=240492, meanQ=6.215134, numObservations: 4
action 1, numVisits=6, meanQ=2.663333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.71367 0.544557 0.544038 0.802337 0.669727 0.88741 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 367
Initial state: 0 0.0324536 0.811023 0.643593 0.890363 0.573941 0.865618 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239750 episodes
GETTING ACTION FROM:
action 2, numVisits=239718, meanQ=6.243308, numObservations: 5
action 3, numVisits=26, meanQ=4.768088, numObservations: 3
action 1, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.0324536 0.811023 0.643593 0.890363 0.573941 0.865618 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 368
Initial state: 0 0.605843 0.819508 0.656029 0.972007 0.596374 0.802006 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240028 episodes
GETTING ACTION FROM:
action 3, numVisits=240016, meanQ=6.234901, numObservations: 4
action 1, numVisits=9, meanQ=2.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.605843 0.819508 0.656029 0.972007 0.596374 0.802006 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 369
Initial state: 0 0.634624 0.864343 0.213497 0.515349 0.583029 0.837961 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240129 episodes
GETTING ACTION FROM:
action 2, numVisits=240106, meanQ=6.217300, numObservations: 5
action 3, numVisits=13, meanQ=3.766931, numObservations: 3
action 1, numVisits=8, meanQ=2.873750, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.634624 0.864343 0.213497 0.515349 0.583029 0.837961 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=32897, meanQ=8.877391, numObservations: 4
action 3, numVisits=44, meanQ=7.885686, numObservations: 3
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 295329 episodes
GETTING ACTION FROM:
action 1, numVisits=328198, meanQ=6.750610, numObservations: 4
action 3, numVisits=70, meanQ=5.728146, numObservations: 3
action 2, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.634624 0.864343 0.213497 0.515349 0.583029 0.837961 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 370
Initial state: 0 0.919334 0.832238 0.575014 0.826128 0.540656 0.832499 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238040 episodes
GETTING ACTION FROM:
action 3, numVisits=237984, meanQ=6.290857, numObservations: 5
action 2, numVisits=35, meanQ=4.993437, numObservations: 4
action 1, numVisits=19, meanQ=3.840011, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.919334 0.832238 0.575014 0.826128 0.540656 0.832499 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 371
Initial state: 0 0.807694 0.924371 0.672256 0.810606 0.514418 0.876729 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238972 episodes
GETTING ACTION FROM:
action 1, numVisits=238965, meanQ=6.238510, numObservations: 5
action 3, numVisits=4, meanQ=-1.002475, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.807694 0.924371 0.672256 0.810606 0.514418 0.876729 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 372
Initial state: 0 0.546201 0.873235 0.894002 0.306337 0.677935 0.884702 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238081 episodes
GETTING ACTION FROM:
action 3, numVisits=238071, meanQ=6.133891, numObservations: 3
action 1, numVisits=6, meanQ=0.830017, numObservations: 2
action 2, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.546201 0.873235 0.894002 0.306337 0.677935 0.884702 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 373
Initial state: 0 0.816542 0.649561 0.575933 0.852233 0.548871 0.807203 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238002 episodes
GETTING ACTION FROM:
action 1, numVisits=237976, meanQ=6.215163, numObservations: 5
action 3, numVisits=23, meanQ=4.509139, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.816542 0.649561 0.575933 0.852233 0.548871 0.807203 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 374
Initial state: 0 0.591771 0.821083 0.539324 0.874865 0.590707 0.679413 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 242362 episodes
GETTING ACTION FROM:
action 2, numVisits=242345, meanQ=6.225936, numObservations: 4
action 1, numVisits=11, meanQ=3.626364, numObservations: 4
action 3, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.591771 0.821083 0.539324 0.874865 0.590707 0.679413 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 375
Initial state: 0 0.631823 0.856389 0.531282 0.878225 0.723367 0.113832 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240509 episodes
GETTING ACTION FROM:
action 2, numVisits=240499, meanQ=6.219303, numObservations: 5
action 1, numVisits=7, meanQ=3.284300, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.631823 0.856389 0.531282 0.878225 0.723367 0.113832 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 376
Initial state: 0 0.680094 0.811276 0.306492 0.128269 0.573107 0.823098 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 237887 episodes
GETTING ACTION FROM:
action 3, numVisits=237778, meanQ=6.217291, numObservations: 5
action 2, numVisits=106, meanQ=5.419342, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.680094 0.811276 0.306492 0.128269 0.573107 0.823098 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 377
Initial state: 0 0.692552 0.800399 0.846501 0.487803 0.577066 0.88918 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 243381 episodes
GETTING ACTION FROM:
action 3, numVisits=243356, meanQ=6.232860, numObservations: 3
action 2, numVisits=20, meanQ=4.444015, numObservations: 3
action 1, numVisits=3, meanQ=-0.966667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.692552 0.800399 0.846501 0.487803 0.577066 0.88918 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 378
Initial state: 0 0.545224 0.809283 0.660334 0.884185 0.466951 0.960717 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241268 episodes
GETTING ACTION FROM:
action 1, numVisits=241205, meanQ=6.232137, numObservations: 4
action 2, numVisits=32, meanQ=4.896569, numObservations: 4
action 3, numVisits=29, meanQ=4.742072, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.545224 0.809283 0.660334 0.884185 0.466951 0.960717 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 379
Initial state: 0 0.61435 0.839937 0.561191 0.886378 0.698487 0.289695 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240767 episodes
GETTING ACTION FROM:
action 3, numVisits=240760, meanQ=6.200602, numObservations: 4
action 2, numVisits=3, meanQ=-0.670000, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 2 0.61435 0.839937 0.561191 0.886378 0.698487 0.289695 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 380
Initial state: 0 0.58984 0.891336 0.51195 0.888819 0.839622 0.42071 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 242094 episodes
GETTING ACTION FROM:
action 2, numVisits=242067, meanQ=6.241450, numObservations: 4
action 3, numVisits=14, meanQ=4.070714, numObservations: 3
action 1, numVisits=11, meanQ=3.625464, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.58984 0.891336 0.51195 0.888819 0.839622 0.42071 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 381
Initial state: 0 0.544186 0.88054 0.937507 0.940671 0.543225 0.808164 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241513 episodes
GETTING ACTION FROM:
action 3, numVisits=241502, meanQ=6.251850, numObservations: 3
action 2, numVisits=7, meanQ=3.284300, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.544186 0.88054 0.937507 0.940671 0.543225 0.808164 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 382
Initial state: 0 0.646032 0.565855 0.596836 0.857519 0.587524 0.811373 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 237035 episodes
GETTING ACTION FROM:
action 2, numVisits=236939, meanQ=6.208243, numObservations: 5
action 1, numVisits=56, meanQ=5.009111, numObservations: 5
action 3, numVisits=38, meanQ=4.752634, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.646032 0.565855 0.596836 0.857519 0.587524 0.811373 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 383
Initial state: 0 0.647874 0.884836 0.991178 0.172353 0.600565 0.862148 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239091 episodes
GETTING ACTION FROM:
action 1, numVisits=239084, meanQ=6.302720, numObservations: 5
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.647874 0.884836 0.991178 0.172353 0.600565 0.862148 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 384
Initial state: 0 0.607865 0.894247 0.256513 0.702363 0.56936 0.854345 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241071 episodes
GETTING ACTION FROM:
action 2, numVisits=240991, meanQ=6.236924, numObservations: 4
action 1, numVisits=68, meanQ=5.374266, numObservations: 4
action 3, numVisits=10, meanQ=2.999010, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.607865 0.894247 0.256513 0.702363 0.56936 0.854345 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=15467, meanQ=8.938920, numObservations: 3
action 1, numVisits=10647, meanQ=8.928695, numObservations: 3
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 296308 episodes
GETTING ACTION FROM:
action 1, numVisits=244101, meanQ=6.691792, numObservations: 4
action 3, numVisits=78320, meanQ=6.680688, numObservations: 4
action 2, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.607865 0.894247 0.256513 0.702363 0.56936 0.854345 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 385
Initial state: 0 0.893784 0.354593 0.513475 0.874593 0.69218 0.802762 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240597 episodes
GETTING ACTION FROM:
action 1, numVisits=240584, meanQ=6.248767, numObservations: 4
action 3, numVisits=9, meanQ=2.432222, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 2 0.893784 0.354593 0.513475 0.874593 0.69218 0.802762 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 386
Initial state: 0 0.560655 0.882317 0.64017 0.889207 0.799146 0.193468 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241109 episodes
GETTING ACTION FROM:
action 2, numVisits=241052, meanQ=6.221222, numObservations: 4
action 1, numVisits=37, meanQ=4.886224, numObservations: 4
action 3, numVisits=18, meanQ=4.054450, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.560655 0.882317 0.64017 0.889207 0.799146 0.193468 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=11050, meanQ=6.466503, numObservations: 4
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 293493 episodes
GETTING ACTION FROM:
action 3, numVisits=304519, meanQ=6.135437, numObservations: 4
action 2, numVisits=25, meanQ=4.594812, numObservations: 3
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.560655 0.882317 0.64017 0.889207 0.799146 0.193468 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=3000, meanQ=5.813054, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 303653 episodes
GETTING ACTION FROM:
action 2, numVisits=306653, meanQ=6.399300, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.560655 0.882317 0.64017 0.889207 0.799146 0.193468 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.8309
Run # 387
Initial state: 0 0.518275 0.892912 0.731259 0.744511 0.528177 0.843138 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239502 episodes
GETTING ACTION FROM:
action 3, numVisits=239452, meanQ=6.254475, numObservations: 4
action 2, numVisits=47, meanQ=4.885745, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.518275 0.892912 0.731259 0.744511 0.528177 0.843138 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 388
Initial state: 0 0.253792 0.779304 0.524859 0.801271 0.581902 0.878234 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239433 episodes
GETTING ACTION FROM:
action 3, numVisits=239409, meanQ=6.237487, numObservations: 5
action 1, numVisits=9, meanQ=3.554444, numObservations: 4
action 2, numVisits=13, meanQ=3.537708, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.253792 0.779304 0.524859 0.801271 0.581902 0.878234 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 389
Initial state: 0 0.804968 0.36245 0.586369 0.808636 0.641077 0.87126 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240757 episodes
GETTING ACTION FROM:
action 1, numVisits=222551, meanQ=6.229958, numObservations: 4
action 2, numVisits=18187, meanQ=6.190473, numObservations: 5
action 3, numVisits=17, meanQ=4.410588, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 2 0.804968 0.36245 0.586369 0.808636 0.641077 0.87126 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 390
Initial state: 0 0.611818 0.807123 0.576688 0.854335 0.453926 0.119321 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240807 episodes
GETTING ACTION FROM:
action 3, numVisits=240803, meanQ=6.223147, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.611818 0.807123 0.576688 0.854335 0.453926 0.119321 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=38850, meanQ=8.878173, numObservations: 3
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 299025 episodes
GETTING ACTION FROM:
action 1, numVisits=337871, meanQ=6.724022, numObservations: 3
action 2, numVisits=4, meanQ=1.747500, numObservations: 3
action 3, numVisits=2, meanQ=-0.509950, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.611818 0.807123 0.576688 0.854335 0.453926 0.119321 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 391
Initial state: 0 0.611473 0.865982 0.308913 0.596739 0.583707 0.866373 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239762 episodes
GETTING ACTION FROM:
action 1, numVisits=239750, meanQ=6.228350, numObservations: 5
action 3, numVisits=8, meanQ=2.873750, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.611473 0.865982 0.308913 0.596739 0.583707 0.866373 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 392
Initial state: 0 0.955347 0.699656 0.641085 0.83254 0.53449 0.87953 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240860 episodes
GETTING ACTION FROM:
action 1, numVisits=240839, meanQ=6.258483, numObservations: 4
action 2, numVisits=10, meanQ=3.990000, numObservations: 4
action 3, numVisits=9, meanQ=2.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 2 0.955347 0.699656 0.641085 0.83254 0.53449 0.87953 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 393
Initial state: 0 0.613513 0.859528 0.534055 0.860405 0.574064 0.656984 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163306 episodes
GETTING ACTION FROM:
action 0, numVisits=163300, meanQ=4.153548, numObservations: 1
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.613513 0.859528 0.534055 0.860405 0.574064 0.656984 w: 1
Observation: 0 0 0.820406 0 0.920341 0 0.743563 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=163253, meanQ=6.214491, numObservations: 3
action 1, numVisits=42, meanQ=5.107857, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 262497 episodes
GETTING ACTION FROM:
action 3, numVisits=425750, meanQ=6.222784, numObservations: 3
action 1, numVisits=42, meanQ=5.107857, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 2 0.613513 0.859528 0.534055 0.860405 0.574064 0.656984 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 394
Initial state: 0 0.687185 0.870667 0.570256 0.801011 0.177561 0.538662 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 245611 episodes
GETTING ACTION FROM:
action 2, numVisits=245601, meanQ=6.238777, numObservations: 3
action 1, numVisits=6, meanQ=2.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 1
action: 2
Next state: 1 0.687185 0.870667 0.570256 0.801011 0.177561 0.538662 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 395
Initial state: 0 0.629929 0.804997 0.647235 0.894715 0.197842 0.0661519 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239173 episodes
GETTING ACTION FROM:
action 1, numVisits=239161, meanQ=6.223915, numObservations: 5
action 2, numVisits=9, meanQ=3.553344, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.629929 0.804997 0.647235 0.894715 0.197842 0.0661519 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 396
Initial state: 0 0.635513 0.823801 0.504033 0.842815 0.57304 0.253737 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 232957 episodes
GETTING ACTION FROM:
action 2, numVisits=232941, meanQ=6.116998, numObservations: 5
action 3, numVisits=9, meanQ=3.554444, numObservations: 3
action 1, numVisits=5, meanQ=1.396000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.635513 0.823801 0.504033 0.842815 0.57304 0.253737 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 397
Initial state: 0 0.731044 0.727048 0.588372 0.875157 0.604073 0.802616 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 242271 episodes
GETTING ACTION FROM:
action 3, numVisits=242254, meanQ=6.233471, numObservations: 3
action 1, numVisits=14, meanQ=3.285007, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.731044 0.727048 0.588372 0.875157 0.604073 0.802616 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 398
Initial state: 0 0.531672 0.86882 0.97396 0.910839 0.588694 0.827526 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 244350 episodes
GETTING ACTION FROM:
action 2, numVisits=244321, meanQ=6.246020, numObservations: 3
action 3, numVisits=23, meanQ=3.824791, numObservations: 4
action 1, numVisits=4, meanQ=1.747500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 2 0.531672 0.86882 0.97396 0.910839 0.588694 0.827526 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 399
Initial state: 0 0.670055 0.866558 0.775209 0.438275 0.652127 0.868951 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 242438 episodes
GETTING ACTION FROM:
action 3, numVisits=242429, meanQ=6.210338, numObservations: 3
action 1, numVisits=5, meanQ=1.396000, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.670055 0.866558 0.775209 0.438275 0.652127 0.868951 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 400
Initial state: 0 0.5987 0.875328 0.570025 0.871481 0.748454 0.318694 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240041 episodes
GETTING ACTION FROM:
action 3, numVisits=239573, meanQ=6.197589, numObservations: 4
action 2, numVisits=459, meanQ=5.876396, numObservations: 5
action 1, numVisits=7, meanQ=1.998571, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 2 0.5987 0.875328 0.570025 0.871481 0.748454 0.318694 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 401
Initial state: 0 0.502001 0.804305 0.510727 0.895544 0.735071 0.483281 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 242209 episodes
GETTING ACTION FROM:
action 1, numVisits=242190, meanQ=6.220027, numObservations: 3
action 3, numVisits=9, meanQ=3.774444, numObservations: 4
action 2, numVisits=8, meanQ=2.873750, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.502001 0.804305 0.510727 0.895544 0.735071 0.483281 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 402
Initial state: 0 0.526555 0.894452 0.692088 0.884997 0.325257 0.932067 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238803 episodes
GETTING ACTION FROM:
action 1, numVisits=238796, meanQ=6.198664, numObservations: 5
action 2, numVisits=4, meanQ=1.992525, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.526555 0.894452 0.692088 0.884997 0.325257 0.932067 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 403
Initial state: 0 0.560546 0.872622 0.971564 0.646623 0.601448 0.885114 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238471 episodes
GETTING ACTION FROM:
action 3, numVisits=238448, meanQ=6.235035, numObservations: 5
action 1, numVisits=17, meanQ=4.410588, numObservations: 3
action 2, numVisits=4, meanQ=1.747500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.560546 0.872622 0.971564 0.646623 0.601448 0.885114 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 404
Initial state: 0 0.556406 0.844813 0.640359 0.81061 0.267917 0.625731 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241929 episodes
GETTING ACTION FROM:
action 3, numVisits=241871, meanQ=6.237082, numObservations: 4
action 1, numVisits=55, meanQ=5.142000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.556406 0.844813 0.640359 0.81061 0.267917 0.625731 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=19517, meanQ=8.867547, numObservations: 4
action 2, numVisits=19808, meanQ=8.867464, numObservations: 5
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 293064 episodes
GETTING ACTION FROM:
action 2, numVisits=189826, meanQ=6.852612, numObservations: 5
action 1, numVisits=142562, meanQ=6.849959, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 2
Next state: 1 0.556406 0.844813 0.640359 0.81061 0.267917 0.625731 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 405
Initial state: 0 0.553706 0.852228 0.645763 0.851401 0.517481 0.179929 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238454 episodes
GETTING ACTION FROM:
action 3, numVisits=187277, meanQ=6.300167, numObservations: 5
action 2, numVisits=51171, meanQ=6.225216, numObservations: 5
action 1, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.553706 0.852228 0.645763 0.851401 0.517481 0.179929 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=14401, meanQ=8.884682, numObservations: 5
action 2, numVisits=11371, meanQ=8.877179, numObservations: 4
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 288669 episodes
GETTING ACTION FROM:
action 1, numVisits=243439, meanQ=6.838288, numObservations: 5
action 2, numVisits=71001, meanQ=6.825731, numObservations: 5
action 3, numVisits=2, meanQ=-0.509950, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.553706 0.852228 0.645763 0.851401 0.517481 0.179929 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 406
Initial state: 0 0.661815 0.876805 0.820847 0.172366 0.592393 0.842122 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 237905 episodes
GETTING ACTION FROM:
action 3, numVisits=237893, meanQ=6.175890, numObservations: 5
action 1, numVisits=9, meanQ=3.554444, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.661815 0.876805 0.820847 0.172366 0.592393 0.842122 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 407
Initial state: 0 0.647943 0.823245 0.599869 0.812498 0.514243 0.752346 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 233736 episodes
GETTING ACTION FROM:
action 1, numVisits=233724, meanQ=6.121941, numObservations: 5
action 3, numVisits=9, meanQ=3.663344, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.647943 0.823245 0.599869 0.812498 0.514243 0.752346 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 408
Initial state: 0 0.552728 0.876849 0.856389 0.40113 0.631755 0.847999 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240565 episodes
GETTING ACTION FROM:
action 3, numVisits=240530, meanQ=6.193217, numObservations: 4
action 2, numVisits=22, meanQ=4.404550, numObservations: 4
action 1, numVisits=11, meanQ=3.626364, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.552728 0.876849 0.856389 0.40113 0.631755 0.847999 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 409
Initial state: 0 0.58784 0.800076 0.581515 0.844321 0.180277 0.316855 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240005 episodes
GETTING ACTION FROM:
action 3, numVisits=239972, meanQ=6.323580, numObservations: 4
action 2, numVisits=30, meanQ=4.926673, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.58784 0.800076 0.581515 0.844321 0.180277 0.316855 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=13092, meanQ=8.931739, numObservations: 3
action 2, numVisits=12835, meanQ=8.931459, numObservations: 3
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 293177 episodes
GETTING ACTION FROM:
action 2, numVisits=239786, meanQ=6.631052, numObservations: 5
action 1, numVisits=79310, meanQ=6.620049, numObservations: 4
action 3, numVisits=9, meanQ=3.552244, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.58784 0.800076 0.581515 0.844321 0.180277 0.316855 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 410
Initial state: 0 0.0769023 0.887362 0.65322 0.854685 0.692535 0.872971 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240424 episodes
GETTING ACTION FROM:
action 2, numVisits=240408, meanQ=6.243272, numObservations: 5
action 3, numVisits=10, meanQ=3.000000, numObservations: 2
action 1, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.0769023 0.887362 0.65322 0.854685 0.692535 0.872971 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 411
Initial state: 0 0.410465 0.853232 0.693068 0.831001 0.527849 0.816886 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240196 episodes
GETTING ACTION FROM:
action 1, numVisits=240190, meanQ=6.224106, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 0 0.410465 0.853232 0.693068 0.831001 0.527849 0.816886 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=10257, meanQ=6.555509, numObservations: 4
action 1, numVisits=415, meanQ=4.945342, numObservations: 3
action 3, numVisits=3, meanQ=2.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 296963 episodes
GETTING ACTION FROM:
action 2, numVisits=307220, meanQ=6.494298, numObservations: 4
action 1, numVisits=415, meanQ=4.945342, numObservations: 3
action 3, numVisits=3, meanQ=2.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.410465 0.853232 0.693068 0.831001 0.527849 0.816886 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 412
Initial state: 0 0.000151538 0.684706 0.637083 0.818225 0.514576 0.862907 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240942 episodes
GETTING ACTION FROM:
action 1, numVisits=240913, meanQ=6.207522, numObservations: 4
action 2, numVisits=7, meanQ=3.284300, numObservations: 4
action 3, numVisits=20, meanQ=2.999505, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 0 0.000151538 0.684706 0.637083 0.818225 0.514576 0.862907 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=32745, meanQ=8.871543, numObservations: 4
action 3, numVisits=528, meanQ=8.607027, numObservations: 4
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 296151 episodes
GETTING ACTION FROM:
action 2, numVisits=326934, meanQ=6.871425, numObservations: 4
action 3, numVisits=2413, meanQ=6.734835, numObservations: 5
action 1, numVisits=78, meanQ=6.005513, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.000151538 0.684706 0.637083 0.818225 0.514576 0.862907 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 413
Initial state: 0 0.56369 0.473547 0.503576 0.848643 0.558617 0.803802 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238989 episodes
GETTING ACTION FROM:
action 3, numVisits=238950, meanQ=6.228812, numObservations: 4
action 2, numVisits=36, meanQ=4.824725, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.56369 0.473547 0.503576 0.848643 0.558617 0.803802 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 414
Initial state: 0 0.565574 0.463943 0.641374 0.847659 0.624063 0.849105 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 237083 episodes
GETTING ACTION FROM:
action 3, numVisits=237044, meanQ=6.224280, numObservations: 5
action 2, numVisits=18, meanQ=4.165000, numObservations: 3
action 1, numVisits=19, meanQ=3.730537, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.565574 0.463943 0.641374 0.847659 0.624063 0.849105 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 415
Initial state: 0 0.541752 0.882229 0.159356 0.871585 0.678526 0.812705 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239890 episodes
GETTING ACTION FROM:
action 3, numVisits=235835, meanQ=6.233387, numObservations: 4
action 1, numVisits=4048, meanQ=6.133860, numObservations: 4
action 2, numVisits=5, meanQ=1.396000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.541752 0.882229 0.159356 0.871585 0.678526 0.812705 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 416
Initial state: 0 0.58571 0.879477 0.792779 0.732778 0.694332 0.873938 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240999 episodes
GETTING ACTION FROM:
action 3, numVisits=240995, meanQ=6.222924, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.58571 0.879477 0.792779 0.732778 0.694332 0.873938 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 417
Initial state: 0 0.636113 0.968601 0.552395 0.859777 0.568317 0.89246 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 236522 episodes
GETTING ACTION FROM:
action 3, numVisits=236491, meanQ=6.237467, numObservations: 5
action 1, numVisits=19, meanQ=2.098963, numObservations: 3
action 2, numVisits=10, meanQ=1.998020, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.636113 0.968601 0.552395 0.859777 0.568317 0.89246 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 418
Initial state: 0 0.645444 0.800663 0.529695 0.848415 0.318369 0.0728934 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238330 episodes
GETTING ACTION FROM:
action 1, numVisits=238325, meanQ=6.215404, numObservations: 5
action 3, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.645444 0.800663 0.529695 0.848415 0.318369 0.0728934 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 419
Initial state: 0 0.630993 0.899803 0.00834624 0.707383 0.619457 0.811155 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240404 episodes
GETTING ACTION FROM:
action 3, numVisits=240399, meanQ=6.272364, numObservations: 4
action 2, numVisits=2, meanQ=-0.509950, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.630993 0.899803 0.00834624 0.707383 0.619457 0.811155 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 420
Initial state: 0 0.0488387 0.106466 0.614687 0.840184 0.543752 0.828141 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240683 episodes
GETTING ACTION FROM:
action 1, numVisits=233384, meanQ=6.299075, numObservations: 4
action 2, numVisits=7258, meanQ=6.227476, numObservations: 5
action 3, numVisits=39, meanQ=5.034359, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 0 0.0488387 0.106466 0.614687 0.840184 0.543752 0.828141 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=12877, meanQ=8.928527, numObservations: 3
action 3, numVisits=12579, meanQ=8.927909, numObservations: 3
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 294744 episodes
GETTING ACTION FROM:
action 3, numVisits=238156, meanQ=6.634635, numObservations: 4
action 2, numVisits=81975, meanQ=6.624630, numObservations: 4
action 1, numVisits=70, meanQ=5.616571, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.0488387 0.106466 0.614687 0.840184 0.543752 0.828141 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 421
Initial state: 0 0.543015 0.012573 0.563224 0.88778 0.590278 0.822518 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239109 episodes
GETTING ACTION FROM:
action 1, numVisits=221869, meanQ=6.308173, numObservations: 5
action 3, numVisits=17233, meanQ=6.188549, numObservations: 4
action 2, numVisits=5, meanQ=1.218000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 2 0.543015 0.012573 0.563224 0.88778 0.590278 0.822518 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 422
Initial state: 0 0.673663 0.814002 0.999699 0.536557 0.692397 0.891168 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 242813 episodes
GETTING ACTION FROM:
action 2, numVisits=242801, meanQ=6.247385, numObservations: 4
action 1, numVisits=8, meanQ=1.498763, numObservations: 2
action 3, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 2 0.673663 0.814002 0.999699 0.536557 0.692397 0.891168 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 423
Initial state: 0 0.435369 0.0963996 0.668554 0.874168 0.525023 0.83056 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 243166 episodes
GETTING ACTION FROM:
action 3, numVisits=243158, meanQ=6.228665, numObservations: 3
action 1, numVisits=4, meanQ=1.992525, numObservations: 2
action 2, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.435369 0.0963996 0.668554 0.874168 0.525023 0.83056 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 424
Initial state: 0 0.119871 0.615819 0.54702 0.824943 0.526685 0.855866 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239000 episodes
GETTING ACTION FROM:
action 1, numVisits=238977, meanQ=6.220848, numObservations: 5
action 2, numVisits=12, meanQ=4.074167, numObservations: 4
action 3, numVisits=9, meanQ=3.554444, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 0 0.119871 0.615819 0.54702 0.824943 0.526685 0.855866 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=13017, meanQ=8.720981, numObservations: 3
action 3, numVisits=8, meanQ=5.373750, numObservations: 3
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 298506 episodes
GETTING ACTION FROM:
action 3, numVisits=245457, meanQ=6.668443, numObservations: 3
action 2, numVisits=66073, meanQ=6.650293, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 3
Next state: 1 0.119871 0.615819 0.54702 0.824943 0.526685 0.855866 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 425
Initial state: 0 0.503179 0.883283 0.562483 0.810551 0.28253 0.00931832 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241257 episodes
GETTING ACTION FROM:
action 3, numVisits=241248, meanQ=6.245824, numObservations: 4
action 1, numVisits=6, meanQ=2.331683, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.503179 0.883283 0.562483 0.810551 0.28253 0.00931832 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=24146, meanQ=8.852571, numObservations: 3
action 1, numVisits=14654, meanQ=8.837911, numObservations: 4
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 298018 episodes
GETTING ACTION FROM:
action 2, numVisits=273238, meanQ=6.827294, numObservations: 3
action 1, numVisits=63579, meanQ=6.813295, numObservations: 4
action 3, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.503179 0.883283 0.562483 0.810551 0.28253 0.00931832 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 426
Initial state: 0 0.688639 0.809444 0.603861 0.832043 0.106257 0.459033 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241084 episodes
GETTING ACTION FROM:
action 1, numVisits=241057, meanQ=6.228884, numObservations: 4
action 2, numVisits=14, meanQ=3.997879, numObservations: 4
action 3, numVisits=11, meanQ=2.726364, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.688639 0.809444 0.603861 0.832043 0.106257 0.459033 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 427
Initial state: 0 0.778728 0.242981 0.503629 0.861714 0.505577 0.825411 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 242743 episodes
GETTING ACTION FROM:
action 2, numVisits=242728, meanQ=6.218633, numObservations: 4
action 1, numVisits=12, meanQ=3.249167, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.778728 0.242981 0.503629 0.861714 0.505577 0.825411 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 428
Initial state: 0 0.971701 0.617324 0.650597 0.878133 0.668411 0.840076 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238651 episodes
GETTING ACTION FROM:
action 3, numVisits=238620, meanQ=6.208770, numObservations: 4
action 2, numVisits=28, meanQ=4.670725, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.971701 0.617324 0.650597 0.878133 0.668411 0.840076 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 429
Initial state: 0 0.549928 0.841365 0.527438 0.847933 0.411477 0.324037 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 242194 episodes
GETTING ACTION FROM:
action 2, numVisits=242184, meanQ=6.236494, numObservations: 4
action 3, numVisits=7, meanQ=3.285714, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.549928 0.841365 0.527438 0.847933 0.411477 0.324037 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 430
Initial state: 0 0.416767 0.765198 0.684676 0.866193 0.659586 0.804236 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 237765 episodes
GETTING ACTION FROM:
action 3, numVisits=219809, meanQ=6.189595, numObservations: 5
action 2, numVisits=17952, meanQ=6.141821, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.416767 0.765198 0.684676 0.866193 0.659586 0.804236 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 431
Initial state: 0 0.938153 0.745092 0.678794 0.839703 0.500415 0.877945 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240471 episodes
GETTING ACTION FROM:
action 2, numVisits=240463, meanQ=6.194952, numObservations: 5
action 3, numVisits=5, meanQ=0.998020, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.938153 0.745092 0.678794 0.839703 0.500415 0.877945 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=10777, meanQ=5.453612, numObservations: 3
action 1, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 272719 episodes
GETTING ACTION FROM:
action 2, numVisits=283491, meanQ=5.923789, numObservations: 4
action -1, numVisits=5, meanQ=1.762000, numObservations: 1
action 1, numVisits=3, meanQ=-0.670000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.938153 0.745092 0.678794 0.839703 0.500415 0.877945 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 432
Initial state: 0 0.635869 0.850654 0.522854 0.84481 0.716048 0.950933 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239916 episodes
GETTING ACTION FROM:
action 2, numVisits=239912, meanQ=6.222325, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.635869 0.850654 0.522854 0.84481 0.716048 0.950933 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 433
Initial state: 0 0.568927 0.213467 0.54923 0.825242 0.51336 0.83941 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238251 episodes
GETTING ACTION FROM:
action 3, numVisits=238245, meanQ=6.266947, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.568927 0.213467 0.54923 0.825242 0.51336 0.83941 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 434
Initial state: 0 0.579229 0.81163 0.550265 0.839338 0.840263 0.443253 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238605 episodes
GETTING ACTION FROM:
action 1, numVisits=234386, meanQ=6.229700, numObservations: 5
action 3, numVisits=4206, meanQ=6.112686, numObservations: 4
action 2, numVisits=11, meanQ=3.544555, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.579229 0.81163 0.550265 0.839338 0.840263 0.443253 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 435
Initial state: 0 0.632359 0.8159 0.672673 0.808629 0.859216 0.191138 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240695 episodes
GETTING ACTION FROM:
action 3, numVisits=240686, meanQ=6.223116, numObservations: 4
action 2, numVisits=4, meanQ=-0.505000, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.632359 0.8159 0.672673 0.808629 0.859216 0.191138 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 436
Initial state: 0 0.276005 0.165124 0.595641 0.870294 0.504772 0.873414 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241225 episodes
GETTING ACTION FROM:
action 2, numVisits=241184, meanQ=6.205921, numObservations: 4
action 1, numVisits=20, meanQ=4.539500, numObservations: 4
action 3, numVisits=19, meanQ=4.320005, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.276005 0.165124 0.595641 0.870294 0.504772 0.873414 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 437
Initial state: 0 0.118216 0.782786 0.534109 0.863673 0.512043 0.839903 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241221 episodes
GETTING ACTION FROM:
action 3, numVisits=241212, meanQ=6.222256, numObservations: 4
action 2, numVisits=6, meanQ=2.663333, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.118216 0.782786 0.534109 0.863673 0.512043 0.839903 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 438
Initial state: 0 0.688142 0.875768 0.235862 0.178908 0.533917 0.895096 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241365 episodes
GETTING ACTION FROM:
action 2, numVisits=241299, meanQ=6.220905, numObservations: 4
action 1, numVisits=38, meanQ=4.906318, numObservations: 4
action 3, numVisits=26, meanQ=4.803081, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.688142 0.875768 0.235862 0.178908 0.533917 0.895096 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=13213, meanQ=8.931136, numObservations: 3
action 3, numVisits=12815, meanQ=8.930181, numObservations: 3
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 294235 episodes
GETTING ACTION FROM:
action 1, numVisits=229877, meanQ=6.582120, numObservations: 5
action 3, numVisits=90385, meanQ=6.572994, numObservations: 3
action 2, numVisits=2, meanQ=-0.509950, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 0 0.688142 0.875768 0.235862 0.178908 0.533917 0.895096 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=1543, meanQ=8.242767, numObservations: 5
action 1, numVisits=641, meanQ=8.107680, numObservations: 4
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 297926 episodes
GETTING ACTION FROM:
action 1, numVisits=263318, meanQ=6.192782, numObservations: 4
action 3, numVisits=36790, meanQ=6.163246, numObservations: 5
action 2, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.688142 0.875768 0.235862 0.178908 0.533917 0.895096 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.8309
Run # 439
Initial state: 0 0.734802 0.922015 0.541776 0.833255 0.684818 0.877221 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238508 episodes
GETTING ACTION FROM:
action 3, numVisits=238499, meanQ=6.239164, numObservations: 4
action 1, numVisits=4, meanQ=1.747500, numObservations: 2
action 2, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.734802 0.922015 0.541776 0.833255 0.684818 0.877221 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 440
Initial state: 0 0.625661 0.830176 0.618131 0.8154 0.0971275 0.731876 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238540 episodes
GETTING ACTION FROM:
action 3, numVisits=238525, meanQ=6.209041, numObservations: 5
action 1, numVisits=12, meanQ=3.249167, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.625661 0.830176 0.618131 0.8154 0.0971275 0.731876 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=13148, meanQ=8.930791, numObservations: 3
action 1, numVisits=12735, meanQ=8.930009, numObservations: 3
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 295211 episodes
GETTING ACTION FROM:
action 2, numVisits=262460, meanQ=6.902008, numObservations: 3
action 1, numVisits=58626, meanQ=6.884484, numObservations: 5
action 3, numVisits=9, meanQ=3.554444, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.625661 0.830176 0.618131 0.8154 0.0971275 0.731876 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 441
Initial state: 0 0.644233 0.824907 0.55753 0.865061 0.236977 0.223396 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239665 episodes
GETTING ACTION FROM:
action 3, numVisits=238509, meanQ=6.200445, numObservations: 4
action 2, numVisits=1023, meanQ=5.982641, numObservations: 4
action 1, numVisits=131, meanQ=5.586415, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.644233 0.824907 0.55753 0.865061 0.236977 0.223396 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=12886, meanQ=8.664854, numObservations: 4
action 2, numVisits=26, meanQ=7.156923, numObservations: 4
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 295720 episodes
GETTING ACTION FROM:
action 1, numVisits=307969, meanQ=6.428961, numObservations: 4
action 2, numVisits=662, meanQ=6.147206, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 1
Next state: 1 0.644233 0.824907 0.55753 0.865061 0.236977 0.223396 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 442
Initial state: 0 0.512305 0.831751 0.111498 0.1678 0.696272 0.815329 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239778 episodes
GETTING ACTION FROM:
action 1, numVisits=239749, meanQ=6.235954, numObservations: 5
action 2, numVisits=26, meanQ=2.883850, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.512305 0.831751 0.111498 0.1678 0.696272 0.815329 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 443
Initial state: 0 0.242042 0.0588431 0.557971 0.818207 0.538389 0.892702 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240971 episodes
GETTING ACTION FROM:
action 3, numVisits=240958, meanQ=6.317347, numObservations: 4
action 1, numVisits=9, meanQ=2.553333, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.242042 0.0588431 0.557971 0.818207 0.538389 0.892702 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 444
Initial state: 0 0.900635 0.197316 0.586861 0.873319 0.575744 0.861085 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241028 episodes
GETTING ACTION FROM:
action 2, numVisits=241021, meanQ=6.234407, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-5.505000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.900635 0.197316 0.586861 0.873319 0.575744 0.861085 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 445
Initial state: 0 0.502928 0.809954 0.618622 0.832323 0.927523 0.945157 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241221 episodes
GETTING ACTION FROM:
action 3, numVisits=241210, meanQ=6.177453, numObservations: 4
action 2, numVisits=4, meanQ=1.747500, numObservations: 3
action 1, numVisits=5, meanQ=1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 2 0.502928 0.809954 0.618622 0.832323 0.927523 0.945157 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 446
Initial state: 0 0.303519 0.0296848 0.618328 0.899016 0.674734 0.891128 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 242638 episodes
GETTING ACTION FROM:
action 2, numVisits=242350, meanQ=6.176138, numObservations: 4
action 3, numVisits=284, meanQ=5.726563, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=2, meanQ=-5.505000, numObservations: 1
action: 2
Next state: 1 0.303519 0.0296848 0.618328 0.899016 0.674734 0.891128 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 447
Initial state: 0 0.664416 0.848124 0.0127544 0.709684 0.609533 0.819293 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 245666 episodes
GETTING ACTION FROM:
action 2, numVisits=245660, meanQ=6.226033, numObservations: 3
action 1, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.664416 0.848124 0.0127544 0.709684 0.609533 0.819293 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=39647, meanQ=8.863196, numObservations: 4
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 294812 episodes
GETTING ACTION FROM:
action 1, numVisits=334408, meanQ=6.641434, numObservations: 4
action 3, numVisits=44, meanQ=5.408636, numObservations: 4
action 2, numVisits=9, meanQ=3.532222, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.664416 0.848124 0.0127544 0.709684 0.609533 0.819293 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 448
Initial state: 0 0.608785 0.281673 0.629439 0.825778 0.659747 0.896458 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 244228 episodes
GETTING ACTION FROM:
action 2, numVisits=244164, meanQ=6.242064, numObservations: 3
action 1, numVisits=59, meanQ=5.119832, numObservations: 3
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.608785 0.281673 0.629439 0.825778 0.659747 0.896458 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 449
Initial state: 0 0.571516 0.894866 0.504796 0.880043 0.533383 0.755879 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239433 episodes
GETTING ACTION FROM:
action 3, numVisits=184798, meanQ=6.224189, numObservations: 5
action 1, numVisits=54631, meanQ=6.219255, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 3
Next state: 2 0.571516 0.894866 0.504796 0.880043 0.533383 0.755879 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 450
Initial state: 0 0.613624 0.830895 0.552203 0.262641 0.542376 0.847927 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238657 episodes
GETTING ACTION FROM:
action 1, numVisits=238644, meanQ=6.238897, numObservations: 5
action 2, numVisits=10, meanQ=2.099000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.613624 0.830895 0.552203 0.262641 0.542376 0.847927 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 451
Initial state: 0 0.60728 0.885659 0.542701 0.802909 0.654661 0.751306 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240847 episodes
GETTING ACTION FROM:
action 1, numVisits=240837, meanQ=6.252294, numObservations: 4
action 2, numVisits=7, meanQ=3.285714, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.60728 0.885659 0.542701 0.802909 0.654661 0.751306 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 452
Initial state: 0 0.674839 0.862634 0.695977 0.877638 0.93823 0.404717 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238236 episodes
GETTING ACTION FROM:
action 2, numVisits=238215, meanQ=6.169691, numObservations: 5
action 3, numVisits=13, meanQ=3.690777, numObservations: 2
action 1, numVisits=6, meanQ=2.150017, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.674839 0.862634 0.695977 0.877638 0.93823 0.404717 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 453
Initial state: 0 0.500547 0.549201 0.605381 0.82337 0.677066 0.837767 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239502 episodes
GETTING ACTION FROM:
action 2, numVisits=239435, meanQ=6.320839, numObservations: 5
action 3, numVisits=31, meanQ=4.862913, numObservations: 4
action 1, numVisits=34, meanQ=4.846771, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.500547 0.549201 0.605381 0.82337 0.677066 0.837767 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 454
Initial state: 0 0.162556 0.573257 0.587274 0.815847 0.675721 0.833963 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238599 episodes
GETTING ACTION FROM:
action 1, numVisits=238543, meanQ=6.228367, numObservations: 5
action 3, numVisits=53, meanQ=5.158496, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.162556 0.573257 0.587274 0.815847 0.675721 0.833963 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=13031, meanQ=8.931440, numObservations: 3
action 2, numVisits=12789, meanQ=8.930857, numObservations: 3
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 292551 episodes
GETTING ACTION FROM:
action 3, numVisits=209896, meanQ=6.824415, numObservations: 5
action 2, numVisits=108472, meanQ=6.817556, numObservations: 3
action 1, numVisits=4, meanQ=1.747500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.162556 0.573257 0.587274 0.815847 0.675721 0.833963 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 455
Initial state: 0 0.631078 0.3747 0.685071 0.854329 0.695249 0.877107 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241056 episodes
GETTING ACTION FROM:
action 1, numVisits=241049, meanQ=6.225855, numObservations: 4
action 2, numVisits=4, meanQ=1.745025, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.631078 0.3747 0.685071 0.854329 0.695249 0.877107 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 456
Initial state: 0 0.566772 0.836453 0.625878 0.570087 0.614345 0.833516 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 242760 episodes
GETTING ACTION FROM:
action 2, numVisits=242754, meanQ=6.303464, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 2 0.566772 0.836453 0.625878 0.570087 0.614345 0.833516 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 457
Initial state: 0 0.598986 0.855054 0.0408858 0.996355 0.693371 0.890285 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238613 episodes
GETTING ACTION FROM:
action 3, numVisits=238588, meanQ=6.230403, numObservations: 5
action 1, numVisits=19, meanQ=4.315263, numObservations: 3
action 2, numVisits=4, meanQ=-0.505000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.598986 0.855054 0.0408858 0.996355 0.693371 0.890285 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 458
Initial state: 0 0.627334 0.881102 0.535852 0.151532 0.692978 0.812223 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238482 episodes
GETTING ACTION FROM:
action 1, numVisits=238434, meanQ=6.179947, numObservations: 5
action 3, numVisits=42, meanQ=5.010012, numObservations: 4
action 2, numVisits=4, meanQ=-0.505000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.627334 0.881102 0.535852 0.151532 0.692978 0.812223 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 459
Initial state: 0 0.660876 0.832055 0.675373 0.801617 0.694624 0.136879 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 237870 episodes
GETTING ACTION FROM:
action 3, numVisits=237848, meanQ=6.206929, numObservations: 5
action 2, numVisits=19, meanQ=3.564216, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.660876 0.832055 0.675373 0.801617 0.694624 0.136879 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=21697, meanQ=8.871390, numObservations: 4
action 1, numVisits=11017, meanQ=8.854748, numObservations: 4
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 293335 episodes
GETTING ACTION FROM:
action 1, numVisits=221215, meanQ=6.929109, numObservations: 5
action 2, numVisits=104808, meanQ=6.918014, numObservations: 4
action 3, numVisits=27, meanQ=5.255559, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.660876 0.832055 0.675373 0.801617 0.694624 0.136879 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 460
Initial state: 0 0.548928 0.887774 0.790653 0.795594 0.605592 0.895494 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239842 episodes
GETTING ACTION FROM:
action 1, numVisits=239837, meanQ=6.314530, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.548928 0.887774 0.790653 0.795594 0.605592 0.895494 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 461
Initial state: 0 0.684995 0.887652 0.237862 0.838936 0.641339 0.801355 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240224 episodes
GETTING ACTION FROM:
action 2, numVisits=240191, meanQ=6.212539, numObservations: 5
action 3, numVisits=29, meanQ=4.888969, numObservations: 4
action 1, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.684995 0.887652 0.237862 0.838936 0.641339 0.801355 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=5955, meanQ=8.747545, numObservations: 3
action 1, numVisits=2, meanQ=4.495000, numObservations: 1
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 298146 episodes
GETTING ACTION FROM:
action 3, numVisits=304098, meanQ=6.304001, numObservations: 3
action 1, numVisits=3, meanQ=-0.670000, numObservations: 2
action 2, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.684995 0.887652 0.237862 0.838936 0.641339 0.801355 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 462
Initial state: 0 0.686239 0.851324 0.544838 0.309103 0.672514 0.88614 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240978 episodes
GETTING ACTION FROM:
action 1, numVisits=240973, meanQ=6.244661, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.686239 0.851324 0.544838 0.309103 0.672514 0.88614 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=10728, meanQ=6.359540, numObservations: 4
action 3, numVisits=27, meanQ=4.591122, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 298640 episodes
GETTING ACTION FROM:
action 2, numVisits=309368, meanQ=6.684366, numObservations: 4
action 3, numVisits=27, meanQ=4.591122, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.686239 0.851324 0.544838 0.309103 0.672514 0.88614 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=3544, meanQ=8.415766, numObservations: 3
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 303013 episodes
GETTING ACTION FROM:
action 1, numVisits=306552, meanQ=6.321543, numObservations: 3
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.686239 0.851324 0.544838 0.309103 0.672514 0.88614 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.8309
Run # 463
Initial state: 0 0.679058 0.899951 0.594864 0.824697 0.400738 0.00174587 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240346 episodes
GETTING ACTION FROM:
action 3, numVisits=240332, meanQ=6.220851, numObservations: 4
action 2, numVisits=7, meanQ=1.998571, numObservations: 3
action 1, numVisits=5, meanQ=1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.679058 0.899951 0.594864 0.824697 0.400738 0.00174587 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=39008, meanQ=8.860346, numObservations: 4
action 1, numVisits=15, meanQ=6.998680, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 295681 episodes
GETTING ACTION FROM:
action 2, numVisits=252557, meanQ=6.742490, numObservations: 4
action 1, numVisits=82147, meanQ=6.732360, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.679058 0.899951 0.594864 0.824697 0.400738 0.00174587 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 464
Initial state: 0 0.507141 0.869129 0.218163 0.61266 0.639615 0.891435 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 245935 episodes
GETTING ACTION FROM:
action 2, numVisits=245928, meanQ=6.228196, numObservations: 3
action 3, numVisits=2, meanQ=-0.509950, numObservations: 1
action 1, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.507141 0.869129 0.218163 0.61266 0.639615 0.891435 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=32771, meanQ=8.855824, numObservations: 5
action 3, numVisits=7191, meanQ=8.819710, numObservations: 3
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 293402 episodes
GETTING ACTION FROM:
action 1, numVisits=250019, meanQ=6.700920, numObservations: 5
action 3, numVisits=83344, meanQ=6.693687, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 1
Next state: 1 0.507141 0.869129 0.218163 0.61266 0.639615 0.891435 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 465
Initial state: 0 0.89974 0.23123 0.54939 0.806106 0.533243 0.883775 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 237653 episodes
GETTING ACTION FROM:
action 3, numVisits=237647, meanQ=6.219508, numObservations: 5
action 1, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.89974 0.23123 0.54939 0.806106 0.533243 0.883775 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 466
Initial state: 0 0.518868 0.877048 0.309443 0.0453415 0.618383 0.823063 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240718 episodes
GETTING ACTION FROM:
action 3, numVisits=240696, meanQ=6.232304, numObservations: 4
action 2, numVisits=18, meanQ=4.109450, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.518868 0.877048 0.309443 0.0453415 0.618383 0.823063 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 467
Initial state: 0 0.510271 0.824024 0.500376 0.852214 0.409759 0.975972 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239549 episodes
GETTING ACTION FROM:
action 2, numVisits=239525, meanQ=6.235595, numObservations: 5
action 3, numVisits=18, meanQ=4.555006, numObservations: 3
action 1, numVisits=4, meanQ=1.992525, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.510271 0.824024 0.500376 0.852214 0.409759 0.975972 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 468
Initial state: 0 0.665422 0.632861 0.525058 0.873985 0.575064 0.857757 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238155 episodes
GETTING ACTION FROM:
action 3, numVisits=238150, meanQ=6.145427, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.665422 0.632861 0.525058 0.873985 0.575064 0.857757 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=10738, meanQ=4.612176, numObservations: 1
action -1, numVisits=93, meanQ=2.831459, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=4, meanQ=-1.002475, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 294154 episodes
GETTING ACTION FROM:
action 1, numVisits=290674, meanQ=6.260476, numObservations: 4
action 0, numVisits=14216, meanQ=3.322797, numObservations: 1
action -1, numVisits=97, meanQ=2.717561, numObservations: 1
action 3, numVisits=4, meanQ=-1.002475, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.665422 0.632861 0.525058 0.873985 0.575064 0.857757 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=2484, meanQ=8.354450, numObservations: 4
action 3, numVisits=2, meanQ=4.495000, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 301443 episodes
GETTING ACTION FROM:
action 2, numVisits=303908, meanQ=6.634532, numObservations: 4
action 3, numVisits=21, meanQ=4.332381, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.665422 0.632861 0.525058 0.873985 0.575064 0.857757 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.8309
Run # 469
Initial state: 0 0.851822 0.995523 0.517967 0.894506 0.653651 0.876086 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238750 episodes
GETTING ACTION FROM:
action 3, numVisits=238745, meanQ=6.231964, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.851822 0.995523 0.517967 0.894506 0.653651 0.876086 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 470
Initial state: 0 0.127839 0.590744 0.622151 0.853318 0.561098 0.844764 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238930 episodes
GETTING ACTION FROM:
action 3, numVisits=238903, meanQ=6.238073, numObservations: 5
action 2, numVisits=23, meanQ=2.426091, numObservations: 4
action 1, numVisits=2, meanQ=-0.509950, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.127839 0.590744 0.622151 0.853318 0.561098 0.844764 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 471
Initial state: 0 0.639856 0.872902 0.987938 0.155741 0.680568 0.837724 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 242439 episodes
GETTING ACTION FROM:
action 2, numVisits=242434, meanQ=6.191092, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.639856 0.872902 0.987938 0.155741 0.680568 0.837724 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 472
Initial state: 0 0.257162 0.187374 0.656765 0.832307 0.690797 0.897324 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239424 episodes
GETTING ACTION FROM:
action 1, numVisits=239414, meanQ=6.238823, numObservations: 5
action 2, numVisits=6, meanQ=2.663333, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 0 0.257162 0.187374 0.656765 0.832307 0.690797 0.897324 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=14453, meanQ=8.934790, numObservations: 3
action 3, numVisits=11600, meanQ=8.928679, numObservations: 3
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 291466 episodes
GETTING ACTION FROM:
action 2, numVisits=170616, meanQ=6.577674, numObservations: 5
action 3, numVisits=146801, meanQ=6.576611, numObservations: 4
action 1, numVisits=103, meanQ=5.851651, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.257162 0.187374 0.656765 0.832307 0.690797 0.897324 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 473
Initial state: 0 0.6291 0.833572 0.512522 0.808325 0.964438 0.669807 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240300 episodes
GETTING ACTION FROM:
action 2, numVisits=239883, meanQ=6.253294, numObservations: 4
action 3, numVisits=361, meanQ=5.882645, numObservations: 5
action 1, numVisits=54, meanQ=5.174819, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.6291 0.833572 0.512522 0.808325 0.964438 0.669807 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 474
Initial state: 0 0.0732329 0.0629274 0.526725 0.807045 0.606654 0.853592 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 158979 episodes
GETTING ACTION FROM:
action 0, numVisits=158972, meanQ=4.057919, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-5.505000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.0732329 0.0629274 0.526725 0.807045 0.606654 0.853592 w: 1
Observation: 0 0 0.157605 0 0.848616 0 0.896038 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=158959, meanQ=6.144253, numObservations: 5
action 3, numVisits=8, meanQ=2.996262, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 253009 episodes
GETTING ACTION FROM:
action 2, numVisits=411968, meanQ=6.202314, numObservations: 5
action 3, numVisits=8, meanQ=2.996262, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.0732329 0.0629274 0.526725 0.807045 0.606654 0.853592 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 475
Initial state: 0 0.610076 0.816891 0.532099 0.85648 0.184173 0.413359 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 246310 episodes
GETTING ACTION FROM:
action 2, numVisits=246304, meanQ=6.205278, numObservations: 3
action 3, numVisits=3, meanQ=-0.670000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.610076 0.816891 0.532099 0.85648 0.184173 0.413359 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 476
Initial state: 0 0.580635 0.959233 0.696259 0.837871 0.640818 0.830101 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241049 episodes
GETTING ACTION FROM:
action 1, numVisits=240989, meanQ=6.221210, numObservations: 4
action 3, numVisits=46, meanQ=4.985007, numObservations: 5
action 2, numVisits=12, meanQ=4.080850, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 2 0.580635 0.959233 0.696259 0.837871 0.640818 0.830101 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 477
Initial state: 0 0.66429 0.877515 0.678392 0.888257 0.492069 0.26758 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239385 episodes
GETTING ACTION FROM:
action 2, numVisits=239377, meanQ=6.207142, numObservations: 5
action 1, numVisits=4, meanQ=1.747500, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.66429 0.877515 0.678392 0.888257 0.492069 0.26758 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 478
Initial state: 0 0.569834 0.878725 0.531117 0.845589 0.575966 0.362044 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 242440 episodes
GETTING ACTION FROM:
action 3, numVisits=242431, meanQ=6.233702, numObservations: 3
action 2, numVisits=3, meanQ=-0.670000, numObservations: 2
action 1, numVisits=4, meanQ=-1.002475, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 2 0.569834 0.878725 0.531117 0.845589 0.575966 0.362044 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 479
Initial state: 0 0.768836 0.943421 0.552621 0.863529 0.69631 0.811317 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 237939 episodes
GETTING ACTION FROM:
action 1, numVisits=237798, meanQ=6.240788, numObservations: 5
action 2, numVisits=137, meanQ=5.616862, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 2 0.768836 0.943421 0.552621 0.863529 0.69631 0.811317 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 480
Initial state: 0 0.852606 0.542481 0.62284 0.817307 0.514995 0.831864 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239308 episodes
GETTING ACTION FROM:
action 1, numVisits=239279, meanQ=6.210870, numObservations: 5
action 2, numVisits=26, meanQ=4.719235, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.852606 0.542481 0.62284 0.817307 0.514995 0.831864 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 481
Initial state: 0 0.627066 0.869927 0.516168 0.803539 0.485317 0.590943 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 236384 episodes
GETTING ACTION FROM:
action 1, numVisits=236372, meanQ=6.217242, numObservations: 5
action 3, numVisits=8, meanQ=2.873750, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.627066 0.869927 0.516168 0.803539 0.485317 0.590943 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 482
Initial state: 0 0.5463 0.189067 0.616883 0.809265 0.566865 0.872421 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241633 episodes
GETTING ACTION FROM:
action 3, numVisits=241513, meanQ=6.199614, numObservations: 4
action 2, numVisits=112, meanQ=4.525628, numObservations: 4
action 1, numVisits=6, meanQ=2.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.5463 0.189067 0.616883 0.809265 0.566865 0.872421 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 483
Initial state: 0 0.311388 0.332549 0.572107 0.897347 0.619743 0.882992 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 242934 episodes
GETTING ACTION FROM:
action 2, numVisits=242917, meanQ=6.239790, numObservations: 4
action 1, numVisits=13, meanQ=3.760000, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.311388 0.332549 0.572107 0.897347 0.619743 0.882992 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 484
Initial state: 0 0.522705 0.803224 0.525822 0.564861 0.519492 0.848882 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238147 episodes
GETTING ACTION FROM:
action 3, numVisits=236033, meanQ=6.232126, numObservations: 5
action 1, numVisits=2099, meanQ=6.086154, numObservations: 4
action 2, numVisits=13, meanQ=3.690777, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.522705 0.803224 0.525822 0.564861 0.519492 0.848882 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=8444, meanQ=5.984691, numObservations: 3
action 1, numVisits=9, meanQ=0.110011, numObservations: 4
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 299997 episodes
GETTING ACTION FROM:
action 2, numVisits=308441, meanQ=6.276311, numObservations: 3
action 1, numVisits=9, meanQ=0.110011, numObservations: 4
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.522705 0.803224 0.525822 0.564861 0.519492 0.848882 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11.89
Run # 485
Initial state: 0 0.53694 0.886684 0.649967 0.825825 0.976359 0.142181 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240650 episodes
GETTING ACTION FROM:
action 1, numVisits=240623, meanQ=6.251461, numObservations: 4
action 3, numVisits=18, meanQ=4.555006, numObservations: 3
action 2, numVisits=7, meanQ=3.285714, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.53694 0.886684 0.649967 0.825825 0.976359 0.142181 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 486
Initial state: 0 0.510273 0.88146 0.543993 0.137787 0.695462 0.808022 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241547 episodes
GETTING ACTION FROM:
action 2, numVisits=241541, meanQ=6.227520, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.510273 0.88146 0.543993 0.137787 0.695462 0.808022 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=20873, meanQ=8.875237, numObservations: 5
action 3, numVisits=12265, meanQ=8.854700, numObservations: 4
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 294491 episodes
GETTING ACTION FROM:
action 1, numVisits=211625, meanQ=6.698678, numObservations: 5
action 3, numVisits=116002, meanQ=6.693113, numObservations: 4
action 2, numVisits=3, meanQ=-0.670000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.510273 0.88146 0.543993 0.137787 0.695462 0.808022 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 487
Initial state: 0 0.516875 0.86477 0.204594 0.329063 0.677796 0.824091 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 242199 episodes
GETTING ACTION FROM:
action 2, numVisits=242192, meanQ=6.238145, numObservations: 4
action 1, numVisits=4, meanQ=-0.505000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.516875 0.86477 0.204594 0.329063 0.677796 0.824091 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=23875, meanQ=8.857348, numObservations: 4
action 1, numVisits=15661, meanQ=8.840611, numObservations: 5
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 294504 episodes
GETTING ACTION FROM:
action 1, numVisits=197531, meanQ=6.677026, numObservations: 5
action 3, numVisits=136507, meanQ=6.673798, numObservations: 4
action 2, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.516875 0.86477 0.204594 0.329063 0.677796 0.824091 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 488
Initial state: 0 0.660963 0.87191 0.600024 0.837298 0.842641 0.410189 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239572 episodes
GETTING ACTION FROM:
action 2, numVisits=239566, meanQ=6.226456, numObservations: 5
action 1, numVisits=3, meanQ=-0.670000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.660963 0.87191 0.600024 0.837298 0.842641 0.410189 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 489
Initial state: 0 0.652254 0.887652 0.538228 0.854655 0.794038 0.678214 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241342 episodes
GETTING ACTION FROM:
action 3, numVisits=241336, meanQ=6.221448, numObservations: 4
action 1, numVisits=2, meanQ=-0.010000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 2 0.652254 0.887652 0.538228 0.854655 0.794038 0.678214 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 490
Initial state: 0 0.618964 0.848426 0.509726 0.85668 0.27546 0.327809 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 236594 episodes
GETTING ACTION FROM:
action 1, numVisits=236586, meanQ=6.212136, numObservations: 5
action 3, numVisits=4, meanQ=1.747500, numObservations: 2
action 2, numVisits=2, meanQ=-0.509950, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.618964 0.848426 0.509726 0.85668 0.27546 0.327809 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 491
Initial state: 0 0.628263 0.802913 0.920131 0.065767 0.598119 0.85589 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240290 episodes
GETTING ACTION FROM:
action 2, numVisits=240279, meanQ=6.290934, numObservations: 5
action 3, numVisits=8, meanQ=2.873750, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.628263 0.802913 0.920131 0.065767 0.598119 0.85589 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 492
Initial state: 0 0.647088 0.839779 0.543617 0.227372 0.638638 0.856818 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 235275 episodes
GETTING ACTION FROM:
action 1, numVisits=235264, meanQ=6.148266, numObservations: 4
action 2, numVisits=7, meanQ=3.285714, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.647088 0.839779 0.543617 0.227372 0.638638 0.856818 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 493
Initial state: 0 0.529205 0.850305 0.514264 0.896165 0.083632 0.453215 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240618 episodes
GETTING ACTION FROM:
action 1, numVisits=240601, meanQ=6.221725, numObservations: 4
action 3, numVisits=13, meanQ=2.305385, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.529205 0.850305 0.514264 0.896165 0.083632 0.453215 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 494
Initial state: 0 0.519132 0.878697 0.742523 0.452025 0.535027 0.805636 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239064 episodes
GETTING ACTION FROM:
action 3, numVisits=239054, meanQ=6.180191, numObservations: 4
action 2, numVisits=7, meanQ=1.998571, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.519132 0.878697 0.742523 0.452025 0.535027 0.805636 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 495
Initial state: 0 0.558462 0.866077 0.510784 0.867291 0.385687 0.839796 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 239750 episodes
GETTING ACTION FROM:
action 2, numVisits=239733, meanQ=6.215786, numObservations: 5
action 3, numVisits=14, meanQ=3.427143, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.558462 0.866077 0.510784 0.867291 0.385687 0.839796 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 496
Initial state: 0 0.976363 0.0620408 0.632676 0.822455 0.565393 0.840206 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 240831 episodes
GETTING ACTION FROM:
action 1, numVisits=240826, meanQ=6.246418, numObservations: 4
action 3, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.976363 0.0620408 0.632676 0.822455 0.565393 0.840206 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 497
Initial state: 0 0.664485 0.89216 0.596099 0.828058 0.177128 0.184916 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241010 episodes
GETTING ACTION FROM:
action 3, numVisits=239084, meanQ=6.260139, numObservations: 4
action 1, numVisits=1917, meanQ=6.105780, numObservations: 5
action 2, numVisits=7, meanQ=3.285714, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.664485 0.89216 0.596099 0.828058 0.177128 0.184916 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=21499, meanQ=8.881900, numObservations: 5
action 2, numVisits=11358, meanQ=8.863900, numObservations: 5
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 289841 episodes
GETTING ACTION FROM:
action 2, numVisits=175764, meanQ=6.641972, numObservations: 5
action 1, numVisits=146899, meanQ=6.639800, numObservations: 5
action 3, numVisits=36, meanQ=5.294728, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.664485 0.89216 0.596099 0.828058 0.177128 0.184916 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 498
Initial state: 0 0.513836 0.806493 0.584796 0.891829 0.943843 0.914819 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 238581 episodes
GETTING ACTION FROM:
action 1, numVisits=238570, meanQ=6.245266, numObservations: 5
action 2, numVisits=6, meanQ=-1.001650, numObservations: 3
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.513836 0.806493 0.584796 0.891829 0.943843 0.914819 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 499
Initial state: 0 0.181784 0.564877 0.601856 0.87429 0.513554 0.851593 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241168 episodes
GETTING ACTION FROM:
action 1, numVisits=241148, meanQ=6.203898, numObservations: 4
action 2, numVisits=7, meanQ=3.422900, numObservations: 2
action 3, numVisits=11, meanQ=2.633664, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 0 0.181784 0.564877 0.601856 0.87429 0.513554 0.851593 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=13935, meanQ=8.933275, numObservations: 3
action 2, numVisits=12717, meanQ=8.930914, numObservations: 3
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 295992 episodes
GETTING ACTION FROM:
action 2, numVisits=241167, meanQ=6.701820, numObservations: 4
action 3, numVisits=81476, meanQ=6.691008, numObservations: 4
action 1, numVisits=2, meanQ=-0.509950, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.181784 0.564877 0.601856 0.87429 0.513554 0.851593 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 500
Initial state: 0 0.651635 0.861641 0.629123 0.827916 0.629464 0.839923 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 241060 episodes
GETTING ACTION FROM:
action 3, numVisits=241050, meanQ=6.215030, numObservations: 4
action 2, numVisits=6, meanQ=2.333333, numObservations: 3
action 1, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.651635 0.861641 0.629123 0.827916 0.629464 0.839923 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
