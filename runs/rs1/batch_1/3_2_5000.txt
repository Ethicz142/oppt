Run # 1
Initial state: 0 0.659885 0.842397 0.092699 0.794437 0.616258 0.882838 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1105664 episodes
GETTING ACTION FROM:
action 3, numVisits=1105629, meanQ=6.237873, numObservations: 5
action -1, numVisits=29, meanQ=4.850749, numObservations: 1
action 2, numVisits=2, meanQ=-0.010000, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 3
Next state: 1 0.659885 0.842397 0.092699 0.794437 0.616258 0.882838 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 2
Initial state: 0 0.554361 0.838086 0.136018 0.0718042 0.697678 0.823979 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1194509 episodes
GETTING ACTION FROM:
action 3, numVisits=1194477, meanQ=6.238871, numObservations: 4
action 1, numVisits=21, meanQ=4.237624, numObservations: 3
action 2, numVisits=7, meanQ=1.998571, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.554361 0.838086 0.136018 0.0718042 0.697678 0.823979 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 3
Initial state: 0 0.607214 0.861763 0.724132 0.957791 0.65472 0.862508 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1200561 episodes
GETTING ACTION FROM:
action 3, numVisits=1200493, meanQ=6.240435, numObservations: 4
action 0, numVisits=30, meanQ=4.866992, numObservations: 1
action 1, numVisits=22, meanQ=4.544545, numObservations: 3
action 2, numVisits=14, meanQ=4.212143, numObservations: 3
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 3
Next state: 1 0.607214 0.861763 0.724132 0.957791 0.65472 0.862508 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 4
Initial state: 0 0.690461 0.893632 0.558188 0.880343 0.0881051 0.469923 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1212110 episodes
GETTING ACTION FROM:
action 3, numVisits=1211944, meanQ=6.228353, numObservations: 3
action 0, numVisits=56, meanQ=5.207615, numObservations: 1
action -1, numVisits=55, meanQ=5.192629, numObservations: 1
action 1, numVisits=54, meanQ=4.985930, numObservations: 4
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.690461 0.893632 0.558188 0.880343 0.0881051 0.469923 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=196372, meanQ=8.859915, numObservations: 5
action 2, numVisits=9, meanQ=5.677778, numObservations: 3
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1447262 episodes
GETTING ACTION FROM:
action 1, numVisits=1643612, meanQ=6.844505, numObservations: 5
action 3, numVisits=22, meanQ=4.706364, numObservations: 4
action 2, numVisits=10, meanQ=4.010000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.690461 0.893632 0.558188 0.880343 0.0881051 0.469923 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 5
Initial state: 0 0.579471 0.859902 0.259538 0.56059 0.619076 0.883085 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1193785 episodes
GETTING ACTION FROM:
action 3, numVisits=1162883, meanQ=6.237799, numObservations: 4
action 2, numVisits=30798, meanQ=6.200725, numObservations: 4
action -1, numVisits=51, meanQ=5.183182, numObservations: 1
action 0, numVisits=49, meanQ=5.156458, numObservations: 1
action 1, numVisits=4, meanQ=1.747500, numObservations: 2
action: 3
Next state: 1 0.579471 0.859902 0.259538 0.56059 0.619076 0.883085 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 6
Initial state: 0 0.619248 0.839456 0.602472 0.885401 0.902776 0.371873 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1200061 episodes
GETTING ACTION FROM:
action 3, numVisits=1200054, meanQ=6.235784, numObservations: 4
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-5.505000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.619248 0.839456 0.602472 0.885401 0.902776 0.371873 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 7
Initial state: 0 0.136278 0.117454 0.536499 0.841777 0.602873 0.887597 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1185853 episodes
GETTING ACTION FROM:
action 1, numVisits=1185845, meanQ=6.325912, numObservations: 5
action 2, numVisits=3, meanQ=-0.670000, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.136278 0.117454 0.536499 0.841777 0.602873 0.887597 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=65642, meanQ=8.937936, numObservations: 3
action 2, numVisits=63478, meanQ=8.937520, numObservations: 3
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1486813 episodes
GETTING ACTION FROM:
action 3, numVisits=1091929, meanQ=6.771400, numObservations: 3
action 2, numVisits=523994, meanQ=6.767892, numObservations: 4
action 1, numVisits=11, meanQ=3.544555, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.136278 0.117454 0.536499 0.841777 0.602873 0.887597 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 8
Initial state: 0 0.510872 0.859254 0.560405 0.840655 0.587224 0.888748 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1198699 episodes
GETTING ACTION FROM:
action 1, numVisits=1198523, meanQ=6.229297, numObservations: 4
action 3, numVisits=98, meanQ=5.408063, numObservations: 4
action 0, numVisits=74, meanQ=5.356910, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 1
Next state: 1 0.510872 0.859254 0.560405 0.840655 0.587224 0.888748 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 9
Initial state: 0 0.56381 0.851983 0.614767 0.865096 0.801412 0.894552 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1172497 episodes
GETTING ACTION FROM:
action 3, numVisits=1172461, meanQ=6.171651, numObservations: 4
action -1, numVisits=26, meanQ=4.590404, numObservations: 1
action 2, numVisits=6, meanQ=2.663333, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.56381 0.851983 0.614767 0.865096 0.801412 0.894552 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 10
Initial state: 0 0.509486 0.877534 0.643434 0.8852 0.948031 0.949234 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1196438 episodes
GETTING ACTION FROM:
action 3, numVisits=1196230, meanQ=6.179320, numObservations: 4
action 1, numVisits=170, meanQ=5.431767, numObservations: 4
action -1, numVisits=28, meanQ=4.698552, numObservations: 1
action 2, numVisits=8, meanQ=2.873750, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.509486 0.877534 0.643434 0.8852 0.948031 0.949234 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 11
Initial state: 0 0.623065 0.84802 0.644614 0.802048 0.0902191 0.0706667 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1195027 episodes
GETTING ACTION FROM:
action 3, numVisits=1195013, meanQ=6.231845, numObservations: 4
action 1, numVisits=8, meanQ=2.872513, numObservations: 4
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 1
action: 3
Next state: 0 0.623065 0.84802 0.644614 0.802048 0.0902191 0.0706667 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=194145, meanQ=8.858898, numObservations: 4
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1479163 episodes
GETTING ACTION FROM:
action 1, numVisits=1673105, meanQ=6.545238, numObservations: 4
action 2, numVisits=201, meanQ=5.979950, numObservations: 5
action 3, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 1
Next state: 1 0.623065 0.84802 0.644614 0.802048 0.0902191 0.0706667 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 12
Initial state: 0 0.614 0.86881 0.846827 0.800145 0.503095 0.890329 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1199666 episodes
GETTING ACTION FROM:
action 3, numVisits=1199558, meanQ=6.231222, numObservations: 4
action 0, numVisits=56, meanQ=5.236397, numObservations: 1
action -1, numVisits=36, meanQ=4.988273, numObservations: 1
action 1, numVisits=15, meanQ=4.181333, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.614 0.86881 0.846827 0.800145 0.503095 0.890329 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 13
Initial state: 0 0.560564 0.814539 0.275739 0.097479 0.554214 0.876856 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1186468 episodes
GETTING ACTION FROM:
action 1, numVisits=1186460, meanQ=6.225617, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 1
Next state: 1 0.560564 0.814539 0.275739 0.097479 0.554214 0.876856 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 14
Initial state: 0 0.670449 0.814137 0.845955 0.097747 0.616634 0.803896 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1204855 episodes
GETTING ACTION FROM:
action 2, numVisits=1204767, meanQ=6.227219, numObservations: 4
action -1, numVisits=43, meanQ=5.059119, numObservations: 1
action 1, numVisits=31, meanQ=4.547423, numObservations: 4
action 3, numVisits=12, meanQ=3.414167, numObservations: 3
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 2
Next state: 2 0.670449 0.814137 0.845955 0.097747 0.616634 0.803896 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 15
Initial state: 0 0.602887 0.823403 0.34672 0.0946233 0.635007 0.85914 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1195491 episodes
GETTING ACTION FROM:
action 1, numVisits=1177568, meanQ=6.228659, numObservations: 4
action 3, numVisits=17918, meanQ=6.151824, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.602887 0.823403 0.34672 0.0946233 0.635007 0.85914 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 16
Initial state: 0 0.101265 0.347208 0.603935 0.885503 0.555852 0.809366 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1181449 episodes
GETTING ACTION FROM:
action 1, numVisits=1181344, meanQ=6.244299, numObservations: 5
action -1, numVisits=39, meanQ=5.009784, numObservations: 1
action 0, numVisits=38, meanQ=4.988749, numObservations: 2
action 2, numVisits=17, meanQ=4.287071, numObservations: 3
action 3, numVisits=11, meanQ=2.726364, numObservations: 3
action: 1
Next state: 0 0.101265 0.347208 0.603935 0.885503 0.555852 0.809366 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=162870, meanQ=8.870328, numObservations: 4
action 2, numVisits=6, meanQ=5.666667, numObservations: 2
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1458193 episodes
GETTING ACTION FROM:
action 3, numVisits=1620964, meanQ=6.816744, numObservations: 4
action 2, numVisits=86, meanQ=5.976744, numObservations: 4
action 1, numVisits=20, meanQ=4.885505, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.101265 0.347208 0.603935 0.885503 0.555852 0.809366 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 17
Initial state: 0 0.268722 0.684028 0.698653 0.840258 0.627451 0.841748 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1196216 episodes
GETTING ACTION FROM:
action 3, numVisits=1196208, meanQ=6.300145, numObservations: 4
action 2, numVisits=2, meanQ=-0.010000, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.268722 0.684028 0.698653 0.840258 0.627451 0.841748 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 18
Initial state: 0 0.637093 0.877632 0.325457 0.522591 0.63342 0.853933 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1211472 episodes
GETTING ACTION FROM:
action 2, numVisits=1211330, meanQ=6.191959, numObservations: 4
action -1, numVisits=89, meanQ=5.400972, numObservations: 1
action 0, numVisits=28, meanQ=4.744286, numObservations: 1
action 1, numVisits=23, meanQ=4.260004, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 2
Next state: 0 0.637093 0.877632 0.325457 0.522591 0.63342 0.853933 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=132708, meanQ=8.858359, numObservations: 3
action 1, numVisits=63893, meanQ=8.850791, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1492559 episodes
GETTING ACTION FROM:
action 1, numVisits=1214296, meanQ=6.994177, numObservations: 3
action 3, numVisits=474864, meanQ=6.989707, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.637093 0.877632 0.325457 0.522591 0.63342 0.853933 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 19
Initial state: 0 0.693184 0.818276 0.469016 0.912994 0.515483 0.832885 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1205417 episodes
GETTING ACTION FROM:
action 2, numVisits=1205408, meanQ=6.226677, numObservations: 4
action 1, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.693184 0.818276 0.469016 0.912994 0.515483 0.832885 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=53874, meanQ=6.490504, numObservations: 4
action 2, numVisits=49, meanQ=4.328163, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1479522 episodes
GETTING ACTION FROM:
action 1, numVisits=1533394, meanQ=6.297917, numObservations: 4
action 2, numVisits=49, meanQ=4.328163, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.693184 0.818276 0.469016 0.912994 0.515483 0.832885 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 20
Initial state: 0 0.527065 0.912375 0.614634 0.814926 0.690882 0.880996 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 805377 episodes
GETTING ACTION FROM:
action -1, numVisits=805360, meanQ=4.123720, numObservations: 1
action 3, numVisits=9, meanQ=1.220022, numObservations: 4
action 2, numVisits=4, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-5.505000, numObservations: 2
action: -1
Next state: 0 0.527065 0.912375 0.614634 0.814926 0.690882 0.880996 w: 1
Observation: 0 0.458905 0 0.703617 0 0.693772 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=805270, meanQ=6.179239, numObservations: 5
action -1, numVisits=49, meanQ=5.126903, numObservations: 1
action 1, numVisits=36, meanQ=3.842781, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
Sampled 1279639 episodes
GETTING ACTION FROM:
action 3, numVisits=2084907, meanQ=6.178378, numObservations: 5
action -1, numVisits=51, meanQ=5.107374, numObservations: 1
action 1, numVisits=36, meanQ=3.842781, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 3
Next state: 1 0.527065 0.912375 0.614634 0.814926 0.690882 0.880996 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 21
Initial state: 0 0.60821 0.883802 0.628373 0.836182 0.00983755 0.865397 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1202668 episodes
GETTING ACTION FROM:
action 1, numVisits=1202634, meanQ=6.215628, numObservations: 4
action 3, numVisits=28, meanQ=3.320364, numObservations: 3
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 1
action: 1
Next state: 1 0.60821 0.883802 0.628373 0.836182 0.00983755 0.865397 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 22
Initial state: 0 0.347097 0.777218 0.620326 0.852778 0.653992 0.883157 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1195700 episodes
GETTING ACTION FROM:
action 2, numVisits=1195605, meanQ=6.189890, numObservations: 4
action 1, numVisits=38, meanQ=4.960274, numObservations: 4
action 0, numVisits=26, meanQ=4.707631, numObservations: 1
action -1, numVisits=23, meanQ=4.564787, numObservations: 1
action 3, numVisits=8, meanQ=2.873750, numObservations: 2
action: 2
Next state: 1 0.347097 0.777218 0.620326 0.852778 0.653992 0.883157 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 23
Initial state: 0 0.870281 0.545835 0.652985 0.831641 0.589208 0.83553 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1180228 episodes
GETTING ACTION FROM:
action 3, numVisits=1180191, meanQ=6.316766, numObservations: 5
action -1, numVisits=23, meanQ=4.639362, numObservations: 1
action 2, numVisits=10, meanQ=3.880010, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 3
Next state: 1 0.870281 0.545835 0.652985 0.831641 0.589208 0.83553 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 24
Initial state: 0 0.579458 0.894603 0.4472 0.29956 0.588666 0.88054 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1208443 episodes
GETTING ACTION FROM:
action 1, numVisits=1208268, meanQ=6.225071, numObservations: 3
action 0, numVisits=65, meanQ=5.292629, numObservations: 1
action 3, numVisits=99, meanQ=5.018285, numObservations: 3
action 2, numVisits=9, meanQ=3.433333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.579458 0.894603 0.4472 0.29956 0.588666 0.88054 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 25
Initial state: 0 0.605196 0.8302 0.334985 0.554355 0.511436 0.813639 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1215153 episodes
GETTING ACTION FROM:
action 2, numVisits=1210425, meanQ=6.241371, numObservations: 3
action 1, numVisits=2958, meanQ=6.107908, numObservations: 5
action 3, numVisits=1766, meanQ=6.065565, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.605196 0.8302 0.334985 0.554355 0.511436 0.813639 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=117061, meanQ=8.859717, numObservations: 4
action 1, numVisits=79906, meanQ=8.854469, numObservations: 3
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1486271 episodes
GETTING ACTION FROM:
action 1, numVisits=859782, meanQ=6.719518, numObservations: 3
action 3, numVisits=823447, meanQ=6.719240, numObservations: 4
action 2, numVisits=10, meanQ=3.097020, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.605196 0.8302 0.334985 0.554355 0.511436 0.813639 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 26
Initial state: 0 0.244972 0.360503 0.555599 0.852988 0.67967 0.86052 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 812655 episodes
GETTING ACTION FROM:
action -1, numVisits=812601, meanQ=4.167353, numObservations: 1
action 0, numVisits=34, meanQ=2.904589, numObservations: 1
action 3, numVisits=14, meanQ=1.213571, numObservations: 4
action 2, numVisits=3, meanQ=-0.670000, numObservations: 2
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action: -1
Next state: 0 0.244972 0.360503 0.555599 0.852988 0.67967 0.86052 w: 1
Observation: 0 0.197124 0 0.632818 0 0.615163 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=812588, meanQ=6.230518, numObservations: 4
action 3, numVisits=6, meanQ=2.663333, numObservations: 3
action 1, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 1290850 episodes
GETTING ACTION FROM:
action 2, numVisits=2103438, meanQ=6.245476, numObservations: 4
action 3, numVisits=6, meanQ=2.663333, numObservations: 3
action 1, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.244972 0.360503 0.555599 0.852988 0.67967 0.86052 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 27
Initial state: 0 0.522219 0.80028 0.691967 0.888755 0.334545 0.0291819 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1185295 episodes
GETTING ACTION FROM:
action 3, numVisits=1185287, meanQ=6.233503, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.522219 0.80028 0.691967 0.888755 0.334545 0.0291819 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=69175, meanQ=8.938807, numObservations: 3
action 2, numVisits=59280, meanQ=8.936669, numObservations: 3
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1468915 episodes
GETTING ACTION FROM:
action 1, numVisits=1074261, meanQ=6.633324, numObservations: 4
action 2, numVisits=523106, meanQ=6.629989, numObservations: 5
action 3, numVisits=4, meanQ=1.747500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.522219 0.80028 0.691967 0.888755 0.334545 0.0291819 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 28
Initial state: 0 0.675396 0.834418 0.531948 0.137479 0.697434 0.893387 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1190777 episodes
GETTING ACTION FROM:
action 3, numVisits=1177876, meanQ=6.229195, numObservations: 5
action 1, numVisits=12892, meanQ=6.087903, numObservations: 4
action 2, numVisits=5, meanQ=0.998020, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.675396 0.834418 0.531948 0.137479 0.697434 0.893387 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 29
Initial state: 0 0.658167 0.851073 0.668413 0.897391 0.476004 0.682466 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1197152 episodes
GETTING ACTION FROM:
action 1, numVisits=1197025, meanQ=6.225351, numObservations: 4
action -1, numVisits=92, meanQ=5.448553, numObservations: 1
action 3, numVisits=31, meanQ=4.442258, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 1
action: 1
Next state: 1 0.658167 0.851073 0.668413 0.897391 0.476004 0.682466 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 30
Initial state: 0 0.314217 0.715589 0.536881 0.851054 0.660309 0.894943 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1197799 episodes
GETTING ACTION FROM:
action 3, numVisits=1197757, meanQ=6.228292, numObservations: 4
action -1, numVisits=32, meanQ=4.852094, numObservations: 1
action 1, numVisits=7, meanQ=1.998571, numObservations: 3
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.314217 0.715589 0.536881 0.851054 0.660309 0.894943 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 31
Initial state: 0 0.552935 0.849791 0.57892 0.834306 0.204015 0.274222 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1197670 episodes
GETTING ACTION FROM:
action 3, numVisits=1197662, meanQ=6.238714, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-5.505000, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 1
action: 3
Next state: 0 0.552935 0.849791 0.57892 0.834306 0.204015 0.274222 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=193630, meanQ=8.862600, numObservations: 4
action 2, numVisits=55, meanQ=7.849456, numObservations: 3
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1469317 episodes
GETTING ACTION FROM:
action 1, numVisits=1662503, meanQ=6.770369, numObservations: 4
action 2, numVisits=332, meanQ=6.356205, numObservations: 4
action 3, numVisits=168, meanQ=6.137153, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.552935 0.849791 0.57892 0.834306 0.204015 0.274222 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 32
Initial state: 0 0.553636 0.807657 0.509372 0.855619 0.647504 0.271433 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1206425 episodes
GETTING ACTION FROM:
action 2, numVisits=1206374, meanQ=6.231899, numObservations: 4
action 0, numVisits=46, meanQ=5.102682, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.553636 0.807657 0.509372 0.855619 0.647504 0.271433 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 33
Initial state: 0 0.674772 0.87426 0.539699 0.899871 0.318775 0.870375 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1211695 episodes
GETTING ACTION FROM:
action 2, numVisits=1211689, meanQ=6.227505, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.674772 0.87426 0.539699 0.899871 0.318775 0.870375 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 34
Initial state: 0 0.968244 0.674151 0.612901 0.883093 0.640042 0.817899 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1185155 episodes
GETTING ACTION FROM:
action 1, numVisits=1185121, meanQ=6.240536, numObservations: 5
action 2, numVisits=24, meanQ=4.692504, numObservations: 3
action 3, numVisits=6, meanQ=0.831667, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.968244 0.674151 0.612901 0.883093 0.640042 0.817899 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 35
Initial state: 0 0.949903 0.00509191 0.632444 0.891229 0.639866 0.831768 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1185845 episodes
GETTING ACTION FROM:
action 3, numVisits=1185762, meanQ=6.230886, numObservations: 5
action -1, numVisits=52, meanQ=5.142754, numObservations: 1
action 0, numVisits=28, meanQ=4.769131, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.949903 0.00509191 0.632444 0.891229 0.639866 0.831768 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=53250, meanQ=6.559305, numObservations: 4
action 3, numVisits=9, meanQ=3.554444, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1486874 episodes
GETTING ACTION FROM:
action 2, numVisits=1540124, meanQ=6.577334, numObservations: 4
action 3, numVisits=9, meanQ=3.554444, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.949903 0.00509191 0.632444 0.891229 0.639866 0.831768 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 36
Initial state: 0 0.781915 0.144782 0.616877 0.851834 0.629372 0.830329 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1199342 episodes
GETTING ACTION FROM:
action 1, numVisits=1199334, meanQ=6.234967, numObservations: 4
action 2, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.781915 0.144782 0.616877 0.851834 0.629372 0.830329 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 37
Initial state: 0 0.641282 0.539488 0.505954 0.841198 0.638002 0.875664 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1196553 episodes
GETTING ACTION FROM:
action 2, numVisits=1196546, meanQ=6.234819, numObservations: 4
action 1, numVisits=2, meanQ=-1.004950, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.641282 0.539488 0.505954 0.841198 0.638002 0.875664 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 38
Initial state: 0 0.598685 0.810198 0.628666 0.892844 0.591515 0.557313 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1204380 episodes
GETTING ACTION FROM:
action 2, numVisits=1204373, meanQ=6.313911, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.598685 0.810198 0.628666 0.892844 0.591515 0.557313 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 39
Initial state: 0 0.212232 0.174669 0.513616 0.884306 0.688477 0.814569 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1198932 episodes
GETTING ACTION FROM:
action 3, numVisits=1198885, meanQ=6.235311, numObservations: 4
action -1, numVisits=30, meanQ=4.822391, numObservations: 1
action 2, numVisits=9, meanQ=2.454444, numObservations: 3
action 1, numVisits=6, meanQ=2.333333, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.212232 0.174669 0.513616 0.884306 0.688477 0.814569 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 40
Initial state: 0 0.646591 0.815274 0.630238 0.840047 0.930359 0.495276 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 882730 episodes
GETTING ACTION FROM:
action 3, numVisits=218217, meanQ=6.222403, numObservations: 5
action -1, numVisits=664509, meanQ=4.169204, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.646591 0.815274 0.630238 0.840047 0.930359 0.495276 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 41
Initial state: 0 0.552177 0.865987 0.78487 0.448776 0.506807 0.898975 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1194263 episodes
GETTING ACTION FROM:
action 2, numVisits=1194185, meanQ=6.227060, numObservations: 5
action 0, numVisits=48, meanQ=5.150119, numObservations: 1
action 3, numVisits=27, meanQ=4.548148, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.552177 0.865987 0.78487 0.448776 0.506807 0.898975 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 42
Initial state: 0 0.538413 0.523075 0.588761 0.825774 0.668844 0.854603 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1209722 episodes
GETTING ACTION FROM:
action 1, numVisits=1209655, meanQ=6.229923, numObservations: 3
action 2, numVisits=36, meanQ=4.984169, numObservations: 4
action 0, numVisits=28, meanQ=4.772566, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.538413 0.523075 0.588761 0.825774 0.668844 0.854603 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 43
Initial state: 0 0.635484 0.841908 0.528173 0.857704 0.571345 0.823577 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1192709 episodes
GETTING ACTION FROM:
action 2, numVisits=1192698, meanQ=6.287725, numObservations: 5
action 3, numVisits=5, meanQ=1.196020, numObservations: 2
action 1, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.635484 0.841908 0.528173 0.857704 0.571345 0.823577 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 44
Initial state: 0 0.691656 0.843325 0.475492 0.920189 0.593268 0.817988 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1195514 episodes
GETTING ACTION FROM:
action 1, numVisits=1195425, meanQ=6.225734, numObservations: 4
action 3, numVisits=61, meanQ=5.117215, numObservations: 5
action 2, numVisits=24, meanQ=4.036671, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.691656 0.843325 0.475492 0.920189 0.593268 0.817988 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 45
Initial state: 0 0.542953 0.832653 0.416945 0.940666 0.653917 0.815295 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1197802 episodes
GETTING ACTION FROM:
action 3, numVisits=1197648, meanQ=6.183436, numObservations: 4
action -1, numVisits=78, meanQ=5.339906, numObservations: 1
action 1, numVisits=42, meanQ=4.845719, numObservations: 4
action 2, numVisits=22, meanQ=4.539550, numObservations: 4
action 0, numVisits=12, meanQ=3.882213, numObservations: 1
action: 3
Next state: 1 0.542953 0.832653 0.416945 0.940666 0.653917 0.815295 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 46
Initial state: 0 0.583359 0.844934 0.233871 0.00114992 0.551866 0.861323 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1201716 episodes
GETTING ACTION FROM:
action 2, numVisits=1201631, meanQ=6.245522, numObservations: 4
action 0, numVisits=42, meanQ=5.049513, numObservations: 1
action -1, numVisits=32, meanQ=4.916012, numObservations: 1
action 1, numVisits=5, meanQ=0.998020, numObservations: 3
action 3, numVisits=6, meanQ=0.831667, numObservations: 3
action: 2
Next state: 0 0.583359 0.844934 0.233871 0.00114992 0.551866 0.861323 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=194710, meanQ=8.858647, numObservations: 4
action 1, numVisits=25, meanQ=7.399208, numObservations: 3
action 2, numVisits=4, meanQ=4.222500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1463060 episodes
GETTING ACTION FROM:
action 1, numVisits=726654, meanQ=6.781932, numObservations: 5
action 3, numVisits=931122, meanQ=6.781373, numObservations: 4
action 2, numVisits=23, meanQ=5.073913, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.583359 0.844934 0.233871 0.00114992 0.551866 0.861323 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 47
Initial state: 0 0.183944 0.991356 0.675009 0.828324 0.534309 0.826755 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1186132 episodes
GETTING ACTION FROM:
action 2, numVisits=1185730, meanQ=6.217286, numObservations: 5
action 1, numVisits=397, meanQ=5.833507, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.183944 0.991356 0.675009 0.828324 0.534309 0.826755 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 48
Initial state: 0 0.606044 0.826144 0.621549 0.893854 0.471322 0.608604 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1208605 episodes
GETTING ACTION FROM:
action 2, numVisits=1208572, meanQ=6.233670, numObservations: 4
action 0, numVisits=26, meanQ=4.676738, numObservations: 1
action 1, numVisits=4, meanQ=1.747500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.606044 0.826144 0.621549 0.893854 0.471322 0.608604 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 49
Initial state: 0 0.652076 0.84131 0.523367 0.819596 0.916763 0.943515 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1179346 episodes
GETTING ACTION FROM:
action 3, numVisits=1172155, meanQ=6.221720, numObservations: 5
action 2, numVisits=7181, meanQ=6.132355, numObservations: 3
action 1, numVisits=6, meanQ=2.661683, numObservations: 4
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.652076 0.84131 0.523367 0.819596 0.916763 0.943515 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 50
Initial state: 0 0.615363 0.0446697 0.615894 0.882096 0.664055 0.872089 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1196368 episodes
GETTING ACTION FROM:
action 1, numVisits=1141339, meanQ=6.228600, numObservations: 4
action 3, numVisits=54971, meanQ=6.135888, numObservations: 3
action 0, numVisits=55, meanQ=5.224970, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.615363 0.0446697 0.615894 0.882096 0.664055 0.872089 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=134129, meanQ=8.876689, numObservations: 4
action 3, numVisits=23353, meanQ=8.849606, numObservations: 5
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1473580 episodes
GETTING ACTION FROM:
action 2, numVisits=1534646, meanQ=6.818602, numObservations: 4
action 3, numVisits=96397, meanQ=6.800226, numObservations: 5
action 1, numVisits=20, meanQ=5.099000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.615363 0.0446697 0.615894 0.882096 0.664055 0.872089 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 51
Initial state: 0 0.315999 0.592231 0.611651 0.863848 0.581295 0.808617 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1185557 episodes
GETTING ACTION FROM:
action 2, numVisits=1185466, meanQ=6.080559, numObservations: 3
action 0, numVisits=87, meanQ=5.281117, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.315999 0.592231 0.611651 0.863848 0.581295 0.808617 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 52
Initial state: 0 0.578898 0.855175 0.240008 0.397631 0.681507 0.886452 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 800870 episodes
GETTING ACTION FROM:
action 0, numVisits=800577, meanQ=4.477788, numObservations: 2
action -1, numVisits=281, meanQ=3.472341, numObservations: 1
action 3, numVisits=7, meanQ=0.568586, numObservations: 2
action 1, numVisits=3, meanQ=-0.670000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 0
Next state: 0 0.578898 0.855175 0.240008 0.397631 0.681507 0.886452 w: 1
Observation: 0 0 0.796325 0 0.333884 0 0.977189 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=108816, meanQ=8.847577, numObservations: 5
action 3, numVisits=52, meanQ=7.670771, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1271370 episodes
GETTING ACTION FROM:
action 1, numVisits=1378476, meanQ=6.392363, numObservations: 5
action 3, numVisits=1658, meanQ=6.205624, numObservations: 3
action -1, numVisits=56, meanQ=5.382377, numObservations: 1
action 0, numVisits=50, meanQ=5.333941, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.578898 0.855175 0.240008 0.397631 0.681507 0.886452 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 53
Initial state: 0 0.0605541 0.514713 0.595199 0.879776 0.599157 0.88114 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1197337 episodes
GETTING ACTION FROM:
action 1, numVisits=1197288, meanQ=6.236394, numObservations: 4
action 0, numVisits=17, meanQ=4.419650, numObservations: 1
action -1, numVisits=16, meanQ=4.341878, numObservations: 1
action 3, numVisits=11, meanQ=1.727273, numObservations: 3
action 2, numVisits=5, meanQ=1.196020, numObservations: 2
action: 1
Next state: 0 0.0605541 0.514713 0.595199 0.879776 0.599157 0.88114 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=164916, meanQ=8.874304, numObservations: 3
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1489132 episodes
GETTING ACTION FROM:
action 3, numVisits=1654040, meanQ=6.633347, numObservations: 3
action 2, numVisits=5, meanQ=3.198000, numObservations: 3
action 1, numVisits=5, meanQ=1.196020, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.0605541 0.514713 0.595199 0.879776 0.599157 0.88114 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 54
Initial state: 0 0.656635 0.862328 0.965595 0.930857 0.601779 0.883748 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1197048 episodes
GETTING ACTION FROM:
action 2, numVisits=1196950, meanQ=6.236752, numObservations: 5
action -1, numVisits=51, meanQ=5.190491, numObservations: 1
action 0, numVisits=22, meanQ=4.644003, numObservations: 1
action 3, numVisits=17, meanQ=3.116482, numObservations: 4
action 1, numVisits=8, meanQ=2.873750, numObservations: 3
action: 2
Next state: 2 0.656635 0.862328 0.965595 0.930857 0.601779 0.883748 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 55
Initial state: 0 0.716083 0.962721 0.502401 0.890762 0.613115 0.801443 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1200700 episodes
GETTING ACTION FROM:
action 1, numVisits=1191570, meanQ=6.319319, numObservations: 4
action 3, numVisits=9046, meanQ=6.100265, numObservations: 4
action 2, numVisits=57, meanQ=5.254739, numObservations: 3
action 0, numVisits=25, meanQ=4.827281, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.716083 0.962721 0.502401 0.890762 0.613115 0.801443 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 56
Initial state: 0 0.592102 0.851298 0.530866 0.895543 0.492678 0.541568 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1197891 episodes
GETTING ACTION FROM:
action 3, numVisits=1197846, meanQ=6.239936, numObservations: 4
action -1, numVisits=22, meanQ=4.617002, numObservations: 1
action 0, numVisits=20, meanQ=4.462993, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.592102 0.851298 0.530866 0.895543 0.492678 0.541568 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=164728, meanQ=8.868605, numObservations: 5
action 1, numVisits=6, meanQ=5.665017, numObservations: 1
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1463145 episodes
GETTING ACTION FROM:
action 2, numVisits=1627820, meanQ=6.575063, numObservations: 5
action 1, numVisits=43, meanQ=5.278840, numObservations: 4
action 3, numVisits=17, meanQ=4.287653, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.592102 0.851298 0.530866 0.895543 0.492678 0.541568 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 57
Initial state: 0 0.601659 0.830305 0.482635 0.797261 0.59391 0.814541 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1161995 episodes
GETTING ACTION FROM:
action 3, numVisits=1158059, meanQ=6.162612, numObservations: 5
action 1, numVisits=3914, meanQ=6.045980, numObservations: 4
action 0, numVisits=18, meanQ=4.229682, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 3
Next state: 1 0.601659 0.830305 0.482635 0.797261 0.59391 0.814541 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 58
Initial state: 0 0.591483 0.820062 0.514026 0.625085 0.589107 0.880373 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1204525 episodes
GETTING ACTION FROM:
action 1, numVisits=1204358, meanQ=6.240716, numObservations: 4
action 2, numVisits=161, meanQ=5.591157, numObservations: 4
action 3, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.591483 0.820062 0.514026 0.625085 0.589107 0.880373 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 59
Initial state: 0 0.0514406 0.703797 0.558931 0.868277 0.622263 0.88487 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1211217 episodes
GETTING ACTION FROM:
action 3, numVisits=1211157, meanQ=6.235109, numObservations: 3
action -1, numVisits=53, meanQ=5.186792, numObservations: 1
action 2, numVisits=3, meanQ=-0.670000, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.0514406 0.703797 0.558931 0.868277 0.622263 0.88487 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 60
Initial state: 0 0.548301 0.834688 0.31456 0.784482 0.682493 0.808651 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1188922 episodes
GETTING ACTION FROM:
action 1, numVisits=1188866, meanQ=6.315142, numObservations: 5
action -1, numVisits=29, meanQ=4.877414, numObservations: 1
action 3, numVisits=23, meanQ=2.473483, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.548301 0.834688 0.31456 0.784482 0.682493 0.808651 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 61
Initial state: 0 0.515809 0.834217 0.691064 0.857535 0.955671 0.276824 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1196067 episodes
GETTING ACTION FROM:
action 3, numVisits=1196052, meanQ=6.230825, numObservations: 4
action 2, numVisits=9, meanQ=3.554444, numObservations: 4
action 1, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.515809 0.834217 0.691064 0.857535 0.955671 0.276824 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 62
Initial state: 0 0.817163 0.620724 0.571517 0.834775 0.508144 0.837473 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1198366 episodes
GETTING ACTION FROM:
action 2, numVisits=1198281, meanQ=6.230470, numObservations: 4
action -1, numVisits=79, meanQ=5.393490, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-5.505000, numObservations: 1
action: 2
Next state: 1 0.817163 0.620724 0.571517 0.834775 0.508144 0.837473 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 63
Initial state: 0 0.621613 0.858371 0.576681 0.818719 0.47807 0.999452 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1199670 episodes
GETTING ACTION FROM:
action 1, numVisits=1199623, meanQ=6.228905, numObservations: 4
action 0, numVisits=27, meanQ=4.791896, numObservations: 1
action 3, numVisits=9, meanQ=3.663344, numObservations: 2
action 2, numVisits=9, meanQ=3.532222, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.621613 0.858371 0.576681 0.818719 0.47807 0.999452 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 64
Initial state: 0 0.987132 0.550114 0.532837 0.866096 0.665719 0.881886 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1206787 episodes
GETTING ACTION FROM:
action 2, numVisits=1206776, meanQ=6.234150, numObservations: 4
action 3, numVisits=6, meanQ=2.333333, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.987132 0.550114 0.532837 0.866096 0.665719 0.881886 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 65
Initial state: 0 0.598792 0.809197 0.581075 0.888338 0.206935 0.99492 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1207442 episodes
GETTING ACTION FROM:
action 2, numVisits=1207435, meanQ=6.234697, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.598792 0.809197 0.581075 0.888338 0.206935 0.99492 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 66
Initial state: 0 0.625412 0.831548 0.533414 0.444685 0.58805 0.819625 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1204530 episodes
GETTING ACTION FROM:
action 2, numVisits=1204470, meanQ=6.239181, numObservations: 4
action 0, numVisits=36, meanQ=4.979847, numObservations: 1
action 3, numVisits=18, meanQ=4.055000, numObservations: 4
action 1, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.625412 0.831548 0.533414 0.444685 0.58805 0.819625 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 67
Initial state: 0 0.637344 0.890897 0.900196 0.152061 0.585749 0.880118 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1195396 episodes
GETTING ACTION FROM:
action 3, numVisits=1195344, meanQ=6.240785, numObservations: 4
action -1, numVisits=28, meanQ=4.798097, numObservations: 1
action 1, numVisits=19, meanQ=4.257895, numObservations: 3
action 2, numVisits=3, meanQ=-0.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.637344 0.890897 0.900196 0.152061 0.585749 0.880118 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 68
Initial state: 0 0.524391 0.814478 0.00968623 0.109619 0.537676 0.888595 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1186191 episodes
GETTING ACTION FROM:
action 1, numVisits=1186167, meanQ=6.229227, numObservations: 5
action 0, numVisits=20, meanQ=4.490944, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.524391 0.814478 0.00968623 0.109619 0.537676 0.888595 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 69
Initial state: 0 0.395192 0.943052 0.680448 0.802934 0.548166 0.877426 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1212912 episodes
GETTING ACTION FROM:
action 3, numVisits=1212836, meanQ=6.230659, numObservations: 3
action 0, numVisits=58, meanQ=5.244710, numObservations: 1
action 1, numVisits=12, meanQ=3.249167, numObservations: 3
action 2, numVisits=4, meanQ=1.747500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.395192 0.943052 0.680448 0.802934 0.548166 0.877426 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 70
Initial state: 0 0.562553 0.863931 0.226476 0.749072 0.519549 0.863059 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1195577 episodes
GETTING ACTION FROM:
action 3, numVisits=1195512, meanQ=6.229674, numObservations: 4
action 0, numVisits=39, meanQ=5.018546, numObservations: 1
action 1, numVisits=19, meanQ=3.736842, numObservations: 3
action 2, numVisits=5, meanQ=1.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.562553 0.863931 0.226476 0.749072 0.519549 0.863059 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 71
Initial state: 0 0.639923 0.898738 0.120412 0.608349 0.644846 0.824168 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1209377 episodes
GETTING ACTION FROM:
action 2, numVisits=1209255, meanQ=6.239371, numObservations: 4
action -1, numVisits=53, meanQ=5.200998, numObservations: 1
action 0, numVisits=45, meanQ=5.093901, numObservations: 1
action 1, numVisits=23, meanQ=3.868696, numObservations: 4
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.639923 0.898738 0.120412 0.608349 0.644846 0.824168 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=195632, meanQ=8.854303, numObservations: 4
action 3, numVisits=46, meanQ=7.695222, numObservations: 3
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1470367 episodes
GETTING ACTION FROM:
action 1, numVisits=1665504, meanQ=6.797817, numObservations: 4
action 3, numVisits=502, meanQ=6.436733, numObservations: 5
action 2, numVisits=40, meanQ=5.440500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.639923 0.898738 0.120412 0.608349 0.644846 0.824168 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 72
Initial state: 0 0.557189 0.829715 0.581835 0.893524 0.289504 0.353042 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1199356 episodes
GETTING ACTION FROM:
action 1, numVisits=1199320, meanQ=6.229191, numObservations: 4
action 2, numVisits=31, meanQ=4.696784, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.557189 0.829715 0.581835 0.893524 0.289504 0.353042 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 73
Initial state: 0 0.58665 0.868981 0.448251 0.440659 0.518185 0.85104 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1204097 episodes
GETTING ACTION FROM:
action 2, numVisits=1204085, meanQ=6.239412, numObservations: 3
action 1, numVisits=6, meanQ=2.331683, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.58665 0.868981 0.448251 0.440659 0.518185 0.85104 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=110743, meanQ=8.855410, numObservations: 3
action 1, numVisits=84037, meanQ=8.851785, numObservations: 5
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1479036 episodes
GETTING ACTION FROM:
action 3, numVisits=1250560, meanQ=6.834024, numObservations: 3
action 1, numVisits=423254, meanQ=6.829136, numObservations: 5
action 2, numVisits=3, meanQ=-0.670000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.58665 0.868981 0.448251 0.440659 0.518185 0.85104 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 74
Initial state: 0 0.633611 0.829065 0.619844 0.842183 0.961408 0.846736 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1194606 episodes
GETTING ACTION FROM:
action 1, numVisits=1194599, meanQ=6.228996, numObservations: 4
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.633611 0.829065 0.619844 0.842183 0.961408 0.846736 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=54499, meanQ=6.512544, numObservations: 4
action 2, numVisits=5, meanQ=2.980000, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1475877 episodes
GETTING ACTION FROM:
action 3, numVisits=1530376, meanQ=6.621363, numObservations: 4
action 2, numVisits=5, meanQ=2.980000, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.633611 0.829065 0.619844 0.842183 0.961408 0.846736 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 75
Initial state: 0 0.602861 0.872874 0.740803 0.527445 0.600245 0.865423 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1208326 episodes
GETTING ACTION FROM:
action 3, numVisits=1208263, meanQ=6.246132, numObservations: 3
action 0, numVisits=52, meanQ=5.199748, numObservations: 1
action -1, numVisits=9, meanQ=3.479650, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.602861 0.872874 0.740803 0.527445 0.600245 0.865423 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 76
Initial state: 0 0.541127 0.865931 0.598172 0.847956 0.108755 0.713973 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1197520 episodes
GETTING ACTION FROM:
action 3, numVisits=1197434, meanQ=6.238555, numObservations: 4
action 0, numVisits=68, meanQ=5.333613, numObservations: 1
action 1, numVisits=14, meanQ=4.210729, numObservations: 3
action 2, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.541127 0.865931 0.598172 0.847956 0.108755 0.713973 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=134008, meanQ=8.871471, numObservations: 4
action 1, numVisits=30954, meanQ=8.850346, numObservations: 3
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1473976 episodes
GETTING ACTION FROM:
action 2, numVisits=1459804, meanQ=6.632957, numObservations: 4
action 1, numVisits=179107, meanQ=6.621157, numObservations: 3
action 3, numVisits=28, meanQ=5.035364, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.541127 0.865931 0.598172 0.847956 0.108755 0.713973 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 77
Initial state: 0 0.673745 0.866774 0.531937 0.860526 0.901644 0.592731 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1197208 episodes
GETTING ACTION FROM:
action 1, numVisits=1197147, meanQ=6.237739, numObservations: 4
action 2, numVisits=51, meanQ=4.967647, numObservations: 4
action 3, numVisits=6, meanQ=2.333333, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.673745 0.866774 0.531937 0.860526 0.901644 0.592731 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=53273, meanQ=6.503631, numObservations: 4
action 1, numVisits=5, meanQ=1.196020, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1477990 episodes
GETTING ACTION FROM:
action 2, numVisits=1531261, meanQ=6.489468, numObservations: 4
action 1, numVisits=5, meanQ=1.196020, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.673745 0.866774 0.531937 0.860526 0.901644 0.592731 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 78
Initial state: 0 0.0918358 0.328094 0.567831 0.819852 0.694361 0.854167 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1200811 episodes
GETTING ACTION FROM:
action 2, numVisits=1200740, meanQ=6.224501, numObservations: 4
action 1, numVisits=63, meanQ=5.133495, numObservations: 5
action 3, numVisits=4, meanQ=-0.505000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.0918358 0.328094 0.567831 0.819852 0.694361 0.854167 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 79
Initial state: 0 0.672973 0.818528 0.544014 0.251542 0.697911 0.818625 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1201673 episodes
GETTING ACTION FROM:
action 1, numVisits=1201620, meanQ=6.207338, numObservations: 4
action 0, numVisits=45, meanQ=5.071252, numObservations: 1
action 3, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 1
Next state: 1 0.672973 0.818528 0.544014 0.251542 0.697911 0.818625 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 80
Initial state: 0 0.654575 0.808617 0.610487 0.231483 0.66548 0.890259 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1196818 episodes
GETTING ACTION FROM:
action 1, numVisits=1196716, meanQ=6.229819, numObservations: 4
action -1, numVisits=64, meanQ=5.283754, numObservations: 1
action 0, numVisits=28, meanQ=4.782483, numObservations: 1
action 3, numVisits=9, meanQ=2.553333, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.654575 0.808617 0.610487 0.231483 0.66548 0.890259 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 81
Initial state: 0 0.676245 0.79246 0.58733 0.816097 0.664668 0.874828 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1200534 episodes
GETTING ACTION FROM:
action 1, numVisits=1200487, meanQ=6.229602, numObservations: 4
action 0, numVisits=42, meanQ=5.080964, numObservations: 1
action 2, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.676245 0.79246 0.58733 0.816097 0.664668 0.874828 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 82
Initial state: 0 0.680862 0.868076 0.684024 0.811174 0.784197 0.198262 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1194306 episodes
GETTING ACTION FROM:
action 3, numVisits=1194297, meanQ=6.229091, numObservations: 4
action 2, numVisits=3, meanQ=-0.670000, numObservations: 3
action 1, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.680862 0.868076 0.684024 0.811174 0.784197 0.198262 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=6618, meanQ=6.146617, numObservations: 4
action 1, numVisits=3, meanQ=2.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1483449 episodes
GETTING ACTION FROM:
action 2, numVisits=1490066, meanQ=6.571265, numObservations: 4
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.680862 0.868076 0.684024 0.811174 0.784197 0.198262 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 83
Initial state: 0 0.572798 0.84965 0.883174 0.776333 0.617412 0.873378 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1187396 episodes
GETTING ACTION FROM:
action 1, numVisits=1187355, meanQ=6.242706, numObservations: 5
action -1, numVisits=33, meanQ=4.904878, numObservations: 1
action 2, numVisits=4, meanQ=-0.505000, numObservations: 3
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 1
action: 1
Next state: 1 0.572798 0.84965 0.883174 0.776333 0.617412 0.873378 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 84
Initial state: 0 0.605781 0.881096 0.338741 0.423025 0.504473 0.877095 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1201051 episodes
GETTING ACTION FROM:
action 3, numVisits=1200987, meanQ=6.179057, numObservations: 4
action 0, numVisits=58, meanQ=5.193689, numObservations: 1
action 1, numVisits=2, meanQ=-0.509950, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 3
Next state: 1 0.605781 0.881096 0.338741 0.423025 0.504473 0.877095 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 85
Initial state: 0 0.629777 0.839242 0.580657 0.957435 0.670535 0.860047 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1179687 episodes
GETTING ACTION FROM:
action 3, numVisits=1179672, meanQ=6.318086, numObservations: 5
action 1, numVisits=7, meanQ=1.998571, numObservations: 3
action 2, numVisits=4, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.629777 0.839242 0.580657 0.957435 0.670535 0.860047 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 86
Initial state: 0 0.699141 0.85942 0.662794 0.833876 0.621898 0.377016 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1179809 episodes
GETTING ACTION FROM:
action 3, numVisits=1161302, meanQ=6.231912, numObservations: 5
action 2, numVisits=18469, meanQ=6.151250, numObservations: 5
action -1, numVisits=20, meanQ=4.449328, numObservations: 1
action 0, numVisits=17, meanQ=4.376664, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.699141 0.85942 0.662794 0.833876 0.621898 0.377016 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 87
Initial state: 0 0.673535 0.890683 0.529834 0.861728 0.121161 0.632319 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1209631 episodes
GETTING ACTION FROM:
action 2, numVisits=1209525, meanQ=6.239145, numObservations: 4
action 0, numVisits=64, meanQ=5.295022, numObservations: 2
action -1, numVisits=35, meanQ=4.946693, numObservations: 1
action 1, numVisits=5, meanQ=1.396000, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 2
Next state: 1 0.673535 0.890683 0.529834 0.861728 0.121161 0.632319 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 88
Initial state: 0 0.265572 0.0155206 0.622662 0.882154 0.641323 0.804221 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1200987 episodes
GETTING ACTION FROM:
action 2, numVisits=1200974, meanQ=6.232666, numObservations: 4
action 1, numVisits=8, meanQ=1.747500, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.265572 0.0155206 0.622662 0.882154 0.641323 0.804221 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 89
Initial state: 0 0.693707 0.833719 0.663497 0.877969 0.170392 0.51192 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1190297 episodes
GETTING ACTION FROM:
action 1, numVisits=1190284, meanQ=6.308854, numObservations: 5
action 2, numVisits=8, meanQ=2.996262, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.693707 0.833719 0.663497 0.877969 0.170392 0.51192 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 90
Initial state: 0 0.624772 0.826437 0.579403 0.834087 0.35474 0.729623 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1196393 episodes
GETTING ACTION FROM:
action 1, numVisits=1196293, meanQ=6.246682, numObservations: 4
action 0, numVisits=48, meanQ=5.158568, numObservations: 1
action -1, numVisits=26, meanQ=4.669901, numObservations: 1
action 2, numVisits=20, meanQ=4.449510, numObservations: 3
action 3, numVisits=6, meanQ=2.663333, numObservations: 4
action: 1
Next state: 1 0.624772 0.826437 0.579403 0.834087 0.35474 0.729623 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 91
Initial state: 0 0.562589 0.867317 0.11049 0.924413 0.582366 0.849204 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1188693 episodes
GETTING ACTION FROM:
action 1, numVisits=1188662, meanQ=6.251590, numObservations: 5
action 3, numVisits=17, meanQ=4.346471, numObservations: 4
action 2, numVisits=9, meanQ=3.554444, numObservations: 3
action 0, numVisits=3, meanQ=1.630000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.562589 0.867317 0.11049 0.924413 0.582366 0.849204 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 92
Initial state: 0 0.600701 0.839077 0.354339 0.0695325 0.522212 0.899029 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1210827 episodes
GETTING ACTION FROM:
action 1, numVisits=1210752, meanQ=6.235237, numObservations: 3
action -1, numVisits=36, meanQ=4.991920, numObservations: 1
action 2, numVisits=33, meanQ=4.846076, numObservations: 4
action 3, numVisits=4, meanQ=-0.505000, numObservations: 3
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.600701 0.839077 0.354339 0.0695325 0.522212 0.899029 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 93
Initial state: 0 0.682153 0.842652 0.0209762 0.916252 0.512886 0.882323 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1203601 episodes
GETTING ACTION FROM:
action 3, numVisits=1203590, meanQ=6.231973, numObservations: 4
action 2, numVisits=6, meanQ=0.831667, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.682153 0.842652 0.0209762 0.916252 0.512886 0.882323 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 94
Initial state: 0 0.551789 0.810521 0.310459 0.512271 0.64333 0.869589 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1208816 episodes
GETTING ACTION FROM:
action 3, numVisits=1208660, meanQ=6.185938, numObservations: 3
action 0, numVisits=85, meanQ=5.367803, numObservations: 1
action -1, numVisits=34, meanQ=4.891467, numObservations: 1
action 2, numVisits=30, meanQ=4.627000, numObservations: 4
action 1, numVisits=7, meanQ=1.998571, numObservations: 3
action: 3
Next state: 1 0.551789 0.810521 0.310459 0.512271 0.64333 0.869589 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 95
Initial state: 0 0.635281 0.283845 0.637683 0.80849 0.571948 0.88784 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1185868 episodes
GETTING ACTION FROM:
action 3, numVisits=1181194, meanQ=6.237319, numObservations: 5
action 2, numVisits=4633, meanQ=6.132654, numObservations: 4
action -1, numVisits=35, meanQ=4.977479, numObservations: 1
action 1, numVisits=4, meanQ=1.747500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.635281 0.283845 0.637683 0.80849 0.571948 0.88784 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 96
Initial state: 0 0.611479 0.840703 0.858611 0.134839 0.600827 0.887148 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1196290 episodes
GETTING ACTION FROM:
action 3, numVisits=1196257, meanQ=6.228037, numObservations: 4
action 0, numVisits=21, meanQ=4.582737, numObservations: 1
action 1, numVisits=9, meanQ=3.442244, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.611479 0.840703 0.858611 0.134839 0.600827 0.887148 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 97
Initial state: 0 0.706237 0.101416 0.693315 0.871532 0.501737 0.84222 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 833258 episodes
GETTING ACTION FROM:
action 0, numVisits=833251, meanQ=6.430513, numObservations: 3
action 1, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.706237 0.101416 0.693315 0.871532 0.501737 0.84222 w: 1
Observation: 0 0 0.0928228 0 0.806056 0 0.787336 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=292139, meanQ=8.449864, numObservations: 4
action 2, numVisits=38, meanQ=4.991850, numObservations: 4
action 1, numVisits=20, meanQ=4.494505, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1284504 episodes
GETTING ACTION FROM:
action 3, numVisits=1576643, meanQ=6.736617, numObservations: 4
action 2, numVisits=38, meanQ=4.991850, numObservations: 4
action 1, numVisits=20, meanQ=4.494505, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.706237 0.101416 0.693315 0.871532 0.501737 0.84222 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 98
Initial state: 0 0.563478 0.884063 0.663067 0.821877 0.182363 0.991746 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1198614 episodes
GETTING ACTION FROM:
action 2, numVisits=1198585, meanQ=6.226027, numObservations: 4
action 3, numVisits=23, meanQ=4.260004, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.563478 0.884063 0.663067 0.821877 0.182363 0.991746 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 99
Initial state: 0 0.643653 0.87858 0.54435 0.20982 0.561528 0.822017 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1190991 episodes
GETTING ACTION FROM:
action 1, numVisits=1190909, meanQ=6.323278, numObservations: 5
action -1, numVisits=41, meanQ=5.132101, numObservations: 1
action 2, numVisits=34, meanQ=4.876179, numObservations: 4
action 3, numVisits=5, meanQ=1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.643653 0.87858 0.54435 0.20982 0.561528 0.822017 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 100
Initial state: 0 0.408958 0.680973 0.588248 0.862853 0.658548 0.807622 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1188635 episodes
GETTING ACTION FROM:
action 3, numVisits=1188598, meanQ=6.226307, numObservations: 4
action -1, numVisits=24, meanQ=4.688517, numObservations: 1
action 1, numVisits=9, meanQ=3.554444, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.408958 0.680973 0.588248 0.862853 0.658548 0.807622 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=53397, meanQ=6.571313, numObservations: 3
action 1, numVisits=8, meanQ=4.247500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1505371 episodes
GETTING ACTION FROM:
action 2, numVisits=1558764, meanQ=6.647973, numObservations: 3
action 1, numVisits=12, meanQ=4.165000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.408958 0.680973 0.588248 0.862853 0.658548 0.807622 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 101
Initial state: 0 0.62753 0.817511 0.554804 0.847852 0.448639 0.739472 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1210218 episodes
GETTING ACTION FROM:
action 2, numVisits=1192645, meanQ=6.219317, numObservations: 3
action 1, numVisits=17475, meanQ=6.159978, numObservations: 4
action -1, numVisits=48, meanQ=5.129633, numObservations: 1
action 0, numVisits=39, meanQ=5.017920, numObservations: 1
action 3, numVisits=11, meanQ=2.814564, numObservations: 4
action: 2
Next state: 1 0.62753 0.817511 0.554804 0.847852 0.448639 0.739472 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 102
Initial state: 0 0.0594676 0.257408 0.674202 0.848977 0.693778 0.861255 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1189935 episodes
GETTING ACTION FROM:
action 2, numVisits=1189921, meanQ=6.310066, numObservations: 5
action 1, numVisits=7, meanQ=3.284300, numObservations: 3
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.0594676 0.257408 0.674202 0.848977 0.693778 0.861255 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=44045, meanQ=8.213852, numObservations: 3
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1444074 episodes
GETTING ACTION FROM:
action 3, numVisits=1243811, meanQ=6.571651, numObservations: 4
action 2, numVisits=244309, meanQ=6.518743, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.0594676 0.257408 0.674202 0.848977 0.693778 0.861255 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 103
Initial state: 0 0.612032 0.850214 0.471922 0.673126 0.539024 0.801331 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1212810 episodes
GETTING ACTION FROM:
action 2, numVisits=1211164, meanQ=6.184300, numObservations: 3
action 1, numVisits=1573, meanQ=5.962423, numObservations: 3
action 0, numVisits=55, meanQ=5.163884, numObservations: 1
action 3, numVisits=16, meanQ=4.123750, numObservations: 3
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.612032 0.850214 0.471922 0.673126 0.539024 0.801331 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=104619, meanQ=8.860419, numObservations: 4
action 3, numVisits=91709, meanQ=8.858316, numObservations: 5
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1466931 episodes
GETTING ACTION FROM:
action 1, numVisits=1219417, meanQ=6.718558, numObservations: 4
action 3, numVisits=443839, meanQ=6.714028, numObservations: 5
action 2, numVisits=4, meanQ=1.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.612032 0.850214 0.471922 0.673126 0.539024 0.801331 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 104
Initial state: 0 0.550377 0.884391 0.694889 0.847448 0.550027 0.852573 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1186221 episodes
GETTING ACTION FROM:
action 3, numVisits=1186119, meanQ=6.241594, numObservations: 5
action 2, numVisits=89, meanQ=4.729101, numObservations: 5
action 1, numVisits=9, meanQ=2.321122, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.550377 0.884391 0.694889 0.847448 0.550027 0.852573 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 105
Initial state: 0 0.623852 0.806175 0.512197 0.826188 0.885632 0.485572 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1198020 episodes
GETTING ACTION FROM:
action 3, numVisits=1197916, meanQ=6.222495, numObservations: 4
action -1, numVisits=48, meanQ=5.146532, numObservations: 1
action 1, numVisits=45, meanQ=4.528671, numObservations: 3
action 2, numVisits=9, meanQ=2.553333, numObservations: 3
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 3
Next state: 2 0.623852 0.806175 0.512197 0.826188 0.885632 0.485572 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 106
Initial state: 0 0.638475 0.83312 0.5671 0.541996 0.55546 0.871278 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1192333 episodes
GETTING ACTION FROM:
action 2, numVisits=1192270, meanQ=6.233045, numObservations: 5
action 1, numVisits=46, meanQ=5.131526, numObservations: 5
action 3, numVisits=13, meanQ=2.844631, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.638475 0.83312 0.5671 0.541996 0.55546 0.871278 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 107
Initial state: 0 0.523052 0.871634 0.693362 0.886443 0.15447 0.0748441 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1195280 episodes
GETTING ACTION FROM:
action 1, numVisits=1195182, meanQ=6.175102, numObservations: 4
action 0, numVisits=79, meanQ=5.332484, numObservations: 1
action 2, numVisits=15, meanQ=3.864007, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.523052 0.871634 0.693362 0.886443 0.15447 0.0748441 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 108
Initial state: 0 0.341103 0.339742 0.617888 0.815339 0.691092 0.818667 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1198324 episodes
GETTING ACTION FROM:
action 1, numVisits=1198318, meanQ=6.234468, numObservations: 4
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.341103 0.339742 0.617888 0.815339 0.691092 0.818667 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=89127, meanQ=8.871276, numObservations: 4
action 2, numVisits=75898, meanQ=8.869356, numObservations: 4
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1471585 episodes
GETTING ACTION FROM:
action 2, numVisits=947491, meanQ=6.581914, numObservations: 4
action 3, numVisits=689118, meanQ=6.580633, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 2
Next state: 0 0.341103 0.339742 0.617888 0.815339 0.691092 0.818667 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=10037, meanQ=8.276766, numObservations: 4
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1467138 episodes
GETTING ACTION FROM:
action 3, numVisits=1334046, meanQ=6.119989, numObservations: 5
action 2, numVisits=143125, meanQ=6.082201, numObservations: 5
action 1, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 3
Next state: 1 0.341103 0.339742 0.617888 0.815339 0.691092 0.818667 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.8309
Run # 109
Initial state: 0 0.547288 0.894812 0.686288 0.884945 0.991178 0.278866 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1194763 episodes
GETTING ACTION FROM:
action 3, numVisits=1194726, meanQ=6.188204, numObservations: 4
action 2, numVisits=29, meanQ=4.551038, numObservations: 4
action 1, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.547288 0.894812 0.686288 0.884945 0.991178 0.278866 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 110
Initial state: 0 0.999312 0.661199 0.578104 0.874435 0.56403 0.838259 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1197023 episodes
GETTING ACTION FROM:
action 2, numVisits=1196984, meanQ=6.230349, numObservations: 4
action 3, numVisits=20, meanQ=4.548510, numObservations: 4
action 0, numVisits=15, meanQ=4.261999, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.999312 0.661199 0.578104 0.874435 0.56403 0.838259 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 111
Initial state: 0 0.574485 0.879702 0.652393 0.632865 0.640927 0.80605 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1197061 episodes
GETTING ACTION FROM:
action 1, numVisits=1197032, meanQ=6.233183, numObservations: 4
action 3, numVisits=11, meanQ=3.725455, numObservations: 3
action 2, numVisits=14, meanQ=3.284300, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.574485 0.879702 0.652393 0.632865 0.640927 0.80605 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 112
Initial state: 0 0.401062 0.871894 0.57387 0.809447 0.55344 0.865703 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1183900 episodes
GETTING ACTION FROM:
action 1, numVisits=1183893, meanQ=6.242014, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.401062 0.871894 0.57387 0.809447 0.55344 0.865703 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 113
Initial state: 0 0.518541 0.848041 0.155686 0.524658 0.546606 0.810399 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1203773 episodes
GETTING ACTION FROM:
action 2, numVisits=1203737, meanQ=6.235101, numObservations: 4
action 1, numVisits=28, meanQ=4.590357, numObservations: 3
action 3, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.518541 0.848041 0.155686 0.524658 0.546606 0.810399 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=148443, meanQ=8.859519, numObservations: 3
action 1, numVisits=46505, meanQ=8.846236, numObservations: 4
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1488658 episodes
GETTING ACTION FROM:
action 3, numVisits=1293471, meanQ=6.887120, numObservations: 3
action 1, numVisits=390109, meanQ=6.881487, numObservations: 4
action 2, numVisits=27, meanQ=5.288889, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.518541 0.848041 0.155686 0.524658 0.546606 0.810399 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 114
Initial state: 0 0.64762 0.84266 0.530253 0.816818 0.751201 0.557184 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1208887 episodes
GETTING ACTION FROM:
action 3, numVisits=1208828, meanQ=6.242776, numObservations: 3
action 2, numVisits=44, meanQ=4.377505, numObservations: 4
action 1, numVisits=11, meanQ=3.634555, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 2 0.64762 0.84266 0.530253 0.816818 0.751201 0.557184 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 115
Initial state: 0 0.642627 0.381637 0.514845 0.887384 0.684991 0.846128 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1160828 episodes
GETTING ACTION FROM:
action 1, numVisits=1160738, meanQ=6.141779, numObservations: 5
action 3, numVisits=60, meanQ=5.072170, numObservations: 4
action -1, numVisits=24, meanQ=4.577920, numObservations: 1
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.642627 0.381637 0.514845 0.887384 0.684991 0.846128 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=62395, meanQ=8.692381, numObservations: 4
action 3, numVisits=6, meanQ=5.665017, numObservations: 2
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1469407 episodes
GETTING ACTION FROM:
action 2, numVisits=1531792, meanQ=6.581007, numObservations: 4
action 1, numVisits=10, meanQ=4.099000, numObservations: 3
action 3, numVisits=7, meanQ=3.284300, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.642627 0.381637 0.514845 0.887384 0.684991 0.846128 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 116
Initial state: 0 0.104231 0.162285 0.675999 0.899087 0.545285 0.842436 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1203230 episodes
GETTING ACTION FROM:
action 1, numVisits=1203190, meanQ=6.174037, numObservations: 4
action -1, numVisits=34, meanQ=4.808523, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 1
Next state: 0 0.104231 0.162285 0.675999 0.899087 0.545285 0.842436 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=64278, meanQ=8.689241, numObservations: 4
action 3, numVisits=29, meanQ=7.278969, numObservations: 3
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1473532 episodes
GETTING ACTION FROM:
action 3, numVisits=398752, meanQ=6.677901, numObservations: 4
action 2, numVisits=1139002, meanQ=6.369738, numObservations: 4
action 1, numVisits=84, meanQ=5.547146, numObservations: 4
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.104231 0.162285 0.675999 0.899087 0.545285 0.842436 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 117
Initial state: 0 0.598781 0.213572 0.558792 0.850878 0.635765 0.825361 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1211498 episodes
GETTING ACTION FROM:
action 2, numVisits=1211433, meanQ=6.227643, numObservations: 4
action -1, numVisits=31, meanQ=4.889427, numObservations: 1
action 0, numVisits=26, meanQ=4.717564, numObservations: 1
action 3, numVisits=6, meanQ=2.150017, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 2
Next state: 1 0.598781 0.213572 0.558792 0.850878 0.635765 0.825361 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 118
Initial state: 0 0.664727 0.879146 0.638984 0.847059 0.117111 0.0549658 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1186082 episodes
GETTING ACTION FROM:
action 2, numVisits=1185999, meanQ=6.227330, numObservations: 5
action -1, numVisits=58, meanQ=5.243236, numObservations: 1
action 0, numVisits=21, meanQ=4.555186, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 2
Next state: 1 0.664727 0.879146 0.638984 0.847059 0.117111 0.0549658 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 119
Initial state: 0 0.532461 0.689485 0.675626 0.802286 0.522308 0.886606 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1185488 episodes
GETTING ACTION FROM:
action 3, numVisits=1185478, meanQ=6.222856, numObservations: 5
action 2, numVisits=5, meanQ=1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.532461 0.689485 0.675626 0.802286 0.522308 0.886606 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 120
Initial state: 0 0.505152 0.84241 0.790124 0.665999 0.535364 0.822891 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1195591 episodes
GETTING ACTION FROM:
action 3, numVisits=1195514, meanQ=6.239651, numObservations: 4
action 0, numVisits=42, meanQ=5.068138, numObservations: 1
action 2, numVisits=32, meanQ=4.405312, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.505152 0.84241 0.790124 0.665999 0.535364 0.822891 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 121
Initial state: 0 0.573595 0.865736 0.770152 0.543493 0.693166 0.841971 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1208816 episodes
GETTING ACTION FROM:
action 2, numVisits=1208749, meanQ=6.224861, numObservations: 4
action 0, numVisits=24, meanQ=4.680170, numObservations: 1
action -1, numVisits=22, meanQ=4.563505, numObservations: 1
action 1, numVisits=16, meanQ=3.930638, numObservations: 3
action 3, numVisits=5, meanQ=0.998020, numObservations: 3
action: 2
Next state: 2 0.573595 0.865736 0.770152 0.543493 0.693166 0.841971 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 122
Initial state: 0 0.852336 0.971141 0.667435 0.845907 0.551636 0.850919 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1201146 episodes
GETTING ACTION FROM:
action 1, numVisits=1201124, meanQ=6.193053, numObservations: 4
action 2, numVisits=9, meanQ=3.553344, numObservations: 3
action 3, numVisits=9, meanQ=2.333333, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.852336 0.971141 0.667435 0.845907 0.551636 0.850919 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 123
Initial state: 0 0.511189 0.837578 0.968324 0.867029 0.643863 0.827099 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1197944 episodes
GETTING ACTION FROM:
action 3, numVisits=1197910, meanQ=6.229909, numObservations: 4
action -1, numVisits=27, meanQ=4.754675, numObservations: 1
action 1, numVisits=4, meanQ=1.747500, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.511189 0.837578 0.968324 0.867029 0.643863 0.827099 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 124
Initial state: 0 0.6471 0.89858 0.658519 0.835998 0.229365 0.722248 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1207925 episodes
GETTING ACTION FROM:
action 3, numVisits=1206813, meanQ=6.236624, numObservations: 3
action 2, numVisits=1080, meanQ=5.946177, numObservations: 5
action 1, numVisits=28, meanQ=4.748582, numObservations: 4
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.6471 0.89858 0.658519 0.835998 0.229365 0.722248 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=132449, meanQ=8.862282, numObservations: 4
action 1, numVisits=62931, meanQ=8.854892, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1473445 episodes
GETTING ACTION FROM:
action 2, numVisits=1418456, meanQ=6.880929, numObservations: 4
action 1, numVisits=250369, meanQ=6.872100, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.6471 0.89858 0.658519 0.835998 0.229365 0.722248 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 125
Initial state: 0 0.629374 0.843646 0.503211 0.84749 0.0452042 0.904587 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1198266 episodes
GETTING ACTION FROM:
action 1, numVisits=1198169, meanQ=6.220520, numObservations: 4
action 0, numVisits=88, meanQ=5.424192, numObservations: 1
action 3, numVisits=6, meanQ=0.831667, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.629374 0.843646 0.503211 0.84749 0.0452042 0.904587 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 126
Initial state: 0 0.536302 0.843457 0.185679 0.900494 0.627402 0.816213 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1214416 episodes
GETTING ACTION FROM:
action 3, numVisits=1214377, meanQ=6.236626, numObservations: 3
action 0, numVisits=14, meanQ=4.097862, numObservations: 1
action 2, numVisits=21, meanQ=3.808105, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 3
Next state: 1 0.536302 0.843457 0.185679 0.900494 0.627402 0.816213 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 127
Initial state: 0 0.661573 0.84443 0.607867 0.882423 0.606448 0.562422 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1199212 episodes
GETTING ACTION FROM:
action 1, numVisits=1199204, meanQ=6.183867, numObservations: 4
action 2, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.661573 0.84443 0.607867 0.882423 0.606448 0.562422 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 128
Initial state: 0 0.601536 0.834925 0.508936 0.874556 0.0798408 0.44175 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1211392 episodes
GETTING ACTION FROM:
action 1, numVisits=1211347, meanQ=6.227235, numObservations: 3
action -1, numVisits=33, meanQ=4.907776, numObservations: 1
action 2, numVisits=8, meanQ=1.498762, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.601536 0.834925 0.508936 0.874556 0.0798408 0.44175 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 129
Initial state: 0 0.569783 0.808457 0.65866 0.867584 0.224685 0.0193519 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1189798 episodes
GETTING ACTION FROM:
action 3, numVisits=1189764, meanQ=6.232095, numObservations: 5
action 1, numVisits=17, meanQ=2.592947, numObservations: 3
action 2, numVisits=13, meanQ=2.153077, numObservations: 3
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.569783 0.808457 0.65866 0.867584 0.224685 0.0193519 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=105760, meanQ=8.871265, numObservations: 4
action 1, numVisits=58184, meanQ=8.863629, numObservations: 3
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1478225 episodes
GETTING ACTION FROM:
action 2, numVisits=1157380, meanQ=6.728046, numObservations: 4
action 1, numVisits=484787, meanQ=6.724181, numObservations: 3
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.569783 0.808457 0.65866 0.867584 0.224685 0.0193519 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 130
Initial state: 0 0.517562 0.806845 0.563055 0.816572 0.747879 0.403153 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1191362 episodes
GETTING ACTION FROM:
action 1, numVisits=1191209, meanQ=6.320426, numObservations: 5
action -1, numVisits=90, meanQ=5.535824, numObservations: 1
action 2, numVisits=56, meanQ=5.009464, numObservations: 3
action 3, numVisits=4, meanQ=1.747500, numObservations: 3
action 0, numVisits=3, meanQ=1.630000, numObservations: 2
action: 1
Next state: 1 0.517562 0.806845 0.563055 0.816572 0.747879 0.403153 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 131
Initial state: 0 0.899636 0.361468 0.674976 0.832622 0.567569 0.881577 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1194898 episodes
GETTING ACTION FROM:
action 3, numVisits=1194807, meanQ=6.237479, numObservations: 4
action 0, numVisits=59, meanQ=5.249340, numObservations: 1
action 2, numVisits=26, meanQ=4.765385, numObservations: 3
action 1, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.899636 0.361468 0.674976 0.832622 0.567569 0.881577 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 132
Initial state: 0 0.54423 0.880353 0.696452 0.815272 0.013189 0.474186 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1187835 episodes
GETTING ACTION FROM:
action 1, numVisits=1187791, meanQ=6.235994, numObservations: 5
action -1, numVisits=32, meanQ=4.909800, numObservations: 1
action 3, numVisits=8, meanQ=2.872513, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.54423 0.880353 0.696452 0.815272 0.013189 0.474186 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 133
Initial state: 0 0.697341 0.886964 0.075358 0.93201 0.56529 0.859483 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1183522 episodes
GETTING ACTION FROM:
action 3, numVisits=1175832, meanQ=6.243452, numObservations: 5
action 1, numVisits=6026, meanQ=6.147064, numObservations: 4
action 2, numVisits=1660, meanQ=6.062841, numObservations: 4
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.697341 0.886964 0.075358 0.93201 0.56529 0.859483 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=53202, meanQ=6.553469, numObservations: 5
action 2, numVisits=12, meanQ=3.983333, numObservations: 4
action 3, numVisits=4, meanQ=-0.505000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1456321 episodes
GETTING ACTION FROM:
action 1, numVisits=1509521, meanQ=6.394865, numObservations: 5
action 2, numVisits=12, meanQ=3.983333, numObservations: 4
action 3, numVisits=4, meanQ=-0.505000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 1
Next state: 1 0.697341 0.886964 0.075358 0.93201 0.56529 0.859483 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 134
Initial state: 0 0.643809 0.861435 0.96163 0.664818 0.520147 0.831634 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1190772 episodes
GETTING ACTION FROM:
action 1, numVisits=1190648, meanQ=6.242737, numObservations: 5
action -1, numVisits=70, meanQ=5.353911, numObservations: 1
action 0, numVisits=47, meanQ=5.145674, numObservations: 1
action 3, numVisits=2, meanQ=-0.010000, numObservations: 2
action 2, numVisits=5, meanQ=-0.802000, numObservations: 4
action: 1
Next state: 1 0.643809 0.861435 0.96163 0.664818 0.520147 0.831634 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 135
Initial state: 0 0.664504 0.28841 0.630273 0.886372 0.627558 0.810148 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1192988 episodes
GETTING ACTION FROM:
action 2, numVisits=1192797, meanQ=6.232367, numObservations: 5
action -1, numVisits=133, meanQ=5.584242, numObservations: 1
action 0, numVisits=55, meanQ=5.228848, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.664504 0.28841 0.630273 0.886372 0.627558 0.810148 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 136
Initial state: 0 0.577466 0.860434 0.969004 0.423292 0.639215 0.845831 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1182953 episodes
GETTING ACTION FROM:
action 1, numVisits=1182919, meanQ=6.228721, numObservations: 5
action 2, numVisits=27, meanQ=3.073707, numObservations: 4
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.577466 0.860434 0.969004 0.423292 0.639215 0.845831 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 137
Initial state: 0 0.521121 0.839056 0.609429 0.590379 0.597238 0.841756 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1190620 episodes
GETTING ACTION FROM:
action 3, numVisits=1189254, meanQ=6.230627, numObservations: 4
action 2, numVisits=1360, meanQ=6.031002, numObservations: 3
action 1, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.521121 0.839056 0.609429 0.590379 0.597238 0.841756 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=53212, meanQ=6.534872, numObservations: 5
action 3, numVisits=2, meanQ=-0.010000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1455673 episodes
GETTING ACTION FROM:
action 1, numVisits=1508883, meanQ=6.287668, numObservations: 5
action 3, numVisits=2, meanQ=-0.010000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 1
Next state: 1 0.521121 0.839056 0.609429 0.590379 0.597238 0.841756 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 138
Initial state: 0 0.695175 0.898065 0.645158 0.873033 0.56105 0.382631 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1198377 episodes
GETTING ACTION FROM:
action 2, numVisits=1198250, meanQ=6.227475, numObservations: 4
action 0, numVisits=104, meanQ=5.495543, numObservations: 1
action 1, numVisits=19, meanQ=3.782642, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.695175 0.898065 0.645158 0.873033 0.56105 0.382631 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 139
Initial state: 0 0.654317 0.894577 0.650214 0.861126 0.0653185 0.153265 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1196744 episodes
GETTING ACTION FROM:
action 3, numVisits=1196732, meanQ=6.236544, numObservations: 4
action 1, numVisits=7, meanQ=3.285714, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.654317 0.894577 0.650214 0.861126 0.0653185 0.153265 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=110387, meanQ=8.881763, numObservations: 3
action 2, numVisits=53973, meanQ=8.877475, numObservations: 5
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1481019 episodes
GETTING ACTION FROM:
action 1, numVisits=1057303, meanQ=6.806193, numObservations: 3
action 2, numVisits=587454, meanQ=6.803655, numObservations: 5
action 3, numVisits=623, meanQ=6.505307, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.654317 0.894577 0.650214 0.861126 0.0653185 0.153265 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 140
Initial state: 0 0.520416 0.88118 0.534725 0.816025 0.162836 0.374897 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1204138 episodes
GETTING ACTION FROM:
action 2, numVisits=1204098, meanQ=6.230895, numObservations: 4
action 0, numVisits=25, meanQ=4.645909, numObservations: 1
action 3, numVisits=8, meanQ=2.873750, numObservations: 2
action 1, numVisits=5, meanQ=1.396000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.520416 0.88118 0.534725 0.816025 0.162836 0.374897 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 141
Initial state: 0 0.948563 0.983737 0.504301 0.888027 0.570195 0.851507 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1205024 episodes
GETTING ACTION FROM:
action 2, numVisits=1205005, meanQ=6.240718, numObservations: 4
action 3, numVisits=7, meanQ=3.284300, numObservations: 3
action 0, numVisits=6, meanQ=2.783350, numObservations: 2
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.948563 0.983737 0.504301 0.888027 0.570195 0.851507 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 142
Initial state: 0 0.345063 0.0350198 0.568988 0.880385 0.567558 0.833972 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1204961 episodes
GETTING ACTION FROM:
action 2, numVisits=1204918, meanQ=6.230048, numObservations: 4
action 1, numVisits=38, meanQ=4.285797, numObservations: 5
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.345063 0.0350198 0.568988 0.880385 0.567558 0.833972 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 143
Initial state: 0 0.693684 0.885697 0.531521 0.811487 0.169979 0.156218 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1190793 episodes
GETTING ACTION FROM:
action 1, numVisits=1190691, meanQ=6.237795, numObservations: 5
action -1, numVisits=43, meanQ=5.090082, numObservations: 1
action 2, numVisits=32, meanQ=4.766259, numObservations: 3
action 3, numVisits=25, meanQ=4.638808, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.693684 0.885697 0.531521 0.811487 0.169979 0.156218 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 144
Initial state: 0 0.514249 0.859616 0.217779 0.69104 0.573377 0.893856 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1211280 episodes
GETTING ACTION FROM:
action 2, numVisits=1211141, meanQ=6.221913, numObservations: 3
action 3, numVisits=109, meanQ=5.452752, numObservations: 4
action 1, numVisits=26, meanQ=4.376923, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.514249 0.859616 0.217779 0.69104 0.573377 0.893856 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=130248, meanQ=8.870808, numObservations: 4
action 3, numVisits=65702, meanQ=8.861477, numObservations: 5
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1464224 episodes
GETTING ACTION FROM:
action 1, numVisits=1235337, meanQ=6.973198, numObservations: 4
action 3, numVisits=424825, meanQ=6.968323, numObservations: 5
action 2, numVisits=13, meanQ=4.536923, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.514249 0.859616 0.217779 0.69104 0.573377 0.893856 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 145
Initial state: 0 0.611988 0.805696 0.543647 0.813852 0.946817 0.410957 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1215210 episodes
GETTING ACTION FROM:
action 2, numVisits=1213081, meanQ=6.250251, numObservations: 3
action 3, numVisits=2081, meanQ=6.087067, numObservations: 4
action -1, numVisits=34, meanQ=4.932030, numObservations: 1
action 1, numVisits=12, meanQ=3.999175, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.611988 0.805696 0.543647 0.813852 0.946817 0.410957 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 146
Initial state: 0 0.607311 0.698967 0.56684 0.854869 0.615455 0.89912 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1211408 episodes
GETTING ACTION FROM:
action 1, numVisits=1211317, meanQ=6.248486, numObservations: 3
action -1, numVisits=77, meanQ=5.398653, numObservations: 1
action 3, numVisits=8, meanQ=2.996262, numObservations: 4
action 2, numVisits=4, meanQ=1.747500, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.607311 0.698967 0.56684 0.854869 0.615455 0.89912 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 147
Initial state: 0 0.941518 0.469288 0.595194 0.815632 0.653737 0.875812 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 991298 episodes
GETTING ACTION FROM:
action 0, numVisits=483361, meanQ=6.309989, numObservations: 2
action 1, numVisits=507884, meanQ=6.229108, numObservations: 5
action -1, numVisits=38, meanQ=5.054366, numObservations: 1
action 2, numVisits=13, meanQ=3.766931, numObservations: 5
action 3, numVisits=2, meanQ=-1.004950, numObservations: 1
action: 0
Next state: 0 0.941518 0.469288 0.595194 0.815632 0.653737 0.875812 w: 1
Observation: 0 0 0.569083 0 0.833769 0 0.807906 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=120459, meanQ=8.764503, numObservations: 4
action 3, numVisits=4842, meanQ=8.685263, numObservations: 4
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1296875 episodes
GETTING ACTION FROM:
action 2, numVisits=1309101, meanQ=6.387721, numObservations: 4
action 3, numVisits=113027, meanQ=6.371859, numObservations: 4
action -1, numVisits=40, meanQ=5.201567, numObservations: 1
action 1, numVisits=9, meanQ=2.553333, numObservations: 4
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 2
Next state: 1 0.941518 0.469288 0.595194 0.815632 0.653737 0.875812 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 148
Initial state: 0 0.569439 0.890282 0.25134 0.140545 0.599776 0.872464 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1201824 episodes
GETTING ACTION FROM:
action 1, numVisits=1201772, meanQ=6.238153, numObservations: 4
action 0, numVisits=45, meanQ=5.103104, numObservations: 1
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 1
action: 1
Next state: 1 0.569439 0.890282 0.25134 0.140545 0.599776 0.872464 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 149
Initial state: 0 0.557624 0.872939 0.739381 0.237133 0.595388 0.805208 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1192410 episodes
GETTING ACTION FROM:
action 2, numVisits=1192221, meanQ=6.231117, numObservations: 5
action -1, numVisits=59, meanQ=5.234049, numObservations: 1
action 3, numVisits=92, meanQ=4.846310, numObservations: 5
action 0, numVisits=23, meanQ=4.666834, numObservations: 1
action 1, numVisits=15, meanQ=3.732007, numObservations: 4
action: 2
Next state: 0 0.557624 0.872939 0.739381 0.237133 0.595388 0.805208 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=6614, meanQ=6.110381, numObservations: 3
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1371139 episodes
GETTING ACTION FROM:
action 2, numVisits=1377675, meanQ=6.311613, numObservations: 4
action 3, numVisits=75, meanQ=5.413200, numObservations: 4
action 1, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 2
Next state: 2 0.557624 0.872939 0.739381 0.237133 0.595388 0.805208 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11.89
Run # 150
Initial state: 0 0.0196689 0.994459 0.637766 0.843883 0.554899 0.813851 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1203296 episodes
GETTING ACTION FROM:
action 2, numVisits=1203239, meanQ=6.237190, numObservations: 4
action 1, numVisits=52, meanQ=4.513658, numObservations: 4
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.0196689 0.994459 0.637766 0.843883 0.554899 0.813851 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 151
Initial state: 0 0.643891 0.0924362 0.573791 0.852103 0.680077 0.862646 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1185954 episodes
GETTING ACTION FROM:
action 3, numVisits=1185832, meanQ=6.231036, numObservations: 5
action -1, numVisits=65, meanQ=5.301981, numObservations: 1
action 0, numVisits=36, meanQ=4.965056, numObservations: 1
action 2, numVisits=18, meanQ=3.444444, numObservations: 2
action 1, numVisits=3, meanQ=-0.670000, numObservations: 1
action: 3
Next state: 1 0.643891 0.0924362 0.573791 0.852103 0.680077 0.862646 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 152
Initial state: 0 0.74398 0.583142 0.508843 0.816265 0.624726 0.834734 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1184008 episodes
GETTING ACTION FROM:
action 3, numVisits=1183916, meanQ=6.309427, numObservations: 5
action 2, numVisits=47, meanQ=4.906177, numObservations: 4
action -1, numVisits=23, meanQ=4.751130, numObservations: 1
action 1, numVisits=20, meanQ=3.999505, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.74398 0.583142 0.508843 0.816265 0.624726 0.834734 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 153
Initial state: 0 0.45632 0.509192 0.59294 0.878026 0.68347 0.832632 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1198563 episodes
GETTING ACTION FROM:
action 3, numVisits=1198514, meanQ=6.238314, numObservations: 4
action 0, numVisits=24, meanQ=4.646731, numObservations: 1
action 2, numVisits=22, meanQ=4.494100, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.45632 0.509192 0.59294 0.878026 0.68347 0.832632 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 154
Initial state: 0 0.604012 0.886264 0.210751 0.977968 0.539815 0.845285 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1193389 episodes
GETTING ACTION FROM:
action 3, numVisits=1193364, meanQ=6.239331, numObservations: 4
action 2, numVisits=10, meanQ=3.790020, numObservations: 3
action 1, numVisits=11, meanQ=3.724555, numObservations: 4
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.604012 0.886264 0.210751 0.977968 0.539815 0.845285 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 155
Initial state: 0 0.640569 0.893075 0.296427 0.764575 0.515008 0.875475 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1184552 episodes
GETTING ACTION FROM:
action 1, numVisits=1184534, meanQ=6.226104, numObservations: 5
action 3, numVisits=9, meanQ=3.552244, numObservations: 3
action 2, numVisits=5, meanQ=1.000000, numObservations: 3
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.640569 0.893075 0.296427 0.764575 0.515008 0.875475 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 156
Initial state: 0 0.850945 0.01916 0.652491 0.802692 0.614017 0.838518 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 844195 episodes
GETTING ACTION FROM:
action 0, numVisits=843731, meanQ=6.278735, numObservations: 2
action -1, numVisits=451, meanQ=3.712619, numObservations: 1
action 3, numVisits=11, meanQ=0.726382, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.850945 0.01916 0.652491 0.802692 0.614017 0.838518 w: 1
Observation: 0 0 0 0 0.767105 0 0.866386 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=608041, meanQ=8.245666, numObservations: 4
action 2, numVisits=2764, meanQ=5.513516, numObservations: 4
action 1, numVisits=7, meanQ=3.140043, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1292941 episodes
GETTING ACTION FROM:
action 3, numVisits=1900982, meanQ=6.853696, numObservations: 4
action 2, numVisits=2764, meanQ=5.513516, numObservations: 4
action 1, numVisits=7, meanQ=3.140043, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.850945 0.01916 0.652491 0.802692 0.614017 0.838518 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 157
Initial state: 0 0.521851 0.108096 0.695987 0.83565 0.579188 0.846224 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1186695 episodes
GETTING ACTION FROM:
action 1, numVisits=1186650, meanQ=6.226561, numObservations: 5
action -1, numVisits=31, meanQ=4.845189, numObservations: 1
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action 3, numVisits=8, meanQ=1.747500, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.521851 0.108096 0.695987 0.83565 0.579188 0.846224 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 158
Initial state: 0 0.675874 0.816429 0.481282 0.664503 0.651978 0.837272 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1164728 episodes
GETTING ACTION FROM:
action 1, numVisits=1164682, meanQ=6.131051, numObservations: 5
action -1, numVisits=38, meanQ=4.903600, numObservations: 1
action 3, numVisits=4, meanQ=1.747500, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.675874 0.816429 0.481282 0.664503 0.651978 0.837272 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 159
Initial state: 0 0.542853 0.844771 0.621858 0.59536 0.622221 0.881153 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1202312 episodes
GETTING ACTION FROM:
action 1, numVisits=1202244, meanQ=6.227824, numObservations: 4
action 0, numVisits=52, meanQ=5.163884, numObservations: 1
action 2, numVisits=12, meanQ=3.998350, numObservations: 3
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 1
Next state: 0 0.542853 0.844771 0.621858 0.59536 0.622221 0.881153 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=54072, meanQ=6.512485, numObservations: 4
action 1, numVisits=60, meanQ=5.593340, numObservations: 4
action 3, numVisits=5, meanQ=1.396000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1478812 episodes
GETTING ACTION FROM:
action 2, numVisits=1532880, meanQ=6.426504, numObservations: 4
action 1, numVisits=62, meanQ=5.380652, numObservations: 4
action 3, numVisits=5, meanQ=1.396000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 2
Next state: 2 0.542853 0.844771 0.621858 0.59536 0.622221 0.881153 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11.89
Run # 160
Initial state: 0 0.52775 0.839628 0.171501 0.0803648 0.614239 0.823669 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1204323 episodes
GETTING ACTION FROM:
action 2, numVisits=1204291, meanQ=6.227012, numObservations: 4
action -1, numVisits=19, meanQ=4.403040, numObservations: 1
action 1, numVisits=6, meanQ=0.650000, numObservations: 2
action 3, numVisits=5, meanQ=-0.802000, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 2
Next state: 0 0.52775 0.839628 0.171501 0.0803648 0.614239 0.823669 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=165600, meanQ=8.873113, numObservations: 4
action 3, numVisits=5, meanQ=5.396000, numObservations: 2
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1482532 episodes
GETTING ACTION FROM:
action 1, numVisits=1648094, meanQ=6.266661, numObservations: 4
action 2, numVisits=20, meanQ=4.549005, numObservations: 4
action 3, numVisits=22, meanQ=4.544545, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 1
Next state: 1 0.52775 0.839628 0.171501 0.0803648 0.614239 0.823669 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 161
Initial state: 0 0.660282 0.802315 0.569544 0.275374 0.665652 0.853738 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1188546 episodes
GETTING ACTION FROM:
action 3, numVisits=1188459, meanQ=6.321422, numObservations: 5
action -1, numVisits=43, meanQ=5.160445, numObservations: 1
action 0, numVisits=23, meanQ=4.752699, numObservations: 1
action 2, numVisits=9, meanQ=3.663344, numObservations: 2
action 1, numVisits=12, meanQ=3.323333, numObservations: 4
action: 3
Next state: 1 0.660282 0.802315 0.569544 0.275374 0.665652 0.853738 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 162
Initial state: 0 0.551478 0.843651 0.456332 0.713061 0.571095 0.872161 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1194764 episodes
GETTING ACTION FROM:
action 3, numVisits=1194673, meanQ=6.232028, numObservations: 4
action 0, numVisits=63, meanQ=5.288384, numObservations: 1
action -1, numVisits=23, meanQ=4.621081, numObservations: 1
action 2, numVisits=4, meanQ=-1.000000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.551478 0.843651 0.456332 0.713061 0.571095 0.872161 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 163
Initial state: 0 0.134928 0.600814 0.513534 0.833962 0.559163 0.83867 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1202639 episodes
GETTING ACTION FROM:
action 1, numVisits=1202602, meanQ=6.232298, numObservations: 4
action 3, numVisits=32, meanQ=4.584069, numObservations: 3
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.134928 0.600814 0.513534 0.833962 0.559163 0.83867 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=117287, meanQ=8.865569, numObservations: 3
action 2, numVisits=77439, meanQ=8.862151, numObservations: 4
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1477076 episodes
GETTING ACTION FROM:
action 2, numVisits=984514, meanQ=6.778126, numObservations: 4
action 3, numVisits=687268, meanQ=6.776575, numObservations: 3
action 1, numVisits=21, meanQ=4.709524, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.134928 0.600814 0.513534 0.833962 0.559163 0.83867 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 164
Initial state: 0 0.104212 0.428005 0.550234 0.806506 0.614935 0.801816 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1205241 episodes
GETTING ACTION FROM:
action 2, numVisits=1205111, meanQ=6.233571, numObservations: 4
action -1, numVisits=59, meanQ=5.263424, numObservations: 1
action 0, numVisits=57, meanQ=5.232447, numObservations: 1
action 1, numVisits=9, meanQ=2.332233, numObservations: 3
action 3, numVisits=5, meanQ=1.000000, numObservations: 2
action: 2
Next state: 1 0.104212 0.428005 0.550234 0.806506 0.614935 0.801816 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 165
Initial state: 0 0.64823 0.885538 0.282565 0.416408 0.561009 0.833049 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1192460 episodes
GETTING ACTION FROM:
action 2, numVisits=1192413, meanQ=6.231942, numObservations: 5
action -1, numVisits=18, meanQ=4.430764, numObservations: 1
action 1, numVisits=18, meanQ=4.054450, numObservations: 3
action 3, numVisits=9, meanQ=3.554444, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.64823 0.885538 0.282565 0.416408 0.561009 0.833049 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=30061, meanQ=8.672934, numObservations: 3
action 1, numVisits=6, meanQ=5.666667, numObservations: 2
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1477423 episodes
GETTING ACTION FROM:
action 1, numVisits=1041833, meanQ=6.579210, numObservations: 4
action 3, numVisits=465654, meanQ=6.510389, numObservations: 3
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.64823 0.885538 0.282565 0.416408 0.561009 0.833049 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 166
Initial state: 0 0.532531 0.896329 0.152349 0.484605 0.564222 0.859588 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1207233 episodes
GETTING ACTION FROM:
action 1, numVisits=1207176, meanQ=6.234065, numObservations: 3
action -1, numVisits=43, meanQ=5.082382, numObservations: 1
action 2, numVisits=9, meanQ=2.553333, numObservations: 2
action 3, numVisits=3, meanQ=-0.670000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.532531 0.896329 0.152349 0.484605 0.564222 0.859588 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=53989, meanQ=6.612913, numObservations: 4
action 3, numVisits=3, meanQ=2.333333, numObservations: 2
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1468804 episodes
GETTING ACTION FROM:
action 2, numVisits=1522777, meanQ=6.617593, numObservations: 4
action 1, numVisits=14, meanQ=4.140014, numObservations: 4
action 3, numVisits=6, meanQ=2.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.532531 0.896329 0.152349 0.484605 0.564222 0.859588 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=18683, meanQ=8.883969, numObservations: 5
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1470143 episodes
GETTING ACTION FROM:
action 3, numVisits=1488812, meanQ=6.691577, numObservations: 5
action 2, numVisits=15, meanQ=4.399333, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.532531 0.896329 0.152349 0.484605 0.564222 0.859588 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.8309
Run # 167
Initial state: 0 0.691436 0.836828 0.788027 0.439361 0.622873 0.846042 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1204758 episodes
GETTING ACTION FROM:
action 3, numVisits=1204746, meanQ=6.241625, numObservations: 4
action 1, numVisits=6, meanQ=2.331683, numObservations: 2
action 2, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.691436 0.836828 0.788027 0.439361 0.622873 0.846042 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 168
Initial state: 0 0.504838 0.860389 0.530821 0.811761 0.577491 0.618902 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1205699 episodes
GETTING ACTION FROM:
action 1, numVisits=1205608, meanQ=6.230488, numObservations: 3
action 0, numVisits=81, meanQ=5.400465, numObservations: 1
action 2, numVisits=6, meanQ=0.831667, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.504838 0.860389 0.530821 0.811761 0.577491 0.618902 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 169
Initial state: 0 0.622285 0.844416 0.619746 0.858719 0.953236 0.528594 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1196794 episodes
GETTING ACTION FROM:
action 2, numVisits=1196739, meanQ=6.234900, numObservations: 4
action 0, numVisits=35, meanQ=4.970173, numObservations: 1
action 1, numVisits=12, meanQ=3.999175, numObservations: 3
action 3, numVisits=6, meanQ=2.495033, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.622285 0.844416 0.619746 0.858719 0.953236 0.528594 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 170
Initial state: 0 0.536608 0.880767 0.693431 0.84556 0.844491 0.987051 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1210394 episodes
GETTING ACTION FROM:
action 1, numVisits=1210350, meanQ=6.241555, numObservations: 3
action -1, numVisits=40, meanQ=5.058758, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.536608 0.880767 0.693431 0.84556 0.844491 0.987051 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 171
Initial state: 0 0.222272 0.0922416 0.577623 0.822356 0.685712 0.887945 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1202375 episodes
GETTING ACTION FROM:
action 2, numVisits=1202305, meanQ=6.232613, numObservations: 4
action -1, numVisits=60, meanQ=5.247803, numObservations: 1
action 3, numVisits=6, meanQ=0.831667, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 2
Next state: 1 0.222272 0.0922416 0.577623 0.822356 0.685712 0.887945 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 172
Initial state: 0 0.761341 0.652291 0.584851 0.861141 0.508456 0.805397 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 805866 episodes
GETTING ACTION FROM:
action -1, numVisits=805848, meanQ=4.180078, numObservations: 1
action 1, numVisits=6, meanQ=0.831667, numObservations: 3
action 3, numVisits=9, meanQ=0.110011, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.761341 0.652291 0.584851 0.861141 0.508456 0.805397 w: 1
Observation: 0 0.803626 0 0.664596 0 0.57625 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=805782, meanQ=6.236485, numObservations: 5
action -1, numVisits=36, meanQ=4.989995, numObservations: 1
action 2, numVisits=18, meanQ=4.433894, numObservations: 3
action 1, numVisits=9, meanQ=3.554444, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 1294928 episodes
GETTING ACTION FROM:
action 3, numVisits=2100710, meanQ=6.359994, numObservations: 5
action -1, numVisits=36, meanQ=4.989995, numObservations: 1
action 2, numVisits=18, meanQ=4.433894, numObservations: 3
action 1, numVisits=9, meanQ=3.554444, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.761341 0.652291 0.584851 0.861141 0.508456 0.805397 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 173
Initial state: 0 0.787437 0.429808 0.607018 0.870948 0.534436 0.803368 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1199192 episodes
GETTING ACTION FROM:
action 2, numVisits=1199165, meanQ=6.180130, numObservations: 4
action 1, numVisits=21, meanQ=4.185248, numObservations: 4
action 3, numVisits=2, meanQ=-1.004950, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.787437 0.429808 0.607018 0.870948 0.534436 0.803368 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 174
Initial state: 0 0.468278 0.335822 0.605945 0.87706 0.542331 0.827877 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1198247 episodes
GETTING ACTION FROM:
action 1, numVisits=1187502, meanQ=6.249429, numObservations: 4
action 3, numVisits=10702, meanQ=6.182449, numObservations: 4
action 0, numVisits=23, meanQ=4.609401, numObservations: 1
action -1, numVisits=19, meanQ=4.493919, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.468278 0.335822 0.605945 0.87706 0.542331 0.827877 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=100176, meanQ=8.879471, numObservations: 3
action 3, numVisits=63461, meanQ=8.872387, numObservations: 4
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1474685 episodes
GETTING ACTION FROM:
action 3, numVisits=979647, meanQ=6.787423, numObservations: 4
action 2, numVisits=658674, meanQ=6.786013, numObservations: 3
action 1, numVisits=2, meanQ=-0.509950, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.468278 0.335822 0.605945 0.87706 0.542331 0.827877 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 175
Initial state: 0 0.537299 0.888901 0.634298 0.879274 0.0969813 0.546329 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1185052 episodes
GETTING ACTION FROM:
action 3, numVisits=1170233, meanQ=6.224794, numObservations: 5
action 2, numVisits=14813, meanQ=6.136945, numObservations: 3
action 1, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.537299 0.888901 0.634298 0.879274 0.0969813 0.546329 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=91346, meanQ=8.869816, numObservations: 3
action 2, numVisits=70104, meanQ=8.866311, numObservations: 4
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1486814 episodes
GETTING ACTION FROM:
action 2, numVisits=897840, meanQ=6.763068, numObservations: 4
action 1, numVisits=750418, meanQ=6.761841, numObservations: 3
action 3, numVisits=7, meanQ=3.412857, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.537299 0.888901 0.634298 0.879274 0.0969813 0.546329 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 176
Initial state: 0 0.623988 0.808595 0.523516 0.822221 0.403417 0.232644 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1209717 episodes
GETTING ACTION FROM:
action 1, numVisits=1209634, meanQ=6.232093, numObservations: 3
action -1, numVisits=47, meanQ=5.116718, numObservations: 1
action 0, numVisits=31, meanQ=4.869182, numObservations: 1
action 3, numVisits=4, meanQ=1.747500, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.623988 0.808595 0.523516 0.822221 0.403417 0.232644 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 177
Initial state: 0 0.68456 0.801926 0.873034 0.597297 0.561998 0.891303 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1195920 episodes
GETTING ACTION FROM:
action 3, numVisits=1165545, meanQ=6.245327, numObservations: 4
action 2, numVisits=30356, meanQ=6.204881, numObservations: 5
action 1, numVisits=15, meanQ=3.666007, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.68456 0.801926 0.873034 0.597297 0.561998 0.891303 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 178
Initial state: 0 0.644394 0.832476 0.618069 0.838156 0.925803 0.497023 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1189421 episodes
GETTING ACTION FROM:
action 3, numVisits=1189348, meanQ=6.229072, numObservations: 5
action -1, numVisits=47, meanQ=5.106327, numObservations: 1
action 2, numVisits=17, meanQ=4.282353, numObservations: 3
action 1, numVisits=7, meanQ=1.998571, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.644394 0.832476 0.618069 0.838156 0.925803 0.497023 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 179
Initial state: 0 0.679468 0.836463 0.582963 0.807233 0.151866 0.274589 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1187616 episodes
GETTING ACTION FROM:
action 3, numVisits=1187508, meanQ=6.315736, numObservations: 5
action 0, numVisits=37, meanQ=5.080101, numObservations: 1
action 2, numVisits=50, meanQ=5.041400, numObservations: 4
action 1, numVisits=19, meanQ=4.257895, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.679468 0.836463 0.582963 0.807233 0.151866 0.274589 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=74659, meanQ=8.939220, numObservations: 3
action 2, numVisits=54100, meanQ=8.934995, numObservations: 3
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1485945 episodes
GETTING ACTION FROM:
action 1, numVisits=975733, meanQ=6.777026, numObservations: 3
action 2, numVisits=638970, meanQ=6.774962, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 1
action: 1
Next state: 1 0.679468 0.836463 0.582963 0.807233 0.151866 0.274589 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 180
Initial state: 0 0.675354 0.825959 0.664378 0.850625 0.946909 0.65912 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1199314 episodes
GETTING ACTION FROM:
action 1, numVisits=1199303, meanQ=6.234300, numObservations: 4
action 3, numVisits=4, meanQ=-0.505000, numObservations: 2
action 2, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.675354 0.825959 0.664378 0.850625 0.946909 0.65912 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 181
Initial state: 0 0.66834 0.84451 0.601815 0.88876 0.522537 0.474548 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1213272 episodes
GETTING ACTION FROM:
action 2, numVisits=1213121, meanQ=6.225401, numObservations: 3
action -1, numVisits=90, meanQ=5.434442, numObservations: 1
action 3, numVisits=57, meanQ=4.960361, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.66834 0.84451 0.601815 0.88876 0.522537 0.474548 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=54714, meanQ=6.578674, numObservations: 5
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1458879 episodes
GETTING ACTION FROM:
action 3, numVisits=1513592, meanQ=6.568235, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=2, meanQ=-5.505000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.66834 0.84451 0.601815 0.88876 0.522537 0.474548 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11.89
Run # 182
Initial state: 0 0.676966 0.849591 0.647558 0.870611 0.566536 0.61783 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1213445 episodes
GETTING ACTION FROM:
action 1, numVisits=1213366, meanQ=6.234442, numObservations: 3
action 0, numVisits=53, meanQ=5.199723, numObservations: 1
action 2, numVisits=22, meanQ=4.498645, numObservations: 3
action 3, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.676966 0.849591 0.647558 0.870611 0.566536 0.61783 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 183
Initial state: 0 0.609939 0.851435 0.160052 0.201445 0.509238 0.845089 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1202842 episodes
GETTING ACTION FROM:
action 1, numVisits=1202830, meanQ=6.295569, numObservations: 4
action 2, numVisits=4, meanQ=2.242500, numObservations: 3
action 3, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.609939 0.851435 0.160052 0.201445 0.509238 0.845089 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 184
Initial state: 0 0.594046 0.846309 0.564052 0.888875 0.0537938 0.466135 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1201669 episodes
GETTING ACTION FROM:
action 2, numVisits=937906, meanQ=6.236826, numObservations: 4
action 3, numVisits=263137, meanQ=6.226321, numObservations: 3
action 1, numVisits=622, meanQ=5.921738, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.594046 0.846309 0.564052 0.888875 0.0537938 0.466135 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 185
Initial state: 0 0.600191 0.805073 0.646682 0.889599 0.62958 0.622149 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1187025 episodes
GETTING ACTION FROM:
action 1, numVisits=1186966, meanQ=6.242753, numObservations: 5
action -1, numVisits=49, meanQ=5.160612, numObservations: 1
action 2, numVisits=6, meanQ=0.831667, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.600191 0.805073 0.646682 0.889599 0.62958 0.622149 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 186
Initial state: 0 0.562575 0.895577 0.998578 0.648002 0.511699 0.868103 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1201727 episodes
GETTING ACTION FROM:
action 1, numVisits=1186835, meanQ=6.222800, numObservations: 4
action 2, numVisits=14808, meanQ=6.136334, numObservations: 4
action 0, numVisits=59, meanQ=5.245048, numObservations: 1
action -1, numVisits=22, meanQ=4.594722, numObservations: 1
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action: 1
Next state: 1 0.562575 0.895577 0.998578 0.648002 0.511699 0.868103 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 187
Initial state: 0 0.583733 0.809116 0.515178 0.852588 0.0713788 0.757177 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 814082 episodes
GETTING ACTION FROM:
action 0, numVisits=814065, meanQ=4.181193, numObservations: 1
action 3, numVisits=6, meanQ=0.831667, numObservations: 2
action 1, numVisits=8, meanQ=0.373750, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.583733 0.809116 0.515178 0.852588 0.0713788 0.757177 w: 1
Observation: 0 0 0.744101 0 0.893802 0 0.732452 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=814056, meanQ=6.243504, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 1293938 episodes
GETTING ACTION FROM:
action 2, numVisits=2107994, meanQ=6.151373, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.583733 0.809116 0.515178 0.852588 0.0713788 0.757177 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 188
Initial state: 0 0.285945 0.892305 0.516642 0.892524 0.528535 0.81549 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1202669 episodes
GETTING ACTION FROM:
action 1, numVisits=1202608, meanQ=6.241231, numObservations: 4
action 0, numVisits=56, meanQ=5.236260, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.285945 0.892305 0.516642 0.892524 0.528535 0.81549 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=194675, meanQ=8.859405, numObservations: 4
action 2, numVisits=6, meanQ=5.665017, numObservations: 1
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1469932 episodes
GETTING ACTION FROM:
action 3, numVisits=1664588, meanQ=6.476616, numObservations: 4
action 1, numVisits=15, meanQ=3.798667, numObservations: 5
action 2, numVisits=9, meanQ=3.332244, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 3
Next state: 1 0.285945 0.892305 0.516642 0.892524 0.528535 0.81549 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 189
Initial state: 0 0.696491 0.83099 0.958742 0.753142 0.650167 0.865466 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1195944 episodes
GETTING ACTION FROM:
action 1, numVisits=1195737, meanQ=6.232227, numObservations: 4
action 3, numVisits=153, meanQ=5.609478, numObservations: 5
action -1, numVisits=49, meanQ=5.169200, numObservations: 1
action 2, numVisits=3, meanQ=-0.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.696491 0.83099 0.958742 0.753142 0.650167 0.865466 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 190
Initial state: 0 0.654579 0.881886 0.552951 0.863345 0.710998 0.732177 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1191033 episodes
GETTING ACTION FROM:
action 3, numVisits=1190947, meanQ=6.239239, numObservations: 5
action 0, numVisits=62, meanQ=5.289197, numObservations: 1
action -1, numVisits=20, meanQ=4.434333, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 1
action: 3
Next state: 2 0.654579 0.881886 0.552951 0.863345 0.710998 0.732177 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 191
Initial state: 0 0.232126 0.397778 0.506849 0.889228 0.562262 0.88455 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1211097 episodes
GETTING ACTION FROM:
action 2, numVisits=1211088, meanQ=6.232934, numObservations: 4
action 1, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.232126 0.397778 0.506849 0.889228 0.562262 0.88455 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 192
Initial state: 0 0.634206 0.851245 0.721259 0.888875 0.565578 0.835928 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1185645 episodes
GETTING ACTION FROM:
action 3, numVisits=1185635, meanQ=6.233490, numObservations: 5
action 1, numVisits=3, meanQ=-0.670000, numObservations: 1
action 2, numVisits=3, meanQ=-1.033333, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.634206 0.851245 0.721259 0.888875 0.565578 0.835928 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 193
Initial state: 0 0.323407 0.939569 0.611519 0.889592 0.641892 0.857053 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1202833 episodes
GETTING ACTION FROM:
action 3, numVisits=1202612, meanQ=6.184009, numObservations: 4
action 1, numVisits=122, meanQ=5.487216, numObservations: 3
action -1, numVisits=85, meanQ=5.375135, numObservations: 1
action 0, numVisits=12, meanQ=3.810241, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action: 3
Next state: 1 0.323407 0.939569 0.611519 0.889592 0.641892 0.857053 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 194
Initial state: 0 0.516529 0.863724 0.666549 0.865233 0.69177 0.872119 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1187537 episodes
GETTING ACTION FROM:
action 1, numVisits=1187519, meanQ=6.230513, numObservations: 5
action 3, numVisits=13, meanQ=3.691538, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.516529 0.863724 0.666549 0.865233 0.69177 0.872119 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 195
Initial state: 0 0.59666 0.803535 0.915041 0.904788 0.627386 0.895271 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1202295 episodes
GETTING ACTION FROM:
action 2, numVisits=1201633, meanQ=6.244596, numObservations: 4
action 3, numVisits=645, meanQ=5.935897, numObservations: 4
action 1, numVisits=13, meanQ=3.613862, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.59666 0.803535 0.915041 0.904788 0.627386 0.895271 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 196
Initial state: 0 0.612066 0.813296 0.654302 0.851664 0.618458 0.866404 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 816263 episodes
GETTING ACTION FROM:
action -1, numVisits=813879, meanQ=4.182816, numObservations: 1
action 0, numVisits=2359, meanQ=3.928505, numObservations: 1
action 1, numVisits=22, meanQ=1.770923, numObservations: 4
action 2, numVisits=2, meanQ=-5.505000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.612066 0.813296 0.654302 0.851664 0.618458 0.866404 w: 1
Observation: 0 0.702606 0 0.724472 0 0.542615 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=813871, meanQ=6.235497, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1262574 episodes
GETTING ACTION FROM:
action 1, numVisits=2076445, meanQ=6.208516, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.612066 0.813296 0.654302 0.851664 0.618458 0.866404 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 197
Initial state: 0 0.537074 0.85327 0.559395 0.812526 0.734645 0.760734 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1206685 episodes
GETTING ACTION FROM:
action 2, numVisits=1206630, meanQ=6.228524, numObservations: 4
action -1, numVisits=23, meanQ=4.666292, numObservations: 1
action 0, numVisits=22, meanQ=4.626183, numObservations: 1
action 3, numVisits=8, meanQ=2.873750, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action: 2
Next state: 1 0.537074 0.85327 0.559395 0.812526 0.734645 0.760734 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 198
Initial state: 0 0.543998 0.862488 0.841313 0.529452 0.552535 0.826678 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1195911 episodes
GETTING ACTION FROM:
action 2, numVisits=1195737, meanQ=6.235291, numObservations: 5
action 0, numVisits=90, meanQ=5.449571, numObservations: 1
action -1, numVisits=81, meanQ=5.409500, numObservations: 1
action 1, numVisits=2, meanQ=-0.010000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.543998 0.862488 0.841313 0.529452 0.552535 0.826678 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 199
Initial state: 0 0.669442 0.876953 0.34729 0.501434 0.567718 0.895654 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1197436 episodes
GETTING ACTION FROM:
action 1, numVisits=1197340, meanQ=6.237807, numObservations: 4
action -1, numVisits=52, meanQ=5.184736, numObservations: 1
action 0, numVisits=13, meanQ=3.747851, numObservations: 1
action 3, numVisits=29, meanQ=3.550693, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action: 1
Next state: 1 0.669442 0.876953 0.34729 0.501434 0.567718 0.895654 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 200
Initial state: 0 0.510616 0.875316 0.57404 0.819362 0.033417 0.865499 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1198074 episodes
GETTING ACTION FROM:
action 3, numVisits=1198003, meanQ=6.232127, numObservations: 4
action 0, numVisits=65, meanQ=5.303308, numObservations: 1
action 1, numVisits=2, meanQ=-0.509950, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.510616 0.875316 0.57404 0.819362 0.033417 0.865499 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=125466, meanQ=8.863727, numObservations: 4
action 2, numVisits=68958, meanQ=8.855562, numObservations: 4
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1470475 episodes
GETTING ACTION FROM:
action 2, numVisits=944822, meanQ=6.534151, numObservations: 4
action 1, numVisits=719061, meanQ=6.532800, numObservations: 4
action 3, numVisits=1014, meanQ=6.289647, numObservations: 4
action -1, numVisits=3, meanQ=1.300000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 2
Next state: 1 0.510616 0.875316 0.57404 0.819362 0.033417 0.865499 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 201
Initial state: 0 0.626455 0.882819 0.912829 0.709281 0.535963 0.822457 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1195039 episodes
GETTING ACTION FROM:
action 3, numVisits=1190628, meanQ=6.224765, numObservations: 4
action 2, numVisits=3256, meanQ=6.097549, numObservations: 4
action 1, numVisits=1099, meanQ=5.996870, numObservations: 5
action -1, numVisits=54, meanQ=5.185025, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.626455 0.882819 0.912829 0.709281 0.535963 0.822457 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 202
Initial state: 0 0.670656 0.864892 0.698236 0.593558 0.56753 0.827855 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1200500 episodes
GETTING ACTION FROM:
action 1, numVisits=1200436, meanQ=6.230949, numObservations: 4
action 2, numVisits=41, meanQ=4.797083, numObservations: 4
action -1, numVisits=20, meanQ=4.428584, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.670656 0.864892 0.698236 0.593558 0.56753 0.827855 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 203
Initial state: 0 0.633447 0.837921 0.648733 0.832105 0.30517 0.741655 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1183923 episodes
GETTING ACTION FROM:
action 3, numVisits=1183917, meanQ=6.315084, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.633447 0.837921 0.648733 0.832105 0.30517 0.741655 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=65524, meanQ=8.937697, numObservations: 3
action 2, numVisits=62718, meanQ=8.937091, numObservations: 3
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1485069 episodes
GETTING ACTION FROM:
action 2, numVisits=1039366, meanQ=6.656339, numObservations: 3
action 1, numVisits=573942, meanQ=6.653838, numObservations: 4
action 3, numVisits=4, meanQ=1.747500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.633447 0.837921 0.648733 0.832105 0.30517 0.741655 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 204
Initial state: 0 0.530029 0.819501 0.616698 0.869959 0.538288 0.797066 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1203881 episodes
GETTING ACTION FROM:
action 1, numVisits=1203779, meanQ=6.321957, numObservations: 4
action 2, numVisits=94, meanQ=5.466707, numObservations: 3
action 3, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.530029 0.819501 0.616698 0.869959 0.538288 0.797066 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 205
Initial state: 0 0.238729 0.826867 0.612658 0.859399 0.591263 0.834746 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1193178 episodes
GETTING ACTION FROM:
action 2, numVisits=1193154, meanQ=6.241426, numObservations: 5
action 1, numVisits=18, meanQ=3.933339, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.238729 0.826867 0.612658 0.859399 0.591263 0.834746 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 206
Initial state: 0 0.612945 0.829215 0.459463 0.91296 0.617847 0.811735 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1192396 episodes
GETTING ACTION FROM:
action 1, numVisits=1192351, meanQ=6.334708, numObservations: 5
action -1, numVisits=31, meanQ=4.962643, numObservations: 1
action 3, numVisits=9, meanQ=0.331111, numObservations: 2
action 2, numVisits=3, meanQ=-0.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.612945 0.829215 0.459463 0.91296 0.617847 0.811735 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 207
Initial state: 0 0.956037 0.348769 0.649884 0.884715 0.536304 0.898112 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1199126 episodes
GETTING ACTION FROM:
action 1, numVisits=1199106, meanQ=6.231630, numObservations: 4
action 3, numVisits=15, meanQ=3.653333, numObservations: 3
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.956037 0.348769 0.649884 0.884715 0.536304 0.898112 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 208
Initial state: 0 0.510846 0.849528 0.804438 0.673013 0.663381 0.861121 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1184998 episodes
GETTING ACTION FROM:
action 1, numVisits=1184951, meanQ=6.326902, numObservations: 5
action 2, numVisits=41, meanQ=3.191954, numObservations: 3
action 3, numVisits=2, meanQ=-0.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.510846 0.849528 0.804438 0.673013 0.663381 0.861121 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 209
Initial state: 0 0.36589 0.12649 0.516626 0.800379 0.57646 0.896812 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1201718 episodes
GETTING ACTION FROM:
action 3, numVisits=1201621, meanQ=6.245170, numObservations: 4
action 2, numVisits=65, meanQ=5.235848, numObservations: 4
action 1, numVisits=28, meanQ=4.819650, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.36589 0.12649 0.516626 0.800379 0.57646 0.896812 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 210
Initial state: 0 0.523028 0.889368 0.626677 0.816325 0.606909 0.293974 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1213458 episodes
GETTING ACTION FROM:
action 1, numVisits=1213388, meanQ=6.232468, numObservations: 3
action -1, numVisits=61, meanQ=5.264191, numObservations: 1
action 3, numVisits=6, meanQ=2.663333, numObservations: 3
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.523028 0.889368 0.626677 0.816325 0.606909 0.293974 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 211
Initial state: 0 0.614308 0.878929 0.610924 0.823036 0.748778 0.398209 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1196925 episodes
GETTING ACTION FROM:
action 3, numVisits=1196857, meanQ=6.236051, numObservations: 4
action 2, numVisits=63, meanQ=3.531595, numObservations: 4
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.614308 0.878929 0.610924 0.823036 0.748778 0.398209 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 212
Initial state: 0 0.368241 0.0899013 0.659784 0.830904 0.633568 0.880091 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1202828 episodes
GETTING ACTION FROM:
action 1, numVisits=1190016, meanQ=6.226615, numObservations: 4
action 3, numVisits=12801, meanQ=6.158859, numObservations: 3
action 2, numVisits=7, meanQ=3.285714, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.368241 0.0899013 0.659784 0.830904 0.633568 0.880091 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=66882, meanQ=8.939218, numObservations: 3
action 2, numVisits=62497, meanQ=8.938216, numObservations: 3
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1476273 episodes
GETTING ACTION FROM:
action 3, numVisits=1106940, meanQ=6.810181, numObservations: 3
action 2, numVisits=498694, meanQ=6.806601, numObservations: 4
action 1, numVisits=19, meanQ=4.788953, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.368241 0.0899013 0.659784 0.830904 0.633568 0.880091 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 213
Initial state: 0 0.62299 0.861061 0.5746 0.841263 0.970003 0.302401 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1207912 episodes
GETTING ACTION FROM:
action 2, numVisits=1207906, meanQ=6.240158, numObservations: 4
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.62299 0.861061 0.5746 0.841263 0.970003 0.302401 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=54634, meanQ=6.555898, numObservations: 4
action 1, numVisits=24, meanQ=4.911254, numObservations: 4
action 2, numVisits=10, meanQ=4.099000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1467443 episodes
GETTING ACTION FROM:
action 3, numVisits=1522071, meanQ=6.460635, numObservations: 4
action 1, numVisits=24, meanQ=4.911254, numObservations: 4
action 2, numVisits=14, meanQ=4.070007, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 3
Next state: 2 0.62299 0.861061 0.5746 0.841263 0.970003 0.302401 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11.89
Run # 214
Initial state: 0 0.660132 0.849808 0.512216 0.871453 0.226673 0.673428 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1223723 episodes
GETTING ACTION FROM:
action 2, numVisits=1223658, meanQ=6.239900, numObservations: 3
action 0, numVisits=40, meanQ=5.019848, numObservations: 1
action -1, numVisits=20, meanQ=4.479718, numObservations: 1
action 1, numVisits=3, meanQ=-0.670000, numObservations: 2
action 3, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 2
Next state: 1 0.660132 0.849808 0.512216 0.871453 0.226673 0.673428 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 215
Initial state: 0 0.635014 0.856599 0.726099 0.334073 0.537506 0.808274 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1207569 episodes
GETTING ACTION FROM:
action 3, numVisits=1207461, meanQ=6.189684, numObservations: 4
action 0, numVisits=64, meanQ=5.240689, numObservations: 1
action 2, numVisits=28, meanQ=4.590357, numObservations: 3
action 1, numVisits=14, meanQ=4.070007, numObservations: 3
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.635014 0.856599 0.726099 0.334073 0.537506 0.808274 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 216
Initial state: 0 0.642846 0.820308 0.0211369 0.602248 0.63376 0.889661 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1201481 episodes
GETTING ACTION FROM:
action 1, numVisits=1201474, meanQ=6.234713, numObservations: 4
action 3, numVisits=2, meanQ=-0.010000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.642846 0.820308 0.0211369 0.602248 0.63376 0.889661 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 217
Initial state: 0 0.512657 0.875582 0.712813 0.945398 0.696566 0.826602 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1203070 episodes
GETTING ACTION FROM:
action 2, numVisits=1203031, meanQ=6.235780, numObservations: 4
action 0, numVisits=32, meanQ=4.910518, numObservations: 1
action 3, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.512657 0.875582 0.712813 0.945398 0.696566 0.826602 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 218
Initial state: 0 0.572427 0.846963 0.684691 0.831011 0.996608 0.565072 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1198979 episodes
GETTING ACTION FROM:
action 1, numVisits=1198948, meanQ=6.235656, numObservations: 4
action -1, numVisits=15, meanQ=4.284742, numObservations: 1
action 3, numVisits=10, meanQ=3.198000, numObservations: 3
action 2, numVisits=4, meanQ=1.747500, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.572427 0.846963 0.684691 0.831011 0.996608 0.565072 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=54405, meanQ=6.483713, numObservations: 5
action 1, numVisits=7, meanQ=1.998571, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1448618 episodes
GETTING ACTION FROM:
action 3, numVisits=1503021, meanQ=6.411608, numObservations: 5
action 1, numVisits=7, meanQ=1.998571, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 3
Next state: 2 0.572427 0.846963 0.684691 0.831011 0.996608 0.565072 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11.89
Run # 219
Initial state: 0 0.690752 0.850813 0.972034 0.103188 0.559521 0.847459 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1214516 episodes
GETTING ACTION FROM:
action 1, numVisits=1214498, meanQ=6.235521, numObservations: 3
action 2, numVisits=13, meanQ=3.683085, numObservations: 3
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.690752 0.850813 0.972034 0.103188 0.559521 0.847459 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 220
Initial state: 0 0.975072 0.320253 0.506436 0.870921 0.571651 0.857487 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1190209 episodes
GETTING ACTION FROM:
action 1, numVisits=1190201, meanQ=6.235276, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.975072 0.320253 0.506436 0.870921 0.571651 0.857487 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 221
Initial state: 0 0.166218 0.726358 0.697406 0.835869 0.687432 0.893058 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1185267 episodes
GETTING ACTION FROM:
action 1, numVisits=1185220, meanQ=6.310824, numObservations: 5
action 0, numVisits=41, meanQ=5.118712, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 1
Next state: 0 0.166218 0.726358 0.697406 0.835869 0.687432 0.893058 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=128431, meanQ=8.940456, numObservations: 3
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1485744 episodes
GETTING ACTION FROM:
action 2, numVisits=1614097, meanQ=6.707649, numObservations: 3
action 3, numVisits=47, meanQ=5.403832, numObservations: 4
action 1, numVisits=33, meanQ=5.330006, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.166218 0.726358 0.697406 0.835869 0.687432 0.893058 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 222
Initial state: 0 0.678366 0.809807 0.591941 0.868267 0.975988 0.67881 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1211942 episodes
GETTING ACTION FROM:
action 1, numVisits=1211908, meanQ=6.234885, numObservations: 3
action 0, numVisits=21, meanQ=4.550845, numObservations: 1
action 3, numVisits=10, meanQ=2.010000, numObservations: 3
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.678366 0.809807 0.591941 0.868267 0.975988 0.67881 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 223
Initial state: 0 0.557322 0.847342 0.588105 0.815311 0.945597 0.135127 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1196510 episodes
GETTING ACTION FROM:
action 3, numVisits=1196388, meanQ=6.231397, numObservations: 4
action 0, numVisits=55, meanQ=5.216866, numObservations: 1
action -1, numVisits=44, meanQ=5.091647, numObservations: 1
action 1, numVisits=22, meanQ=4.493650, numObservations: 4
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.557322 0.847342 0.588105 0.815311 0.945597 0.135127 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 224
Initial state: 0 0.0869133 0.501171 0.504418 0.879586 0.525022 0.867978 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1192264 episodes
GETTING ACTION FROM:
action 2, numVisits=1192209, meanQ=6.185579, numObservations: 5
action 0, numVisits=38, meanQ=4.944701, numObservations: 1
action 3, numVisits=14, meanQ=4.134286, numObservations: 4
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.0869133 0.501171 0.504418 0.879586 0.525022 0.867978 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 225
Initial state: 0 0.191992 0.318507 0.605104 0.866839 0.680804 0.859755 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1209057 episodes
GETTING ACTION FROM:
action 2, numVisits=1208964, meanQ=6.169313, numObservations: 4
action -1, numVisits=48, meanQ=5.080707, numObservations: 1
action 3, numVisits=20, meanQ=4.495000, numObservations: 3
action 1, numVisits=23, meanQ=4.302617, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.191992 0.318507 0.605104 0.866839 0.680804 0.859755 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 226
Initial state: 0 0.529953 0.825425 0.123907 0.686122 0.543344 0.889112 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 809503 episodes
GETTING ACTION FROM:
action -1, numVisits=809490, meanQ=4.178725, numObservations: 1
action 3, numVisits=7, meanQ=0.555714, numObservations: 3
action 2, numVisits=3, meanQ=-0.670000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.529953 0.825425 0.123907 0.686122 0.543344 0.889112 w: 1
Observation: 0 0.541212 0 0.127523 0 0.628051 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=806712, meanQ=6.228415, numObservations: 4
action 1, numVisits=2568, meanQ=6.089143, numObservations: 5
action 3, numVisits=164, meanQ=5.658093, numObservations: 4
action -1, numVisits=26, meanQ=4.766906, numObservations: 1
action 0, numVisits=19, meanQ=4.475663, numObservations: 1
Sampled 1299694 episodes
GETTING ACTION FROM:
action 3, numVisits=1294165, meanQ=6.439624, numObservations: 4
action 2, numVisits=812399, meanQ=6.226078, numObservations: 4
action 1, numVisits=2574, meanQ=6.087582, numObservations: 5
action -1, numVisits=26, meanQ=4.766906, numObservations: 1
action 0, numVisits=19, meanQ=4.475663, numObservations: 1
action: 3
Next state: 1 0.529953 0.825425 0.123907 0.686122 0.543344 0.889112 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 227
Initial state: 0 0.503578 0.825993 0.203512 0.366588 0.52678 0.800265 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1186265 episodes
GETTING ACTION FROM:
action 3, numVisits=1186240, meanQ=6.225853, numObservations: 5
action 0, numVisits=19, meanQ=4.472355, numObservations: 1
action 1, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.503578 0.825993 0.203512 0.366588 0.52678 0.800265 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 228
Initial state: 0 0.5435 0.88899 0.992326 0.674511 0.604555 0.834025 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1217359 episodes
GETTING ACTION FROM:
action 2, numVisits=1217275, meanQ=6.233467, numObservations: 3
action -1, numVisits=26, meanQ=4.726339, numObservations: 1
action 1, numVisits=34, meanQ=4.456768, numObservations: 3
action 3, numVisits=22, meanQ=4.454545, numObservations: 3
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 2
Next state: 2 0.5435 0.88899 0.992326 0.674511 0.604555 0.834025 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 229
Initial state: 0 0.58285 0.40909 0.62961 0.817945 0.629771 0.865094 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1201463 episodes
GETTING ACTION FROM:
action 1, numVisits=1201427, meanQ=6.240337, numObservations: 4
action -1, numVisits=21, meanQ=4.503121, numObservations: 1
action 0, numVisits=11, meanQ=3.770864, numObservations: 1
action 2, numVisits=3, meanQ=-0.670000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.58285 0.40909 0.62961 0.817945 0.629771 0.865094 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 230
Initial state: 0 0.588484 0.885513 0.909743 0.310811 0.615 0.889024 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1197759 episodes
GETTING ACTION FROM:
action 2, numVisits=1197732, meanQ=6.238046, numObservations: 4
action 0, numVisits=20, meanQ=4.559712, numObservations: 1
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.588484 0.885513 0.909743 0.310811 0.615 0.889024 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 231
Initial state: 0 0.585754 0.841356 0.658009 0.974207 0.548649 0.868967 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1199856 episodes
GETTING ACTION FROM:
action 1, numVisits=1199837, meanQ=6.241404, numObservations: 4
action 0, numVisits=13, meanQ=3.953002, numObservations: 1
action 3, numVisits=3, meanQ=-0.670000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.585754 0.841356 0.658009 0.974207 0.548649 0.868967 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 232
Initial state: 0 0.538366 0.83736 0.58183 0.877356 0.968877 0.469679 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1202994 episodes
GETTING ACTION FROM:
action 1, numVisits=1202970, meanQ=6.227531, numObservations: 4
action -1, numVisits=17, meanQ=4.271431, numObservations: 1
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.538366 0.83736 0.58183 0.877356 0.968877 0.469679 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 233
Initial state: 0 0.539786 0.897658 0.354528 0.986155 0.651149 0.807998 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1183823 episodes
GETTING ACTION FROM:
action 3, numVisits=1183781, meanQ=6.238254, numObservations: 5
action 0, numVisits=31, meanQ=4.861361, numObservations: 1
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action 1, numVisits=5, meanQ=0.998020, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.539786 0.897658 0.354528 0.986155 0.651149 0.807998 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 234
Initial state: 0 0.66208 0.881858 0.53845 0.852472 0.419727 0.441851 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1198517 episodes
GETTING ACTION FROM:
action 1, numVisits=1198465, meanQ=6.235386, numObservations: 4
action -1, numVisits=27, meanQ=4.785376, numObservations: 1
action 2, numVisits=22, meanQ=4.044550, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.66208 0.881858 0.53845 0.852472 0.419727 0.441851 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 235
Initial state: 0 0.511234 0.853702 0.520178 0.861891 0.607588 0.591351 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1206133 episodes
GETTING ACTION FROM:
action 2, numVisits=1206067, meanQ=6.238771, numObservations: 4
action -1, numVisits=60, meanQ=5.267190, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 2
Next state: 1 0.511234 0.853702 0.520178 0.861891 0.607588 0.591351 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 236
Initial state: 0 0.607533 0.88793 0.197734 0.942571 0.564857 0.874251 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1197638 episodes
GETTING ACTION FROM:
action 1, numVisits=1197624, meanQ=6.225576, numObservations: 4
action 3, numVisits=8, meanQ=2.873750, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.607533 0.88793 0.197734 0.942571 0.564857 0.874251 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 237
Initial state: 0 0.584861 0.869025 0.207922 0.152361 0.580055 0.875017 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1196111 episodes
GETTING ACTION FROM:
action 3, numVisits=1196045, meanQ=6.313314, numObservations: 4
action -1, numVisits=51, meanQ=5.252721, numObservations: 1
action 1, numVisits=9, meanQ=3.554444, numObservations: 3
action 2, numVisits=4, meanQ=1.475000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.584861 0.869025 0.207922 0.152361 0.580055 0.875017 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 238
Initial state: 0 0.565612 0.89347 0.946574 0.849398 0.633724 0.838859 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1193929 episodes
GETTING ACTION FROM:
action 2, numVisits=1193894, meanQ=6.235756, numObservations: 5
action 0, numVisits=19, meanQ=4.463846, numObservations: 1
action 3, numVisits=13, meanQ=3.690015, numObservations: 4
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.565612 0.89347 0.946574 0.849398 0.633724 0.838859 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 239
Initial state: 0 0.679174 0.873444 0.540034 0.857991 0.252371 0.282911 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 893739 episodes
GETTING ACTION FROM:
action 2, numVisits=239162, meanQ=6.192946, numObservations: 4
action -1, numVisits=654564, meanQ=4.166231, numObservations: 1
action 1, numVisits=10, meanQ=1.098010, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.679174 0.873444 0.540034 0.857991 0.252371 0.282911 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 240
Initial state: 0 0.204594 0.48719 0.673084 0.89419 0.666807 0.800588 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1195431 episodes
GETTING ACTION FROM:
action 1, numVisits=1195371, meanQ=6.231178, numObservations: 4
action 0, numVisits=49, meanQ=5.145123, numObservations: 1
action 2, numVisits=6, meanQ=0.831667, numObservations: 3
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.204594 0.48719 0.673084 0.89419 0.666807 0.800588 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=171840, meanQ=8.865128, numObservations: 5
action 3, numVisits=21997, meanQ=8.834209, numObservations: 5
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1445721 episodes
GETTING ACTION FROM:
action 3, numVisits=1027477, meanQ=6.904622, numObservations: 5
action 2, numVisits=612065, meanQ=6.901144, numObservations: 5
action 1, numVisits=17, meanQ=4.876471, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.204594 0.48719 0.673084 0.89419 0.666807 0.800588 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 241
Initial state: 0 0.692922 0.858054 0.570108 0.813598 0.664481 0.436698 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1210956 episodes
GETTING ACTION FROM:
action 1, numVisits=1210949, meanQ=6.228083, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.692922 0.858054 0.570108 0.813598 0.664481 0.436698 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 242
Initial state: 0 0.655205 0.877013 0.0715513 0.563114 0.558137 0.868471 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1200474 episodes
GETTING ACTION FROM:
action 1, numVisits=1200393, meanQ=6.180327, numObservations: 4
action -1, numVisits=36, meanQ=4.921020, numObservations: 1
action 0, numVisits=25, meanQ=4.614207, numObservations: 1
action 3, numVisits=18, meanQ=4.046694, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 1
Next state: 1 0.655205 0.877013 0.0715513 0.563114 0.558137 0.868471 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 243
Initial state: 0 0.506242 0.861973 0.990071 0.151238 0.671506 0.811102 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1205463 episodes
GETTING ACTION FROM:
action 3, numVisits=1205439, meanQ=6.224690, numObservations: 3
action -1, numVisits=17, meanQ=4.405324, numObservations: 1
action 1, numVisits=4, meanQ=1.747500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.506242 0.861973 0.990071 0.151238 0.671506 0.811102 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 244
Initial state: 0 0.991791 0.884 0.509865 0.838196 0.570556 0.802558 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1194618 episodes
GETTING ACTION FROM:
action 3, numVisits=1194203, meanQ=6.227644, numObservations: 4
action 2, numVisits=312, meanQ=5.763555, numObservations: 4
action -1, numVisits=58, meanQ=5.247132, numObservations: 1
action 0, numVisits=44, meanQ=5.082578, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.991791 0.884 0.509865 0.838196 0.570556 0.802558 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 245
Initial state: 0 0.528052 0.872194 0.615854 0.811138 0.612171 0.602857 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1207447 episodes
GETTING ACTION FROM:
action 2, numVisits=1207421, meanQ=6.237821, numObservations: 4
action -1, numVisits=13, meanQ=4.006942, numObservations: 1
action 1, numVisits=10, meanQ=2.188000, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.528052 0.872194 0.615854 0.811138 0.612171 0.602857 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 246
Initial state: 0 0.621616 0.815072 0.790403 0.130551 0.527491 0.844518 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1204727 episodes
GETTING ACTION FROM:
action 2, numVisits=1204714, meanQ=6.235130, numObservations: 4
action 1, numVisits=7, meanQ=3.285714, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.621616 0.815072 0.790403 0.130551 0.527491 0.844518 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 247
Initial state: 0 0.683087 0.815959 0.424848 0.779561 0.54939 0.821327 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1199040 episodes
GETTING ACTION FROM:
action 1, numVisits=1198979, meanQ=6.239400, numObservations: 4
action -1, numVisits=24, meanQ=4.685003, numObservations: 1
action 3, numVisits=29, meanQ=4.406907, numObservations: 5
action 2, numVisits=6, meanQ=2.663333, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.683087 0.815959 0.424848 0.779561 0.54939 0.821327 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 248
Initial state: 0 0.553228 0.825366 0.60456 0.859818 0.241926 0.893465 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 836476 episodes
GETTING ACTION FROM:
action 0, numVisits=835407, meanQ=6.387756, numObservations: 3
action -1, numVisits=1053, meanQ=4.109153, numObservations: 1
action 1, numVisits=13, meanQ=0.766923, numObservations: 4
action 2, numVisits=2, meanQ=-0.509950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.553228 0.825366 0.60456 0.859818 0.241926 0.893465 w: 1
Observation: 0 0 0.821881 0 0.953564 0 0.897939 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=360478, meanQ=8.202337, numObservations: 5
action 3, numVisits=66, meanQ=5.884091, numObservations: 3
action 1, numVisits=64, meanQ=5.854225, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1275137 episodes
GETTING ACTION FROM:
action 2, numVisits=1635370, meanQ=6.557251, numObservations: 5
action 1, numVisits=244, meanQ=6.065804, numObservations: 4
action 3, numVisits=131, meanQ=5.845191, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.553228 0.825366 0.60456 0.859818 0.241926 0.893465 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 249
Initial state: 0 0.508363 0.807327 0.400026 0.0484372 0.565944 0.804602 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1190495 episodes
GETTING ACTION FROM:
action 2, numVisits=1190386, meanQ=6.239072, numObservations: 5
action 0, numVisits=53, meanQ=5.212184, numObservations: 1
action -1, numVisits=50, meanQ=5.178244, numObservations: 1
action 1, numVisits=4, meanQ=1.747500, numObservations: 2
action 3, numVisits=2, meanQ=-0.010000, numObservations: 2
action: 2
Next state: 0 0.508363 0.807327 0.400026 0.0484372 0.565944 0.804602 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=76760, meanQ=8.941502, numObservations: 3
action 1, numVisits=52641, meanQ=8.936568, numObservations: 3
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1480586 episodes
GETTING ACTION FROM:
action 3, numVisits=1162119, meanQ=6.833146, numObservations: 3
action 1, numVisits=447867, meanQ=6.828788, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 1
action: 3
Next state: 1 0.508363 0.807327 0.400026 0.0484372 0.565944 0.804602 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 250
Initial state: 0 0.584882 0.822151 0.247139 0.668401 0.549783 0.863879 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1181034 episodes
GETTING ACTION FROM:
action 3, numVisits=1180525, meanQ=6.237658, numObservations: 5
action 2, numVisits=411, meanQ=5.864701, numObservations: 4
action 0, numVisits=55, meanQ=5.228228, numObservations: 1
action -1, numVisits=42, meanQ=5.073658, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.584882 0.822151 0.247139 0.668401 0.549783 0.863879 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=6394, meanQ=6.047380, numObservations: 4
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1345832 episodes
GETTING ACTION FROM:
action 3, numVisits=1352222, meanQ=6.075901, numObservations: 4
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action 1, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 3
Next state: 1 0.584882 0.822151 0.247139 0.668401 0.549783 0.863879 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 251
Initial state: 0 0.844475 0.112164 0.519192 0.847548 0.687892 0.876852 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1198048 episodes
GETTING ACTION FROM:
action 1, numVisits=1197998, meanQ=6.240422, numObservations: 4
action 0, numVisits=42, meanQ=5.087084, numObservations: 1
action 2, numVisits=4, meanQ=1.747500, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.844475 0.112164 0.519192 0.847548 0.687892 0.876852 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=53294, meanQ=6.590977, numObservations: 5
action 1, numVisits=57, meanQ=5.218247, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1449901 episodes
GETTING ACTION FROM:
action 3, numVisits=1503193, meanQ=6.376961, numObservations: 5
action 1, numVisits=57, meanQ=5.218247, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 3
Next state: 1 0.844475 0.112164 0.519192 0.847548 0.687892 0.876852 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 252
Initial state: 0 0.68078 0.82649 0.534411 0.825277 0.931391 0.331117 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1196685 episodes
GETTING ACTION FROM:
action 1, numVisits=1196676, meanQ=6.224760, numObservations: 4
action 3, numVisits=4, meanQ=1.747500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.68078 0.82649 0.534411 0.825277 0.931391 0.331117 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 253
Initial state: 0 0.550371 0.821833 0.564095 0.870346 0.515237 0.803869 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1198996 episodes
GETTING ACTION FROM:
action 1, numVisits=1198990, meanQ=6.229613, numObservations: 4
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.550371 0.821833 0.564095 0.870346 0.515237 0.803869 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 254
Initial state: 0 0.578089 0.801241 0.637169 0.856002 0.0492121 0.838796 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1220548 episodes
GETTING ACTION FROM:
action 2, numVisits=1220539, meanQ=6.223336, numObservations: 3
action 3, numVisits=3, meanQ=-0.670000, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.578089 0.801241 0.637169 0.856002 0.0492121 0.838796 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 255
Initial state: 0 0.496362 0.160277 0.545265 0.864232 0.603658 0.814923 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1197291 episodes
GETTING ACTION FROM:
action 2, numVisits=1197205, meanQ=6.180381, numObservations: 5
action -1, numVisits=38, meanQ=4.913622, numObservations: 1
action 1, numVisits=31, meanQ=4.119358, numObservations: 3
action 3, numVisits=15, meanQ=3.732007, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.496362 0.160277 0.545265 0.864232 0.603658 0.814923 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 256
Initial state: 0 0.511673 0.827865 0.508351 0.283009 0.583898 0.841264 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1209840 episodes
GETTING ACTION FROM:
action 2, numVisits=1209826, meanQ=6.230631, numObservations: 4
action 3, numVisits=9, meanQ=3.663344, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.511673 0.827865 0.508351 0.283009 0.583898 0.841264 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 257
Initial state: 0 0.649577 0.866304 0.409727 0.250691 0.530601 0.846477 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1180243 episodes
GETTING ACTION FROM:
action 3, numVisits=1180119, meanQ=6.224079, numObservations: 5
action 0, numVisits=102, meanQ=5.481343, numObservations: 1
action -1, numVisits=19, meanQ=4.265078, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.649577 0.866304 0.409727 0.250691 0.530601 0.846477 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 258
Initial state: 0 0.655192 0.870671 0.946481 0.10671 0.67369 0.833019 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1186528 episodes
GETTING ACTION FROM:
action 1, numVisits=1070225, meanQ=6.233499, numObservations: 5
action 2, numVisits=116036, meanQ=6.208178, numObservations: 4
action 3, numVisits=195, meanQ=5.662309, numObservations: 5
action 0, numVisits=41, meanQ=5.069108, numObservations: 1
action -1, numVisits=31, meanQ=4.875415, numObservations: 1
action: 1
Next state: 1 0.655192 0.870671 0.946481 0.10671 0.67369 0.833019 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 259
Initial state: 0 0.659192 0.810257 0.0311672 0.355899 0.651807 0.889168 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1182827 episodes
GETTING ACTION FROM:
action 3, numVisits=1182775, meanQ=6.219532, numObservations: 5
action -1, numVisits=45, meanQ=5.084888, numObservations: 1
action 1, numVisits=4, meanQ=1.747500, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.659192 0.810257 0.0311672 0.355899 0.651807 0.889168 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 260
Initial state: 0 0.560004 0.80267 0.649964 0.802369 0.320974 0.6066 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1194065 episodes
GETTING ACTION FROM:
action 2, numVisits=1193985, meanQ=6.320673, numObservations: 5
action 3, numVisits=35, meanQ=5.025146, numObservations: 5
action -1, numVisits=33, meanQ=4.986045, numObservations: 1
action 1, numVisits=10, meanQ=3.198000, numObservations: 3
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.560004 0.80267 0.649964 0.802369 0.320974 0.6066 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 261
Initial state: 0 0.560534 0.89081 0.697777 0.248613 0.529179 0.82299 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1201566 episodes
GETTING ACTION FROM:
action 1, numVisits=1201522, meanQ=6.226980, numObservations: 4
action -1, numVisits=20, meanQ=4.514999, numObservations: 1
action 0, numVisits=16, meanQ=4.189496, numObservations: 1
action 2, numVisits=6, meanQ=0.831667, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 1
Next state: 1 0.560534 0.89081 0.697777 0.248613 0.529179 0.82299 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 262
Initial state: 0 0.665847 0.844782 0.508357 0.821191 0.243064 0.437094 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1195708 episodes
GETTING ACTION FROM:
action 2, numVisits=1195551, meanQ=6.232447, numObservations: 5
action 0, numVisits=69, meanQ=5.322588, numObservations: 1
action -1, numVisits=64, meanQ=5.299662, numObservations: 1
action 3, numVisits=21, meanQ=3.809048, numObservations: 3
action 1, numVisits=3, meanQ=-1.033333, numObservations: 2
action: 2
Next state: 1 0.665847 0.844782 0.508357 0.821191 0.243064 0.437094 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 263
Initial state: 0 0.0584896 0.0209888 0.551562 0.890993 0.656548 0.878912 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1199053 episodes
GETTING ACTION FROM:
action 3, numVisits=928374, meanQ=6.235999, numObservations: 4
action 2, numVisits=270673, meanQ=6.224560, numObservations: 4
action 1, numVisits=2, meanQ=-0.010000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.0584896 0.0209888 0.551562 0.890993 0.656548 0.878912 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 264
Initial state: 0 0.612635 0.801263 0.646066 0.813607 0.289252 0.926079 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1181597 episodes
GETTING ACTION FROM:
action 3, numVisits=952879, meanQ=6.236148, numObservations: 5
action 2, numVisits=228690, meanQ=6.134217, numObservations: 3
action -1, numVisits=17, meanQ=4.322645, numObservations: 1
action 1, numVisits=9, meanQ=2.332233, numObservations: 3
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 3
Next state: 1 0.612635 0.801263 0.646066 0.813607 0.289252 0.926079 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 265
Initial state: 0 0.6373 0.841646 0.687781 0.875583 0.781117 0.929864 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1196140 episodes
GETTING ACTION FROM:
action 2, numVisits=1195976, meanQ=6.226766, numObservations: 5
action 3, numVisits=78, meanQ=5.309872, numObservations: 5
action -1, numVisits=46, meanQ=5.102855, numObservations: 1
action 0, numVisits=39, meanQ=4.987601, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.6373 0.841646 0.687781 0.875583 0.781117 0.929864 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 266
Initial state: 0 0.233655 0.555383 0.630769 0.823561 0.638858 0.818464 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1195417 episodes
GETTING ACTION FROM:
action 3, numVisits=1195349, meanQ=6.238513, numObservations: 4
action -1, numVisits=54, meanQ=5.223464, numObservations: 1
action 2, numVisits=10, meanQ=3.198000, numObservations: 3
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action 1, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 3
Next state: 1 0.233655 0.555383 0.630769 0.823561 0.638858 0.818464 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 267
Initial state: 0 0.661992 0.894481 0.642851 0.859171 0.628877 0.635376 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1188844 episodes
GETTING ACTION FROM:
action 1, numVisits=1188756, meanQ=6.241592, numObservations: 5
action -1, numVisits=43, meanQ=5.081303, numObservations: 1
action 2, numVisits=42, meanQ=5.034290, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.661992 0.894481 0.642851 0.859171 0.628877 0.635376 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 268
Initial state: 0 0.878978 0.38909 0.54507 0.88347 0.551779 0.81678 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1180552 episodes
GETTING ACTION FROM:
action 3, numVisits=1180472, meanQ=6.181732, numObservations: 5
action -1, numVisits=72, meanQ=5.296918, numObservations: 1
action 2, numVisits=4, meanQ=1.742550, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.878978 0.38909 0.54507 0.88347 0.551779 0.81678 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 269
Initial state: 0 0.655074 0.866137 0.676612 0.80523 0.146264 0.790615 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1162913 episodes
GETTING ACTION FROM:
action 2, numVisits=1162902, meanQ=6.150988, numObservations: 5
action 1, numVisits=5, meanQ=1.396000, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.655074 0.866137 0.676612 0.80523 0.146264 0.790615 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 270
Initial state: 0 0.682198 0.896498 0.0811655 0.564571 0.521193 0.887176 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1199529 episodes
GETTING ACTION FROM:
action 3, numVisits=1199497, meanQ=6.243080, numObservations: 4
action 0, numVisits=27, meanQ=4.744095, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.682198 0.896498 0.0811655 0.564571 0.521193 0.887176 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 271
Initial state: 0 0.58087 0.882613 0.859269 0.233471 0.633134 0.806993 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1188493 episodes
GETTING ACTION FROM:
action 3, numVisits=1188470, meanQ=6.182771, numObservations: 5
action -1, numVisits=18, meanQ=4.375017, numObservations: 1
action 1, numVisits=2, meanQ=-0.010000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.58087 0.882613 0.859269 0.233471 0.633134 0.806993 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 272
Initial state: 0 0.546393 0.848762 0.739591 0.800263 0.593743 0.860108 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1206794 episodes
GETTING ACTION FROM:
action 2, numVisits=1206752, meanQ=6.224911, numObservations: 4
action 1, numVisits=30, meanQ=4.699007, numObservations: 2
action -1, numVisits=8, meanQ=3.445000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 2
Next state: 1 0.546393 0.848762 0.739591 0.800263 0.593743 0.860108 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 273
Initial state: 0 0.656889 0.894535 0.67289 0.897329 0.407384 0.784157 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1207389 episodes
GETTING ACTION FROM:
action 2, numVisits=1207277, meanQ=6.232306, numObservations: 4
action 1, numVisits=78, meanQ=5.226927, numObservations: 4
action -1, numVisits=30, meanQ=4.814950, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.656889 0.894535 0.67289 0.897329 0.407384 0.784157 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 274
Initial state: 0 0.570967 0.88907 0.641549 0.879929 0.0345154 0.222412 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1217091 episodes
GETTING ACTION FROM:
action 2, numVisits=1217061, meanQ=6.232779, numObservations: 3
action 1, numVisits=22, meanQ=4.445455, numObservations: 4
action 3, numVisits=4, meanQ=1.747500, numObservations: 3
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 2
Next state: 1 0.570967 0.88907 0.641549 0.879929 0.0345154 0.222412 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 275
Initial state: 0 0.520647 0.88885 0.557556 0.84919 0.868033 0.838476 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1188979 episodes
GETTING ACTION FROM:
action 1, numVisits=1188882, meanQ=6.223416, numObservations: 5
action -1, numVisits=92, meanQ=5.438401, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.520647 0.88885 0.557556 0.84919 0.868033 0.838476 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 276
Initial state: 0 0.700797 0.343729 0.549115 0.881004 0.576092 0.857711 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1211270 episodes
GETTING ACTION FROM:
action 3, numVisits=1211220, meanQ=6.223486, numObservations: 3
action 2, numVisits=39, meanQ=3.127949, numObservations: 4
action 1, numVisits=7, meanQ=1.997157, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.700797 0.343729 0.549115 0.881004 0.576092 0.857711 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 277
Initial state: 0 0.802325 0.899535 0.663123 0.88011 0.610296 0.865088 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1198921 episodes
GETTING ACTION FROM:
action 3, numVisits=1198877, meanQ=6.282693, numObservations: 4
action 1, numVisits=20, meanQ=4.549005, numObservations: 4
action 0, numVisits=20, meanQ=4.483319, numObservations: 1
action 2, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.802325 0.899535 0.663123 0.88011 0.610296 0.865088 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 278
Initial state: 0 0.635139 0.860961 0.139515 0.0981215 0.556629 0.824884 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1180490 episodes
GETTING ACTION FROM:
action 3, numVisits=1180438, meanQ=6.229991, numObservations: 5
action -1, numVisits=35, meanQ=4.964435, numObservations: 1
action 1, numVisits=14, meanQ=4.070714, numObservations: 3
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.635139 0.860961 0.139515 0.0981215 0.556629 0.824884 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 279
Initial state: 0 0.585232 0.892543 0.574651 0.8863 0.0279157 0.331771 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1173489 episodes
GETTING ACTION FROM:
action 3, numVisits=1173480, meanQ=6.234896, numObservations: 5
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.585232 0.892543 0.574651 0.8863 0.0279157 0.331771 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=84053, meanQ=8.873997, numObservations: 4
action 1, numVisits=77271, meanQ=8.872770, numObservations: 5
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1455751 episodes
GETTING ACTION FROM:
action 1, numVisits=1169071, meanQ=6.790159, numObservations: 5
action 2, numVisits=448002, meanQ=6.785694, numObservations: 4
action 3, numVisits=3, meanQ=2.330033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.585232 0.892543 0.574651 0.8863 0.0279157 0.331771 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 280
Initial state: 0 0.550791 0.838969 0.091985 0.845319 0.557114 0.84024 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1210445 episodes
GETTING ACTION FROM:
action 3, numVisits=1210438, meanQ=6.234759, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-5.505000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.550791 0.838969 0.091985 0.845319 0.557114 0.84024 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=54444, meanQ=6.512044, numObservations: 4
action 2, numVisits=19, meanQ=4.945268, numObservations: 4
action 3, numVisits=4, meanQ=1.747500, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1477808 episodes
GETTING ACTION FROM:
action 1, numVisits=1532251, meanQ=6.669161, numObservations: 4
action 2, numVisits=20, meanQ=4.148005, numObservations: 4
action 3, numVisits=4, meanQ=1.747500, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.550791 0.838969 0.091985 0.845319 0.557114 0.84024 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 281
Initial state: 0 0.643042 0.866175 0.780563 0.73556 0.695951 0.813016 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1224442 episodes
GETTING ACTION FROM:
action 2, numVisits=1224435, meanQ=6.180970, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.643042 0.866175 0.780563 0.73556 0.695951 0.813016 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 282
Initial state: 0 0.656882 0.828022 0.837811 0.738116 0.661021 0.804921 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1210304 episodes
GETTING ACTION FROM:
action 3, numVisits=1210286, meanQ=6.220982, numObservations: 3
action 2, numVisits=13, meanQ=3.607692, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.656882 0.828022 0.837811 0.738116 0.661021 0.804921 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 283
Initial state: 0 0.675704 0.865247 0.37113 0.483404 0.545615 0.813496 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1195796 episodes
GETTING ACTION FROM:
action 3, numVisits=1195428, meanQ=6.222208, numObservations: 4
action 2, numVisits=175, meanQ=5.646575, numObservations: 3
action -1, numVisits=95, meanQ=5.460917, numObservations: 1
action 0, numVisits=81, meanQ=5.392397, numObservations: 1
action 1, numVisits=17, meanQ=4.346471, numObservations: 3
action: 3
Next state: 1 0.675704 0.865247 0.37113 0.483404 0.545615 0.813496 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 284
Initial state: 0 0.532349 0.80153 0.234276 0.844521 0.581856 0.842565 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1199486 episodes
GETTING ACTION FROM:
action 1, numVisits=1199473, meanQ=6.218986, numObservations: 4
action 3, numVisits=7, meanQ=3.284300, numObservations: 3
action 2, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.532349 0.80153 0.234276 0.844521 0.581856 0.842565 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 285
Initial state: 0 0.55698 0.698625 0.540561 0.890377 0.629125 0.882487 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1190195 episodes
GETTING ACTION FROM:
action 2, numVisits=1190180, meanQ=6.239567, numObservations: 5
action 1, numVisits=9, meanQ=3.553344, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.55698 0.698625 0.540561 0.890377 0.629125 0.882487 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 286
Initial state: 0 0.647103 0.841937 0.523986 0.89156 0.855782 0.28577 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1209787 episodes
GETTING ACTION FROM:
action 1, numVisits=1209736, meanQ=6.217811, numObservations: 3
action 0, numVisits=43, meanQ=5.036429, numObservations: 1
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.647103 0.841937 0.523986 0.89156 0.855782 0.28577 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 287
Initial state: 0 0.320604 0.31437 0.675297 0.841997 0.661771 0.812802 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1184408 episodes
GETTING ACTION FROM:
action 2, numVisits=1161614, meanQ=6.239687, numObservations: 5
action 1, numVisits=22725, meanQ=6.195656, numObservations: 5
action -1, numVisits=64, meanQ=5.303898, numObservations: 1
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.320604 0.31437 0.675297 0.841997 0.661771 0.812802 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 288
Initial state: 0 0.432569 0.254141 0.555781 0.878511 0.606704 0.828799 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1187836 episodes
GETTING ACTION FROM:
action 2, numVisits=1187728, meanQ=6.239241, numObservations: 5
action 0, numVisits=55, meanQ=5.236585, numObservations: 1
action -1, numVisits=49, meanQ=5.168664, numObservations: 1
action 1, numVisits=2, meanQ=-0.010000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 2
Next state: 1 0.432569 0.254141 0.555781 0.878511 0.606704 0.828799 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 289
Initial state: 0 0.698436 0.837651 0.646484 0.855458 0.657643 0.845762 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1211673 episodes
GETTING ACTION FROM:
action 1, numVisits=1211653, meanQ=6.227986, numObservations: 3
action -1, numVisits=8, meanQ=3.567512, numObservations: 1
action 2, numVisits=6, meanQ=2.333333, numObservations: 2
action 3, numVisits=4, meanQ=1.747500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.698436 0.837651 0.646484 0.855458 0.657643 0.845762 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 290
Initial state: 0 0.794773 0.339874 0.564522 0.880958 0.662938 0.802665 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1198874 episodes
GETTING ACTION FROM:
action 3, numVisits=1198748, meanQ=6.229763, numObservations: 4
action 1, numVisits=115, meanQ=5.502437, numObservations: 5
action 2, numVisits=7, meanQ=1.995743, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.794773 0.339874 0.564522 0.880958 0.662938 0.802665 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 291
Initial state: 0 0.585226 0.048854 0.655067 0.841538 0.538607 0.884821 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1201065 episodes
GETTING ACTION FROM:
action 1, numVisits=1201047, meanQ=6.239815, numObservations: 4
action 0, numVisits=13, meanQ=4.155640, numObservations: 1
action 3, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.585226 0.048854 0.655067 0.841538 0.538607 0.884821 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=134982, meanQ=8.858765, numObservations: 4
action 3, numVisits=60474, meanQ=8.849157, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1477278 episodes
GETTING ACTION FROM:
action 2, numVisits=974043, meanQ=6.608447, numObservations: 4
action 3, numVisits=698691, meanQ=6.607244, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.585226 0.048854 0.655067 0.841538 0.538607 0.884821 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 292
Initial state: 0 0.567954 0.80196 0.988507 0.482814 0.583953 0.830277 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1192721 episodes
GETTING ACTION FROM:
action 2, numVisits=1192707, meanQ=6.324166, numObservations: 5
action 1, numVisits=7, meanQ=0.428571, numObservations: 3
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.567954 0.80196 0.988507 0.482814 0.583953 0.830277 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 293
Initial state: 0 0.964708 0.439407 0.606803 0.888505 0.656368 0.809314 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1182196 episodes
GETTING ACTION FROM:
action 1, numVisits=1182125, meanQ=6.236434, numObservations: 5
action 3, numVisits=48, meanQ=5.014173, numObservations: 5
action 0, numVisits=18, meanQ=4.422060, numObservations: 1
action 2, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.964708 0.439407 0.606803 0.888505 0.656368 0.809314 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 294
Initial state: 0 0.269174 0.764234 0.584144 0.875245 0.686728 0.855333 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1218345 episodes
GETTING ACTION FROM:
action 2, numVisits=1218338, meanQ=6.183747, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.269174 0.764234 0.584144 0.875245 0.686728 0.855333 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 295
Initial state: 0 0.619214 0.827879 0.694111 0.805013 0.447827 0.886125 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1191755 episodes
GETTING ACTION FROM:
action 1, numVisits=1191749, meanQ=6.195884, numObservations: 5
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.619214 0.827879 0.694111 0.805013 0.447827 0.886125 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 296
Initial state: 0 0.690966 0.899894 0.441024 0.663903 0.545621 0.817752 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1168597 episodes
GETTING ACTION FROM:
action 1, numVisits=1168541, meanQ=6.222042, numObservations: 4
action -1, numVisits=27, meanQ=4.748808, numObservations: 1
action 3, numVisits=23, meanQ=4.117830, numObservations: 5
action 2, numVisits=4, meanQ=1.475000, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 1
Next state: 1 0.690966 0.899894 0.441024 0.663903 0.545621 0.817752 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 297
Initial state: 0 0.639618 0.800248 0.600447 0.862322 0.566482 0.436138 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1215741 episodes
GETTING ACTION FROM:
action 3, numVisits=1215681, meanQ=6.228853, numObservations: 3
action 1, numVisits=22, meanQ=4.454545, numObservations: 3
action 2, numVisits=23, meanQ=4.260004, numObservations: 3
action -1, numVisits=13, meanQ=3.986354, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.639618 0.800248 0.600447 0.862322 0.566482 0.436138 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=118572, meanQ=8.864773, numObservations: 4
action 1, numVisits=78088, meanQ=8.860547, numObservations: 4
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1458867 episodes
GETTING ACTION FROM:
action 2, numVisits=913588, meanQ=6.814416, numObservations: 4
action 1, numVisits=741938, meanQ=6.813581, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 2
Next state: 1 0.639618 0.800248 0.600447 0.862322 0.566482 0.436138 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 298
Initial state: 0 0.416297 0.521847 0.584555 0.84932 0.507483 0.857357 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1192183 episodes
GETTING ACTION FROM:
action 3, numVisits=1192059, meanQ=6.236051, numObservations: 5
action -1, numVisits=89, meanQ=5.446752, numObservations: 1
action 1, numVisits=32, meanQ=4.701259, numObservations: 3
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.416297 0.521847 0.584555 0.84932 0.507483 0.857357 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 299
Initial state: 0 0.670494 0.833808 0.594902 0.236606 0.593669 0.823293 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1213828 episodes
GETTING ACTION FROM:
action 1, numVisits=1213762, meanQ=6.233417, numObservations: 3
action 3, numVisits=53, meanQ=4.932645, numObservations: 4
action 2, numVisits=9, meanQ=3.554444, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.670494 0.833808 0.594902 0.236606 0.593669 0.823293 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 300
Initial state: 0 0.02201 0.401933 0.555644 0.800909 0.525088 0.829061 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1186908 episodes
GETTING ACTION FROM:
action 3, numVisits=1161302, meanQ=6.231553, numObservations: 5
action 1, numVisits=25527, meanQ=6.183667, numObservations: 4
action -1, numVisits=73, meanQ=5.359726, numObservations: 1
action 2, numVisits=4, meanQ=-1.002475, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 3
Next state: 1 0.02201 0.401933 0.555644 0.800909 0.525088 0.829061 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 301
Initial state: 0 0.34303 0.190656 0.656837 0.834102 0.641172 0.835279 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1188613 episodes
GETTING ACTION FROM:
action 2, numVisits=1187502, meanQ=6.220343, numObservations: 5
action 3, numVisits=984, meanQ=5.984210, numObservations: 4
action 1, numVisits=65, meanQ=5.274002, numObservations: 3
action 0, numVisits=60, meanQ=5.260141, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.34303 0.190656 0.656837 0.834102 0.641172 0.835279 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 302
Initial state: 0 0.547773 0.815658 0.266182 0.165604 0.616254 0.871163 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1190847 episodes
GETTING ACTION FROM:
action 1, numVisits=1190628, meanQ=6.233793, numObservations: 5
action 2, numVisits=156, meanQ=5.626348, numObservations: 5
action -1, numVisits=60, meanQ=5.271915, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.547773 0.815658 0.266182 0.165604 0.616254 0.871163 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 303
Initial state: 0 0.916571 0.911211 0.611041 0.801687 0.636327 0.865753 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 904197 episodes
GETTING ACTION FROM:
action 3, numVisits=269029, meanQ=6.229110, numObservations: 4
action -1, numVisits=635164, meanQ=4.160285, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.916571 0.911211 0.611041 0.801687 0.636327 0.865753 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=9671, meanQ=6.566369, numObservations: 4
action 3, numVisits=2436, meanQ=5.461578, numObservations: 4
action 1, numVisits=10, meanQ=3.089000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1487715 episodes
GETTING ACTION FROM:
action 2, numVisits=1497384, meanQ=6.421518, numObservations: 4
action 3, numVisits=2436, meanQ=5.461578, numObservations: 4
action 1, numVisits=10, meanQ=3.089000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 2
Next state: 1 0.916571 0.911211 0.611041 0.801687 0.636327 0.865753 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 304
Initial state: 0 0.565045 0.889263 0.663483 0.862285 0.569985 0.0477954 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1201766 episodes
GETTING ACTION FROM:
action 2, numVisits=1190137, meanQ=6.234798, numObservations: 4
action 1, numVisits=11624, meanQ=6.167471, numObservations: 4
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.565045 0.889263 0.663483 0.862285 0.569985 0.0477954 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 305
Initial state: 0 0.603614 0.861904 0.0700462 0.651993 0.634285 0.852689 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1187040 episodes
GETTING ACTION FROM:
action 1, numVisits=1186897, meanQ=6.246348, numObservations: 5
action 3, numVisits=112, meanQ=4.766251, numObservations: 4
action 2, numVisits=27, meanQ=4.624819, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.603614 0.861904 0.0700462 0.651993 0.634285 0.852689 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 306
Initial state: 0 0.207795 0.233157 0.636443 0.86971 0.598769 0.823553 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1190399 episodes
GETTING ACTION FROM:
action 2, numVisits=1190381, meanQ=6.218921, numObservations: 5
action 1, numVisits=11, meanQ=3.633655, numObservations: 3
action 3, numVisits=3, meanQ=-0.670000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.207795 0.233157 0.636443 0.86971 0.598769 0.823553 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 307
Initial state: 0 0.578269 0.693476 0.657167 0.809019 0.594633 0.825784 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1190889 episodes
GETTING ACTION FROM:
action 3, numVisits=1190868, meanQ=6.237292, numObservations: 4
action 2, numVisits=16, meanQ=2.185637, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.578269 0.693476 0.657167 0.809019 0.594633 0.825784 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 308
Initial state: 0 0.634958 0.845714 0.582268 0.854797 0.18727 0.00424868 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1200342 episodes
GETTING ACTION FROM:
action 1, numVisits=1200334, meanQ=6.234114, numObservations: 4
action 3, numVisits=3, meanQ=-0.670000, numObservations: 1
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.634958 0.845714 0.582268 0.854797 0.18727 0.00424868 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 309
Initial state: 0 0.831446 0.156994 0.572423 0.826913 0.522996 0.874944 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1186194 episodes
GETTING ACTION FROM:
action 3, numVisits=1186128, meanQ=6.217917, numObservations: 5
action 0, numVisits=47, meanQ=5.131386, numObservations: 1
action -1, numVisits=15, meanQ=4.170832, numObservations: 1
action 2, numVisits=2, meanQ=-0.010000, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action: 3
Next state: 1 0.831446 0.156994 0.572423 0.826913 0.522996 0.874944 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 310
Initial state: 0 0.591937 0.821077 0.618351 0.870014 0.489938 0.229668 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1196869 episodes
GETTING ACTION FROM:
action 3, numVisits=1196839, meanQ=6.228238, numObservations: 4
action 0, numVisits=24, meanQ=4.678423, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 1, numVisits=2, meanQ=-5.505000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.591937 0.821077 0.618351 0.870014 0.489938 0.229668 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=193717, meanQ=8.859656, numObservations: 4
action 2, numVisits=14, meanQ=6.850000, numObservations: 3
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1471229 episodes
GETTING ACTION FROM:
action 1, numVisits=1664369, meanQ=6.645082, numObservations: 4
action 2, numVisits=579, meanQ=6.332332, numObservations: 5
action 3, numVisits=13, meanQ=3.691538, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 0 0.591937 0.821077 0.618351 0.870014 0.489938 0.229668 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=11757, meanQ=8.244600, numObservations: 5
action 1, numVisits=8080, meanQ=8.231042, numObservations: 4
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1477768 episodes
GETTING ACTION FROM:
action 2, numVisits=1403325, meanQ=6.542967, numObservations: 5
action 1, numVisits=94279, meanQ=6.524672, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 2
Next state: 1 0.591937 0.821077 0.618351 0.870014 0.489938 0.229668 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.8309
Run # 311
Initial state: 0 0.658052 0.88918 0.02962 0.815523 0.609066 0.83051 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 804511 episodes
GETTING ACTION FROM:
action -1, numVisits=804503, meanQ=4.172913, numObservations: 1
action 1, numVisits=3, meanQ=-0.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.658052 0.88918 0.02962 0.815523 0.609066 0.83051 w: 1
Observation: 0 0.609285 0 0 0 0.680552 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=717026, meanQ=6.242391, numObservations: 5
action 3, numVisits=87461, meanQ=6.194230, numObservations: 5
action 2, numVisits=11, meanQ=3.725455, numObservations: 3
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
Sampled 1269668 episodes
GETTING ACTION FROM:
action 1, numVisits=1986694, meanQ=6.441926, numObservations: 5
action 3, numVisits=87461, meanQ=6.194230, numObservations: 5
action 2, numVisits=11, meanQ=3.725455, numObservations: 3
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 1
Next state: 1 0.658052 0.88918 0.02962 0.815523 0.609066 0.83051 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 312
Initial state: 0 0.514543 0.850488 0.320338 0.426217 0.554683 0.863784 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1194803 episodes
GETTING ACTION FROM:
action 2, numVisits=1194779, meanQ=6.232294, numObservations: 5
action -1, numVisits=10, meanQ=3.673693, numObservations: 1
action 3, numVisits=11, meanQ=2.726364, numObservations: 3
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.514543 0.850488 0.320338 0.426217 0.554683 0.863784 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=120019, meanQ=8.870172, numObservations: 4
action 3, numVisits=44305, meanQ=8.857134, numObservations: 3
action 2, numVisits=13, meanQ=6.775385, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1481213 episodes
GETTING ACTION FROM:
action 1, numVisits=1162882, meanQ=6.555275, numObservations: 4
action 3, numVisits=482616, meanQ=6.551352, numObservations: 3
action 2, numVisits=52, meanQ=5.262115, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.514543 0.850488 0.320338 0.426217 0.554683 0.863784 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 313
Initial state: 0 0.364025 0.440319 0.689881 0.820964 0.643362 0.88446 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1182458 episodes
GETTING ACTION FROM:
action 1, numVisits=1182389, meanQ=6.230086, numObservations: 5
action -1, numVisits=38, meanQ=5.013501, numObservations: 1
action 3, numVisits=27, meanQ=4.426670, numObservations: 4
action 2, numVisits=2, meanQ=-1.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.364025 0.440319 0.689881 0.820964 0.643362 0.88446 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=88540, meanQ=8.878593, numObservations: 4
action 3, numVisits=74396, meanQ=8.876103, numObservations: 4
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1464127 episodes
GETTING ACTION FROM:
action 2, numVisits=1425934, meanQ=7.074776, numObservations: 4
action 3, numVisits=201128, meanQ=7.064166, numObservations: 4
action 1, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.364025 0.440319 0.689881 0.820964 0.643362 0.88446 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 314
Initial state: 0 0.621016 0.865259 0.674125 0.500739 0.666031 0.830941 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1188794 episodes
GETTING ACTION FROM:
action 1, numVisits=1188788, meanQ=6.242496, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.621016 0.865259 0.674125 0.500739 0.666031 0.830941 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 315
Initial state: 0 0.661009 0.868639 0.452373 0.411679 0.515853 0.853193 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1200557 episodes
GETTING ACTION FROM:
action 3, numVisits=1200493, meanQ=6.249219, numObservations: 4
action -1, numVisits=51, meanQ=5.196479, numObservations: 1
action 0, numVisits=10, meanQ=3.757345, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.661009 0.868639 0.452373 0.411679 0.515853 0.853193 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 316
Initial state: 0 0.509421 0.840566 0.968983 0.395373 0.659846 0.867335 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1204710 episodes
GETTING ACTION FROM:
action 2, numVisits=1204702, meanQ=6.224460, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.509421 0.840566 0.968983 0.395373 0.659846 0.867335 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 317
Initial state: 0 0.614741 0.861379 0.550906 0.148725 0.688655 0.801292 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1196169 episodes
GETTING ACTION FROM:
action 3, numVisits=1196159, meanQ=6.242585, numObservations: 4
action 2, numVisits=5, meanQ=1.196020, numObservations: 3
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.614741 0.861379 0.550906 0.148725 0.688655 0.801292 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 318
Initial state: 0 0.689756 0.199198 0.572256 0.875576 0.66095 0.838271 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1191219 episodes
GETTING ACTION FROM:
action 1, numVisits=1191209, meanQ=6.186814, numObservations: 5
action 3, numVisits=5, meanQ=1.196020, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.689756 0.199198 0.572256 0.875576 0.66095 0.838271 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 319
Initial state: 0 0.800418 0.938933 0.638566 0.816254 0.508004 0.823359 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1198915 episodes
GETTING ACTION FROM:
action 3, numVisits=1198877, meanQ=6.237127, numObservations: 4
action 0, numVisits=20, meanQ=4.472563, numObservations: 1
action 1, numVisits=9, meanQ=3.553344, numObservations: 4
action 2, numVisits=7, meanQ=1.998571, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.800418 0.938933 0.638566 0.816254 0.508004 0.823359 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 320
Initial state: 0 0.615477 0.894046 0.739503 0.034242 0.502086 0.832618 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 811568 episodes
GETTING ACTION FROM:
action 0, numVisits=804851, meanQ=4.177983, numObservations: 1
action -1, numVisits=6709, meanQ=4.096129, numObservations: 1
action 2, numVisits=4, meanQ=-0.505000, numObservations: 3
action 1, numVisits=3, meanQ=-0.670000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.615477 0.894046 0.739503 0.034242 0.502086 0.832618 w: 1
Observation: 0 0 0.794857 0 0.0650601 0 0.902994 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=802344, meanQ=6.237335, numObservations: 4
action 3, numVisits=2463, meanQ=6.092255, numObservations: 4
action 1, numVisits=23, meanQ=4.643478, numObservations: 4
action 0, numVisits=18, meanQ=4.460242, numObservations: 1
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
Sampled 1292996 episodes
GETTING ACTION FROM:
action 2, numVisits=2095316, meanQ=6.226618, numObservations: 4
action 3, numVisits=2485, meanQ=6.074263, numObservations: 4
action 0, numVisits=19, meanQ=4.376284, numObservations: 1
action 1, numVisits=24, meanQ=3.991667, numObservations: 4
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 2
Next state: 2 0.615477 0.894046 0.739503 0.034242 0.502086 0.832618 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 321
Initial state: 0 0.67773 0.85159 0.695235 0.819422 0.102753 0.474502 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1196651 episodes
GETTING ACTION FROM:
action 3, numVisits=1196590, meanQ=6.247410, numObservations: 4
action -1, numVisits=34, meanQ=4.915757, numObservations: 1
action 1, numVisits=24, meanQ=4.040012, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.67773 0.85159 0.695235 0.819422 0.102753 0.474502 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=107614, meanQ=8.865664, numObservations: 3
action 2, numVisits=56719, meanQ=8.857475, numObservations: 3
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1482992 episodes
GETTING ACTION FROM:
action 1, numVisits=902604, meanQ=6.808172, numObservations: 3
action 2, numVisits=744604, meanQ=6.807405, numObservations: 3
action 3, numVisits=118, meanQ=6.090000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.67773 0.85159 0.695235 0.819422 0.102753 0.474502 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 322
Initial state: 0 0.57169 0.87109 0.652176 0.804377 0.276244 0.23863 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1182215 episodes
GETTING ACTION FROM:
action 1, numVisits=1182144, meanQ=6.226364, numObservations: 5
action 0, numVisits=39, meanQ=5.020879, numObservations: 1
action 3, numVisits=19, meanQ=4.209489, numObservations: 3
action 2, numVisits=11, meanQ=2.726364, numObservations: 3
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 1
Next state: 1 0.57169 0.87109 0.652176 0.804377 0.276244 0.23863 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 323
Initial state: 0 0.510054 0.829331 0.405772 0.429543 0.58188 0.867265 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1194163 episodes
GETTING ACTION FROM:
action 2, numVisits=1194126, meanQ=6.307952, numObservations: 5
action -1, numVisits=22, meanQ=4.632654, numObservations: 1
action 1, numVisits=11, meanQ=3.724555, numObservations: 5
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 2
Next state: 0 0.510054 0.829331 0.405772 0.429543 0.58188 0.867265 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=129954, meanQ=8.940108, numObservations: 3
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1474690 episodes
GETTING ACTION FROM:
action 1, numVisits=1600414, meanQ=6.634974, numObservations: 4
action 3, numVisits=4150, meanQ=6.522923, numObservations: 5
action 2, numVisits=82, meanQ=5.747073, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.510054 0.829331 0.405772 0.429543 0.58188 0.867265 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 324
Initial state: 0 0.617301 0.875147 0.620283 0.176052 0.677538 0.804611 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1197600 episodes
GETTING ACTION FROM:
action 1, numVisits=1197519, meanQ=6.246963, numObservations: 4
action -1, numVisits=75, meanQ=5.377374, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.617301 0.875147 0.620283 0.176052 0.677538 0.804611 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 325
Initial state: 0 0.97093 0.401238 0.508207 0.80361 0.675793 0.804799 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1191616 episodes
GETTING ACTION FROM:
action 2, numVisits=1191594, meanQ=6.228541, numObservations: 5
action -1, numVisits=15, meanQ=4.237412, numObservations: 1
action 3, numVisits=4, meanQ=-0.754975, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.97093 0.401238 0.508207 0.80361 0.675793 0.804799 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 326
Initial state: 0 0.837177 0.221835 0.665421 0.874562 0.634602 0.853808 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1185950 episodes
GETTING ACTION FROM:
action 2, numVisits=1185830, meanQ=6.219502, numObservations: 5
action -1, numVisits=92, meanQ=5.444199, numObservations: 1
action 3, numVisits=19, meanQ=4.361584, numObservations: 5
action 1, numVisits=7, meanQ=3.284300, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.837177 0.221835 0.665421 0.874562 0.634602 0.853808 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 327
Initial state: 0 0.539504 0.882588 0.322249 0.138479 0.571426 0.847003 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1183280 episodes
GETTING ACTION FROM:
action 2, numVisits=1178463, meanQ=6.239241, numObservations: 5
action 1, numVisits=4795, meanQ=6.135427, numObservations: 4
action 0, numVisits=13, meanQ=4.140170, numObservations: 1
action 3, numVisits=7, meanQ=3.284300, numObservations: 4
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 2
Next state: 0 0.539504 0.882588 0.322249 0.138479 0.571426 0.847003 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=83195, meanQ=8.873790, numObservations: 4
action 3, numVisits=78677, meanQ=8.873192, numObservations: 5
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1463333 episodes
GETTING ACTION FROM:
action 3, numVisits=1140029, meanQ=6.848414, numObservations: 5
action 1, numVisits=485175, meanQ=6.844542, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 1
action: 3
Next state: 1 0.539504 0.882588 0.322249 0.138479 0.571426 0.847003 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 328
Initial state: 0 0.66845 0.842034 0.530763 0.892663 0.00199439 0.771292 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1204041 episodes
GETTING ACTION FROM:
action 2, numVisits=1204020, meanQ=6.232149, numObservations: 4
action 3, numVisits=16, meanQ=3.998762, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.66845 0.842034 0.530763 0.892663 0.00199439 0.771292 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 329
Initial state: 0 0.142201 0.0757718 0.59968 0.866124 0.607802 0.804496 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1194406 episodes
GETTING ACTION FROM:
action 2, numVisits=1163173, meanQ=6.238490, numObservations: 5
action 3, numVisits=31121, meanQ=6.200608, numObservations: 4
action -1, numVisits=109, meanQ=5.521196, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.142201 0.0757718 0.59968 0.866124 0.607802 0.804496 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 330
Initial state: 0 0.510515 0.801166 0.620328 0.959401 0.662991 0.892719 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1193663 episodes
GETTING ACTION FROM:
action 3, numVisits=1193513, meanQ=6.233735, numObservations: 4
action 0, numVisits=79, meanQ=5.387955, numObservations: 1
action 2, numVisits=50, meanQ=5.017800, numObservations: 4
action -1, numVisits=17, meanQ=4.374893, numObservations: 1
action 1, numVisits=4, meanQ=1.747500, numObservations: 2
action: 3
Next state: 1 0.510515 0.801166 0.620328 0.959401 0.662991 0.892719 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 331
Initial state: 0 0.633002 0.894076 0.611642 0.825725 0.648439 0.541165 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1187411 episodes
GETTING ACTION FROM:
action 1, numVisits=1187218, meanQ=6.229941, numObservations: 5
action -1, numVisits=119, meanQ=5.542262, numObservations: 1
action 0, numVisits=66, meanQ=5.309632, numObservations: 1
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action 3, numVisits=4, meanQ=1.747500, numObservations: 3
action: 1
Next state: 1 0.633002 0.894076 0.611642 0.825725 0.648439 0.541165 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 332
Initial state: 0 0.667171 0.841834 0.565052 0.588669 0.518144 0.833434 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1214774 episodes
GETTING ACTION FROM:
action 2, numVisits=1214643, meanQ=6.230861, numObservations: 3
action -1, numVisits=123, meanQ=5.560209, numObservations: 1
action 3, numVisits=4, meanQ=1.475000, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 2
Next state: 0 0.667171 0.841834 0.565052 0.588669 0.518144 0.833434 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=197157, meanQ=8.861765, numObservations: 4
action 1, numVisits=65, meanQ=7.968465, numObservations: 4
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1467050 episodes
GETTING ACTION FROM:
action 3, numVisits=1663394, meanQ=6.607685, numObservations: 4
action 1, numVisits=877, meanQ=6.356830, numObservations: 5
action 2, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.667171 0.841834 0.565052 0.588669 0.518144 0.833434 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 333
Initial state: 0 0.565828 0.810933 0.674311 0.871857 0.833542 0.633349 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1188332 episodes
GETTING ACTION FROM:
action 1, numVisits=1188223, meanQ=6.228379, numObservations: 5
action -1, numVisits=38, meanQ=5.021286, numObservations: 1
action 0, numVisits=28, meanQ=4.798765, numObservations: 1
action 2, numVisits=39, meanQ=4.582056, numObservations: 4
action 3, numVisits=4, meanQ=1.747500, numObservations: 2
action: 1
Next state: 1 0.565828 0.810933 0.674311 0.871857 0.833542 0.633349 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 334
Initial state: 0 0.62202 0.870453 0.63371 0.0876068 0.620643 0.893186 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1201053 episodes
GETTING ACTION FROM:
action 2, numVisits=1201041, meanQ=6.171338, numObservations: 4
action 1, numVisits=6, meanQ=2.663333, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.62202 0.870453 0.63371 0.0876068 0.620643 0.893186 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 335
Initial state: 0 0.612752 0.838329 0.356641 0.186216 0.652278 0.81065 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1197603 episodes
GETTING ACTION FROM:
action 1, numVisits=1197590, meanQ=6.228023, numObservations: 4
action 2, numVisits=6, meanQ=2.333333, numObservations: 2
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.612752 0.838329 0.356641 0.186216 0.652278 0.81065 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 336
Initial state: 0 0.66576 0.857076 0.28608 0.661646 0.685166 0.806702 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1196940 episodes
GETTING ACTION FROM:
action 1, numVisits=1196874, meanQ=6.239387, numObservations: 4
action -1, numVisits=33, meanQ=4.938734, numObservations: 1
action 3, numVisits=29, meanQ=4.748286, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.66576 0.857076 0.28608 0.661646 0.685166 0.806702 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 337
Initial state: 0 0.555479 0.822102 0.984111 0.171432 0.657059 0.885945 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 880045 episodes
GETTING ACTION FROM:
action 3, numVisits=212199, meanQ=6.221674, numObservations: 4
action 0, numVisits=667842, meanQ=4.170191, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.555479 0.822102 0.984111 0.171432 0.657059 0.885945 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 338
Initial state: 0 0.514016 0.817379 0.390652 0.643667 0.617792 0.853725 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1192320 episodes
GETTING ACTION FROM:
action 3, numVisits=1192280, meanQ=6.230908, numObservations: 4
action -1, numVisits=24, meanQ=4.695959, numObservations: 1
action 1, numVisits=10, meanQ=3.000000, numObservations: 3
action 2, numVisits=4, meanQ=1.747500, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.514016 0.817379 0.390652 0.643667 0.617792 0.853725 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 339
Initial state: 0 0.650555 0.873462 0.684513 0.876639 0.232753 0.814392 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1206276 episodes
GETTING ACTION FROM:
action 2, numVisits=1206265, meanQ=6.232035, numObservations: 3
action 1, numVisits=4, meanQ=1.747500, numObservations: 3
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.650555 0.873462 0.684513 0.876639 0.232753 0.814392 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 340
Initial state: 0 0.62108 0.826423 0.783106 0.403386 0.607961 0.899705 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1195315 episodes
GETTING ACTION FROM:
action 1, numVisits=1195186, meanQ=6.307580, numObservations: 4
action 0, numVisits=82, meanQ=5.486293, numObservations: 2
action -1, numVisits=17, meanQ=4.461507, numObservations: 1
action 2, numVisits=28, meanQ=3.998939, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 1
Next state: 1 0.62108 0.826423 0.783106 0.403386 0.607961 0.899705 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 341
Initial state: 0 0.331899 0.764212 0.599886 0.877511 0.675871 0.807966 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1209530 episodes
GETTING ACTION FROM:
action 1, numVisits=1209446, meanQ=6.180123, numObservations: 3
action 0, numVisits=65, meanQ=5.248253, numObservations: 1
action 2, numVisits=13, meanQ=3.766931, numObservations: 4
action 3, numVisits=4, meanQ=1.747500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.331899 0.764212 0.599886 0.877511 0.675871 0.807966 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=138882, meanQ=8.861230, numObservations: 4
action 2, numVisits=57353, meanQ=8.853234, numObservations: 4
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1464048 episodes
GETTING ACTION FROM:
action 3, numVisits=886560, meanQ=6.853492, numObservations: 4
action 2, numVisits=773561, meanQ=6.852831, numObservations: 4
action 1, numVisits=163, meanQ=6.227486, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.331899 0.764212 0.599886 0.877511 0.675871 0.807966 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 342
Initial state: 0 0.631917 0.859453 0.636758 0.861006 0.368691 0.292635 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1187963 episodes
GETTING ACTION FROM:
action 1, numVisits=1187956, meanQ=6.238289, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.631917 0.859453 0.636758 0.861006 0.368691 0.292635 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 343
Initial state: 0 0.553925 0.852615 0.504558 0.830934 0.113359 0.750801 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1185893 episodes
GETTING ACTION FROM:
action 1, numVisits=1185803, meanQ=6.229942, numObservations: 5
action -1, numVisits=79, meanQ=5.392234, numObservations: 1
action 2, numVisits=7, meanQ=3.285714, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 1
Next state: 1 0.553925 0.852615 0.504558 0.830934 0.113359 0.750801 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 344
Initial state: 0 0.630928 0.8151 0.021754 0.905334 0.668806 0.880787 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1198342 episodes
GETTING ACTION FROM:
action 3, numVisits=1198265, meanQ=6.228019, numObservations: 4
action -1, numVisits=73, meanQ=5.344963, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.630928 0.8151 0.021754 0.905334 0.668806 0.880787 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 345
Initial state: 0 0.185442 0.595696 0.565204 0.824675 0.523504 0.888874 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1201927 episodes
GETTING ACTION FROM:
action 2, numVisits=1201871, meanQ=6.189752, numObservations: 4
action 0, numVisits=34, meanQ=4.894830, numObservations: 1
action 1, numVisits=19, meanQ=3.736321, numObservations: 3
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.185442 0.595696 0.565204 0.824675 0.523504 0.888874 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 346
Initial state: 0 0.533074 0.888731 0.0322955 0.964962 0.678215 0.805191 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1182834 episodes
GETTING ACTION FROM:
action 1, numVisits=1182578, meanQ=6.220435, numObservations: 5
action 2, numVisits=187, meanQ=5.675723, numObservations: 4
action -1, numVisits=59, meanQ=5.225331, numObservations: 1
action 3, numVisits=8, meanQ=2.872513, numObservations: 3
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 1
Next state: 1 0.533074 0.888731 0.0322955 0.964962 0.678215 0.805191 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 347
Initial state: 0 0.830494 0.140095 0.565862 0.894016 0.60419 0.876691 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1196579 episodes
GETTING ACTION FROM:
action 1, numVisits=1196571, meanQ=6.230158, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 2 0.830494 0.140095 0.565862 0.894016 0.60419 0.876691 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 348
Initial state: 0 0.539423 0.839014 0.143306 0.551121 0.57403 0.847618 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1208053 episodes
GETTING ACTION FROM:
action 1, numVisits=1208040, meanQ=6.242312, numObservations: 3
action 3, numVisits=7, meanQ=3.284300, numObservations: 2
action 2, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.539423 0.839014 0.143306 0.551121 0.57403 0.847618 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 349
Initial state: 0 0.66462 0.809911 0.785082 0.626834 0.643205 0.882069 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1202840 episodes
GETTING ACTION FROM:
action 3, numVisits=1202829, meanQ=6.229186, numObservations: 4
action 1, numVisits=4, meanQ=1.747500, numObservations: 3
action 2, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.66462 0.809911 0.785082 0.626834 0.643205 0.882069 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 350
Initial state: 0 0.655646 0.816136 0.0764824 0.658407 0.66552 0.872269 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1208780 episodes
GETTING ACTION FROM:
action 2, numVisits=1208773, meanQ=6.181943, numObservations: 4
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.655646 0.816136 0.0764824 0.658407 0.66552 0.872269 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=106722, meanQ=8.873848, numObservations: 4
action 3, numVisits=59457, meanQ=8.867436, numObservations: 4
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1473220 episodes
GETTING ACTION FROM:
action 3, numVisits=1079106, meanQ=6.814635, numObservations: 4
action 1, numVisits=560289, meanQ=6.811705, numObservations: 4
action 2, numVisits=5, meanQ=2.980000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.655646 0.816136 0.0764824 0.658407 0.66552 0.872269 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 351
Initial state: 0 0.677969 0.889363 0.609177 0.836023 0.432558 0.150873 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1199931 episodes
GETTING ACTION FROM:
action 2, numVisits=1199925, meanQ=6.238071, numObservations: 5
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.677969 0.889363 0.609177 0.836023 0.432558 0.150873 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 352
Initial state: 0 0.626028 0.886936 0.539838 0.837274 0.561001 0.355879 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1209804 episodes
GETTING ACTION FROM:
action 3, numVisits=1209703, meanQ=6.240150, numObservations: 3
action 0, numVisits=97, meanQ=5.476744, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.626028 0.886936 0.539838 0.837274 0.561001 0.355879 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 353
Initial state: 0 0.510699 0.134714 0.548798 0.882162 0.655194 0.840094 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1195782 episodes
GETTING ACTION FROM:
action 3, numVisits=1195773, meanQ=6.233597, numObservations: 4
action 2, numVisits=3, meanQ=-0.673300, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-5.505000, numObservations: 1
action: 3
Next state: 1 0.510699 0.134714 0.548798 0.882162 0.655194 0.840094 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 354
Initial state: 0 0.555197 0.142397 0.56606 0.898653 0.584755 0.875388 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1199598 episodes
GETTING ACTION FROM:
action 3, numVisits=1187257, meanQ=6.230771, numObservations: 4
action 1, numVisits=12283, meanQ=6.166418, numObservations: 5
action -1, numVisits=47, meanQ=5.144757, numObservations: 1
action 2, numVisits=9, meanQ=3.554444, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.555197 0.142397 0.56606 0.898653 0.584755 0.875388 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 355
Initial state: 0 0.805923 0.439255 0.650321 0.893925 0.615145 0.804007 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1185241 episodes
GETTING ACTION FROM:
action 1, numVisits=1185227, meanQ=6.226312, numObservations: 5
action 2, numVisits=8, meanQ=2.736263, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.805923 0.439255 0.650321 0.893925 0.615145 0.804007 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=52867, meanQ=6.502148, numObservations: 4
action 1, numVisits=7, meanQ=3.568571, numObservations: 2
action 3, numVisits=3, meanQ=2.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1477121 episodes
GETTING ACTION FROM:
action 2, numVisits=1529983, meanQ=6.433707, numObservations: 4
action 1, numVisits=7, meanQ=3.568571, numObservations: 2
action 3, numVisits=6, meanQ=2.333333, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 2
Next state: 1 0.805923 0.439255 0.650321 0.893925 0.615145 0.804007 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 356
Initial state: 0 0.67833 0.877942 0.326273 0.401435 0.660811 0.856561 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1180501 episodes
GETTING ACTION FROM:
action 1, numVisits=1180453, meanQ=6.235647, numObservations: 5
action -1, numVisits=34, meanQ=4.950626, numObservations: 1
action 3, numVisits=10, meanQ=1.197010, numObservations: 3
action 2, numVisits=2, meanQ=-0.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.67833 0.877942 0.326273 0.401435 0.660811 0.856561 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 357
Initial state: 0 0.580168 0.884579 0.542396 0.994302 0.606887 0.890843 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1197698 episodes
GETTING ACTION FROM:
action 1, numVisits=1182206, meanQ=6.228687, numObservations: 4
action 2, numVisits=15487, meanQ=6.151573, numObservations: 4
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.580168 0.884579 0.542396 0.994302 0.606887 0.890843 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 358
Initial state: 0 0.563666 0.863198 0.619879 0.881555 0.801692 0.41904 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1201331 episodes
GETTING ACTION FROM:
action 1, numVisits=1201297, meanQ=6.229310, numObservations: 4
action 3, numVisits=23, meanQ=4.303048, numObservations: 3
action 2, numVisits=7, meanQ=1.998571, numObservations: 3
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.563666 0.863198 0.619879 0.881555 0.801692 0.41904 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 359
Initial state: 0 0.624767 0.833523 0.0407155 0.440263 0.645712 0.884606 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1179813 episodes
GETTING ACTION FROM:
action 1, numVisits=1179764, meanQ=6.233584, numObservations: 5
action 0, numVisits=28, meanQ=4.776710, numObservations: 1
action 2, numVisits=8, meanQ=2.872513, numObservations: 4
action 3, numVisits=11, meanQ=2.725464, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.624767 0.833523 0.0407155 0.440263 0.645712 0.884606 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 360
Initial state: 0 0.693776 0.862415 0.518126 0.899597 0.800274 0.152318 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1199250 episodes
GETTING ACTION FROM:
action 3, numVisits=1199094, meanQ=6.187213, numObservations: 4
action 2, numVisits=84, meanQ=5.337383, numObservations: 5
action -1, numVisits=64, meanQ=5.238978, numObservations: 1
action 1, numVisits=6, meanQ=2.663333, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.693776 0.862415 0.518126 0.899597 0.800274 0.152318 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 361
Initial state: 0 0.640887 0.845102 0.692153 0.8689 0.949573 0.271419 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 865336 episodes
GETTING ACTION FROM:
action 3, numVisits=188236, meanQ=6.186659, numObservations: 4
action 0, numVisits=677096, meanQ=4.172904, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.640887 0.845102 0.692153 0.8689 0.949573 0.271419 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 362
Initial state: 0 0.535171 0.892027 0.51498 0.86317 0.108147 0.573776 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1217579 episodes
GETTING ACTION FROM:
action 2, numVisits=1217572, meanQ=6.218936, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.535171 0.892027 0.51498 0.86317 0.108147 0.573776 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 363
Initial state: 0 0.011908 0.0475012 0.685521 0.846505 0.52336 0.850996 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1161624 episodes
GETTING ACTION FROM:
action 3, numVisits=1161523, meanQ=6.147022, numObservations: 5
action -1, numVisits=35, meanQ=4.884290, numObservations: 1
action 1, numVisits=38, meanQ=4.875003, numObservations: 4
action 2, numVisits=26, meanQ=4.292696, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.011908 0.0475012 0.685521 0.846505 0.52336 0.850996 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 364
Initial state: 0 0.683809 0.817721 0.678588 0.84446 0.1243 0.354121 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1207322 episodes
GETTING ACTION FROM:
action 3, numVisits=1174038, meanQ=6.238336, numObservations: 3
action 2, numVisits=33246, meanQ=6.183256, numObservations: 5
action -1, numVisits=27, meanQ=4.776042, numObservations: 1
action 1, numVisits=9, meanQ=3.554444, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.683809 0.817721 0.678588 0.84446 0.1243 0.354121 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=162953, meanQ=8.860117, numObservations: 5
action 2, numVisits=27975, meanQ=8.835599, numObservations: 4
action 3, numVisits=3, meanQ=2.330033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1460928 episodes
GETTING ACTION FROM:
action 1, numVisits=1200521, meanQ=6.768737, numObservations: 5
action 2, numVisits=451335, meanQ=6.764357, numObservations: 4
action 3, numVisits=3, meanQ=2.330033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.683809 0.817721 0.678588 0.84446 0.1243 0.354121 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 365
Initial state: 0 0.697201 0.806527 0.21703 0.806772 0.58094 0.893908 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1184442 episodes
GETTING ACTION FROM:
action 1, numVisits=1184408, meanQ=6.236089, numObservations: 5
action -1, numVisits=23, meanQ=4.626306, numObservations: 1
action 3, numVisits=7, meanQ=1.997157, numObservations: 3
action 2, numVisits=2, meanQ=-1.004950, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 1
Next state: 1 0.697201 0.806527 0.21703 0.806772 0.58094 0.893908 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 366
Initial state: 0 0.829561 0.405181 0.610434 0.864112 0.505145 0.809521 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1198756 episodes
GETTING ACTION FROM:
action 2, numVisits=1198730, meanQ=6.229556, numObservations: 4
action 1, numVisits=21, meanQ=3.854776, numObservations: 3
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.829561 0.405181 0.610434 0.864112 0.505145 0.809521 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 367
Initial state: 0 0.673218 0.0225379 0.66889 0.814546 0.603792 0.855894 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1191728 episodes
GETTING ACTION FROM:
action 1, numVisits=1191722, meanQ=6.240281, numObservations: 5
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.673218 0.0225379 0.66889 0.814546 0.603792 0.855894 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=163802, meanQ=8.872992, numObservations: 3
action 3, numVisits=21, meanQ=6.760476, numObservations: 3
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1501753 episodes
GETTING ACTION FROM:
action 2, numVisits=1665379, meanQ=6.728211, numObservations: 3
action 3, numVisits=194, meanQ=6.179589, numObservations: 4
action 1, numVisits=4, meanQ=1.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.673218 0.0225379 0.66889 0.814546 0.603792 0.855894 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 368
Initial state: 0 0.546277 0.867621 0.551824 0.878059 0.403311 0.316335 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1179543 episodes
GETTING ACTION FROM:
action 3, numVisits=1087513, meanQ=6.241063, numObservations: 5
action 2, numVisits=92016, meanQ=6.211563, numObservations: 3
action 1, numVisits=10, meanQ=2.297000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.546277 0.867621 0.551824 0.878059 0.403311 0.316335 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=26753, meanQ=8.785590, numObservations: 4
action 2, numVisits=16, meanQ=7.186875, numObservations: 3
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1472913 episodes
GETTING ACTION FROM:
action 1, numVisits=1497898, meanQ=6.616032, numObservations: 4
action 2, numVisits=1783, meanQ=6.440875, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 1
action: 1
Next state: 1 0.546277 0.867621 0.551824 0.878059 0.403311 0.316335 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 369
Initial state: 0 0.650084 0.895061 0.618769 0.44817 0.515471 0.868867 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1181674 episodes
GETTING ACTION FROM:
action 3, numVisits=1181610, meanQ=6.243760, numObservations: 5
action 0, numVisits=50, meanQ=5.180576, numObservations: 1
action 2, numVisits=10, meanQ=3.198000, numObservations: 4
action 1, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.650084 0.895061 0.618769 0.44817 0.515471 0.868867 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 370
Initial state: 0 0.685397 0.872133 0.540362 0.940384 0.621555 0.898842 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1198749 episodes
GETTING ACTION FROM:
action 1, numVisits=1198662, meanQ=6.243481, numObservations: 4
action -1, numVisits=65, meanQ=5.316106, numObservations: 1
action 0, numVisits=20, meanQ=4.503217, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.685397 0.872133 0.540362 0.940384 0.621555 0.898842 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 371
Initial state: 0 0.54117 0.880606 0.528056 0.800342 0.517855 0.865337 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1195006 episodes
GETTING ACTION FROM:
action 2, numVisits=1194998, meanQ=6.225019, numObservations: 5
action 1, numVisits=2, meanQ=-0.010000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.54117 0.880606 0.528056 0.800342 0.517855 0.865337 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 372
Initial state: 0 0.159729 0.922607 0.633294 0.844334 0.690411 0.810152 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1188652 episodes
GETTING ACTION FROM:
action 3, numVisits=1188595, meanQ=6.174455, numObservations: 5
action 0, numVisits=47, meanQ=5.055810, numObservations: 1
action 1, numVisits=6, meanQ=2.663333, numObservations: 2
action 2, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.159729 0.922607 0.633294 0.844334 0.690411 0.810152 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 373
Initial state: 0 0.235777 0.40191 0.638422 0.836919 0.517675 0.805168 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1193289 episodes
GETTING ACTION FROM:
action 2, numVisits=1188853, meanQ=6.230971, numObservations: 5
action 3, numVisits=4428, meanQ=6.124126, numObservations: 5
action 1, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.235777 0.40191 0.638422 0.836919 0.517675 0.805168 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 374
Initial state: 0 0.647699 0.83288 0.582731 0.874562 0.658403 0.576516 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1196420 episodes
GETTING ACTION FROM:
action 1, numVisits=1196410, meanQ=6.229151, numObservations: 4
action 3, numVisits=5, meanQ=0.998020, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.647699 0.83288 0.582731 0.874562 0.658403 0.576516 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 375
Initial state: 0 0.876599 0.486467 0.5276 0.845783 0.514815 0.846488 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1202333 episodes
GETTING ACTION FROM:
action 3, numVisits=1202278, meanQ=6.238126, numObservations: 4
action 0, numVisits=50, meanQ=5.142425, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.876599 0.486467 0.5276 0.845783 0.514815 0.846488 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 376
Initial state: 0 0.217779 0.358113 0.550484 0.815151 0.607407 0.822898 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1188780 episodes
GETTING ACTION FROM:
action 1, numVisits=1188771, meanQ=6.230755, numObservations: 5
action 2, numVisits=2, meanQ=-0.010000, numObservations: 2
action 3, numVisits=3, meanQ=-0.670000, numObservations: 3
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.217779 0.358113 0.550484 0.815151 0.607407 0.822898 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=108034, meanQ=8.874176, numObservations: 4
action 2, numVisits=55713, meanQ=8.867363, numObservations: 5
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1461597 episodes
GETTING ACTION FROM:
action 2, numVisits=1123791, meanQ=6.795442, numObservations: 5
action 3, numVisits=501551, meanQ=6.791733, numObservations: 4
action 1, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.217779 0.358113 0.550484 0.815151 0.607407 0.822898 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 377
Initial state: 0 0.567124 0.876755 0.519213 0.847969 0.721477 0.687715 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 990206 episodes
GETTING ACTION FROM:
action 0, numVisits=478185, meanQ=6.430053, numObservations: 3
action 2, numVisits=509984, meanQ=6.231348, numObservations: 5
action 3, numVisits=2012, meanQ=6.075575, numObservations: 3
action -1, numVisits=20, meanQ=4.595809, numObservations: 1
action 1, numVisits=5, meanQ=1.178000, numObservations: 2
action: 0
Next state: 0 0.567124 0.876755 0.519213 0.847969 0.721477 0.687715 w: 1
Observation: 0 0 0.814235 0 0.756152 0 0.784006 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=163919, meanQ=8.482795, numObservations: 4
action 3, numVisits=4, meanQ=4.000000, numObservations: 3
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1304575 episodes
GETTING ACTION FROM:
action 1, numVisits=1468489, meanQ=6.533829, numObservations: 4
action 3, numVisits=9, meanQ=2.333333, numObservations: 3
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.567124 0.876755 0.519213 0.847969 0.721477 0.687715 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 378
Initial state: 0 0.448925 0.408109 0.632817 0.895222 0.605937 0.886992 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1185298 episodes
GETTING ACTION FROM:
action 1, numVisits=1185197, meanQ=6.233563, numObservations: 5
action -1, numVisits=47, meanQ=5.143395, numObservations: 1
action 0, numVisits=41, meanQ=5.057800, numObservations: 1
action 3, numVisits=7, meanQ=3.284300, numObservations: 2
action 2, numVisits=6, meanQ=2.333333, numObservations: 2
action: 1
Next state: 0 0.448925 0.408109 0.632817 0.895222 0.605937 0.886992 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=77863, meanQ=8.869202, numObservations: 4
action 2, numVisits=85206, meanQ=8.868819, numObservations: 3
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1488453 episodes
GETTING ACTION FROM:
action 2, numVisits=1028822, meanQ=6.693901, numObservations: 3
action 3, numVisits=622696, meanQ=6.691831, numObservations: 4
action 1, numVisits=5, meanQ=1.396000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.448925 0.408109 0.632817 0.895222 0.605937 0.886992 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 379
Initial state: 0 0.577195 0.893918 0.301966 0.746373 0.60057 0.85524 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1205995 episodes
GETTING ACTION FROM:
action 2, numVisits=1205976, meanQ=6.234952, numObservations: 4
action 1, numVisits=12, meanQ=3.990017, numObservations: 2
action 3, numVisits=3, meanQ=-0.670000, numObservations: 3
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.577195 0.893918 0.301966 0.746373 0.60057 0.85524 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=131346, meanQ=8.938783, numObservations: 3
action 1, numVisits=4, meanQ=3.997525, numObservations: 3
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1475980 episodes
GETTING ACTION FROM:
action 3, numVisits=1607223, meanQ=6.665881, numObservations: 4
action 1, numVisits=106, meanQ=5.801606, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 1
action: 3
Next state: 1 0.577195 0.893918 0.301966 0.746373 0.60057 0.85524 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 380
Initial state: 0 0.463563 0.803759 0.526443 0.895951 0.584936 0.861283 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1201118 episodes
GETTING ACTION FROM:
action 3, numVisits=1201085, meanQ=6.241600, numObservations: 4
action 1, numVisits=27, meanQ=4.793704, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.463563 0.803759 0.526443 0.895951 0.584936 0.861283 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=53865, meanQ=6.528385, numObservations: 5
action 3, numVisits=5, meanQ=1.396000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1454322 episodes
GETTING ACTION FROM:
action 1, numVisits=1508185, meanQ=6.512603, numObservations: 5
action 3, numVisits=5, meanQ=1.396000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 1
Next state: 0 0.463563 0.803759 0.526443 0.895951 0.584936 0.861283 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=1947, meanQ=8.557404, numObservations: 5
action 3, numVisits=1224, meanQ=8.504158, numObservations: 4
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1479110 episodes
GETTING ACTION FROM:
action 2, numVisits=1450748, meanQ=6.117457, numObservations: 5
action 3, numVisits=31523, meanQ=6.080281, numObservations: 5
action 1, numVisits=9, meanQ=3.554444, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 2
Next state: 1 0.463563 0.803759 0.526443 0.895951 0.584936 0.861283 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.8309
Run # 381
Initial state: 0 0.697216 0.87746 0.876835 0.440976 0.643856 0.800551 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1201047 episodes
GETTING ACTION FROM:
action 3, numVisits=587199, meanQ=6.241581, numObservations: 3
action 2, numVisits=613747, meanQ=6.230850, numObservations: 5
action -1, numVisits=87, meanQ=5.435813, numObservations: 1
action 1, numVisits=12, meanQ=3.999175, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.697216 0.87746 0.876835 0.440976 0.643856 0.800551 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 382
Initial state: 0 0.597766 0.895036 0.680821 0.886547 0.819809 0.0806398 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1203588 episodes
GETTING ACTION FROM:
action 1, numVisits=1203579, meanQ=6.220384, numObservations: 4
action 3, numVisits=4, meanQ=1.747500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.597766 0.895036 0.680821 0.886547 0.819809 0.0806398 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 383
Initial state: 0 0.662674 0.344509 0.503136 0.872471 0.582048 0.888938 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1201307 episodes
GETTING ACTION FROM:
action 1, numVisits=1201187, meanQ=6.235867, numObservations: 4
action -1, numVisits=75, meanQ=5.368767, numObservations: 1
action 3, numVisits=23, meanQ=4.651743, numObservations: 3
action 0, numVisits=16, meanQ=4.330472, numObservations: 1
action 2, numVisits=6, meanQ=2.663333, numObservations: 3
action: 1
Next state: 0 0.662674 0.344509 0.503136 0.872471 0.582048 0.888938 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=133251, meanQ=8.865397, numObservations: 4
action 3, numVisits=61587, meanQ=8.857531, numObservations: 3
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1469009 episodes
GETTING ACTION FROM:
action 2, numVisits=1436670, meanQ=7.033040, numObservations: 4
action 3, numVisits=227061, meanQ=7.023398, numObservations: 3
action 1, numVisits=117, meanQ=6.311368, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.662674 0.344509 0.503136 0.872471 0.582048 0.888938 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 384
Initial state: 0 0.576459 0.239204 0.691677 0.897406 0.546002 0.832253 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1197782 episodes
GETTING ACTION FROM:
action 1, numVisits=1197754, meanQ=6.225882, numObservations: 4
action 0, numVisits=15, meanQ=4.189784, numObservations: 1
action 3, numVisits=9, meanQ=1.331122, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.576459 0.239204 0.691677 0.897406 0.546002 0.832253 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 385
Initial state: 0 0.616641 0.817012 0.45336 0.628022 0.623346 0.832565 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1202742 episodes
GETTING ACTION FROM:
action 3, numVisits=1202679, meanQ=6.229050, numObservations: 4
action 0, numVisits=31, meanQ=4.860542, numObservations: 1
action -1, numVisits=24, meanQ=4.687050, numObservations: 1
action 1, numVisits=7, meanQ=3.285714, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.616641 0.817012 0.45336 0.628022 0.623346 0.832565 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 386
Initial state: 0 0.624511 0.89596 0.493176 0.415541 0.572502 0.826658 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1202407 episodes
GETTING ACTION FROM:
action 2, numVisits=1202394, meanQ=6.230538, numObservations: 4
action 1, numVisits=7, meanQ=1.687143, numObservations: 3
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 2
Next state: 0 0.624511 0.89596 0.493176 0.415541 0.572502 0.826658 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=92478, meanQ=8.869157, numObservations: 5
action 3, numVisits=73455, meanQ=8.866193, numObservations: 3
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1459616 episodes
GETTING ACTION FROM:
action 1, numVisits=1159844, meanQ=6.707345, numObservations: 5
action 3, numVisits=465704, meanQ=6.703373, numObservations: 3
action 2, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.624511 0.89596 0.493176 0.415541 0.572502 0.826658 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 387
Initial state: 0 0.695139 0.880052 0.0360991 0.926073 0.63428 0.856454 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1211337 episodes
GETTING ACTION FROM:
action 3, numVisits=1211228, meanQ=6.182583, numObservations: 3
action 0, numVisits=85, meanQ=5.369034, numObservations: 2
action 1, numVisits=18, meanQ=1.770572, numObservations: 4
action 2, numVisits=4, meanQ=-0.505000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.695139 0.880052 0.0360991 0.926073 0.63428 0.856454 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 388
Initial state: 0 0.681866 0.813566 0.554353 0.866805 0.979299 0.769018 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1197725 episodes
GETTING ACTION FROM:
action 3, numVisits=1197690, meanQ=6.231829, numObservations: 4
action -1, numVisits=17, meanQ=4.275300, numObservations: 1
action 2, numVisits=15, meanQ=3.798007, numObservations: 3
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.681866 0.813566 0.554353 0.866805 0.979299 0.769018 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 389
Initial state: 0 0.509945 0.809491 0.767971 0.680749 0.597695 0.837736 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1205281 episodes
GETTING ACTION FROM:
action 1, numVisits=1121961, meanQ=6.230131, numObservations: 4
action 2, numVisits=83298, meanQ=6.202656, numObservations: 3
action -1, numVisits=11, meanQ=3.904195, numObservations: 1
action 3, numVisits=9, meanQ=3.554444, numObservations: 3
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.509945 0.809491 0.767971 0.680749 0.597695 0.837736 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 390
Initial state: 0 0.680392 0.80833 0.87018 0.995239 0.500027 0.842074 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1182519 episodes
GETTING ACTION FROM:
action 3, numVisits=1182444, meanQ=6.237326, numObservations: 5
action 2, numVisits=55, meanQ=5.138185, numObservations: 4
action 1, numVisits=16, meanQ=3.936269, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.680392 0.80833 0.87018 0.995239 0.500027 0.842074 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 391
Initial state: 0 0.675193 0.837715 0.608661 0.871312 0.787352 0.448981 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1188416 episodes
GETTING ACTION FROM:
action 2, numVisits=1188404, meanQ=6.176970, numObservations: 5
action 3, numVisits=7, meanQ=1.998571, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.675193 0.837715 0.608661 0.871312 0.787352 0.448981 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 392
Initial state: 0 0.643389 0.830538 0.641487 0.885565 0.911368 0.644602 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1199228 episodes
GETTING ACTION FROM:
action 1, numVisits=1199165, meanQ=6.290659, numObservations: 4
action -1, numVisits=51, meanQ=5.242533, numObservations: 1
action 2, numVisits=6, meanQ=2.333333, numObservations: 2
action 3, numVisits=4, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 1
Next state: 1 0.643389 0.830538 0.641487 0.885565 0.911368 0.644602 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 393
Initial state: 0 0.623903 0.880009 0.389431 0.17949 0.637344 0.83317 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1204266 episodes
GETTING ACTION FROM:
action 1, numVisits=1204216, meanQ=6.224167, numObservations: 3
action -1, numVisits=38, meanQ=5.002605, numObservations: 1
action 3, numVisits=9, meanQ=1.332222, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.623903 0.880009 0.389431 0.17949 0.637344 0.83317 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 394
Initial state: 0 0.587596 0.827276 0.642808 0.801246 0.132725 0.380884 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1181266 episodes
GETTING ACTION FROM:
action 3, numVisits=1181234, meanQ=6.225155, numObservations: 5
action 2, numVisits=15, meanQ=3.065340, numObservations: 4
action 1, numVisits=13, meanQ=2.998462, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.587596 0.827276 0.642808 0.801246 0.132725 0.380884 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=70155, meanQ=8.938747, numObservations: 3
action 1, numVisits=58197, meanQ=8.936281, numObservations: 3
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1480861 episodes
GETTING ACTION FROM:
action 2, numVisits=1113428, meanQ=6.601850, numObservations: 3
action 1, numVisits=495781, meanQ=6.598176, numObservations: 5
action 3, numVisits=5, meanQ=3.198000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.587596 0.827276 0.642808 0.801246 0.132725 0.380884 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 395
Initial state: 0 0.554541 0.806873 0.460246 0.939521 0.657543 0.832044 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1210988 episodes
GETTING ACTION FROM:
action 1, numVisits=1210456, meanQ=6.181047, numObservations: 3
action 2, numVisits=517, meanQ=5.849004, numObservations: 4
action 3, numVisits=11, meanQ=3.725455, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.554541 0.806873 0.460246 0.939521 0.657543 0.832044 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 396
Initial state: 0 0.652467 0.855526 0.578759 0.893642 0.366267 0.419163 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1197884 episodes
GETTING ACTION FROM:
action 1, numVisits=1197854, meanQ=6.237223, numObservations: 4
action 3, numVisits=20, meanQ=4.044500, numObservations: 3
action 2, numVisits=6, meanQ=2.331683, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.652467 0.855526 0.578759 0.893642 0.366267 0.419163 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 397
Initial state: 0 0.670821 0.337306 0.578271 0.867805 0.521565 0.837799 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1184559 episodes
GETTING ACTION FROM:
action 3, numVisits=1184546, meanQ=6.233205, numObservations: 5
action 1, numVisits=8, meanQ=3.121250, numObservations: 3
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.670821 0.337306 0.578271 0.867805 0.521565 0.837799 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 398
Initial state: 0 0.291151 0.0292548 0.518073 0.895475 0.550032 0.822292 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1196859 episodes
GETTING ACTION FROM:
action 3, numVisits=1196795, meanQ=6.225073, numObservations: 4
action -1, numVisits=54, meanQ=5.199755, numObservations: 1
action 2, numVisits=7, meanQ=3.285714, numObservations: 3
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.291151 0.0292548 0.518073 0.895475 0.550032 0.822292 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 399
Initial state: 0 0.390852 0.384841 0.585361 0.846314 0.509868 0.856024 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1198861 episodes
GETTING ACTION FROM:
action 1, numVisits=1198849, meanQ=6.221833, numObservations: 4
action 3, numVisits=7, meanQ=1.997157, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.390852 0.384841 0.585361 0.846314 0.509868 0.856024 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=29520, meanQ=8.820966, numObservations: 3
action 1, numVisits=3, meanQ=2.993333, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1487628 episodes
GETTING ACTION FROM:
action 2, numVisits=1517114, meanQ=6.516317, numObservations: 3
action 1, numVisits=35, meanQ=5.246000, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 2
Next state: 1 0.390852 0.384841 0.585361 0.846314 0.509868 0.856024 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 400
Initial state: 0 0.521232 0.803109 0.223549 0.58136 0.536589 0.881041 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1210869 episodes
GETTING ACTION FROM:
action 3, numVisits=1204132, meanQ=6.237235, numObservations: 3
action 1, numVisits=4966, meanQ=6.130115, numObservations: 4
action 2, numVisits=1728, meanQ=6.056642, numObservations: 5
action -1, numVisits=41, meanQ=5.031270, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.521232 0.803109 0.223549 0.58136 0.536589 0.881041 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 401
Initial state: 0 0.654565 0.842986 0.699866 0.85451 0.8086 0.573743 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1193846 episodes
GETTING ACTION FROM:
action 3, numVisits=1193826, meanQ=6.237460, numObservations: 4
action 2, numVisits=14, meanQ=3.207150, numObservations: 3
action 1, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.654565 0.842986 0.699866 0.85451 0.8086 0.573743 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 402
Initial state: 0 0.521667 0.891004 0.0571763 0.944786 0.586338 0.895861 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1184380 episodes
GETTING ACTION FROM:
action 3, numVisits=1179791, meanQ=6.230033, numObservations: 5
action 2, numVisits=4477, meanQ=6.116881, numObservations: 4
action -1, numVisits=54, meanQ=5.202533, numObservations: 1
action 0, numVisits=50, meanQ=5.159153, numObservations: 1
action 1, numVisits=8, meanQ=2.873750, numObservations: 2
action: 3
Next state: 1 0.521667 0.891004 0.0571763 0.944786 0.586338 0.895861 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 403
Initial state: 0 0.655666 0.698113 0.61111 0.860112 0.503021 0.82076 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1199547 episodes
GETTING ACTION FROM:
action 2, numVisits=1199471, meanQ=6.235572, numObservations: 5
action -1, numVisits=56, meanQ=5.232860, numObservations: 1
action 1, numVisits=10, meanQ=3.089000, numObservations: 3
action 3, numVisits=8, meanQ=2.872513, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.655666 0.698113 0.61111 0.860112 0.503021 0.82076 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 404
Initial state: 0 0.542912 0.859446 0.900736 0.446079 0.696615 0.813476 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1184141 episodes
GETTING ACTION FROM:
action 3, numVisits=1183208, meanQ=6.178478, numObservations: 5
action 2, numVisits=910, meanQ=5.936262, numObservations: 5
action 0, numVisits=17, meanQ=4.330255, numObservations: 1
action 1, numVisits=4, meanQ=1.747500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.542912 0.859446 0.900736 0.446079 0.696615 0.813476 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 405
Initial state: 0 0.62354 0.891545 0.691993 0.80637 0.053401 0.0533917 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1192640 episodes
GETTING ACTION FROM:
action 3, numVisits=1192572, meanQ=6.222266, numObservations: 5
action 1, numVisits=45, meanQ=4.999560, numObservations: 4
action 2, numVisits=19, meanQ=4.257374, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.62354 0.891545 0.691993 0.80637 0.053401 0.0533917 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=72781, meanQ=8.941386, numObservations: 3
action 1, numVisits=56508, meanQ=8.938382, numObservations: 3
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1472789 episodes
GETTING ACTION FROM:
action 1, numVisits=807074, meanQ=6.695465, numObservations: 3
action 2, numVisits=795003, meanQ=6.695154, numObservations: 5
action 3, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.62354 0.891545 0.691993 0.80637 0.053401 0.0533917 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 406
Initial state: 0 0.644428 0.862137 0.548518 0.523686 0.669787 0.841696 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1193600 episodes
GETTING ACTION FROM:
action 3, numVisits=1193582, meanQ=6.233779, numObservations: 4
action 2, numVisits=12, meanQ=3.249167, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.644428 0.862137 0.548518 0.523686 0.669787 0.841696 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 407
Initial state: 0 0.746875 0.302036 0.67539 0.852436 0.667899 0.887094 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1187308 episodes
GETTING ACTION FROM:
action 3, numVisits=1187278, meanQ=6.307309, numObservations: 5
action -1, numVisits=25, meanQ=4.791979, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.746875 0.302036 0.67539 0.852436 0.667899 0.887094 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 408
Initial state: 0 0.281113 0.466132 0.654083 0.855592 0.652032 0.803896 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1197470 episodes
GETTING ACTION FROM:
action 2, numVisits=1197460, meanQ=6.236071, numObservations: 4
action 3, numVisits=4, meanQ=1.747500, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.281113 0.466132 0.654083 0.855592 0.652032 0.803896 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 409
Initial state: 0 0.196958 0.61046 0.557436 0.826233 0.687847 0.80033 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1146866 episodes
GETTING ACTION FROM:
action 3, numVisits=1146739, meanQ=6.140139, numObservations: 5
action 0, numVisits=56, meanQ=5.118885, numObservations: 1
action -1, numVisits=49, meanQ=5.072872, numObservations: 1
action 2, numVisits=11, meanQ=2.725464, numObservations: 3
action 1, numVisits=11, meanQ=2.634564, numObservations: 3
action: 3
Next state: 1 0.196958 0.61046 0.557436 0.826233 0.687847 0.80033 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 410
Initial state: 0 0.699257 0.813871 0.682315 0.802586 0.87505 0.844457 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1199876 episodes
GETTING ACTION FROM:
action 1, numVisits=1199840, meanQ=6.237791, numObservations: 4
action 0, numVisits=23, meanQ=4.586153, numObservations: 1
action 2, numVisits=7, meanQ=1.998571, numObservations: 3
action 3, numVisits=4, meanQ=1.745025, numObservations: 3
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 1
Next state: 1 0.699257 0.813871 0.682315 0.802586 0.87505 0.844457 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 411
Initial state: 0 0.774587 0.887281 0.644871 0.871193 0.685335 0.817089 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1183829 episodes
GETTING ACTION FROM:
action 1, numVisits=1183808, meanQ=6.232614, numObservations: 5
action 3, numVisits=12, meanQ=4.000000, numObservations: 3
action 2, numVisits=5, meanQ=1.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.774587 0.887281 0.644871 0.871193 0.685335 0.817089 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 412
Initial state: 0 0.691429 0.868627 0.693361 0.0832372 0.58618 0.859274 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1184582 episodes
GETTING ACTION FROM:
action 3, numVisits=1184564, meanQ=6.232896, numObservations: 5
action 1, numVisits=7, meanQ=3.285714, numObservations: 2
action 2, numVisits=7, meanQ=3.284300, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.691429 0.868627 0.693361 0.0832372 0.58618 0.859274 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 413
Initial state: 0 0.744836 0.118893 0.642814 0.896106 0.696659 0.812473 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1198050 episodes
GETTING ACTION FROM:
action 1, numVisits=1197931, meanQ=6.238278, numObservations: 4
action 2, numVisits=91, meanQ=5.447364, numObservations: 3
action 3, numVisits=18, meanQ=4.055000, numObservations: 3
action 0, numVisits=8, meanQ=3.567512, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.744836 0.118893 0.642814 0.896106 0.696659 0.812473 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 414
Initial state: 0 0.597706 0.885372 0.58823 0.831207 0.550883 0.861734 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1209222 episodes
GETTING ACTION FROM:
action 1, numVisits=1206531, meanQ=6.238176, numObservations: 3
action 3, numVisits=2676, meanQ=6.095156, numObservations: 4
action 2, numVisits=11, meanQ=3.544555, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.597706 0.885372 0.58823 0.831207 0.550883 0.861734 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 415
Initial state: 0 0.699827 0.801411 0.650254 0.840158 0.313283 0.139676 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1188135 episodes
GETTING ACTION FROM:
action 1, numVisits=1188125, meanQ=6.232626, numObservations: 5
action 2, numVisits=4, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.699827 0.801411 0.650254 0.840158 0.313283 0.139676 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 416
Initial state: 0 0.696419 0.892568 0.668936 0.887671 0.0430494 0.259111 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 810735 episodes
GETTING ACTION FROM:
action -1, numVisits=810726, meanQ=4.158743, numObservations: 1
action 1, numVisits=3, meanQ=-0.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.696419 0.892568 0.668936 0.887671 0.0430494 0.259111 w: 1
Observation: 0 0.686172 0 0.755783 0 0.0523119 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=810701, meanQ=6.230777, numObservations: 4
action -1, numVisits=15, meanQ=4.172625, numObservations: 1
action 2, numVisits=6, meanQ=2.333333, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1282711 episodes
GETTING ACTION FROM:
action 1, numVisits=2093412, meanQ=6.207029, numObservations: 4
action -1, numVisits=15, meanQ=4.172625, numObservations: 1
action 2, numVisits=6, meanQ=2.333333, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.696419 0.892568 0.668936 0.887671 0.0430494 0.259111 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 417
Initial state: 0 0.499867 0.763396 0.572911 0.880255 0.543112 0.826746 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1181151 episodes
GETTING ACTION FROM:
action 3, numVisits=1181103, meanQ=6.182635, numObservations: 4
action -1, numVisits=40, meanQ=4.982055, numObservations: 1
action 2, numVisits=5, meanQ=1.396000, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.499867 0.763396 0.572911 0.880255 0.543112 0.826746 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 418
Initial state: 0 0.622776 0.83328 0.621973 0.85121 0.542742 0.138397 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1196036 episodes
GETTING ACTION FROM:
action 3, numVisits=1195908, meanQ=6.234071, numObservations: 4
action 0, numVisits=71, meanQ=5.333357, numObservations: 1
action -1, numVisits=49, meanQ=5.130201, numObservations: 1
action 1, numVisits=7, meanQ=3.285714, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.622776 0.83328 0.621973 0.85121 0.542742 0.138397 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=39446, meanQ=8.695453, numObservations: 4
action 1, numVisits=24698, meanQ=8.680791, numObservations: 4
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1470125 episodes
GETTING ACTION FROM:
action 2, numVisits=921109, meanQ=6.775747, numObservations: 4
action 1, numVisits=613158, meanQ=6.773889, numObservations: 4
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.622776 0.83328 0.621973 0.85121 0.542742 0.138397 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 419
Initial state: 0 0.592942 0.0107294 0.580974 0.859439 0.571587 0.897315 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1204993 episodes
GETTING ACTION FROM:
action 2, numVisits=1204951, meanQ=6.313857, numObservations: 4
action 0, numVisits=19, meanQ=4.441494, numObservations: 1
action 1, numVisits=19, meanQ=4.314221, numObservations: 3
action 3, numVisits=2, meanQ=-0.509950, numObservations: 1
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 2
Next state: 1 0.592942 0.0107294 0.580974 0.859439 0.571587 0.897315 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 420
Initial state: 0 0.618615 0.854305 0.519531 0.849623 0.079773 0.696704 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1201629 episodes
GETTING ACTION FROM:
action 2, numVisits=1201615, meanQ=6.230810, numObservations: 4
action 1, numVisits=9, meanQ=1.320011, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.618615 0.854305 0.519531 0.849623 0.079773 0.696704 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 421
Initial state: 0 0.918451 0.967325 0.647847 0.831585 0.591591 0.807278 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1187248 episodes
GETTING ACTION FROM:
action 2, numVisits=1187227, meanQ=6.237184, numObservations: 5
action 1, numVisits=14, meanQ=3.349286, numObservations: 4
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.918451 0.967325 0.647847 0.831585 0.591591 0.807278 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 422
Initial state: 0 0.535163 0.831426 0.643174 0.381398 0.622296 0.858972 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1202784 episodes
GETTING ACTION FROM:
action 3, numVisits=1202713, meanQ=6.187450, numObservations: 4
action -1, numVisits=32, meanQ=4.850067, numObservations: 1
action 0, numVisits=22, meanQ=4.588719, numObservations: 1
action 2, numVisits=15, meanQ=4.108667, numObservations: 3
action 1, numVisits=2, meanQ=-1.004950, numObservations: 1
action: 3
Next state: 1 0.535163 0.831426 0.643174 0.381398 0.622296 0.858972 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 423
Initial state: 0 0.447831 0.127087 0.59471 0.826546 0.618945 0.867469 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1190698 episodes
GETTING ACTION FROM:
action 2, numVisits=1190644, meanQ=6.312397, numObservations: 5
action 0, numVisits=50, meanQ=5.244373, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.447831 0.127087 0.59471 0.826546 0.618945 0.867469 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 424
Initial state: 0 0.658775 0.866767 0.0509111 0.271868 0.527416 0.841956 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1202508 episodes
GETTING ACTION FROM:
action 2, numVisits=1202454, meanQ=6.225345, numObservations: 4
action 0, numVisits=30, meanQ=4.860226, numObservations: 1
action 3, numVisits=18, meanQ=2.443333, numObservations: 5
action 1, numVisits=4, meanQ=1.747500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.658775 0.866767 0.0509111 0.271868 0.527416 0.841956 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=165506, meanQ=8.876257, numObservations: 4
action 3, numVisits=6, meanQ=5.666667, numObservations: 2
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1471591 episodes
GETTING ACTION FROM:
action 1, numVisits=1637090, meanQ=6.579475, numObservations: 4
action 3, numVisits=12, meanQ=4.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 1
Next state: 1 0.658775 0.866767 0.0509111 0.271868 0.527416 0.841956 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 425
Initial state: 0 0.517162 0.833319 0.892303 0.116007 0.608895 0.868476 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1188689 episodes
GETTING ACTION FROM:
action 3, numVisits=1188649, meanQ=6.229279, numObservations: 5
action 1, numVisits=34, meanQ=4.552362, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 3
Next state: 1 0.517162 0.833319 0.892303 0.116007 0.608895 0.868476 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 426
Initial state: 0 0.604736 0.83177 0.581163 0.806521 0.856537 0.870931 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1188316 episodes
GETTING ACTION FROM:
action 2, numVisits=1188289, meanQ=6.136642, numObservations: 3
action -1, numVisits=21, meanQ=4.380479, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 1, numVisits=2, meanQ=-1.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.604736 0.83177 0.581163 0.806521 0.856537 0.870931 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 427
Initial state: 0 0.570749 0.735034 0.508993 0.807733 0.614931 0.858226 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1189581 episodes
GETTING ACTION FROM:
action 2, numVisits=1189508, meanQ=6.234807, numObservations: 5
action 0, numVisits=63, meanQ=5.284035, numObservations: 1
action -1, numVisits=8, meanQ=3.567512, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.570749 0.735034 0.508993 0.807733 0.614931 0.858226 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 428
Initial state: 0 0.656253 0.888966 0.873885 0.652126 0.653528 0.812344 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1188468 episodes
GETTING ACTION FROM:
action 1, numVisits=1188385, meanQ=6.238669, numObservations: 5
action -1, numVisits=63, meanQ=5.295780, numObservations: 1
action 2, numVisits=7, meanQ=3.284300, numObservations: 3
action 3, numVisits=11, meanQ=2.627273, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.656253 0.888966 0.873885 0.652126 0.653528 0.812344 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 429
Initial state: 0 0.547865 0.818946 0.617732 0.801416 0.564593 0.329904 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1184975 episodes
GETTING ACTION FROM:
action 3, numVisits=1184933, meanQ=6.236300, numObservations: 5
action -1, numVisits=35, meanQ=4.955396, numObservations: 1
action 1, numVisits=4, meanQ=1.747500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.547865 0.818946 0.617732 0.801416 0.564593 0.329904 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 430
Initial state: 0 0.581268 0.806348 0.786429 0.173909 0.633857 0.840599 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1200147 episodes
GETTING ACTION FROM:
action 1, numVisits=1200134, meanQ=6.239705, numObservations: 4
action 2, numVisits=8, meanQ=1.611250, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.581268 0.806348 0.786429 0.173909 0.633857 0.840599 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 431
Initial state: 0 0.973376 0.853273 0.515618 0.815366 0.523172 0.810024 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1195992 episodes
GETTING ACTION FROM:
action 1, numVisits=1195886, meanQ=6.244004, numObservations: 4
action 0, numVisits=91, meanQ=5.456636, numObservations: 1
action -1, numVisits=12, meanQ=3.917244, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.973376 0.853273 0.515618 0.815366 0.523172 0.810024 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 432
Initial state: 0 0.528136 0.807308 0.60533 0.898435 0.183552 0.866182 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1210916 episodes
GETTING ACTION FROM:
action 3, numVisits=1210794, meanQ=6.225746, numObservations: 3
action 0, numVisits=78, meanQ=5.372011, numObservations: 1
action 1, numVisits=40, meanQ=4.662755, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 3
Next state: 0 0.528136 0.807308 0.60533 0.898435 0.183552 0.866182 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=196283, meanQ=8.860708, numObservations: 3
action 1, numVisits=13, meanQ=6.920769, numObservations: 3
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1490377 episodes
GETTING ACTION FROM:
action 2, numVisits=1686651, meanQ=7.051287, numObservations: 3
action 1, numVisits=20, meanQ=5.098505, numObservations: 3
action 3, numVisits=3, meanQ=2.330033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.528136 0.807308 0.60533 0.898435 0.183552 0.866182 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 433
Initial state: 0 0.630522 0.847828 0.721528 0.863179 0.572789 0.809817 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1188375 episodes
GETTING ACTION FROM:
action 3, numVisits=1188251, meanQ=6.234597, numObservations: 5
action -1, numVisits=105, meanQ=5.504174, numObservations: 1
action 2, numVisits=14, meanQ=4.134286, numObservations: 4
action 1, numVisits=3, meanQ=-0.670000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.630522 0.847828 0.721528 0.863179 0.572789 0.809817 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 434
Initial state: 0 0.685711 0.898655 0.602919 0.892438 0.152141 0.837706 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1203406 episodes
GETTING ACTION FROM:
action 2, numVisits=1203398, meanQ=6.232751, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 2
Next state: 1 0.685711 0.898655 0.602919 0.892438 0.152141 0.837706 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 435
Initial state: 0 0.549569 0.850046 0.0165055 0.522106 0.524642 0.803153 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1192076 episodes
GETTING ACTION FROM:
action 2, numVisits=1192038, meanQ=6.311529, numObservations: 5
action -1, numVisits=27, meanQ=4.872452, numObservations: 1
action 1, numVisits=8, meanQ=1.498763, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.549569 0.850046 0.0165055 0.522106 0.524642 0.803153 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=101892, meanQ=8.878975, numObservations: 4
action 1, numVisits=61664, meanQ=8.870925, numObservations: 4
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1475219 episodes
GETTING ACTION FROM:
action 1, numVisits=975828, meanQ=6.499555, numObservations: 4
action 3, numVisits=662943, meanQ=6.497761, numObservations: 4
action 2, numVisits=3, meanQ=-0.670000, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.549569 0.850046 0.0165055 0.522106 0.524642 0.803153 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 436
Initial state: 0 0.501564 0.877255 0.66602 0.814317 0.806264 0.598174 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1207356 episodes
GETTING ACTION FROM:
action 2, numVisits=1207295, meanQ=6.232195, numObservations: 4
action -1, numVisits=48, meanQ=5.151886, numObservations: 1
action 3, numVisits=7, meanQ=3.285714, numObservations: 3
action 1, numVisits=4, meanQ=-1.000000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.501564 0.877255 0.66602 0.814317 0.806264 0.598174 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 437
Initial state: 0 0.616649 0.131769 0.677027 0.814122 0.628211 0.808464 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1198204 episodes
GETTING ACTION FROM:
action 1, numVisits=1198192, meanQ=6.236078, numObservations: 4
action 2, numVisits=5, meanQ=1.396000, numObservations: 2
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 2 0.616649 0.131769 0.677027 0.814122 0.628211 0.808464 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 438
Initial state: 0 0.407506 0.0874287 0.521851 0.84326 0.6949 0.863059 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1194706 episodes
GETTING ACTION FROM:
action 2, numVisits=1194446, meanQ=6.230702, numObservations: 5
action -1, numVisits=127, meanQ=5.573073, numObservations: 1
action 1, numVisits=99, meanQ=5.422225, numObservations: 4
action 0, numVisits=33, meanQ=4.908336, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.407506 0.0874287 0.521851 0.84326 0.6949 0.863059 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 439
Initial state: 0 0.616066 0.87558 0.587328 0.867557 0.971963 0.748967 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1195309 episodes
GETTING ACTION FROM:
action 1, numVisits=1017839, meanQ=6.243614, numObservations: 4
action 2, numVisits=177464, meanQ=6.231922, numObservations: 4
action 3, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.616066 0.87558 0.587328 0.867557 0.971963 0.748967 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 440
Initial state: 0 0.544326 0.822764 0.501318 0.874408 0.421141 0.436329 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1205624 episodes
GETTING ACTION FROM:
action 2, numVisits=1205506, meanQ=6.168304, numObservations: 4
action -1, numVisits=73, meanQ=5.289646, numObservations: 1
action 0, numVisits=31, meanQ=4.813907, numObservations: 1
action 1, numVisits=13, meanQ=3.607692, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.544326 0.822764 0.501318 0.874408 0.421141 0.436329 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 441
Initial state: 0 0.5908 0.838905 0.661378 0.882694 0.646694 0.182789 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1188081 episodes
GETTING ACTION FROM:
action 1, numVisits=1188049, meanQ=6.325747, numObservations: 5
action -1, numVisits=27, meanQ=4.868505, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.5908 0.838905 0.661378 0.882694 0.646694 0.182789 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=44219, meanQ=8.215303, numObservations: 3
action 3, numVisits=3, meanQ=2.993333, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1448732 episodes
GETTING ACTION FROM:
action 3, numVisits=1253109, meanQ=6.417423, numObservations: 5
action 1, numVisits=239843, meanQ=6.219081, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 3
Next state: 2 0.5908 0.838905 0.661378 0.882694 0.646694 0.182789 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11.89
Run # 442
Initial state: 0 0.657633 0.871831 0.0801459 0.86744 0.541382 0.878632 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1196793 episodes
GETTING ACTION FROM:
action 2, numVisits=1196707, meanQ=6.190841, numObservations: 5
action -1, numVisits=47, meanQ=5.102083, numObservations: 1
action 0, numVisits=26, meanQ=4.720138, numObservations: 1
action 1, numVisits=6, meanQ=2.150017, numObservations: 2
action 3, numVisits=7, meanQ=1.998571, numObservations: 3
action: 2
Next state: 0 0.657633 0.871831 0.0801459 0.86744 0.541382 0.878632 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=29291, meanQ=8.754294, numObservations: 3
action 3, numVisits=100, meanQ=8.098802, numObservations: 4
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1481575 episodes
GETTING ACTION FROM:
action 3, numVisits=940160, meanQ=6.649225, numObservations: 4
action 1, numVisits=570802, meanQ=6.630317, numObservations: 3
action 2, numVisits=5, meanQ=1.396000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.657633 0.871831 0.0801459 0.86744 0.541382 0.878632 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 443
Initial state: 0 0.585355 0.885217 0.675194 0.882298 0.866394 0.171904 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1195397 episodes
GETTING ACTION FROM:
action 1, numVisits=1192094, meanQ=6.236327, numObservations: 4
action 2, numVisits=2329, meanQ=6.086236, numObservations: 4
action 3, numVisits=909, meanQ=5.993670, numObservations: 5
action 0, numVisits=63, meanQ=5.290107, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.585355 0.885217 0.675194 0.882298 0.866394 0.171904 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 444
Initial state: 0 0.531515 0.802985 0.615491 0.843163 0.837492 0.892245 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1161842 episodes
GETTING ACTION FROM:
action 2, numVisits=1161726, meanQ=6.149793, numObservations: 5
action 1, numVisits=99, meanQ=5.061414, numObservations: 4
action 3, numVisits=13, meanQ=3.843846, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.531515 0.802985 0.615491 0.843163 0.837492 0.892245 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 445
Initial state: 0 0.618289 0.858798 0.59343 0.817696 0.947439 0.32128 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1199437 episodes
GETTING ACTION FROM:
action 3, numVisits=1199355, meanQ=6.228904, numObservations: 4
action -1, numVisits=55, meanQ=5.204856, numObservations: 1
action 0, numVisits=23, meanQ=4.560509, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action: 3
Next state: 2 0.618289 0.858798 0.59343 0.817696 0.947439 0.32128 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 446
Initial state: 0 0.536079 0.842327 0.621334 0.886461 0.935325 0.347789 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1184730 episodes
GETTING ACTION FROM:
action 3, numVisits=1184717, meanQ=6.241848, numObservations: 5
action 2, numVisits=7, meanQ=1.998571, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 2 0.536079 0.842327 0.621334 0.886461 0.935325 0.347789 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 447
Initial state: 0 0.766608 0.20561 0.682569 0.838453 0.531152 0.850128 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1215076 episodes
GETTING ACTION FROM:
action 2, numVisits=1215042, meanQ=6.233747, numObservations: 3
action 0, numVisits=26, meanQ=4.755490, numObservations: 1
action 3, numVisits=4, meanQ=1.747500, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.766608 0.20561 0.682569 0.838453 0.531152 0.850128 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 448
Initial state: 0 0.693409 0.852687 0.420065 0.476393 0.531938 0.859929 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1206306 episodes
GETTING ACTION FROM:
action 2, numVisits=1206279, meanQ=6.236733, numObservations: 4
action -1, numVisits=23, meanQ=4.669841, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.693409 0.852687 0.420065 0.476393 0.531938 0.859929 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=126362, meanQ=8.866657, numObservations: 5
action 3, numVisits=68308, meanQ=8.858598, numObservations: 5
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1451973 episodes
GETTING ACTION FROM:
action 1, numVisits=1321013, meanQ=6.847334, numObservations: 5
action 3, numVisits=325625, meanQ=6.840568, numObservations: 5
action 2, numVisits=6, meanQ=2.331683, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.693409 0.852687 0.420065 0.476393 0.531938 0.859929 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 449
Initial state: 0 0.24934 0.968974 0.658814 0.89267 0.660707 0.88851 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1214867 episodes
GETTING ACTION FROM:
action 3, numVisits=1129998, meanQ=6.237520, numObservations: 3
action 1, numVisits=84864, meanQ=6.212941, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.24934 0.968974 0.658814 0.89267 0.660707 0.88851 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 450
Initial state: 0 0.391211 0.309509 0.639452 0.811092 0.50246 0.876173 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1188194 episodes
GETTING ACTION FROM:
action 1, numVisits=1188170, meanQ=6.240821, numObservations: 5
action 0, numVisits=16, meanQ=4.298641, numObservations: 1
action 2, numVisits=3, meanQ=-0.670000, numObservations: 2
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.391211 0.309509 0.639452 0.811092 0.50246 0.876173 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=164202, meanQ=8.869742, numObservations: 3
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1489404 episodes
GETTING ACTION FROM:
action 3, numVisits=1653603, meanQ=6.749767, numObservations: 3
action 2, numVisits=4, meanQ=1.747500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.391211 0.309509 0.639452 0.811092 0.50246 0.876173 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 451
Initial state: 0 0.613406 0.862512 0.541293 0.693222 0.644551 0.833058 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1199993 episodes
GETTING ACTION FROM:
action 2, numVisits=1199919, meanQ=6.226378, numObservations: 5
action -1, numVisits=38, meanQ=4.990821, numObservations: 1
action 0, numVisits=20, meanQ=4.507965, numObservations: 1
action 1, numVisits=14, meanQ=1.856436, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action: 2
Next state: 2 0.613406 0.862512 0.541293 0.693222 0.644551 0.833058 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 452
Initial state: 0 0.590808 0.801574 0.538243 0.836208 0.735005 0.776274 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1201781 episodes
GETTING ACTION FROM:
action 2, numVisits=1201730, meanQ=6.235795, numObservations: 4
action 0, numVisits=46, meanQ=5.105663, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.590808 0.801574 0.538243 0.836208 0.735005 0.776274 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 453
Initial state: 0 0.928474 0.189689 0.500363 0.839012 0.545224 0.888953 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1190404 episodes
GETTING ACTION FROM:
action 1, numVisits=1190287, meanQ=6.326185, numObservations: 5
action 0, numVisits=84, meanQ=5.513770, numObservations: 1
action -1, numVisits=31, meanQ=4.935112, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.928474 0.189689 0.500363 0.839012 0.545224 0.888953 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 454
Initial state: 0 0.519323 0.814843 0.59678 0.893812 0.620717 0.0826961 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1191856 episodes
GETTING ACTION FROM:
action 1, numVisits=1191812, meanQ=6.224166, numObservations: 4
action 3, numVisits=19, meanQ=3.262632, numObservations: 4
action 2, numVisits=21, meanQ=2.950952, numObservations: 5
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.519323 0.814843 0.59678 0.893812 0.620717 0.0826961 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 455
Initial state: 0 0.507738 0.857776 0.047274 0.374448 0.603298 0.884059 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1187733 episodes
GETTING ACTION FROM:
action 2, numVisits=1187697, meanQ=6.179917, numObservations: 5
action 1, numVisits=21, meanQ=4.332381, numObservations: 3
action 3, numVisits=11, meanQ=3.626364, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.507738 0.857776 0.047274 0.374448 0.603298 0.884059 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=29236, meanQ=8.775943, numObservations: 4
action 1, numVisits=71, meanQ=8.027889, numObservations: 4
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1471014 episodes
GETTING ACTION FROM:
action 3, numVisits=1483310, meanQ=6.399991, numObservations: 4
action 1, numVisits=16955, meanQ=6.358521, numObservations: 5
action 2, numVisits=54, meanQ=5.233706, numObservations: 3
action -1, numVisits=3, meanQ=1.300000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 3
Next state: 1 0.507738 0.857776 0.047274 0.374448 0.603298 0.884059 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 456
Initial state: 0 0.298563 0.575327 0.633771 0.890785 0.519662 0.851534 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1186555 episodes
GETTING ACTION FROM:
action 3, numVisits=1186519, meanQ=6.236412, numObservations: 5
action -1, numVisits=21, meanQ=4.506983, numObservations: 1
action 1, numVisits=12, meanQ=3.165017, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.298563 0.575327 0.633771 0.890785 0.519662 0.851534 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 457
Initial state: 0 0.923329 0.0206286 0.517297 0.811314 0.668077 0.833317 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1203916 episodes
GETTING ACTION FROM:
action 2, numVisits=1203832, meanQ=6.215473, numObservations: 4
action 0, numVisits=56, meanQ=5.208535, numObservations: 1
action 1, numVisits=20, meanQ=4.440500, numObservations: 3
action 3, numVisits=6, meanQ=2.663333, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.923329 0.0206286 0.517297 0.811314 0.668077 0.833317 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 458
Initial state: 0 0.57607 0.890705 0.427004 0.936049 0.515398 0.833125 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1174405 episodes
GETTING ACTION FROM:
action 1, numVisits=1174397, meanQ=6.225949, numObservations: 4
action 3, numVisits=2, meanQ=-0.010000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.57607 0.890705 0.427004 0.936049 0.515398 0.833125 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 459
Initial state: 0 0.610008 0.887826 0.676412 0.872368 0.526147 0.991379 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1191376 episodes
GETTING ACTION FROM:
action 3, numVisits=18226, meanQ=6.267933, numObservations: 3
action 1, numVisits=1173145, meanQ=6.228889, numObservations: 5
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.610008 0.887826 0.676412 0.872368 0.526147 0.991379 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 460
Initial state: 0 0.621568 0.858354 0.19736 0.87697 0.594429 0.887816 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1190592 episodes
GETTING ACTION FROM:
action 3, numVisits=1177478, meanQ=6.235298, numObservations: 5
action 1, numVisits=13100, meanQ=6.167279, numObservations: 5
action -1, numVisits=10, meanQ=3.739360, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.621568 0.858354 0.19736 0.87697 0.594429 0.887816 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 461
Initial state: 0 0.510272 0.888523 0.239311 0.353274 0.657282 0.815397 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1199139 episodes
GETTING ACTION FROM:
action 3, numVisits=1198914, meanQ=6.233830, numObservations: 4
action 2, numVisits=185, meanQ=5.658830, numObservations: 5
action -1, numVisits=36, meanQ=4.987376, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 3
Next state: 1 0.510272 0.888523 0.239311 0.353274 0.657282 0.815397 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 462
Initial state: 0 0.538323 0.893202 0.552517 0.818172 0.369129 0.744327 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1191266 episodes
GETTING ACTION FROM:
action 2, numVisits=1191107, meanQ=6.305704, numObservations: 4
action 1, numVisits=103, meanQ=5.539128, numObservations: 4
action 3, numVisits=30, meanQ=4.781340, numObservations: 4
action 0, numVisits=24, meanQ=4.745680, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.538323 0.893202 0.552517 0.818172 0.369129 0.744327 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 463
Initial state: 0 0.635388 0.816874 0.595266 0.854943 0.434271 0.757035 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1186480 episodes
GETTING ACTION FROM:
action 3, numVisits=1186412, meanQ=6.238509, numObservations: 5
action -1, numVisits=47, meanQ=5.129017, numObservations: 1
action 2, numVisits=13, meanQ=3.690777, numObservations: 2
action 1, numVisits=6, meanQ=2.661683, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.635388 0.816874 0.595266 0.854943 0.434271 0.757035 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=113639, meanQ=8.874677, numObservations: 3
action 1, numVisits=49885, meanQ=8.863415, numObservations: 4
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1481336 episodes
GETTING ACTION FROM:
action 1, numVisits=919199, meanQ=6.651201, numObservations: 4
action 2, numVisits=725659, meanQ=6.650144, numObservations: 3
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.635388 0.816874 0.595266 0.854943 0.434271 0.757035 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 464
Initial state: 0 0.642776 0.805332 0.709058 0.709206 0.681316 0.824139 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1212814 episodes
GETTING ACTION FROM:
action 2, numVisits=1148845, meanQ=6.228232, numObservations: 3
action 3, numVisits=63963, meanQ=6.198609, numObservations: 5
action 1, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.642776 0.805332 0.709058 0.709206 0.681316 0.824139 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 465
Initial state: 0 0.513094 0.869358 0.500597 0.841103 0.469041 0.24009 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1193992 episodes
GETTING ACTION FROM:
action 3, numVisits=1193928, meanQ=6.222445, numObservations: 4
action -1, numVisits=29, meanQ=4.786569, numObservations: 1
action 2, numVisits=32, meanQ=4.618750, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.513094 0.869358 0.500597 0.841103 0.469041 0.24009 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=96955, meanQ=8.872752, numObservations: 4
action 1, numVisits=67594, meanQ=8.868054, numObservations: 4
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1460250 episodes
GETTING ACTION FROM:
action 2, numVisits=1110534, meanQ=6.717244, numObservations: 4
action 1, numVisits=514239, meanQ=6.713976, numObservations: 4
action 3, numVisits=27, meanQ=4.877781, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.513094 0.869358 0.500597 0.841103 0.469041 0.24009 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 466
Initial state: 0 0.713627 0.991597 0.628142 0.825223 0.5645 0.818872 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1160973 episodes
GETTING ACTION FROM:
action 2, numVisits=1160960, meanQ=6.137930, numObservations: 5
action 3, numVisits=7, meanQ=1.871429, numObservations: 3
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 2
Next state: 1 0.713627 0.991597 0.628142 0.825223 0.5645 0.818872 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 467
Initial state: 0 0.550363 0.855307 0.281319 0.969355 0.595142 0.821355 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1209005 episodes
GETTING ACTION FROM:
action 2, numVisits=1208960, meanQ=6.239062, numObservations: 4
action -1, numVisits=22, meanQ=4.537926, numObservations: 1
action 3, numVisits=7, meanQ=3.282886, numObservations: 3
action 1, numVisits=14, meanQ=3.277864, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.550363 0.855307 0.281319 0.969355 0.595142 0.821355 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 468
Initial state: 0 0.505306 0.852794 0.0683515 0.368136 0.695297 0.870712 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1196454 episodes
GETTING ACTION FROM:
action 1, numVisits=1196310, meanQ=6.241903, numObservations: 4
action 3, numVisits=90, meanQ=5.403447, numObservations: 5
action 0, numVisits=48, meanQ=5.126123, numObservations: 1
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.505306 0.852794 0.0683515 0.368136 0.695297 0.870712 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 469
Initial state: 0 0.512661 0.837439 0.258831 0.417126 0.597741 0.840594 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1187192 episodes
GETTING ACTION FROM:
action 1, numVisits=866317, meanQ=6.230448, numObservations: 5
action 3, numVisits=320870, meanQ=6.209679, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.512661 0.837439 0.258831 0.417126 0.597741 0.840594 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=38663, meanQ=6.515481, numObservations: 5
action 2, numVisits=27, meanQ=4.921489, numObservations: 4
action 1, numVisits=5, meanQ=1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1442096 episodes
GETTING ACTION FROM:
action 3, numVisits=1480757, meanQ=6.495833, numObservations: 5
action 2, numVisits=27, meanQ=4.921489, numObservations: 4
action 1, numVisits=5, meanQ=1.000000, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.512661 0.837439 0.258831 0.417126 0.597741 0.840594 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 470
Initial state: 0 0.62666 0.891606 0.763293 0.0313459 0.548878 0.811056 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1200974 episodes
GETTING ACTION FROM:
action 2, numVisits=1200956, meanQ=6.236017, numObservations: 4
action 0, numVisits=12, meanQ=3.851054, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.62666 0.891606 0.763293 0.0313459 0.548878 0.811056 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 471
Initial state: 0 0.969186 0.10871 0.609126 0.879604 0.635516 0.811984 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1201265 episodes
GETTING ACTION FROM:
action 2, numVisits=1201199, meanQ=6.226989, numObservations: 4
action 0, numVisits=35, meanQ=4.951541, numObservations: 1
action -1, numVisits=26, meanQ=4.719559, numObservations: 1
action 1, numVisits=4, meanQ=1.747500, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.969186 0.10871 0.609126 0.879604 0.635516 0.811984 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 472
Initial state: 0 0.656225 0.889152 0.607479 0.856059 0.90545 0.0407048 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1190981 episodes
GETTING ACTION FROM:
action 2, numVisits=1190974, meanQ=6.224948, numObservations: 5
action 0, numVisits=3, meanQ=-1.676600, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.656225 0.889152 0.607479 0.856059 0.90545 0.0407048 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 473
Initial state: 0 0.634661 0.889545 0.52485 0.834423 0.44978 0.241876 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1204739 episodes
GETTING ACTION FROM:
action 2, numVisits=1185871, meanQ=6.237414, numObservations: 4
action 1, numVisits=18833, meanQ=6.189476, numObservations: 3
action -1, numVisits=29, meanQ=4.824686, numObservations: 1
action 3, numVisits=4, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.634661 0.889545 0.52485 0.834423 0.44978 0.241876 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 474
Initial state: 0 0.629095 0.875593 0.649492 0.890136 0.484436 0.573098 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1196759 episodes
GETTING ACTION FROM:
action 1, numVisits=1196686, meanQ=6.182984, numObservations: 4
action 0, numVisits=44, meanQ=5.041357, numObservations: 1
action -1, numVisits=26, meanQ=4.699764, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.629095 0.875593 0.649492 0.890136 0.484436 0.573098 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 475
Initial state: 0 0.541738 0.881417 0.664485 0.871655 0.612738 0.582425 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1184044 episodes
GETTING ACTION FROM:
action 2, numVisits=1184008, meanQ=6.198107, numObservations: 3
action 0, numVisits=18, meanQ=4.376151, numObservations: 1
action 1, numVisits=6, meanQ=2.333333, numObservations: 2
action 3, numVisits=10, meanQ=2.099000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.541738 0.881417 0.664485 0.871655 0.612738 0.582425 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 476
Initial state: 0 0.573626 0.824613 0.608771 0.819127 0.00391648 0.353277 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1186918 episodes
GETTING ACTION FROM:
action 3, numVisits=1186854, meanQ=6.229516, numObservations: 5
action -1, numVisits=26, meanQ=4.713515, numObservations: 1
action 2, numVisits=32, meanQ=4.414375, numObservations: 5
action 1, numVisits=4, meanQ=1.525000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.573626 0.824613 0.608771 0.819127 0.00391648 0.353277 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=110625, meanQ=8.873585, numObservations: 5
action 1, numVisits=53015, meanQ=8.863560, numObservations: 4
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1453946 episodes
GETTING ACTION FROM:
action 2, numVisits=1330011, meanQ=6.842773, numObservations: 5
action 1, numVisits=287573, meanQ=6.835202, numObservations: 4
action 3, numVisits=3, meanQ=2.330033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.573626 0.824613 0.608771 0.819127 0.00391648 0.353277 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 477
Initial state: 0 0.509497 0.851966 0.76582 0.770418 0.660903 0.802492 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1201053 episodes
GETTING ACTION FROM:
action 2, numVisits=1201021, meanQ=6.314166, numObservations: 5
action 3, numVisits=27, meanQ=4.628156, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.509497 0.851966 0.76582 0.770418 0.660903 0.802492 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 478
Initial state: 0 0.23863 0.173043 0.662729 0.836629 0.619822 0.865307 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1198651 episodes
GETTING ACTION FROM:
action 1, numVisits=1198594, meanQ=6.235387, numObservations: 4
action -1, numVisits=40, meanQ=5.010469, numObservations: 1
action 2, numVisits=10, meanQ=2.890010, numObservations: 2
action 3, numVisits=5, meanQ=1.396000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.23863 0.173043 0.662729 0.836629 0.619822 0.865307 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=122324, meanQ=8.857027, numObservations: 3
action 3, numVisits=72309, meanQ=8.849511, numObservations: 5
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1478605 episodes
GETTING ACTION FROM:
action 2, numVisits=1109968, meanQ=6.647206, numObservations: 3
action 3, numVisits=563268, meanQ=6.644163, numObservations: 5
action 1, numVisits=3, meanQ=-0.670000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.23863 0.173043 0.662729 0.836629 0.619822 0.865307 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 479
Initial state: 0 0.677941 0.866667 0.299705 0.0417576 0.669524 0.848531 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1188374 episodes
GETTING ACTION FROM:
action 1, numVisits=1188307, meanQ=6.231418, numObservations: 5
action 0, numVisits=35, meanQ=4.967483, numObservations: 1
action -1, numVisits=20, meanQ=4.470726, numObservations: 1
action 3, numVisits=6, meanQ=2.663333, numObservations: 3
action 2, numVisits=6, meanQ=0.831667, numObservations: 3
action: 1
Next state: 1 0.677941 0.866667 0.299705 0.0417576 0.669524 0.848531 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 480
Initial state: 0 0.668102 0.86006 0.589038 0.886121 0.150099 0.247465 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1187909 episodes
GETTING ACTION FROM:
action 1, numVisits=1187783, meanQ=6.234540, numObservations: 5
action 2, numVisits=119, meanQ=5.499330, numObservations: 3
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.668102 0.86006 0.589038 0.886121 0.150099 0.247465 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 481
Initial state: 0 0.517528 0.816689 0.402143 0.700234 0.59012 0.85346 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1193976 episodes
GETTING ACTION FROM:
action 2, numVisits=917172, meanQ=6.186669, numObservations: 4
action 1, numVisits=276753, meanQ=6.143937, numObservations: 4
action 0, numVisits=35, meanQ=4.916782, numObservations: 1
action 3, numVisits=14, meanQ=4.068593, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.517528 0.816689 0.402143 0.700234 0.59012 0.85346 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=66248, meanQ=8.876006, numObservations: 4
action 3, numVisits=60120, meanQ=8.873405, numObservations: 4
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1469834 episodes
GETTING ACTION FROM:
action 3, numVisits=1132615, meanQ=6.619460, numObservations: 4
action 1, numVisits=463583, meanQ=6.615614, numObservations: 4
action 2, numVisits=5, meanQ=0.998020, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.517528 0.816689 0.402143 0.700234 0.59012 0.85346 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 482
Initial state: 0 0.681923 0.832176 0.447123 0.733247 0.660378 0.809696 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1204532 episodes
GETTING ACTION FROM:
action 2, numVisits=1204491, meanQ=6.245723, numObservations: 4
action -1, numVisits=33, meanQ=4.947643, numObservations: 1
action 3, numVisits=5, meanQ=1.396000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.681923 0.832176 0.447123 0.733247 0.660378 0.809696 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=93578, meanQ=8.869974, numObservations: 5
action 1, numVisits=72023, meanQ=8.865443, numObservations: 3
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1463003 episodes
GETTING ACTION FROM:
action 3, numVisits=1362420, meanQ=7.102273, numObservations: 5
action 1, numVisits=266183, meanQ=7.094012, numObservations: 3
action 2, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.681923 0.832176 0.447123 0.733247 0.660378 0.809696 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=12349, meanQ=8.363792, numObservations: 4
action 1, numVisits=2034, meanQ=8.280282, numObservations: 3
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1492126 episodes
GETTING ACTION FROM:
action 3, numVisits=1488716, meanQ=6.790572, numObservations: 4
action 2, numVisits=9778, meanQ=6.719386, numObservations: 4
action 1, numVisits=8016, meanQ=6.710742, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.681923 0.832176 0.447123 0.733247 0.660378 0.809696 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.8309
Run # 483
Initial state: 0 0.608822 0.838688 0.0828814 0.166356 0.563748 0.874391 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1200316 episodes
GETTING ACTION FROM:
action 1, numVisits=1200278, meanQ=6.226065, numObservations: 4
action 2, numVisits=27, meanQ=4.551485, numObservations: 3
action 3, numVisits=7, meanQ=3.284300, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.608822 0.838688 0.0828814 0.166356 0.563748 0.874391 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 484
Initial state: 0 0.546542 0.849808 0.87179 0.526935 0.506937 0.898321 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1200785 episodes
GETTING ACTION FROM:
action 2, numVisits=1177399, meanQ=6.231668, numObservations: 4
action 1, numVisits=23321, meanQ=6.128759, numObservations: 4
action 0, numVisits=61, meanQ=5.269242, numObservations: 1
action 3, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 2 0.546542 0.849808 0.87179 0.526935 0.506937 0.898321 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 485
Initial state: 0 0.0234404 0.761132 0.518902 0.868712 0.586259 0.880481 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1199099 episodes
GETTING ACTION FROM:
action 1, numVisits=1199077, meanQ=6.230573, numObservations: 4
action 2, numVisits=16, meanQ=3.368131, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.0234404 0.761132 0.518902 0.868712 0.586259 0.880481 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=128392, meanQ=8.862769, numObservations: 3
action 3, numVisits=65883, meanQ=8.854861, numObservations: 4
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1483826 episodes
GETTING ACTION FROM:
action 2, numVisits=1044433, meanQ=6.712316, numObservations: 3
action 3, numVisits=633667, meanQ=6.710114, numObservations: 4
action 1, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.0234404 0.761132 0.518902 0.868712 0.586259 0.880481 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 486
Initial state: 0 0.681912 0.844468 0.804441 0.978446 0.528184 0.811771 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1202920 episodes
GETTING ACTION FROM:
action 3, numVisits=1202855, meanQ=6.231326, numObservations: 4
action 1, numVisits=57, meanQ=5.199125, numObservations: 4
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.681912 0.844468 0.804441 0.978446 0.528184 0.811771 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 487
Initial state: 0 0.345386 0.622635 0.522247 0.813294 0.691744 0.850369 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1199320 episodes
GETTING ACTION FROM:
action 1, numVisits=1199252, meanQ=6.223795, numObservations: 4
action 0, numVisits=25, meanQ=4.664479, numObservations: 1
action 3, numVisits=28, meanQ=4.352864, numObservations: 4
action 2, numVisits=13, meanQ=3.683085, numObservations: 4
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 1
Next state: 0 0.345386 0.622635 0.522247 0.813294 0.691744 0.850369 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=96355, meanQ=8.870093, numObservations: 4
action 2, numVisits=67966, meanQ=8.865758, numObservations: 5
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1463451 episodes
GETTING ACTION FROM:
action 3, numVisits=1225172, meanQ=6.649980, numObservations: 4
action 2, numVisits=402596, meanQ=6.644809, numObservations: 5
action 1, numVisits=5, meanQ=2.762000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.345386 0.622635 0.522247 0.813294 0.691744 0.850369 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 488
Initial state: 0 0.684367 0.892505 0.107226 0.49781 0.689167 0.820847 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1199033 episodes
GETTING ACTION FROM:
action 3, numVisits=1199009, meanQ=6.239493, numObservations: 4
action 0, numVisits=19, meanQ=4.458038, numObservations: 1
action 2, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.684367 0.892505 0.107226 0.49781 0.689167 0.820847 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 489
Initial state: 0 0.519946 0.887553 0.613241 0.897628 0.630862 0.0314422 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1184668 episodes
GETTING ACTION FROM:
action 3, numVisits=1183473, meanQ=6.228720, numObservations: 5
action 1, numVisits=1189, meanQ=6.006034, numObservations: 3
action 2, numVisits=2, meanQ=-0.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.519946 0.887553 0.613241 0.897628 0.630862 0.0314422 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=88278, meanQ=8.871716, numObservations: 3
action 2, numVisits=74355, meanQ=8.870240, numObservations: 5
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1484650 episodes
GETTING ACTION FROM:
action 1, numVisits=1256851, meanQ=6.825290, numObservations: 3
action 2, numVisits=390430, meanQ=6.819848, numObservations: 5
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.519946 0.887553 0.613241 0.897628 0.630862 0.0314422 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 490
Initial state: 0 0.66455 0.829966 0.597581 0.859448 0.150863 0.691085 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1191290 episodes
GETTING ACTION FROM:
action 2, numVisits=1191171, meanQ=6.183137, numObservations: 5
action 1, numVisits=100, meanQ=5.346103, numObservations: 5
action 3, numVisits=15, meanQ=3.798667, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.66455 0.829966 0.597581 0.859448 0.150863 0.691085 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 491
Initial state: 0 0.624221 0.871006 0.169917 0.466888 0.598424 0.855128 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1187321 episodes
GETTING ACTION FROM:
action 3, numVisits=1187166, meanQ=6.228491, numObservations: 5
action 1, numVisits=116, meanQ=5.513019, numObservations: 5
action -1, numVisits=30, meanQ=4.846396, numObservations: 1
action 2, numVisits=7, meanQ=3.284300, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.624221 0.871006 0.169917 0.466888 0.598424 0.855128 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 492
Initial state: 0 0.519625 0.890503 0.0158996 0.946787 0.60297 0.890834 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1193939 episodes
GETTING ACTION FROM:
action 2, numVisits=1193803, meanQ=6.229093, numObservations: 5
action 0, numVisits=57, meanQ=5.242609, numObservations: 1
action -1, numVisits=46, meanQ=5.128036, numObservations: 1
action 3, numVisits=32, meanQ=4.581253, numObservations: 4
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.519625 0.890503 0.0158996 0.946787 0.60297 0.890834 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 493
Initial state: 0 0.166333 0.189565 0.679644 0.811473 0.631788 0.806207 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1197168 episodes
GETTING ACTION FROM:
action 2, numVisits=1197086, meanQ=6.224307, numObservations: 5
action -1, numVisits=56, meanQ=5.217613, numObservations: 1
action 3, numVisits=20, meanQ=4.549500, numObservations: 2
action 1, numVisits=4, meanQ=1.747500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.166333 0.189565 0.679644 0.811473 0.631788 0.806207 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 494
Initial state: 0 0.502618 0.856908 0.568192 0.836388 0.103287 0.191 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1199815 episodes
GETTING ACTION FROM:
action 3, numVisits=1199734, meanQ=6.236471, numObservations: 4
action -1, numVisits=51, meanQ=5.191478, numObservations: 1
action 2, numVisits=26, meanQ=4.335000, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.502618 0.856908 0.568192 0.836388 0.103287 0.191 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=119490, meanQ=8.860400, numObservations: 5
action 1, numVisits=75862, meanQ=8.856432, numObservations: 4
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1460314 episodes
GETTING ACTION FROM:
action 2, numVisits=1354361, meanQ=6.875215, numObservations: 5
action 1, numVisits=301268, meanQ=6.867910, numObservations: 4
action 3, numVisits=38, meanQ=5.607368, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.502618 0.856908 0.568192 0.836388 0.103287 0.191 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 495
Initial state: 0 0.598118 0.807557 0.46315 0.908705 0.603051 0.847074 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1197337 episodes
GETTING ACTION FROM:
action 1, numVisits=1197202, meanQ=6.236902, numObservations: 4
action 0, numVisits=80, meanQ=5.405274, numObservations: 1
action -1, numVisits=42, meanQ=5.065461, numObservations: 1
action 2, numVisits=9, meanQ=2.442233, numObservations: 3
action 3, numVisits=4, meanQ=1.747500, numObservations: 1
action: 1
Next state: 1 0.598118 0.807557 0.46315 0.908705 0.603051 0.847074 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 496
Initial state: 0 0.541505 0.871462 0.0848877 0.488864 0.678182 0.80511 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1193495 episodes
GETTING ACTION FROM:
action 2, numVisits=1193450, meanQ=6.185130, numObservations: 5
action 3, numVisits=33, meanQ=4.753945, numObservations: 3
action -1, numVisits=9, meanQ=3.056700, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.541505 0.871462 0.0848877 0.488864 0.678182 0.80511 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=164457, meanQ=8.873126, numObservations: 5
action 3, numVisits=24, meanQ=7.415008, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1455348 episodes
GETTING ACTION FROM:
action 1, numVisits=1619497, meanQ=6.589369, numObservations: 5
action 3, numVisits=332, meanQ=6.171236, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.541505 0.871462 0.0848877 0.488864 0.678182 0.80511 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 497
Initial state: 0 0.580762 0.838181 0.0285348 0.447171 0.507022 0.837943 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1200509 episodes
GETTING ACTION FROM:
action 3, numVisits=1067733, meanQ=6.237522, numObservations: 4
action 1, numVisits=132646, meanQ=6.223025, numObservations: 3
action 2, numVisits=44, meanQ=5.110691, numObservations: 4
action -1, numVisits=46, meanQ=5.109694, numObservations: 1
action 0, numVisits=40, meanQ=5.051307, numObservations: 1
action: 3
Next state: 1 0.580762 0.838181 0.0285348 0.447171 0.507022 0.837943 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 498
Initial state: 0 0.539861 0.260885 0.688367 0.853237 0.522324 0.854299 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1198430 episodes
GETTING ACTION FROM:
action 2, numVisits=1198410, meanQ=6.234962, numObservations: 4
action 3, numVisits=12, meanQ=3.983333, numObservations: 2
action 1, numVisits=4, meanQ=1.747500, numObservations: 3
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.539861 0.260885 0.688367 0.853237 0.522324 0.854299 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 499
Initial state: 0 0.683812 0.800223 0.935225 0.0891105 0.630739 0.893576 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1195788 episodes
GETTING ACTION FROM:
action 2, numVisits=1195724, meanQ=6.227045, numObservations: 5
action -1, numVisits=30, meanQ=4.769781, numObservations: 1
action 0, numVisits=25, meanQ=4.668025, numObservations: 1
action 1, numVisits=7, meanQ=1.998571, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 2
Next state: 2 0.683812 0.800223 0.935225 0.0891105 0.630739 0.893576 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 500
Initial state: 0 0.630829 0.504953 0.655802 0.886473 0.666709 0.895896 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1195872 episodes
GETTING ACTION FROM:
action 1, numVisits=1195826, meanQ=6.231566, numObservations: 4
action 0, numVisits=27, meanQ=4.774578, numObservations: 1
action 3, numVisits=12, meanQ=2.333333, numObservations: 4
action 2, numVisits=5, meanQ=1.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.630829 0.504953 0.655802 0.886473 0.666709 0.895896 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
