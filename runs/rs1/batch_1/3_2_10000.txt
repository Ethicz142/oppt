Run # 1
Initial state: 0 0.622324 0.827192 0.295556 0.703006 0.500895 0.860783 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2242911 episodes
GETTING ACTION FROM:
action 3, numVisits=2242865, meanQ=6.232039, numObservations: 4
action 0, numVisits=39, meanQ=4.985387, numObservations: 1
action 1, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.622324 0.827192 0.295556 0.703006 0.500895 0.860783 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 2
Initial state: 0 0.507114 0.844616 0.493767 0.373825 0.53292 0.855477 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2341102 episodes
GETTING ACTION FROM:
action 2, numVisits=2341088, meanQ=6.231355, numObservations: 5
action 1, numVisits=9, meanQ=2.553333, numObservations: 3
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.507114 0.844616 0.493767 0.373825 0.53292 0.855477 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=254446, meanQ=8.938890, numObservations: 3
action 1, numVisits=13, meanQ=6.690785, numObservations: 2
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2893325 episodes
GETTING ACTION FROM:
action 3, numVisits=3147138, meanQ=6.602159, numObservations: 4
action 1, numVisits=640, meanQ=6.288141, numObservations: 5
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=3, meanQ=1.300000, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 3
Next state: 1 0.507114 0.844616 0.493767 0.373825 0.53292 0.855477 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 3
Initial state: 0 0.541022 0.827493 0.638436 0.810899 0.778077 0.490389 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2331898 episodes
GETTING ACTION FROM:
action 2, numVisits=2331887, meanQ=6.235265, numObservations: 4
action 3, numVisits=5, meanQ=1.396000, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.541022 0.827493 0.638436 0.810899 0.778077 0.490389 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 4
Initial state: 0 0.0716609 0.769216 0.554702 0.883752 0.559015 0.894144 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2300473 episodes
GETTING ACTION FROM:
action 1, numVisits=2300465, meanQ=6.238913, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.0716609 0.769216 0.554702 0.883752 0.559015 0.894144 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=316789, meanQ=8.880859, numObservations: 4
action 2, numVisits=34, meanQ=7.558238, numObservations: 3
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2862388 episodes
GETTING ACTION FROM:
action 3, numVisits=2496048, meanQ=6.615026, numObservations: 4
action 2, numVisits=682790, meanQ=6.611079, numObservations: 4
action 1, numVisits=372, meanQ=6.203007, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 3
Next state: 1 0.0716609 0.769216 0.554702 0.883752 0.559015 0.894144 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 5
Initial state: 0 0.569697 0.838692 0.527272 0.883508 0.172028 0.794856 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2353625 episodes
GETTING ACTION FROM:
action 3, numVisits=2353597, meanQ=6.234179, numObservations: 3
action 1, numVisits=23, meanQ=4.165222, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.569697 0.838692 0.527272 0.883508 0.172028 0.794856 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=192233, meanQ=8.850155, numObservations: 4
action 2, numVisits=190500, meanQ=8.849373, numObservations: 4
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2862535 episodes
GETTING ACTION FROM:
action 2, numVisits=2104926, meanQ=6.948866, numObservations: 4
action 1, numVisits=1140329, meanQ=6.946978, numObservations: 4
action 3, numVisits=14, meanQ=4.140721, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.569697 0.838692 0.527272 0.883508 0.172028 0.794856 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 6
Initial state: 0 0.632668 0.884514 0.687299 0.853587 0.199079 0.956047 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1634254 episodes
GETTING ACTION FROM:
action 0, numVisits=1634245, meanQ=6.346283, numObservations: 3
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 2
action 3, numVisits=2, meanQ=-5.505000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.632668 0.884514 0.687299 0.853587 0.199079 0.956047 w: 1
Observation: 0 0 0.932088 0 0.796804 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=443590, meanQ=8.733535, numObservations: 3
action 3, numVisits=17, meanQ=6.647059, numObservations: 4
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2523379 episodes
GETTING ACTION FROM:
action 1, numVisits=2966939, meanQ=6.774952, numObservations: 3
action 3, numVisits=46, meanQ=5.473702, numObservations: 5
action 2, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.632668 0.884514 0.687299 0.853587 0.199079 0.956047 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 7
Initial state: 0 0.696595 0.83946 0.54564 0.86222 0.631276 0.148218 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2321259 episodes
GETTING ACTION FROM:
action 3, numVisits=2321224, meanQ=6.233644, numObservations: 4
action -1, numVisits=19, meanQ=4.466574, numObservations: 1
action 1, numVisits=12, meanQ=3.082517, numObservations: 3
action 2, numVisits=2, meanQ=-0.010000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.696595 0.83946 0.54564 0.86222 0.631276 0.148218 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 8
Initial state: 0 0.568482 0.84358 0.217433 0.697595 0.504394 0.833408 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2288313 episodes
GETTING ACTION FROM:
action 1, numVisits=2288152, meanQ=6.238306, numObservations: 5
action -1, numVisits=75, meanQ=5.358229, numObservations: 1
action 0, numVisits=50, meanQ=5.124751, numObservations: 1
action 3, numVisits=35, meanQ=3.731157, numObservations: 4
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.568482 0.84358 0.217433 0.697595 0.504394 0.833408 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 9
Initial state: 0 0.675823 0.84373 0.437913 0.668818 0.638463 0.831064 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2320120 episodes
GETTING ACTION FROM:
action 1, numVisits=2226103, meanQ=6.307441, numObservations: 4
action 3, numVisits=94012, meanQ=6.218586, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.675823 0.84373 0.437913 0.668818 0.638463 0.831064 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 10
Initial state: 0 0.638641 0.807089 0.142658 0.991379 0.685457 0.848505 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2346006 episodes
GETTING ACTION FROM:
action 1, numVisits=2345989, meanQ=6.224025, numObservations: 3
action 3, numVisits=12, meanQ=3.998350, numObservations: 3
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.638641 0.807089 0.142658 0.991379 0.685457 0.848505 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 11
Initial state: 0 0.551459 0.88396 0.490112 0.332716 0.500824 0.820213 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2295970 episodes
GETTING ACTION FROM:
action 1, numVisits=2295866, meanQ=6.235696, numObservations: 5
action 0, numVisits=53, meanQ=5.177041, numObservations: 1
action -1, numVisits=38, meanQ=4.973601, numObservations: 1
action 2, numVisits=12, meanQ=3.998350, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.551459 0.88396 0.490112 0.332716 0.500824 0.820213 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 12
Initial state: 0 0.643972 0.868035 0.685106 0.865985 0.614726 0.181759 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2351468 episodes
GETTING ACTION FROM:
action 2, numVisits=2351392, meanQ=6.232971, numObservations: 3
action 1, numVisits=40, meanQ=4.472750, numObservations: 3
action 0, numVisits=20, meanQ=4.417142, numObservations: 1
action 3, numVisits=14, meanQ=4.070007, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.643972 0.868035 0.685106 0.865985 0.614726 0.181759 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 13
Initial state: 0 0.600785 0.849776 0.579952 0.910038 0.555948 0.842185 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2325244 episodes
GETTING ACTION FROM:
action 1, numVisits=2325228, meanQ=6.234481, numObservations: 4
action 0, numVisits=11, meanQ=3.668200, numObservations: 2
action 2, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.600785 0.849776 0.579952 0.910038 0.555948 0.842185 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 14
Initial state: 0 0.615003 0.899536 0.535194 0.805087 0.836533 0.886727 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2358051 episodes
GETTING ACTION FROM:
action 2, numVisits=2357120, meanQ=6.236168, numObservations: 3
action 1, numVisits=883, meanQ=5.970445, numObservations: 4
action -1, numVisits=45, meanQ=5.093588, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.615003 0.899536 0.535194 0.805087 0.836533 0.886727 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 15
Initial state: 0 0.665274 0.807927 0.661717 0.898589 0.175136 0.30239 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2347749 episodes
GETTING ACTION FROM:
action 1, numVisits=2347686, meanQ=6.223607, numObservations: 3
action -1, numVisits=42, meanQ=5.026543, numObservations: 1
action 2, numVisits=17, meanQ=3.764118, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.665274 0.807927 0.661717 0.898589 0.175136 0.30239 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 16
Initial state: 0 0.654777 0.849301 0.64898 0.835052 0.960626 0.510867 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2336972 episodes
GETTING ACTION FROM:
action 2, numVisits=2260858, meanQ=6.229836, numObservations: 4
action 3, numVisits=76075, meanQ=6.198142, numObservations: 4
action -1, numVisits=32, meanQ=4.833859, numObservations: 1
action 1, numVisits=5, meanQ=0.998020, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 2
Next state: 1 0.654777 0.849301 0.64898 0.835052 0.960626 0.510867 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 17
Initial state: 0 0.597486 0.865302 0.241938 0.73469 0.521602 0.894019 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2324790 episodes
GETTING ACTION FROM:
action 3, numVisits=832567, meanQ=6.310639, numObservations: 4
action 2, numVisits=1492101, meanQ=6.228502, numObservations: 4
action 1, numVisits=118, meanQ=5.484944, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.597486 0.865302 0.241938 0.73469 0.521602 0.894019 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=33192, meanQ=7.966928, numObservations: 3
action 2, numVisits=9, meanQ=4.555556, numObservations: 3
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2923805 episodes
GETTING ACTION FROM:
action 2, numVisits=2787060, meanQ=6.628031, numObservations: 3
action 3, numVisits=169942, meanQ=6.612585, numObservations: 3
action 1, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.597486 0.865302 0.241938 0.73469 0.521602 0.894019 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=20529, meanQ=8.791837, numObservations: 5
action 3, numVisits=47, meanQ=7.676600, numObservations: 3
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2892525 episodes
GETTING ACTION FROM:
action 3, numVisits=367269, meanQ=6.722548, numObservations: 3
action 1, numVisits=2545804, meanQ=6.446873, numObservations: 5
action 2, numVisits=27, meanQ=4.628889, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 3
Next state: 1 0.597486 0.865302 0.241938 0.73469 0.521602 0.894019 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.8309
Run # 18
Initial state: 0 0.58121 0.899038 0.798991 0.475443 0.507857 0.891809 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2338167 episodes
GETTING ACTION FROM:
action 1, numVisits=2338155, meanQ=6.226522, numObservations: 3
action 3, numVisits=7, meanQ=1.998571, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.58121 0.899038 0.798991 0.475443 0.507857 0.891809 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 19
Initial state: 0 0.692619 0.898613 0.483211 0.84015 0.663747 0.870472 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2317109 episodes
GETTING ACTION FROM:
action 3, numVisits=2317077, meanQ=6.225535, numObservations: 4
action -1, numVisits=19, meanQ=4.471381, numObservations: 1
action 1, numVisits=8, meanQ=2.873750, numObservations: 2
action 2, numVisits=3, meanQ=-0.670000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.692619 0.898613 0.483211 0.84015 0.663747 0.870472 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 20
Initial state: 0 0.628783 0.879869 0.02487 0.927639 0.66455 0.889617 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2326622 episodes
GETTING ACTION FROM:
action 1, numVisits=2326523, meanQ=6.303083, numObservations: 4
action 3, numVisits=81, meanQ=5.364730, numObservations: 4
action -1, numVisits=14, meanQ=3.923738, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 1
Next state: 1 0.628783 0.879869 0.02487 0.927639 0.66455 0.889617 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 21
Initial state: 0 0.674199 0.800615 0.527966 0.863421 0.507374 0.611468 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2331608 episodes
GETTING ACTION FROM:
action 2, numVisits=2331469, meanQ=6.231159, numObservations: 4
action 0, numVisits=80, meanQ=5.373251, numObservations: 1
action -1, numVisits=52, meanQ=5.164300, numObservations: 1
action 3, numVisits=4, meanQ=1.747500, numObservations: 2
action 1, numVisits=3, meanQ=-0.670000, numObservations: 2
action: 2
Next state: 1 0.674199 0.800615 0.527966 0.863421 0.507374 0.611468 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 22
Initial state: 0 0.778206 0.00819194 0.523024 0.80989 0.670032 0.876136 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2290718 episodes
GETTING ACTION FROM:
action 3, numVisits=2290709, meanQ=6.240821, numObservations: 5
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.778206 0.00819194 0.523024 0.80989 0.670032 0.876136 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 23
Initial state: 0 0.52018 0.801529 0.645151 0.504059 0.513839 0.858728 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2309649 episodes
GETTING ACTION FROM:
action 2, numVisits=2309557, meanQ=6.236081, numObservations: 5
action 1, numVisits=84, meanQ=5.296311, numObservations: 4
action 3, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.52018 0.801529 0.645151 0.504059 0.513839 0.858728 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 24
Initial state: 0 0.673339 0.334161 0.609437 0.847446 0.697576 0.816039 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2331439 episodes
GETTING ACTION FROM:
action 2, numVisits=2331431, meanQ=6.243392, numObservations: 4
action 3, numVisits=3, meanQ=-0.670000, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.673339 0.334161 0.609437 0.847446 0.697576 0.816039 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 25
Initial state: 0 0.567261 0.837365 0.372746 0.844403 0.603935 0.846373 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2323001 episodes
GETTING ACTION FROM:
action 3, numVisits=2322933, meanQ=6.221908, numObservations: 4
action 0, numVisits=34, meanQ=4.912117, numObservations: 1
action 2, numVisits=20, meanQ=3.548510, numObservations: 5
action 1, numVisits=12, meanQ=3.248342, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.567261 0.837365 0.372746 0.844403 0.603935 0.846373 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 26
Initial state: 0 0.548166 0.460291 0.520021 0.863095 0.646816 0.885831 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2321662 episodes
GETTING ACTION FROM:
action 3, numVisits=2321655, meanQ=6.224422, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.548166 0.460291 0.520021 0.863095 0.646816 0.885831 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 27
Initial state: 0 0.953389 0.984605 0.689304 0.824059 0.525351 0.848356 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2325060 episodes
GETTING ACTION FROM:
action 2, numVisits=2325030, meanQ=6.236847, numObservations: 4
action 1, numVisits=25, meanQ=4.235204, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.953389 0.984605 0.689304 0.824059 0.525351 0.848356 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 28
Initial state: 0 0.157616 0.073366 0.632512 0.816659 0.515144 0.802848 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2347138 episodes
GETTING ACTION FROM:
action 2, numVisits=2274194, meanQ=6.232108, numObservations: 3
action 1, numVisits=72916, meanQ=6.172420, numObservations: 3
action 0, numVisits=20, meanQ=4.259404, numObservations: 2
action 3, numVisits=6, meanQ=2.496683, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.157616 0.073366 0.632512 0.816659 0.515144 0.802848 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 29
Initial state: 0 0.677877 0.894871 0.667491 0.867647 0.0574578 0.450663 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2325745 episodes
GETTING ACTION FROM:
action 1, numVisits=775723, meanQ=6.239681, numObservations: 5
action 2, numVisits=1549845, meanQ=6.232372, numObservations: 3
action 3, numVisits=154, meanQ=5.616181, numObservations: 4
action -1, numVisits=21, meanQ=4.406855, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.677877 0.894871 0.667491 0.867647 0.0574578 0.450663 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=34310, meanQ=6.483006, numObservations: 4
action 1, numVisits=21, meanQ=3.799524, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2886186 episodes
GETTING ACTION FROM:
action 2, numVisits=2920494, meanQ=6.315849, numObservations: 4
action 1, numVisits=21, meanQ=3.799524, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.677877 0.894871 0.667491 0.867647 0.0574578 0.450663 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 30
Initial state: 0 0.539557 0.810881 0.602836 0.843939 0.347996 0.744121 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2338820 episodes
GETTING ACTION FROM:
action 2, numVisits=2338789, meanQ=6.238938, numObservations: 4
action -1, numVisits=27, meanQ=4.760953, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.539557 0.810881 0.602836 0.843939 0.347996 0.744121 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 31
Initial state: 0 0.220127 0.944145 0.567463 0.801687 0.521914 0.844029 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2298426 episodes
GETTING ACTION FROM:
action 3, numVisits=2298270, meanQ=6.223816, numObservations: 5
action 1, numVisits=83, meanQ=5.346689, numObservations: 4
action 2, numVisits=69, meanQ=5.246087, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.220127 0.944145 0.567463 0.801687 0.521914 0.844029 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 32
Initial state: 0 0.208943 0.659553 0.514469 0.816817 0.657938 0.8216 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1576474 episodes
GETTING ACTION FROM:
action -1, numVisits=1576467, meanQ=4.164155, numObservations: 1
action 3, numVisits=3, meanQ=-0.670000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.208943 0.659553 0.514469 0.816817 0.657938 0.8216 w: 1
Observation: 0 0.234523 0 0.522858 0 0.608556 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=1561686, meanQ=6.223849, numObservations: 4
action 2, numVisits=14774, meanQ=6.135856, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 2515484 episodes
GETTING ACTION FROM:
action 3, numVisits=4077170, meanQ=6.219263, numObservations: 4
action 2, numVisits=14774, meanQ=6.135856, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.208943 0.659553 0.514469 0.816817 0.657938 0.8216 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 33
Initial state: 0 0.483685 0.463478 0.556388 0.872312 0.515671 0.8667 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2038847 episodes
GETTING ACTION FROM:
action 1, numVisits=1411862, meanQ=6.244649, numObservations: 4
action 0, numVisits=626981, meanQ=4.157721, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.483685 0.463478 0.556388 0.872312 0.515671 0.8667 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=166165, meanQ=8.860043, numObservations: 3
action 2, numVisits=62843, meanQ=8.849131, numObservations: 4
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2881201 episodes
GETTING ACTION FROM:
action 3, numVisits=2058297, meanQ=6.615594, numObservations: 3
action 2, numVisits=1051909, meanQ=6.613376, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 3
Next state: 1 0.483685 0.463478 0.556388 0.872312 0.515671 0.8667 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 34
Initial state: 0 0.519426 0.89953 0.600181 0.813903 0.136987 0.788948 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2304271 episodes
GETTING ACTION FROM:
action 1, numVisits=2304201, meanQ=6.233655, numObservations: 5
action 0, numVisits=61, meanQ=5.251414, numObservations: 1
action 3, numVisits=6, meanQ=2.331683, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.519426 0.89953 0.600181 0.813903 0.136987 0.788948 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 35
Initial state: 0 0.557551 0.809655 0.644553 0.851621 0.927631 0.540679 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2338246 episodes
GETTING ACTION FROM:
action 3, numVisits=2338213, meanQ=6.235144, numObservations: 3
action 0, numVisits=23, meanQ=4.543337, numObservations: 1
action 1, numVisits=4, meanQ=1.747500, numObservations: 3
action 2, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.557551 0.809655 0.644553 0.851621 0.927631 0.540679 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 36
Initial state: 0 0.627543 0.826496 0.536757 0.845373 0.805461 0.919883 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2299375 episodes
GETTING ACTION FROM:
action 1, numVisits=2299289, meanQ=6.232706, numObservations: 5
action 2, numVisits=70, meanQ=5.145147, numObservations: 5
action 3, numVisits=12, meanQ=3.983333, numObservations: 4
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.627543 0.826496 0.536757 0.845373 0.805461 0.919883 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 37
Initial state: 0 0.64063 0.851926 0.660682 0.851757 0.374515 0.621279 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2319544 episodes
GETTING ACTION FROM:
action 1, numVisits=2319500, meanQ=6.232124, numObservations: 4
action 0, numVisits=25, meanQ=4.631213, numObservations: 2
action 2, numVisits=7, meanQ=3.285714, numObservations: 3
action 3, numVisits=10, meanQ=2.208000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.64063 0.851926 0.660682 0.851757 0.374515 0.621279 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 38
Initial state: 0 0.537711 0.85753 0.540294 0.880312 0.915459 0.481809 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2329784 episodes
GETTING ACTION FROM:
action 1, numVisits=1293017, meanQ=6.234994, numObservations: 4
action 3, numVisits=1036758, meanQ=6.234447, numObservations: 4
action 2, numVisits=5, meanQ=1.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.537711 0.85753 0.540294 0.880312 0.915459 0.481809 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=56272, meanQ=6.507811, numObservations: 4
action 2, numVisits=2067, meanQ=6.369313, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2857701 episodes
GETTING ACTION FROM:
action 3, numVisits=2809144, meanQ=6.352129, numObservations: 4
action 2, numVisits=106894, meanQ=6.328976, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 3
Next state: 0 0.537711 0.85753 0.540294 0.880312 0.915459 0.481809 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=25219, meanQ=8.151277, numObservations: 5
action 1, numVisits=335, meanQ=6.118865, numObservations: 4
action 3, numVisits=21, meanQ=5.128576, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2873891 episodes
GETTING ACTION FROM:
action 1, numVisits=2480427, meanQ=6.518691, numObservations: 5
action 2, numVisits=419012, meanQ=6.500899, numObservations: 5
action 3, numVisits=25, meanQ=4.948004, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 1
Next state: 1 0.537711 0.85753 0.540294 0.880312 0.915459 0.481809 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.8309
Run # 39
Initial state: 0 0.543913 0.879685 0.0407812 0.716871 0.582556 0.858019 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2317160 episodes
GETTING ACTION FROM:
action 3, numVisits=2316983, meanQ=6.239934, numObservations: 4
action -1, numVisits=61, meanQ=5.252161, numObservations: 1
action 2, numVisits=63, meanQ=5.156987, numObservations: 5
action 0, numVisits=35, meanQ=4.944093, numObservations: 1
action 1, numVisits=18, meanQ=4.054450, numObservations: 3
action: 3
Next state: 1 0.543913 0.879685 0.0407812 0.716871 0.582556 0.858019 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 40
Initial state: 0 0.542454 0.878365 0.158028 0.59589 0.512035 0.844742 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2310408 episodes
GETTING ACTION FROM:
action 2, numVisits=2310402, meanQ=6.234324, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.542454 0.878365 0.158028 0.59589 0.512035 0.844742 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=174696, meanQ=8.867480, numObservations: 5
action 3, numVisits=143778, meanQ=8.864973, numObservations: 4
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2854495 episodes
GETTING ACTION FROM:
action 1, numVisits=1726782, meanQ=6.666557, numObservations: 5
action 3, numVisits=1446183, meanQ=6.666051, numObservations: 4
action 2, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 1
Next state: 1 0.542454 0.878365 0.158028 0.59589 0.512035 0.844742 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 41
Initial state: 0 0.523146 0.821529 0.519338 0.155321 0.593905 0.809647 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2327683 episodes
GETTING ACTION FROM:
action 2, numVisits=2327597, meanQ=6.237835, numObservations: 4
action 0, numVisits=60, meanQ=5.247159, numObservations: 1
action -1, numVisits=21, meanQ=4.496800, numObservations: 1
action 1, numVisits=3, meanQ=-0.670000, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 2
Next state: 2 0.523146 0.821529 0.519338 0.155321 0.593905 0.809647 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 42
Initial state: 0 0.540746 0.898522 0.503586 0.832672 0.954722 0.125761 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2295324 episodes
GETTING ACTION FROM:
action 1, numVisits=2295306, meanQ=6.230688, numObservations: 5
action 3, numVisits=10, meanQ=2.999010, numObservations: 2
action 2, numVisits=4, meanQ=1.745025, numObservations: 3
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.540746 0.898522 0.503586 0.832672 0.954722 0.125761 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 43
Initial state: 0 0.627789 0.820722 0.495899 0.140999 0.660732 0.878034 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2308346 episodes
GETTING ACTION FROM:
action 1, numVisits=2308295, meanQ=6.241132, numObservations: 5
action 0, numVisits=45, meanQ=5.057398, numObservations: 1
action 2, numVisits=2, meanQ=-0.010000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.627789 0.820722 0.495899 0.140999 0.660732 0.878034 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 44
Initial state: 0 0.562506 0.834841 0.964945 0.734477 0.542712 0.823105 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2308197 episodes
GETTING ACTION FROM:
action 2, numVisits=2308152, meanQ=6.238783, numObservations: 5
action 0, numVisits=40, meanQ=5.005611, numObservations: 1
action 1, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.562506 0.834841 0.964945 0.734477 0.542712 0.823105 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 45
Initial state: 0 0.576496 0.810362 0.667636 0.809932 0.416736 0.619748 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2323812 episodes
GETTING ACTION FROM:
action 3, numVisits=2323753, meanQ=6.239283, numObservations: 4
action -1, numVisits=50, meanQ=5.153379, numObservations: 1
action 1, numVisits=6, meanQ=2.331683, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.576496 0.810362 0.667636 0.809932 0.416736 0.619748 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=128364, meanQ=8.939212, numObservations: 3
action 2, numVisits=124269, meanQ=8.938890, numObservations: 3
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2876394 episodes
GETTING ACTION FROM:
action 2, numVisits=2303487, meanQ=6.862442, numObservations: 4
action 1, numVisits=825536, meanQ=6.859008, numObservations: 3
action 3, numVisits=5, meanQ=3.198000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.576496 0.810362 0.667636 0.809932 0.416736 0.619748 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 46
Initial state: 0 0.646166 0.878654 0.655306 0.849612 0.903623 0.938648 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2321767 episodes
GETTING ACTION FROM:
action 3, numVisits=2321704, meanQ=6.188627, numObservations: 4
action 0, numVisits=42, meanQ=4.989604, numObservations: 1
action -1, numVisits=17, meanQ=4.323347, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 1, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 3
Next state: 2 0.646166 0.878654 0.655306 0.849612 0.903623 0.938648 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 47
Initial state: 0 0.689774 0.823338 0.645913 0.896804 0.9766 0.937472 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1769234 episodes
GETTING ACTION FROM:
action 0, numVisits=1280014, meanQ=6.413844, numObservations: 3
action 3, numVisits=489080, meanQ=6.211895, numObservations: 4
action -1, numVisits=124, meanQ=5.568549, numObservations: 1
action 1, numVisits=14, meanQ=2.076429, numObservations: 4
action 2, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 0
Next state: 0 0.689774 0.823338 0.645913 0.896804 0.9766 0.937472 w: 1
Observation: 0 0 0.757687 0 0.858141 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=557910, meanQ=8.347780, numObservations: 5
action 1, numVisits=4, meanQ=4.000000, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2497084 episodes
GETTING ACTION FROM:
action 3, numVisits=3054928, meanQ=6.254692, numObservations: 5
action 0, numVisits=62, meanQ=5.276403, numObservations: 1
action 1, numVisits=8, meanQ=2.873750, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.689774 0.823338 0.645913 0.896804 0.9766 0.937472 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 48
Initial state: 0 0.988987 0.13283 0.529178 0.86567 0.534911 0.801992 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2322833 episodes
GETTING ACTION FROM:
action 1, numVisits=2322808, meanQ=6.188520, numObservations: 4
action 3, numVisits=18, meanQ=4.109450, numObservations: 4
action 2, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.988987 0.13283 0.529178 0.86567 0.534911 0.801992 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 49
Initial state: 0 0.357606 0.106529 0.523171 0.887145 0.518555 0.838634 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2322170 episodes
GETTING ACTION FROM:
action 3, numVisits=2322139, meanQ=6.310359, numObservations: 4
action 1, numVisits=25, meanQ=4.595604, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.357606 0.106529 0.523171 0.887145 0.518555 0.838634 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 50
Initial state: 0 0.585013 0.529203 0.535903 0.809493 0.614095 0.856009 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2316985 episodes
GETTING ACTION FROM:
action 3, numVisits=2298309, meanQ=6.315231, numObservations: 4
action 2, numVisits=18668, meanQ=6.192754, numObservations: 3
action 1, numVisits=4, meanQ=1.747500, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.585013 0.529203 0.535903 0.809493 0.614095 0.856009 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 51
Initial state: 0 0.651032 0.823613 0.586661 0.829962 0.59104 0.161618 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2357622 episodes
GETTING ACTION FROM:
action 1, numVisits=2357594, meanQ=6.233990, numObservations: 3
action 3, numVisits=14, meanQ=3.915000, numObservations: 3
action 2, numVisits=10, meanQ=3.198000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.651032 0.823613 0.586661 0.829962 0.59104 0.161618 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 52
Initial state: 0 0.6622 0.813992 0.581435 0.8817 0.613281 0.174243 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2323415 episodes
GETTING ACTION FROM:
action 2, numVisits=2323320, meanQ=6.225646, numObservations: 5
action -1, numVisits=64, meanQ=5.266800, numObservations: 1
action 0, numVisits=22, meanQ=4.583267, numObservations: 1
action 3, numVisits=4, meanQ=1.747500, numObservations: 3
action 1, numVisits=5, meanQ=1.396000, numObservations: 3
action: 2
Next state: 0 0.6622 0.813992 0.581435 0.8817 0.613281 0.174243 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=104009, meanQ=6.483546, numObservations: 5
action 3, numVisits=25, meanQ=4.999208, numObservations: 4
action 2, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2842574 episodes
GETTING ACTION FROM:
action 1, numVisits=2946581, meanQ=6.646267, numObservations: 5
action 3, numVisits=25, meanQ=4.999208, numObservations: 4
action 2, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 1
Next state: 1 0.6622 0.813992 0.581435 0.8817 0.613281 0.174243 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 53
Initial state: 0 0.616818 0.19665 0.520931 0.898981 0.691338 0.852047 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2292897 episodes
GETTING ACTION FROM:
action 1, numVisits=2292869, meanQ=6.233655, numObservations: 5
action 3, numVisits=19, meanQ=4.419474, numObservations: 3
action 2, numVisits=5, meanQ=1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.616818 0.19665 0.520931 0.898981 0.691338 0.852047 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 54
Initial state: 0 0.615152 0.809215 0.842559 0.921419 0.66481 0.8735 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2298338 episodes
GETTING ACTION FROM:
action 3, numVisits=2298328, meanQ=6.317323, numObservations: 5
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.615152 0.809215 0.842559 0.921419 0.66481 0.8735 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 55
Initial state: 0 0.632542 0.861797 0.612157 0.856226 0.83933 0.859864 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2352265 episodes
GETTING ACTION FROM:
action 1, numVisits=2352186, meanQ=6.234617, numObservations: 3
action 0, numVisits=54, meanQ=5.178663, numObservations: 1
action 2, numVisits=14, meanQ=4.070007, numObservations: 3
action 3, numVisits=9, meanQ=3.554444, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.632542 0.861797 0.612157 0.856226 0.83933 0.859864 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 56
Initial state: 0 0.505356 0.867741 0.523826 0.631124 0.546414 0.827452 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2319082 episodes
GETTING ACTION FROM:
action 1, numVisits=2319016, meanQ=6.184409, numObservations: 4
action 0, numVisits=47, meanQ=5.052729, numObservations: 1
action 2, numVisits=16, meanQ=3.298769, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.505356 0.867741 0.523826 0.631124 0.546414 0.827452 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 57
Initial state: 0 0.662401 0.880592 0.575988 0.821598 0.71002 0.0453691 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2327106 episodes
GETTING ACTION FROM:
action 3, numVisits=2327000, meanQ=6.235163, numObservations: 4
action 1, numVisits=69, meanQ=5.264496, numObservations: 5
action 0, numVisits=34, meanQ=4.917352, numObservations: 1
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.662401 0.880592 0.575988 0.821598 0.71002 0.0453691 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 58
Initial state: 0 0.570478 0.877979 0.650578 0.826437 0.843728 0.399194 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2306752 episodes
GETTING ACTION FROM:
action 3, numVisits=2306721, meanQ=6.230626, numObservations: 4
action 2, numVisits=25, meanQ=4.104800, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 3
Next state: 2 0.570478 0.877979 0.650578 0.826437 0.843728 0.399194 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 59
Initial state: 0 0.534631 0.891533 0.631299 0.820184 0.380137 0.432751 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2326507 episodes
GETTING ACTION FROM:
action 3, numVisits=2326497, meanQ=6.185498, numObservations: 4
action 1, numVisits=4, meanQ=1.747500, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.534631 0.891533 0.631299 0.820184 0.380137 0.432751 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=131008, meanQ=8.938806, numObservations: 3
action 2, numVisits=121565, meanQ=8.938036, numObservations: 3
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2893392 episodes
GETTING ACTION FROM:
action 1, numVisits=2101051, meanQ=6.611874, numObservations: 3
action 2, numVisits=1044909, meanQ=6.609583, numObservations: 5
action 3, numVisits=4, meanQ=1.747500, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 1
Next state: 1 0.534631 0.891533 0.631299 0.820184 0.380137 0.432751 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 60
Initial state: 0 0.618929 0.850787 0.698295 0.808674 0.699934 0.922557 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2321539 episodes
GETTING ACTION FROM:
action 3, numVisits=2321531, meanQ=6.309369, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 1
action: 3
Next state: 1 0.618929 0.850787 0.698295 0.808674 0.699934 0.922557 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 61
Initial state: 0 0.58501 0.836868 0.539542 0.998505 0.663855 0.8005 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2310640 episodes
GETTING ACTION FROM:
action 1, numVisits=2310625, meanQ=6.240238, numObservations: 4
action 2, numVisits=7, meanQ=-0.575714, numObservations: 3
action 3, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.58501 0.836868 0.539542 0.998505 0.663855 0.8005 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 62
Initial state: 0 0.575 0.437571 0.634694 0.87758 0.654624 0.874759 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2295839 episodes
GETTING ACTION FROM:
action 1, numVisits=2295506, meanQ=6.228462, numObservations: 5
action 2, numVisits=318, meanQ=5.320681, numObservations: 3
action 3, numVisits=11, meanQ=3.541855, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.575 0.437571 0.634694 0.87758 0.654624 0.874759 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=124257, meanQ=8.669730, numObservations: 4
action 3, numVisits=41, meanQ=7.559766, numObservations: 3
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2882714 episodes
GETTING ACTION FROM:
action 2, numVisits=3006817, meanQ=6.587530, numObservations: 4
action 3, numVisits=192, meanQ=6.030471, numObservations: 3
action 1, numVisits=2, meanQ=-1.004950, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.575 0.437571 0.634694 0.87758 0.654624 0.874759 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 63
Initial state: 0 0.687226 0.854163 0.679717 0.806678 0.704565 0.385331 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2302263 episodes
GETTING ACTION FROM:
action 1, numVisits=2301940, meanQ=6.317285, numObservations: 5
action 2, numVisits=214, meanQ=5.773182, numObservations: 3
action 0, numVisits=106, meanQ=5.577818, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.687226 0.854163 0.679717 0.806678 0.704565 0.385331 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 64
Initial state: 0 0.528779 0.88545 0.509053 0.856055 0.623619 0.831774 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2301830 episodes
GETTING ACTION FROM:
action 3, numVisits=2170418, meanQ=6.314447, numObservations: 5
action 2, numVisits=113780, meanQ=6.248852, numObservations: 5
action 1, numVisits=17588, meanQ=6.195341, numObservations: 5
action 0, numVisits=42, meanQ=5.130437, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 3
Next state: 1 0.528779 0.88545 0.509053 0.856055 0.623619 0.831774 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 65
Initial state: 0 0.367838 0.309408 0.606808 0.897097 0.53422 0.856032 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2322174 episodes
GETTING ACTION FROM:
action 1, numVisits=2321909, meanQ=6.229819, numObservations: 4
action 2, numVisits=153, meanQ=5.538891, numObservations: 5
action -1, numVisits=70, meanQ=5.307405, numObservations: 1
action 0, numVisits=34, meanQ=4.908902, numObservations: 1
action 3, numVisits=8, meanQ=2.860012, numObservations: 3
action: 1
Next state: 0 0.367838 0.309408 0.606808 0.897097 0.53422 0.856032 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=182054, meanQ=8.867546, numObservations: 3
action 2, numVisits=137939, meanQ=8.865444, numObservations: 4
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2892514 episodes
GETTING ACTION FROM:
action 3, numVisits=2065501, meanQ=6.612979, numObservations: 3
action 2, numVisits=1147001, meanQ=6.611070, numObservations: 4
action 1, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 3
Next state: 1 0.367838 0.309408 0.606808 0.897097 0.53422 0.856032 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 66
Initial state: 0 0.675292 0.874374 0.853243 0.101651 0.538766 0.839139 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2326348 episodes
GETTING ACTION FROM:
action 2, numVisits=2326308, meanQ=6.232783, numObservations: 4
action 0, numVisits=34, meanQ=4.856575, numObservations: 1
action 3, numVisits=2, meanQ=-0.010000, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.675292 0.874374 0.853243 0.101651 0.538766 0.839139 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 67
Initial state: 0 0.605133 0.854275 0.610014 0.843344 0.505036 0.231243 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2302211 episodes
GETTING ACTION FROM:
action 1, numVisits=2302190, meanQ=6.183092, numObservations: 5
action 3, numVisits=13, meanQ=2.998462, numObservations: 3
action 2, numVisits=4, meanQ=1.747500, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.605133 0.854275 0.610014 0.843344 0.505036 0.231243 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 68
Initial state: 0 0.641327 0.881487 0.672168 0.882448 0.626382 0.526365 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2332034 episodes
GETTING ACTION FROM:
action 2, numVisits=2331931, meanQ=6.312844, numObservations: 4
action 0, numVisits=60, meanQ=5.300787, numObservations: 1
action 3, numVisits=29, meanQ=4.780000, numObservations: 3
action 1, numVisits=12, meanQ=3.157508, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.641327 0.881487 0.672168 0.882448 0.626382 0.526365 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 69
Initial state: 0 0.646151 0.811403 0.774301 0.919595 0.677615 0.852253 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2299346 episodes
GETTING ACTION FROM:
action 1, numVisits=2299257, meanQ=6.240631, numObservations: 5
action 0, numVisits=78, meanQ=5.371745, numObservations: 2
action 3, numVisits=7, meanQ=3.285714, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 1
Next state: 1 0.646151 0.811403 0.774301 0.919595 0.677615 0.852253 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 70
Initial state: 0 0.606065 0.864725 0.56519 0.862892 0.340271 0.95854 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2332019 episodes
GETTING ACTION FROM:
action 2, numVisits=2318957, meanQ=6.233068, numObservations: 4
action 3, numVisits=13056, meanQ=6.092977, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.606065 0.864725 0.56519 0.862892 0.340271 0.95854 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 71
Initial state: 0 0.557672 0.86352 0.691856 0.819577 0.664144 0.598852 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2308772 episodes
GETTING ACTION FROM:
action 3, numVisits=2308746, meanQ=6.232621, numObservations: 5
action 1, numVisits=16, meanQ=4.123750, numObservations: 3
action 2, numVisits=6, meanQ=2.331683, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.557672 0.86352 0.691856 0.819577 0.664144 0.598852 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 72
Initial state: 0 0.588871 0.835858 0.690956 0.31695 0.526942 0.816515 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2296834 episodes
GETTING ACTION FROM:
action 1, numVisits=2296761, meanQ=6.239029, numObservations: 5
action -1, numVisits=55, meanQ=5.209322, numObservations: 1
action 2, numVisits=15, meanQ=3.665347, numObservations: 4
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.588871 0.835858 0.690956 0.31695 0.526942 0.816515 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 73
Initial state: 0 0.530891 0.81353 0.599362 0.844209 0.589962 0.418209 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2308035 episodes
GETTING ACTION FROM:
action 1, numVisits=2308001, meanQ=6.231398, numObservations: 5
action -1, numVisits=20, meanQ=4.478819, numObservations: 1
action 3, numVisits=10, meanQ=3.109000, numObservations: 2
action 2, numVisits=2, meanQ=-0.010000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.530891 0.81353 0.599362 0.844209 0.589962 0.418209 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 74
Initial state: 0 0.657509 0.873426 0.0228268 0.679208 0.683538 0.839996 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2302273 episodes
GETTING ACTION FROM:
action 1, numVisits=1419912, meanQ=6.237811, numObservations: 5
action 2, numVisits=882280, meanQ=6.144867, numObservations: 3
action -1, numVisits=70, meanQ=5.265906, numObservations: 1
action 3, numVisits=9, meanQ=2.332233, numObservations: 3
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 1
Next state: 1 0.657509 0.873426 0.0228268 0.679208 0.683538 0.839996 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 75
Initial state: 0 0.644977 0.860764 0.628482 0.80523 0.231839 0.418455 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2347410 episodes
GETTING ACTION FROM:
action 2, numVisits=2347378, meanQ=6.239819, numObservations: 3
action 3, numVisits=20, meanQ=4.499010, numObservations: 2
action 1, numVisits=8, meanQ=2.623775, numObservations: 3
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.644977 0.860764 0.628482 0.80523 0.231839 0.418455 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 76
Initial state: 0 0.548369 0.852947 0.583381 0.812007 0.985767 0.690808 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2330457 episodes
GETTING ACTION FROM:
action 2, numVisits=2330439, meanQ=6.233379, numObservations: 4
action 1, numVisits=9, meanQ=3.554444, numObservations: 3
action 3, numVisits=5, meanQ=1.396000, numObservations: 3
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.548369 0.852947 0.583381 0.812007 0.985767 0.690808 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 77
Initial state: 0 0.803865 0.487422 0.679428 0.832334 0.538398 0.835241 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2275761 episodes
GETTING ACTION FROM:
action 2, numVisits=2275724, meanQ=6.148235, numObservations: 4
action 0, numVisits=23, meanQ=4.508227, numObservations: 1
action 3, numVisits=11, meanQ=3.545455, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.803865 0.487422 0.679428 0.832334 0.538398 0.835241 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 78
Initial state: 0 0.232998 0.687483 0.5935 0.825481 0.554723 0.88986 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2328634 episodes
GETTING ACTION FROM:
action 2, numVisits=2328459, meanQ=6.230591, numObservations: 5
action 3, numVisits=170, meanQ=5.582114, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.232998 0.687483 0.5935 0.825481 0.554723 0.88986 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 79
Initial state: 0 0.633878 0.899584 0.558812 0.802656 0.252725 0.604847 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2303892 episodes
GETTING ACTION FROM:
action 1, numVisits=2303794, meanQ=6.225061, numObservations: 5
action -1, numVisits=79, meanQ=5.353246, numObservations: 1
action 2, numVisits=14, meanQ=3.992857, numObservations: 2
action 3, numVisits=3, meanQ=-0.670000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.633878 0.899584 0.558812 0.802656 0.252725 0.604847 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 80
Initial state: 0 0.657049 0.814754 0.316526 0.7288 0.532603 0.849681 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2302902 episodes
GETTING ACTION FROM:
action 1, numVisits=2302840, meanQ=6.228687, numObservations: 5
action -1, numVisits=36, meanQ=4.924765, numObservations: 1
action 0, numVisits=18, meanQ=4.380134, numObservations: 1
action 3, numVisits=7, meanQ=1.998571, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.657049 0.814754 0.316526 0.7288 0.532603 0.849681 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 81
Initial state: 0 0.66736 0.887458 0.645838 0.80823 0.967282 0.0269578 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2325062 episodes
GETTING ACTION FROM:
action 1, numVisits=2325056, meanQ=6.229078, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.66736 0.887458 0.645838 0.80823 0.967282 0.0269578 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 82
Initial state: 0 0.863314 0.22636 0.690765 0.87055 0.65864 0.834068 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2311429 episodes
GETTING ACTION FROM:
action 2, numVisits=2311420, meanQ=6.236047, numObservations: 4
action 1, numVisits=4, meanQ=1.747500, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.863314 0.22636 0.690765 0.87055 0.65864 0.834068 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 83
Initial state: 0 0.70661 0.429403 0.621915 0.886248 0.644225 0.856523 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2326189 episodes
GETTING ACTION FROM:
action 2, numVisits=1519488, meanQ=6.323444, numObservations: 5
action 1, numVisits=806632, meanQ=6.246171, numObservations: 4
action -1, numVisits=66, meanQ=5.344547, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.70661 0.429403 0.621915 0.886248 0.644225 0.856523 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 84
Initial state: 0 0.591312 0.864783 0.640077 0.870756 0.652375 0.644707 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2330398 episodes
GETTING ACTION FROM:
action 2, numVisits=2329051, meanQ=6.179227, numObservations: 4
action 3, numVisits=1268, meanQ=5.968403, numObservations: 4
action 0, numVisits=66, meanQ=5.227915, numObservations: 1
action 1, numVisits=11, meanQ=3.329091, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.591312 0.864783 0.640077 0.870756 0.652375 0.644707 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 85
Initial state: 0 0.526632 0.847099 0.347048 0.270018 0.615277 0.848467 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2330879 episodes
GETTING ACTION FROM:
action 1, numVisits=2330803, meanQ=6.220652, numObservations: 4
action 3, numVisits=70, meanQ=5.190433, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.526632 0.847099 0.347048 0.270018 0.615277 0.848467 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 86
Initial state: 0 0.660273 0.822175 0.497281 0.961029 0.500094 0.877854 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2320728 episodes
GETTING ACTION FROM:
action 1, numVisits=2320692, meanQ=6.234167, numObservations: 4
action 0, numVisits=27, meanQ=4.720330, numObservations: 1
action 3, numVisits=6, meanQ=2.496683, numObservations: 3
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.660273 0.822175 0.497281 0.961029 0.500094 0.877854 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 87
Initial state: 0 0.538955 0.848708 0.224632 0.780666 0.603481 0.867039 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1633514 episodes
GETTING ACTION FROM:
action 0, numVisits=1629712, meanQ=6.289507, numObservations: 2
action -1, numVisits=3792, meanQ=4.158118, numObservations: 1
action 3, numVisits=4, meanQ=-0.505000, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=4, meanQ=-1.000000, numObservations: 3
action: 0
Next state: 0 0.538955 0.848708 0.224632 0.780666 0.603481 0.867039 w: 1
Observation: 0 0 0.910963 0 0.804663 0 0.822224 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1151262, meanQ=8.247135, numObservations: 5
action 3, numVisits=4781, meanQ=5.631607, numObservations: 4
action 1, numVisits=14, meanQ=3.927871, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2521208 episodes
GETTING ACTION FROM:
action 2, numVisits=3672470, meanQ=6.862077, numObservations: 5
action 3, numVisits=4781, meanQ=5.631607, numObservations: 4
action 1, numVisits=14, meanQ=3.927871, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.538955 0.848708 0.224632 0.780666 0.603481 0.867039 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=141900, meanQ=8.940272, numObservations: 3
action 3, numVisits=139064, meanQ=8.940094, numObservations: 3
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2888875 episodes
GETTING ACTION FROM:
action 3, numVisits=2028152, meanQ=6.555581, numObservations: 4
action 1, numVisits=1141682, meanQ=6.553695, numObservations: 4
action 2, numVisits=4, meanQ=1.747500, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 3
Next state: 1 0.538955 0.848708 0.224632 0.780666 0.603481 0.867039 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 5.8309
Run # 88
Initial state: 0 0.593818 0.881749 0.645472 0.883084 0.67039 0.397257 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2297999 episodes
GETTING ACTION FROM:
action 3, numVisits=2297930, meanQ=6.181578, numObservations: 5
action -1, numVisits=26, meanQ=4.658533, numObservations: 1
action 0, numVisits=22, meanQ=4.542177, numObservations: 1
action 1, numVisits=16, meanQ=3.436875, numObservations: 2
action 2, numVisits=5, meanQ=1.396000, numObservations: 4
action: 3
Next state: 2 0.593818 0.881749 0.645472 0.883084 0.67039 0.397257 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 89
Initial state: 0 0.658202 0.85128 0.689639 0.84578 0.966941 0.447712 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2291628 episodes
GETTING ACTION FROM:
action 1, numVisits=2291621, meanQ=6.244664, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.658202 0.85128 0.689639 0.84578 0.966941 0.447712 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 90
Initial state: 0 0.104758 0.0559244 0.574598 0.847822 0.606489 0.841163 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2341250 episodes
GETTING ACTION FROM:
action 3, numVisits=2341226, meanQ=6.231966, numObservations: 3
action -1, numVisits=17, meanQ=4.334318, numObservations: 1
action 1, numVisits=3, meanQ=-0.670000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.104758 0.0559244 0.574598 0.847822 0.606489 0.841163 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 91
Initial state: 0 0.636219 0.8951 0.640444 0.871256 0.865898 0.0216253 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2339447 episodes
GETTING ACTION FROM:
action 1, numVisits=2339351, meanQ=6.237515, numObservations: 3
action 2, numVisits=62, meanQ=5.248550, numObservations: 5
action -1, numVisits=29, meanQ=4.780222, numObservations: 1
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.636219 0.8951 0.640444 0.871256 0.865898 0.0216253 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 92
Initial state: 0 0.664202 0.824356 0.665638 0.812473 0.75401 0.938707 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2294590 episodes
GETTING ACTION FROM:
action 3, numVisits=2294501, meanQ=6.180403, numObservations: 5
action 2, numVisits=68, meanQ=5.174707, numObservations: 4
action 0, numVisits=18, meanQ=4.147284, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.664202 0.824356 0.665638 0.812473 0.75401 0.938707 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 93
Initial state: 0 0.606896 0.825371 0.666304 0.849138 0.659153 0.755298 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2288291 episodes
GETTING ACTION FROM:
action 3, numVisits=2288221, meanQ=6.237622, numObservations: 5
action 2, numVisits=64, meanQ=5.251252, numObservations: 4
action 1, numVisits=2, meanQ=-0.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.606896 0.825371 0.666304 0.849138 0.659153 0.755298 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 94
Initial state: 0 0.6843 0.880546 0.581232 0.271062 0.699135 0.834483 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2326539 episodes
GETTING ACTION FROM:
action 2, numVisits=2326528, meanQ=6.228543, numObservations: 4
action 1, numVisits=6, meanQ=0.650000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.6843 0.880546 0.581232 0.271062 0.699135 0.834483 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 95
Initial state: 0 0.54528 0.894558 0.567795 0.838535 0.908954 0.0358402 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2308454 episodes
GETTING ACTION FROM:
action 2, numVisits=2308408, meanQ=6.230702, numObservations: 5
action -1, numVisits=40, meanQ=5.003233, numObservations: 1
action 1, numVisits=3, meanQ=-0.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.54528 0.894558 0.567795 0.838535 0.908954 0.0358402 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 96
Initial state: 0 0.513701 0.879878 0.0525857 0.437091 0.664676 0.847576 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2310334 episodes
GETTING ACTION FROM:
action 2, numVisits=2310312, meanQ=6.182166, numObservations: 5
action 1, numVisits=17, meanQ=4.282353, numObservations: 4
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.513701 0.879878 0.0525857 0.437091 0.664676 0.847576 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=141421, meanQ=8.940336, numObservations: 3
action 3, numVisits=109346, meanQ=8.937791, numObservations: 3
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2851078 episodes
GETTING ACTION FROM:
action 3, numVisits=1650729, meanQ=6.641061, numObservations: 4
action 1, numVisits=1451112, meanQ=6.640638, numObservations: 5
action 2, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 3
Next state: 1 0.513701 0.879878 0.0525857 0.437091 0.664676 0.847576 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 97
Initial state: 0 0.592445 0.871984 0.467373 0.705377 0.570486 0.825476 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2328338 episodes
GETTING ACTION FROM:
action 1, numVisits=2328301, meanQ=6.238398, numObservations: 4
action 0, numVisits=33, meanQ=4.885609, numObservations: 1
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.592445 0.871984 0.467373 0.705377 0.570486 0.825476 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 98
Initial state: 0 0.614844 0.805062 0.631744 0.886411 0.130528 0.227962 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2322944 episodes
GETTING ACTION FROM:
action 3, numVisits=2322913, meanQ=6.312912, numObservations: 4
action 2, numVisits=26, meanQ=4.806546, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.614844 0.805062 0.631744 0.886411 0.130528 0.227962 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=143059, meanQ=8.708681, numObservations: 4
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2872515 episodes
GETTING ACTION FROM:
action 2, numVisits=3015553, meanQ=6.473585, numObservations: 4
action 1, numVisits=19, meanQ=4.315263, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 1
action: 2
Next state: 1 0.614844 0.805062 0.631744 0.886411 0.130528 0.227962 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 99
Initial state: 0 0.699831 0.874144 0.669866 0.887347 0.066221 0.389815 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2368015 episodes
GETTING ACTION FROM:
action 2, numVisits=2367990, meanQ=6.238016, numObservations: 3
action -1, numVisits=19, meanQ=4.466675, numObservations: 1
action 3, numVisits=3, meanQ=-0.670000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.699831 0.874144 0.669866 0.887347 0.066221 0.389815 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 100
Initial state: 0 0.65765 0.847394 0.5424 0.81841 0.681655 0.837982 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2309714 episodes
GETTING ACTION FROM:
action 2, numVisits=2309705, meanQ=6.231094, numObservations: 5
action 3, numVisits=4, meanQ=1.747500, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.65765 0.847394 0.5424 0.81841 0.681655 0.837982 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 101
Initial state: 0 0.667099 0.84414 0.0468341 0.652922 0.62015 0.878636 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2325636 episodes
GETTING ACTION FROM:
action 3, numVisits=2325552, meanQ=6.232613, numObservations: 4
action -1, numVisits=66, meanQ=5.264714, numObservations: 1
action 2, numVisits=15, meanQ=2.247333, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.667099 0.84414 0.0468341 0.652922 0.62015 0.878636 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 102
Initial state: 0 0.669259 0.88765 0.478268 0.785826 0.513576 0.801392 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2325409 episodes
GETTING ACTION FROM:
action 1, numVisits=2325397, meanQ=6.233685, numObservations: 4
action 2, numVisits=4, meanQ=1.747500, numObservations: 3
action 3, numVisits=4, meanQ=1.747500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.669259 0.88765 0.478268 0.785826 0.513576 0.801392 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=103393, meanQ=6.505721, numObservations: 3
action 1, numVisits=20, meanQ=4.331005, numObservations: 3
action 2, numVisits=8, meanQ=4.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2870293 episodes
GETTING ACTION FROM:
action 3, numVisits=2973670, meanQ=6.551701, numObservations: 3
action 1, numVisits=20, meanQ=4.331005, numObservations: 3
action 2, numVisits=21, meanQ=4.238095, numObservations: 4
action 0, numVisits=3, meanQ=1.300000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 3
Next state: 1 0.669259 0.88765 0.478268 0.785826 0.513576 0.801392 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 103
Initial state: 0 0.53933 0.867861 0.512618 0.882295 0.530122 0.278509 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2331900 episodes
GETTING ACTION FROM:
action 2, numVisits=2331139, meanQ=6.229539, numObservations: 4
action 1, numVisits=732, meanQ=5.950559, numObservations: 4
action -1, numVisits=23, meanQ=4.586444, numObservations: 1
action 3, numVisits=4, meanQ=1.747500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.53933 0.867861 0.512618 0.882295 0.530122 0.278509 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 104
Initial state: 0 0.539475 0.882937 0.546186 0.841135 0.588032 0.0307562 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2326431 episodes
GETTING ACTION FROM:
action 3, numVisits=2326367, meanQ=6.232871, numObservations: 4
action -1, numVisits=44, meanQ=5.076570, numObservations: 1
action 2, numVisits=11, meanQ=3.725455, numObservations: 3
action 1, numVisits=7, meanQ=3.285714, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.539475 0.882937 0.546186 0.841135 0.588032 0.0307562 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=280888, meanQ=8.895149, numObservations: 4
action 1, numVisits=37784, meanQ=8.871651, numObservations: 5
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2870965 episodes
GETTING ACTION FROM:
action 2, numVisits=2579110, meanQ=6.627692, numObservations: 4
action 1, numVisits=610416, meanQ=6.623328, numObservations: 5
action 3, numVisits=110, meanQ=5.857637, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 2
Next state: 1 0.539475 0.882937 0.546186 0.841135 0.588032 0.0307562 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 105
Initial state: 0 0.621801 0.821831 0.645258 0.822339 0.362276 0.726303 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2328854 episodes
GETTING ACTION FROM:
action 1, numVisits=2328774, meanQ=6.239355, numObservations: 4
action 2, numVisits=72, meanQ=5.298894, numObservations: 3
action 3, numVisits=4, meanQ=1.475000, numObservations: 3
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 1
Next state: 1 0.621801 0.821831 0.645258 0.822339 0.362276 0.726303 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 106
Initial state: 0 0.790231 0.841036 0.509012 0.832718 0.588957 0.803486 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2329860 episodes
GETTING ACTION FROM:
action 1, numVisits=2329792, meanQ=6.194754, numObservations: 4
action -1, numVisits=63, meanQ=5.228222, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.790231 0.841036 0.509012 0.832718 0.588957 0.803486 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 107
Initial state: 0 0.686243 0.883627 0.903138 0.621961 0.697007 0.890278 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2317720 episodes
GETTING ACTION FROM:
action 2, numVisits=2317601, meanQ=6.234783, numObservations: 5
action -1, numVisits=113, meanQ=5.514435, numObservations: 1
action 1, numVisits=3, meanQ=-0.670000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.686243 0.883627 0.903138 0.621961 0.697007 0.890278 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 108
Initial state: 0 0.14941 0.280879 0.566948 0.896711 0.62461 0.896495 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2320937 episodes
GETTING ACTION FROM:
action 3, numVisits=2320901, meanQ=6.234985, numObservations: 4
action 0, numVisits=30, meanQ=4.824079, numObservations: 1
action 1, numVisits=2, meanQ=-0.010000, numObservations: 2
action 2, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.14941 0.280879 0.566948 0.896711 0.62461 0.896495 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 109
Initial state: 0 0.562876 0.430477 0.611645 0.897764 0.687771 0.815166 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2305581 episodes
GETTING ACTION FROM:
action 1, numVisits=2305550, meanQ=6.230398, numObservations: 5
action 2, numVisits=19, meanQ=4.257895, numObservations: 3
action 3, numVisits=8, meanQ=3.010000, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.562876 0.430477 0.611645 0.897764 0.687771 0.815166 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=124831, meanQ=8.687520, numObservations: 3
action 2, numVisits=19, meanQ=6.894216, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2892226 episodes
GETTING ACTION FROM:
action 3, numVisits=3015921, meanQ=6.455871, numObservations: 3
action 2, numVisits=1152, meanQ=6.231806, numObservations: 4
action 0, numVisits=3, meanQ=1.300000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.562876 0.430477 0.611645 0.897764 0.687771 0.815166 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 110
Initial state: 0 0.69073 0.860627 0.517736 0.896042 0.411415 0.791613 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2339794 episodes
GETTING ACTION FROM:
action 2, numVisits=2339748, meanQ=6.241196, numObservations: 4
action -1, numVisits=32, meanQ=4.889410, numObservations: 1
action 1, numVisits=10, meanQ=2.980000, numObservations: 3
action 3, numVisits=2, meanQ=-1.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.69073 0.860627 0.517736 0.896042 0.411415 0.791613 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 111
Initial state: 0 0.503527 0.800066 0.635319 0.255282 0.508354 0.885132 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2328747 episodes
GETTING ACTION FROM:
action 3, numVisits=2328686, meanQ=6.233397, numObservations: 4
action 0, numVisits=47, meanQ=5.110420, numObservations: 1
action 2, numVisits=6, meanQ=2.331683, numObservations: 3
action 1, numVisits=6, meanQ=2.150017, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 3
Next state: 1 0.503527 0.800066 0.635319 0.255282 0.508354 0.885132 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 112
Initial state: 0 0.584981 0.860953 0.5927 0.178088 0.669451 0.893517 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2353033 episodes
GETTING ACTION FROM:
action 2, numVisits=2352889, meanQ=6.232693, numObservations: 3
action 0, numVisits=140, meanQ=5.586853, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.584981 0.860953 0.5927 0.178088 0.669451 0.893517 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 113
Initial state: 0 0.660719 0.887526 0.591343 0.876781 0.78809 0.353699 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2301269 episodes
GETTING ACTION FROM:
action 2, numVisits=2295364, meanQ=6.236703, numObservations: 4
action 1, numVisits=5899, meanQ=6.138832, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.660719 0.887526 0.591343 0.876781 0.78809 0.353699 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 114
Initial state: 0 0.821167 0.945759 0.505991 0.841119 0.697189 0.883309 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2332531 episodes
GETTING ACTION FROM:
action 2, numVisits=2332422, meanQ=6.234372, numObservations: 4
action 0, numVisits=68, meanQ=5.299370, numObservations: 1
action 3, numVisits=22, meanQ=4.445005, numObservations: 4
action 1, numVisits=17, meanQ=4.165300, numObservations: 3
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.821167 0.945759 0.505991 0.841119 0.697189 0.883309 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 115
Initial state: 0 0.623701 0.857841 0.0323051 0.543486 0.550366 0.821549 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2321030 episodes
GETTING ACTION FROM:
action 2, numVisits=2320989, meanQ=6.183030, numObservations: 5
action -1, numVisits=24, meanQ=4.598020, numObservations: 1
action 1, numVisits=11, meanQ=3.626364, numObservations: 3
action 3, numVisits=4, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.623701 0.857841 0.0323051 0.543486 0.550366 0.821549 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=125272, meanQ=8.689887, numObservations: 4
action 1, numVisits=12, meanQ=5.665842, numObservations: 1
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2894583 episodes
GETTING ACTION FROM:
action 3, numVisits=3019833, meanQ=6.546815, numObservations: 4
action 1, numVisits=31, meanQ=5.128713, numObservations: 3
action 2, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 3
Next state: 0 0.623701 0.857841 0.0323051 0.543486 0.550366 0.821549 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=24714, meanQ=8.840253, numObservations: 4
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2917661 episodes
GETTING ACTION FROM:
action 1, numVisits=2942355, meanQ=6.545631, numObservations: 4
action 3, numVisits=10, meanQ=4.099000, numObservations: 4
action 2, numVisits=10, meanQ=3.990000, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 1
Next state: 1 0.623701 0.857841 0.0323051 0.543486 0.550366 0.821549 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.8309
Run # 116
Initial state: 0 0.669711 0.822335 0.382378 0.143139 0.568982 0.846968 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2297083 episodes
GETTING ACTION FROM:
action 1, numVisits=2297057, meanQ=6.231738, numObservations: 4
action -1, numVisits=16, meanQ=4.235989, numObservations: 1
action 2, numVisits=6, meanQ=2.333333, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.669711 0.822335 0.382378 0.143139 0.568982 0.846968 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 117
Initial state: 0 0.654842 0.859776 0.570719 0.861685 0.4865 0.936503 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2282364 episodes
GETTING ACTION FROM:
action 3, numVisits=2282300, meanQ=6.233036, numObservations: 5
action 2, numVisits=58, meanQ=4.747074, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.654842 0.859776 0.570719 0.861685 0.4865 0.936503 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=102120, meanQ=6.548621, numObservations: 3
action 3, numVisits=5, meanQ=2.980000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2933590 episodes
GETTING ACTION FROM:
action 2, numVisits=3035708, meanQ=6.457251, numObservations: 3
action 3, numVisits=5, meanQ=2.980000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.654842 0.859776 0.570719 0.861685 0.4865 0.936503 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 118
Initial state: 0 0.550605 0.632292 0.617818 0.856866 0.656646 0.884723 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2340399 episodes
GETTING ACTION FROM:
action 2, numVisits=2340392, meanQ=6.237611, numObservations: 4
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.550605 0.632292 0.617818 0.856866 0.656646 0.884723 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 119
Initial state: 0 0.592086 0.820405 0.411057 0.0318307 0.501137 0.88499 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2297125 episodes
GETTING ACTION FROM:
action 3, numVisits=2297083, meanQ=6.228371, numObservations: 5
action -1, numVisits=20, meanQ=4.450510, numObservations: 1
action 1, numVisits=18, meanQ=3.993894, numObservations: 4
action 2, numVisits=2, meanQ=-0.010000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.592086 0.820405 0.411057 0.0318307 0.501137 0.88499 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=103643, meanQ=6.490115, numObservations: 4
action 3, numVisits=21, meanQ=4.332381, numObservations: 3
action 1, numVisits=2, meanQ=-0.509950, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2884765 episodes
GETTING ACTION FROM:
action 2, numVisits=2988406, meanQ=6.382374, numObservations: 4
action 3, numVisits=21, meanQ=4.332381, numObservations: 3
action 1, numVisits=2, meanQ=-0.509950, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.592086 0.820405 0.411057 0.0318307 0.501137 0.88499 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=60710, meanQ=8.879278, numObservations: 3
action 3, numVisits=234, meanQ=8.449529, numObservations: 3
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2945674 episodes
GETTING ACTION FROM:
action 3, numVisits=2706416, meanQ=6.863904, numObservations: 3
action 1, numVisits=300199, meanQ=6.852822, numObservations: 3
action 2, numVisits=4, meanQ=1.747500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.592086 0.820405 0.411057 0.0318307 0.501137 0.88499 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.8309
Run # 120
Initial state: 0 0.579059 0.800864 0.977715 0.616533 0.611695 0.890732 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2314486 episodes
GETTING ACTION FROM:
action 3, numVisits=2314454, meanQ=6.226335, numObservations: 4
action 1, numVisits=17, meanQ=3.762953, numObservations: 2
action 2, numVisits=11, meanQ=3.626364, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.579059 0.800864 0.977715 0.616533 0.611695 0.890732 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 121
Initial state: 0 0.383567 0.198288 0.595902 0.838337 0.511619 0.86856 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2330380 episodes
GETTING ACTION FROM:
action 3, numVisits=2330356, meanQ=6.236072, numObservations: 4
action -1, numVisits=17, meanQ=4.350253, numObservations: 1
action 2, numVisits=4, meanQ=1.745025, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.383567 0.198288 0.595902 0.838337 0.511619 0.86856 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 122
Initial state: 0 0.560562 0.807807 0.72572 0.195551 0.662348 0.862691 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2323636 episodes
GETTING ACTION FROM:
action 2, numVisits=2323603, meanQ=6.236593, numObservations: 5
action -1, numVisits=27, meanQ=4.767439, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 2
Next state: 2 0.560562 0.807807 0.72572 0.195551 0.662348 0.862691 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 123
Initial state: 0 0.584669 0.805623 0.548395 0.880225 0.464695 0.538074 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2276924 episodes
GETTING ACTION FROM:
action 3, numVisits=2275757, meanQ=6.143716, numObservations: 4
action 2, numVisits=1088, meanQ=5.881588, numObservations: 5
action 0, numVisits=72, meanQ=5.229373, numObservations: 1
action 1, numVisits=5, meanQ=1.396000, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.584669 0.805623 0.548395 0.880225 0.464695 0.538074 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=257094, meanQ=8.860084, numObservations: 4
action 1, numVisits=112430, meanQ=8.852257, numObservations: 5
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2860411 episodes
GETTING ACTION FROM:
action 2, numVisits=1808270, meanQ=6.817426, numObservations: 4
action 1, numVisits=1421664, meanQ=6.816595, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 2
Next state: 1 0.584669 0.805623 0.548395 0.880225 0.464695 0.538074 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 124
Initial state: 0 0.029201 0.879173 0.525169 0.841858 0.55622 0.831894 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2319615 episodes
GETTING ACTION FROM:
action 3, numVisits=2319548, meanQ=6.237665, numObservations: 4
action 0, numVisits=41, meanQ=5.024893, numObservations: 1
action 2, numVisits=22, meanQ=3.225909, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.029201 0.879173 0.525169 0.841858 0.55622 0.831894 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 125
Initial state: 0 0.520777 0.848281 0.550741 0.8199 0.371079 0.0768335 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2324948 episodes
GETTING ACTION FROM:
action 1, numVisits=2324921, meanQ=6.227068, numObservations: 4
action 0, numVisits=20, meanQ=4.396077, numObservations: 1
action 2, numVisits=4, meanQ=1.745025, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.520777 0.848281 0.550741 0.8199 0.371079 0.0768335 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 126
Initial state: 0 0.00575729 0.30435 0.597151 0.882263 0.590727 0.898018 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2323909 episodes
GETTING ACTION FROM:
action 3, numVisits=2323883, meanQ=6.184011, numObservations: 4
action 1, numVisits=18, meanQ=3.943350, numObservations: 3
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.00575729 0.30435 0.597151 0.882263 0.590727 0.898018 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 127
Initial state: 0 0.507589 0.873895 0.0421098 0.0170594 0.649845 0.869397 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2323485 episodes
GETTING ACTION FROM:
action 3, numVisits=2323345, meanQ=6.236753, numObservations: 4
action 2, numVisits=110, meanQ=5.502002, numObservations: 4
action 1, numVisits=26, meanQ=4.715769, numObservations: 4
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.507589 0.873895 0.0421098 0.0170594 0.649845 0.869397 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 128
Initial state: 0 0.101119 0.60301 0.645212 0.831171 0.614113 0.839508 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2319787 episodes
GETTING ACTION FROM:
action 3, numVisits=2319681, meanQ=6.237051, numObservations: 4
action 2, numVisits=40, meanQ=5.022003, numObservations: 4
action 0, numVisits=34, meanQ=4.914965, numObservations: 1
action 1, numVisits=30, meanQ=4.332673, numObservations: 4
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 3
Next state: 0 0.101119 0.60301 0.645212 0.831171 0.614113 0.839508 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=103472, meanQ=6.508854, numObservations: 4
action 3, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2867324 episodes
GETTING ACTION FROM:
action 1, numVisits=2970796, meanQ=6.853906, numObservations: 4
action 3, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.101119 0.60301 0.645212 0.831171 0.614113 0.839508 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=33426, meanQ=8.885904, numObservations: 5
action 3, numVisits=361, meanQ=8.571977, numObservations: 3
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2884737 episodes
GETTING ACTION FROM:
action 3, numVisits=2395432, meanQ=6.675097, numObservations: 4
action 2, numVisits=523086, meanQ=6.650874, numObservations: 5
action 1, numVisits=5, meanQ=3.198000, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 3
Next state: 1 0.101119 0.60301 0.645212 0.831171 0.614113 0.839508 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.8309
Run # 129
Initial state: 0 0.62779 0.894111 0.643644 0.815539 0.227557 0.737634 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2343702 episodes
GETTING ACTION FROM:
action 2, numVisits=2343637, meanQ=6.238269, numObservations: 4
action 0, numVisits=24, meanQ=4.640329, numObservations: 1
action -1, numVisits=20, meanQ=4.502930, numObservations: 1
action 1, numVisits=17, meanQ=4.358235, numObservations: 3
action 3, numVisits=4, meanQ=-0.505000, numObservations: 2
action: 2
Next state: 1 0.62779 0.894111 0.643644 0.815539 0.227557 0.737634 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 130
Initial state: 0 0.566718 0.842013 0.695369 0.82267 0.186066 0.535362 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2346647 episodes
GETTING ACTION FROM:
action 2, numVisits=2346620, meanQ=6.230081, numObservations: 4
action -1, numVisits=16, meanQ=4.126121, numObservations: 1
action 1, numVisits=8, meanQ=1.747500, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.566718 0.842013 0.695369 0.82267 0.186066 0.535362 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 131
Initial state: 0 0.551564 0.0597009 0.587917 0.876215 0.506536 0.849857 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2326032 episodes
GETTING ACTION FROM:
action 3, numVisits=2326024, meanQ=6.179226, numObservations: 4
action 1, numVisits=3, meanQ=-0.670000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.551564 0.0597009 0.587917 0.876215 0.506536 0.849857 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 132
Initial state: 0 0.684759 0.803935 0.603516 0.819433 0.889463 0.920928 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2343653 episodes
GETTING ACTION FROM:
action 3, numVisits=2343578, meanQ=6.304213, numObservations: 4
action -1, numVisits=54, meanQ=5.261397, numObservations: 1
action 2, numVisits=18, meanQ=4.109450, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.684759 0.803935 0.603516 0.819433 0.889463 0.920928 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 133
Initial state: 0 0.590361 0.867051 0.611166 0.814175 0.914182 0.0107703 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2309689 episodes
GETTING ACTION FROM:
action 3, numVisits=2309659, meanQ=6.235228, numObservations: 4
action 2, numVisits=22, meanQ=4.444555, numObservations: 3
action 1, numVisits=4, meanQ=1.247550, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.590361 0.867051 0.611166 0.814175 0.914182 0.0107703 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 134
Initial state: 0 0.676216 0.850534 0.658426 0.80344 0.282897 0.79454 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2341153 episodes
GETTING ACTION FROM:
action 2, numVisits=2341003, meanQ=6.233603, numObservations: 4
action -1, numVisits=65, meanQ=5.276924, numObservations: 1
action 0, numVisits=48, meanQ=5.126238, numObservations: 1
action 1, numVisits=26, meanQ=4.460008, numObservations: 3
action 3, numVisits=11, meanQ=3.545455, numObservations: 3
action: 2
Next state: 1 0.676216 0.850534 0.658426 0.80344 0.282897 0.79454 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 135
Initial state: 0 0.807427 0.0902713 0.699721 0.800497 0.68022 0.819851 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2298454 episodes
GETTING ACTION FROM:
action 1, numVisits=2298428, meanQ=6.234001, numObservations: 5
action 3, numVisits=21, meanQ=3.808576, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.807427 0.0902713 0.699721 0.800497 0.68022 0.819851 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 136
Initial state: 0 0.587379 0.84634 0.451714 0.0312023 0.591708 0.818368 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2315397 episodes
GETTING ACTION FROM:
action 2, numVisits=2315391, meanQ=6.240114, numObservations: 5
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.587379 0.84634 0.451714 0.0312023 0.591708 0.818368 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=135374, meanQ=8.939099, numObservations: 3
action 3, numVisits=114974, meanQ=8.937462, numObservations: 3
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2903148 episodes
GETTING ACTION FROM:
action 3, numVisits=1580142, meanQ=6.514368, numObservations: 4
action 1, numVisits=1573342, meanQ=6.514299, numObservations: 3
action 2, numVisits=11, meanQ=3.544555, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 3
Next state: 1 0.587379 0.84634 0.451714 0.0312023 0.591708 0.818368 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 137
Initial state: 0 0.560999 0.800454 0.523709 0.879014 0.42098 0.505682 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2314347 episodes
GETTING ACTION FROM:
action 2, numVisits=2314330, meanQ=6.231690, numObservations: 4
action 3, numVisits=9, meanQ=3.554444, numObservations: 2
action 1, numVisits=4, meanQ=2.242500, numObservations: 3
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.560999 0.800454 0.523709 0.879014 0.42098 0.505682 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 138
Initial state: 0 0.634754 0.853535 0.723931 0.680579 0.55608 0.886868 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2279059 episodes
GETTING ACTION FROM:
action 3, numVisits=2279051, meanQ=6.143425, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.634754 0.853535 0.723931 0.680579 0.55608 0.886868 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 139
Initial state: 0 0.541213 0.873784 0.645653 0.82451 0.010963 0.30629 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2345487 episodes
GETTING ACTION FROM:
action 2, numVisits=2345449, meanQ=6.226882, numObservations: 3
action 0, numVisits=30, meanQ=4.769637, numObservations: 1
action 3, numVisits=4, meanQ=-0.505000, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.541213 0.873784 0.645653 0.82451 0.010963 0.30629 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 140
Initial state: 0 0.673076 0.803837 0.942879 0.426283 0.617975 0.835345 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2309071 episodes
GETTING ACTION FROM:
action 1, numVisits=2308983, meanQ=6.238706, numObservations: 5
action 0, numVisits=57, meanQ=5.223421, numObservations: 1
action -1, numVisits=27, meanQ=4.732641, numObservations: 1
action 3, numVisits=2, meanQ=-0.010000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 1
Next state: 1 0.673076 0.803837 0.942879 0.426283 0.617975 0.835345 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 141
Initial state: 0 0.513122 0.816919 0.569775 0.807859 0.271665 0.632283 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2344252 episodes
GETTING ACTION FROM:
action 2, numVisits=1610281, meanQ=6.226344, numObservations: 3
action 3, numVisits=733914, meanQ=6.218838, numObservations: 4
action 0, numVisits=41, meanQ=5.006964, numObservations: 1
action 1, numVisits=14, meanQ=4.070007, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.513122 0.816919 0.569775 0.807859 0.271665 0.632283 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 142
Initial state: 0 0.535902 0.893442 0.52197 0.602024 0.661353 0.861842 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2325614 episodes
GETTING ACTION FROM:
action 1, numVisits=2325392, meanQ=6.229666, numObservations: 4
action 3, numVisits=183, meanQ=5.664956, numObservations: 4
action -1, numVisits=27, meanQ=4.751505, numObservations: 1
action 2, numVisits=10, meanQ=2.999010, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.535902 0.893442 0.52197 0.602024 0.661353 0.861842 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 143
Initial state: 0 0.552121 0.860661 0.727735 0.0397755 0.685013 0.807313 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2295498 episodes
GETTING ACTION FROM:
action 3, numVisits=2295452, meanQ=6.239433, numObservations: 5
action -1, numVisits=32, meanQ=4.789705, numObservations: 1
action 2, numVisits=7, meanQ=1.997157, numObservations: 3
action 1, numVisits=5, meanQ=1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.552121 0.860661 0.727735 0.0397755 0.685013 0.807313 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 144
Initial state: 0 0.644994 0.804511 0.76461 0.972666 0.673799 0.890531 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2293603 episodes
GETTING ACTION FROM:
action 2, numVisits=2293595, meanQ=6.229091, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.644994 0.804511 0.76461 0.972666 0.673799 0.890531 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 145
Initial state: 0 0.613065 0.864756 0.522088 0.887145 0.6297 0.824662 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2327138 episodes
GETTING ACTION FROM:
action 1, numVisits=2327127, meanQ=6.221311, numObservations: 4
action 2, numVisits=6, meanQ=0.830017, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.613065 0.864756 0.522088 0.887145 0.6297 0.824662 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 146
Initial state: 0 0.790121 0.592705 0.55403 0.811868 0.673699 0.843846 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2332769 episodes
GETTING ACTION FROM:
action 1, numVisits=2332755, meanQ=6.185986, numObservations: 4
action 3, numVisits=8, meanQ=1.747500, numObservations: 2
action 2, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 1
Next state: 2 0.790121 0.592705 0.55403 0.811868 0.673699 0.843846 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 147
Initial state: 0 0.545915 0.885795 0.571018 0.899963 0.945352 0.682362 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2310935 episodes
GETTING ACTION FROM:
action 1, numVisits=2310859, meanQ=6.231279, numObservations: 5
action -1, numVisits=51, meanQ=5.153301, numObservations: 1
action 2, numVisits=9, meanQ=3.553344, numObservations: 4
action 3, numVisits=14, meanQ=3.427143, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.545915 0.885795 0.571018 0.899963 0.945352 0.682362 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 148
Initial state: 0 0.577082 0.884002 0.274039 0.859726 0.602328 0.800524 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2293235 episodes
GETTING ACTION FROM:
action 1, numVisits=2293127, meanQ=6.227153, numObservations: 5
action 0, numVisits=69, meanQ=5.306882, numObservations: 1
action -1, numVisits=34, meanQ=4.884978, numObservations: 1
action 2, numVisits=3, meanQ=-0.670000, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 1
Next state: 1 0.577082 0.884002 0.274039 0.859726 0.602328 0.800524 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 149
Initial state: 0 0.738613 0.196163 0.534278 0.816271 0.552218 0.866041 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2289938 episodes
GETTING ACTION FROM:
action 2, numVisits=2289884, meanQ=6.241582, numObservations: 5
action 1, numVisits=26, meanQ=4.715769, numObservations: 4
action 0, numVisits=25, meanQ=4.676836, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.738613 0.196163 0.534278 0.816271 0.552218 0.866041 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 150
Initial state: 0 0.54928 0.802557 0.607062 0.802208 0.181143 0.469355 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2317120 episodes
GETTING ACTION FROM:
action 3, numVisits=2317091, meanQ=6.234430, numObservations: 4
action 2, numVisits=13, meanQ=3.690777, numObservations: 5
action 1, numVisits=12, meanQ=3.323333, numObservations: 3
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.54928 0.802557 0.607062 0.802208 0.181143 0.469355 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=376200, meanQ=8.860824, numObservations: 4
action 2, numVisits=32, meanQ=7.467509, numObservations: 3
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2885013 episodes
GETTING ACTION FROM:
action 1, numVisits=3259632, meanQ=6.524168, numObservations: 4
action 2, numVisits=1592, meanQ=6.332058, numObservations: 3
action 3, numVisits=16, meanQ=4.555019, numObservations: 4
action 0, numVisits=6, meanQ=2.620000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 1
Next state: 1 0.54928 0.802557 0.607062 0.802208 0.181143 0.469355 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 151
Initial state: 0 0.655951 0.687539 0.589669 0.804587 0.50508 0.861589 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2334276 episodes
GETTING ACTION FROM:
action 2, numVisits=2334201, meanQ=6.240150, numObservations: 4
action 0, numVisits=24, meanQ=4.632019, numObservations: 1
action -1, numVisits=25, meanQ=4.562895, numObservations: 1
action 1, numVisits=20, meanQ=3.994010, numObservations: 3
action 3, numVisits=6, meanQ=2.328383, numObservations: 2
action: 2
Next state: 1 0.655951 0.687539 0.589669 0.804587 0.50508 0.861589 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 152
Initial state: 0 0.548723 0.858207 0.978436 0.926299 0.570279 0.871709 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2305616 episodes
GETTING ACTION FROM:
action 1, numVisits=2305573, meanQ=6.231840, numObservations: 5
action 0, numVisits=37, meanQ=4.963906, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 1
Next state: 0 0.548723 0.858207 0.978436 0.926299 0.570279 0.871709 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=101198, meanQ=6.507052, numObservations: 4
action 1, numVisits=2969, meanQ=5.539075, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2884019 episodes
GETTING ACTION FROM:
action 2, numVisits=2985215, meanQ=6.340014, numObservations: 4
action 1, numVisits=2969, meanQ=5.539075, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.548723 0.858207 0.978436 0.926299 0.570279 0.871709 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 153
Initial state: 0 0.697273 0.87649 0.733122 0.379441 0.573169 0.87965 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2321220 episodes
GETTING ACTION FROM:
action 3, numVisits=2321058, meanQ=6.185874, numObservations: 4
action 0, numVisits=90, meanQ=5.369173, numObservations: 1
action -1, numVisits=37, meanQ=4.911162, numObservations: 1
action 2, numVisits=24, meanQ=3.664596, numObservations: 3
action 1, numVisits=11, meanQ=3.633655, numObservations: 3
action: 3
Next state: 1 0.697273 0.87649 0.733122 0.379441 0.573169 0.87965 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 154
Initial state: 0 0.578359 0.892451 0.528142 0.848145 0.522186 0.298885 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2330922 episodes
GETTING ACTION FROM:
action 1, numVisits=2330904, meanQ=6.309243, numObservations: 4
action 3, numVisits=12, meanQ=4.081675, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.578359 0.892451 0.528142 0.848145 0.522186 0.298885 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 155
Initial state: 0 0.634645 0.833785 0.580039 0.863897 0.603703 0.821469 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2295062 episodes
GETTING ACTION FROM:
action 2, numVisits=2294989, meanQ=6.176342, numObservations: 5
action 3, numVisits=54, meanQ=5.070191, numObservations: 4
action 1, numVisits=15, meanQ=3.593340, numObservations: 4
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.634645 0.833785 0.580039 0.863897 0.603703 0.821469 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 156
Initial state: 0 0.592259 0.67309 0.555036 0.879478 0.634194 0.815199 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2349862 episodes
GETTING ACTION FROM:
action 2, numVisits=2297408, meanQ=6.316414, numObservations: 4
action 3, numVisits=52449, meanQ=6.202634, numObservations: 4
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.592259 0.67309 0.555036 0.879478 0.634194 0.815199 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 157
Initial state: 0 0.48038 0.370772 0.600646 0.854167 0.52187 0.848839 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2320888 episodes
GETTING ACTION FROM:
action 3, numVisits=2320810, meanQ=6.234972, numObservations: 4
action -1, numVisits=51, meanQ=5.165690, numObservations: 1
action 0, numVisits=24, meanQ=4.561520, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.48038 0.370772 0.600646 0.854167 0.52187 0.848839 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 158
Initial state: 0 0.676463 0.879563 0.903146 0.157753 0.511468 0.87946 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2324596 episodes
GETTING ACTION FROM:
action 3, numVisits=2324568, meanQ=6.233136, numObservations: 4
action 0, numVisits=19, meanQ=4.420942, numObservations: 1
action 1, numVisits=6, meanQ=2.663333, numObservations: 3
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.676463 0.879563 0.903146 0.157753 0.511468 0.87946 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 159
Initial state: 0 0.918007 0.775826 0.684868 0.874027 0.546762 0.803551 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2290918 episodes
GETTING ACTION FROM:
action 1, numVisits=2290721, meanQ=6.236181, numObservations: 5
action 3, numVisits=144, meanQ=5.521321, numObservations: 4
action -1, numVisits=25, meanQ=4.585675, numObservations: 1
action 0, numVisits=18, meanQ=4.280331, numObservations: 1
action 2, numVisits=10, meanQ=3.198000, numObservations: 4
action: 1
Next state: 2 0.918007 0.775826 0.684868 0.874027 0.546762 0.803551 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 160
Initial state: 0 0.143111 0.749421 0.669446 0.805255 0.520976 0.85029 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2330952 episodes
GETTING ACTION FROM:
action 1, numVisits=2330856, meanQ=6.233851, numObservations: 4
action -1, numVisits=75, meanQ=5.349547, numObservations: 1
action 2, numVisits=17, meanQ=2.587065, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 1
action: 1
Next state: 0 0.143111 0.749421 0.669446 0.805255 0.520976 0.85029 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=56900, meanQ=8.759875, numObservations: 5
action 3, numVisits=641, meanQ=8.521322, numObservations: 3
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2862012 episodes
GETTING ACTION FROM:
action 2, numVisits=2867677, meanQ=6.611090, numObservations: 5
action 3, numVisits=51868, meanQ=6.581371, numObservations: 3
action 1, numVisits=7, meanQ=3.568571, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 2
Next state: 1 0.143111 0.749421 0.669446 0.805255 0.520976 0.85029 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 161
Initial state: 0 0.516933 0.811216 0.704614 0.0954851 0.628137 0.842942 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2324966 episodes
GETTING ACTION FROM:
action 2, numVisits=2324949, meanQ=6.236534, numObservations: 4
action 3, numVisits=11, meanQ=3.545455, numObservations: 2
action 1, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.516933 0.811216 0.704614 0.0954851 0.628137 0.842942 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=12562, meanQ=6.103561, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2846227 episodes
GETTING ACTION FROM:
action 1, numVisits=2858787, meanQ=6.656244, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.516933 0.811216 0.704614 0.0954851 0.628137 0.842942 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 162
Initial state: 0 0.538961 0.838756 0.695595 0.80481 0.637051 0.830303 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2340092 episodes
GETTING ACTION FROM:
action 2, numVisits=2340013, meanQ=6.223059, numObservations: 4
action 0, numVisits=43, meanQ=5.022840, numObservations: 1
action -1, numVisits=33, meanQ=4.826580, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.538961 0.838756 0.695595 0.80481 0.637051 0.830303 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 163
Initial state: 0 0.240214 0.141344 0.592365 0.853773 0.552815 0.821014 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2319132 episodes
GETTING ACTION FROM:
action 3, numVisits=2319055, meanQ=6.236963, numObservations: 4
action -1, numVisits=47, meanQ=5.095418, numObservations: 1
action 1, numVisits=26, meanQ=3.995392, numObservations: 4
action 2, numVisits=2, meanQ=-0.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 3
Next state: 1 0.240214 0.141344 0.592365 0.853773 0.552815 0.821014 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 164
Initial state: 0 0.614358 0.813898 0.52934 0.895336 0.784884 0.0809499 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2299512 episodes
GETTING ACTION FROM:
action 3, numVisits=2289244, meanQ=6.228938, numObservations: 5
action 2, numVisits=10195, meanQ=6.129962, numObservations: 4
action 0, numVisits=46, meanQ=5.081335, numObservations: 1
action 1, numVisits=25, meanQ=4.591604, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.614358 0.813898 0.52934 0.895336 0.784884 0.0809499 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 165
Initial state: 0 0.646037 0.237218 0.534315 0.803438 0.607412 0.826801 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2311719 episodes
GETTING ACTION FROM:
action 2, numVisits=2311688, meanQ=6.185835, numObservations: 5
action 1, numVisits=18, meanQ=3.932239, numObservations: 3
action 3, numVisits=9, meanQ=3.554444, numObservations: 3
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.646037 0.237218 0.534315 0.803438 0.607412 0.826801 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 166
Initial state: 0 0.526887 0.899906 0.532955 0.815947 0.173562 0.217917 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2259675 episodes
GETTING ACTION FROM:
action 2, numVisits=2259662, meanQ=6.147986, numObservations: 4
action 1, numVisits=8, meanQ=3.121250, numObservations: 3
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.526887 0.899906 0.532955 0.815947 0.173562 0.217917 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 167
Initial state: 0 0.217946 0.553342 0.653677 0.833497 0.659699 0.838547 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2310961 episodes
GETTING ACTION FROM:
action 2, numVisits=2310948, meanQ=6.228675, numObservations: 5
action 3, numVisits=7, meanQ=1.998571, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.217946 0.553342 0.653677 0.833497 0.659699 0.838547 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 168
Initial state: 0 0.500123 0.834115 0.460299 0.539287 0.521395 0.843246 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2339871 episodes
GETTING ACTION FROM:
action 2, numVisits=2339733, meanQ=6.233095, numObservations: 4
action 3, numVisits=79, meanQ=5.301267, numObservations: 3
action 0, numVisits=52, meanQ=5.168039, numObservations: 1
action 1, numVisits=5, meanQ=1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.500123 0.834115 0.460299 0.539287 0.521395 0.843246 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=271428, meanQ=8.858457, numObservations: 5
action 1, numVisits=108876, meanQ=8.849959, numObservations: 4
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2871068 episodes
GETTING ACTION FROM:
action 3, numVisits=2437211, meanQ=6.773882, numObservations: 5
action 1, numVisits=814026, meanQ=6.770233, numObservations: 4
action 2, numVisits=136, meanQ=6.084191, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.500123 0.834115 0.460299 0.539287 0.521395 0.843246 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 169
Initial state: 0 0.679958 0.830124 0.505703 0.88418 0.889625 0.551651 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2307995 episodes
GETTING ACTION FROM:
action 3, numVisits=2307989, meanQ=6.234285, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.679958 0.830124 0.505703 0.88418 0.889625 0.551651 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 170
Initial state: 0 0.637214 0.852418 0.667331 0.782498 0.638686 0.880188 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2338960 episodes
GETTING ACTION FROM:
action 1, numVisits=2338769, meanQ=6.232600, numObservations: 3
action 2, numVisits=129, meanQ=5.530467, numObservations: 4
action -1, numVisits=58, meanQ=5.214464, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.637214 0.852418 0.667331 0.782498 0.638686 0.880188 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 171
Initial state: 0 0.545579 0.802618 0.544918 0.887267 0.427389 0.200138 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2323501 episodes
GETTING ACTION FROM:
action 1, numVisits=2323431, meanQ=6.233796, numObservations: 4
action 0, numVisits=57, meanQ=5.203253, numObservations: 1
action 2, numVisits=6, meanQ=2.496683, numObservations: 2
action 3, numVisits=5, meanQ=1.396000, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 1
Next state: 1 0.545579 0.802618 0.544918 0.887267 0.427389 0.200138 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 172
Initial state: 0 0.576261 0.805473 0.539774 0.831174 0.421342 0.78774 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2329176 episodes
GETTING ACTION FROM:
action 3, numVisits=2329067, meanQ=6.234566, numObservations: 4
action 0, numVisits=73, meanQ=5.334892, numObservations: 1
action -1, numVisits=17, meanQ=4.373762, numObservations: 1
action 2, numVisits=17, meanQ=3.234118, numObservations: 5
action 1, numVisits=2, meanQ=-0.010000, numObservations: 2
action: 3
Next state: 0 0.576261 0.805473 0.539774 0.831174 0.421342 0.78774 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=378398, meanQ=8.850926, numObservations: 4
action 1, numVisits=5, meanQ=5.396000, numObservations: 2
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2894675 episodes
GETTING ACTION FROM:
action 2, numVisits=3272362, meanQ=6.544555, numObservations: 4
action 1, numVisits=709, meanQ=6.241537, numObservations: 4
action 3, numVisits=6, meanQ=2.331683, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.576261 0.805473 0.539774 0.831174 0.421342 0.78774 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 173
Initial state: 0 0.615103 0.853153 0.570131 0.861364 0.228235 0.0143346 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2346448 episodes
GETTING ACTION FROM:
action 2, numVisits=2345808, meanQ=6.186087, numObservations: 3
action 1, numVisits=550, meanQ=5.855258, numObservations: 5
action 0, numVisits=72, meanQ=5.287268, numObservations: 1
action -1, numVisits=17, meanQ=4.280998, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.615103 0.853153 0.570131 0.861364 0.228235 0.0143346 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 174
Initial state: 0 0.623577 0.840151 0.215149 0.710523 0.582205 0.80386 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2346705 episodes
GETTING ACTION FROM:
action 2, numVisits=2346676, meanQ=6.233884, numObservations: 4
action -1, numVisits=23, meanQ=4.627841, numObservations: 1
action 3, numVisits=2, meanQ=-1.004950, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action 1, numVisits=2, meanQ=-5.505000, numObservations: 1
action: 2
Next state: 0 0.623577 0.840151 0.215149 0.710523 0.582205 0.80386 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=58802, meanQ=8.688985, numObservations: 3
action 2, numVisits=8, meanQ=6.066250, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2676684 episodes
GETTING ACTION FROM:
action 2, numVisits=2246953, meanQ=6.241457, numObservations: 4
action 1, numVisits=488539, meanQ=6.173276, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 2
Next state: 0 0.623577 0.840151 0.215149 0.710523 0.582205 0.80386 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=132149, meanQ=8.941128, numObservations: 3
action 3, numVisits=106854, meanQ=8.938967, numObservations: 3
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2935617 episodes
GETTING ACTION FROM:
action 3, numVisits=2707557, meanQ=6.739672, numObservations: 3
action 1, numVisits=467045, meanQ=6.733029, numObservations: 5
action 2, numVisits=19, meanQ=4.778947, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.623577 0.840151 0.215149 0.710523 0.582205 0.80386 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.8309
Run # 175
Initial state: 0 0.679139 0.818119 0.549565 0.885136 0.905252 0.827747 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2302714 episodes
GETTING ACTION FROM:
action 1, numVisits=2302669, meanQ=6.239205, numObservations: 5
action -1, numVisits=24, meanQ=4.670880, numObservations: 1
action 2, numVisits=17, meanQ=3.763535, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.679139 0.818119 0.549565 0.885136 0.905252 0.827747 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 176
Initial state: 0 0.163066 0.3213 0.521309 0.827119 0.6864 0.85533 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2350667 episodes
GETTING ACTION FROM:
action 1, numVisits=2350653, meanQ=6.181826, numObservations: 3
action 2, numVisits=8, meanQ=2.996263, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.163066 0.3213 0.521309 0.827119 0.6864 0.85533 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=224379, meanQ=8.853603, numObservations: 5
action 3, numVisits=156596, meanQ=8.849598, numObservations: 5
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2852338 episodes
GETTING ACTION FROM:
action 2, numVisits=2499759, meanQ=6.916184, numObservations: 5
action 3, numVisits=733548, meanQ=6.911947, numObservations: 5
action 1, numVisits=7, meanQ=3.270014, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.163066 0.3213 0.521309 0.827119 0.6864 0.85533 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 177
Initial state: 0 0.152681 0.457706 0.577615 0.894391 0.611027 0.807775 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2274025 episodes
GETTING ACTION FROM:
action 1, numVisits=417763, meanQ=6.182482, numObservations: 4
action 3, numVisits=1856248, meanQ=6.137499, numObservations: 4
action 2, numVisits=10, meanQ=1.998020, numObservations: 3
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.152681 0.457706 0.577615 0.894391 0.611027 0.807775 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=68190, meanQ=8.842300, numObservations: 5
action 2, numVisits=7, meanQ=6.141443, numObservations: 2
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2840130 episodes
GETTING ACTION FROM:
action 3, numVisits=2908290, meanQ=6.633287, numObservations: 5
action 2, numVisits=32, meanQ=5.249691, numObservations: 3
action 1, numVisits=4, meanQ=1.747500, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 3
Next state: 1 0.152681 0.457706 0.577615 0.894391 0.611027 0.807775 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 178
Initial state: 0 0.663968 0.84042 0.515342 0.89101 0.592518 0.836101 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2364007 episodes
GETTING ACTION FROM:
action 2, numVisits=2363923, meanQ=6.239829, numObservations: 3
action -1, numVisits=75, meanQ=5.351180, numObservations: 1
action 1, numVisits=6, meanQ=0.831667, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.663968 0.84042 0.515342 0.89101 0.592518 0.836101 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 179
Initial state: 0 0.584314 0.826552 0.559521 0.865077 0.779662 0.817674 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2330159 episodes
GETTING ACTION FROM:
action 1, numVisits=2330053, meanQ=6.247164, numObservations: 4
action 0, numVisits=90, meanQ=5.440844, numObservations: 1
action 3, numVisits=12, meanQ=3.983333, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.584314 0.826552 0.559521 0.865077 0.779662 0.817674 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 180
Initial state: 0 0.556793 0.850782 0.662439 0.875764 0.595621 0.665771 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2325570 episodes
GETTING ACTION FROM:
action 1, numVisits=2325507, meanQ=6.183078, numObservations: 4
action 0, numVisits=38, meanQ=4.898650, numObservations: 1
action -1, numVisits=22, meanQ=4.504746, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.556793 0.850782 0.662439 0.875764 0.595621 0.665771 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 181
Initial state: 0 0.667726 0.880024 0.554238 0.860095 0.0314523 0.342885 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2312659 episodes
GETTING ACTION FROM:
action 2, numVisits=2312343, meanQ=6.231181, numObservations: 4
action 3, numVisits=263, meanQ=5.758132, numObservations: 5
action 1, numVisits=49, meanQ=5.120004, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.667726 0.880024 0.554238 0.860095 0.0314523 0.342885 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 182
Initial state: 0 0.632762 0.843325 0.88929 0.853135 0.656911 0.885657 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2343346 episodes
GETTING ACTION FROM:
action 1, numVisits=2343225, meanQ=6.229561, numObservations: 3
action 0, numVisits=62, meanQ=5.245168, numObservations: 1
action -1, numVisits=50, meanQ=5.133802, numObservations: 1
action 2, numVisits=8, meanQ=2.996263, numObservations: 4
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.632762 0.843325 0.88929 0.853135 0.656911 0.885657 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 183
Initial state: 0 0.256386 0.656658 0.629518 0.832959 0.61549 0.826001 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2294257 episodes
GETTING ACTION FROM:
action 1, numVisits=2287984, meanQ=6.229000, numObservations: 5
action 3, numVisits=6206, meanQ=6.135128, numObservations: 3
action 0, numVisits=64, meanQ=5.265636, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.256386 0.656658 0.629518 0.832959 0.61549 0.826001 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=314445, meanQ=8.882697, numObservations: 5
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2835167 episodes
GETTING ACTION FROM:
action 2, numVisits=3149436, meanQ=6.354680, numObservations: 5
action 1, numVisits=173, meanQ=5.705107, numObservations: 5
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.256386 0.656658 0.629518 0.832959 0.61549 0.826001 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 184
Initial state: 0 0.574784 0.625156 0.663244 0.838477 0.522017 0.86991 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2347400 episodes
GETTING ACTION FROM:
action 1, numVisits=2347324, meanQ=6.227355, numObservations: 3
action 0, numVisits=48, meanQ=5.109372, numObservations: 1
action 2, numVisits=24, meanQ=4.412087, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 2 0.574784 0.625156 0.663244 0.838477 0.522017 0.86991 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 185
Initial state: 0 0.41839 0.0856312 0.645366 0.894418 0.699888 0.867162 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2301726 episodes
GETTING ACTION FROM:
action 1, numVisits=2301666, meanQ=6.234820, numObservations: 5
action 2, numVisits=45, meanQ=5.065340, numObservations: 4
action 3, numVisits=11, meanQ=2.726364, numObservations: 3
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.41839 0.0856312 0.645366 0.894418 0.699888 0.867162 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=57218, meanQ=8.707008, numObservations: 5
action 3, numVisits=103, meanQ=8.067381, numObservations: 4
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2846720 episodes
GETTING ACTION FROM:
action 2, numVisits=2902586, meanQ=6.685318, numObservations: 5
action 3, numVisits=1452, meanQ=6.483359, numObservations: 5
action 1, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 2
Next state: 1 0.41839 0.0856312 0.645366 0.894418 0.699888 0.867162 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 186
Initial state: 0 0.200459 0.977308 0.57214 0.868947 0.574243 0.890142 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2338927 episodes
GETTING ACTION FROM:
action 2, numVisits=2338921, meanQ=6.231065, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.200459 0.977308 0.57214 0.868947 0.574243 0.890142 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 187
Initial state: 0 0.640888 0.815507 0.679224 0.818105 0.641678 0.101633 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2301453 episodes
GETTING ACTION FROM:
action 1, numVisits=2301429, meanQ=6.240907, numObservations: 5
action -1, numVisits=19, meanQ=4.393972, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.640888 0.815507 0.679224 0.818105 0.641678 0.101633 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 188
Initial state: 0 0.970112 0.722061 0.669514 0.840679 0.544912 0.864488 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2325298 episodes
GETTING ACTION FROM:
action 1, numVisits=2325272, meanQ=6.234013, numObservations: 4
action -1, numVisits=17, meanQ=4.373300, numObservations: 1
action 2, numVisits=4, meanQ=1.747500, numObservations: 3
action 3, numVisits=3, meanQ=-1.033333, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 1
Next state: 2 0.970112 0.722061 0.669514 0.840679 0.544912 0.864488 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 189
Initial state: 0 0.60136 0.863615 0.542764 0.814729 0.678751 0.211351 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2349257 episodes
GETTING ACTION FROM:
action 1, numVisits=2186244, meanQ=6.234759, numObservations: 3
action 2, numVisits=162961, meanQ=6.218474, numObservations: 4
action 0, numVisits=49, meanQ=5.128650, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.60136 0.863615 0.542764 0.814729 0.678751 0.211351 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 190
Initial state: 0 0.61858 0.859487 0.568945 0.814456 0.194626 0.152318 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2324786 episodes
GETTING ACTION FROM:
action 1, numVisits=2324730, meanQ=6.231776, numObservations: 4
action -1, numVisits=38, meanQ=4.959939, numObservations: 1
action 2, numVisits=14, meanQ=4.070714, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 1
action: 1
Next state: 1 0.61858 0.859487 0.568945 0.814456 0.194626 0.152318 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 191
Initial state: 0 0.680848 0.80584 0.717187 0.532602 0.5193 0.852641 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2279461 episodes
GETTING ACTION FROM:
action 3, numVisits=2279419, meanQ=6.136335, numObservations: 4
action 1, numVisits=36, meanQ=4.549450, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 3
Next state: 1 0.680848 0.80584 0.717187 0.532602 0.5193 0.852641 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 192
Initial state: 0 0.661263 0.895279 0.776757 0.30723 0.692019 0.844818 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2335856 episodes
GETTING ACTION FROM:
action 2, numVisits=2335646, meanQ=6.228179, numObservations: 4
action 0, numVisits=41, meanQ=4.976307, numObservations: 1
action 3, numVisits=141, meanQ=4.937309, numObservations: 5
action -1, numVisits=26, meanQ=4.709876, numObservations: 1
action 1, numVisits=2, meanQ=-0.010000, numObservations: 2
action: 2
Next state: 2 0.661263 0.895279 0.776757 0.30723 0.692019 0.844818 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 193
Initial state: 0 0.680672 0.844874 0.905113 0.592938 0.530423 0.857959 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2327345 episodes
GETTING ACTION FROM:
action 1, numVisits=2319427, meanQ=6.232320, numObservations: 4
action 2, numVisits=7885, meanQ=6.149466, numObservations: 4
action -1, numVisits=29, meanQ=4.783175, numObservations: 1
action 3, numVisits=2, meanQ=-0.010000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.680672 0.844874 0.905113 0.592938 0.530423 0.857959 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=105641, meanQ=6.487378, numObservations: 5
action 1, numVisits=33, meanQ=3.436973, numObservations: 3
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2851362 episodes
GETTING ACTION FROM:
action 2, numVisits=2957001, meanQ=6.407508, numObservations: 5
action 1, numVisits=33, meanQ=3.436973, numObservations: 3
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 2
Next state: 2 0.680672 0.844874 0.905113 0.592938 0.530423 0.857959 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11.89
Run # 194
Initial state: 0 0.622445 0.602158 0.611445 0.837414 0.507889 0.871826 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2353387 episodes
GETTING ACTION FROM:
action 3, numVisits=2353378, meanQ=6.235104, numObservations: 3
action 1, numVisits=4, meanQ=2.242500, numObservations: 4
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.622445 0.602158 0.611445 0.837414 0.507889 0.871826 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 195
Initial state: 0 0.690039 0.886446 0.743419 0.146684 0.545687 0.823752 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2357629 episodes
GETTING ACTION FROM:
action 2, numVisits=2357588, meanQ=6.234537, numObservations: 3
action 3, numVisits=33, meanQ=4.846976, numObservations: 4
action 1, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.690039 0.886446 0.743419 0.146684 0.545687 0.823752 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 196
Initial state: 0 0.522738 0.88617 0.557907 0.895116 0.818345 0.0257185 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2305119 episodes
GETTING ACTION FROM:
action 3, numVisits=2305037, meanQ=6.226945, numObservations: 5
action -1, numVisits=56, meanQ=5.183128, numObservations: 1
action 1, numVisits=21, meanQ=4.280005, numObservations: 4
action 2, numVisits=3, meanQ=-0.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.522738 0.88617 0.557907 0.895116 0.818345 0.0257185 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 197
Initial state: 0 0.647018 0.823007 0.765529 0.302697 0.520227 0.869214 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2335327 episodes
GETTING ACTION FROM:
action 2, numVisits=2335283, meanQ=6.230881, numObservations: 4
action 1, numVisits=19, meanQ=4.418953, numObservations: 4
action 3, numVisits=21, meanQ=4.331910, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 2 0.647018 0.823007 0.765529 0.302697 0.520227 0.869214 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 198
Initial state: 0 0.603812 0.835887 0.506933 0.864026 0.176402 0.676072 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2321351 episodes
GETTING ACTION FROM:
action 3, numVisits=2319928, meanQ=6.231544, numObservations: 4
action 2, numVisits=1297, meanQ=6.021909, numObservations: 5
action 0, numVisits=75, meanQ=5.337608, numObservations: 1
action 1, numVisits=49, meanQ=4.302869, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.603812 0.835887 0.506933 0.864026 0.176402 0.676072 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=271022, meanQ=8.887233, numObservations: 4
action 2, numVisits=47970, meanQ=8.867882, numObservations: 4
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2884235 episodes
GETTING ACTION FROM:
action 1, numVisits=2615092, meanQ=6.588515, numObservations: 4
action 2, numVisits=587711, meanQ=6.583177, numObservations: 4
action 3, numVisits=423, meanQ=6.215793, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 1
Next state: 1 0.603812 0.835887 0.506933 0.864026 0.176402 0.676072 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 199
Initial state: 0 0.630512 0.825433 0.55675 0.836698 0.724216 0.505965 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2302802 episodes
GETTING ACTION FROM:
action 1, numVisits=2302753, meanQ=6.224898, numObservations: 5
action 0, numVisits=22, meanQ=4.525641, numObservations: 1
action 3, numVisits=23, meanQ=4.299130, numObservations: 4
action 2, numVisits=2, meanQ=-5.505000, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.630512 0.825433 0.55675 0.836698 0.724216 0.505965 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 200
Initial state: 0 0.556363 0.894571 0.798435 0.00470504 0.648564 0.838378 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2315929 episodes
GETTING ACTION FROM:
action 2, numVisits=2315852, meanQ=6.234098, numObservations: 5
action -1, numVisits=60, meanQ=5.234153, numObservations: 1
action 3, numVisits=13, meanQ=3.690015, numObservations: 3
action 1, numVisits=2, meanQ=-0.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.556363 0.894571 0.798435 0.00470504 0.648564 0.838378 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 201
Initial state: 0 0.755901 0.390006 0.600448 0.865359 0.559208 0.893198 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2338717 episodes
GETTING ACTION FROM:
action 2, numVisits=2338614, meanQ=6.228993, numObservations: 4
action -1, numVisits=80, meanQ=5.359512, numObservations: 1
action 3, numVisits=12, meanQ=3.983333, numObservations: 2
action 1, numVisits=9, meanQ=3.663344, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.755901 0.390006 0.600448 0.865359 0.559208 0.893198 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 202
Initial state: 0 0.642163 0.839761 0.451827 0.88436 0.564096 0.881356 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2331640 episodes
GETTING ACTION FROM:
action 3, numVisits=2331440, meanQ=6.232596, numObservations: 4
action 1, numVisits=195, meanQ=5.618719, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.642163 0.839761 0.451827 0.88436 0.564096 0.881356 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 203
Initial state: 0 0.547172 0.893147 0.128907 0.756161 0.528639 0.842842 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2304493 episodes
GETTING ACTION FROM:
action 3, numVisits=2304446, meanQ=6.235304, numObservations: 5
action -1, numVisits=21, meanQ=4.463098, numObservations: 1
action 2, numVisits=13, meanQ=2.921546, numObservations: 3
action 1, numVisits=11, meanQ=2.815464, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.547172 0.893147 0.128907 0.756161 0.528639 0.842842 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 204
Initial state: 0 0.562626 0.835037 0.538738 0.810502 0.544213 0.588031 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2336648 episodes
GETTING ACTION FROM:
action 1, numVisits=2336186, meanQ=6.182549, numObservations: 4
action 3, numVisits=419, meanQ=5.793528, numObservations: 4
action 0, numVisits=27, meanQ=4.635622, numObservations: 1
action 2, numVisits=14, meanQ=4.062157, numObservations: 3
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.562626 0.835037 0.538738 0.810502 0.544213 0.588031 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 205
Initial state: 0 0.67835 0.82958 0.922602 0.0832934 0.653726 0.895018 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2295732 episodes
GETTING ACTION FROM:
action 2, numVisits=2281342, meanQ=6.231627, numObservations: 5
action 0, numVisits=14368, meanQ=4.314312, numObservations: 1
action 3, numVisits=19, meanQ=1.678421, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.67835 0.82958 0.922602 0.0832934 0.653726 0.895018 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 206
Initial state: 0 0.679953 0.950445 0.642977 0.857161 0.671862 0.816959 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2337747 episodes
GETTING ACTION FROM:
action 3, numVisits=2337714, meanQ=6.228885, numObservations: 3
action 2, numVisits=27, meanQ=4.753333, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-5.505000, numObservations: 1
action: 3
Next state: 1 0.679953 0.950445 0.642977 0.857161 0.671862 0.816959 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 207
Initial state: 0 0.887108 0.816122 0.568006 0.862355 0.640327 0.887014 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2302690 episodes
GETTING ACTION FROM:
action 1, numVisits=2302671, meanQ=6.237734, numObservations: 5
action 2, numVisits=11, meanQ=1.906373, numObservations: 4
action 3, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.887108 0.816122 0.568006 0.862355 0.640327 0.887014 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 208
Initial state: 0 0.665559 0.842392 0.57579 0.827506 0.248298 0.463048 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2330548 episodes
GETTING ACTION FROM:
action 2, numVisits=2330142, meanQ=6.232082, numObservations: 4
action 1, numVisits=358, meanQ=5.662977, numObservations: 4
action 0, numVisits=43, meanQ=5.059346, numObservations: 1
action 3, numVisits=3, meanQ=-1.033333, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.665559 0.842392 0.57579 0.827506 0.248298 0.463048 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 209
Initial state: 0 0.690839 0.826807 0.834595 0.880587 0.584578 0.816458 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2309543 episodes
GETTING ACTION FROM:
action 1, numVisits=2309515, meanQ=6.236435, numObservations: 5
action 3, numVisits=21, meanQ=1.860962, numObservations: 4
action 2, numVisits=3, meanQ=-1.033333, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.690839 0.826807 0.834595 0.880587 0.584578 0.816458 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 210
Initial state: 0 0.130595 0.405159 0.525426 0.840943 0.511554 0.824047 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2311076 episodes
GETTING ACTION FROM:
action 1, numVisits=2311067, meanQ=6.237495, numObservations: 4
action 3, numVisits=4, meanQ=1.747500, numObservations: 3
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.130595 0.405159 0.525426 0.840943 0.511554 0.824047 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=255843, meanQ=8.868322, numObservations: 4
action 3, numVisits=62605, meanQ=8.853847, numObservations: 5
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2864615 episodes
GETTING ACTION FROM:
action 2, numVisits=2593511, meanQ=6.731872, numObservations: 4
action 3, numVisits=589533, meanQ=6.726879, numObservations: 5
action 1, numVisits=20, meanQ=4.495000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.130595 0.405159 0.525426 0.840943 0.511554 0.824047 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 211
Initial state: 0 0.835175 0.879997 0.517059 0.841976 0.613682 0.856752 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2360938 episodes
GETTING ACTION FROM:
action 1, numVisits=2360872, meanQ=6.231926, numObservations: 3
action 2, numVisits=35, meanQ=4.900857, numObservations: 4
action 3, numVisits=27, meanQ=4.507411, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.835175 0.879997 0.517059 0.841976 0.613682 0.856752 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 212
Initial state: 0 0.0682218 0.932539 0.642022 0.842597 0.552867 0.848583 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2288122 episodes
GETTING ACTION FROM:
action 1, numVisits=2288089, meanQ=6.229125, numObservations: 5
action 0, numVisits=22, meanQ=4.455678, numObservations: 1
action 2, numVisits=6, meanQ=0.831667, numObservations: 3
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.0682218 0.932539 0.642022 0.842597 0.552867 0.848583 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=102830, meanQ=6.472543, numObservations: 4
action 2, numVisits=5, meanQ=-0.980000, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2888527 episodes
GETTING ACTION FROM:
action 3, numVisits=2991357, meanQ=6.865971, numObservations: 4
action 2, numVisits=5, meanQ=-0.980000, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.0682218 0.932539 0.642022 0.842597 0.552867 0.848583 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 213
Initial state: 0 0.70508 0.967556 0.654386 0.842542 0.532674 0.835672 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2324920 episodes
GETTING ACTION FROM:
action 1, numVisits=2324840, meanQ=6.224073, numObservations: 4
action -1, numVisits=59, meanQ=5.207982, numObservations: 1
action 0, numVisits=16, meanQ=4.287253, numObservations: 1
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 1
Next state: 1 0.70508 0.967556 0.654386 0.842542 0.532674 0.835672 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 214
Initial state: 0 0.566639 0.401411 0.56466 0.857096 0.683445 0.817516 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2290314 episodes
GETTING ACTION FROM:
action 1, numVisits=2290270, meanQ=6.234204, numObservations: 5
action 0, numVisits=29, meanQ=4.779015, numObservations: 1
action 2, numVisits=11, meanQ=2.726364, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 1
Next state: 2 0.566639 0.401411 0.56466 0.857096 0.683445 0.817516 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 215
Initial state: 0 0.614443 0.823008 0.682779 0.807787 0.939199 0.110568 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2338076 episodes
GETTING ACTION FROM:
action 1, numVisits=2338067, meanQ=6.313997, numObservations: 4
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action 2, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.614443 0.823008 0.682779 0.807787 0.939199 0.110568 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 216
Initial state: 0 0.0973989 0.403286 0.560268 0.896189 0.647612 0.862705 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2327741 episodes
GETTING ACTION FROM:
action 1, numVisits=2279365, meanQ=6.230808, numObservations: 4
action 3, numVisits=48348, meanQ=6.187291, numObservations: 5
action -1, numVisits=20, meanQ=4.509288, numObservations: 1
action 2, numVisits=6, meanQ=2.663333, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.0973989 0.403286 0.560268 0.896189 0.647612 0.862705 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=312753, meanQ=8.857837, numObservations: 5
action 2, numVisits=57719, meanQ=8.840509, numObservations: 4
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2824029 episodes
GETTING ACTION FROM:
action 3, numVisits=2951908, meanQ=6.889985, numObservations: 5
action 2, numVisits=242556, meanQ=6.878773, numObservations: 4
action 1, numVisits=38, meanQ=5.257900, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.0973989 0.403286 0.560268 0.896189 0.647612 0.862705 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 217
Initial state: 0 0.657159 0.821434 0.506386 0.868678 0.345032 0.530585 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2329592 episodes
GETTING ACTION FROM:
action 1, numVisits=2319507, meanQ=6.309118, numObservations: 4
action 3, numVisits=10064, meanQ=6.227857, numObservations: 4
action 2, numVisits=17, meanQ=4.223535, numObservations: 4
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.657159 0.821434 0.506386 0.868678 0.345032 0.530585 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 218
Initial state: 0 0.692345 0.839065 0.613599 0.840154 0.132358 0.286541 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2319950 episodes
GETTING ACTION FROM:
action 3, numVisits=2319846, meanQ=6.235438, numObservations: 4
action -1, numVisits=42, meanQ=5.043940, numObservations: 1
action 0, numVisits=31, meanQ=4.774520, numObservations: 1
action 1, numVisits=29, meanQ=4.431724, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 3
Next state: 0 0.692345 0.839065 0.613599 0.840154 0.132358 0.286541 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=141690, meanQ=8.876829, numObservations: 4
action 1, numVisits=178026, meanQ=8.876816, numObservations: 4
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2872917 episodes
GETTING ACTION FROM:
action 1, numVisits=1811200, meanQ=6.796906, numObservations: 4
action 2, numVisits=1381432, meanQ=6.796169, numObservations: 4
action 3, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.692345 0.839065 0.613599 0.840154 0.132358 0.286541 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 219
Initial state: 0 0.46172 0.557669 0.597799 0.867608 0.621761 0.832054 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2324751 episodes
GETTING ACTION FROM:
action 1, numVisits=2324687, meanQ=6.232077, numObservations: 4
action -1, numVisits=29, meanQ=4.807676, numObservations: 1
action 3, numVisits=29, meanQ=4.742414, numObservations: 5
action 2, numVisits=4, meanQ=-0.505000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.46172 0.557669 0.597799 0.867608 0.621761 0.832054 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=56191, meanQ=8.743033, numObservations: 5
action 2, numVisits=1712, meanQ=8.598723, numObservations: 5
action 1, numVisits=5, meanQ=4.960000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2829508 episodes
GETTING ACTION FROM:
action 3, numVisits=2863170, meanQ=6.728634, numObservations: 5
action 2, numVisits=24181, meanQ=6.683338, numObservations: 5
action 1, numVisits=65, meanQ=5.697538, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.46172 0.557669 0.597799 0.867608 0.621761 0.832054 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 220
Initial state: 0 0.698816 0.833479 0.670689 0.826002 0.273074 0.240715 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2331123 episodes
GETTING ACTION FROM:
action 2, numVisits=2331082, meanQ=6.319769, numObservations: 5
action -1, numVisits=10, meanQ=3.739360, numObservations: 1
action 3, numVisits=13, meanQ=3.683085, numObservations: 3
action 1, numVisits=16, meanQ=3.435638, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.698816 0.833479 0.670689 0.826002 0.273074 0.240715 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 221
Initial state: 0 0.584177 0.88539 0.587207 0.965906 0.512234 0.812085 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2339865 episodes
GETTING ACTION FROM:
action 1, numVisits=2339780, meanQ=6.247920, numObservations: 4
action -1, numVisits=28, meanQ=4.781046, numObservations: 1
action 2, numVisits=28, meanQ=4.668214, numObservations: 4
action 3, numVisits=27, meanQ=4.467407, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.584177 0.88539 0.587207 0.965906 0.512234 0.812085 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 222
Initial state: 0 0.559243 0.810432 0.69845 0.892054 0.072878 0.111455 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2325304 episodes
GETTING ACTION FROM:
action 3, numVisits=2259924, meanQ=6.235930, numObservations: 4
action 1, numVisits=65365, meanQ=6.208080, numObservations: 3
action 2, numVisits=11, meanQ=3.725455, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.559243 0.810432 0.69845 0.892054 0.072878 0.111455 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=279368, meanQ=8.857544, numObservations: 4
action 2, numVisits=88082, meanQ=8.846181, numObservations: 4
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2881334 episodes
GETTING ACTION FROM:
action 1, numVisits=2864595, meanQ=6.903057, numObservations: 4
action 2, numVisits=384188, meanQ=6.895122, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 1
Next state: 1 0.559243 0.810432 0.69845 0.892054 0.072878 0.111455 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 223
Initial state: 0 0.557152 0.436275 0.5239 0.856564 0.571058 0.848555 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2345615 episodes
GETTING ACTION FROM:
action 2, numVisits=2345575, meanQ=6.234311, numObservations: 4
action -1, numVisits=16, meanQ=4.248488, numObservations: 1
action 3, numVisits=21, meanQ=3.903333, numObservations: 4
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.557152 0.436275 0.5239 0.856564 0.571058 0.848555 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 224
Initial state: 0 0.695647 0.88821 0.591683 0.809572 0.944508 0.844662 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2322846 episodes
GETTING ACTION FROM:
action 3, numVisits=2322802, meanQ=6.225559, numObservations: 4
action 2, numVisits=31, meanQ=4.697103, numObservations: 4
action 1, numVisits=9, meanQ=3.554444, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.695647 0.88821 0.591683 0.809572 0.944508 0.844662 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 225
Initial state: 0 0.532793 0.823987 0.198717 0.654001 0.579308 0.880078 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2326554 episodes
GETTING ACTION FROM:
action 3, numVisits=2284699, meanQ=6.231363, numObservations: 4
action 2, numVisits=41817, meanQ=6.189443, numObservations: 5
action -1, numVisits=27, meanQ=4.699775, numObservations: 1
action 1, numVisits=9, meanQ=3.663344, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action: 3
Next state: 1 0.532793 0.823987 0.198717 0.654001 0.579308 0.880078 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 226
Initial state: 0 0.61872 0.117334 0.53354 0.834042 0.641699 0.880277 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2310316 episodes
GETTING ACTION FROM:
action 2, numVisits=2310144, meanQ=6.229814, numObservations: 5
action -1, numVisits=101, meanQ=5.453159, numObservations: 1
action 0, numVisits=43, meanQ=5.049485, numObservations: 1
action 3, numVisits=20, meanQ=3.990000, numObservations: 3
action 1, numVisits=8, meanQ=0.373750, numObservations: 3
action: 2
Next state: 1 0.61872 0.117334 0.53354 0.834042 0.641699 0.880277 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 227
Initial state: 0 0.783542 0.356922 0.681214 0.85627 0.65741 0.859615 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2303076 episodes
GETTING ACTION FROM:
action 3, numVisits=2302941, meanQ=6.236224, numObservations: 5
action 0, numVisits=71, meanQ=5.322156, numObservations: 1
action 2, numVisits=58, meanQ=3.403626, numObservations: 5
action 1, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.783542 0.356922 0.681214 0.85627 0.65741 0.859615 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 228
Initial state: 0 0.347832 0.132353 0.573394 0.846693 0.651138 0.820397 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2343848 episodes
GETTING ACTION FROM:
action 2, numVisits=2343801, meanQ=6.318258, numObservations: 4
action -1, numVisits=29, meanQ=4.865138, numObservations: 1
action 0, numVisits=16, meanQ=4.226801, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.347832 0.132353 0.573394 0.846693 0.651138 0.820397 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 229
Initial state: 0 0.57366 0.831914 0.597961 0.820989 0.657181 0.36725 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2299021 episodes
GETTING ACTION FROM:
action 1, numVisits=2298946, meanQ=6.227064, numObservations: 5
action 0, numVisits=36, meanQ=4.948194, numObservations: 1
action 3, numVisits=27, meanQ=4.147419, numObservations: 4
action 2, numVisits=10, meanQ=3.000000, numObservations: 4
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 1
Next state: 1 0.57366 0.831914 0.597961 0.820989 0.657181 0.36725 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 230
Initial state: 0 0.574002 0.875194 0.50002 0.837961 0.327844 0.885774 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2306041 episodes
GETTING ACTION FROM:
action 2, numVisits=2298663, meanQ=6.236988, numObservations: 5
action 3, numVisits=7366, meanQ=6.135956, numObservations: 5
action 1, numVisits=8, meanQ=2.873750, numObservations: 3
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.574002 0.875194 0.50002 0.837961 0.327844 0.885774 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 231
Initial state: 0 0.585922 0.556298 0.547761 0.861008 0.555732 0.814244 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2329035 episodes
GETTING ACTION FROM:
action 1, numVisits=2328988, meanQ=6.180380, numObservations: 4
action -1, numVisits=34, meanQ=4.841309, numObservations: 1
action 3, numVisits=9, meanQ=3.554444, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.585922 0.556298 0.547761 0.861008 0.555732 0.814244 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 232
Initial state: 0 0.376591 0.602624 0.624783 0.865686 0.560069 0.841043 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2320187 episodes
GETTING ACTION FROM:
action 2, numVisits=2320108, meanQ=6.234961, numObservations: 4
action 0, numVisits=50, meanQ=5.134351, numObservations: 1
action -1, numVisits=20, meanQ=4.380345, numObservations: 1
action 3, numVisits=8, meanQ=2.601250, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.376591 0.602624 0.624783 0.865686 0.560069 0.841043 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 233
Initial state: 0 0.590139 0.803918 0.473646 0.124517 0.638276 0.814623 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2315619 episodes
GETTING ACTION FROM:
action 3, numVisits=2315542, meanQ=6.323183, numObservations: 5
action -1, numVisits=63, meanQ=5.349351, numObservations: 1
action 2, numVisits=10, meanQ=2.099000, numObservations: 3
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action 1, numVisits=2, meanQ=-5.505000, numObservations: 1
action: 3
Next state: 1 0.590139 0.803918 0.473646 0.124517 0.638276 0.814623 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 234
Initial state: 0 0.910924 0.45692 0.60442 0.831302 0.611229 0.807314 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2300101 episodes
GETTING ACTION FROM:
action 1, numVisits=2298799, meanQ=6.227640, numObservations: 5
action 2, numVisits=1245, meanQ=6.010289, numObservations: 4
action 0, numVisits=43, meanQ=5.044285, numObservations: 1
action 3, numVisits=12, meanQ=3.067500, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.910924 0.45692 0.60442 0.831302 0.611229 0.807314 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 235
Initial state: 0 0.563604 0.815924 0.690857 0.00212231 0.535069 0.887841 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2303424 episodes
GETTING ACTION FROM:
action 3, numVisits=2303358, meanQ=6.228609, numObservations: 5
action -1, numVisits=22, meanQ=4.484468, numObservations: 1
action 1, numVisits=31, meanQ=4.483552, numObservations: 5
action 2, numVisits=11, meanQ=3.725455, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.563604 0.815924 0.690857 0.00212231 0.535069 0.887841 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 236
Initial state: 0 0.596366 0.896938 0.182003 0.651286 0.585238 0.864623 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2311296 episodes
GETTING ACTION FROM:
action 3, numVisits=2311228, meanQ=6.232149, numObservations: 4
action 2, numVisits=56, meanQ=5.184287, numObservations: 5
action 1, numVisits=8, meanQ=3.121250, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.596366 0.896938 0.182003 0.651286 0.585238 0.864623 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 237
Initial state: 0 0.573757 0.831332 0.699472 0.843974 0.0542043 0.6872 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2317745 episodes
GETTING ACTION FROM:
action 3, numVisits=2317699, meanQ=6.224865, numObservations: 4
action 0, numVisits=38, meanQ=4.895743, numObservations: 1
action 2, numVisits=4, meanQ=-0.754975, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 1, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 3
Next state: 0 0.573757 0.831332 0.699472 0.843974 0.0542043 0.6872 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=252860, meanQ=8.856226, numObservations: 4
action 2, numVisits=123502, meanQ=8.850497, numObservations: 3
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2889125 episodes
GETTING ACTION FROM:
action 1, numVisits=2403544, meanQ=6.781067, numObservations: 4
action 2, numVisits=861940, meanQ=6.777639, numObservations: 3
action 3, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.573757 0.831332 0.699472 0.843974 0.0542043 0.6872 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 238
Initial state: 0 0.535919 0.861848 0.895785 0.0947032 0.561837 0.892321 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2327964 episodes
GETTING ACTION FROM:
action 1, numVisits=2327894, meanQ=6.232895, numObservations: 4
action 0, numVisits=62, meanQ=5.257177, numObservations: 1
action 3, numVisits=4, meanQ=1.747500, numObservations: 1
action 2, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.535919 0.861848 0.895785 0.0947032 0.561837 0.892321 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 239
Initial state: 0 0.226176 0.502128 0.583962 0.863971 0.521262 0.807569 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2343002 episodes
GETTING ACTION FROM:
action 2, numVisits=2342881, meanQ=6.234191, numObservations: 4
action -1, numVisits=40, meanQ=4.988251, numObservations: 1
action 1, numVisits=20, meanQ=4.494505, numObservations: 3
action 3, numVisits=59, meanQ=4.411193, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.226176 0.502128 0.583962 0.863971 0.521262 0.807569 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=104169, meanQ=6.550505, numObservations: 5
action 2, numVisits=26, meanQ=5.104231, numObservations: 3
action 1, numVisits=18, meanQ=4.665556, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2852686 episodes
GETTING ACTION FROM:
action 3, numVisits=2956851, meanQ=6.576625, numObservations: 5
action 2, numVisits=28, meanQ=4.668214, numObservations: 3
action 1, numVisits=18, meanQ=4.665556, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.226176 0.502128 0.583962 0.863971 0.521262 0.807569 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 240
Initial state: 0 0.565029 0.882662 0.957473 0.00730303 0.504318 0.883676 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2349155 episodes
GETTING ACTION FROM:
action 1, numVisits=2349051, meanQ=6.225052, numObservations: 3
action 0, numVisits=50, meanQ=5.139499, numObservations: 1
action -1, numVisits=24, meanQ=4.650907, numObservations: 1
action 3, numVisits=28, meanQ=4.070361, numObservations: 4
action 2, numVisits=2, meanQ=-1.004950, numObservations: 1
action: 1
Next state: 1 0.565029 0.882662 0.957473 0.00730303 0.504318 0.883676 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 241
Initial state: 0 0.611412 0.853185 0.613384 0.868469 0.638451 0.810019 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2344704 episodes
GETTING ACTION FROM:
action 2, numVisits=2344555, meanQ=6.183742, numObservations: 4
action -1, numVisits=53, meanQ=5.135979, numObservations: 1
action 1, numVisits=51, meanQ=5.011771, numObservations: 5
action 0, numVisits=26, meanQ=4.613816, numObservations: 1
action 3, numVisits=19, meanQ=4.419474, numObservations: 5
action: 2
Next state: 1 0.611412 0.853185 0.613384 0.868469 0.638451 0.810019 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 242
Initial state: 0 0.634348 0.889826 0.654208 0.850441 0.507406 0.715033 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2347954 episodes
GETTING ACTION FROM:
action 3, numVisits=2347853, meanQ=6.234133, numObservations: 3
action 0, numVisits=53, meanQ=5.173389, numObservations: 1
action 2, numVisits=43, meanQ=5.014186, numObservations: 4
action 1, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 3
Next state: 2 0.634348 0.889826 0.654208 0.850441 0.507406 0.715033 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 243
Initial state: 0 0.57796 0.852299 0.532097 0.836544 0.452946 0.68345 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2314398 episodes
GETTING ACTION FROM:
action 2, numVisits=2314370, meanQ=6.318666, numObservations: 5
action 3, numVisits=17, meanQ=3.763535, numObservations: 4
action 1, numVisits=7, meanQ=3.284300, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.57796 0.852299 0.532097 0.836544 0.452946 0.68345 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 244
Initial state: 0 0.581696 0.891644 0.527817 0.866527 0.0742558 0.646729 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2339660 episodes
GETTING ACTION FROM:
action 2, numVisits=2339623, meanQ=6.241857, numObservations: 4
action 0, numVisits=32, meanQ=4.869222, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.581696 0.891644 0.527817 0.866527 0.0742558 0.646729 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 245
Initial state: 0 0.539875 0.865466 0.66542 0.824352 0.0667554 0.287025 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2309821 episodes
GETTING ACTION FROM:
action 1, numVisits=2309783, meanQ=6.242337, numObservations: 5
action -1, numVisits=29, meanQ=4.707428, numObservations: 1
action 2, numVisits=5, meanQ=1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 1
Next state: 1 0.539875 0.865466 0.66542 0.824352 0.0667554 0.287025 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 246
Initial state: 0 0.653986 0.890597 0.675875 0.851787 0.483385 0.00106817 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2304926 episodes
GETTING ACTION FROM:
action 3, numVisits=2304879, meanQ=6.235149, numObservations: 4
action 2, numVisits=41, meanQ=4.988056, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.653986 0.890597 0.675875 0.851787 0.483385 0.00106817 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=211623, meanQ=8.879747, numObservations: 4
action 1, numVisits=106178, meanQ=8.874338, numObservations: 4
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2882583 episodes
GETTING ACTION FROM:
action 2, numVisits=1714404, meanQ=6.654836, numObservations: 4
action 1, numVisits=1485974, meanQ=6.654375, numObservations: 4
action 3, numVisits=4, meanQ=1.747500, numObservations: 3
action -1, numVisits=3, meanQ=1.300000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 2
Next state: 1 0.653986 0.890597 0.675875 0.851787 0.483385 0.00106817 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 247
Initial state: 0 0.65552 0.807442 0.967151 0.631869 0.695399 0.835469 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2301971 episodes
GETTING ACTION FROM:
action 3, numVisits=2301963, meanQ=6.224318, numObservations: 5
action 2, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.65552 0.807442 0.967151 0.631869 0.695399 0.835469 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 248
Initial state: 0 0.541402 0.360316 0.558685 0.89546 0.564098 0.8594 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2328503 episodes
GETTING ACTION FROM:
action 3, numVisits=2328456, meanQ=6.238744, numObservations: 4
action 1, numVisits=19, meanQ=3.725795, numObservations: 3
action 2, numVisits=24, meanQ=3.206679, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.541402 0.360316 0.558685 0.89546 0.564098 0.8594 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 249
Initial state: 0 0.217722 0.645795 0.589975 0.862086 0.622955 0.854944 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2330953 episodes
GETTING ACTION FROM:
action 3, numVisits=2325624, meanQ=6.225800, numObservations: 3
action 2, numVisits=5320, meanQ=6.096192, numObservations: 5
action 1, numVisits=5, meanQ=1.196020, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.217722 0.645795 0.589975 0.862086 0.622955 0.854944 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=103004, meanQ=6.482905, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2838703 episodes
GETTING ACTION FROM:
action 2, numVisits=2941705, meanQ=6.621939, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.217722 0.645795 0.589975 0.862086 0.622955 0.854944 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 250
Initial state: 0 0.675849 0.884231 0.673222 0.847318 0.919159 0.400611 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2326715 episodes
GETTING ACTION FROM:
action 3, numVisits=2326672, meanQ=6.225009, numObservations: 4
action 0, numVisits=21, meanQ=4.544458, numObservations: 1
action 2, numVisits=17, meanQ=3.763535, numObservations: 3
action 1, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 2 0.675849 0.884231 0.673222 0.847318 0.919159 0.400611 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 251
Initial state: 0 0.403012 0.465381 0.698648 0.880546 0.504892 0.850762 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2327127 episodes
GETTING ACTION FROM:
action 1, numVisits=2326543, meanQ=6.223966, numObservations: 4
action 2, numVisits=537, meanQ=5.890414, numObservations: 5
action 0, numVisits=43, meanQ=5.026942, numObservations: 1
action 3, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.403012 0.465381 0.698648 0.880546 0.504892 0.850762 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=131081, meanQ=8.939251, numObservations: 3
action 2, numVisits=121517, meanQ=8.938519, numObservations: 3
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2877837 episodes
GETTING ACTION FROM:
action 3, numVisits=2158116, meanQ=6.570617, numObservations: 3
action 2, numVisits=972311, meanQ=6.567974, numObservations: 5
action 1, numVisits=7, meanQ=1.998571, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 3
Next state: 1 0.403012 0.465381 0.698648 0.880546 0.504892 0.850762 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 252
Initial state: 0 0.331729 0.28892 0.534412 0.802233 0.571865 0.851487 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2322364 episodes
GETTING ACTION FROM:
action 3, numVisits=2322352, meanQ=6.311576, numObservations: 4
action 2, numVisits=7, meanQ=3.285714, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.331729 0.28892 0.534412 0.802233 0.571865 0.851487 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 253
Initial state: 0 0.329076 0.143408 0.589721 0.845016 0.553319 0.816683 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2304625 episodes
GETTING ACTION FROM:
action 3, numVisits=2304610, meanQ=6.233731, numObservations: 5
action 1, numVisits=10, meanQ=3.197010, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.329076 0.143408 0.589721 0.845016 0.553319 0.816683 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 254
Initial state: 0 0.52875 0.872144 0.656769 0.868323 0.603696 0.902789 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2311809 episodes
GETTING ACTION FROM:
action 3, numVisits=2311748, meanQ=6.232866, numObservations: 4
action 0, numVisits=24, meanQ=4.603078, numObservations: 1
action 1, numVisits=34, meanQ=4.547353, numObservations: 4
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.52875 0.872144 0.656769 0.868323 0.603696 0.902789 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 255
Initial state: 0 0.592021 0.878048 0.449349 0.720432 0.519796 0.897628 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2318882 episodes
GETTING ACTION FROM:
action 1, numVisits=2318826, meanQ=6.236978, numObservations: 4
action 0, numVisits=45, meanQ=5.080111, numObservations: 1
action 3, numVisits=5, meanQ=0.998020, numObservations: 3
action 2, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.592021 0.878048 0.449349 0.720432 0.519796 0.897628 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 256
Initial state: 0 0.626758 0.863234 0.131109 0.585137 0.579957 0.855429 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2327622 episodes
GETTING ACTION FROM:
action 3, numVisits=2327531, meanQ=6.237428, numObservations: 4
action -1, numVisits=26, meanQ=4.719716, numObservations: 1
action 1, numVisits=49, meanQ=4.033063, numObservations: 4
action 2, numVisits=14, meanQ=2.783571, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.626758 0.863234 0.131109 0.585137 0.579957 0.855429 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 257
Initial state: 0 0.572082 0.841823 0.185343 0.011193 0.674431 0.879611 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2303584 episodes
GETTING ACTION FROM:
action 3, numVisits=2303545, meanQ=6.237451, numObservations: 5
action 0, numVisits=20, meanQ=4.507705, numObservations: 1
action 2, numVisits=11, meanQ=3.544555, numObservations: 4
action 1, numVisits=6, meanQ=2.331683, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.572082 0.841823 0.185343 0.011193 0.674431 0.879611 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 258
Initial state: 0 0.51759 0.862314 0.113319 0.350715 0.608117 0.800556 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2303207 episodes
GETTING ACTION FROM:
action 3, numVisits=2303142, meanQ=6.228558, numObservations: 5
action -1, numVisits=37, meanQ=4.967222, numObservations: 1
action 2, numVisits=25, meanQ=4.675200, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.51759 0.862314 0.113319 0.350715 0.608117 0.800556 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=103652, meanQ=6.461620, numObservations: 5
action 3, numVisits=99, meanQ=5.691415, numObservations: 3
action 1, numVisits=4, meanQ=-0.505000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2858943 episodes
GETTING ACTION FROM:
action 2, numVisits=2962593, meanQ=6.508544, numObservations: 5
action 3, numVisits=99, meanQ=5.691415, numObservations: 3
action 1, numVisits=4, meanQ=-0.505000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 2
Next state: 0 0.51759 0.862314 0.113319 0.350715 0.608117 0.800556 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=26031, meanQ=8.884426, numObservations: 3
action 3, numVisits=4, meanQ=4.245025, numObservations: 2
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2960897 episodes
GETTING ACTION FROM:
action 1, numVisits=2972416, meanQ=6.645552, numObservations: 3
action 2, numVisits=14134, meanQ=6.584464, numObservations: 5
action 3, numVisits=381, meanQ=6.241182, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 1
Next state: 1 0.51759 0.862314 0.113319 0.350715 0.608117 0.800556 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.8309
Run # 259
Initial state: 0 0.681844 0.832505 0.682765 0.830986 0.712711 0.313845 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2333111 episodes
GETTING ACTION FROM:
action 3, numVisits=2333099, meanQ=6.311954, numObservations: 4
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action 2, numVisits=4, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.681844 0.832505 0.682765 0.830986 0.712711 0.313845 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 260
Initial state: 0 0.130066 0.831964 0.525068 0.817908 0.595828 0.800709 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2327092 episodes
GETTING ACTION FROM:
action 1, numVisits=2326722, meanQ=6.237750, numObservations: 4
action 3, numVisits=305, meanQ=5.800525, numObservations: 4
action -1, numVisits=61, meanQ=5.239180, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.130066 0.831964 0.525068 0.817908 0.595828 0.800709 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 261
Initial state: 0 0.681027 0.810393 0.536096 0.888386 0.0628192 0.0453453 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2332949 episodes
GETTING ACTION FROM:
action 1, numVisits=2332880, meanQ=6.176026, numObservations: 4
action 0, numVisits=35, meanQ=4.868323, numObservations: 1
action 2, numVisits=30, meanQ=4.732007, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.681027 0.810393 0.536096 0.888386 0.0628192 0.0453453 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 262
Initial state: 0 0.603539 0.883356 0.728946 0.322481 0.600327 0.860196 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2337910 episodes
GETTING ACTION FROM:
action 2, numVisits=2337810, meanQ=6.310760, numObservations: 4
action -1, numVisits=45, meanQ=5.149117, numObservations: 1
action 0, numVisits=40, meanQ=5.098432, numObservations: 1
action 1, numVisits=7, meanQ=3.285714, numObservations: 2
action 3, numVisits=8, meanQ=2.873750, numObservations: 3
action: 2
Next state: 0 0.603539 0.883356 0.728946 0.322481 0.600327 0.860196 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=17547, meanQ=8.930832, numObservations: 3
action 3, numVisits=2, meanQ=4.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2902864 episodes
GETTING ACTION FROM:
action 1, numVisits=2920395, meanQ=6.546710, numObservations: 3
action 3, numVisits=15, meanQ=3.732007, numObservations: 4
action -1, numVisits=3, meanQ=1.300000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.603539 0.883356 0.728946 0.322481 0.600327 0.860196 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 263
Initial state: 0 0.515679 0.858091 0.544729 0.894017 0.748238 0.773172 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2348731 episodes
GETTING ACTION FROM:
action 2, numVisits=2348673, meanQ=6.183999, numObservations: 4
action -1, numVisits=41, meanQ=4.947351, numObservations: 1
action 1, numVisits=13, meanQ=3.606931, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 2
Next state: 1 0.515679 0.858091 0.544729 0.894017 0.748238 0.773172 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 264
Initial state: 0 0.598268 0.708832 0.516209 0.868998 0.504014 0.882259 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2325734 episodes
GETTING ACTION FROM:
action 1, numVisits=2325646, meanQ=6.237141, numObservations: 4
action -1, numVisits=42, meanQ=5.037166, numObservations: 1
action 0, numVisits=22, meanQ=4.579906, numObservations: 1
action 3, numVisits=20, meanQ=4.485000, numObservations: 4
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action: 1
Next state: 2 0.598268 0.708832 0.516209 0.868998 0.504014 0.882259 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 265
Initial state: 0 0.569415 0.886626 0.570244 0.822381 0.163006 0.019953 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2305412 episodes
GETTING ACTION FROM:
action 2, numVisits=2305288, meanQ=6.231530, numObservations: 5
action 0, numVisits=111, meanQ=5.501455, numObservations: 1
action 1, numVisits=10, meanQ=3.197010, numObservations: 3
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.569415 0.886626 0.570244 0.822381 0.163006 0.019953 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 266
Initial state: 0 0.445784 0.859759 0.539283 0.868399 0.661166 0.859212 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2326232 episodes
GETTING ACTION FROM:
action 1, numVisits=2326222, meanQ=6.183266, numObservations: 4
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action 3, numVisits=2, meanQ=-0.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.445784 0.859759 0.539283 0.868399 0.661166 0.859212 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=58519, meanQ=8.691219, numObservations: 3
action 3, numVisits=22, meanQ=7.271818, numObservations: 4
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2905257 episodes
GETTING ACTION FROM:
action 2, numVisits=2962278, meanQ=6.480372, numObservations: 3
action 3, numVisits=1488, meanQ=6.277661, numObservations: 4
action 1, numVisits=31, meanQ=4.697742, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 2
Next state: 1 0.445784 0.859759 0.539283 0.868399 0.661166 0.859212 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 267
Initial state: 0 0.558007 0.862944 0.349164 0.104277 0.681855 0.820695 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2331597 episodes
GETTING ACTION FROM:
action 1, numVisits=2331572, meanQ=6.234140, numObservations: 4
action 3, numVisits=12, meanQ=3.248342, numObservations: 3
action 2, numVisits=9, meanQ=2.553333, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.558007 0.862944 0.349164 0.104277 0.681855 0.820695 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 268
Initial state: 0 0.616587 0.832479 0.69074 0.858644 0.575916 0.672755 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2348913 episodes
GETTING ACTION FROM:
action 3, numVisits=2348856, meanQ=6.231550, numObservations: 3
action -1, numVisits=45, meanQ=5.049686, numObservations: 1
action 1, numVisits=8, meanQ=1.747500, numObservations: 3
action 2, numVisits=2, meanQ=-1.004950, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 3
Next state: 0 0.616587 0.832479 0.69074 0.858644 0.575916 0.672755 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=265941, meanQ=8.863175, numObservations: 4
action 1, numVisits=114958, meanQ=8.857873, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2892701 episodes
GETTING ACTION FROM:
action 2, numVisits=2378944, meanQ=6.724139, numObservations: 4
action 1, numVisits=894654, meanQ=6.720957, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.616587 0.832479 0.69074 0.858644 0.575916 0.672755 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 269
Initial state: 0 0.557138 0.856581 0.569307 0.83168 0.482894 0.428496 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2351159 episodes
GETTING ACTION FROM:
action 2, numVisits=2351142, meanQ=6.300137, numObservations: 4
action -1, numVisits=11, meanQ=3.892450, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.557138 0.856581 0.569307 0.83168 0.482894 0.428496 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 270
Initial state: 0 0.592274 0.842436 0.642955 0.883013 0.552917 0.804645 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2318902 episodes
GETTING ACTION FROM:
action 1, numVisits=2317771, meanQ=6.226661, numObservations: 4
action 3, numVisits=1109, meanQ=5.992249, numObservations: 4
action -1, numVisits=19, meanQ=4.389898, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.592274 0.842436 0.642955 0.883013 0.552917 0.804645 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 271
Initial state: 0 0.534555 0.816201 0.620249 0.887026 0.825647 0.408793 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2294928 episodes
GETTING ACTION FROM:
action 1, numVisits=2294871, meanQ=6.232553, numObservations: 5
action -1, numVisits=47, meanQ=5.105772, numObservations: 1
action 2, numVisits=6, meanQ=2.481667, numObservations: 3
action 3, numVisits=2, meanQ=-0.010000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.534555 0.816201 0.620249 0.887026 0.825647 0.408793 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 272
Initial state: 0 0.0941657 0.047246 0.6434 0.880379 0.621974 0.888667 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2328931 episodes
GETTING ACTION FROM:
action 1, numVisits=2328917, meanQ=6.234922, numObservations: 4
action 2, numVisits=7, meanQ=1.842857, numObservations: 2
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.0941657 0.047246 0.6434 0.880379 0.621974 0.888667 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=273334, meanQ=8.894025, numObservations: 5
action 3, numVisits=45637, meanQ=8.874246, numObservations: 3
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2868562 episodes
GETTING ACTION FROM:
action 2, numVisits=2680793, meanQ=6.428713, numObservations: 5
action 3, numVisits=506735, meanQ=6.422349, numObservations: 3
action 1, numVisits=4, meanQ=-0.754975, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.0941657 0.047246 0.6434 0.880379 0.621974 0.888667 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 273
Initial state: 0 0.441883 0.21561 0.602538 0.861603 0.547417 0.866095 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2318616 episodes
GETTING ACTION FROM:
action 3, numVisits=2318609, meanQ=6.240745, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.441883 0.21561 0.602538 0.861603 0.547417 0.866095 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 274
Initial state: 0 0.664001 0.814019 0.514949 0.76133 0.647444 0.887584 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2319947 episodes
GETTING ACTION FROM:
action 3, numVisits=2319803, meanQ=6.237447, numObservations: 4
action 2, numVisits=82, meanQ=5.368905, numObservations: 4
action 0, numVisits=41, meanQ=5.028809, numObservations: 1
action -1, numVisits=20, meanQ=4.429403, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.664001 0.814019 0.514949 0.76133 0.647444 0.887584 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 275
Initial state: 0 0.653392 0.884086 0.600831 0.602336 0.501239 0.844551 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2318699 episodes
GETTING ACTION FROM:
action 1, numVisits=2318691, meanQ=6.228971, numObservations: 4
action 2, numVisits=2, meanQ=-0.010000, numObservations: 2
action 3, numVisits=2, meanQ=-0.509950, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.653392 0.884086 0.600831 0.602336 0.501239 0.844551 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 276
Initial state: 0 0.587654 0.837298 0.558475 0.889218 0.602187 0.12533 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1479958 episodes
GETTING ACTION FROM:
action 0, numVisits=1479938, meanQ=5.796458, numObservations: 3
action 3, numVisits=15, meanQ=1.532687, numObservations: 3
action 1, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.587654 0.837298 0.558475 0.889218 0.602187 0.12533 w: 1
Observation: 0 0 0.761862 0 0.949668 0 0.0487322 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=449203, meanQ=6.544163, numObservations: 1
action 1, numVisits=6, meanQ=0.831667, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 2
Sampled 1667426 episodes
GETTING ACTION FROM:
action -1, numVisits=2116628, meanQ=5.342503, numObservations: 1
action 1, numVisits=6, meanQ=0.831667, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 2
action: -1
Next state: 0 0.587654 0.837298 0.558475 0.889218 0.602187 0.12533 w: 1
Observation: 0 0.569459 0 0.471782 0 0.559834 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=2116547, meanQ=6.531092, numObservations: 5
action 2, numVisits=58, meanQ=5.360174, numObservations: 4
action 3, numVisits=18, meanQ=4.665556, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 2488182 episodes
GETTING ACTION FROM:
action 2, numVisits=183945, meanQ=6.447313, numObservations: 4
action 1, numVisits=4420839, meanQ=6.097694, numObservations: 5
action 3, numVisits=21, meanQ=4.284295, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.587654 0.837298 0.558475 0.889218 0.602187 0.12533 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.8409
Run # 277
Initial state: 0 0.0510438 0.850611 0.689714 0.807174 0.579618 0.895556 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2337094 episodes
GETTING ACTION FROM:
action 2, numVisits=2337061, meanQ=6.238552, numObservations: 4
action 0, numVisits=28, meanQ=4.792808, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.0510438 0.850611 0.689714 0.807174 0.579618 0.895556 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 278
Initial state: 0 0.645244 0.813052 0.502841 0.0988113 0.61518 0.868666 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2330494 episodes
GETTING ACTION FROM:
action 3, numVisits=2330477, meanQ=6.240511, numObservations: 4
action 1, numVisits=9, meanQ=3.554444, numObservations: 2
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.645244 0.813052 0.502841 0.0988113 0.61518 0.868666 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 279
Initial state: 0 0.603441 0.88893 0.636828 0.973652 0.535506 0.813014 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2299641 episodes
GETTING ACTION FROM:
action 1, numVisits=2299634, meanQ=6.234912, numObservations: 5
action 2, numVisits=2, meanQ=-0.509950, numObservations: 1
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.603441 0.88893 0.636828 0.973652 0.535506 0.813014 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 280
Initial state: 0 0.265845 0.92445 0.557542 0.836184 0.629115 0.889837 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2299141 episodes
GETTING ACTION FROM:
action 1, numVisits=2299047, meanQ=6.236536, numObservations: 5
action 0, numVisits=54, meanQ=5.196424, numObservations: 1
action 2, numVisits=34, meanQ=4.814712, numObservations: 3
action 3, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.265845 0.92445 0.557542 0.836184 0.629115 0.889837 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 281
Initial state: 0 0.668811 0.878642 0.622681 0.818538 0.496446 0.502715 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2341378 episodes
GETTING ACTION FROM:
action 1, numVisits=2340929, meanQ=6.189855, numObservations: 3
action 2, numVisits=406, meanQ=5.803009, numObservations: 5
action 0, numVisits=31, meanQ=4.810194, numObservations: 1
action 3, numVisits=10, meanQ=2.999010, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.668811 0.878642 0.622681 0.818538 0.496446 0.502715 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 282
Initial state: 0 0.996897 0.524378 0.593019 0.859885 0.62323 0.867118 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2306379 episodes
GETTING ACTION FROM:
action 3, numVisits=2306326, meanQ=6.231628, numObservations: 5
action -1, numVisits=19, meanQ=4.387259, numObservations: 1
action 1, numVisits=30, meanQ=4.326667, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.996897 0.524378 0.593019 0.859885 0.62323 0.867118 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 283
Initial state: 0 0.561986 0.858406 0.00594221 0.45924 0.619203 0.80646 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2341135 episodes
GETTING ACTION FROM:
action 2, numVisits=2341125, meanQ=6.235004, numObservations: 4
action 3, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 2
Next state: 0 0.561986 0.858406 0.00594221 0.45924 0.619203 0.80646 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=321437, meanQ=8.889130, numObservations: 5
action 3, numVisits=4, meanQ=3.997525, numObservations: 2
action 2, numVisits=5, meanQ=2.762000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2840076 episodes
GETTING ACTION FROM:
action 1, numVisits=3161463, meanQ=6.570464, numObservations: 5
action 3, numVisits=52, meanQ=5.365002, numObservations: 4
action 2, numVisits=5, meanQ=2.762000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 1
Next state: 1 0.561986 0.858406 0.00594221 0.45924 0.619203 0.80646 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 284
Initial state: 0 0.697539 0.896637 0.595578 0.887194 0.159649 0.492366 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2315342 episodes
GETTING ACTION FROM:
action 3, numVisits=2315171, meanQ=6.183405, numObservations: 4
action 1, numVisits=166, meanQ=5.560093, numObservations: 3
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.697539 0.896637 0.595578 0.887194 0.159649 0.492366 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=202367, meanQ=8.868781, numObservations: 4
action 1, numVisits=117003, meanQ=8.864319, numObservations: 4
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2874227 episodes
GETTING ACTION FROM:
action 2, numVisits=2747036, meanQ=6.981608, numObservations: 4
action 1, numVisits=446533, meanQ=6.974668, numObservations: 4
action 3, numVisits=29, meanQ=5.472762, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.697539 0.896637 0.595578 0.887194 0.159649 0.492366 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 285
Initial state: 0 0.672574 0.884877 0.583649 0.87428 0.388045 0.690351 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2312063 episodes
GETTING ACTION FROM:
action 1, numVisits=2312050, meanQ=6.315790, numObservations: 5
action 3, numVisits=7, meanQ=3.284300, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 1
action: 1
Next state: 1 0.672574 0.884877 0.583649 0.87428 0.388045 0.690351 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 286
Initial state: 0 0.240473 0.00662611 0.675746 0.806946 0.578278 0.872268 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2281776 episodes
GETTING ACTION FROM:
action 1, numVisits=2281368, meanQ=6.150270, numObservations: 4
action 3, numVisits=336, meanQ=5.723717, numObservations: 5
action -1, numVisits=47, meanQ=5.000908, numObservations: 1
action 0, numVisits=23, meanQ=4.499234, numObservations: 1
action 2, numVisits=2, meanQ=-0.509950, numObservations: 1
action: 1
Next state: 0 0.240473 0.00662611 0.675746 0.806946 0.578278 0.872268 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=247454, meanQ=8.905624, numObservations: 3
action 2, numVisits=65018, meanQ=8.891225, numObservations: 4
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2900278 episodes
GETTING ACTION FROM:
action 3, numVisits=2788368, meanQ=6.765753, numObservations: 3
action 2, numVisits=424379, meanQ=6.758429, numObservations: 4
action 1, numVisits=4, meanQ=-0.505000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.240473 0.00662611 0.675746 0.806946 0.578278 0.872268 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 287
Initial state: 0 0.651685 0.398716 0.516147 0.815521 0.530084 0.887002 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2325107 episodes
GETTING ACTION FROM:
action 3, numVisits=2325060, meanQ=6.224506, numObservations: 4
action -1, numVisits=34, meanQ=4.858177, numObservations: 1
action 2, numVisits=9, meanQ=3.553344, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.651685 0.398716 0.516147 0.815521 0.530084 0.887002 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 288
Initial state: 0 0.583625 0.803569 0.999551 0.951203 0.610759 0.872657 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2320494 episodes
GETTING ACTION FROM:
action 3, numVisits=2320440, meanQ=6.187007, numObservations: 4
action 0, numVisits=22, meanQ=4.529206, numObservations: 1
action 2, numVisits=28, meanQ=4.284307, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.583625 0.803569 0.999551 0.951203 0.610759 0.872657 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 289
Initial state: 0 0.381518 0.863735 0.677292 0.837991 0.53515 0.882913 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2308763 episodes
GETTING ACTION FROM:
action 3, numVisits=2308726, meanQ=6.232057, numObservations: 4
action 0, numVisits=26, meanQ=4.704668, numObservations: 1
action 1, numVisits=7, meanQ=1.998571, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.381518 0.863735 0.677292 0.837991 0.53515 0.882913 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 290
Initial state: 0 0.0398797 0.638262 0.641621 0.883413 0.636108 0.873221 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2331109 episodes
GETTING ACTION FROM:
action 3, numVisits=2331087, meanQ=6.232339, numObservations: 4
action 1, numVisits=9, meanQ=3.554444, numObservations: 3
action 2, numVisits=9, meanQ=3.552244, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.0398797 0.638262 0.641621 0.883413 0.636108 0.873221 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 291
Initial state: 0 0.352473 0.113873 0.622734 0.851144 0.610634 0.802864 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2351169 episodes
GETTING ACTION FROM:
action 3, numVisits=2351103, meanQ=6.231058, numObservations: 3
action 0, numVisits=25, meanQ=4.592159, numObservations: 1
action -1, numVisits=21, meanQ=4.422582, numObservations: 1
action 1, numVisits=18, meanQ=4.108350, numObservations: 4
action 2, numVisits=2, meanQ=-0.509950, numObservations: 1
action: 3
Next state: 1 0.352473 0.113873 0.622734 0.851144 0.610634 0.802864 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 292
Initial state: 0 0.921125 0.978469 0.627352 0.806494 0.608588 0.89147 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2318506 episodes
GETTING ACTION FROM:
action 2, numVisits=2318387, meanQ=6.229322, numObservations: 4
action 1, numVisits=109, meanQ=5.361836, numObservations: 5
action 3, numVisits=6, meanQ=2.663333, numObservations: 4
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.921125 0.978469 0.627352 0.806494 0.608588 0.89147 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 293
Initial state: 0 0.0464722 0.799355 0.603465 0.808171 0.578108 0.868778 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2319820 episodes
GETTING ACTION FROM:
action 2, numVisits=2319734, meanQ=6.239763, numObservations: 5
action -1, numVisits=51, meanQ=5.166623, numObservations: 1
action 0, numVisits=32, meanQ=4.886109, numObservations: 1
action 1, numVisits=2, meanQ=-0.010000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.0464722 0.799355 0.603465 0.808171 0.578108 0.868778 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 294
Initial state: 0 0.141153 0.549759 0.611372 0.895188 0.503097 0.83235 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2355034 episodes
GETTING ACTION FROM:
action 1, numVisits=2354962, meanQ=6.231578, numObservations: 3
action 3, numVisits=34, meanQ=4.908238, numObservations: 4
action -1, numVisits=21, meanQ=4.485960, numObservations: 1
action 2, numVisits=15, meanQ=3.731347, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.141153 0.549759 0.611372 0.895188 0.503097 0.83235 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=382537, meanQ=8.855094, numObservations: 4
action 3, numVisits=111, meanQ=8.116759, numObservations: 4
action 1, numVisits=3, meanQ=2.660033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2898252 episodes
GETTING ACTION FROM:
action 2, numVisits=3278782, meanQ=6.678465, numObservations: 4
action 3, numVisits=2099, meanQ=6.507975, numObservations: 4
action 1, numVisits=18, meanQ=4.488894, numObservations: 4
action 0, numVisits=4, meanQ=2.702500, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 2
Next state: 1 0.141153 0.549759 0.611372 0.895188 0.503097 0.83235 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 295
Initial state: 0 0.568631 0.89436 0.963877 0.080446 0.680405 0.828205 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2333453 episodes
GETTING ACTION FROM:
action 2, numVisits=2333433, meanQ=6.229566, numObservations: 4
action 1, numVisits=12, meanQ=3.908342, numObservations: 3
action 3, numVisits=4, meanQ=1.747500, numObservations: 1
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.568631 0.89436 0.963877 0.080446 0.680405 0.828205 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=104507, meanQ=6.501260, numObservations: 3
action 3, numVisits=104, meanQ=5.796155, numObservations: 4
action 2, numVisits=19, meanQ=4.836316, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2902428 episodes
GETTING ACTION FROM:
action 1, numVisits=3006894, meanQ=6.422240, numObservations: 3
action 3, numVisits=106, meanQ=5.667925, numObservations: 4
action 2, numVisits=52, meanQ=5.280965, numObservations: 5
action -1, numVisits=6, meanQ=2.620000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 1
Next state: 1 0.568631 0.89436 0.963877 0.080446 0.680405 0.828205 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 296
Initial state: 0 0.523832 0.898674 0.696506 0.80243 0.210858 0.0393609 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2333022 episodes
GETTING ACTION FROM:
action 1, numVisits=2332930, meanQ=6.230118, numObservations: 4
action -1, numVisits=57, meanQ=5.197255, numObservations: 1
action 0, numVisits=26, meanQ=4.620250, numObservations: 1
action 2, numVisits=4, meanQ=1.747500, numObservations: 3
action 3, numVisits=5, meanQ=1.000000, numObservations: 1
action: 1
Next state: 1 0.523832 0.898674 0.696506 0.80243 0.210858 0.0393609 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 297
Initial state: 0 0.658564 0.828974 0.523071 0.85099 0.0751562 0.169313 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1582746 episodes
GETTING ACTION FROM:
action -1, numVisits=1582734, meanQ=4.113561, numObservations: 1
action 2, numVisits=4, meanQ=-0.505000, numObservations: 2
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 1
action: -1
Next state: 0 0.658564 0.828974 0.523071 0.85099 0.0751562 0.169313 w: 1
Observation: 0 0.637236 0 0.528631 0 0.0813796 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=1540247, meanQ=6.183968, numObservations: 4
action 1, numVisits=42481, meanQ=6.122741, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2548809 episodes
GETTING ACTION FROM:
action 3, numVisits=4089056, meanQ=6.168575, numObservations: 4
action 1, numVisits=42481, meanQ=6.122741, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.658564 0.828974 0.523071 0.85099 0.0751562 0.169313 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=314077, meanQ=8.875719, numObservations: 4
action 1, numVisits=219976, meanQ=8.873427, numObservations: 4
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2876976 episodes
GETTING ACTION FROM:
action 2, numVisits=2617700, meanQ=7.163760, numObservations: 4
action 1, numVisits=793325, meanQ=7.159832, numObservations: 4
action 3, numVisits=5, meanQ=3.198000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.658564 0.828974 0.523071 0.85099 0.0751562 0.169313 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 5.8309
Run # 298
Initial state: 0 0.633835 0.829047 0.510183 0.855193 0.76953 0.352015 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2321847 episodes
GETTING ACTION FROM:
action 2, numVisits=2321831, meanQ=6.231233, numObservations: 5
action 3, numVisits=11, meanQ=3.814555, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.633835 0.829047 0.510183 0.855193 0.76953 0.352015 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 299
Initial state: 0 0.630809 0.858514 0.508163 0.838585 0.0156172 0.612769 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2326231 episodes
GETTING ACTION FROM:
action 2, numVisits=2326214, meanQ=6.233779, numObservations: 4
action 1, numVisits=6, meanQ=2.663333, numObservations: 3
action 3, numVisits=7, meanQ=1.998571, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.630809 0.858514 0.508163 0.838585 0.0156172 0.612769 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 300
Initial state: 0 0.521389 0.884476 0.0138538 0.847472 0.513818 0.871057 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2329147 episodes
GETTING ACTION FROM:
action 2, numVisits=2329140, meanQ=6.222152, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.521389 0.884476 0.0138538 0.847472 0.513818 0.871057 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=33562, meanQ=7.829214, numObservations: 4
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2895288 episodes
GETTING ACTION FROM:
action 3, numVisits=2928841, meanQ=6.524476, numObservations: 4
action 1, numVisits=8, meanQ=2.873750, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 3
Next state: 1 0.521389 0.884476 0.0138538 0.847472 0.513818 0.871057 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 301
Initial state: 0 0.684558 0.84696 0.802396 0.0589671 0.562012 0.826678 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2328971 episodes
GETTING ACTION FROM:
action 2, numVisits=2328897, meanQ=6.309218, numObservations: 5
action 3, numVisits=41, meanQ=5.039512, numObservations: 3
action -1, numVisits=29, meanQ=4.888741, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.684558 0.84696 0.802396 0.0589671 0.562012 0.826678 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 302
Initial state: 0 0.49902 0.584103 0.661096 0.884338 0.605673 0.874876 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2351284 episodes
GETTING ACTION FROM:
action 2, numVisits=2351275, meanQ=6.237557, numObservations: 4
action 3, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.49902 0.584103 0.661096 0.884338 0.605673 0.874876 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 303
Initial state: 0 0.618278 0.852271 0.847239 0.399121 0.57985 0.888402 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2289019 episodes
GETTING ACTION FROM:
action 3, numVisits=2288977, meanQ=6.231808, numObservations: 5
action 0, numVisits=25, meanQ=4.680896, numObservations: 1
action 2, numVisits=13, meanQ=3.607692, numObservations: 3
action 1, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.618278 0.852271 0.847239 0.399121 0.57985 0.888402 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 304
Initial state: 0 0.558287 0.869551 0.6722 0.867404 0.978141 0.543941 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2324368 episodes
GETTING ACTION FROM:
action 1, numVisits=2324330, meanQ=6.226488, numObservations: 4
action 0, numVisits=26, meanQ=4.597662, numObservations: 1
action 2, numVisits=8, meanQ=1.747500, numObservations: 3
action 3, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.558287 0.869551 0.6722 0.867404 0.978141 0.543941 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 305
Initial state: 0 0.580305 0.833774 0.146769 0.939055 0.53373 0.823691 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2347706 episodes
GETTING ACTION FROM:
action 2, numVisits=2332909, meanQ=6.227230, numObservations: 4
action 1, numVisits=14718, meanQ=6.134004, numObservations: 4
action -1, numVisits=72, meanQ=5.327022, numObservations: 1
action 3, numVisits=5, meanQ=1.196020, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 2
Next state: 0 0.580305 0.833774 0.146769 0.939055 0.53373 0.823691 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=103707, meanQ=6.552913, numObservations: 5
action 3, numVisits=10, meanQ=4.297000, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2840991 episodes
GETTING ACTION FROM:
action 1, numVisits=2944693, meanQ=6.549282, numObservations: 5
action 3, numVisits=13, meanQ=3.843846, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.580305 0.833774 0.146769 0.939055 0.53373 0.823691 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 306
Initial state: 0 0.672796 0.809555 0.625457 0.894673 0.122318 0.104673 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2312845 episodes
GETTING ACTION FROM:
action 2, numVisits=2312831, meanQ=6.232383, numObservations: 5
action 1, numVisits=8, meanQ=2.623775, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 1
action: 2
Next state: 1 0.672796 0.809555 0.625457 0.894673 0.122318 0.104673 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 307
Initial state: 0 0.623923 0.865321 0.854431 0.880178 0.506565 0.88876 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2323931 episodes
GETTING ACTION FROM:
action 1, numVisits=2323924, meanQ=6.212019, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.623923 0.865321 0.854431 0.880178 0.506565 0.88876 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 308
Initial state: 0 0.506801 0.816525 0.663649 0.809215 0.469888 0.216775 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2338509 episodes
GETTING ACTION FROM:
action 3, numVisits=2338459, meanQ=6.226443, numObservations: 3
action 0, numVisits=38, meanQ=4.983461, numObservations: 1
action 2, numVisits=9, meanQ=3.553344, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.506801 0.816525 0.663649 0.809215 0.469888 0.216775 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=380357, meanQ=8.854472, numObservations: 4
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2880921 episodes
GETTING ACTION FROM:
action 2, numVisits=3260607, meanQ=6.720919, numObservations: 4
action 3, numVisits=376, meanQ=6.299162, numObservations: 5
action 1, numVisits=295, meanQ=6.253120, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 2
Next state: 1 0.506801 0.816525 0.663649 0.809215 0.469888 0.216775 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 309
Initial state: 0 0.410133 0.135573 0.642903 0.889224 0.55212 0.86793 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2340342 episodes
GETTING ACTION FROM:
action 2, numVisits=2340270, meanQ=6.236375, numObservations: 4
action -1, numVisits=59, meanQ=5.241491, numObservations: 1
action 3, numVisits=9, meanQ=3.554444, numObservations: 2
action 1, numVisits=2, meanQ=-0.010000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.410133 0.135573 0.642903 0.889224 0.55212 0.86793 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 310
Initial state: 0 0.511245 0.843511 0.50715 0.85052 0.986596 0.999749 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2332283 episodes
GETTING ACTION FROM:
action 3, numVisits=2332255, meanQ=6.237242, numObservations: 4
action 1, numVisits=23, meanQ=4.260004, numObservations: 3
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.511245 0.843511 0.50715 0.85052 0.986596 0.999749 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 311
Initial state: 0 0.670009 0.815736 0.585163 0.810003 0.724939 0.739781 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1565884 episodes
GETTING ACTION FROM:
action -1, numVisits=1565869, meanQ=4.255560, numObservations: 1
action 3, numVisits=9, meanQ=1.090000, numObservations: 3
action 2, numVisits=3, meanQ=-0.670000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.670009 0.815736 0.585163 0.810003 0.724939 0.739781 w: 1
Observation: 0 0.666415 0 0.574458 0 0.787037 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=1562953, meanQ=6.321037, numObservations: 5
action 1, numVisits=1768, meanQ=6.143335, numObservations: 5
action 2, numVisits=1118, meanQ=6.088592, numObservations: 4
action -1, numVisits=27, meanQ=4.853613, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 2464630 episodes
GETTING ACTION FROM:
action 1, numVisits=2049827, meanQ=6.320683, numObservations: 5
action 3, numVisits=1979343, meanQ=6.249298, numObservations: 5
action 2, numVisits=1298, meanQ=6.037233, numObservations: 4
action -1, numVisits=28, meanQ=4.795695, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.670009 0.815736 0.585163 0.810003 0.724939 0.739781 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 312
Initial state: 0 0.709767 0.384015 0.686592 0.887905 0.663014 0.861957 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2330406 episodes
GETTING ACTION FROM:
action 3, numVisits=2330337, meanQ=6.232901, numObservations: 4
action 0, numVisits=64, meanQ=5.276689, numObservations: 1
action 1, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.709767 0.384015 0.686592 0.887905 0.663014 0.861957 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 313
Initial state: 0 0.654296 0.82758 0.561113 0.807688 0.455236 0.831876 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2305540 episodes
GETTING ACTION FROM:
action 2, numVisits=2305469, meanQ=6.224107, numObservations: 5
action 0, numVisits=63, meanQ=5.252398, numObservations: 1
action 1, numVisits=5, meanQ=1.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.654296 0.82758 0.561113 0.807688 0.455236 0.831876 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 314
Initial state: 0 0.692269 0.835582 0.827019 0.991735 0.606544 0.814852 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2352233 episodes
GETTING ACTION FROM:
action 2, numVisits=2349593, meanQ=6.234663, numObservations: 3
action 1, numVisits=2295, meanQ=6.076843, numObservations: 4
action 3, numVisits=290, meanQ=5.785924, numObservations: 4
action 0, numVisits=31, meanQ=4.832094, numObservations: 1
action -1, numVisits=24, meanQ=4.616166, numObservations: 1
action: 2
Next state: 1 0.692269 0.835582 0.827019 0.991735 0.606544 0.814852 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 315
Initial state: 0 0.596264 0.876122 0.675097 0.889409 0.42114 0.249204 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2357040 episodes
GETTING ACTION FROM:
action 1, numVisits=2353843, meanQ=6.226496, numObservations: 3
action 3, numVisits=3151, meanQ=5.936426, numObservations: 4
action -1, numVisits=30, meanQ=4.823867, numObservations: 1
action 2, numVisits=14, meanQ=4.070714, numObservations: 4
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 1
Next state: 1 0.596264 0.876122 0.675097 0.889409 0.42114 0.249204 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 316
Initial state: 0 0.567518 0.234914 0.595473 0.839462 0.695576 0.843995 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2322796 episodes
GETTING ACTION FROM:
action 1, numVisits=2322757, meanQ=6.243253, numObservations: 4
action 3, numVisits=34, meanQ=4.558244, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.567518 0.234914 0.595473 0.839462 0.695576 0.843995 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=222906, meanQ=8.856489, numObservations: 5
action 3, numVisits=155215, meanQ=8.853340, numObservations: 4
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2845643 episodes
GETTING ACTION FROM:
action 2, numVisits=2555400, meanQ=6.940675, numObservations: 5
action 3, numVisits=668360, meanQ=6.935999, numObservations: 4
action 1, numVisits=5, meanQ=3.198000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.567518 0.234914 0.595473 0.839462 0.695576 0.843995 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 317
Initial state: 0 0.593765 0.863861 0.585899 0.893807 0.109182 0.731379 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2307494 episodes
GETTING ACTION FROM:
action 1, numVisits=2307482, meanQ=6.234727, numObservations: 5
action 2, numVisits=5, meanQ=1.396000, numObservations: 2
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.593765 0.863861 0.585899 0.893807 0.109182 0.731379 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 318
Initial state: 0 0.767102 0.801958 0.590176 0.888307 0.612152 0.857504 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2299773 episodes
GETTING ACTION FROM:
action 1, numVisits=2299685, meanQ=6.243973, numObservations: 5
action 0, numVisits=52, meanQ=5.168673, numObservations: 1
action -1, numVisits=29, meanQ=4.820761, numObservations: 1
action 2, numVisits=6, meanQ=2.663333, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.767102 0.801958 0.590176 0.888307 0.612152 0.857504 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 319
Initial state: 0 0.603305 0.421916 0.57771 0.899954 0.544854 0.858254 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2325153 episodes
GETTING ACTION FROM:
action 3, numVisits=2325099, meanQ=6.183256, numObservations: 4
action -1, numVisits=42, meanQ=5.004806, numObservations: 1
action 1, numVisits=9, meanQ=3.554444, numObservations: 3
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.603305 0.421916 0.57771 0.899954 0.544854 0.858254 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 320
Initial state: 0 0.149114 0.322164 0.577594 0.880187 0.63794 0.874439 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2326342 episodes
GETTING ACTION FROM:
action 2, numVisits=2326212, meanQ=6.227049, numObservations: 4
action 0, numVisits=78, meanQ=5.363973, numObservations: 2
action 3, numVisits=46, meanQ=4.481957, numObservations: 3
action 1, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 2
Next state: 1 0.149114 0.322164 0.577594 0.880187 0.63794 0.874439 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 321
Initial state: 0 0.665219 0.818116 0.209182 0.790741 0.692552 0.809905 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2329457 episodes
GETTING ACTION FROM:
action 3, numVisits=2329425, meanQ=6.229184, numObservations: 3
action -1, numVisits=18, meanQ=4.336597, numObservations: 1
action 2, numVisits=11, meanQ=2.726364, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.665219 0.818116 0.209182 0.790741 0.692552 0.809905 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 322
Initial state: 0 0.654505 0.80759 0.61791 0.847138 0.540659 0.925158 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2304146 episodes
GETTING ACTION FROM:
action 1, numVisits=2304090, meanQ=6.231654, numObservations: 5
action 0, numVisits=45, meanQ=5.092293, numObservations: 1
action 3, numVisits=5, meanQ=2.762000, numObservations: 2
action 2, numVisits=4, meanQ=1.747500, numObservations: 3
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 1
Next state: 1 0.654505 0.80759 0.61791 0.847138 0.540659 0.925158 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 323
Initial state: 0 0.620223 0.879734 0.570774 0.894452 0.321183 0.563655 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2347595 episodes
GETTING ACTION FROM:
action 2, numVisits=2347564, meanQ=6.182636, numObservations: 4
action -1, numVisits=12, meanQ=3.757186, numObservations: 1
action 0, numVisits=11, meanQ=3.577600, numObservations: 1
action 1, numVisits=6, meanQ=2.663333, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action: 2
Next state: 1 0.620223 0.879734 0.570774 0.894452 0.321183 0.563655 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 324
Initial state: 0 0.511161 0.888277 0.585893 0.826175 0.763217 0.975701 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2307385 episodes
GETTING ACTION FROM:
action 1, numVisits=2307274, meanQ=6.229067, numObservations: 5
action 3, numVisits=105, meanQ=5.485816, numObservations: 4
action 2, numVisits=2, meanQ=-0.010000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.511161 0.888277 0.585893 0.826175 0.763217 0.975701 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 325
Initial state: 0 0.116288 0.926492 0.564865 0.863309 0.615094 0.852261 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2309721 episodes
GETTING ACTION FROM:
action 3, numVisits=2309601, meanQ=6.228043, numObservations: 4
action 2, numVisits=89, meanQ=5.342812, numObservations: 5
action 0, numVisits=14, meanQ=4.066499, numObservations: 1
action 1, numVisits=15, meanQ=3.858000, numObservations: 4
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 3
Next state: 1 0.116288 0.926492 0.564865 0.863309 0.615094 0.852261 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 326
Initial state: 0 0.686899 0.838066 0.663294 0.808475 0.937517 0.0444697 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2364926 episodes
GETTING ACTION FROM:
action 2, numVisits=2364859, meanQ=6.227301, numObservations: 3
action 0, numVisits=39, meanQ=5.001483, numObservations: 1
action 3, numVisits=21, meanQ=4.237624, numObservations: 4
action 1, numVisits=5, meanQ=2.798040, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.686899 0.838066 0.663294 0.808475 0.937517 0.0444697 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 327
Initial state: 0 0.571839 0.84951 0.834391 0.799413 0.689289 0.843936 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2299479 episodes
GETTING ACTION FROM:
action 1, numVisits=2299442, meanQ=6.227898, numObservations: 5
action -1, numVisits=27, meanQ=4.739006, numObservations: 1
action 3, numVisits=6, meanQ=0.831667, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.571839 0.84951 0.834391 0.799413 0.689289 0.843936 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=104410, meanQ=6.455209, numObservations: 4
action 3, numVisits=3, meanQ=2.333333, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2883472 episodes
GETTING ACTION FROM:
action 2, numVisits=2987876, meanQ=6.246919, numObservations: 4
action 3, numVisits=7, meanQ=3.285714, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 2
Next state: 0 0.571839 0.84951 0.834391 0.799413 0.689289 0.843936 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=3852, meanQ=6.166799, numObservations: 3
action 3, numVisits=11, meanQ=2.725464, numObservations: 3
action 2, numVisits=9, meanQ=2.442233, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2925879 episodes
GETTING ACTION FROM:
action 1, numVisits=2929731, meanQ=6.876377, numObservations: 4
action 3, numVisits=11, meanQ=2.725464, numObservations: 3
action 2, numVisits=9, meanQ=2.442233, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.571839 0.84951 0.834391 0.799413 0.689289 0.843936 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.8309
Run # 328
Initial state: 0 0.523969 0.887359 0.6324 0.87305 0.556197 0.80408 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2323521 episodes
GETTING ACTION FROM:
action 1, numVisits=2323498, meanQ=6.235997, numObservations: 4
action 3, numVisits=17, meanQ=3.763535, numObservations: 3
action 2, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.523969 0.887359 0.6324 0.87305 0.556197 0.80408 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 329
Initial state: 0 0.678535 0.80044 0.542707 0.855263 0.190671 0.766448 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2331605 episodes
GETTING ACTION FROM:
action 2, numVisits=2331562, meanQ=6.224871, numObservations: 4
action 0, numVisits=18, meanQ=4.341782, numObservations: 1
action -1, numVisits=17, meanQ=4.221708, numObservations: 1
action 1, numVisits=6, meanQ=2.331683, numObservations: 2
action 3, numVisits=2, meanQ=-0.010000, numObservations: 2
action: 2
Next state: 1 0.678535 0.80044 0.542707 0.855263 0.190671 0.766448 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 330
Initial state: 0 0.594163 0.874638 0.409646 0.29067 0.666607 0.897631 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2293722 episodes
GETTING ACTION FROM:
action 3, numVisits=2293705, meanQ=6.238147, numObservations: 5
action 1, numVisits=11, meanQ=1.906373, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 3
Next state: 0 0.594163 0.874638 0.409646 0.29067 0.666607 0.897631 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=103708, meanQ=6.549643, numObservations: 4
action 2, numVisits=29, meanQ=3.751731, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2894279 episodes
GETTING ACTION FROM:
action 1, numVisits=2997985, meanQ=6.697418, numObservations: 4
action 2, numVisits=29, meanQ=3.751731, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.594163 0.874638 0.409646 0.29067 0.666607 0.897631 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 331
Initial state: 0 0.55581 0.839011 0.593359 0.826825 0.924848 0.517346 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2292072 episodes
GETTING ACTION FROM:
action 3, numVisits=2292003, meanQ=6.238979, numObservations: 5
action 1, numVisits=46, meanQ=5.106089, numObservations: 3
action 0, numVisits=18, meanQ=4.398802, numObservations: 1
action 2, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 3
Next state: 2 0.55581 0.839011 0.593359 0.826825 0.924848 0.517346 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 332
Initial state: 0 0.56995 0.898996 0.561626 0.899639 0.271188 0.932876 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2329287 episodes
GETTING ACTION FROM:
action 3, numVisits=2329056, meanQ=6.233470, numObservations: 4
action 0, numVisits=176, meanQ=5.659338, numObservations: 2
action -1, numVisits=42, meanQ=5.053656, numObservations: 1
action 2, numVisits=11, meanQ=2.724564, numObservations: 2
action 1, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 3
Next state: 0 0.56995 0.898996 0.561626 0.899639 0.271188 0.932876 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=103874, meanQ=6.509752, numObservations: 4
action 2, numVisits=5, meanQ=3.198000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2880423 episodes
GETTING ACTION FROM:
action 1, numVisits=2984294, meanQ=6.237220, numObservations: 4
action 2, numVisits=6, meanQ=0.831667, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.56995 0.898996 0.561626 0.899639 0.271188 0.932876 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 333
Initial state: 0 0.670468 0.868752 0.651866 0.840454 0.956879 0.613613 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2325020 episodes
GETTING ACTION FROM:
action 2, numVisits=2324880, meanQ=6.308554, numObservations: 5
action 1, numVisits=110, meanQ=5.526275, numObservations: 4
action -1, numVisits=26, meanQ=4.789834, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 1
action: 2
Next state: 1 0.670468 0.868752 0.651866 0.840454 0.956879 0.613613 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 334
Initial state: 0 0.438914 0.976232 0.692033 0.832355 0.526221 0.861366 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2315011 episodes
GETTING ACTION FROM:
action 3, numVisits=2310770, meanQ=6.233661, numObservations: 4
action 1, numVisits=4176, meanQ=6.102383, numObservations: 4
action 0, numVisits=61, meanQ=5.241128, numObservations: 1
action 2, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.438914 0.976232 0.692033 0.832355 0.526221 0.861366 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 335
Initial state: 0 0.954049 0.103383 0.685401 0.868669 0.58827 0.817713 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2328893 episodes
GETTING ACTION FROM:
action 3, numVisits=2328847, meanQ=6.234098, numObservations: 4
action -1, numVisits=40, meanQ=5.025486, numObservations: 1
action 2, numVisits=2, meanQ=-0.010000, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 3
Next state: 1 0.954049 0.103383 0.685401 0.868669 0.58827 0.817713 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 336
Initial state: 0 0.568292 0.852839 0.576977 0.692802 0.59852 0.842705 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2317890 episodes
GETTING ACTION FROM:
action 3, numVisits=2317727, meanQ=6.224787, numObservations: 4
action 1, numVisits=155, meanQ=5.573682, numObservations: 5
action 2, numVisits=4, meanQ=1.745025, numObservations: 3
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.568292 0.852839 0.576977 0.692802 0.59852 0.842705 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 337
Initial state: 0 0.612752 0.858102 0.558514 0.872744 0.0534964 0.176243 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2335682 episodes
GETTING ACTION FROM:
action 2, numVisits=2335655, meanQ=6.237009, numObservations: 4
action 0, numVisits=22, meanQ=4.451324, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.612752 0.858102 0.558514 0.872744 0.0534964 0.176243 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 338
Initial state: 0 0.662457 0.864841 0.636408 0.858085 0.94193 0.681127 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2323980 episodes
GETTING ACTION FROM:
action 1, numVisits=2323965, meanQ=6.238822, numObservations: 4
action 3, numVisits=9, meanQ=3.554444, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.662457 0.864841 0.636408 0.858085 0.94193 0.681127 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 339
Initial state: 0 0.855465 0.997303 0.645215 0.883875 0.557482 0.831125 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2349217 episodes
GETTING ACTION FROM:
action 3, numVisits=2349163, meanQ=6.239885, numObservations: 3
action -1, numVisits=22, meanQ=4.590609, numObservations: 1
action 0, numVisits=14, meanQ=4.196351, numObservations: 1
action 2, numVisits=9, meanQ=2.333333, numObservations: 4
action 1, numVisits=9, meanQ=2.332233, numObservations: 2
action: 3
Next state: 0 0.855465 0.997303 0.645215 0.883875 0.557482 0.831125 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=104203, meanQ=6.622107, numObservations: 4
action 3, numVisits=12, meanQ=4.080850, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2882235 episodes
GETTING ACTION FROM:
action 1, numVisits=2986436, meanQ=6.653972, numObservations: 4
action 3, numVisits=12, meanQ=4.080850, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 1
Next state: 1 0.855465 0.997303 0.645215 0.883875 0.557482 0.831125 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 340
Initial state: 0 0.565356 0.804575 0.780692 0.96664 0.671422 0.830393 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2344116 episodes
GETTING ACTION FROM:
action 2, numVisits=2344055, meanQ=6.236832, numObservations: 4
action -1, numVisits=36, meanQ=4.935509, numObservations: 1
action 3, numVisits=20, meanQ=3.994505, numObservations: 3
action 1, numVisits=3, meanQ=-0.670000, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 2
Next state: 1 0.565356 0.804575 0.780692 0.96664 0.671422 0.830393 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 341
Initial state: 0 0.638124 0.882295 0.402152 0.849577 0.643628 0.826781 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2306883 episodes
GETTING ACTION FROM:
action 3, numVisits=2293245, meanQ=6.228759, numObservations: 5
action 1, numVisits=13594, meanQ=6.106815, numObservations: 4
action 0, numVisits=31, meanQ=4.828993, numObservations: 1
action 2, numVisits=11, meanQ=3.725455, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.638124 0.882295 0.402152 0.849577 0.643628 0.826781 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 342
Initial state: 0 0.6536 0.831047 0.550307 0.867814 0.77531 0.854205 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2322223 episodes
GETTING ACTION FROM:
action 3, numVisits=2321467, meanQ=6.233488, numObservations: 4
action 2, numVisits=750, meanQ=5.950522, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-5.505000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.6536 0.831047 0.550307 0.867814 0.77531 0.854205 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 343
Initial state: 0 0.5159 0.885935 0.268452 0.906607 0.528869 0.804056 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2303244 episodes
GETTING ACTION FROM:
action 3, numVisits=2294596, meanQ=6.241019, numObservations: 5
action 1, numVisits=8322, meanQ=6.159517, numObservations: 4
action 2, numVisits=245, meanQ=5.726421, numObservations: 4
action -1, numVisits=61, meanQ=5.261361, numObservations: 1
action 0, numVisits=20, meanQ=4.516977, numObservations: 1
action: 3
Next state: 1 0.5159 0.885935 0.268452 0.906607 0.528869 0.804056 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 344
Initial state: 0 0.689807 0.82844 0.625628 0.87423 0.598154 0.555779 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2317247 episodes
GETTING ACTION FROM:
action 3, numVisits=2317199, meanQ=6.234847, numObservations: 4
action 0, numVisits=27, meanQ=4.648812, numObservations: 1
action 2, numVisits=15, meanQ=4.180673, numObservations: 2
action 1, numVisits=4, meanQ=1.747500, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.689807 0.82844 0.625628 0.87423 0.598154 0.555779 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 345
Initial state: 0 0.18953 0.0332822 0.592701 0.800216 0.633972 0.855004 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2346619 episodes
GETTING ACTION FROM:
action 2, numVisits=2346523, meanQ=6.189308, numObservations: 4
action 3, numVisits=57, meanQ=5.097902, numObservations: 4
action -1, numVisits=35, meanQ=4.890371, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.18953 0.0332822 0.592701 0.800216 0.633972 0.855004 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 346
Initial state: 0 0.692014 0.884271 0.648292 0.0736164 0.567077 0.845565 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2315520 episodes
GETTING ACTION FROM:
action 1, numVisits=2315511, meanQ=6.232612, numObservations: 5
action 2, numVisits=4, meanQ=1.747500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.692014 0.884271 0.648292 0.0736164 0.567077 0.845565 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 347
Initial state: 0 0.56607 0.849057 0.536981 0.807852 0.609513 0.435507 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2308895 episodes
GETTING ACTION FROM:
action 3, numVisits=2308880, meanQ=6.211501, numObservations: 5
action 1, numVisits=9, meanQ=3.554444, numObservations: 3
action 2, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.56607 0.849057 0.536981 0.807852 0.609513 0.435507 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 348
Initial state: 0 0.621285 0.825078 0.644015 0.816594 0.0192607 0.833143 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2300894 episodes
GETTING ACTION FROM:
action 3, numVisits=2300746, meanQ=6.226353, numObservations: 5
action -1, numVisits=118, meanQ=5.523972, numObservations: 1
action 0, numVisits=20, meanQ=4.462913, numObservations: 1
action 2, numVisits=9, meanQ=2.332233, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.621285 0.825078 0.644015 0.816594 0.0192607 0.833143 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 349
Initial state: 0 0.505643 0.855494 0.540251 0.813751 0.802948 0.740695 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2275296 episodes
GETTING ACTION FROM:
action 3, numVisits=2275285, meanQ=6.216144, numObservations: 5
action 1, numVisits=4, meanQ=1.747500, numObservations: 2
action 2, numVisits=3, meanQ=-0.670000, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 2 0.505643 0.855494 0.540251 0.813751 0.802948 0.740695 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 350
Initial state: 0 0.509136 0.838196 0.673978 0.884064 0.186914 0.777031 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2322656 episodes
GETTING ACTION FROM:
action 3, numVisits=2322581, meanQ=6.236872, numObservations: 4
action -1, numVisits=64, meanQ=5.257912, numObservations: 1
action 2, numVisits=8, meanQ=1.746262, numObservations: 3
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.509136 0.838196 0.673978 0.884064 0.186914 0.777031 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=199489, meanQ=8.882518, numObservations: 4
action 1, numVisits=119993, meanQ=8.877224, numObservations: 4
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2866895 episodes
GETTING ACTION FROM:
action 2, numVisits=2152204, meanQ=6.893492, numObservations: 4
action 1, numVisits=1034169, meanQ=6.891591, numObservations: 4
action 3, numVisits=5, meanQ=1.196020, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.509136 0.838196 0.673978 0.884064 0.186914 0.777031 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 351
Initial state: 0 0.637588 0.840909 0.392564 0.31733 0.654706 0.872628 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2296704 episodes
GETTING ACTION FROM:
action 3, numVisits=2296624, meanQ=6.183526, numObservations: 5
action 0, numVisits=43, meanQ=5.004992, numObservations: 1
action -1, numVisits=15, meanQ=4.157491, numObservations: 1
action 2, numVisits=11, meanQ=2.725464, numObservations: 3
action 1, numVisits=11, meanQ=2.724564, numObservations: 3
action: 3
Next state: 1 0.637588 0.840909 0.392564 0.31733 0.654706 0.872628 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 352
Initial state: 0 0.512473 0.864945 0.27282 0.809434 0.677487 0.800891 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2349424 episodes
GETTING ACTION FROM:
action 3, numVisits=2349418, meanQ=6.231537, numObservations: 3
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.512473 0.864945 0.27282 0.809434 0.677487 0.800891 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 353
Initial state: 0 0.59757 0.832145 0.122056 0.225688 0.558698 0.868244 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2329582 episodes
GETTING ACTION FROM:
action 2, numVisits=2329569, meanQ=6.228478, numObservations: 4
action 1, numVisits=8, meanQ=2.873750, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.59757 0.832145 0.122056 0.225688 0.558698 0.868244 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=222965, meanQ=8.876510, numObservations: 4
action 3, numVisits=96947, meanQ=8.870578, numObservations: 5
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2864434 episodes
GETTING ACTION FROM:
action 3, numVisits=1672103, meanQ=6.621229, numObservations: 5
action 1, numVisits=1512236, meanQ=6.620819, numObservations: 4
action 2, numVisits=5, meanQ=2.980000, numObservations: 2
action -1, numVisits=3, meanQ=1.300000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 3
Next state: 1 0.59757 0.832145 0.122056 0.225688 0.558698 0.868244 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 354
Initial state: 0 0.59931 0.892418 0.652461 0.883311 0.00826957 0.983632 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2302116 episodes
GETTING ACTION FROM:
action 3, numVisits=2302087, meanQ=6.239163, numObservations: 5
action 0, numVisits=14, meanQ=3.959899, numObservations: 1
action 1, numVisits=11, meanQ=3.725455, numObservations: 4
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 3
Next state: 0 0.59931 0.892418 0.652461 0.883311 0.00826957 0.983632 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=103120, meanQ=6.567772, numObservations: 5
action 2, numVisits=19, meanQ=4.778947, numObservations: 4
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2848065 episodes
GETTING ACTION FROM:
action 1, numVisits=2951178, meanQ=6.465987, numObservations: 5
action 2, numVisits=24, meanQ=4.825000, numObservations: 4
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 1
Next state: 1 0.59931 0.892418 0.652461 0.883311 0.00826957 0.983632 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 355
Initial state: 0 0.60721 0.834991 0.392137 0.153965 0.635781 0.838658 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2348984 episodes
GETTING ACTION FROM:
action 3, numVisits=2348889, meanQ=6.229362, numObservations: 3
action -1, numVisits=40, meanQ=5.002625, numObservations: 1
action 0, numVisits=29, meanQ=4.785825, numObservations: 1
action 1, numVisits=25, meanQ=4.278408, numObservations: 5
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.60721 0.834991 0.392137 0.153965 0.635781 0.838658 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 356
Initial state: 0 0.655388 0.826023 0.501973 0.881646 0.088544 0.20762 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2307423 episodes
GETTING ACTION FROM:
action 3, numVisits=2307336, meanQ=6.231624, numObservations: 5
action -1, numVisits=42, meanQ=5.031188, numObservations: 1
action 1, numVisits=37, meanQ=4.939738, numObservations: 3
action 2, numVisits=6, meanQ=2.663333, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.655388 0.826023 0.501973 0.881646 0.088544 0.20762 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=127355, meanQ=8.938969, numObservations: 3
action 2, numVisits=123237, meanQ=8.938661, numObservations: 3
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2849736 episodes
GETTING ACTION FROM:
action 2, numVisits=1596864, meanQ=6.615879, numObservations: 5
action 1, numVisits=1503461, meanQ=6.615631, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 1
action: 2
Next state: 1 0.655388 0.826023 0.501973 0.881646 0.088544 0.20762 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 357
Initial state: 0 0.479636 0.266819 0.673914 0.848758 0.536004 0.874502 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2304040 episodes
GETTING ACTION FROM:
action 1, numVisits=2303966, meanQ=6.236650, numObservations: 5
action 0, numVisits=50, meanQ=5.146160, numObservations: 1
action 2, numVisits=21, meanQ=4.449529, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.479636 0.266819 0.673914 0.848758 0.536004 0.874502 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=316998, meanQ=8.882552, numObservations: 4
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2881781 episodes
GETTING ACTION FROM:
action 2, numVisits=3197561, meanQ=6.894802, numObservations: 4
action 3, numVisits=1210, meanQ=6.674898, numObservations: 4
action 1, numVisits=10, meanQ=3.990000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.479636 0.266819 0.673914 0.848758 0.536004 0.874502 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 358
Initial state: 0 0.736925 0.994769 0.599433 0.869505 0.689159 0.83905 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2326097 episodes
GETTING ACTION FROM:
action 2, numVisits=2326087, meanQ=6.240110, numObservations: 4
action 1, numVisits=4, meanQ=1.745025, numObservations: 2
action 3, numVisits=2, meanQ=-1.004950, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.736925 0.994769 0.599433 0.869505 0.689159 0.83905 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=125639, meanQ=8.681718, numObservations: 3
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2910318 episodes
GETTING ACTION FROM:
action 3, numVisits=1421165, meanQ=6.583184, numObservations: 4
action 1, numVisits=1614779, meanQ=6.509909, numObservations: 3
action 2, numVisits=13, meanQ=3.523846, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 3
Next state: 1 0.736925 0.994769 0.599433 0.869505 0.689159 0.83905 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 359
Initial state: 0 0.250052 0.895693 0.510129 0.810465 0.542435 0.85124 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2315333 episodes
GETTING ACTION FROM:
action 1, numVisits=2315291, meanQ=6.234695, numObservations: 4
action 0, numVisits=30, meanQ=4.801766, numObservations: 1
action 3, numVisits=9, meanQ=3.554444, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.250052 0.895693 0.510129 0.810465 0.542435 0.85124 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=58824, meanQ=8.667215, numObservations: 4
action 2, numVisits=225, meanQ=8.184360, numObservations: 4
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2850693 episodes
GETTING ACTION FROM:
action 2, numVisits=2580620, meanQ=6.754964, numObservations: 5
action 3, numVisits=329070, meanQ=6.734581, numObservations: 4
action 1, numVisits=53, meanQ=5.600953, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.250052 0.895693 0.510129 0.810465 0.542435 0.85124 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=2890, meanQ=8.389650, numObservations: 3
action 3, numVisits=35, meanQ=7.310860, numObservations: 4
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2873619 episodes
GETTING ACTION FROM:
action 2, numVisits=2876438, meanQ=6.604979, numObservations: 5
action 3, numVisits=97, meanQ=5.710104, numObservations: 4
action 1, numVisits=8, meanQ=2.873750, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 2
Next state: 1 0.250052 0.895693 0.510129 0.810465 0.542435 0.85124 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.8309
Run # 360
Initial state: 0 0.739433 0.712148 0.636158 0.857815 0.610462 0.895354 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2308913 episodes
GETTING ACTION FROM:
action 2, numVisits=2308898, meanQ=6.234665, numObservations: 5
action 1, numVisits=5, meanQ=1.396000, numObservations: 3
action 3, numVisits=6, meanQ=0.831667, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.739433 0.712148 0.636158 0.857815 0.610462 0.895354 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 361
Initial state: 0 0.969904 0.867171 0.619611 0.858552 0.603139 0.822358 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2332499 episodes
GETTING ACTION FROM:
action 1, numVisits=2332394, meanQ=6.227098, numObservations: 4
action 2, numVisits=100, meanQ=5.365101, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.969904 0.867171 0.619611 0.858552 0.603139 0.822358 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 362
Initial state: 0 0.597985 0.889601 0.68008 0.89686 0.856913 0.630853 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1571411 episodes
GETTING ACTION FROM:
action -1, numVisits=1571403, meanQ=4.252674, numObservations: 1
action 1, numVisits=3, meanQ=-0.670000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.597985 0.889601 0.68008 0.89686 0.856913 0.630853 w: 1
Observation: 0 0.561871 0 0.645552 0 0.800142 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=1571380, meanQ=6.319180, numObservations: 5
action 2, numVisits=11, meanQ=3.723655, numObservations: 3
action 1, numVisits=7, meanQ=1.998571, numObservations: 3
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 2483888 episodes
GETTING ACTION FROM:
action 3, numVisits=4055268, meanQ=6.325554, numObservations: 5
action 2, numVisits=11, meanQ=3.723655, numObservations: 3
action 1, numVisits=7, meanQ=1.998571, numObservations: 3
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 2 0.597985 0.889601 0.68008 0.89686 0.856913 0.630853 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 363
Initial state: 0 0.516822 0.842887 0.650865 0.885305 0.944596 0.446831 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2338404 episodes
GETTING ACTION FROM:
action 2, numVisits=1964452, meanQ=6.233492, numObservations: 3
action 1, numVisits=373935, meanQ=6.218809, numObservations: 4
action 3, numVisits=13, meanQ=3.446169, numObservations: 3
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.516822 0.842887 0.650865 0.885305 0.944596 0.446831 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 364
Initial state: 0 0.810231 0.189133 0.611061 0.836642 0.613257 0.888294 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2338140 episodes
GETTING ACTION FROM:
action 2, numVisits=2338134, meanQ=6.226120, numObservations: 4
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.810231 0.189133 0.611061 0.836642 0.613257 0.888294 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 365
Initial state: 0 0.569622 0.890362 0.574623 0.815443 0.660845 0.800493 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2343983 episodes
GETTING ACTION FROM:
action 1, numVisits=2343948, meanQ=6.231267, numObservations: 3
action -1, numVisits=29, meanQ=4.742137, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.569622 0.890362 0.574623 0.815443 0.660845 0.800493 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 366
Initial state: 0 0.697317 0.832291 0.676564 0.851539 0.42136 0.960614 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2303259 episodes
GETTING ACTION FROM:
action 1, numVisits=2303158, meanQ=6.243764, numObservations: 5
action 3, numVisits=47, meanQ=5.026598, numObservations: 4
action -1, numVisits=35, meanQ=4.941378, numObservations: 1
action 2, numVisits=17, meanQ=3.571182, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.697317 0.832291 0.676564 0.851539 0.42136 0.960614 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 367
Initial state: 0 0.589217 0.826239 0.51856 0.88481 0.879598 0.429947 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2312138 episodes
GETTING ACTION FROM:
action 2, numVisits=2281355, meanQ=6.234852, numObservations: 4
action 3, numVisits=30774, meanQ=6.192742, numObservations: 5
action 1, numVisits=5, meanQ=1.178000, numObservations: 3
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.589217 0.826239 0.51856 0.88481 0.879598 0.429947 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 368
Initial state: 0 0.64885 0.813659 0.61418 0.817581 0.835122 0.52992 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2353905 episodes
GETTING ACTION FROM:
action 2, numVisits=2353874, meanQ=6.227205, numObservations: 4
action -1, numVisits=27, meanQ=4.732088, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.64885 0.813659 0.61418 0.817581 0.835122 0.52992 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 369
Initial state: 0 0.583065 0.841465 0.629744 0.81407 0.0176598 0.627498 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2262893 episodes
GETTING ACTION FROM:
action 3, numVisits=2262881, meanQ=6.215905, numObservations: 5
action 1, numVisits=6, meanQ=2.333333, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 3
Next state: 0 0.583065 0.841465 0.629744 0.81407 0.0176598 0.627498 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=122667, meanQ=8.672496, numObservations: 5
action 2, numVisits=13, meanQ=6.768462, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2859491 episodes
GETTING ACTION FROM:
action 1, numVisits=2981552, meanQ=6.391187, numObservations: 5
action 2, numVisits=617, meanQ=6.069952, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.583065 0.841465 0.629744 0.81407 0.0176598 0.627498 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 370
Initial state: 0 0.193745 0.948724 0.64866 0.816621 0.612686 0.864114 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2348692 episodes
GETTING ACTION FROM:
action 3, numVisits=2348240, meanQ=6.189390, numObservations: 3
action 2, numVisits=302, meanQ=5.645709, numObservations: 5
action 0, numVisits=134, meanQ=5.525495, numObservations: 1
action -1, numVisits=14, meanQ=3.967301, numObservations: 1
action 1, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 3
Next state: 0 0.193745 0.948724 0.64866 0.816621 0.612686 0.864114 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=104961, meanQ=5.410074, numObservations: 4
action 0, numVisits=144, meanQ=4.862292, numObservations: 1
action -1, numVisits=98, meanQ=4.736025, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2646415 episodes
GETTING ACTION FROM:
action 3, numVisits=2751376, meanQ=6.087427, numObservations: 4
action 0, numVisits=144, meanQ=4.862292, numObservations: 1
action -1, numVisits=98, meanQ=4.736025, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.193745 0.948724 0.64866 0.816621 0.612686 0.864114 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 371
Initial state: 0 0.633467 0.874649 0.596335 0.866315 0.216055 0.0796141 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2310327 episodes
GETTING ACTION FROM:
action 3, numVisits=2310318, meanQ=6.244496, numObservations: 4
action 2, numVisits=4, meanQ=1.747500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.633467 0.874649 0.596335 0.866315 0.216055 0.0796141 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=272504, meanQ=8.851256, numObservations: 4
action 1, numVisits=102130, meanQ=8.842973, numObservations: 3
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2893192 episodes
GETTING ACTION FROM:
action 2, numVisits=2796966, meanQ=6.968938, numObservations: 4
action 1, numVisits=470856, meanQ=6.962234, numObservations: 3
action 3, numVisits=5, meanQ=1.396000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.633467 0.874649 0.596335 0.866315 0.216055 0.0796141 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 372
Initial state: 0 0.677331 0.853903 0.869491 0.56766 0.631157 0.856526 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2324331 episodes
GETTING ACTION FROM:
action 1, numVisits=2324324, meanQ=6.239142, numObservations: 4
action 2, numVisits=2, meanQ=-1.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.677331 0.853903 0.869491 0.56766 0.631157 0.856526 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 373
Initial state: 0 0.682652 0.876889 0.503423 0.855905 0.970105 0.0432513 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2305506 episodes
GETTING ACTION FROM:
action 2, numVisits=2305478, meanQ=6.240289, numObservations: 5
action 1, numVisits=22, meanQ=4.400005, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 1
action: 2
Next state: 0 0.682652 0.876889 0.503423 0.855905 0.970105 0.0432513 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=75863, meanQ=8.693989, numObservations: 3
action 1, numVisits=48643, meanQ=8.684060, numObservations: 4
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2913104 episodes
GETTING ACTION FROM:
action 3, numVisits=2187930, meanQ=6.463886, numObservations: 3
action 1, numVisits=849673, meanQ=6.460634, numObservations: 4
action 2, numVisits=6, meanQ=2.496683, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 3
Next state: 2 0.682652 0.876889 0.503423 0.855905 0.970105 0.0432513 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11.89
Run # 374
Initial state: 0 0.506655 0.832056 0.607092 0.150533 0.504699 0.867884 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2326841 episodes
GETTING ACTION FROM:
action 2, numVisits=2326817, meanQ=6.231433, numObservations: 4
action -1, numVisits=10, meanQ=3.764687, numObservations: 1
action 0, numVisits=10, meanQ=3.246010, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 1, numVisits=2, meanQ=-5.505000, numObservations: 1
action: 2
Next state: 2 0.506655 0.832056 0.607092 0.150533 0.504699 0.867884 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 375
Initial state: 0 0.435179 0.24165 0.661273 0.88994 0.671306 0.843677 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2259247 episodes
GETTING ACTION FROM:
action 3, numVisits=2259172, meanQ=6.224627, numObservations: 5
action -1, numVisits=60, meanQ=5.237375, numObservations: 1
action 1, numVisits=10, meanQ=2.999010, numObservations: 3
action 2, numVisits=3, meanQ=-0.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.435179 0.24165 0.661273 0.88994 0.671306 0.843677 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 376
Initial state: 0 0.0315309 0.208404 0.69844 0.871865 0.636804 0.802353 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2317437 episodes
GETTING ACTION FROM:
action 2, numVisits=2317423, meanQ=6.326108, numObservations: 5
action -1, numVisits=9, meanQ=2.947800, numObservations: 1
action 1, numVisits=2, meanQ=-0.509950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.0315309 0.208404 0.69844 0.871865 0.636804 0.802353 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 377
Initial state: 0 0.104438 0.79079 0.668472 0.879451 0.60312 0.891407 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2377129 episodes
GETTING ACTION FROM:
action 2, numVisits=2377095, meanQ=6.234064, numObservations: 3
action -1, numVisits=17, meanQ=4.202456, numObservations: 1
action 1, numVisits=13, meanQ=3.766931, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.104438 0.79079 0.668472 0.879451 0.60312 0.891407 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 378
Initial state: 0 0.549442 0.842455 0.547491 0.547583 0.662774 0.869729 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2296460 episodes
GETTING ACTION FROM:
action 3, numVisits=2296340, meanQ=6.232028, numObservations: 5
action -1, numVisits=98, meanQ=5.456674, numObservations: 1
action 1, numVisits=12, meanQ=3.990842, numObservations: 3
action 2, numVisits=8, meanQ=2.873750, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.549442 0.842455 0.547491 0.547583 0.662774 0.869729 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 379
Initial state: 0 0.636531 0.807528 0.629466 0.822782 0.668884 0.55461 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2310253 episodes
GETTING ACTION FROM:
action 1, numVisits=2310184, meanQ=6.235075, numObservations: 5
action -1, numVisits=62, meanQ=5.247008, numObservations: 1
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.636531 0.807528 0.629466 0.822782 0.668884 0.55461 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 380
Initial state: 0 0.558897 0.820453 0.528829 0.895882 0.850844 0.705582 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2298788 episodes
GETTING ACTION FROM:
action 3, numVisits=2284093, meanQ=6.232071, numObservations: 5
action 1, numVisits=14688, meanQ=6.133322, numObservations: 4
action 2, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 2 0.558897 0.820453 0.528829 0.895882 0.850844 0.705582 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 381
Initial state: 0 0.641171 0.815265 0.355895 0.316684 0.519627 0.865069 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2295165 episodes
GETTING ACTION FROM:
action 3, numVisits=2295137, meanQ=6.233946, numObservations: 5
action 0, numVisits=21, meanQ=4.489204, numObservations: 1
action 1, numVisits=3, meanQ=-0.670000, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 3
Next state: 1 0.641171 0.815265 0.355895 0.316684 0.519627 0.865069 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 382
Initial state: 0 0.811121 0.623214 0.622124 0.865263 0.668193 0.843941 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2356227 episodes
GETTING ACTION FROM:
action 2, numVisits=2356151, meanQ=6.234571, numObservations: 3
action 3, numVisits=38, meanQ=4.963947, numObservations: 4
action 0, numVisits=32, meanQ=4.866255, numObservations: 1
action 1, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 2
Next state: 1 0.811121 0.623214 0.622124 0.865263 0.668193 0.843941 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 383
Initial state: 0 0.613658 0.825115 0.363699 0.0854034 0.551227 0.848908 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2371680 episodes
GETTING ACTION FROM:
action 2, numVisits=2371609, meanQ=6.224423, numObservations: 3
action -1, numVisits=27, meanQ=4.723272, numObservations: 1
action 3, numVisits=40, meanQ=4.583505, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 2
Next state: 0 0.613658 0.825115 0.363699 0.0854034 0.551227 0.848908 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=202013, meanQ=8.853860, numObservations: 5
action 1, numVisits=183088, meanQ=8.853222, numObservations: 4
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2858083 episodes
GETTING ACTION FROM:
action 3, numVisits=1827864, meanQ=6.598851, numObservations: 5
action 1, numVisits=1415168, meanQ=6.598120, numObservations: 4
action 2, numVisits=151, meanQ=5.969737, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action: 3
Next state: 1 0.613658 0.825115 0.363699 0.0854034 0.551227 0.848908 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 384
Initial state: 0 0.513481 0.863878 0.699826 0.835682 0.798337 0.524275 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2297062 episodes
GETTING ACTION FROM:
action 2, numVisits=2297000, meanQ=6.235572, numObservations: 5
action 0, numVisits=31, meanQ=4.863626, numObservations: 1
action 3, numVisits=27, meanQ=4.628889, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-5.505000, numObservations: 1
action: 2
Next state: 1 0.513481 0.863878 0.699826 0.835682 0.798337 0.524275 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 385
Initial state: 0 0.671348 0.824734 0.587244 0.881987 0.215379 0.146415 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2359011 episodes
GETTING ACTION FROM:
action 3, numVisits=2347449, meanQ=6.238526, numObservations: 3
action 1, numVisits=11550, meanQ=6.168358, numObservations: 5
action 2, numVisits=8, meanQ=2.871275, numObservations: 3
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.671348 0.824734 0.587244 0.881987 0.215379 0.146415 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=199013, meanQ=8.862189, numObservations: 4
action 1, numVisits=181693, meanQ=8.861619, numObservations: 3
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2883316 episodes
GETTING ACTION FROM:
action 2, numVisits=2483667, meanQ=6.858574, numObservations: 4
action 1, numVisits=780352, meanQ=6.854702, numObservations: 3
action 3, numVisits=4, meanQ=-0.505000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.671348 0.824734 0.587244 0.881987 0.215379 0.146415 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 386
Initial state: 0 0.615944 0.822812 0.503186 0.878868 0.466005 0.666608 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2321762 episodes
GETTING ACTION FROM:
action 2, numVisits=2321676, meanQ=6.244638, numObservations: 5
action -1, numVisits=48, meanQ=5.137679, numObservations: 1
action 0, numVisits=30, meanQ=4.791535, numObservations: 1
action 1, numVisits=6, meanQ=2.663333, numObservations: 2
action 3, numVisits=2, meanQ=-1.004950, numObservations: 1
action: 2
Next state: 1 0.615944 0.822812 0.503186 0.878868 0.466005 0.666608 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 387
Initial state: 0 0.63288 0.84793 0.690425 0.888041 0.925534 0.84992 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2319955 episodes
GETTING ACTION FROM:
action 1, numVisits=1658163, meanQ=6.235678, numObservations: 4
action 3, numVisits=661760, meanQ=6.231081, numObservations: 5
action 0, numVisits=28, meanQ=4.783791, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 1
Next state: 1 0.63288 0.84793 0.690425 0.888041 0.925534 0.84992 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 388
Initial state: 0 0.684783 0.827351 0.602358 0.767603 0.584636 0.842606 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2277436 episodes
GETTING ACTION FROM:
action 3, numVisits=2277062, meanQ=6.140248, numObservations: 4
action 2, numVisits=284, meanQ=5.679213, numObservations: 5
action 0, numVisits=49, meanQ=5.020379, numObservations: 1
action 1, numVisits=39, meanQ=4.887179, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.684783 0.827351 0.602358 0.767603 0.584636 0.842606 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 389
Initial state: 0 0.678204 0.858369 0.776299 0.549061 0.513175 0.896804 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2331342 episodes
GETTING ACTION FROM:
action 2, numVisits=2331321, meanQ=6.234720, numObservations: 4
action 3, numVisits=11, meanQ=2.627273, numObservations: 3
action 1, numVisits=6, meanQ=0.831667, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.678204 0.858369 0.776299 0.549061 0.513175 0.896804 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 390
Initial state: 0 0.556154 0.867076 0.657052 0.476917 0.625904 0.808429 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2292111 episodes
GETTING ACTION FROM:
action 3, numVisits=2291643, meanQ=6.230756, numObservations: 5
action 2, numVisits=396, meanQ=5.815965, numObservations: 3
action 0, numVisits=44, meanQ=5.062080, numObservations: 1
action -1, numVisits=27, meanQ=4.675774, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.556154 0.867076 0.657052 0.476917 0.625904 0.808429 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 391
Initial state: 0 0.909829 0.334024 0.634988 0.866093 0.619525 0.85789 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2326296 episodes
GETTING ACTION FROM:
action 1, numVisits=2326279, meanQ=6.235857, numObservations: 4
action 2, numVisits=12, meanQ=3.983333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.909829 0.334024 0.634988 0.866093 0.619525 0.85789 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 392
Initial state: 0 0.50521 0.898428 0.237502 0.800467 0.600629 0.841348 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2302682 episodes
GETTING ACTION FROM:
action 3, numVisits=2302659, meanQ=6.231946, numObservations: 5
action 2, numVisits=18, meanQ=3.993894, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.50521 0.898428 0.237502 0.800467 0.600629 0.841348 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 393
Initial state: 0 0.57812 0.88168 0.531628 0.877034 0.296878 0.225505 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2301632 episodes
GETTING ACTION FROM:
action 1, numVisits=2301623, meanQ=6.232492, numObservations: 5
action 2, numVisits=4, meanQ=1.747500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.57812 0.88168 0.531628 0.877034 0.296878 0.225505 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 394
Initial state: 0 0.0772384 0.129047 0.552644 0.832075 0.533567 0.852799 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2294180 episodes
GETTING ACTION FROM:
action 1, numVisits=2294166, meanQ=6.234996, numObservations: 5
action 3, numVisits=6, meanQ=2.333333, numObservations: 2
action 2, numVisits=4, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.0772384 0.129047 0.552644 0.832075 0.533567 0.852799 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=274595, meanQ=8.877285, numObservations: 4
action 2, numVisits=41785, meanQ=8.855197, numObservations: 4
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2865215 episodes
GETTING ACTION FROM:
action 3, numVisits=2987311, meanQ=6.899360, numObservations: 4
action 2, numVisits=194283, meanQ=6.886183, numObservations: 4
action 1, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.0772384 0.129047 0.552644 0.832075 0.533567 0.852799 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 395
Initial state: 0 0.699715 0.370995 0.531743 0.839797 0.628555 0.893765 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2298208 episodes
GETTING ACTION FROM:
action 1, numVisits=2298162, meanQ=6.229312, numObservations: 5
action 0, numVisits=21, meanQ=4.530025, numObservations: 1
action -1, numVisits=14, meanQ=4.032061, numObservations: 1
action 2, numVisits=7, meanQ=3.284300, numObservations: 4
action 3, numVisits=4, meanQ=1.747500, numObservations: 3
action: 1
Next state: 2 0.699715 0.370995 0.531743 0.839797 0.628555 0.893765 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 396
Initial state: 0 0.50356 0.898043 0.0266968 0.825867 0.590838 0.842924 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2296861 episodes
GETTING ACTION FROM:
action 3, numVisits=2296844, meanQ=6.234110, numObservations: 5
action 2, numVisits=11, meanQ=3.634555, numObservations: 3
action 1, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.50356 0.898043 0.0266968 0.825867 0.590838 0.842924 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 397
Initial state: 0 0.526713 0.858338 0.2445 0.879288 0.660659 0.877878 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2308455 episodes
GETTING ACTION FROM:
action 2, numVisits=2308371, meanQ=6.228691, numObservations: 5
action -1, numVisits=55, meanQ=5.195425, numObservations: 1
action 3, numVisits=23, meanQ=4.303048, numObservations: 4
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.526713 0.858338 0.2445 0.879288 0.660659 0.877878 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=57004, meanQ=8.778056, numObservations: 5
action 1, numVisits=36, meanQ=7.665836, numObservations: 3
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2879848 episodes
GETTING ACTION FROM:
action 1, numVisits=2283227, meanQ=6.605607, numObservations: 4
action 3, numVisits=653638, meanQ=6.587006, numObservations: 5
action 2, numVisits=22, meanQ=4.908191, numObservations: 4
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 1
Next state: 1 0.526713 0.858338 0.2445 0.879288 0.660659 0.877878 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 398
Initial state: 0 0.691777 0.873802 0.835364 0.201995 0.620926 0.897707 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2337710 episodes
GETTING ACTION FROM:
action 2, numVisits=2337646, meanQ=6.239876, numObservations: 4
action 0, numVisits=47, meanQ=5.119378, numObservations: 2
action 3, numVisits=11, meanQ=2.724564, numObservations: 4
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 2
Next state: 2 0.691777 0.873802 0.835364 0.201995 0.620926 0.897707 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 399
Initial state: 0 0.6188 0.324977 0.60444 0.86916 0.683127 0.842586 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2348819 episodes
GETTING ACTION FROM:
action 3, numVisits=2344449, meanQ=6.229257, numObservations: 3
action 1, numVisits=4335, meanQ=6.115582, numObservations: 4
action 0, numVisits=26, meanQ=4.650720, numObservations: 1
action 2, numVisits=7, meanQ=1.997157, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.6188 0.324977 0.60444 0.86916 0.683127 0.842586 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 400
Initial state: 0 0.953916 0.0864203 0.596097 0.890154 0.697176 0.863221 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2335748 episodes
GETTING ACTION FROM:
action 2, numVisits=2335688, meanQ=6.238187, numObservations: 4
action 0, numVisits=51, meanQ=5.149879, numObservations: 1
action 1, numVisits=5, meanQ=1.196020, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.953916 0.0864203 0.596097 0.890154 0.697176 0.863221 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 401
Initial state: 0 0.641928 0.880049 0.553896 0.8269 0.230417 0.933011 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2297773 episodes
GETTING ACTION FROM:
action 3, numVisits=2297759, meanQ=6.137362, numObservations: 3
action 2, numVisits=9, meanQ=0.110011, numObservations: 3
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.641928 0.880049 0.553896 0.8269 0.230417 0.933011 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 402
Initial state: 0 0.684258 0.803055 0.861673 0.868939 0.676501 0.874385 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2336136 episodes
GETTING ACTION FROM:
action 1, numVisits=2336129, meanQ=6.239743, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.684258 0.803055 0.861673 0.868939 0.676501 0.874385 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 403
Initial state: 0 0.613336 0.806545 0.631142 0.0902458 0.688269 0.821034 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2305121 episodes
GETTING ACTION FROM:
action 3, numVisits=2305057, meanQ=6.226785, numObservations: 5
action 0, numVisits=47, meanQ=5.098250, numObservations: 1
action 1, numVisits=12, meanQ=2.330858, numObservations: 3
action 2, numVisits=3, meanQ=-0.670000, numObservations: 3
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.613336 0.806545 0.631142 0.0902458 0.688269 0.821034 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 404
Initial state: 0 0.509706 0.843112 0.370515 0.929725 0.575215 0.802215 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2341584 episodes
GETTING ACTION FROM:
action 2, numVisits=2341533, meanQ=6.233306, numObservations: 4
action -1, numVisits=45, meanQ=5.088128, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 1
action: 2
Next state: 1 0.509706 0.843112 0.370515 0.929725 0.575215 0.802215 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 405
Initial state: 0 0.657014 0.888255 0.537932 0.0593381 0.632238 0.865644 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2305260 episodes
GETTING ACTION FROM:
action 3, numVisits=2305253, meanQ=6.189895, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.657014 0.888255 0.537932 0.0593381 0.632238 0.865644 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 406
Initial state: 0 0.601914 0.80259 0.516153 0.898666 0.799154 0.696601 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2324317 episodes
GETTING ACTION FROM:
action 2, numVisits=2324292, meanQ=6.238439, numObservations: 4
action 3, numVisits=16, meanQ=4.055006, numObservations: 4
action 1, numVisits=5, meanQ=1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.601914 0.80259 0.516153 0.898666 0.799154 0.696601 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 407
Initial state: 0 0.667628 0.862244 0.0954105 0.312554 0.638724 0.880534 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2327078 episodes
GETTING ACTION FROM:
action 2, numVisits=2327071, meanQ=6.188255, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-5.505000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.667628 0.862244 0.0954105 0.312554 0.638724 0.880534 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=320193, meanQ=8.868901, numObservations: 3
action 3, numVisits=80, meanQ=8.012004, numObservations: 4
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2915529 episodes
GETTING ACTION FROM:
action 1, numVisits=3234799, meanQ=6.627776, numObservations: 3
action 3, numVisits=937, meanQ=6.373373, numObservations: 4
action 2, numVisits=65, meanQ=5.494923, numObservations: 4
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.667628 0.862244 0.0954105 0.312554 0.638724 0.880534 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 408
Initial state: 0 0.545868 0.857971 0.539141 0.872925 0.444557 0.0069399 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2288838 episodes
GETTING ACTION FROM:
action 3, numVisits=2288614, meanQ=6.239760, numObservations: 4
action 2, numVisits=217, meanQ=5.592397, numObservations: 4
action 1, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.545868 0.857971 0.539141 0.872925 0.444557 0.0069399 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=314481, meanQ=8.876590, numObservations: 3
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2918010 episodes
GETTING ACTION FROM:
action 1, numVisits=3232485, meanQ=6.678662, numObservations: 3
action 3, numVisits=5, meanQ=3.198000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 1
Next state: 1 0.545868 0.857971 0.539141 0.872925 0.444557 0.0069399 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 409
Initial state: 0 0.541671 0.876483 0.157446 0.052465 0.663193 0.814271 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2346533 episodes
GETTING ACTION FROM:
action 3, numVisits=2345355, meanQ=6.243497, numObservations: 3
action 2, numVisits=1169, meanQ=6.020821, numObservations: 3
action 1, numVisits=5, meanQ=1.396000, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.541671 0.876483 0.157446 0.052465 0.663193 0.814271 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 410
Initial state: 0 0.670335 0.8994 0.859505 0.928377 0.609626 0.872894 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2350806 episodes
GETTING ACTION FROM:
action 1, numVisits=2350712, meanQ=6.181583, numObservations: 3
action -1, numVisits=79, meanQ=5.324466, numObservations: 1
action 2, numVisits=11, meanQ=3.725455, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.670335 0.8994 0.859505 0.928377 0.609626 0.872894 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 411
Initial state: 0 0.462412 0.343859 0.684667 0.875734 0.598333 0.848449 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2340180 episodes
GETTING ACTION FROM:
action 2, numVisits=2340080, meanQ=6.313784, numObservations: 4
action 0, numVisits=58, meanQ=5.277723, numObservations: 1
action -1, numVisits=34, meanQ=4.941256, numObservations: 1
action 3, numVisits=6, meanQ=2.331683, numObservations: 2
action 1, numVisits=2, meanQ=-0.010000, numObservations: 2
action: 2
Next state: 1 0.462412 0.343859 0.684667 0.875734 0.598333 0.848449 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 412
Initial state: 0 0.526938 0.818428 0.751302 0.437579 0.50984 0.887905 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2352205 episodes
GETTING ACTION FROM:
action 1, numVisits=2352165, meanQ=6.229936, numObservations: 3
action -1, numVisits=18, meanQ=4.365804, numObservations: 1
action 3, numVisits=18, meanQ=4.053350, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.526938 0.818428 0.751302 0.437579 0.50984 0.887905 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 413
Initial state: 0 0.659104 0.844934 0.0528698 0.873088 0.572709 0.837936 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2312480 episodes
GETTING ACTION FROM:
action 2, numVisits=2312425, meanQ=6.239891, numObservations: 5
action 0, numVisits=31, meanQ=4.828250, numObservations: 1
action 3, numVisits=21, meanQ=4.450000, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.659104 0.844934 0.0528698 0.873088 0.572709 0.837936 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=47622, meanQ=8.711989, numObservations: 5
action 3, numVisits=10489, meanQ=8.695253, numObservations: 4
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2857451 episodes
GETTING ACTION FROM:
action 1, numVisits=2781783, meanQ=6.645758, numObservations: 5
action 3, numVisits=133773, meanQ=6.628923, numObservations: 4
action 2, numVisits=5, meanQ=3.198000, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 1
Next state: 1 0.659104 0.844934 0.0528698 0.873088 0.572709 0.837936 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 414
Initial state: 0 0.560556 0.826398 0.510748 0.88045 0.0523573 0.44358 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2302446 episodes
GETTING ACTION FROM:
action 3, numVisits=2302424, meanQ=6.241001, numObservations: 5
action 0, numVisits=17, meanQ=4.311260, numObservations: 1
action 1, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.560556 0.826398 0.510748 0.88045 0.0523573 0.44358 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=249772, meanQ=8.939348, numObservations: 3
action 1, numVisits=5, meanQ=4.998020, numObservations: 2
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2861559 episodes
GETTING ACTION FROM:
action 2, numVisits=3111321, meanQ=6.900090, numObservations: 5
action 1, numVisits=11, meanQ=3.544555, numObservations: 2
action 3, numVisits=5, meanQ=3.198000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.560556 0.826398 0.510748 0.88045 0.0523573 0.44358 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 415
Initial state: 0 0.682477 0.878067 0.137052 0.842457 0.677903 0.852851 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2339441 episodes
GETTING ACTION FROM:
action 1, numVisits=2333778, meanQ=6.230793, numObservations: 3
action 2, numVisits=5657, meanQ=6.119091, numObservations: 4
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 1
Next state: 1 0.682477 0.878067 0.137052 0.842457 0.677903 0.852851 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 416
Initial state: 0 0.57193 0.898659 0.176411 0.559025 0.549295 0.849769 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2321853 episodes
GETTING ACTION FROM:
action 2, numVisits=2321750, meanQ=6.235557, numObservations: 5
action -1, numVisits=42, meanQ=5.049152, numObservations: 1
action 0, numVisits=34, meanQ=4.886968, numObservations: 1
action 3, numVisits=17, meanQ=4.287071, numObservations: 3
action 1, numVisits=10, meanQ=3.198000, numObservations: 4
action: 2
Next state: 0 0.57193 0.898659 0.176411 0.559025 0.549295 0.849769 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=318818, meanQ=8.874742, numObservations: 4
action 1, numVisits=5, meanQ=4.998020, numObservations: 2
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2879097 episodes
GETTING ACTION FROM:
action 3, numVisits=3197907, meanQ=6.520104, numObservations: 4
action 2, numVisits=6, meanQ=2.331683, numObservations: 2
action 1, numVisits=6, meanQ=2.331683, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 3
Next state: 1 0.57193 0.898659 0.176411 0.559025 0.549295 0.849769 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 417
Initial state: 0 0.767449 0.843701 0.633611 0.833535 0.687779 0.87669 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2317730 episodes
GETTING ACTION FROM:
action 1, numVisits=2317696, meanQ=6.324742, numObservations: 5
action 0, numVisits=28, meanQ=4.876708, numObservations: 1
action 2, numVisits=3, meanQ=-0.670000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.767449 0.843701 0.633611 0.833535 0.687779 0.87669 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 418
Initial state: 0 0.139423 0.584788 0.500637 0.805824 0.619584 0.824576 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2323957 episodes
GETTING ACTION FROM:
action 1, numVisits=2323843, meanQ=6.231438, numObservations: 4
action 0, numVisits=63, meanQ=5.268733, numObservations: 1
action -1, numVisits=38, meanQ=4.931729, numObservations: 1
action 3, numVisits=8, meanQ=2.873750, numObservations: 2
action 2, numVisits=5, meanQ=0.998020, numObservations: 2
action: 1
Next state: 0 0.139423 0.584788 0.500637 0.805824 0.619584 0.824576 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=319611, meanQ=8.855545, numObservations: 5
action 2, numVisits=58356, meanQ=8.838395, numObservations: 5
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2826209 episodes
GETTING ACTION FROM:
action 3, numVisits=1891492, meanQ=6.718322, numObservations: 5
action 2, numVisits=1312652, meanQ=6.717163, numObservations: 5
action 1, numVisits=31, meanQ=4.834203, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 3
Next state: 0 0.139423 0.584788 0.500637 0.805824 0.619584 0.824576 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=22382, meanQ=8.692061, numObservations: 5
action 3, numVisits=3336, meanQ=8.620530, numObservations: 3
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2874421 episodes
GETTING ACTION FROM:
action 2, numVisits=2878849, meanQ=6.512550, numObservations: 5
action 3, numVisits=19153, meanQ=6.461024, numObservations: 3
action 1, numVisits=2136, meanQ=6.346980, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 2
Next state: 0 0.139423 0.584788 0.500637 0.805824 0.619584 0.824576 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=2743, meanQ=8.802720, numObservations: 3
action 3, numVisits=42, meanQ=7.879767, numObservations: 3
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2907702 episodes
GETTING ACTION FROM:
action 2, numVisits=2909944, meanQ=6.539059, numObservations: 4
action 3, numVisits=515, meanQ=6.190195, numObservations: 4
action 1, numVisits=27, meanQ=4.962593, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 2
Next state: 1 0.139423 0.584788 0.500637 0.805824 0.619584 0.824576 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 5.76259
Run # 419
Initial state: 0 0.611137 0.852581 0.567451 0.855896 0.169542 0.417114 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2330487 episodes
GETTING ACTION FROM:
action 2, numVisits=2330452, meanQ=6.222835, numObservations: 4
action 1, numVisits=29, meanQ=3.550352, numObservations: 3
action 3, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.611137 0.852581 0.567451 0.855896 0.169542 0.417114 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 420
Initial state: 0 0.742758 0.636263 0.553345 0.855306 0.521046 0.805094 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2305126 episodes
GETTING ACTION FROM:
action 3, numVisits=2305043, meanQ=6.234411, numObservations: 5
action 0, numVisits=30, meanQ=4.792301, numObservations: 1
action 1, numVisits=30, meanQ=4.626340, numObservations: 3
action -1, numVisits=18, meanQ=4.360336, numObservations: 1
action 2, numVisits=5, meanQ=1.000000, numObservations: 2
action: 3
Next state: 1 0.742758 0.636263 0.553345 0.855306 0.521046 0.805094 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 421
Initial state: 0 0.594777 0.830488 0.545403 0.863271 0.12941 0.635987 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2307942 episodes
GETTING ACTION FROM:
action 3, numVisits=2307888, meanQ=6.239554, numObservations: 5
action 0, numVisits=50, meanQ=5.143738, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.594777 0.830488 0.545403 0.863271 0.12941 0.635987 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=250070, meanQ=8.940496, numObservations: 3
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2884771 episodes
GETTING ACTION FROM:
action 2, numVisits=3134589, meanQ=6.620098, numObservations: 4
action 1, numVisits=236, meanQ=6.113816, numObservations: 4
action 3, numVisits=16, meanQ=4.123750, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 2
Next state: 1 0.594777 0.830488 0.545403 0.863271 0.12941 0.635987 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 422
Initial state: 0 0.755715 0.65685 0.582848 0.842302 0.667333 0.802084 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2341549 episodes
GETTING ACTION FROM:
action 2, numVisits=2341513, meanQ=6.232118, numObservations: 4
action -1, numVisits=19, meanQ=4.437065, numObservations: 1
action 1, numVisits=13, meanQ=2.228469, numObservations: 3
action 3, numVisits=2, meanQ=-5.505000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.755715 0.65685 0.582848 0.842302 0.667333 0.802084 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 423
Initial state: 0 0.506401 0.897803 0.518509 0.880461 0.104834 0.0589226 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2300444 episodes
GETTING ACTION FROM:
action 3, numVisits=2300376, meanQ=6.228773, numObservations: 4
action 0, numVisits=58, meanQ=5.219630, numObservations: 1
action 1, numVisits=5, meanQ=1.000000, numObservations: 2
action 2, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.506401 0.897803 0.518509 0.880461 0.104834 0.0589226 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=228943, meanQ=8.885902, numObservations: 5
action 1, numVisits=87810, meanQ=8.876008, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2826938 episodes
GETTING ACTION FROM:
action 1, numVisits=1965613, meanQ=6.803629, numObservations: 4
action 2, numVisits=1178078, meanQ=6.802005, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.506401 0.897803 0.518509 0.880461 0.104834 0.0589226 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 424
Initial state: 0 0.593564 0.207244 0.624132 0.817872 0.629122 0.844851 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2351133 episodes
GETTING ACTION FROM:
action 2, numVisits=2351126, meanQ=6.190386, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.593564 0.207244 0.624132 0.817872 0.629122 0.844851 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 425
Initial state: 0 0.666077 0.821165 0.530663 0.223085 0.650129 0.86512 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2309927 episodes
GETTING ACTION FROM:
action 2, numVisits=2271423, meanQ=6.238745, numObservations: 5
action 3, numVisits=38429, meanQ=6.193893, numObservations: 4
action 0, numVisits=42, meanQ=5.035623, numObservations: 1
action -1, numVisits=31, meanQ=4.796289, numObservations: 1
action 1, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 2
Next state: 2 0.666077 0.821165 0.530663 0.223085 0.650129 0.86512 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 426
Initial state: 0 0.932596 0.579128 0.668112 0.809873 0.682324 0.892386 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2338596 episodes
GETTING ACTION FROM:
action 1, numVisits=2338590, meanQ=6.218777, numObservations: 3
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.932596 0.579128 0.668112 0.809873 0.682324 0.892386 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 427
Initial state: 0 0.572122 0.857804 0.693574 0.869492 0.755414 0.718526 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2321953 episodes
GETTING ACTION FROM:
action 1, numVisits=2321878, meanQ=6.247314, numObservations: 4
action 0, numVisits=34, meanQ=4.919805, numObservations: 1
action -1, numVisits=34, meanQ=4.919614, numObservations: 1
action 2, numVisits=6, meanQ=0.995017, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.572122 0.857804 0.693574 0.869492 0.755414 0.718526 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 428
Initial state: 0 0.448785 0.40478 0.627467 0.84903 0.640634 0.83726 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2293408 episodes
GETTING ACTION FROM:
action 2, numVisits=2293354, meanQ=6.235751, numObservations: 5
action 1, numVisits=37, meanQ=4.704868, numObservations: 5
action 3, numVisits=13, meanQ=2.998462, numObservations: 3
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.448785 0.40478 0.627467 0.84903 0.640634 0.83726 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 429
Initial state: 0 0.546795 0.816421 0.659722 0.884624 0.637269 0.170059 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2307566 episodes
GETTING ACTION FROM:
action 2, numVisits=2307488, meanQ=6.322837, numObservations: 5
action 0, numVisits=65, meanQ=5.374203, numObservations: 1
action 3, numVisits=7, meanQ=1.997157, numObservations: 3
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.546795 0.816421 0.659722 0.884624 0.637269 0.170059 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 430
Initial state: 0 0.51747 0.821944 0.566094 0.830526 0.587361 0.317312 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2332947 episodes
GETTING ACTION FROM:
action 2, numVisits=2332878, meanQ=6.181549, numObservations: 4
action 0, numVisits=39, meanQ=4.942219, numObservations: 1
action -1, numVisits=27, meanQ=4.652115, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.51747 0.821944 0.566094 0.830526 0.587361 0.317312 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=106575, meanQ=5.425266, numObservations: 4
action -1, numVisits=21, meanQ=3.848903, numObservations: 1
action 1, numVisits=6, meanQ=0.831667, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2647383 episodes
GETTING ACTION FROM:
action 2, numVisits=2753958, meanQ=6.034687, numObservations: 4
action -1, numVisits=21, meanQ=3.848903, numObservations: 1
action 1, numVisits=6, meanQ=0.831667, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.51747 0.821944 0.566094 0.830526 0.587361 0.317312 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 431
Initial state: 0 0.0801359 0.228105 0.656819 0.875734 0.562811 0.815297 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2322761 episodes
GETTING ACTION FROM:
action 1, numVisits=2322712, meanQ=6.232445, numObservations: 4
action -1, numVisits=44, meanQ=5.069743, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.0801359 0.228105 0.656819 0.875734 0.562811 0.815297 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=205650, meanQ=8.858502, numObservations: 5
action 3, numVisits=170647, meanQ=8.857071, numObservations: 5
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2840074 episodes
GETTING ACTION FROM:
action 3, numVisits=2413450, meanQ=6.989234, numObservations: 5
action 2, numVisits=802891, meanQ=6.985554, numObservations: 5
action 1, numVisits=31, meanQ=5.157742, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.0801359 0.228105 0.656819 0.875734 0.562811 0.815297 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 432
Initial state: 0 0.600006 0.837588 0.534389 0.874521 0.640131 0.300434 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2339153 episodes
GETTING ACTION FROM:
action 2, numVisits=2338960, meanQ=6.235141, numObservations: 4
action -1, numVisits=83, meanQ=5.388184, numObservations: 1
action 1, numVisits=67, meanQ=5.249156, numObservations: 3
action 0, numVisits=41, meanQ=5.004883, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action: 2
Next state: 1 0.600006 0.837588 0.534389 0.874521 0.640131 0.300434 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 433
Initial state: 0 0.598974 0.813155 0.550336 0.862545 0.32426 0.647897 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2342051 episodes
GETTING ACTION FROM:
action 2, numVisits=2341972, meanQ=6.229678, numObservations: 4
action 0, numVisits=26, meanQ=4.692392, numObservations: 1
action -1, numVisits=12, meanQ=3.485012, numObservations: 1
action 3, numVisits=40, meanQ=2.995000, numObservations: 5
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.598974 0.813155 0.550336 0.862545 0.32426 0.647897 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 434
Initial state: 0 0.622963 0.84369 0.553411 0.803129 0.0462573 0.636278 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2330675 episodes
GETTING ACTION FROM:
action 3, numVisits=2330625, meanQ=6.226372, numObservations: 4
action 0, numVisits=31, meanQ=4.848099, numObservations: 1
action 1, numVisits=13, meanQ=3.843846, numObservations: 3
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 3
Next state: 0 0.622963 0.84369 0.553411 0.803129 0.0462573 0.636278 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=328360, meanQ=8.858651, numObservations: 4
action 2, numVisits=49942, meanQ=8.838698, numObservations: 5
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2858920 episodes
GETTING ACTION FROM:
action 1, numVisits=2784673, meanQ=6.780864, numObservations: 4
action 2, numVisits=452548, meanQ=6.773972, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 1
Next state: 1 0.622963 0.84369 0.553411 0.803129 0.0462573 0.636278 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 435
Initial state: 0 0.45757 0.931004 0.64903 0.863865 0.572974 0.855064 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2322866 episodes
GETTING ACTION FROM:
action 3, numVisits=2322840, meanQ=6.235105, numObservations: 4
action 2, numVisits=21, meanQ=4.133814, numObservations: 3
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.45757 0.931004 0.64903 0.863865 0.572974 0.855064 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=103570, meanQ=6.528101, numObservations: 4
action 3, numVisits=8, meanQ=4.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2893127 episodes
GETTING ACTION FROM:
action 1, numVisits=2996694, meanQ=6.508075, numObservations: 4
action 3, numVisits=9, meanQ=3.554444, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.45757 0.931004 0.64903 0.863865 0.572974 0.855064 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=25718, meanQ=8.027267, numObservations: 3
action 3, numVisits=2421, meanQ=5.653539, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2921254 episodes
GETTING ACTION FROM:
action 1, numVisits=2946970, meanQ=6.685036, numObservations: 4
action 3, numVisits=2421, meanQ=5.653539, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.45757 0.931004 0.64903 0.863865 0.572974 0.855064 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=2715, meanQ=8.699787, numObservations: 3
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2962063 episodes
GETTING ACTION FROM:
action 2, numVisits=2959263, meanQ=6.677432, numObservations: 3
action 1, numVisits=5514, meanQ=6.575660, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 2
Next state: 1 0.45757 0.931004 0.64903 0.863865 0.572974 0.855064 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 5.76259
Run # 436
Initial state: 0 0.553284 0.811192 0.56405 0.83243 0.164764 0.837267 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2325987 episodes
GETTING ACTION FROM:
action 2, numVisits=2120078, meanQ=6.233720, numObservations: 4
action 1, numVisits=205863, meanQ=6.218357, numObservations: 3
action -1, numVisits=43, meanQ=5.021129, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.553284 0.811192 0.56405 0.83243 0.164764 0.837267 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 437
Initial state: 0 0.616268 0.801827 0.695556 0.826292 0.933973 0.375755 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2348753 episodes
GETTING ACTION FROM:
action 2, numVisits=2348746, meanQ=6.223285, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.616268 0.801827 0.695556 0.826292 0.933973 0.375755 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 438
Initial state: 0 0.594872 0.150403 0.512641 0.811358 0.606209 0.880258 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2352007 episodes
GETTING ACTION FROM:
action 3, numVisits=2351765, meanQ=6.186177, numObservations: 3
action 1, numVisits=219, meanQ=5.654500, numObservations: 3
action 2, numVisits=19, meanQ=4.366847, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.594872 0.150403 0.512641 0.811358 0.606209 0.880258 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 439
Initial state: 0 0.779938 0.272527 0.527188 0.843564 0.625865 0.847443 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2345785 episodes
GETTING ACTION FROM:
action 3, numVisits=2345769, meanQ=6.235398, numObservations: 3
action 2, numVisits=9, meanQ=3.554444, numObservations: 1
action 1, numVisits=3, meanQ=-0.670000, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.779938 0.272527 0.527188 0.843564 0.625865 0.847443 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 440
Initial state: 0 0.590421 0.835116 0.623606 0.898258 0.952639 0.507649 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2309041 episodes
GETTING ACTION FROM:
action 2, numVisits=2306915, meanQ=6.230153, numObservations: 5
action 1, numVisits=2092, meanQ=6.064715, numObservations: 5
action -1, numVisits=20, meanQ=4.402703, numObservations: 1
action 3, numVisits=12, meanQ=2.241675, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.590421 0.835116 0.623606 0.898258 0.952639 0.507649 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 441
Initial state: 0 0.539705 0.825211 0.662946 0.845352 0.81555 0.00669323 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2328109 episodes
GETTING ACTION FROM:
action 1, numVisits=134267, meanQ=6.241318, numObservations: 4
action 2, numVisits=2193826, meanQ=6.231046, numObservations: 4
action -1, numVisits=10, meanQ=3.798191, numObservations: 1
action 3, numVisits=4, meanQ=1.747500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.539705 0.825211 0.662946 0.845352 0.81555 0.00669323 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 442
Initial state: 0 0.61072 0.875617 0.622956 0.871408 0.206994 0.919389 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2289468 episodes
GETTING ACTION FROM:
action 3, numVisits=2289424, meanQ=6.229985, numObservations: 5
action 0, numVisits=39, meanQ=4.980601, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.61072 0.875617 0.622956 0.871408 0.206994 0.919389 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=84283, meanQ=6.097359, numObservations: 5
action 1, numVisits=79, meanQ=5.304813, numObservations: 3
action 3, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2845258 episodes
GETTING ACTION FROM:
action 2, numVisits=2929539, meanQ=6.464692, numObservations: 5
action 1, numVisits=79, meanQ=5.304813, numObservations: 3
action 3, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 2
Next state: 1 0.61072 0.875617 0.622956 0.871408 0.206994 0.919389 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 443
Initial state: 0 0.515636 0.822217 0.0351017 0.375356 0.528124 0.807097 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2351895 episodes
GETTING ACTION FROM:
action 2, numVisits=2351886, meanQ=6.181677, numObservations: 4
action 3, numVisits=2, meanQ=-0.010000, numObservations: 2
action 1, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.515636 0.822217 0.0351017 0.375356 0.528124 0.807097 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=110207, meanQ=8.692965, numObservations: 3
action 3, numVisits=16843, meanQ=8.655609, numObservations: 4
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2888816 episodes
GETTING ACTION FROM:
action 3, numVisits=2391157, meanQ=6.843057, numObservations: 4
action 1, numVisits=624677, meanQ=6.838131, numObservations: 3
action 2, numVisits=33, meanQ=5.390606, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.515636 0.822217 0.0351017 0.375356 0.528124 0.807097 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 444
Initial state: 0 0.368381 0.914958 0.599188 0.861025 0.686244 0.830831 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2322252 episodes
GETTING ACTION FROM:
action 3, numVisits=2322175, meanQ=6.241385, numObservations: 4
action 0, numVisits=38, meanQ=4.998748, numObservations: 1
action -1, numVisits=25, meanQ=4.710428, numObservations: 1
action 2, numVisits=11, meanQ=2.807273, numObservations: 4
action 1, numVisits=3, meanQ=-0.670000, numObservations: 2
action: 3
Next state: 1 0.368381 0.914958 0.599188 0.861025 0.686244 0.830831 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 445
Initial state: 0 0.507779 0.966569 0.608259 0.886521 0.65721 0.820565 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2347464 episodes
GETTING ACTION FROM:
action 2, numVisits=2347381, meanQ=6.226574, numObservations: 3
action -1, numVisits=41, meanQ=5.021873, numObservations: 1
action 0, numVisits=28, meanQ=4.768615, numObservations: 1
action 1, numVisits=10, meanQ=3.198000, numObservations: 3
action 3, numVisits=4, meanQ=-0.505000, numObservations: 2
action: 2
Next state: 1 0.507779 0.966569 0.608259 0.886521 0.65721 0.820565 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 446
Initial state: 0 0.565219 0.8321 0.584387 0.859047 0.157376 0.0570418 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2297393 episodes
GETTING ACTION FROM:
action 1, numVisits=2297381, meanQ=6.228946, numObservations: 5
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action 3, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 1
Next state: 0 0.565219 0.8321 0.584387 0.859047 0.157376 0.0570418 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=11938, meanQ=6.353988, numObservations: 5
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2861012 episodes
GETTING ACTION FROM:
action 2, numVisits=2872947, meanQ=6.405594, numObservations: 5
action 3, numVisits=2, meanQ=-0.010000, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 2
Next state: 1 0.565219 0.8321 0.584387 0.859047 0.157376 0.0570418 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 447
Initial state: 0 0.691953 0.87924 0.612951 0.838721 0.669598 0.395651 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2314865 episodes
GETTING ACTION FROM:
action 3, numVisits=2292046, meanQ=6.314963, numObservations: 5
action 1, numVisits=22814, meanQ=6.184426, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.691953 0.87924 0.612951 0.838721 0.669598 0.395651 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 448
Initial state: 0 0.0586794 0.794939 0.680026 0.833451 0.631131 0.897782 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2314564 episodes
GETTING ACTION FROM:
action 2, numVisits=2314508, meanQ=6.233839, numObservations: 5
action 1, numVisits=35, meanQ=4.742006, numObservations: 4
action 0, numVisits=17, meanQ=4.341922, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.0586794 0.794939 0.680026 0.833451 0.631131 0.897782 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 449
Initial state: 0 0.941429 0.614648 0.541083 0.868029 0.53539 0.83354 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2324246 episodes
GETTING ACTION FROM:
action 1, numVisits=2324216, meanQ=6.241568, numObservations: 4
action 3, numVisits=25, meanQ=4.544004, numObservations: 4
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.941429 0.614648 0.541083 0.868029 0.53539 0.83354 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=317967, meanQ=8.886196, numObservations: 5
action 3, numVisits=56, meanQ=7.927864, numObservations: 4
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2857576 episodes
GETTING ACTION FROM:
action 2, numVisits=3175180, meanQ=6.823669, numObservations: 5
action 3, numVisits=416, meanQ=6.424665, numObservations: 5
action 1, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.941429 0.614648 0.541083 0.868029 0.53539 0.83354 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 450
Initial state: 0 0.65648 0.887957 0.404484 0.850544 0.540614 0.882058 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2310182 episodes
GETTING ACTION FROM:
action 2, numVisits=2304011, meanQ=6.316862, numObservations: 5
action 3, numVisits=3996, meanQ=6.188394, numObservations: 4
action 1, numVisits=2159, meanQ=6.152873, numObservations: 4
action -1, numVisits=14, meanQ=4.112513, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.65648 0.887957 0.404484 0.850544 0.540614 0.882058 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 451
Initial state: 0 0.597268 0.969956 0.546844 0.857562 0.609593 0.814607 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2320780 episodes
GETTING ACTION FROM:
action 2, numVisits=2320760, meanQ=6.232360, numObservations: 5
action -1, numVisits=15, meanQ=4.229565, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.597268 0.969956 0.546844 0.857562 0.609593 0.814607 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 452
Initial state: 0 0.605693 0.862675 0.620701 0.829238 0.459401 0.132226 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2295639 episodes
GETTING ACTION FROM:
action 2, numVisits=2295561, meanQ=6.232237, numObservations: 5
action 0, numVisits=57, meanQ=5.223037, numObservations: 1
action -1, numVisits=18, meanQ=4.387520, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.605693 0.862675 0.620701 0.829238 0.459401 0.132226 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 453
Initial state: 0 0.591224 0.100885 0.53266 0.874065 0.657662 0.833985 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2330729 episodes
GETTING ACTION FROM:
action 1, numVisits=2330672, meanQ=6.233183, numObservations: 4
action 0, numVisits=33, meanQ=4.895111, numObservations: 1
action 3, numVisits=10, meanQ=3.198000, numObservations: 3
action 2, numVisits=12, meanQ=3.082517, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.591224 0.100885 0.53266 0.874065 0.657662 0.833985 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 454
Initial state: 0 0.512073 0.868862 0.390561 0.517815 0.527135 0.847313 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2311694 episodes
GETTING ACTION FROM:
action 1, numVisits=2258545, meanQ=6.225961, numObservations: 4
action 2, numVisits=44136, meanQ=6.185589, numObservations: 5
action 3, numVisits=8919, meanQ=6.143446, numObservations: 4
action 0, numVisits=78, meanQ=5.348414, numObservations: 1
action -1, numVisits=16, meanQ=4.316851, numObservations: 1
action: 1
Next state: 1 0.512073 0.868862 0.390561 0.517815 0.527135 0.847313 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 455
Initial state: 0 0.577261 0.88108 0.632915 0.842091 0.659198 0.891562 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2295373 episodes
GETTING ACTION FROM:
action 1, numVisits=2295151, meanQ=6.234166, numObservations: 5
action -1, numVisits=116, meanQ=5.526128, numObservations: 1
action 2, numVisits=65, meanQ=4.932466, numObservations: 4
action 0, numVisits=30, meanQ=4.738618, numObservations: 1
action 3, numVisits=11, meanQ=2.726364, numObservations: 3
action: 1
Next state: 1 0.577261 0.88108 0.632915 0.842091 0.659198 0.891562 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 456
Initial state: 0 0.752349 0.0859313 0.546591 0.831539 0.651849 0.897592 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2313208 episodes
GETTING ACTION FROM:
action 3, numVisits=2312715, meanQ=6.230935, numObservations: 4
action 1, numVisits=448, meanQ=5.792536, numObservations: 4
action 2, numVisits=41, meanQ=5.034634, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.752349 0.0859313 0.546591 0.831539 0.651849 0.897592 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 457
Initial state: 0 0.562527 0.852691 0.379798 0.776149 0.596723 0.824098 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2328533 episodes
GETTING ACTION FROM:
action 3, numVisits=2328478, meanQ=6.228160, numObservations: 4
action -1, numVisits=19, meanQ=4.333426, numObservations: 1
action 1, numVisits=32, meanQ=2.860941, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.562527 0.852691 0.379798 0.776149 0.596723 0.824098 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 458
Initial state: 0 0.594016 0.841643 0.689233 0.587 0.656792 0.868266 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2354886 episodes
GETTING ACTION FROM:
action 1, numVisits=2354794, meanQ=6.234136, numObservations: 3
action -1, numVisits=36, meanQ=4.929783, numObservations: 1
action 0, numVisits=21, meanQ=4.519629, numObservations: 1
action 2, numVisits=33, meanQ=4.442124, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action: 1
Next state: 1 0.594016 0.841643 0.689233 0.587 0.656792 0.868266 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 459
Initial state: 0 0.558426 0.808027 0.899851 0.347306 0.508317 0.895538 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2333350 episodes
GETTING ACTION FROM:
action 2, numVisits=2333301, meanQ=6.187637, numObservations: 4
action 0, numVisits=40, meanQ=4.978773, numObservations: 1
action 1, numVisits=4, meanQ=1.747500, numObservations: 2
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.558426 0.808027 0.899851 0.347306 0.508317 0.895538 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 460
Initial state: 0 0.692556 0.804864 0.694002 0.605873 0.699354 0.875633 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2329403 episodes
GETTING ACTION FROM:
action 1, numVisits=1574930, meanQ=6.313723, numObservations: 4
action 3, numVisits=753700, meanQ=6.227433, numObservations: 4
action 2, numVisits=757, meanQ=5.956689, numObservations: 4
action -1, numVisits=14, meanQ=4.136684, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.692556 0.804864 0.694002 0.605873 0.699354 0.875633 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=63001, meanQ=7.886965, numObservations: 4
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2622752 episodes
GETTING ACTION FROM:
action 1, numVisits=2685748, meanQ=6.269135, numObservations: 4
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 1
Next state: 1 0.692556 0.804864 0.694002 0.605873 0.699354 0.875633 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 461
Initial state: 0 0.821138 0.83278 0.518658 0.884653 0.699251 0.878302 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2316370 episodes
GETTING ACTION FROM:
action 3, numVisits=2316360, meanQ=6.233919, numObservations: 4
action 2, numVisits=5, meanQ=1.396000, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.821138 0.83278 0.518658 0.884653 0.699251 0.878302 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 462
Initial state: 0 0.591965 0.809529 0.671264 0.894453 0.616475 0.5387 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2338314 episodes
GETTING ACTION FROM:
action 2, numVisits=2336566, meanQ=6.223929, numObservations: 4
action 3, numVisits=1743, meanQ=5.701714, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.591965 0.809529 0.671264 0.894453 0.616475 0.5387 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 463
Initial state: 0 0.575916 0.878549 0.196011 0.75945 0.522996 0.807805 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2304825 episodes
GETTING ACTION FROM:
action 1, numVisits=2304486, meanQ=6.236623, numObservations: 5
action 2, numVisits=181, meanQ=5.661934, numObservations: 4
action 0, numVisits=128, meanQ=5.559223, numObservations: 1
action -1, numVisits=29, meanQ=4.794914, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.575916 0.878549 0.196011 0.75945 0.522996 0.807805 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 464
Initial state: 0 0.610147 0.802306 0.721794 0.931169 0.558212 0.847072 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2366931 episodes
GETTING ACTION FROM:
action 2, numVisits=2366925, meanQ=6.228701, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.610147 0.802306 0.721794 0.931169 0.558212 0.847072 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 465
Initial state: 0 0.676603 0.831831 0.558819 0.805796 0.931342 0.887511 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2281851 episodes
GETTING ACTION FROM:
action 1, numVisits=2281780, meanQ=6.139096, numObservations: 4
action 0, numVisits=23, meanQ=4.432337, numObservations: 1
action -1, numVisits=21, meanQ=4.394295, numObservations: 1
action 2, numVisits=22, meanQ=2.627273, numObservations: 3
action 3, numVisits=5, meanQ=1.396000, numObservations: 3
action: 1
Next state: 1 0.676603 0.831831 0.558819 0.805796 0.931342 0.887511 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 466
Initial state: 0 0.665253 0.83223 0.653982 0.822486 0.707945 0.0341198 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2322020 episodes
GETTING ACTION FROM:
action 1, numVisits=2322012, meanQ=6.236236, numObservations: 4
action 2, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.665253 0.83223 0.653982 0.822486 0.707945 0.0341198 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 467
Initial state: 0 0.537969 0.744771 0.571474 0.845595 0.59569 0.888303 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2306770 episodes
GETTING ACTION FROM:
action 2, numVisits=2306745, meanQ=6.235236, numObservations: 5
action 1, numVisits=14, meanQ=3.427143, numObservations: 4
action 3, numVisits=7, meanQ=3.284300, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.537969 0.744771 0.571474 0.845595 0.59569 0.888303 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 468
Initial state: 0 0.606598 0.805676 0.597639 0.890652 0.747685 0.441763 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2324870 episodes
GETTING ACTION FROM:
action 1, numVisits=2324748, meanQ=6.238944, numObservations: 4
action 2, numVisits=46, meanQ=5.079789, numObservations: 3
action -1, numVisits=35, meanQ=4.939607, numObservations: 1
action 0, numVisits=31, meanQ=4.824195, numObservations: 1
action 3, numVisits=10, meanQ=2.099000, numObservations: 4
action: 1
Next state: 1 0.606598 0.805676 0.597639 0.890652 0.747685 0.441763 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 469
Initial state: 0 0.667346 0.877004 0.595317 0.811525 0.637857 0.768512 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2325813 episodes
GETTING ACTION FROM:
action 1, numVisits=2325432, meanQ=6.235193, numObservations: 4
action 3, numVisits=324, meanQ=5.807964, numObservations: 4
action 2, numVisits=53, meanQ=5.181323, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.667346 0.877004 0.595317 0.811525 0.637857 0.768512 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 470
Initial state: 0 0.524203 0.894827 0.575813 0.885107 0.69538 0.440008 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2326042 episodes
GETTING ACTION FROM:
action 1, numVisits=2325962, meanQ=6.236593, numObservations: 4
action 0, numVisits=18, meanQ=4.398108, numObservations: 1
action -1, numVisits=17, meanQ=4.279974, numObservations: 1
action 3, numVisits=43, meanQ=4.217442, numObservations: 4
action 2, numVisits=2, meanQ=-0.010000, numObservations: 2
action: 1
Next state: 1 0.524203 0.894827 0.575813 0.885107 0.69538 0.440008 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 471
Initial state: 0 0.67387 0.804494 0.636921 0.88634 0.847273 0.575292 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2339916 episodes
GETTING ACTION FROM:
action 2, numVisits=2339867, meanQ=6.234794, numObservations: 4
action -1, numVisits=30, meanQ=4.833003, numObservations: 1
action 1, numVisits=14, meanQ=3.285714, numObservations: 3
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.67387 0.804494 0.636921 0.88634 0.847273 0.575292 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 472
Initial state: 0 0.578414 0.812188 0.368365 0.289759 0.690056 0.883261 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1789706 episodes
GETTING ACTION FROM:
action 0, numVisits=1277545, meanQ=6.403666, numObservations: 3
action 2, numVisits=512115, meanQ=6.231458, numObservations: 4
action 3, numVisits=42, meanQ=3.944771, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 0
Next state: 0 0.578414 0.812188 0.368365 0.289759 0.690056 0.883261 w: 1
Observation: 0 0 0.906258 0 0.255635 0 0.83505 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=392739, meanQ=8.608251, numObservations: 3
action 1, numVisits=7, meanQ=4.855714, numObservations: 3
action 2, numVisits=7, meanQ=3.425729, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2565871 episodes
GETTING ACTION FROM:
action 3, numVisits=2956876, meanQ=6.619580, numObservations: 3
action 1, numVisits=1681, meanQ=6.434581, numObservations: 4
action 0, numVisits=37, meanQ=5.310324, numObservations: 1
action -1, numVisits=25, meanQ=4.997462, numObservations: 1
action 2, numVisits=7, meanQ=3.425729, numObservations: 2
action: 3
Next state: 1 0.578414 0.812188 0.368365 0.289759 0.690056 0.883261 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 473
Initial state: 0 0.410537 0.523175 0.535961 0.82016 0.574471 0.818457 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2324834 episodes
GETTING ACTION FROM:
action 1, numVisits=2324739, meanQ=6.229721, numObservations: 4
action 2, numVisits=90, meanQ=5.148004, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.410537 0.523175 0.535961 0.82016 0.574471 0.818457 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=94785, meanQ=8.876634, numObservations: 4
action 3, numVisits=224870, meanQ=8.874081, numObservations: 4
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2853074 episodes
GETTING ACTION FROM:
action 3, numVisits=2241012, meanQ=6.739638, numObservations: 4
action 2, numVisits=931713, meanQ=6.736790, numObservations: 4
action 1, numVisits=5, meanQ=3.198000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.410537 0.523175 0.535961 0.82016 0.574471 0.818457 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 474
Initial state: 0 0.680782 0.844375 0.665316 0.802362 0.302457 0.946229 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2327076 episodes
GETTING ACTION FROM:
action 1, numVisits=2326970, meanQ=6.235036, numObservations: 4
action 3, numVisits=75, meanQ=5.339068, numObservations: 3
action 2, numVisits=27, meanQ=4.514452, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.680782 0.844375 0.665316 0.802362 0.302457 0.946229 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 475
Initial state: 0 0.527196 0.86781 0.61246 0.886663 0.555934 0.188223 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2278564 episodes
GETTING ACTION FROM:
action 2, numVisits=2278393, meanQ=6.199738, numObservations: 5
action 3, numVisits=111, meanQ=5.395138, numObservations: 4
action -1, numVisits=54, meanQ=5.160100, numObservations: 1
action 1, numVisits=4, meanQ=1.475000, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 2
Next state: 1 0.527196 0.86781 0.61246 0.886663 0.555934 0.188223 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 476
Initial state: 0 0.047867 0.283183 0.58785 0.841637 0.59442 0.854279 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2282562 episodes
GETTING ACTION FROM:
action 1, numVisits=2282552, meanQ=6.134088, numObservations: 4
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.047867 0.283183 0.58785 0.841637 0.59442 0.854279 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=235556, meanQ=8.881951, numObservations: 4
action 2, numVisits=77172, meanQ=8.870633, numObservations: 4
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2851450 episodes
GETTING ACTION FROM:
action 3, numVisits=2592318, meanQ=6.894793, numObservations: 4
action 2, numVisits=571859, meanQ=6.889269, numObservations: 4
action 1, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.047867 0.283183 0.58785 0.841637 0.59442 0.854279 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 477
Initial state: 0 0.579134 0.815194 0.656449 0.892034 0.951589 0.186527 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2304664 episodes
GETTING ACTION FROM:
action 1, numVisits=2304508, meanQ=6.232085, numObservations: 4
action 2, numVisits=112, meanQ=5.498754, numObservations: 4
action 3, numVisits=40, meanQ=4.937753, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.579134 0.815194 0.656449 0.892034 0.951589 0.186527 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 478
Initial state: 0 0.525734 0.875648 0.293772 0.0284705 0.694444 0.88136 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1580666 episodes
GETTING ACTION FROM:
action 0, numVisits=1580654, meanQ=4.121746, numObservations: 1
action 2, numVisits=3, meanQ=-0.670000, numObservations: 3
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 0
Next state: 0 0.525734 0.875648 0.293772 0.0284705 0.694444 0.88136 w: 1
Observation: 0 0 0.834122 0 0 0 0.980705 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=1580560, meanQ=6.188974, numObservations: 4
action 0, numVisits=42, meanQ=4.966044, numObservations: 1
action 2, numVisits=47, meanQ=3.583198, numObservations: 3
action 1, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
Sampled 2524263 episodes
GETTING ACTION FROM:
action 3, numVisits=4104823, meanQ=6.233633, numObservations: 4
action 0, numVisits=42, meanQ=4.966044, numObservations: 1
action 2, numVisits=47, meanQ=3.583198, numObservations: 3
action 1, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 3
Next state: 1 0.525734 0.875648 0.293772 0.0284705 0.694444 0.88136 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 479
Initial state: 0 0.516766 0.87334 0.52573 0.854419 0.65888 0.0467244 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2323363 episodes
GETTING ACTION FROM:
action 2, numVisits=2323321, meanQ=6.220551, numObservations: 4
action 0, numVisits=25, meanQ=4.659812, numObservations: 1
action 3, numVisits=12, meanQ=3.158333, numObservations: 3
action 1, numVisits=3, meanQ=-1.033333, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 2
Next state: 1 0.516766 0.87334 0.52573 0.854419 0.65888 0.0467244 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 480
Initial state: 0 0.734847 0.155752 0.525162 0.878145 0.507038 0.84901 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2331464 episodes
GETTING ACTION FROM:
action 2, numVisits=2331298, meanQ=6.226426, numObservations: 4
action 1, numVisits=63, meanQ=5.171271, numObservations: 5
action -1, numVisits=54, meanQ=5.167106, numObservations: 1
action 3, numVisits=32, meanQ=4.583450, numObservations: 5
action 0, numVisits=17, meanQ=4.295103, numObservations: 1
action: 2
Next state: 1 0.734847 0.155752 0.525162 0.878145 0.507038 0.84901 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 481
Initial state: 0 0.625704 0.815359 0.64571 0.827432 0.00307744 0.409693 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2296885 episodes
GETTING ACTION FROM:
action 3, numVisits=2296823, meanQ=6.138693, numObservations: 3
action -1, numVisits=36, meanQ=4.860801, numObservations: 1
action 0, numVisits=17, meanQ=4.204075, numObservations: 1
action 1, numVisits=6, meanQ=2.331683, numObservations: 3
action 2, numVisits=3, meanQ=-0.670000, numObservations: 2
action: 3
Next state: 0 0.625704 0.815359 0.64571 0.827432 0.00307744 0.409693 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=182764, meanQ=8.854324, numObservations: 5
action 1, numVisits=189481, meanQ=8.853873, numObservations: 3
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2865579 episodes
GETTING ACTION FROM:
action 1, numVisits=1757063, meanQ=6.748991, numObservations: 3
action 2, numVisits=1480753, meanQ=6.748465, numObservations: 5
action 3, numVisits=9, meanQ=3.312222, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.625704 0.815359 0.64571 0.827432 0.00307744 0.409693 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 482
Initial state: 0 0.595871 0.873695 0.547806 0.763258 0.608507 0.893147 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2278058 episodes
GETTING ACTION FROM:
action 3, numVisits=2277952, meanQ=6.136935, numObservations: 4
action -1, numVisits=50, meanQ=5.039268, numObservations: 1
action 1, numVisits=20, meanQ=4.331500, numObservations: 3
action 0, numVisits=18, meanQ=4.293230, numObservations: 1
action 2, numVisits=18, meanQ=4.165000, numObservations: 4
action: 3
Next state: 1 0.595871 0.873695 0.547806 0.763258 0.608507 0.893147 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 483
Initial state: 0 0.517594 0.818745 0.0158465 0.23807 0.504949 0.883567 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2296520 episodes
GETTING ACTION FROM:
action 1, numVisits=2296474, meanQ=6.235891, numObservations: 5
action 2, numVisits=29, meanQ=4.780000, numObservations: 2
action 3, numVisits=13, meanQ=3.690777, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.517594 0.818745 0.0158465 0.23807 0.504949 0.883567 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=102418, meanQ=6.549926, numObservations: 5
action 1, numVisits=10, meanQ=2.099000, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2861942 episodes
GETTING ACTION FROM:
action 2, numVisits=2964360, meanQ=6.755183, numObservations: 5
action 1, numVisits=10, meanQ=2.099000, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.517594 0.818745 0.0158465 0.23807 0.504949 0.883567 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=33089, meanQ=8.880739, numObservations: 3
action 1, numVisits=4879, meanQ=8.822636, numObservations: 4
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2879064 episodes
GETTING ACTION FROM:
action 1, numVisits=2373445, meanQ=6.523748, numObservations: 5
action 3, numVisits=543566, meanQ=6.517380, numObservations: 3
action 2, numVisits=20, meanQ=4.549500, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 1
Next state: 1 0.517594 0.818745 0.0158465 0.23807 0.504949 0.883567 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.8309
Run # 484
Initial state: 0 0.568882 0.884267 0.816305 0.50045 0.59545 0.863115 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2307525 episodes
GETTING ACTION FROM:
action 3, numVisits=2307344, meanQ=6.229654, numObservations: 4
action 2, numVisits=161, meanQ=5.584348, numObservations: 5
action 1, numVisits=16, meanQ=3.999381, numObservations: 3
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.568882 0.884267 0.816305 0.50045 0.59545 0.863115 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 485
Initial state: 0 0.629738 0.810611 0.256752 0.581769 0.638031 0.826263 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2351572 episodes
GETTING ACTION FROM:
action 2, numVisits=2351516, meanQ=6.235465, numObservations: 3
action 0, numVisits=35, meanQ=4.921301, numObservations: 1
action 3, numVisits=14, meanQ=3.915000, numObservations: 3
action 1, numVisits=5, meanQ=1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.629738 0.810611 0.256752 0.581769 0.638031 0.826263 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=382792, meanQ=8.860107, numObservations: 5
action 3, numVisits=5, meanQ=5.396000, numObservations: 2
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2845376 episodes
GETTING ACTION FROM:
action 1, numVisits=3227763, meanQ=6.801676, numObservations: 5
action 3, numVisits=378, meanQ=6.374365, numObservations: 5
action 2, numVisits=33, meanQ=5.225455, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.629738 0.810611 0.256752 0.581769 0.638031 0.826263 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 486
Initial state: 0 0.678163 0.866986 0.586214 0.884841 0.192817 0.696295 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2326443 episodes
GETTING ACTION FROM:
action 1, numVisits=2326330, meanQ=6.232675, numObservations: 4
action 0, numVisits=78, meanQ=5.357951, numObservations: 1
action 3, numVisits=29, meanQ=4.550697, numObservations: 3
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.678163 0.866986 0.586214 0.884841 0.192817 0.696295 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 487
Initial state: 0 0.561456 0.894678 0.595977 0.885056 0.444569 0.573797 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2327824 episodes
GETTING ACTION FROM:
action 1, numVisits=2314995, meanQ=6.232789, numObservations: 4
action 2, numVisits=12735, meanQ=6.083990, numObservations: 4
action 0, numVisits=79, meanQ=5.375806, numObservations: 1
action -1, numVisits=14, meanQ=3.958894, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.561456 0.894678 0.595977 0.885056 0.444569 0.573797 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 488
Initial state: 0 0.594332 0.866745 0.527167 0.86773 0.794412 0.135644 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2342692 episodes
GETTING ACTION FROM:
action 2, numVisits=2342618, meanQ=6.237776, numObservations: 4
action -1, numVisits=69, meanQ=5.313690, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-5.505000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.594332 0.866745 0.527167 0.86773 0.794412 0.135644 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 489
Initial state: 0 0.650984 0.833974 0.543155 0.355961 0.683037 0.823338 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1572726 episodes
GETTING ACTION FROM:
action -1, numVisits=1572708, meanQ=4.175202, numObservations: 1
action 3, numVisits=6, meanQ=0.995017, numObservations: 3
action 2, numVisits=6, meanQ=0.831667, numObservations: 2
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: -1
Next state: 0 0.650984 0.833974 0.543155 0.355961 0.683037 0.823338 w: 1
Observation: 0 0.611071 0 0.600699 0 0.693685 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1572580, meanQ=6.232368, numObservations: 5
action -1, numVisits=93, meanQ=5.448573, numObservations: 1
action 3, numVisits=31, meanQ=4.831935, numObservations: 4
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2489455 episodes
GETTING ACTION FROM:
action 1, numVisits=4062035, meanQ=6.327036, numObservations: 5
action -1, numVisits=93, meanQ=5.448573, numObservations: 1
action 3, numVisits=31, meanQ=4.831935, numObservations: 4
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.650984 0.833974 0.543155 0.355961 0.683037 0.823338 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 490
Initial state: 0 0.705161 0.676139 0.549497 0.848254 0.529087 0.843979 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2333711 episodes
GETTING ACTION FROM:
action 2, numVisits=2333699, meanQ=6.229536, numObservations: 4
action 3, numVisits=4, meanQ=1.747500, numObservations: 2
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.705161 0.676139 0.549497 0.848254 0.529087 0.843979 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 491
Initial state: 0 0.501012 0.890726 0.655665 0.859227 0.619388 0.270433 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2343535 episodes
GETTING ACTION FROM:
action 3, numVisits=2343491, meanQ=6.185211, numObservations: 3
action 0, numVisits=30, meanQ=4.755430, numObservations: 1
action 1, numVisits=6, meanQ=2.663333, numObservations: 3
action 2, numVisits=6, meanQ=0.831667, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.501012 0.890726 0.655665 0.859227 0.619388 0.270433 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 492
Initial state: 0 0.678655 0.864822 0.324638 0.244469 0.503536 0.810634 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2329635 episodes
GETTING ACTION FROM:
action 2, numVisits=2329593, meanQ=6.221467, numObservations: 4
action 0, numVisits=27, meanQ=4.736644, numObservations: 1
action 3, numVisits=11, meanQ=3.814555, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 2
Next state: 0 0.678655 0.864822 0.324638 0.244469 0.503536 0.810634 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=320946, meanQ=8.877876, numObservations: 4
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2849922 episodes
GETTING ACTION FROM:
action 3, numVisits=3170834, meanQ=6.718808, numObservations: 4
action 2, numVisits=29, meanQ=4.817586, numObservations: 3
action 1, numVisits=5, meanQ=3.198000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 3
Next state: 1 0.678655 0.864822 0.324638 0.244469 0.503536 0.810634 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 493
Initial state: 0 0.687487 0.884655 0.692977 0.863749 0.832067 0.547608 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2299355 episodes
GETTING ACTION FROM:
action 1, numVisits=2299348, meanQ=6.234956, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.687487 0.884655 0.692977 0.863749 0.832067 0.547608 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 494
Initial state: 0 0.663166 0.421336 0.537383 0.873042 0.669314 0.826879 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2325996 episodes
GETTING ACTION FROM:
action 1, numVisits=2320814, meanQ=6.237983, numObservations: 4
action 2, numVisits=5158, meanQ=6.097439, numObservations: 4
action 3, numVisits=20, meanQ=4.430500, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.663166 0.421336 0.537383 0.873042 0.669314 0.826879 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=318597, meanQ=8.881464, numObservations: 4
action 2, numVisits=24, meanQ=7.415833, numObservations: 3
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2873736 episodes
GETTING ACTION FROM:
action 3, numVisits=3191024, meanQ=6.728221, numObservations: 4
action 2, numVisits=1332, meanQ=6.513581, numObservations: 3
action 1, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.663166 0.421336 0.537383 0.873042 0.669314 0.826879 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 495
Initial state: 0 0.849204 0.942068 0.525528 0.816614 0.555992 0.827087 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2304953 episodes
GETTING ACTION FROM:
action 1, numVisits=2304893, meanQ=6.242879, numObservations: 5
action 0, numVisits=29, meanQ=4.731452, numObservations: 2
action 3, numVisits=28, meanQ=4.703218, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.849204 0.942068 0.525528 0.816614 0.555992 0.827087 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 496
Initial state: 0 0.58856 0.835451 0.541891 0.0479393 0.612125 0.841822 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2312434 episodes
GETTING ACTION FROM:
action 3, numVisits=2312393, meanQ=6.235749, numObservations: 5
action 1, numVisits=35, meanQ=4.798577, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.58856 0.835451 0.541891 0.0479393 0.612125 0.841822 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 497
Initial state: 0 0.565564 0.852655 0.638803 0.889818 0.789369 0.411513 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2324633 episodes
GETTING ACTION FROM:
action 3, numVisits=2324606, meanQ=6.229036, numObservations: 4
action 0, numVisits=17, meanQ=4.247510, numObservations: 1
action 2, numVisits=6, meanQ=2.663333, numObservations: 3
action 1, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.565564 0.852655 0.638803 0.889818 0.789369 0.411513 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 498
Initial state: 0 0.679801 0.875256 0.54073 0.805873 0.385107 0.786175 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2322778 episodes
GETTING ACTION FROM:
action 3, numVisits=2321094, meanQ=6.238320, numObservations: 4
action 1, numVisits=1527, meanQ=5.979838, numObservations: 5
action -1, numVisits=89, meanQ=5.412295, numObservations: 1
action 0, numVisits=58, meanQ=5.225964, numObservations: 1
action 2, numVisits=10, meanQ=3.198000, numObservations: 2
action: 3
Next state: 0 0.679801 0.875256 0.54073 0.805873 0.385107 0.786175 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=165059, meanQ=8.862174, numObservations: 4
action 1, numVisits=155030, meanQ=8.862025, numObservations: 4
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2871775 episodes
GETTING ACTION FROM:
action 1, numVisits=1797323, meanQ=6.625485, numObservations: 4
action 2, numVisits=1394474, meanQ=6.624628, numObservations: 4
action 3, numVisits=65, meanQ=5.476158, numObservations: 4
action -1, numVisits=3, meanQ=1.300000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 1
Next state: 1 0.679801 0.875256 0.54073 0.805873 0.385107 0.786175 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 499
Initial state: 0 0.580858 0.820125 0.26145 0.511061 0.671989 0.849663 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2303017 episodes
GETTING ACTION FROM:
action 1, numVisits=2302996, meanQ=6.183678, numObservations: 5
action 2, numVisits=15, meanQ=3.732007, numObservations: 3
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 1
action: 1
Next state: 1 0.580858 0.820125 0.26145 0.511061 0.671989 0.849663 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 500
Initial state: 0 0.519077 0.840772 0.0874538 0.120296 0.62169 0.818282 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2292844 episodes
GETTING ACTION FROM:
action 3, numVisits=2292351, meanQ=6.245808, numObservations: 5
action 2, numVisits=481, meanQ=5.837753, numObservations: 5
action 1, numVisits=8, meanQ=2.737500, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.519077 0.840772 0.0874538 0.120296 0.62169 0.818282 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
