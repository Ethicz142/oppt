Run # 1
Initial state: 0 0.167632 0.768791 0.73227 0.00385338 0.851446 0.992327 0.00255904 0.520127 0.401692 0.357734 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88124 episodes
GETTING ACTION FROM:
action 4, numVisits=88115, meanQ=33.008356, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.167632 0.768791 0.73227 0.00385338 0.851446 0.992327 0.00255904 0.520127 0.401692 0.357734 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=7835, meanQ=37.373318, numObservations: 9
action 0, numVisits=16, meanQ=-2.372488, numObservations: 14
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action -1, numVisits=9, meanQ=-12.230000, numObservations: 8
Sampled 33470 episodes
GETTING ACTION FROM:
action 2, numVisits=41305, meanQ=31.762479, numObservations: 9
action 0, numVisits=16, meanQ=-2.372488, numObservations: 14
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action -1, numVisits=9, meanQ=-12.230000, numObservations: 8
action: 2
Next state: 2 0.167632 0.768791 0.73227 0.00385338 0.851446 0.992327 0.00255904 0.520127 0.401692 0.357734 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -110.99
Run # 2
Initial state: 0 0.573156 0.398592 0.823905 0.871584 0.594346 0.635205 0.472851 0.738055 0.968886 0.66316 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 83757 episodes
GETTING ACTION FROM:
action 2, numVisits=83746, meanQ=35.040350, numObservations: 9
action 4, numVisits=6, meanQ=10.666667, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.573156 0.398592 0.823905 0.871584 0.594346 0.635205 0.472851 0.738055 0.968886 0.66316 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 3
Initial state: 0 0.198756 0.541324 0.466988 0.644242 0.539093 0.37848 0.41599 0.119116 0.466625 0.112495 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 83606 episodes
GETTING ACTION FROM:
action 1, numVisits=83559, meanQ=34.170678, numObservations: 9
action 2, numVisits=36, meanQ=8.447225, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=7, meanQ=-5.285714, numObservations: 5
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.198756 0.541324 0.466988 0.644242 0.539093 0.37848 0.41599 0.119116 0.466625 0.112495 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=8418, meanQ=39.115049, numObservations: 9
action 5, numVisits=42, meanQ=31.881431, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 98892 episodes
GETTING ACTION FROM:
action 2, numVisits=107310, meanQ=42.498781, numObservations: 9
action 5, numVisits=42, meanQ=31.881431, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.198756 0.541324 0.466988 0.644242 0.539093 0.37848 0.41599 0.119116 0.466625 0.112495 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 4
Initial state: 0 0.0563338 0.827652 0.186569 0.146043 0.410567 0.0854796 0.638965 0.951728 0.433056 0.477789 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88963 episodes
GETTING ACTION FROM:
action 1, numVisits=88936, meanQ=31.503297, numObservations: 9
action 5, numVisits=17, meanQ=14.468824, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=6, meanQ=-5.998333, numObservations: 4
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.0563338 0.827652 0.186569 0.146043 0.410567 0.0854796 0.638965 0.951728 0.433056 0.477789 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=8932, meanQ=38.989205, numObservations: 9
action 3, numVisits=3, meanQ=26.326667, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 91912 episodes
GETTING ACTION FROM:
action 2, numVisits=100844, meanQ=40.882572, numObservations: 9
action 3, numVisits=3, meanQ=26.326667, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 2
Next state: 0 0.0563338 0.827652 0.186569 0.146043 0.410567 0.0854796 0.638965 0.951728 0.433056 0.477789 w: 1
Observation: 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=1052, meanQ=35.161909, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 66145 episodes
GETTING ACTION FROM:
action 3, numVisits=67197, meanQ=35.756148, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.0563338 0.827652 0.186569 0.146043 0.410567 0.0854796 0.638965 0.951728 0.433056 0.477789 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -120.88
Run # 5
Initial state: 0 0.305996 0.645408 0.528425 0.442593 0.596658 0.684518 0.240872 0.197934 0.349943 0.698028 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87043 episodes
GETTING ACTION FROM:
action 3, numVisits=87015, meanQ=32.140052, numObservations: 9
action 5, numVisits=23, meanQ=14.699135, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.305996 0.645408 0.528425 0.442593 0.596658 0.684518 0.240872 0.197934 0.349943 0.698028 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 6
Initial state: 0 0.567309 0.378077 0.819472 0.861382 0.523716 0.0312841 0.128386 0.636738 0.784894 0.673019 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 82307 episodes
GETTING ACTION FROM:
action 2, numVisits=82300, meanQ=34.306702, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.567309 0.378077 0.819472 0.861382 0.523716 0.0312841 0.128386 0.636738 0.784894 0.673019 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 7
Initial state: 0 0.528655 0.765409 0.288716 0.380406 0.877777 0.0772683 0.111865 0.376132 0.560014 0.460545 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 84797 episodes
GETTING ACTION FROM:
action 2, numVisits=84772, meanQ=33.593266, numObservations: 9
action 5, numVisits=10, meanQ=23.207010, numObservations: 6
action 1, numVisits=4, meanQ=21.500000, numObservations: 4
action 4, numVisits=8, meanQ=21.500000, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.528655 0.765409 0.288716 0.380406 0.877777 0.0772683 0.111865 0.376132 0.560014 0.460545 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=2898, meanQ=33.861773, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=3, meanQ=-4.003333, numObservations: 3
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 25132 episodes
GETTING ACTION FROM:
action 3, numVisits=28030, meanQ=33.271325, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=3, meanQ=-4.003333, numObservations: 3
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.528655 0.765409 0.288716 0.380406 0.877777 0.0772683 0.111865 0.376132 0.560014 0.460545 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -110.99
Run # 8
Initial state: 0 0.762835 0.849033 0.781464 0.62251 0.202495 0.991406 0.483721 0.460682 0.726356 0.235702 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48478 episodes
GETTING ACTION FROM:
action 0, numVisits=48432, meanQ=63.201647, numObservations: 243
action -1, numVisits=12, meanQ=-1.918325, numObservations: 11
action 4, numVisits=9, meanQ=-2.111111, numObservations: 5
action 5, numVisits=18, meanQ=-3.277772, numObservations: 9
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=5, meanQ=-21.000000, numObservations: 4
action: 0
Next state: 0 0.762835 0.849033 0.781464 0.62251 0.202495 0.991406 0.483721 0.460682 0.726356 0.235702 w: 1
Observation: 0 0 3 0 3 0 3 0 2 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=421, meanQ=83.615198, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 111797 episodes
GETTING ACTION FROM:
action 4, numVisits=112218, meanQ=89.159084, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.762835 0.849033 0.781464 0.62251 0.202495 0.991406 0.483721 0.460682 0.726356 0.235702 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 9
Initial state: 0 0.491188 0.375115 0.231045 0.18715 0.642045 0.605011 0.500264 0.962367 0.876935 0.733189 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49013 episodes
GETTING ACTION FROM:
action 0, numVisits=48982, meanQ=62.526082, numObservations: 243
action -1, numVisits=26, meanQ=-5.313073, numObservations: 24
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.491188 0.375115 0.231045 0.18715 0.642045 0.605011 0.500264 0.962367 0.876935 0.733189 w: 1
Observation: 0 0 2 0 2 0 3 0 3 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=291, meanQ=55.846047, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 93779 episodes
GETTING ACTION FROM:
action 4, numVisits=94070, meanQ=67.160582, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.491188 0.375115 0.231045 0.18715 0.642045 0.605011 0.500264 0.962367 0.876935 0.733189 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 10
Initial state: 0 0.90265 0.918511 0.52224 0.42278 0.306204 0.756083 0.78698 0.0838007 0.169184 0.450031 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89081 episodes
GETTING ACTION FROM:
action 5, numVisits=89069, meanQ=32.218349, numObservations: 9
action 1, numVisits=6, meanQ=14.000000, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.90265 0.918511 0.52224 0.42278 0.306204 0.756083 0.78698 0.0838007 0.169184 0.450031 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 11
Initial state: 0 0.381453 0.360182 0.0813742 0.962816 0.718087 0.691853 0.536928 0.483969 0.776455 0.980204 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88511 episodes
GETTING ACTION FROM:
action 1, numVisits=88488, meanQ=31.400853, numObservations: 9
action 5, numVisits=18, meanQ=18.998900, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.381453 0.360182 0.0813742 0.962816 0.718087 0.691853 0.536928 0.483969 0.776455 0.980204 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=2996, meanQ=38.261785, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 4, numVisits=9, meanQ=-3.111111, numObservations: 6
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 31765 episodes
GETTING ACTION FROM:
action 2, numVisits=34761, meanQ=32.039752, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 4, numVisits=9, meanQ=-3.111111, numObservations: 6
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.381453 0.360182 0.0813742 0.962816 0.718087 0.691853 0.536928 0.483969 0.776455 0.980204 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=1860, meanQ=42.648667, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 29053 episodes
GETTING ACTION FROM:
action 4, numVisits=30913, meanQ=52.858436, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.381453 0.360182 0.0813742 0.962816 0.718087 0.691853 0.536928 0.483969 0.776455 0.980204 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action -1, numVisits=260, meanQ=54.901295, numObservations: 57
action 0, numVisits=4, meanQ=-6.389059, numObservations: 3
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-21.034942, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37462 episodes
GETTING ACTION FROM:
action -1, numVisits=37722, meanQ=5.895042, numObservations: 243
action 0, numVisits=4, meanQ=-6.389059, numObservations: 3
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-21.034942, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.381453 0.360182 0.0813742 0.962816 0.718087 0.691853 0.536928 0.483969 0.776455 0.980204 w: 1
Observation: 0 1 0 1 0 3 0 2 0 3 0 
Immediate reward: -2
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 5, numVisits=28, meanQ=73.428763, numObservations: 8
action 3, numVisits=3, meanQ=59.605928, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-17.433407, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 1, numVisits=1, meanQ=-545.182559, numObservations: 1
Sampled 126375 episodes
GETTING ACTION FROM:
action 5, numVisits=126379, meanQ=66.828616, numObservations: 9
action 3, numVisits=27, meanQ=50.178436, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-17.433407, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 1, numVisits=1, meanQ=-545.182559, numObservations: 1
action: 5
Next state: 1 0.381453 0.360182 0.0813742 0.962816 0.718087 0.691853 0.536928 0.483969 0.776455 0.980204 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 60.4873
Run # 12
Initial state: 0 0.525916 0.449381 0.474858 0.252568 0.0864899 0.447231 0.345442 0.897609 0.567598 0.161589 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88940 episodes
GETTING ACTION FROM:
action 4, numVisits=88904, meanQ=32.731441, numObservations: 9
action 3, numVisits=20, meanQ=25.405505, numObservations: 8
action 1, numVisits=10, meanQ=19.927030, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.525916 0.449381 0.474858 0.252568 0.0864899 0.447231 0.345442 0.897609 0.567598 0.161589 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=8965, meanQ=40.048418, numObservations: 9
action 5, numVisits=6, meanQ=-1.000000, numObservations: 4
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 96779 episodes
GETTING ACTION FROM:
action 1, numVisits=105744, meanQ=45.320945, numObservations: 9
action 5, numVisits=6, meanQ=-1.000000, numObservations: 4
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.525916 0.449381 0.474858 0.252568 0.0864899 0.447231 0.345442 0.897609 0.567598 0.161589 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 13
Initial state: 0 0.40183 0.360326 0.936931 0.655728 0.81143 0.418276 0.916063 0.654723 0.600328 0.446922 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48229 episodes
GETTING ACTION FROM:
action -1, numVisits=48190, meanQ=48.251566, numObservations: 243
action 0, numVisits=13, meanQ=-1.848454, numObservations: 12
action 3, numVisits=22, meanQ=-3.272723, numObservations: 7
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.40183 0.360326 0.936931 0.655728 0.81143 0.418276 0.916063 0.654723 0.600328 0.446922 w: 1
Observation: 0 2 0 3 0 3 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=308, meanQ=79.052404, numObservations: 9
action 2, numVisits=12, meanQ=32.333333, numObservations: 5
action 4, numVisits=3, meanQ=32.333333, numObservations: 2
action 3, numVisits=7, meanQ=26.284286, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 112259 episodes
GETTING ACTION FROM:
action 1, numVisits=112567, meanQ=85.853458, numObservations: 9
action 2, numVisits=12, meanQ=32.333333, numObservations: 5
action 4, numVisits=3, meanQ=32.333333, numObservations: 2
action 3, numVisits=7, meanQ=26.284286, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.40183 0.360326 0.936931 0.655728 0.81143 0.418276 0.916063 0.654723 0.600328 0.446922 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=6792, meanQ=90.152658, numObservations: 9
action 3, numVisits=4, meanQ=49.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 123769 episodes
GETTING ACTION FROM:
action 1, numVisits=130561, meanQ=96.716077, numObservations: 9
action 3, numVisits=4, meanQ=49.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.40183 0.360326 0.936931 0.655728 0.81143 0.418276 0.916063 0.654723 0.600328 0.446922 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 84.1399
Run # 14
Initial state: 0 0.361185 0.217087 0.572268 0.726621 0.34054 0.571076 0.880033 0.0589077 0.523553 0.452345 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 81707 episodes
GETTING ACTION FROM:
action 3, numVisits=81680, meanQ=33.344528, numObservations: 9
action 1, numVisits=11, meanQ=13.364545, numObservations: 7
action 5, numVisits=12, meanQ=13.167500, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.361185 0.217087 0.572268 0.726621 0.34054 0.571076 0.880033 0.0589077 0.523553 0.452345 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 15
Initial state: 0 0.683624 0.0970153 0.278713 0.811522 0.0337748 0.0803617 0.635372 0.0599093 0.550005 0.386003 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89983 episodes
GETTING ACTION FROM:
action 1, numVisits=89975, meanQ=33.050298, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.683624 0.0970153 0.278713 0.811522 0.0337748 0.0803617 0.635372 0.0599093 0.550005 0.386003 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 16
Initial state: 0 0.443389 0.944612 0.0355264 0.099654 0.70831 0.738915 0.458744 0.39786 0.648599 0.218652 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 83413 episodes
GETTING ACTION FROM:
action 5, numVisits=83393, meanQ=34.839052, numObservations: 9
action 2, numVisits=7, meanQ=26.284286, numObservations: 5
action 4, numVisits=8, meanQ=24.000000, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.443389 0.944612 0.0355264 0.099654 0.70831 0.738915 0.458744 0.39786 0.648599 0.218652 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 17
Initial state: 0 0.570502 0.123297 0.16767 0.185581 0.513994 0.414713 0.589521 0.328846 0.111857 0.33643 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89972 episodes
GETTING ACTION FROM:
action 5, numVisits=89960, meanQ=32.412161, numObservations: 9
action 3, numVisits=7, meanQ=10.428571, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.570502 0.123297 0.16767 0.185581 0.513994 0.414713 0.589521 0.328846 0.111857 0.33643 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=8172, meanQ=36.947254, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=3, meanQ=-4.003333, numObservations: 3
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 28606 episodes
GETTING ACTION FROM:
action 2, numVisits=36778, meanQ=35.805386, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=3, meanQ=-4.003333, numObservations: 3
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.570502 0.123297 0.16767 0.185581 0.513994 0.414713 0.589521 0.328846 0.111857 0.33643 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=2876, meanQ=52.207665, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 22113 episodes
GETTING ACTION FROM:
action 3, numVisits=24989, meanQ=39.609290, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 3
Next state: 1 0.570502 0.123297 0.16767 0.185581 0.513994 0.414713 0.589521 0.328846 0.111857 0.33643 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 75.1399
Run # 18
Initial state: 0 0.638418 0.939799 0.466319 0.35563 0.472482 0.880572 0.18091 0.730626 0.446968 0.42631 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 83933 episodes
GETTING ACTION FROM:
action 5, numVisits=83921, meanQ=33.136299, numObservations: 9
action 2, numVisits=7, meanQ=7.995714, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.638418 0.939799 0.466319 0.35563 0.472482 0.880572 0.18091 0.730626 0.446968 0.42631 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 19
Initial state: 0 0.482244 0.163642 0.722829 0.342994 0.141518 0.771322 0.418713 0.416434 0.431646 0.265605 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89558 episodes
GETTING ACTION FROM:
action 1, numVisits=89546, meanQ=31.981778, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 5, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=3, meanQ=-7.663333, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.482244 0.163642 0.722829 0.342994 0.141518 0.771322 0.418713 0.416434 0.431646 0.265605 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=582, meanQ=33.812112, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 85022 episodes
GETTING ACTION FROM:
action 5, numVisits=85604, meanQ=34.457127, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.482244 0.163642 0.722829 0.342994 0.141518 0.771322 0.418713 0.416434 0.431646 0.265605 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=83, meanQ=36.874302, numObservations: 9
action 2, numVisits=34, meanQ=27.026330, numObservations: 7
action 4, numVisits=10, meanQ=22.101131, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 85133 episodes
GETTING ACTION FROM:
action 3, numVisits=85194, meanQ=25.073052, numObservations: 9
action 4, numVisits=25, meanQ=20.240452, numObservations: 8
action 2, numVisits=41, meanQ=19.802322, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 3
Next state: 0 0.482244 0.163642 0.722829 0.342994 0.141518 0.771322 0.418713 0.416434 0.431646 0.265605 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 4, numVisits=689, meanQ=60.843365, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-20.652535, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 1, numVisits=1, meanQ=-1062.450044, numObservations: 1
Sampled 98735 episodes
GETTING ACTION FROM:
action 4, numVisits=99424, meanQ=39.214978, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-20.652535, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 1, numVisits=1, meanQ=-1062.450044, numObservations: 1
action: 4
Next state: 1 0.482244 0.163642 0.722829 0.342994 0.141518 0.771322 0.418713 0.416434 0.431646 0.265605 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 63.3885
Run # 20
Initial state: 0 0.52145 0.121334 0.589252 0.965496 0.806657 0.926301 0.567406 0.423333 0.783475 0.113002 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 83735 episodes
GETTING ACTION FROM:
action 4, numVisits=83725, meanQ=33.995413, numObservations: 9
action 1, numVisits=4, meanQ=-1.000000, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.52145 0.121334 0.589252 0.965496 0.806657 0.926301 0.567406 0.423333 0.783475 0.113002 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 21
Initial state: 0 0.0689046 0.919703 0.452723 0.434899 0.907634 0.843455 0.48576 0.233548 0.890512 0.869176 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48439 episodes
GETTING ACTION FROM:
action -1, numVisits=48414, meanQ=48.586174, numObservations: 243
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action 4, numVisits=6, meanQ=-4.333333, numObservations: 6
action 0, numVisits=13, meanQ=-8.777692, numObservations: 12
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.0689046 0.919703 0.452723 0.434899 0.907634 0.843455 0.48576 0.233548 0.890512 0.869176 w: 1
Observation: 0 1 0 2 0 3 0 2 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=199, meanQ=54.498574, numObservations: 9
action 2, numVisits=5, meanQ=37.198000, numObservations: 3
action 3, numVisits=8, meanQ=35.373750, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 70630 episodes
GETTING ACTION FROM:
action 1, numVisits=70829, meanQ=46.701330, numObservations: 9
action 2, numVisits=5, meanQ=37.198000, numObservations: 3
action 3, numVisits=8, meanQ=35.373750, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 1
Next state: 0 0.0689046 0.919703 0.452723 0.434899 0.907634 0.843455 0.48576 0.233548 0.890512 0.869176 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=22189, meanQ=65.344284, numObservations: 9
action 4, numVisits=10, meanQ=59.000000, numObservations: 6
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 110395 episodes
GETTING ACTION FROM:
action 2, numVisits=132584, meanQ=67.339869, numObservations: 9
action 4, numVisits=10, meanQ=59.000000, numObservations: 6
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 2
Next state: 1 0.0689046 0.919703 0.452723 0.434899 0.907634 0.843455 0.48576 0.233548 0.890512 0.869176 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 84.1399
Run # 22
Initial state: 0 0.84001 0.541408 0.283275 0.217876 0.520786 0.367941 0.263506 0.17742 0.43786 0.230652 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48893 episodes
GETTING ACTION FROM:
action 0, numVisits=48869, meanQ=63.606755, numObservations: 243
action -1, numVisits=8, meanQ=-1.010000, numObservations: 8
action 3, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=4, meanQ=-6.249975, numObservations: 3
action 1, numVisits=7, meanQ=-15.285714, numObservations: 5
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.84001 0.541408 0.283275 0.217876 0.520786 0.367941 0.263506 0.17742 0.43786 0.230652 w: 1
Observation: 0 0 3 0 1 0 2 0 1 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=189, meanQ=75.456566, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=3, meanQ=-7.333333, numObservations: 2
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 108527 episodes
GETTING ACTION FROM:
action 3, numVisits=108716, meanQ=85.806844, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=3, meanQ=-7.333333, numObservations: 2
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.84001 0.541408 0.283275 0.217876 0.520786 0.367941 0.263506 0.17742 0.43786 0.230652 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 23
Initial state: 0 0.0362076 0.500042 0.474429 0.128492 0.532079 0.457278 0.0779306 0.916456 0.225406 0.685161 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 83192 episodes
GETTING ACTION FROM:
action 2, numVisits=83178, meanQ=33.820909, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 3, numVisits=5, meanQ=-3.000000, numObservations: 2
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.0362076 0.500042 0.474429 0.128492 0.532079 0.457278 0.0779306 0.916456 0.225406 0.685161 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 24
Initial state: 0 0.841596 0.228366 0.482292 0.410114 0.257717 0.60043 0.777173 0.920755 0.358004 0.0481487 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88688 episodes
GETTING ACTION FROM:
action 4, numVisits=88678, meanQ=31.480717, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.841596 0.228366 0.482292 0.410114 0.257717 0.60043 0.777173 0.920755 0.358004 0.0481487 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 25
Initial state: 0 0.00644512 0.113527 0.407524 0.802783 0.573883 0.458492 0.811856 0.114235 0.96071 0.93254 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48677 episodes
GETTING ACTION FROM:
action -1, numVisits=48658, meanQ=50.081896, numObservations: 243
action 0, numVisits=14, meanQ=-1.010000, numObservations: 14
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.00644512 0.113527 0.407524 0.802783 0.573883 0.458492 0.811856 0.114235 0.96071 0.93254 w: 1
Observation: 0 1 0 2 0 2 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=213, meanQ=44.456858, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 102862 episodes
GETTING ACTION FROM:
action 2, numVisits=103075, meanQ=47.616822, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.00644512 0.113527 0.407524 0.802783 0.573883 0.458492 0.811856 0.114235 0.96071 0.93254 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 26
Initial state: 0 0.567072 0.365792 0.0609422 0.367299 0.231888 0.122008 0.377554 0.881262 0.614744 0.904934 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88967 episodes
GETTING ACTION FROM:
action 2, numVisits=88958, meanQ=31.509114, numObservations: 9
action 1, numVisits=3, meanQ=25.666667, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.567072 0.365792 0.0609422 0.367299 0.231888 0.122008 0.377554 0.881262 0.614744 0.904934 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=2956, meanQ=40.052777, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=3, meanQ=-4.003333, numObservations: 3
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 31475 episodes
GETTING ACTION FROM:
action 1, numVisits=34431, meanQ=32.473804, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=3, meanQ=-4.003333, numObservations: 3
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.567072 0.365792 0.0609422 0.367299 0.231888 0.122008 0.377554 0.881262 0.614744 0.904934 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 27
Initial state: 0 0.320126 0.738179 0.556435 0.421008 0.711831 0.581474 0.369376 0.442588 0.104349 0.244926 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88548 episodes
GETTING ACTION FROM:
action 5, numVisits=88537, meanQ=32.508474, numObservations: 9
action 1, numVisits=6, meanQ=14.000000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.320126 0.738179 0.556435 0.421008 0.711831 0.581474 0.369376 0.442588 0.104349 0.244926 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=493, meanQ=24.189235, numObservations: 184
action 0, numVisits=43, meanQ=-1.862551, numObservations: 38
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 41297 episodes
GETTING ACTION FROM:
action -1, numVisits=41790, meanQ=4.234486, numObservations: 243
action 0, numVisits=43, meanQ=-1.862551, numObservations: 38
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.320126 0.738179 0.556435 0.421008 0.711831 0.581474 0.369376 0.442588 0.104349 0.244926 w: 1
Observation: 0 1 0 2 0 3 0 1 0 1 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=24, meanQ=93.537765, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-1060.773727, numObservations: 1
Sampled 85954 episodes
GETTING ACTION FROM:
action 2, numVisits=85978, meanQ=83.056538, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-1060.773727, numObservations: 1
action: 2
Next state: 0 0.320126 0.738179 0.556435 0.421008 0.711831 0.581474 0.369376 0.442588 0.104349 0.244926 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=2198, meanQ=95.688628, numObservations: 9
action 3, numVisits=5, meanQ=35.542716, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-17.160186, numObservations: 1
action 4, numVisits=1, meanQ=-17.851074, numObservations: 1
action 5, numVisits=1, meanQ=-1076.851446, numObservations: 1
Sampled 119665 episodes
GETTING ACTION FROM:
action 2, numVisits=121863, meanQ=97.373038, numObservations: 9
action 3, numVisits=5, meanQ=35.542716, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-17.160186, numObservations: 1
action 4, numVisits=1, meanQ=-17.851074, numObservations: 1
action 5, numVisits=1, meanQ=-1076.851446, numObservations: 1
action: 2
Next state: 1 0.320126 0.738179 0.556435 0.421008 0.711831 0.581474 0.369376 0.442588 0.104349 0.244926 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 72.2985
Run # 28
Initial state: 0 0.501341 0.368756 0.520239 0.144622 0.591321 0.596267 0.119373 0.156261 0.407354 0.557721 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49055 episodes
GETTING ACTION FROM:
action -1, numVisits=49042, meanQ=50.064107, numObservations: 243
action 0, numVisits=8, meanQ=-1.010000, numObservations: 8
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.501341 0.368756 0.520239 0.144622 0.591321 0.596267 0.119373 0.156261 0.407354 0.557721 w: 1
Observation: 0 2 0 2 0 1 0 1 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=121, meanQ=9.690264, numObservations: 79
action -1, numVisits=4, meanQ=-3.734975, numObservations: 3
action 3, numVisits=9, meanQ=-5.113333, numObservations: 5
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=11, meanQ=-10.090909, numObservations: 5
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 49667 episodes
GETTING ACTION FROM:
action 0, numVisits=49788, meanQ=75.890104, numObservations: 243
action -1, numVisits=4, meanQ=-3.734975, numObservations: 3
action 3, numVisits=9, meanQ=-5.113333, numObservations: 5
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=11, meanQ=-10.090909, numObservations: 5
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.501341 0.368756 0.520239 0.144622 0.591321 0.596267 0.119373 0.156261 0.407354 0.557721 w: 1
Observation: 0 0 3 0 1 0 3 0 1 0 3 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=31, meanQ=36.773552, numObservations: 8
action 3, numVisits=5, meanQ=32.402000, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 117660 episodes
GETTING ACTION FROM:
action 1, numVisits=117690, meanQ=54.688876, numObservations: 9
action 3, numVisits=6, meanQ=25.168333, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.501341 0.368756 0.520239 0.144622 0.591321 0.596267 0.119373 0.156261 0.407354 0.557721 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 93.0499
Run # 29
Initial state: 0 0.47825 0.591587 0.613044 0.780481 0.621071 0.976485 0.30519 0.186615 0.457421 0.476792 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48609 episodes
GETTING ACTION FROM:
action 0, numVisits=48575, meanQ=61.902387, numObservations: 243
action -1, numVisits=19, meanQ=-1.114732, numObservations: 18
action 4, numVisits=11, meanQ=-1.909091, numObservations: 6
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.47825 0.591587 0.613044 0.780481 0.621071 0.976485 0.30519 0.186615 0.457421 0.476792 w: 1
Observation: 0 0 3 0 2 0 3 0 1 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=211, meanQ=52.524617, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 100865 episodes
GETTING ACTION FROM:
action 2, numVisits=101076, meanQ=57.318292, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.47825 0.591587 0.613044 0.780481 0.621071 0.976485 0.30519 0.186615 0.457421 0.476792 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 30
Initial state: 0 0.875096 0.655772 0.598438 0.164668 0.285579 0.639304 0.931873 0.905527 0.551997 0.42862 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88559 episodes
GETTING ACTION FROM:
action 1, numVisits=88509, meanQ=33.222937, numObservations: 9
action 4, numVisits=43, meanQ=27.167216, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.875096 0.655772 0.598438 0.164668 0.285579 0.639304 0.931873 0.905527 0.551997 0.42862 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 31
Initial state: 0 0.858864 0.166126 0.934309 0.175217 0.975186 0.186081 0.436337 0.59132 0.557104 0.462859 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89324 episodes
GETTING ACTION FROM:
action 3, numVisits=89310, meanQ=32.648717, numObservations: 9
action 4, numVisits=3, meanQ=25.333367, numObservations: 2
action 1, numVisits=7, meanQ=23.284300, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.858864 0.166126 0.934309 0.175217 0.975186 0.186081 0.436337 0.59132 0.557104 0.462859 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=1774, meanQ=33.284393, numObservations: 9
action 1, numVisits=20, meanQ=10.603005, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=5, meanQ=-2.802000, numObservations: 4
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 95746 episodes
GETTING ACTION FROM:
action 4, numVisits=97496, meanQ=6.995296, numObservations: 9
action 1, numVisits=22, meanQ=0.457277, numObservations: 8
action -1, numVisits=12, meanQ=-1.835000, numObservations: 12
action 0, numVisits=12, meanQ=-1.835000, numObservations: 12
action 2, numVisits=5, meanQ=-2.802000, numObservations: 4
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.858864 0.166126 0.934309 0.175217 0.975186 0.186081 0.436337 0.59132 0.557104 0.462859 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 32
Initial state: 0 0.499896 0.874467 0.578256 0.422538 0.320998 0.758896 0.235354 0.394361 0.144996 0.224082 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88688 episodes
GETTING ACTION FROM:
action 2, numVisits=88626, meanQ=32.960258, numObservations: 9
action 4, numVisits=20, meanQ=30.504510, numObservations: 6
action 5, numVisits=37, meanQ=29.893516, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.499896 0.874467 0.578256 0.422538 0.320998 0.758896 0.235354 0.394361 0.144996 0.224082 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 33
Initial state: 0 0.416314 0.326696 0.435573 0.286182 0.485116 0.388489 0.719496 0.807324 0.195298 0.0127531 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89207 episodes
GETTING ACTION FROM:
action 3, numVisits=89186, meanQ=32.567259, numObservations: 9
action 1, numVisits=16, meanQ=8.442506, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.416314 0.326696 0.435573 0.286182 0.485116 0.388489 0.719496 0.807324 0.195298 0.0127531 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 34
Initial state: 0 0.847235 0.139389 0.418362 0.48704 0.329951 0.137162 0.0909457 0.289846 0.539583 0.67052 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89082 episodes
GETTING ACTION FROM:
action 1, numVisits=89070, meanQ=32.728477, numObservations: 9
action 3, numVisits=7, meanQ=13.285714, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.847235 0.139389 0.418362 0.48704 0.329951 0.137162 0.0909457 0.289846 0.539583 0.67052 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 35
Initial state: 0 0.622078 0.627185 0.343325 0.397682 0.414502 0.424132 0.903906 0.407676 0.195041 0.766905 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 82515 episodes
GETTING ACTION FROM:
action 5, numVisits=82506, meanQ=33.973956, numObservations: 9
action 4, numVisits=4, meanQ=21.747500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.622078 0.627185 0.343325 0.397682 0.414502 0.424132 0.903906 0.407676 0.195041 0.766905 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=8347, meanQ=36.059813, numObservations: 9
action 1, numVisits=6, meanQ=32.333333, numObservations: 6
action 5, numVisits=3, meanQ=25.663367, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 96423 episodes
GETTING ACTION FROM:
action 4, numVisits=104766, meanQ=41.198256, numObservations: 9
action 1, numVisits=10, meanQ=28.000000, numObservations: 8
action 5, numVisits=3, meanQ=25.663367, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 4
Next state: 1 0.622078 0.627185 0.343325 0.397682 0.414502 0.424132 0.903906 0.407676 0.195041 0.766905 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 36
Initial state: 0 0.497977 0.446219 0.185578 0.25033 0.153131 0.0619978 0.745357 0.900352 0.96321 0.820647 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 82480 episodes
GETTING ACTION FROM:
action 3, numVisits=82466, meanQ=34.397954, numObservations: 9
action 1, numVisits=4, meanQ=21.500000, numObservations: 3
action 4, numVisits=5, meanQ=14.800020, numObservations: 4
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.497977 0.446219 0.185578 0.25033 0.153131 0.0619978 0.745357 0.900352 0.96321 0.820647 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=1490, meanQ=52.586189, numObservations: 228
action 0, numVisits=24, meanQ=-1.010000, numObservations: 24
action 2, numVisits=3, meanQ=-4.003333, numObservations: 3
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 42972 episodes
GETTING ACTION FROM:
action -1, numVisits=44462, meanQ=8.522744, numObservations: 243
action 0, numVisits=24, meanQ=-1.010000, numObservations: 24
action 2, numVisits=3, meanQ=-4.003333, numObservations: 3
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.497977 0.446219 0.185578 0.25033 0.153131 0.0619978 0.745357 0.900352 0.96321 0.820647 w: 1
Observation: 0 2 0 1 0 1 0 1 0 3 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action -1, numVisits=40, meanQ=6.974020, numObservations: 17
action 0, numVisits=12, meanQ=-9.755000, numObservations: 9
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 26269 episodes
GETTING ACTION FROM:
action -1, numVisits=26309, meanQ=24.043502, numObservations: 212
action 0, numVisits=12, meanQ=-9.755000, numObservations: 9
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.497977 0.446219 0.185578 0.25033 0.153131 0.0619978 0.745357 0.900352 0.96321 0.820647 w: 1
Observation: 0 3 0 1 0 1 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 0, numVisits=19, meanQ=13.785289, numObservations: 11
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-16.123390, numObservations: 1
action 4, numVisits=1, meanQ=-16.225168, numObservations: 1
action 1, numVisits=1, meanQ=-16.444777, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-1079.196967, numObservations: 1
Sampled 33376 episodes
GETTING ACTION FROM:
action -1, numVisits=33373, meanQ=71.109648, numObservations: 200
action 2, numVisits=1, meanQ=-16.123390, numObservations: 1
action 4, numVisits=1, meanQ=-16.225168, numObservations: 1
action 1, numVisits=1, meanQ=-16.444777, numObservations: 1
action 0, numVisits=24, meanQ=-25.809872, numObservations: 13
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-1079.196967, numObservations: 1
action: -1
Next state: 0 0.497977 0.446219 0.185578 0.25033 0.153131 0.0619978 0.745357 0.900352 0.96321 0.820647 w: 1
Observation: 0 3 0 1 0 1 0 3 0 2 0 
Immediate reward: -2
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 1, numVisits=2, meanQ=99.000000, numObservations: 1
action 2, numVisits=2, meanQ=99.000000, numObservations: 2
action 5, numVisits=7, meanQ=70.428571, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 108620 episodes
GETTING ACTION FROM:
action 1, numVisits=108621, meanQ=95.452775, numObservations: 9
action 5, numVisits=7, meanQ=70.428571, numObservations: 5
action 2, numVisits=3, meanQ=62.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.497977 0.446219 0.185578 0.25033 0.153131 0.0619978 0.745357 0.900352 0.96321 0.820647 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 5
Improving policy...
PLANNING FROM:
action 1, numVisits=6789, meanQ=96.448480, numObservations: 9
action 5, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-14.556804, numObservations: 1
action 2, numVisits=1, meanQ=-21.670413, numObservations: 1
action 3, numVisits=1, meanQ=-1078.482538, numObservations: 1
Sampled 122678 episodes
GETTING ACTION FROM:
action 1, numVisits=129467, meanQ=98.548897, numObservations: 9
action 5, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-14.556804, numObservations: 1
action 2, numVisits=1, meanQ=-21.670413, numObservations: 1
action 3, numVisits=1, meanQ=-1078.482538, numObservations: 1
action: 1
Next state: 1 0.497977 0.446219 0.185578 0.25033 0.153131 0.0619978 0.745357 0.900352 0.96321 0.820647 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 66.7007
Run # 37
Initial state: 0 0.809503 0.389434 0.417856 0.761306 0.874049 0.0242794 0.428288 0.457906 0.880344 0.203039 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80759 episodes
GETTING ACTION FROM:
action 4, numVisits=80735, meanQ=34.391374, numObservations: 9
action 2, numVisits=9, meanQ=17.998889, numObservations: 6
action 1, numVisits=11, meanQ=13.546364, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.809503 0.389434 0.417856 0.761306 0.874049 0.0242794 0.428288 0.457906 0.880344 0.203039 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 38
Initial state: 0 0.697234 0.52144 0.317617 0.223064 0.905502 0.327188 0.462458 0.45714 0.383379 0.915362 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 83984 episodes
GETTING ACTION FROM:
action 4, numVisits=83960, meanQ=34.037806, numObservations: 9
action 3, numVisits=19, meanQ=28.052632, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.697234 0.52144 0.317617 0.223064 0.905502 0.327188 0.462458 0.45714 0.383379 0.915362 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 39
Initial state: 0 0.268637 0.438561 0.436386 0.416696 0.660253 0.0631941 0.112323 0.841165 0.426642 0.35147 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88880 episodes
GETTING ACTION FROM:
action 5, numVisits=88861, meanQ=32.693615, numObservations: 9
action 2, numVisits=7, meanQ=26.142857, numObservations: 5
action 1, numVisits=3, meanQ=25.666667, numObservations: 3
action 4, numVisits=6, meanQ=24.013367, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.268637 0.438561 0.436386 0.416696 0.660253 0.0631941 0.112323 0.841165 0.426642 0.35147 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=1575, meanQ=29.706298, numObservations: 9
action 4, numVisits=20, meanQ=6.153505, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 49564 episodes
GETTING ACTION FROM:
action 3, numVisits=51137, meanQ=17.858728, numObservations: 9
action 4, numVisits=20, meanQ=6.153505, numObservations: 7
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.268637 0.438561 0.436386 0.416696 0.660253 0.0631941 0.112323 0.841165 0.426642 0.35147 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -110.99
Run # 40
Initial state: 0 0.0995726 0.00754731 0.0342571 0.292129 0.840311 0.285475 0.547477 0.680142 0.411548 0.419093 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89032 episodes
GETTING ACTION FROM:
action 4, numVisits=89006, meanQ=33.332152, numObservations: 9
action -1, numVisits=6, meanQ=-1.010000, numObservations: 6
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 5, numVisits=11, meanQ=-4.455455, numObservations: 6
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.0995726 0.00754731 0.0342571 0.292129 0.840311 0.285475 0.547477 0.680142 0.411548 0.419093 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 41
Initial state: 0 0.312245 0.067594 0.900466 0.470053 0.939561 0.222519 0.505981 0.479227 0.100073 0.193052 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89937 episodes
GETTING ACTION FROM:
action 2, numVisits=89920, meanQ=33.056458, numObservations: 9
action 1, numVisits=12, meanQ=14.000000, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.312245 0.067594 0.900466 0.470053 0.939561 0.222519 0.505981 0.479227 0.100073 0.193052 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 42
Initial state: 0 0.23387 0.880747 0.410894 0.438043 0.751047 0.367032 0.987878 0.644841 0.0233413 0.88906 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88829 episodes
GETTING ACTION FROM:
action 1, numVisits=88820, meanQ=31.785941, numObservations: 9
action 5, numVisits=4, meanQ=18.502500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.23387 0.880747 0.410894 0.438043 0.751047 0.367032 0.987878 0.644841 0.0233413 0.88906 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 43
Initial state: 0 0.567875 0.381094 0.175627 0.376964 0.698473 0.0245134 0.343345 0.869231 0.951378 0.677795 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48227 episodes
GETTING ACTION FROM:
action 0, numVisits=48209, meanQ=61.783866, numObservations: 243
action -1, numVisits=13, meanQ=-1.163069, numObservations: 12
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.567875 0.381094 0.175627 0.376964 0.698473 0.0245134 0.343345 0.869231 0.951378 0.677795 w: 1
Observation: 0 0 2 0 2 0 1 0 3 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=181, meanQ=64.985544, numObservations: 9
action 4, numVisits=4, meanQ=21.747500, numObservations: 2
action 5, numVisits=5, meanQ=19.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 100486 episodes
GETTING ACTION FROM:
action 2, numVisits=100667, meanQ=64.661266, numObservations: 9
action 4, numVisits=4, meanQ=21.747500, numObservations: 2
action 5, numVisits=5, meanQ=19.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 2
Next state: 0 0.567875 0.381094 0.175627 0.376964 0.698473 0.0245134 0.343345 0.869231 0.951378 0.677795 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=6311, meanQ=88.028690, numObservations: 9
action 5, numVisits=2, meanQ=44.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 65138 episodes
GETTING ACTION FROM:
action 1, numVisits=71449, meanQ=77.914386, numObservations: 9
action 5, numVisits=2, meanQ=44.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.567875 0.381094 0.175627 0.376964 0.698473 0.0245134 0.343345 0.869231 0.951378 0.677795 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 84.1399
Run # 44
Initial state: 0 0.216051 0.347598 0.705372 0.139514 0.330978 0.136727 0.412553 0.488831 0.0616286 0.0923909 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49006 episodes
GETTING ACTION FROM:
action -1, numVisits=48960, meanQ=50.346256, numObservations: 243
action 0, numVisits=38, meanQ=-3.667368, numObservations: 37
action 2, numVisits=4, meanQ=-6.000000, numObservations: 4
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.216051 0.347598 0.705372 0.139514 0.330978 0.136727 0.412553 0.488831 0.0616286 0.0923909 w: 1
Observation: 0 1 0 3 0 1 0 2 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=235, meanQ=74.126140, numObservations: 9
action 3, numVisits=2, meanQ=44.495000, numObservations: 2
action 2, numVisits=3, meanQ=32.333333, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 112894 episodes
GETTING ACTION FROM:
action 4, numVisits=113129, meanQ=87.369279, numObservations: 9
action 3, numVisits=2, meanQ=44.495000, numObservations: 2
action 2, numVisits=3, meanQ=32.333333, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 4
Next state: 1 0.216051 0.347598 0.705372 0.139514 0.330978 0.136727 0.412553 0.488831 0.0616286 0.0923909 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 45
Initial state: 0 0.403566 0.479284 0.824705 0.217853 0.731073 0.92846 0.849635 0.19296 0.157459 0.829033 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88966 episodes
GETTING ACTION FROM:
action 1, numVisits=88943, meanQ=32.181497, numObservations: 9
action -1, numVisits=6, meanQ=-1.010000, numObservations: 6
action 0, numVisits=6, meanQ=-1.341650, numObservations: 5
action 3, numVisits=8, meanQ=-3.624987, numObservations: 3
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.403566 0.479284 0.824705 0.217853 0.731073 0.92846 0.849635 0.19296 0.157459 0.829033 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 46
Initial state: 0 0.901537 0.689996 0.564778 0.979664 0.566693 0.378826 0.318803 0.427673 0.243961 0.703419 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89199 episodes
GETTING ACTION FROM:
action 1, numVisits=89180, meanQ=32.284679, numObservations: 9
action 4, numVisits=11, meanQ=13.726364, numObservations: 6
action 5, numVisits=4, meanQ=-1.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.901537 0.689996 0.564778 0.979664 0.566693 0.378826 0.318803 0.427673 0.243961 0.703419 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 47
Initial state: 0 0.126244 0.0251804 0.570548 0.193526 0.540077 0.381042 0.598491 0.188419 0.240017 0.387972 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 82605 episodes
GETTING ACTION FROM:
action 2, numVisits=82592, meanQ=32.831178, numObservations: 9
action 3, numVisits=4, meanQ=16.500000, numObservations: 4
action 5, numVisits=5, meanQ=13.018020, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.126244 0.0251804 0.570548 0.193526 0.540077 0.381042 0.598491 0.188419 0.240017 0.387972 w: 1
Observation: 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 48
Initial state: 0 0.471988 0.443649 0.413881 0.295372 0.687287 0.156273 0.659866 0.480097 0.990019 0.469266 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 90411 episodes
GETTING ACTION FROM:
action 4, numVisits=90388, meanQ=32.875246, numObservations: 9
action 2, numVisits=15, meanQ=23.864667, numObservations: 7
action 3, numVisits=4, meanQ=21.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.471988 0.443649 0.413881 0.295372 0.687287 0.156273 0.659866 0.480097 0.990019 0.469266 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 49
Initial state: 0 0.787755 0.084549 0.264757 0.324677 0.463147 0.36341 0.481577 0.984829 0.86142 0.947106 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 84316 episodes
GETTING ACTION FROM:
action 3, numVisits=84303, meanQ=34.000174, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action 5, numVisits=5, meanQ=-4.998000, numObservations: 4
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.787755 0.084549 0.264757 0.324677 0.463147 0.36341 0.481577 0.984829 0.86142 0.947106 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 50
Initial state: 0 0.788726 0.474648 0.393862 0.535663 0.533737 0.448147 0.155375 0.830915 0.737764 0.231144 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 82009 episodes
GETTING ACTION FROM:
action 4, numVisits=82002, meanQ=34.368491, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.788726 0.474648 0.393862 0.535663 0.533737 0.448147 0.155375 0.830915 0.737764 0.231144 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 51
Initial state: 0 0.974115 0.337822 0.96424 0.487599 0.839369 0.026592 0.723623 0.899406 0.501378 0.389517 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 84336 episodes
GETTING ACTION FROM:
action 1, numVisits=84330, meanQ=35.001761, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.974115 0.337822 0.96424 0.487599 0.839369 0.026592 0.723623 0.899406 0.501378 0.389517 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 52
Initial state: 0 0.412822 0.418741 0.522273 0.273083 0.729242 0.712128 0.231756 0.29286 0.911565 0.176941 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89189 episodes
GETTING ACTION FROM:
action 4, numVisits=89155, meanQ=32.360641, numObservations: 9
action 2, numVisits=26, meanQ=8.268081, numObservations: 8
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.412822 0.418741 0.522273 0.273083 0.729242 0.712128 0.231756 0.29286 0.911565 0.176941 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=8154, meanQ=36.136038, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 20784 episodes
GETTING ACTION FROM:
action 5, numVisits=28938, meanQ=37.521650, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.412822 0.418741 0.522273 0.273083 0.729242 0.712128 0.231756 0.29286 0.911565 0.176941 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -110.99
Run # 53
Initial state: 0 0.559753 0.403136 0.273081 0.870006 0.128677 0.391339 0.575529 0.261861 0.772949 0.840172 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87155 episodes
GETTING ACTION FROM:
action 5, numVisits=87142, meanQ=32.641519, numObservations: 9
action 3, numVisits=8, meanQ=21.623750, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.559753 0.403136 0.273081 0.870006 0.128677 0.391339 0.575529 0.261861 0.772949 0.840172 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 54
Initial state: 0 0.895557 0.11214 0.418153 0.449422 0.835855 0.455373 0.923697 0.343638 0.276112 0.0364207 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88961 episodes
GETTING ACTION FROM:
action 1, numVisits=88929, meanQ=32.352356, numObservations: 9
action 2, numVisits=15, meanQ=9.198000, numObservations: 7
action 5, numVisits=13, meanQ=3.691538, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.895557 0.11214 0.418153 0.449422 0.835855 0.455373 0.923697 0.343638 0.276112 0.0364207 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 55
Initial state: 0 0.35392 0.639877 0.520585 0.62008 0.851761 0.29071 0.512089 0.777416 0.45671 0.487778 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89039 episodes
GETTING ACTION FROM:
action 3, numVisits=89023, meanQ=33.050697, numObservations: 9
action 2, numVisits=11, meanQ=13.546364, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.35392 0.639877 0.520585 0.62008 0.851761 0.29071 0.512089 0.777416 0.45671 0.487778 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 56
Initial state: 0 0.400641 0.744946 0.904137 0.825833 0.406032 0.391388 0.978198 0.948014 0.0733135 0.0686508 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88025 episodes
GETTING ACTION FROM:
action 3, numVisits=88014, meanQ=33.047302, numObservations: 9
action 2, numVisits=6, meanQ=27.348350, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.400641 0.744946 0.904137 0.825833 0.406032 0.391388 0.978198 0.948014 0.0733135 0.0686508 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 57
Initial state: 0 0.0838719 0.430093 0.0851472 0.442766 0.79555 0.410975 0.677038 0.624646 0.558241 0.452504 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88292 episodes
GETTING ACTION FROM:
action 1, numVisits=88266, meanQ=31.837970, numObservations: 9
action 2, numVisits=18, meanQ=28.943889, numObservations: 9
action 3, numVisits=4, meanQ=21.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.0838719 0.430093 0.0851472 0.442766 0.79555 0.410975 0.677038 0.624646 0.558241 0.452504 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 58
Initial state: 0 0.256862 0.968927 0.808493 0.0103482 0.438453 0.602288 0.525824 0.465665 0.475822 0.124238 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 77467 episodes
GETTING ACTION FROM:
action 5, numVisits=77461, meanQ=36.502545, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.256862 0.968927 0.808493 0.0103482 0.438453 0.602288 0.525824 0.465665 0.475822 0.124238 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 59
Initial state: 0 0.312137 0.8441 0.188705 0.289722 0.275255 0.507801 0.421834 0.396738 0.0282824 0.599881 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 83819 episodes
GETTING ACTION FROM:
action 5, numVisits=83809, meanQ=33.334103, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.312137 0.8441 0.188705 0.289722 0.275255 0.507801 0.421834 0.396738 0.0282824 0.599881 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 60
Initial state: 0 0.505914 0.453824 0.462179 0.633627 0.00683813 0.0859556 0.908316 0.823329 0.980379 0.740375 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 85397 episodes
GETTING ACTION FROM:
action 1, numVisits=85376, meanQ=33.853606, numObservations: 9
action 5, numVisits=14, meanQ=0.362879, numObservations: 6
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.505914 0.453824 0.462179 0.633627 0.00683813 0.0859556 0.908316 0.823329 0.980379 0.740375 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 61
Initial state: 0 0.413207 0.674237 0.493938 0.415364 0.6687 0.131077 0.579576 0.545074 0.162136 0.553511 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89453 episodes
GETTING ACTION FROM:
action 1, numVisits=89445, meanQ=31.765272, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 3
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.413207 0.674237 0.493938 0.415364 0.6687 0.131077 0.579576 0.545074 0.162136 0.553511 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 62
Initial state: 0 0.830326 0.220297 0.852277 0.652934 0.287432 0.997888 0.929382 0.831398 0.437715 0.415375 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89184 episodes
GETTING ACTION FROM:
action 1, numVisits=89152, meanQ=32.169735, numObservations: 9
action 4, numVisits=18, meanQ=11.665578, numObservations: 7
action 2, numVisits=10, meanQ=8.099000, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.830326 0.220297 0.852277 0.652934 0.287432 0.997888 0.929382 0.831398 0.437715 0.415375 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 63
Initial state: 0 0.431748 0.0215643 0.878038 0.00439446 0.368219 0.640967 0.469188 0.477452 0.246709 0.0798602 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89600 episodes
GETTING ACTION FROM:
action 2, numVisits=89549, meanQ=32.225728, numObservations: 9
action 1, numVisits=8, meanQ=24.000000, numObservations: 5
action 4, numVisits=39, meanQ=23.385649, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.431748 0.0215643 0.878038 0.00439446 0.368219 0.640967 0.469188 0.477452 0.246709 0.0798602 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 64
Initial state: 0 0.244838 0.593416 0.764031 0.519209 0.146651 0.00237262 0.260476 0.934022 0.447225 0.383011 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 86427 episodes
GETTING ACTION FROM:
action 2, numVisits=86402, meanQ=31.222525, numObservations: 9
action 5, numVisits=18, meanQ=0.676128, numObservations: 7
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.244838 0.593416 0.764031 0.519209 0.146651 0.00237262 0.260476 0.934022 0.447225 0.383011 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 65
Initial state: 0 0.88155 0.897435 0.978188 0.131095 0.443901 0.467289 0.207198 0.14305 0.623936 0.374943 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87374 episodes
GETTING ACTION FROM:
action 2, numVisits=87333, meanQ=32.755356, numObservations: 9
action 4, numVisits=35, meanQ=12.257154, numObservations: 8
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.88155 0.897435 0.978188 0.131095 0.443901 0.467289 0.207198 0.14305 0.623936 0.374943 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 66
Initial state: 0 0.596879 0.399745 0.705192 0.445213 0.49083 0.865109 0.460534 0.370619 0.755262 0.517052 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49113 episodes
GETTING ACTION FROM:
action -1, numVisits=49040, meanQ=51.058592, numObservations: 243
action 2, numVisits=46, meanQ=-1.084778, numObservations: 9
action 0, numVisits=17, meanQ=-1.651171, numObservations: 16
action 5, numVisits=7, meanQ=-2.428571, numObservations: 4
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.596879 0.399745 0.705192 0.445213 0.49083 0.865109 0.460534 0.370619 0.755262 0.517052 w: 1
Observation: 0 1 0 3 0 2 0 2 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=239, meanQ=41.599460, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 100258 episodes
GETTING ACTION FROM:
action 3, numVisits=100497, meanQ=61.959479, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 3
Next state: 1 0.596879 0.399745 0.705192 0.445213 0.49083 0.865109 0.460534 0.370619 0.755262 0.517052 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 67
Initial state: 0 0.442119 0.0451817 0.337847 0.605839 0.408374 0.486739 0.438923 0.682132 0.790446 0.193334 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 84155 episodes
GETTING ACTION FROM:
action 4, numVisits=84144, meanQ=34.535154, numObservations: 9
action 2, numVisits=6, meanQ=9.180017, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.442119 0.0451817 0.337847 0.605839 0.408374 0.486739 0.438923 0.682132 0.790446 0.193334 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 68
Initial state: 0 0.854513 0.382494 0.994704 0.846309 0.673217 0.395441 0.518155 0.420527 0.959845 0.685164 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88866 episodes
GETTING ACTION FROM:
action 1, numVisits=88855, meanQ=31.131019, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=4, meanQ=-5.752500, numObservations: 3
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.854513 0.382494 0.994704 0.846309 0.673217 0.395441 0.518155 0.420527 0.959845 0.685164 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 69
Initial state: 0 0.506853 0.418698 0.619473 0.423463 0.81673 0.353503 0.139652 0.422081 0.889843 0.702531 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 82692 episodes
GETTING ACTION FROM:
action 1, numVisits=82680, meanQ=35.171871, numObservations: 9
action 4, numVisits=7, meanQ=10.428571, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.506853 0.418698 0.619473 0.423463 0.81673 0.353503 0.139652 0.422081 0.889843 0.702531 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 70
Initial state: 0 0.573876 0.375083 0.296161 0.160705 0.850092 0.719522 0.878978 0.78996 0.373269 0.487351 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 84665 episodes
GETTING ACTION FROM:
action 1, numVisits=84653, meanQ=33.692037, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=7, meanQ=-2.428571, numObservations: 4
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.573876 0.375083 0.296161 0.160705 0.850092 0.719522 0.878978 0.78996 0.373269 0.487351 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 71
Initial state: 0 0.110759 0.633202 0.697142 0.214188 0.699811 0.360745 0.946136 0.447225 0.493476 0.40406 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89108 episodes
GETTING ACTION FROM:
action 1, numVisits=89101, meanQ=32.526364, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.110759 0.633202 0.697142 0.214188 0.699811 0.360745 0.946136 0.447225 0.493476 0.40406 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 72
Initial state: 0 0.144953 0.601614 0.175194 0.753197 0.808738 0.812368 0.562796 0.403881 0.250847 0.37825 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89641 episodes
GETTING ACTION FROM:
action 5, numVisits=89615, meanQ=32.121177, numObservations: 9
action 1, numVisits=20, meanQ=15.454015, numObservations: 7
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.144953 0.601614 0.175194 0.753197 0.808738 0.812368 0.562796 0.403881 0.250847 0.37825 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 73
Initial state: 0 0.527789 0.389694 0.869578 0.774183 0.767103 0.73974 0.15398 0.720679 0.709628 0.332701 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89130 episodes
GETTING ACTION FROM:
action 1, numVisits=89107, meanQ=32.810397, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 5, numVisits=16, meanQ=-4.563125, numObservations: 9
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.527789 0.389694 0.869578 0.774183 0.767103 0.73974 0.15398 0.720679 0.709628 0.332701 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 74
Initial state: 0 0.546387 0.61922 0.832304 0.576474 0.415164 0.430791 0.88995 0.615526 0.376688 0.523369 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89131 episodes
GETTING ACTION FROM:
action 2, numVisits=89119, meanQ=33.076851, numObservations: 9
action 1, numVisits=3, meanQ=25.666667, numObservations: 3
action 3, numVisits=3, meanQ=22.363367, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=3, meanQ=-4.333333, numObservations: 2
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.546387 0.61922 0.832304 0.576474 0.415164 0.430791 0.88995 0.615526 0.376688 0.523369 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 75
Initial state: 0 0.494352 0.39877 0.0502821 0.25753 0.335397 0.756809 0.0624649 0.466934 0.283058 0.255342 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87848 episodes
GETTING ACTION FROM:
action 5, numVisits=87842, meanQ=33.024718, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.494352 0.39877 0.0502821 0.25753 0.335397 0.756809 0.0624649 0.466934 0.283058 0.255342 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=7717, meanQ=36.150783, numObservations: 9
action 4, numVisits=3, meanQ=26.326667, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 26668 episodes
GETTING ACTION FROM:
action 3, numVisits=34385, meanQ=36.215756, numObservations: 9
action 4, numVisits=3, meanQ=26.326667, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 3
Next state: 0 0.494352 0.39877 0.0502821 0.25753 0.335397 0.756809 0.0624649 0.466934 0.283058 0.255342 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=2544, meanQ=58.813020, numObservations: 9
action 1, numVisits=13, meanQ=27.690000, numObservations: 8
action 2, numVisits=4, meanQ=21.747500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 39797 episodes
GETTING ACTION FROM:
action 4, numVisits=42341, meanQ=64.604185, numObservations: 9
action 1, numVisits=13, meanQ=27.690000, numObservations: 8
action 2, numVisits=4, meanQ=21.747500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 4
Next state: 0 0.494352 0.39877 0.0502821 0.25753 0.335397 0.756809 0.0624649 0.466934 0.283058 0.255342 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=1667, meanQ=82.743977, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 56600 episodes
GETTING ACTION FROM:
action 1, numVisits=58267, meanQ=69.533737, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.494352 0.39877 0.0502821 0.25753 0.335397 0.756809 0.0624649 0.466934 0.283058 0.255342 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 63.3885
Run # 76
Initial state: 0 0.539923 0.41111 0.0741293 0.961228 0.626285 0.924471 0.274378 0.540134 0.384404 0.335283 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 84315 episodes
GETTING ACTION FROM:
action 1, numVisits=84309, meanQ=34.157968, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.539923 0.41111 0.0741293 0.961228 0.626285 0.924471 0.274378 0.540134 0.384404 0.335283 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 77
Initial state: 0 0.512808 0.487776 0.215836 0.581918 0.614397 0.203593 0.0588417 0.0802228 0.47251 0.965585 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 83030 episodes
GETTING ACTION FROM:
action 1, numVisits=83007, meanQ=33.819545, numObservations: 9
action 5, numVisits=7, meanQ=23.568571, numObservations: 5
action 4, numVisits=8, meanQ=21.623750, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.512808 0.487776 0.215836 0.581918 0.614397 0.203593 0.0588417 0.0802228 0.47251 0.965585 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 78
Initial state: 0 0.598965 0.691502 0.0510379 0.953021 0.898269 0.938159 0.412796 0.139013 0.519786 0.363603 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89328 episodes
GETTING ACTION FROM:
action 5, numVisits=89296, meanQ=32.634923, numObservations: 9
action 2, numVisits=15, meanQ=29.600007, numObservations: 5
action 3, numVisits=13, meanQ=24.550785, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.598965 0.691502 0.0510379 0.953021 0.898269 0.938159 0.412796 0.139013 0.519786 0.363603 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 79
Initial state: 0 0.496147 0.446136 0.777134 0.387567 0.102523 0.286044 0.0985241 0.682235 0.976116 0.722764 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49413 episodes
GETTING ACTION FROM:
action 0, numVisits=49375, meanQ=63.751105, numObservations: 243
action -1, numVisits=19, meanQ=-1.583679, numObservations: 18
action 1, numVisits=3, meanQ=-4.003333, numObservations: 3
action 5, numVisits=3, meanQ=-4.333333, numObservations: 2
action 4, numVisits=11, meanQ=-6.356355, numObservations: 7
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.496147 0.446136 0.777134 0.387567 0.102523 0.286044 0.0985241 0.682235 0.976116 0.722764 w: 1
Observation: 0 0 2 0 1 0 1 0 3 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=307, meanQ=79.070980, numObservations: 9
action 5, numVisits=2, meanQ=44.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 110044 episodes
GETTING ACTION FROM:
action 1, numVisits=110351, meanQ=88.480208, numObservations: 9
action 5, numVisits=2, meanQ=44.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.496147 0.446136 0.777134 0.387567 0.102523 0.286044 0.0985241 0.682235 0.976116 0.722764 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 80
Initial state: 0 0.248251 0.645664 0.878825 0.706321 0.940976 0.051739 0.272218 0.0858456 0.445994 0.389672 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49175 episodes
GETTING ACTION FROM:
action -1, numVisits=49141, meanQ=50.196370, numObservations: 243
action 0, numVisits=24, meanQ=-1.010000, numObservations: 24
action 1, numVisits=6, meanQ=-4.333333, numObservations: 5
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.248251 0.645664 0.878825 0.706321 0.940976 0.051739 0.272218 0.0858456 0.445994 0.389672 w: 1
Observation: 0 1 0 3 0 2 0 1 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=213, meanQ=6.269297, numObservations: 8
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action -1, numVisits=4, meanQ=-1.507475, numObservations: 3
action 1, numVisits=3, meanQ=-4.003333, numObservations: 2
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 113926 episodes
GETTING ACTION FROM:
action 2, numVisits=114139, meanQ=11.449130, numObservations: 9
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action -1, numVisits=4, meanQ=-1.507475, numObservations: 3
action 1, numVisits=3, meanQ=-4.003333, numObservations: 2
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 2
Next state: 1 0.248251 0.645664 0.878825 0.706321 0.940976 0.051739 0.272218 0.0858456 0.445994 0.389672 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 81
Initial state: 0 0.783274 0.284614 0.65036 0.935149 0.453104 0.702402 0.574615 0.421144 0.28524 0.717718 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 86957 episodes
GETTING ACTION FROM:
action 1, numVisits=86951, meanQ=31.854599, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.783274 0.284614 0.65036 0.935149 0.453104 0.702402 0.574615 0.421144 0.28524 0.717718 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 82
Initial state: 0 0.335654 0.909001 0.115425 0.45042 0.187809 0.546233 0.423564 0.411204 0.641187 0.303336 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87449 episodes
GETTING ACTION FROM:
action 3, numVisits=87433, meanQ=33.772182, numObservations: 9
action 4, numVisits=6, meanQ=10.996667, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=5, meanQ=-3.000000, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.335654 0.909001 0.115425 0.45042 0.187809 0.546233 0.423564 0.411204 0.641187 0.303336 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=8879, meanQ=40.725607, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=3, meanQ=-4.003333, numObservations: 3
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 95858 episodes
GETTING ACTION FROM:
action 1, numVisits=104737, meanQ=48.021124, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=3, meanQ=-4.003333, numObservations: 3
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.335654 0.909001 0.115425 0.45042 0.187809 0.546233 0.423564 0.411204 0.641187 0.303336 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 0, numVisits=455, meanQ=41.978199, numObservations: 119
action -1, numVisits=8, meanQ=-1.258737, numObservations: 7
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=3, meanQ=-34.333333, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 39248 episodes
GETTING ACTION FROM:
action 0, numVisits=39703, meanQ=4.773416, numObservations: 243
action -1, numVisits=8, meanQ=-1.258737, numObservations: 7
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=3, meanQ=-34.333333, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.335654 0.909001 0.115425 0.45042 0.187809 0.546233 0.423564 0.411204 0.641187 0.303336 w: 1
Observation: 0 0 3 0 2 0 3 0 1 0 3 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=230, meanQ=85.031012, numObservations: 9
action 3, numVisits=4, meanQ=41.770025, numObservations: 1
action 5, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 109579 episodes
GETTING ACTION FROM:
action 2, numVisits=109809, meanQ=91.599302, numObservations: 9
action 3, numVisits=4, meanQ=41.770025, numObservations: 1
action 5, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 2
Next state: 2 0.335654 0.909001 0.115425 0.45042 0.187809 0.546233 0.423564 0.411204 0.641187 0.303336 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -121.85
Run # 83
Initial state: 0 0.923499 0.940929 0.385881 0.800498 0.478545 0.448025 0.926261 0.252409 0.262169 0.910164 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 83453 episodes
GETTING ACTION FROM:
action 1, numVisits=83431, meanQ=33.859432, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 4, numVisits=9, meanQ=-2.111111, numObservations: 5
action 3, numVisits=3, meanQ=-4.003333, numObservations: 3
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.923499 0.940929 0.385881 0.800498 0.478545 0.448025 0.926261 0.252409 0.262169 0.910164 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 84
Initial state: 0 0.415848 0.680695 0.353131 0.912423 0.929004 0.0365648 0.950359 0.720186 0.462046 0.380475 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87611 episodes
GETTING ACTION FROM:
action 4, numVisits=87451, meanQ=31.826546, numObservations: 9
action 3, numVisits=148, meanQ=26.322656, numObservations: 9
action 5, numVisits=4, meanQ=21.747500, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 4
Next state: 1 0.415848 0.680695 0.353131 0.912423 0.929004 0.0365648 0.950359 0.720186 0.462046 0.380475 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 85
Initial state: 0 0.286178 0.384287 0.177156 0.0973811 0.211299 0.490148 0.474636 0.315462 0.442329 0.42202 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 84428 episodes
GETTING ACTION FROM:
action 5, numVisits=84410, meanQ=34.925666, numObservations: 9
action 2, numVisits=9, meanQ=30.221111, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action 3, numVisits=3, meanQ=-4.333333, numObservations: 3
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.286178 0.384287 0.177156 0.0973811 0.211299 0.490148 0.474636 0.315462 0.442329 0.42202 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 86
Initial state: 0 0.984822 0.968365 0.0787414 0.535412 0.241474 0.0973551 0.191947 0.564688 0.515946 0.39701 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79803 episodes
GETTING ACTION FROM:
action 4, numVisits=79776, meanQ=34.629619, numObservations: 9
action 5, numVisits=15, meanQ=16.332673, numObservations: 7
action 1, numVisits=6, meanQ=14.000000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.984822 0.968365 0.0787414 0.535412 0.241474 0.0973551 0.191947 0.564688 0.515946 0.39701 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=8036, meanQ=51.667326, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 68880 episodes
GETTING ACTION FROM:
action 4, numVisits=76916, meanQ=64.165414, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.984822 0.968365 0.0787414 0.535412 0.241474 0.0973551 0.191947 0.564688 0.515946 0.39701 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=27169, meanQ=53.578562, numObservations: 9
action 3, numVisits=8, meanQ=21.747500, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 85435 episodes
GETTING ACTION FROM:
action 4, numVisits=112604, meanQ=71.422848, numObservations: 9
action 3, numVisits=8, meanQ=21.747500, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 4
Next state: 0 0.984822 0.968365 0.0787414 0.535412 0.241474 0.0973551 0.191947 0.564688 0.515946 0.39701 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=38078, meanQ=48.194601, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 108034 episodes
GETTING ACTION FROM:
action 1, numVisits=146112, meanQ=53.589077, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.984822 0.968365 0.0787414 0.535412 0.241474 0.0973551 0.191947 0.564688 0.515946 0.39701 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 63.3885
Run # 87
Initial state: 0 0.554776 0.444697 0.99351 0.813459 0.705955 0.38633 0.811414 0.202986 0.765023 0.269121 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 85000 episodes
GETTING ACTION FROM:
action 4, numVisits=84979, meanQ=34.888538, numObservations: 9
action 1, numVisits=5, meanQ=19.000000, numObservations: 3
action 5, numVisits=5, meanQ=19.000000, numObservations: 4
action 3, numVisits=4, meanQ=16.747500, numObservations: 3
action 2, numVisits=5, meanQ=15.198000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 4
Next state: 2 0.554776 0.444697 0.99351 0.813459 0.705955 0.38633 0.811414 0.202986 0.765023 0.269121 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 88
Initial state: 0 0.64444 0.0146832 0.245722 0.922262 0.909767 0.0775332 0.454384 0.396915 0.238589 0.382347 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88551 episodes
GETTING ACTION FROM:
action 3, numVisits=88539, meanQ=31.920738, numObservations: 9
action 2, numVisits=3, meanQ=25.666667, numObservations: 2
action 4, numVisits=5, meanQ=15.000000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.64444 0.0146832 0.245722 0.922262 0.909767 0.0775332 0.454384 0.396915 0.238589 0.382347 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 89
Initial state: 0 0.137606 0.970726 0.121272 0.585419 0.965261 0.26187 0.137226 0.60945 0.514351 0.372841 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 83955 episodes
GETTING ACTION FROM:
action 5, numVisits=83948, meanQ=34.867101, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.137606 0.970726 0.121272 0.585419 0.965261 0.26187 0.137226 0.60945 0.514351 0.372841 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 90
Initial state: 0 0.199087 0.66542 0.873725 0.832153 0.248844 0.0517093 0.819024 0.50068 0.494001 0.367568 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89386 episodes
GETTING ACTION FROM:
action 3, numVisits=89379, meanQ=32.369789, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.199087 0.66542 0.873725 0.832153 0.248844 0.0517093 0.819024 0.50068 0.494001 0.367568 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=8189, meanQ=38.602481, numObservations: 9
action 2, numVisits=5, meanQ=19.000000, numObservations: 4
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 27103 episodes
GETTING ACTION FROM:
action 1, numVisits=35292, meanQ=31.499488, numObservations: 9
action 2, numVisits=5, meanQ=19.000000, numObservations: 4
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.199087 0.66542 0.873725 0.832153 0.248844 0.0517093 0.819024 0.50068 0.494001 0.367568 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=2576, meanQ=48.520869, numObservations: 9
action 2, numVisits=6, meanQ=9.013367, numObservations: 4
action 1, numVisits=6, meanQ=7.680017, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 36831 episodes
GETTING ACTION FROM:
action 5, numVisits=39407, meanQ=53.617364, numObservations: 9
action 2, numVisits=6, meanQ=9.013367, numObservations: 4
action 1, numVisits=6, meanQ=7.680017, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 5
Next state: 1 0.199087 0.66542 0.873725 0.832153 0.248844 0.0517093 0.819024 0.50068 0.494001 0.367568 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 75.1399
Run # 91
Initial state: 0 0.738602 0.384468 0.587239 0.803956 0.493502 0.448277 0.916056 0.86765 0.703299 0.782294 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89255 episodes
GETTING ACTION FROM:
action 2, numVisits=89246, meanQ=32.949799, numObservations: 9
action 1, numVisits=4, meanQ=21.500000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.738602 0.384468 0.587239 0.803956 0.493502 0.448277 0.916056 0.86765 0.703299 0.782294 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 92
Initial state: 0 0.570492 0.359605 0.125647 0.670089 0.133295 0.655468 0.197587 0.830534 0.971457 0.860474 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89830 episodes
GETTING ACTION FROM:
action 2, numVisits=89814, meanQ=32.422188, numObservations: 9
action 1, numVisits=10, meanQ=3.999010, numObservations: 6
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.570492 0.359605 0.125647 0.670089 0.133295 0.655468 0.197587 0.830534 0.971457 0.860474 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 93
Initial state: 0 0.32533 0.53388 0.373219 0.0649533 0.563479 0.419541 0.92812 0.897815 0.217655 0.850698 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89224 episodes
GETTING ACTION FROM:
action 5, numVisits=89201, meanQ=32.570041, numObservations: 9
action 4, numVisits=5, meanQ=15.000000, numObservations: 4
action 1, numVisits=13, meanQ=13.615385, numObservations: 6
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.32533 0.53388 0.373219 0.0649533 0.563479 0.419541 0.92812 0.897815 0.217655 0.850698 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=9140, meanQ=35.846912, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 100832 episodes
GETTING ACTION FROM:
action 2, numVisits=109972, meanQ=39.393585, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 2
Next state: 0 0.32533 0.53388 0.373219 0.0649533 0.563479 0.419541 0.92812 0.897815 0.217655 0.850698 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=5532, meanQ=55.589340, numObservations: 9
action 5, numVisits=3, meanQ=25.663367, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 49965 episodes
GETTING ACTION FROM:
action 4, numVisits=55497, meanQ=45.624851, numObservations: 9
action 5, numVisits=3, meanQ=25.663367, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.32533 0.53388 0.373219 0.0649533 0.563479 0.419541 0.92812 0.897815 0.217655 0.850698 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 75.1399
Run # 94
Initial state: 0 0.245556 0.503217 0.276463 0.204263 0.448039 0.386617 0.0193298 0.752458 0.819749 0.320052 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87410 episodes
GETTING ACTION FROM:
action 1, numVisits=87374, meanQ=32.609995, numObservations: 9
action 3, numVisits=25, meanQ=16.999204, numObservations: 9
action 5, numVisits=7, meanQ=13.285714, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.245556 0.503217 0.276463 0.204263 0.448039 0.386617 0.0193298 0.752458 0.819749 0.320052 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=8901, meanQ=38.296779, numObservations: 9
action 5, numVisits=8, meanQ=21.747500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 94799 episodes
GETTING ACTION FROM:
action 4, numVisits=103700, meanQ=44.354110, numObservations: 9
action 5, numVisits=8, meanQ=21.747500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 4
Next state: 1 0.245556 0.503217 0.276463 0.204263 0.448039 0.386617 0.0193298 0.752458 0.819749 0.320052 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 95
Initial state: 0 0.442151 0.0764562 0.550091 0.681512 0.736919 0.419157 0.328866 0.772283 0.498783 0.477478 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88907 episodes
GETTING ACTION FROM:
action 4, numVisits=88900, meanQ=33.133807, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.442151 0.0764562 0.550091 0.681512 0.736919 0.419157 0.328866 0.772283 0.498783 0.477478 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=9068, meanQ=38.813851, numObservations: 9
action 5, numVisits=4, meanQ=21.747500, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 98276 episodes
GETTING ACTION FROM:
action 2, numVisits=107344, meanQ=43.698731, numObservations: 9
action 5, numVisits=4, meanQ=21.747500, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.442151 0.0764562 0.550091 0.681512 0.736919 0.419157 0.328866 0.772283 0.498783 0.477478 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 96
Initial state: 0 0.318203 0.456807 0.000491745 0.877346 0.419063 0.18515 0.46194 0.409815 0.480149 0.667299 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 85688 episodes
GETTING ACTION FROM:
action 2, numVisits=85678, meanQ=34.387709, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=5, meanQ=-3.000000, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.318203 0.456807 0.000491745 0.877346 0.419063 0.18515 0.46194 0.409815 0.480149 0.667299 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=8737, meanQ=47.094488, numObservations: 9
action 5, numVisits=5, meanQ=37.198000, numObservations: 4
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 76709 episodes
GETTING ACTION FROM:
action 2, numVisits=85446, meanQ=60.482389, numObservations: 9
action 5, numVisits=5, meanQ=37.198000, numObservations: 4
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.318203 0.456807 0.000491745 0.877346 0.419063 0.18515 0.46194 0.409815 0.480149 0.667299 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 97
Initial state: 0 0.398629 0.729365 0.0296334 0.818505 0.0701972 0.326627 0.491596 0.423072 0.275794 0.490101 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 83599 episodes
GETTING ACTION FROM:
action 3, numVisits=83588, meanQ=34.664670, numObservations: 9
action 4, numVisits=6, meanQ=9.015017, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.398629 0.729365 0.0296334 0.818505 0.0701972 0.326627 0.491596 0.423072 0.275794 0.490101 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=7561, meanQ=36.818226, numObservations: 9
action 1, numVisits=12, meanQ=23.249167, numObservations: 5
action 2, numVisits=4, meanQ=21.747500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 29599 episodes
GETTING ACTION FROM:
action 5, numVisits=37160, meanQ=30.138800, numObservations: 9
action 1, numVisits=12, meanQ=23.249167, numObservations: 5
action 2, numVisits=4, meanQ=21.747500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 5
Next state: 0 0.398629 0.729365 0.0296334 0.818505 0.0701972 0.326627 0.491596 0.423072 0.275794 0.490101 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=2637, meanQ=49.511452, numObservations: 9
action 1, numVisits=26, meanQ=23.344238, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=3, meanQ=-4.003333, numObservations: 3
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 18349 episodes
GETTING ACTION FROM:
action 5, numVisits=20986, meanQ=50.225323, numObservations: 9
action 1, numVisits=26, meanQ=23.344238, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=3, meanQ=-4.003333, numObservations: 3
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.398629 0.729365 0.0296334 0.818505 0.0701972 0.326627 0.491596 0.423072 0.275794 0.490101 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 75.1399
Run # 98
Initial state: 0 0.538997 0.45586 0.845834 0.319751 0.0821437 0.731483 0.851007 0.336118 0.460844 0.980425 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 86983 episodes
GETTING ACTION FROM:
action 2, numVisits=86957, meanQ=33.554235, numObservations: 9
action -1, numVisits=11, meanQ=-1.010000, numObservations: 11
action 0, numVisits=11, meanQ=-1.010000, numObservations: 11
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.538997 0.45586 0.845834 0.319751 0.0821437 0.731483 0.851007 0.336118 0.460844 0.980425 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 99
Initial state: 0 0.44921 0.363051 0.127781 0.563234 0.119533 0.966161 0.394533 0.182039 0.584685 0.00558549 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 84553 episodes
GETTING ACTION FROM:
action 1, numVisits=84547, meanQ=33.643825, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.44921 0.363051 0.127781 0.563234 0.119533 0.966161 0.394533 0.182039 0.584685 0.00558549 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 100
Initial state: 0 0.0253555 0.731031 0.466414 0.415077 0.708714 0.297845 0.249891 0.180511 0.709082 0.526322 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89085 episodes
GETTING ACTION FROM:
action 2, numVisits=89073, meanQ=31.906463, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 3
action 4, numVisits=5, meanQ=-8.998000, numObservations: 4
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.0253555 0.731031 0.466414 0.415077 0.708714 0.297845 0.249891 0.180511 0.709082 0.526322 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 101
Initial state: 0 0.120546 0.623747 0.597334 0.658038 0.917422 0.62964 0.562245 0.400583 0.608915 0.147326 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87673 episodes
GETTING ACTION FROM:
action 1, numVisits=87661, meanQ=32.837504, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=5, meanQ=-3.000000, numObservations: 5
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.120546 0.623747 0.597334 0.658038 0.917422 0.62964 0.562245 0.400583 0.608915 0.147326 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=8863, meanQ=38.587859, numObservations: 9
action -1, numVisits=6, meanQ=-1.010000, numObservations: 6
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=3, meanQ=-34.333333, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 97560 episodes
GETTING ACTION FROM:
action 3, numVisits=106423, meanQ=38.959328, numObservations: 9
action -1, numVisits=6, meanQ=-1.010000, numObservations: 6
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=3, meanQ=-34.333333, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.120546 0.623747 0.597334 0.658038 0.917422 0.62964 0.562245 0.400583 0.608915 0.147326 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 102
Initial state: 0 0.533775 0.483827 0.23513 0.85293 0.0327806 0.433519 0.152201 0.111588 0.00226542 0.841663 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49172 episodes
GETTING ACTION FROM:
action -1, numVisits=49157, meanQ=50.164580, numObservations: 243
action 1, numVisits=3, meanQ=-4.333333, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=8, meanQ=-13.632500, numObservations: 7
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.533775 0.483827 0.23513 0.85293 0.0327806 0.433519 0.152201 0.111588 0.00226542 0.841663 w: 1
Observation: 0 2 0 1 0 1 0 1 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=258, meanQ=78.801967, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 110631 episodes
GETTING ACTION FROM:
action 1, numVisits=110889, meanQ=84.253447, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.533775 0.483827 0.23513 0.85293 0.0327806 0.433519 0.152201 0.111588 0.00226542 0.841663 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 103
Initial state: 0 0.458319 0.0698386 0.131408 0.873967 0.546785 0.379098 0.93182 0.645978 0.167321 0.909977 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 86145 episodes
GETTING ACTION FROM:
action 2, numVisits=86128, meanQ=31.979875, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=10, meanQ=-5.000000, numObservations: 7
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.458319 0.0698386 0.131408 0.873967 0.546785 0.379098 0.93182 0.645978 0.167321 0.909977 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=8652, meanQ=45.221087, numObservations: 9
action 5, numVisits=3, meanQ=32.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 75129 episodes
GETTING ACTION FROM:
action 2, numVisits=83781, meanQ=59.412966, numObservations: 9
action 5, numVisits=3, meanQ=32.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.458319 0.0698386 0.131408 0.873967 0.546785 0.379098 0.93182 0.645978 0.167321 0.909977 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=30168, meanQ=40.075778, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=3, meanQ=-4.003333, numObservations: 2
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 103521 episodes
GETTING ACTION FROM:
action 4, numVisits=133689, meanQ=50.848827, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=3, meanQ=-4.003333, numObservations: 2
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 4
Next state: 1 0.458319 0.0698386 0.131408 0.873967 0.546785 0.379098 0.93182 0.645978 0.167321 0.909977 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 75.1399
Run # 104
Initial state: 0 0.922127 0.87197 0.749826 0.914493 0.780621 0.841617 0.270362 0.637638 0.554961 0.460718 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49547 episodes
GETTING ACTION FROM:
action -1, numVisits=49507, meanQ=50.651491, numObservations: 243
action 0, numVisits=33, meanQ=-1.520600, numObservations: 29
action 5, numVisits=3, meanQ=-4.333333, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.922127 0.87197 0.749826 0.914493 0.780621 0.841617 0.270362 0.637638 0.554961 0.460718 w: 1
Observation: 0 3 0 3 0 3 0 1 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=264, meanQ=80.943524, numObservations: 9
action 4, numVisits=2, meanQ=44.495000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 112816 episodes
GETTING ACTION FROM:
action 5, numVisits=113080, meanQ=84.093749, numObservations: 9
action 4, numVisits=2, meanQ=44.495000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.922127 0.87197 0.749826 0.914493 0.780621 0.841617 0.270362 0.637638 0.554961 0.460718 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 105
Initial state: 0 0.522699 0.0632283 0.459822 0.926247 0.438361 0.381382 0.927492 0.536287 0.772328 0.815487 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 83466 episodes
GETTING ACTION FROM:
action 2, numVisits=83459, meanQ=34.089881, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.522699 0.0632283 0.459822 0.926247 0.438361 0.381382 0.927492 0.536287 0.772328 0.815487 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 106
Initial state: 0 0.55187 0.579735 0.727002 0.710669 0.994501 0.00890986 0.836942 0.803894 0.46544 0.429958 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 90166 episodes
GETTING ACTION FROM:
action 4, numVisits=90154, meanQ=33.184476, numObservations: 9
action 5, numVisits=5, meanQ=15.000000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.55187 0.579735 0.727002 0.710669 0.994501 0.00890986 0.836942 0.803894 0.46544 0.429958 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 107
Initial state: 0 0.434448 0.433829 0.951211 0.404551 0.843557 0.670741 0.946511 0.0516466 0.834304 0.764218 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 83479 episodes
GETTING ACTION FROM:
action 3, numVisits=83459, meanQ=35.076546, numObservations: 9
action 5, numVisits=14, meanQ=4.572143, numObservations: 7
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.434448 0.433829 0.951211 0.404551 0.843557 0.670741 0.946511 0.0516466 0.834304 0.764218 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 108
Initial state: 0 0.456667 0.855021 0.00562861 0.705059 0.448591 0.433391 0.289062 0.959436 0.251919 0.785319 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89353 episodes
GETTING ACTION FROM:
action 4, numVisits=89343, meanQ=32.790427, numObservations: 9
action 5, numVisits=3, meanQ=25.996667, numObservations: 3
action 1, numVisits=3, meanQ=25.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.456667 0.855021 0.00562861 0.705059 0.448591 0.433391 0.289062 0.959436 0.251919 0.785319 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=9105, meanQ=39.089838, numObservations: 9
action 4, numVisits=3, meanQ=25.663367, numObservations: 2
action 3, numVisits=13, meanQ=19.768462, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=3, meanQ=-4.003333, numObservations: 3
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 97349 episodes
GETTING ACTION FROM:
action 1, numVisits=106454, meanQ=41.629487, numObservations: 9
action 4, numVisits=3, meanQ=25.663367, numObservations: 2
action 3, numVisits=13, meanQ=19.768462, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=3, meanQ=-4.003333, numObservations: 3
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 1
Next state: 1 0.456667 0.855021 0.00562861 0.705059 0.448591 0.433391 0.289062 0.959436 0.251919 0.785319 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 109
Initial state: 0 0.388583 0.657728 0.0697132 0.187337 0.949996 0.866806 0.0329223 0.0655094 0.496888 0.365091 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 86274 episodes
GETTING ACTION FROM:
action 5, numVisits=86267, meanQ=33.493698, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.388583 0.657728 0.0697132 0.187337 0.949996 0.866806 0.0329223 0.0655094 0.496888 0.365091 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 110
Initial state: 0 0.449002 0.631078 0.159235 0.977692 0.361009 0.972615 0.483073 0.37279 0.919719 0.489376 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 86989 episodes
GETTING ACTION FROM:
action 3, numVisits=86958, meanQ=32.598079, numObservations: 9
action 4, numVisits=23, meanQ=29.575665, numObservations: 8
action 2, numVisits=4, meanQ=21.747500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.449002 0.631078 0.159235 0.977692 0.361009 0.972615 0.483073 0.37279 0.919719 0.489376 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=8687, meanQ=37.636869, numObservations: 9
action 4, numVisits=39, meanQ=29.773338, numObservations: 9
action 2, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 98924 episodes
GETTING ACTION FROM:
action 5, numVisits=107611, meanQ=40.362422, numObservations: 9
action 4, numVisits=39, meanQ=29.773338, numObservations: 9
action 2, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.449002 0.631078 0.159235 0.977692 0.361009 0.972615 0.483073 0.37279 0.919719 0.489376 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 111
Initial state: 0 0.415241 0.323281 0.465531 0.633557 0.411252 0.662203 0.616203 0.187547 0.574562 0.392669 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88745 episodes
GETTING ACTION FROM:
action 2, numVisits=88717, meanQ=32.465598, numObservations: 9
action -1, numVisits=11, meanQ=-1.010000, numObservations: 11
action 0, numVisits=11, meanQ=-1.010000, numObservations: 11
action 3, numVisits=3, meanQ=-4.333333, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.415241 0.323281 0.465531 0.633557 0.411252 0.662203 0.616203 0.187547 0.574562 0.392669 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 112
Initial state: 0 0.372937 0.811391 0.773007 0.873938 0.481621 0.479794 0.154557 0.890757 0.66372 0.74405 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49332 episodes
GETTING ACTION FROM:
action 0, numVisits=49261, meanQ=62.798507, numObservations: 243
action -1, numVisits=66, meanQ=-1.280750, numObservations: 57
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.372937 0.811391 0.773007 0.873938 0.481621 0.479794 0.154557 0.890757 0.66372 0.74405 w: 1
Observation: 0 0 1 0 3 0 2 0 3 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=396, meanQ=88.430579, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 111088 episodes
GETTING ACTION FROM:
action 3, numVisits=111484, meanQ=91.548803, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.372937 0.811391 0.773007 0.873938 0.481621 0.479794 0.154557 0.890757 0.66372 0.74405 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 113
Initial state: 0 0.473038 0.531147 0.803378 0.240085 0.140839 0.0918434 0.782398 0.452114 0.490631 0.484803 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 86199 episodes
GETTING ACTION FROM:
action 3, numVisits=86152, meanQ=33.906613, numObservations: 9
action 1, numVisits=35, meanQ=12.517717, numObservations: 9
action 5, numVisits=8, meanQ=10.373750, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.473038 0.531147 0.803378 0.240085 0.140839 0.0918434 0.782398 0.452114 0.490631 0.484803 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=7762, meanQ=38.744746, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 27546 episodes
GETTING ACTION FROM:
action 4, numVisits=35308, meanQ=31.805565, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.473038 0.531147 0.803378 0.240085 0.140839 0.0918434 0.782398 0.452114 0.490631 0.484803 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 114
Initial state: 0 0.309284 0.370796 0.356553 0.62609 0.890632 0.33442 0.871898 0.46164 0.464473 0.428199 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 86908 episodes
GETTING ACTION FROM:
action 2, numVisits=86902, meanQ=32.796095, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.309284 0.370796 0.356553 0.62609 0.890632 0.33442 0.871898 0.46164 0.464473 0.428199 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 115
Initial state: 0 0.328988 0.465476 0.518953 0.41279 0.953276 0.814161 0.724195 0.537293 0.888024 0.937848 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49326 episodes
GETTING ACTION FROM:
action -1, numVisits=49289, meanQ=50.449798, numObservations: 243
action 0, numVisits=30, meanQ=-4.442330, numObservations: 28
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=3, meanQ=-34.333333, numObservations: 2
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.328988 0.465476 0.518953 0.41279 0.953276 0.814161 0.724195 0.537293 0.888024 0.937848 w: 1
Observation: 0 1 0 1 0 3 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=96, meanQ=2.433653, numObservations: 81
action -1, numVisits=15, meanQ=-7.742000, numObservations: 14
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 52763 episodes
GETTING ACTION FROM:
action 0, numVisits=52859, meanQ=74.036980, numObservations: 243
action -1, numVisits=15, meanQ=-7.742000, numObservations: 14
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 0
Next state: 0 0.328988 0.465476 0.518953 0.41279 0.953276 0.814161 0.724195 0.537293 0.888024 0.937848 w: 1
Observation: 0 0 3 0 2 0 3 0 3 0 3 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=252, meanQ=82.148711, numObservations: 9
action 4, numVisits=7, meanQ=54.855714, numObservations: 3
action 5, numVisits=3, meanQ=32.333333, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 107597 episodes
GETTING ACTION FROM:
action 2, numVisits=107849, meanQ=86.850020, numObservations: 9
action 4, numVisits=7, meanQ=54.855714, numObservations: 3
action 5, numVisits=3, meanQ=32.333333, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 2
Next state: 1 0.328988 0.465476 0.518953 0.41279 0.953276 0.814161 0.724195 0.537293 0.888024 0.937848 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 93.0499
Run # 116
Initial state: 0 0.534243 0.476508 0.106565 0.88244 0.623433 0.358887 0.735822 0.782997 0.0144763 0.743374 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 83646 episodes
GETTING ACTION FROM:
action 1, numVisits=83624, meanQ=35.521775, numObservations: 9
action 4, numVisits=14, meanQ=18.142871, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=4, meanQ=-5.752500, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.534243 0.476508 0.106565 0.88244 0.623433 0.358887 0.735822 0.782997 0.0144763 0.743374 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 117
Initial state: 0 0.0522152 0.687528 0.513813 0.462349 0.734428 0.726785 0.696708 0.412837 0.967405 0.89617 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 82758 episodes
GETTING ACTION FROM:
action 2, numVisits=82748, meanQ=33.212189, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action 3, numVisits=3, meanQ=-4.333333, numObservations: 2
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.0522152 0.687528 0.513813 0.462349 0.734428 0.726785 0.696708 0.412837 0.967405 0.89617 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 118
Initial state: 0 0.932394 0.785335 0.510599 0.81 0.747515 0.166984 0.335551 0.7553 0.450389 0.451232 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 86080 episodes
GETTING ACTION FROM:
action 4, numVisits=86058, meanQ=33.627377, numObservations: 9
action 1, numVisits=17, meanQ=2.062947, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.932394 0.785335 0.510599 0.81 0.747515 0.166984 0.335551 0.7553 0.450389 0.451232 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=8817, meanQ=43.453779, numObservations: 9
action 2, numVisits=16, meanQ=34.123131, numObservations: 7
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 76300 episodes
GETTING ACTION FROM:
action 4, numVisits=85117, meanQ=59.759217, numObservations: 9
action 2, numVisits=16, meanQ=34.123131, numObservations: 7
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.932394 0.785335 0.510599 0.81 0.747515 0.166984 0.335551 0.7553 0.450389 0.451232 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=30451, meanQ=39.763789, numObservations: 9
action 4, numVisits=5, meanQ=9.612020, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 96972 episodes
GETTING ACTION FROM:
action 1, numVisits=127423, meanQ=46.636098, numObservations: 9
action 4, numVisits=5, meanQ=9.612020, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.932394 0.785335 0.510599 0.81 0.747515 0.166984 0.335551 0.7553 0.450389 0.451232 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 75.1399
Run # 119
Initial state: 0 0.748211 0.424209 0.954906 0.529837 0.413677 0.528356 0.434512 0.385843 0.0140076 0.363606 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88745 episodes
GETTING ACTION FROM:
action 1, numVisits=88737, meanQ=33.184964, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.748211 0.424209 0.954906 0.529837 0.413677 0.528356 0.434512 0.385843 0.0140076 0.363606 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 120
Initial state: 0 0.0897749 0.198362 0.339885 0.209152 0.504945 0.384255 0.793202 0.611228 0.713405 0.0817675 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48854 episodes
GETTING ACTION FROM:
action 0, numVisits=48791, meanQ=61.471489, numObservations: 243
action -1, numVisits=53, meanQ=-3.326600, numObservations: 50
action 5, numVisits=6, meanQ=-4.499983, numObservations: 5
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.0897749 0.198362 0.339885 0.209152 0.504945 0.384255 0.793202 0.611228 0.713405 0.0817675 w: 1
Observation: 0 0 1 0 1 0 3 0 3 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=93, meanQ=78.976880, numObservations: 8
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 88633 episodes
GETTING ACTION FROM:
action 3, numVisits=88726, meanQ=66.612790, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 3
Next state: 1 0.0897749 0.198362 0.339885 0.209152 0.504945 0.384255 0.793202 0.611228 0.713405 0.0817675 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 121
Initial state: 0 0.110109 0.363499 0.88968 0.0650498 0.560818 0.437735 0.68267 0.130195 0.814389 0.476528 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 85547 episodes
GETTING ACTION FROM:
action 5, numVisits=85539, meanQ=33.940923, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.110109 0.363499 0.88968 0.0650498 0.560818 0.437735 0.68267 0.130195 0.814389 0.476528 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 122
Initial state: 0 0.739912 0.408928 0.369389 0.476851 0.330385 0.745633 0.567849 0.388297 0.882876 0.808606 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 84742 episodes
GETTING ACTION FROM:
action 5, numVisits=84711, meanQ=33.242916, numObservations: 9
action 3, numVisits=12, meanQ=2.916692, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=15, meanQ=-2.868000, numObservations: 7
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.739912 0.408928 0.369389 0.476851 0.330385 0.745633 0.567849 0.388297 0.882876 0.808606 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 123
Initial state: 0 0.833795 0.0269362 0.250537 0.54271 0.629801 0.685412 0.610611 0.731609 0.481478 0.378092 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 83768 episodes
GETTING ACTION FROM:
action 1, numVisits=83745, meanQ=34.282121, numObservations: 9
action 3, numVisits=4, meanQ=21.500000, numObservations: 4
action 2, numVisits=14, meanQ=18.356429, numObservations: 8
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.833795 0.0269362 0.250537 0.54271 0.629801 0.685412 0.610611 0.731609 0.481478 0.378092 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 124
Initial state: 0 0.34228 0.570683 0.416196 9.20249e-05 0.892306 0.815021 0.37128 0.281942 0.442956 0.481253 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89752 episodes
GETTING ACTION FROM:
action 2, numVisits=89738, meanQ=32.047306, numObservations: 9
action 5, numVisits=8, meanQ=17.885013, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.34228 0.570683 0.416196 9.20249e-05 0.892306 0.815021 0.37128 0.281942 0.442956 0.481253 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 125
Initial state: 0 0.192805 0.588177 0.945938 0.24556 0.178238 0.855339 0.0209181 0.810196 0.547576 0.464039 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88745 episodes
GETTING ACTION FROM:
action 2, numVisits=88731, meanQ=32.343790, numObservations: 9
action 5, numVisits=6, meanQ=10.670000, numObservations: 3
action 4, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.192805 0.588177 0.945938 0.24556 0.178238 0.855339 0.0209181 0.810196 0.547576 0.464039 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 126
Initial state: 0 0.967115 0.429483 0.966876 0.493427 0.351293 0.358718 0.523763 0.907227 0.482943 0.396675 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 83892 episodes
GETTING ACTION FROM:
action 1, numVisits=83885, meanQ=34.269685, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.967115 0.429483 0.966876 0.493427 0.351293 0.358718 0.523763 0.907227 0.482943 0.396675 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 127
Initial state: 0 0.65832 0.372374 0.952196 0.757311 0.327362 0.286338 0.493273 0.391279 0.173671 0.76755 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89767 episodes
GETTING ACTION FROM:
action 2, numVisits=89756, meanQ=32.232299, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=3, meanQ=-7.663333, numObservations: 2
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.65832 0.372374 0.952196 0.757311 0.327362 0.286338 0.493273 0.391279 0.173671 0.76755 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 128
Initial state: 0 0.870468 0.901051 0.808932 0.719548 0.463744 0.361316 0.852764 0.789755 0.0715921 0.851809 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89334 episodes
GETTING ACTION FROM:
action 1, numVisits=89324, meanQ=32.827319, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.870468 0.901051 0.808932 0.719548 0.463744 0.361316 0.852764 0.789755 0.0715921 0.851809 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 129
Initial state: 0 0.319661 0.0798229 0.579218 0.721352 0.722092 0.821755 0.999292 0.25412 0.48788 0.366025 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87616 episodes
GETTING ACTION FROM:
action 1, numVisits=87590, meanQ=32.463160, numObservations: 9
action 4, numVisits=21, meanQ=15.524286, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.319661 0.0798229 0.579218 0.721352 0.722092 0.821755 0.999292 0.25412 0.48788 0.366025 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=7874, meanQ=38.710234, numObservations: 9
action 2, numVisits=5, meanQ=31.414020, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 30473 episodes
GETTING ACTION FROM:
action 4, numVisits=38343, meanQ=35.016279, numObservations: 9
action 2, numVisits=9, meanQ=26.343507, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 4
Next state: 2 0.319661 0.0798229 0.579218 0.721352 0.722092 0.821755 0.999292 0.25412 0.48788 0.366025 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -110.99
Run # 130
Initial state: 0 0.466333 0.4213 0.261299 0.603757 0.768326 0.522049 0.0291363 0.102816 0.309604 0.214915 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 83776 episodes
GETTING ACTION FROM:
action 3, numVisits=83770, meanQ=34.816312, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.466333 0.4213 0.261299 0.603757 0.768326 0.522049 0.0291363 0.102816 0.309604 0.214915 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 131
Initial state: 0 0.469673 0.296097 0.699195 0.744002 0.500106 0.41306 0.700068 0.000330637 0.959555 0.481021 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 85860 episodes
GETTING ACTION FROM:
action 3, numVisits=85844, meanQ=33.672973, numObservations: 9
action 1, numVisits=8, meanQ=7.997500, numObservations: 6
action 5, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.469673 0.296097 0.699195 0.744002 0.500106 0.41306 0.700068 0.000330637 0.959555 0.481021 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 132
Initial state: 0 0.580939 0.930905 0.578852 0.466905 0.782349 0.925111 0.0444489 0.160611 0.743038 0.227474 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89400 episodes
GETTING ACTION FROM:
action 5, numVisits=89393, meanQ=32.473370, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.580939 0.930905 0.578852 0.466905 0.782349 0.925111 0.0444489 0.160611 0.743038 0.227474 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 133
Initial state: 0 0.568988 0.428524 0.515283 0.974361 0.787615 0.376953 0.418654 0.105165 0.153144 0.174808 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89704 episodes
GETTING ACTION FROM:
action 1, numVisits=89697, meanQ=32.779360, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.568988 0.428524 0.515283 0.974361 0.787615 0.376953 0.418654 0.105165 0.153144 0.174808 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 134
Initial state: 0 0.995258 0.508205 0.171474 0.714885 0.692726 0.665491 0.821509 0.26853 0.488343 0.438449 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 84419 episodes
GETTING ACTION FROM:
action 2, numVisits=84400, meanQ=33.402155, numObservations: 9
action 4, numVisits=12, meanQ=14.082500, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=3, meanQ=-4.333333, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.995258 0.508205 0.171474 0.714885 0.692726 0.665491 0.821509 0.26853 0.488343 0.438449 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 135
Initial state: 0 0.0469243 0.184866 0.302058 0.23781 0.48017 0.431315 0.935635 0.635813 0.400711 0.334621 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 84552 episodes
GETTING ACTION FROM:
action 1, numVisits=84541, meanQ=33.727980, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action 3, numVisits=4, meanQ=-6.249975, numObservations: 3
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.0469243 0.184866 0.302058 0.23781 0.48017 0.431315 0.935635 0.635813 0.400711 0.334621 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=8555, meanQ=38.791542, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 98381 episodes
GETTING ACTION FROM:
action 2, numVisits=106936, meanQ=47.737013, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 2
Next state: 0 0.0469243 0.184866 0.302058 0.23781 0.48017 0.431315 0.935635 0.635813 0.400711 0.334621 w: 1
Observation: 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 0, numVisits=1099, meanQ=58.552321, numObservations: 152
action -1, numVisits=31, meanQ=-5.227400, numObservations: 24
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 24820 episodes
GETTING ACTION FROM:
action 0, numVisits=25919, meanQ=15.734196, numObservations: 241
action -1, numVisits=31, meanQ=-5.227400, numObservations: 24
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 0
Next state: 0 0.0469243 0.184866 0.302058 0.23781 0.48017 0.431315 0.935635 0.635813 0.400711 0.334621 w: 1
Observation: 0 0 1 0 1 0 2 0 3 0 1 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=14, meanQ=81.907202, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-14.978567, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 85191 episodes
GETTING ACTION FROM:
action 3, numVisits=85205, meanQ=74.383677, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-14.978567, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.0469243 0.184866 0.302058 0.23781 0.48017 0.431315 0.935635 0.635813 0.400711 0.334621 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 5, numVisits=84, meanQ=83.497619, numObservations: 8
action 3, numVisits=5, meanQ=52.120534, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-15.265380, numObservations: 1
action 1, numVisits=1, meanQ=-16.425712, numObservations: 1
action 2, numVisits=1, meanQ=-1076.497867, numObservations: 1
Sampled 96039 episodes
GETTING ACTION FROM:
action 5, numVisits=96122, meanQ=27.343422, numObservations: 9
action 3, numVisits=6, meanQ=26.600445, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-15.265380, numObservations: 1
action 1, numVisits=1, meanQ=-16.425712, numObservations: 1
action 2, numVisits=1, meanQ=-1076.497867, numObservations: 1
action: 5
Next state: 2 0.0469243 0.184866 0.302058 0.23781 0.48017 0.431315 0.935635 0.635813 0.400711 0.334621 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -131.544
Run # 136
Initial state: 0 0.12926 0.927288 0.5766 0.391844 0.517183 0.86398 0.185733 0.415801 0.170868 0.134186 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 84153 episodes
GETTING ACTION FROM:
action 1, numVisits=84145, meanQ=34.011821, numObservations: 9
action 2, numVisits=3, meanQ=25.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.12926 0.927288 0.5766 0.391844 0.517183 0.86398 0.185733 0.415801 0.170868 0.134186 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=8476, meanQ=37.994528, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 100101 episodes
GETTING ACTION FROM:
action 2, numVisits=108577, meanQ=46.195629, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.12926 0.927288 0.5766 0.391844 0.517183 0.86398 0.185733 0.415801 0.170868 0.134186 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 137
Initial state: 0 0.433049 0.376374 0.0808002 0.958999 0.730878 0.722949 0.613794 0.996269 0.0785782 0.258479 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87908 episodes
GETTING ACTION FROM:
action 3, numVisits=87888, meanQ=32.260433, numObservations: 9
action 1, numVisits=15, meanQ=2.471340, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.433049 0.376374 0.0808002 0.958999 0.730878 0.722949 0.613794 0.996269 0.0785782 0.258479 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 138
Initial state: 0 0.183536 0.440808 0.475922 0.472706 0.592202 0.392391 0.205585 0.847181 0.0484129 0.737523 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 86713 episodes
GETTING ACTION FROM:
action 4, numVisits=86706, meanQ=33.730027, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.183536 0.440808 0.475922 0.472706 0.592202 0.392391 0.205585 0.847181 0.0484129 0.737523 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 139
Initial state: 0 0.547259 0.36233 0.552764 0.660685 0.386191 0.903807 0.169487 0.589558 0.611156 0.080655 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 86861 episodes
GETTING ACTION FROM:
action 5, numVisits=86847, meanQ=31.784448, numObservations: 9
action 1, numVisits=8, meanQ=7.750000, numObservations: 7
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.547259 0.36233 0.552764 0.660685 0.386191 0.903807 0.169487 0.589558 0.611156 0.080655 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 140
Initial state: 0 0.535238 0.927652 0.554521 0.681483 0.0934418 0.482598 0.112173 0.926729 0.496941 0.426683 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 84607 episodes
GETTING ACTION FROM:
action 2, numVisits=84601, meanQ=33.781601, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.535238 0.927652 0.554521 0.681483 0.0934418 0.482598 0.112173 0.926729 0.496941 0.426683 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 141
Initial state: 0 0.257477 0.205664 0.831037 0.157464 0.446493 0.422129 0.421947 0.116499 0.925057 0.0587658 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89177 episodes
GETTING ACTION FROM:
action 1, numVisits=88154, meanQ=33.121909, numObservations: 9
action 4, numVisits=1018, meanQ=30.721549, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.257477 0.205664 0.831037 0.157464 0.446493 0.422129 0.421947 0.116499 0.925057 0.0587658 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=7890, meanQ=39.143107, numObservations: 9
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=3, meanQ=-34.333333, numObservations: 3
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 24929 episodes
GETTING ACTION FROM:
action 4, numVisits=32819, meanQ=31.093082, numObservations: 9
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=3, meanQ=-34.333333, numObservations: 3
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.257477 0.205664 0.831037 0.157464 0.446493 0.422129 0.421947 0.116499 0.925057 0.0587658 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 0, numVisits=503, meanQ=31.357616, numObservations: 117
action 3, numVisits=5, meanQ=-2.802000, numObservations: 4
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action -1, numVisits=6, meanQ=-17.840000, numObservations: 5
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 19300 episodes
GETTING ACTION FROM:
action 0, numVisits=19803, meanQ=14.508747, numObservations: 243
action 3, numVisits=5, meanQ=-2.802000, numObservations: 4
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action -1, numVisits=6, meanQ=-17.840000, numObservations: 5
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.257477 0.205664 0.831037 0.157464 0.446493 0.422129 0.421947 0.116499 0.925057 0.0587658 w: 1
Observation: 0 0 1 0 1 0 2 0 1 0 1 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=168, meanQ=88.876731, numObservations: 8
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-16.812636, numObservations: 1
action 4, numVisits=1, meanQ=-545.183786, numObservations: 1
action 1, numVisits=1, meanQ=-1075.715460, numObservations: 1
Sampled 81568 episodes
GETTING ACTION FROM:
action 3, numVisits=81736, meanQ=83.297252, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-16.812636, numObservations: 1
action 4, numVisits=1, meanQ=-545.183786, numObservations: 1
action 1, numVisits=1, meanQ=-1075.715460, numObservations: 1
action: 3
Next state: 1 0.257477 0.205664 0.831037 0.157464 0.446493 0.422129 0.421947 0.116499 0.925057 0.0587658 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 72.2094
Run # 142
Initial state: 0 0.866014 0.515927 0.463341 0.47574 0.318173 0.416306 0.830349 0.86105 0.991461 0.453537 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88804 episodes
GETTING ACTION FROM:
action 3, numVisits=88785, meanQ=32.955684, numObservations: 9
action 5, numVisits=8, meanQ=10.250000, numObservations: 7
action 2, numVisits=4, meanQ=-1.000000, numObservations: 4
action 4, numVisits=4, meanQ=-1.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.866014 0.515927 0.463341 0.47574 0.318173 0.416306 0.830349 0.86105 0.991461 0.453537 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=3005, meanQ=39.779548, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 32819 episodes
GETTING ACTION FROM:
action 5, numVisits=35824, meanQ=37.338685, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.866014 0.515927 0.463341 0.47574 0.318173 0.416306 0.830349 0.86105 0.991461 0.453537 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 143
Initial state: 0 0.888595 0.0622828 0.581692 0.743541 0.562092 0.415201 0.753196 0.24802 0.939407 0.369642 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89386 episodes
GETTING ACTION FROM:
action 4, numVisits=89376, meanQ=32.636703, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.888595 0.0622828 0.581692 0.743541 0.562092 0.415201 0.753196 0.24802 0.939407 0.369642 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 144
Initial state: 0 0.136842 0.47446 0.39644 0.676613 0.793147 0.554661 0.519424 0.386404 0.604292 0.657186 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89663 episodes
GETTING ACTION FROM:
action 3, numVisits=89636, meanQ=33.492356, numObservations: 9
action 2, numVisits=17, meanQ=7.705894, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=6, meanQ=-4.333333, numObservations: 5
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.136842 0.47446 0.39644 0.676613 0.793147 0.554661 0.519424 0.386404 0.604292 0.657186 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 145
Initial state: 0 0.0813499 0.373332 0.0234044 0.153184 0.249257 0.400811 0.785491 0.284054 0.518835 0.456055 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89387 episodes
GETTING ACTION FROM:
action 5, numVisits=89379, meanQ=32.078330, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.0813499 0.373332 0.0234044 0.153184 0.249257 0.400811 0.785491 0.284054 0.518835 0.456055 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 146
Initial state: 0 0.608923 0.227693 0.42882 0.44824 0.0155946 0.668621 0.538893 0.642248 0.308274 0.0818935 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 83722 episodes
GETTING ACTION FROM:
action 5, numVisits=83708, meanQ=33.991422, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=7, meanQ=-4.141429, numObservations: 6
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.608923 0.227693 0.42882 0.44824 0.0155946 0.668621 0.538893 0.642248 0.308274 0.0818935 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=7755, meanQ=36.010781, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 28561 episodes
GETTING ACTION FROM:
action 1, numVisits=36316, meanQ=38.595887, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.608923 0.227693 0.42882 0.44824 0.0155946 0.668621 0.538893 0.642248 0.308274 0.0818935 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -110.99
Run # 147
Initial state: 0 0.856383 0.527689 0.44777 0.461319 0.236555 0.151721 0.157487 0.715785 0.798987 0.936651 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 90068 episodes
GETTING ACTION FROM:
action 5, numVisits=90055, meanQ=32.834366, numObservations: 9
action 2, numVisits=4, meanQ=21.500000, numObservations: 3
action 1, numVisits=4, meanQ=16.747500, numObservations: 4
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.856383 0.527689 0.44777 0.461319 0.236555 0.151721 0.157487 0.715785 0.798987 0.936651 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 148
Initial state: 0 0.440762 0.374208 0.0566625 0.88471 0.434474 0.0297128 0.782385 0.287877 0.965757 0.631431 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 83203 episodes
GETTING ACTION FROM:
action 5, numVisits=83192, meanQ=32.458448, numObservations: 9
action 3, numVisits=6, meanQ=14.000000, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.440762 0.374208 0.0566625 0.88471 0.434474 0.0297128 0.782385 0.287877 0.965757 0.631431 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 149
Initial state: 0 0.269536 0.476191 0.446716 0.576781 0.992421 0.580334 0.0349849 0.0688979 0.476946 0.361182 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 86433 episodes
GETTING ACTION FROM:
action 3, numVisits=86414, meanQ=32.006588, numObservations: 9
action 5, numVisits=14, meanQ=11.143571, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.269536 0.476191 0.446716 0.576781 0.992421 0.580334 0.0349849 0.0688979 0.476946 0.361182 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 150
Initial state: 0 0.872829 0.625075 0.129847 0.894641 0.435422 0.855167 0.179008 0.984742 0.504873 0.401256 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89220 episodes
GETTING ACTION FROM:
action 5, numVisits=89201, meanQ=32.828585, numObservations: 9
action 4, numVisits=14, meanQ=9.785714, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.872829 0.625075 0.129847 0.894641 0.435422 0.855167 0.179008 0.984742 0.504873 0.401256 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 151
Initial state: 0 0.394522 0.859833 0.7705 0.330828 0.484678 0.559331 0.645865 0.0285023 0.462873 0.395258 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89393 episodes
GETTING ACTION FROM:
action 5, numVisits=89385, meanQ=32.200872, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.394522 0.859833 0.7705 0.330828 0.484678 0.559331 0.645865 0.0285023 0.462873 0.395258 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 152
Initial state: 0 0.765706 0.185214 0.412144 0.407535 0.636678 0.305963 0.875832 0.859912 0.112996 0.676044 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 83453 episodes
GETTING ACTION FROM:
action 4, numVisits=83446, meanQ=33.299079, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.765706 0.185214 0.412144 0.407535 0.636678 0.305963 0.875832 0.859912 0.112996 0.676044 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 153
Initial state: 0 0.509403 0.379144 0.696778 0.0798392 0.324132 0.257815 0.505878 0.0420393 0.27517 0.725235 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 86467 episodes
GETTING ACTION FROM:
action 4, numVisits=86448, meanQ=33.015229, numObservations: 9
action 1, numVisits=14, meanQ=24.000007, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.509403 0.379144 0.696778 0.0798392 0.324132 0.257815 0.505878 0.0420393 0.27517 0.725235 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 154
Initial state: 0 0.402103 0.517177 0.635372 0.773904 0.505517 0.375528 0.546307 0.233304 0.367552 0.0138317 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87226 episodes
GETTING ACTION FROM:
action 1, numVisits=87220, meanQ=32.152941, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.402103 0.517177 0.635372 0.773904 0.505517 0.375528 0.546307 0.233304 0.367552 0.0138317 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 155
Initial state: 0 0.51695 0.3876 0.908467 0.556177 0.078181 0.309728 0.664647 0.235936 0.809907 0.386928 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 84320 episodes
GETTING ACTION FROM:
action 4, numVisits=84286, meanQ=34.521791, numObservations: 9
action 3, numVisits=29, meanQ=21.037938, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.51695 0.3876 0.908467 0.556177 0.078181 0.309728 0.664647 0.235936 0.809907 0.386928 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 156
Initial state: 0 0.673557 0.765665 0.441841 0.382942 0.0305608 0.453566 0.695278 0.0856073 0.088137 0.998507 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 82870 episodes
GETTING ACTION FROM:
action 2, numVisits=82863, meanQ=34.763424, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.673557 0.765665 0.441841 0.382942 0.0305608 0.453566 0.695278 0.0856073 0.088137 0.998507 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 157
Initial state: 0 0.853971 0.635146 0.0177255 0.918526 0.250259 0.0272327 0.436355 0.728565 0.411828 0.485757 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 86124 episodes
GETTING ACTION FROM:
action 5, numVisits=86118, meanQ=33.185533, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.853971 0.635146 0.0177255 0.918526 0.250259 0.0272327 0.436355 0.728565 0.411828 0.485757 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1333, meanQ=35.754573, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 119528 episodes
GETTING ACTION FROM:
action 2, numVisits=120861, meanQ=39.155969, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.853971 0.635146 0.0177255 0.918526 0.250259 0.0272327 0.436355 0.728565 0.411828 0.485757 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=1756, meanQ=68.857327, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 124537 episodes
GETTING ACTION FROM:
action 5, numVisits=126293, meanQ=89.645840, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.853971 0.635146 0.0177255 0.918526 0.250259 0.0272327 0.436355 0.728565 0.411828 0.485757 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 75.1399
Run # 158
Initial state: 0 0.662685 0.358124 0.124504 0.598803 0.145395 0.266116 0.982997 0.1007 0.411524 0.373394 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87811 episodes
GETTING ACTION FROM:
action 2, numVisits=87802, meanQ=31.998350, numObservations: 9
action 5, numVisits=4, meanQ=16.500000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.662685 0.358124 0.124504 0.598803 0.145395 0.266116 0.982997 0.1007 0.411524 0.373394 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=2988, meanQ=34.330659, numObservations: 9
action 4, numVisits=4, meanQ=21.747500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 26994 episodes
GETTING ACTION FROM:
action 3, numVisits=29982, meanQ=37.302931, numObservations: 9
action 4, numVisits=4, meanQ=21.747500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.662685 0.358124 0.124504 0.598803 0.145395 0.266116 0.982997 0.1007 0.411524 0.373394 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 0, numVisits=1648, meanQ=51.096170, numObservations: 194
action -1, numVisits=16, meanQ=-1.691244, numObservations: 15
action 4, numVisits=9, meanQ=-4.003333, numObservations: 6
action 1, numVisits=3, meanQ=-4.003333, numObservations: 2
action 2, numVisits=3, meanQ=-4.003333, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 9621 episodes
GETTING ACTION FROM:
action 0, numVisits=11269, meanQ=34.398598, numObservations: 242
action -1, numVisits=16, meanQ=-1.691244, numObservations: 15
action 4, numVisits=9, meanQ=-4.003333, numObservations: 6
action 1, numVisits=3, meanQ=-4.003333, numObservations: 2
action 2, numVisits=3, meanQ=-4.003333, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 0
Next state: 0 0.662685 0.358124 0.124504 0.598803 0.145395 0.266116 0.982997 0.1007 0.411524 0.373394 w: 1
Observation: 0 0 2 0 1 0 1 0 1 0 2 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=6, meanQ=79.605131, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-16.827413, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-546.675807, numObservations: 1
action 3, numVisits=1, meanQ=-547.583406, numObservations: 1
Sampled 53968 episodes
GETTING ACTION FROM:
action 1, numVisits=53974, meanQ=64.833703, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-16.827413, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-546.675807, numObservations: 1
action 3, numVisits=1, meanQ=-547.583406, numObservations: 1
action: 1
Next state: 2 0.662685 0.358124 0.124504 0.598803 0.145395 0.266116 0.982997 0.1007 0.411524 0.373394 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -121.85
Run # 159
Initial state: 0 0.649583 0.666131 0.848242 0.0512562 0.765062 0.313007 0.180913 0.533369 0.564988 0.425357 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 83480 episodes
GETTING ACTION FROM:
action 2, numVisits=83472, meanQ=33.453053, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.649583 0.666131 0.848242 0.0512562 0.765062 0.313007 0.180913 0.533369 0.564988 0.425357 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 160
Initial state: 0 0.872845 0.0023087 0.410608 0.737162 0.436141 0.306573 0.541421 0.453141 0.859351 0.410335 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89600 episodes
GETTING ACTION FROM:
action 3, numVisits=89588, meanQ=33.104368, numObservations: 9
action 2, numVisits=4, meanQ=21.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=4, meanQ=-6.249975, numObservations: 3
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.872845 0.0023087 0.410608 0.737162 0.436141 0.306573 0.541421 0.453141 0.859351 0.410335 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 161
Initial state: 0 0.15202 0.548324 0.742663 0.489075 0.478054 0.395392 0.117118 0.91674 0.266101 0.0213981 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49988 episodes
GETTING ACTION FROM:
action -1, numVisits=49968, meanQ=52.672656, numObservations: 243
action 0, numVisits=13, meanQ=-1.010000, numObservations: 13
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.15202 0.548324 0.742663 0.489075 0.478054 0.395392 0.117118 0.91674 0.266101 0.0213981 w: 1
Observation: 0 1 0 3 0 2 0 1 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=266, meanQ=83.155604, numObservations: 9
action 1, numVisits=4, meanQ=44.495000, numObservations: 3
action 2, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 110147 episodes
GETTING ACTION FROM:
action 3, numVisits=110413, meanQ=79.218258, numObservations: 9
action 1, numVisits=4, meanQ=44.495000, numObservations: 3
action 2, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.15202 0.548324 0.742663 0.489075 0.478054 0.395392 0.117118 0.91674 0.266101 0.0213981 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 162
Initial state: 0 0.519794 0.39418 0.337091 0.768738 0.647363 0.29904 0.46361 0.602906 0.466407 0.282906 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 85644 episodes
GETTING ACTION FROM:
action 2, numVisits=85618, meanQ=32.659523, numObservations: 9
action -1, numVisits=11, meanQ=-1.010000, numObservations: 11
action 0, numVisits=11, meanQ=-1.010000, numObservations: 11
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.519794 0.39418 0.337091 0.768738 0.647363 0.29904 0.46361 0.602906 0.466407 0.282906 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=8468, meanQ=46.031435, numObservations: 9
action 4, numVisits=5, meanQ=33.594000, numObservations: 5
action 1, numVisits=9, meanQ=30.331111, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 76338 episodes
GETTING ACTION FROM:
action 2, numVisits=84806, meanQ=59.786651, numObservations: 9
action 4, numVisits=5, meanQ=33.594000, numObservations: 5
action 1, numVisits=9, meanQ=30.331111, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 2
Next state: 1 0.519794 0.39418 0.337091 0.768738 0.647363 0.29904 0.46361 0.602906 0.466407 0.282906 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 163
Initial state: 0 0.508939 0.760686 0.481469 0.429705 0.655645 0.00468528 0.742283 0.197306 0.647669 0.117248 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 90141 episodes
GETTING ACTION FROM:
action 4, numVisits=90102, meanQ=32.567400, numObservations: 9
action 1, numVisits=30, meanQ=14.114017, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=5, meanQ=-6.802000, numObservations: 4
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.508939 0.760686 0.481469 0.429705 0.655645 0.00468528 0.742283 0.197306 0.647669 0.117248 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 164
Initial state: 0 0.863219 0.0409459 0.418636 0.328124 0.904443 0.336827 0.412358 0.475232 0.0562403 0.0714181 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 81265 episodes
GETTING ACTION FROM:
action 1, numVisits=81258, meanQ=34.010981, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.863219 0.0409459 0.418636 0.328124 0.904443 0.336827 0.412358 0.475232 0.0562403 0.0714181 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 165
Initial state: 0 0.857777 0.221258 0.79123 0.3052 0.567722 0.381855 0.834503 0.791929 0.853093 0.77887 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49623 episodes
GETTING ACTION FROM:
action -1, numVisits=49596, meanQ=48.811329, numObservations: 243
action 0, numVisits=15, meanQ=-1.010000, numObservations: 15
action 3, numVisits=6, meanQ=-4.333333, numObservations: 5
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.857777 0.221258 0.79123 0.3052 0.567722 0.381855 0.834503 0.791929 0.853093 0.77887 w: 1
Observation: 0 3 0 3 0 2 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=277, meanQ=80.776820, numObservations: 9
action 4, numVisits=3, meanQ=32.333333, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 113982 episodes
GETTING ACTION FROM:
action 3, numVisits=114259, meanQ=90.452192, numObservations: 9
action 4, numVisits=3, meanQ=32.333333, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.857777 0.221258 0.79123 0.3052 0.567722 0.381855 0.834503 0.791929 0.853093 0.77887 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 166
Initial state: 0 0.456634 0.410359 0.595797 0.0360564 0.86329 0.618797 0.211549 0.955366 0.193446 0.125579 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 90231 episodes
GETTING ACTION FROM:
action 2, numVisits=90211, meanQ=32.403969, numObservations: 9
action 5, numVisits=14, meanQ=15.857857, numObservations: 7
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.456634 0.410359 0.595797 0.0360564 0.86329 0.618797 0.211549 0.955366 0.193446 0.125579 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 167
Initial state: 0 0.604758 0.345761 0.584664 0.10764 0.630915 0.472392 0.244712 0.121285 0.489505 0.373421 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88063 episodes
GETTING ACTION FROM:
action 5, numVisits=88053, meanQ=31.455550, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=5, meanQ=-3.000000, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.604758 0.345761 0.584664 0.10764 0.630915 0.472392 0.244712 0.121285 0.489505 0.373421 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 168
Initial state: 0 0.289291 0.832515 0.54307 0.10771 0.399393 0.0249313 0.750602 0.444865 0.512177 0.390693 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89240 episodes
GETTING ACTION FROM:
action 1, numVisits=89234, meanQ=32.182709, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.289291 0.832515 0.54307 0.10771 0.399393 0.0249313 0.750602 0.444865 0.512177 0.390693 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 169
Initial state: 0 0.477919 0.987544 0.0484892 0.490991 0.146418 0.13367 0.743467 0.37692 0.404123 0.480677 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 85780 episodes
GETTING ACTION FROM:
action 3, numVisits=85774, meanQ=34.104205, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.477919 0.987544 0.0484892 0.490991 0.146418 0.13367 0.743467 0.37692 0.404123 0.480677 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=7754, meanQ=37.516539, numObservations: 9
action 5, numVisits=24, meanQ=25.335838, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=3, meanQ=-4.003333, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 28599 episodes
GETTING ACTION FROM:
action 4, numVisits=36353, meanQ=34.916957, numObservations: 9
action 5, numVisits=24, meanQ=25.335838, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=3, meanQ=-4.003333, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.477919 0.987544 0.0484892 0.490991 0.146418 0.13367 0.743467 0.37692 0.404123 0.480677 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 170
Initial state: 0 0.51529 0.369292 0.0296188 0.925007 0.26071 0.985503 0.0101135 0.608694 0.897783 0.343287 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 86303 episodes
GETTING ACTION FROM:
action 4, numVisits=86297, meanQ=33.366704, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.51529 0.369292 0.0296188 0.925007 0.26071 0.985503 0.0101135 0.608694 0.897783 0.343287 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 171
Initial state: 0 0.284164 0.670381 0.00795462 0.559092 0.47268 0.433667 0.106943 0.207241 0.947794 0.00116752 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 90194 episodes
GETTING ACTION FROM:
action 1, numVisits=90141, meanQ=31.824664, numObservations: 9
action 2, numVisits=47, meanQ=25.490432, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.284164 0.670381 0.00795462 0.559092 0.47268 0.433667 0.106943 0.207241 0.947794 0.00116752 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=9291, meanQ=37.207201, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 5, numVisits=5, meanQ=-2.802000, numObservations: 4
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 96676 episodes
GETTING ACTION FROM:
action 2, numVisits=105967, meanQ=47.799305, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 5, numVisits=5, meanQ=-2.802000, numObservations: 4
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 2
Next state: 0 0.284164 0.670381 0.00795462 0.559092 0.47268 0.433667 0.106943 0.207241 0.947794 0.00116752 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=2587, meanQ=51.769163, numObservations: 9
action 4, numVisits=4, meanQ=21.747500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 43021 episodes
GETTING ACTION FROM:
action 3, numVisits=45608, meanQ=43.642281, numObservations: 9
action 4, numVisits=4, meanQ=21.747500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.284164 0.670381 0.00795462 0.559092 0.47268 0.433667 0.106943 0.207241 0.947794 0.00116752 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=580, meanQ=81.040271, numObservations: 9
action 4, numVisits=2, meanQ=44.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 110978 episodes
GETTING ACTION FROM:
action 3, numVisits=111558, meanQ=87.119675, numObservations: 9
action 4, numVisits=2, meanQ=44.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 3
Next state: 1 0.284164 0.670381 0.00795462 0.559092 0.47268 0.433667 0.106943 0.207241 0.947794 0.00116752 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 63.3885
Run # 172
Initial state: 0 0.400652 0.572282 0.496778 0.391246 0.787825 0.637562 0.855311 0.105669 0.345033 0.0214517 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87004 episodes
GETTING ACTION FROM:
action 2, numVisits=86976, meanQ=32.340479, numObservations: 9
action 1, numVisits=23, meanQ=17.652174, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.400652 0.572282 0.496778 0.391246 0.787825 0.637562 0.855311 0.105669 0.345033 0.0214517 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 173
Initial state: 0 0.245127 0.358808 0.0838599 0.728226 0.513461 0.481274 0.268826 0.354653 0.525884 0.182777 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 85831 episodes
GETTING ACTION FROM:
action 2, numVisits=85822, meanQ=32.892168, numObservations: 9
action 3, numVisits=4, meanQ=21.747500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.245127 0.358808 0.0838599 0.728226 0.513461 0.481274 0.268826 0.354653 0.525884 0.182777 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=7620, meanQ=37.656422, numObservations: 9
action 3, numVisits=5, meanQ=15.396000, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 31179 episodes
GETTING ACTION FROM:
action 4, numVisits=38799, meanQ=32.958958, numObservations: 9
action 3, numVisits=5, meanQ=15.396000, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 4
Next state: 0 0.245127 0.358808 0.0838599 0.728226 0.513461 0.481274 0.268826 0.354653 0.525884 0.182777 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=2063, meanQ=49.776456, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 25191 episodes
GETTING ACTION FROM:
action 1, numVisits=27254, meanQ=39.278721, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 1
Next state: 2 0.245127 0.358808 0.0838599 0.728226 0.513461 0.481274 0.268826 0.354653 0.525884 0.182777 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -120.88
Run # 174
Initial state: 0 0.568597 0.29561 0.741867 0.782042 0.277198 0.382689 0.418168 0.421204 0.82925 0.206839 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88360 episodes
GETTING ACTION FROM:
action 2, numVisits=88346, meanQ=32.228998, numObservations: 9
action 3, numVisits=8, meanQ=10.250000, numObservations: 5
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.568597 0.29561 0.741867 0.782042 0.277198 0.382689 0.418168 0.421204 0.82925 0.206839 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 175
Initial state: 0 0.27852 0.314409 0.0507585 0.99169 0.352861 0.952382 0.611057 0.0341265 0.455255 0.481851 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48928 episodes
GETTING ACTION FROM:
action 0, numVisits=48910, meanQ=61.567717, numObservations: 243
action -1, numVisits=13, meanQ=-1.010000, numObservations: 13
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.27852 0.314409 0.0507585 0.99169 0.352861 0.952382 0.611057 0.0341265 0.455255 0.481851 w: 1
Observation: 0 0 1 0 3 0 3 0 1 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=119, meanQ=58.163810, numObservations: 9
action 4, numVisits=3, meanQ=32.333333, numObservations: 3
action 3, numVisits=5, meanQ=15.396000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 84579 episodes
GETTING ACTION FROM:
action 2, numVisits=84698, meanQ=64.594957, numObservations: 9
action 4, numVisits=3, meanQ=32.333333, numObservations: 3
action 3, numVisits=5, meanQ=15.396000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 2
Next state: 1 0.27852 0.314409 0.0507585 0.99169 0.352861 0.952382 0.611057 0.0341265 0.455255 0.481851 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 176
Initial state: 0 0.113248 0.163129 0.321474 0.816785 0.0423896 0.367091 0.546445 0.488771 0.427351 0.512453 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89718 episodes
GETTING ACTION FROM:
action 2, numVisits=89704, meanQ=33.348048, numObservations: 9
action 4, numVisits=4, meanQ=16.500000, numObservations: 4
action 1, numVisits=5, meanQ=15.000000, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.113248 0.163129 0.321474 0.816785 0.0423896 0.367091 0.546445 0.488771 0.427351 0.512453 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=9101, meanQ=40.591228, numObservations: 9
action 4, numVisits=8, meanQ=24.000000, numObservations: 6
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 96511 episodes
GETTING ACTION FROM:
action 1, numVisits=105612, meanQ=46.360526, numObservations: 9
action 4, numVisits=8, meanQ=24.000000, numObservations: 6
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.113248 0.163129 0.321474 0.816785 0.0423896 0.367091 0.546445 0.488771 0.427351 0.512453 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=5753, meanQ=60.339871, numObservations: 9
action 5, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 15384 episodes
GETTING ACTION FROM:
action 2, numVisits=21137, meanQ=58.630961, numObservations: 9
action 5, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.113248 0.163129 0.321474 0.816785 0.0423896 0.367091 0.546445 0.488771 0.427351 0.512453 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=6726, meanQ=60.887402, numObservations: 9
action 4, numVisits=7, meanQ=36.424300, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 27487 episodes
GETTING ACTION FROM:
action 2, numVisits=34213, meanQ=69.784709, numObservations: 9
action 4, numVisits=7, meanQ=36.424300, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 2
Next state: 1 0.113248 0.163129 0.321474 0.816785 0.0423896 0.367091 0.546445 0.488771 0.427351 0.512453 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 63.3885
Run # 177
Initial state: 0 0.441294 0.738622 0.108144 0.473548 0.510641 0.893647 0.693359 0.461364 0.41588 0.426071 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88972 episodes
GETTING ACTION FROM:
action 4, numVisits=88937, meanQ=32.354565, numObservations: 9
action 5, numVisits=16, meanQ=22.249375, numObservations: 7
action 2, numVisits=4, meanQ=21.500000, numObservations: 4
action 1, numVisits=11, meanQ=20.917282, numObservations: 7
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 4
Next state: 1 0.441294 0.738622 0.108144 0.473548 0.510641 0.893647 0.693359 0.461364 0.41588 0.426071 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 178
Initial state: 0 0.486517 0.446796 0.499882 0.648199 0.611897 0.574401 0.030551 0.762273 0.523967 0.926715 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 84176 episodes
GETTING ACTION FROM:
action 1, numVisits=84169, meanQ=34.583769, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.486517 0.446796 0.499882 0.648199 0.611897 0.574401 0.030551 0.762273 0.523967 0.926715 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 179
Initial state: 0 0.833865 0.400801 0.453576 0.473054 0.784031 0.753848 0.722054 0.771426 0.460257 0.640355 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49327 episodes
GETTING ACTION FROM:
action -1, numVisits=49289, meanQ=47.501743, numObservations: 243
action 0, numVisits=28, meanQ=-1.081068, numObservations: 27
action 3, numVisits=6, meanQ=-4.333333, numObservations: 4
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.833865 0.400801 0.453576 0.473054 0.784031 0.753848 0.722054 0.771426 0.460257 0.640355 w: 1
Observation: 0 3 0 2 0 1 0 3 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=223, meanQ=47.114309, numObservations: 9
action 4, numVisits=6, meanQ=32.333333, numObservations: 3
action 3, numVisits=3, meanQ=26.326667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 111408 episodes
GETTING ACTION FROM:
action 5, numVisits=111631, meanQ=50.257056, numObservations: 9
action 4, numVisits=6, meanQ=32.333333, numObservations: 3
action 3, numVisits=3, meanQ=26.326667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.833865 0.400801 0.453576 0.473054 0.784031 0.753848 0.722054 0.771426 0.460257 0.640355 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 180
Initial state: 0 0.493385 0.381068 0.938701 0.779076 0.535101 0.208204 0.657491 0.921478 0.222231 0.586173 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49402 episodes
GETTING ACTION FROM:
action 0, numVisits=49370, meanQ=63.824770, numObservations: 243
action -1, numVisits=27, meanQ=-1.156667, numObservations: 25
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.493385 0.381068 0.938701 0.779076 0.535101 0.208204 0.657491 0.921478 0.222231 0.586173 w: 1
Observation: 0 0 2 0 1 0 1 0 3 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=321, meanQ=86.411038, numObservations: 9
action 4, numVisits=3, meanQ=62.663333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 110196 episodes
GETTING ACTION FROM:
action 1, numVisits=110517, meanQ=85.810028, numObservations: 9
action 4, numVisits=3, meanQ=62.663333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 1
Next state: 1 0.493385 0.381068 0.938701 0.779076 0.535101 0.208204 0.657491 0.921478 0.222231 0.586173 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 181
Initial state: 0 0.417873 0.297699 0.540276 0.389981 0.66709 0.404592 0.0198269 0.731222 0.497642 0.869682 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89809 episodes
GETTING ACTION FROM:
action 1, numVisits=89797, meanQ=31.904566, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=6, meanQ=-4.168333, numObservations: 5
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.417873 0.297699 0.540276 0.389981 0.66709 0.404592 0.0198269 0.731222 0.497642 0.869682 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 182
Initial state: 0 0.586634 0.103169 0.636074 0.857117 0.527478 0.377595 0.952253 0.940006 0.270312 0.379623 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88715 episodes
GETTING ACTION FROM:
action 1, numVisits=88709, meanQ=32.478850, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.586634 0.103169 0.636074 0.857117 0.527478 0.377595 0.952253 0.940006 0.270312 0.379623 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 183
Initial state: 0 0.157444 0.75257 0.842857 0.967692 0.443687 0.138064 0.139494 0.892963 0.426722 0.486925 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 83027 episodes
GETTING ACTION FROM:
action 3, numVisits=83017, meanQ=33.593495, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=5, meanQ=-3.000000, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.157444 0.75257 0.842857 0.967692 0.443687 0.138064 0.139494 0.892963 0.426722 0.486925 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1316, meanQ=36.109082, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 60048 episodes
GETTING ACTION FROM:
action 2, numVisits=61364, meanQ=22.745183, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.157444 0.75257 0.842857 0.967692 0.443687 0.138064 0.139494 0.892963 0.426722 0.486925 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 184
Initial state: 0 0.39907 0.480892 0.362209 0.479599 0.116922 0.822965 0.738829 0.230299 0.8184 0.137372 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 84175 episodes
GETTING ACTION FROM:
action 5, numVisits=84152, meanQ=33.447682, numObservations: 9
action 4, numVisits=6, meanQ=9.001667, numObservations: 4
action 1, numVisits=13, meanQ=2.090785, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.39907 0.480892 0.362209 0.479599 0.116922 0.822965 0.738829 0.230299 0.8184 0.137372 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 185
Initial state: 0 0.0531323 0.782822 0.897007 0.898751 0.511057 0.411625 0.00849946 0.769656 0.141776 0.381535 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 84154 episodes
GETTING ACTION FROM:
action 4, numVisits=84139, meanQ=31.966885, numObservations: 9
action 3, numVisits=10, meanQ=4.901010, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.0531323 0.782822 0.897007 0.898751 0.511057 0.411625 0.00849946 0.769656 0.141776 0.381535 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=8423, meanQ=55.944278, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 60510 episodes
GETTING ACTION FROM:
action 4, numVisits=68933, meanQ=67.268266, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.0531323 0.782822 0.897007 0.898751 0.511057 0.411625 0.00849946 0.769656 0.141776 0.381535 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 0, numVisits=25520, meanQ=66.831017, numObservations: 243
action -1, numVisits=39, meanQ=-3.599231, numObservations: 38
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 57298 episodes
GETTING ACTION FROM:
action 0, numVisits=82818, meanQ=43.738504, numObservations: 243
action -1, numVisits=39, meanQ=-3.599231, numObservations: 38
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 0
Next state: 0 0.0531323 0.782822 0.897007 0.898751 0.511057 0.411625 0.00849946 0.769656 0.141776 0.381535 w: 1
Observation: 0 0 3 0 3 0 3 0 2 0 2 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=81, meanQ=61.753335, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 120080 episodes
GETTING ACTION FROM:
action 1, numVisits=120161, meanQ=72.368965, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 1
Next state: 0 0.0531323 0.782822 0.897007 0.898751 0.511057 0.411625 0.00849946 0.769656 0.141776 0.381535 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 5, numVisits=4054, meanQ=83.150907, numObservations: 9
action 4, numVisits=2, meanQ=44.495000, numObservations: 1
action 2, numVisits=3, meanQ=32.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 123414 episodes
GETTING ACTION FROM:
action 5, numVisits=127468, meanQ=93.736933, numObservations: 9
action 4, numVisits=2, meanQ=44.495000, numObservations: 1
action 2, numVisits=3, meanQ=32.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 5
Next state: 0 0.0531323 0.782822 0.897007 0.898751 0.511057 0.411625 0.00849946 0.769656 0.141776 0.381535 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: -11
Updated belief

t = 5
Improving policy...
PLANNING FROM:
action 2, numVisits=581, meanQ=87.705140, numObservations: 9
action 4, numVisits=2, meanQ=44.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 128165 episodes
GETTING ACTION FROM:
action 2, numVisits=128746, meanQ=65.161797, numObservations: 9
action 4, numVisits=2, meanQ=44.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 2
Next state: 2 0.0531323 0.782822 0.897007 0.898751 0.511057 0.411625 0.00849946 0.769656 0.141776 0.381535 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -141.14
Run # 186
Initial state: 0 0.547991 0.433538 0.313843 0.572661 0.0253759 0.426899 0.538071 0.829151 0.385849 0.691552 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48648 episodes
GETTING ACTION FROM:
action 0, numVisits=48581, meanQ=62.703027, numObservations: 243
action -1, numVisits=58, meanQ=-1.112584, numObservations: 55
action 5, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=3, meanQ=-34.333333, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.547991 0.433538 0.313843 0.572661 0.0253759 0.426899 0.538071 0.829151 0.385849 0.691552 w: 1
Observation: 0 0 2 0 3 0 2 0 3 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=205, meanQ=60.263374, numObservations: 9
action 3, numVisits=116, meanQ=42.199310, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 97457 episodes
GETTING ACTION FROM:
action 2, numVisits=97662, meanQ=64.995543, numObservations: 9
action 3, numVisits=116, meanQ=42.199310, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 2
Next state: 1 0.547991 0.433538 0.313843 0.572661 0.0253759 0.426899 0.538071 0.829151 0.385849 0.691552 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 187
Initial state: 0 0.910062 0.873961 0.441617 0.394345 0.930545 0.591951 0.786782 0.94695 0.93061 0.847882 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 84048 episodes
GETTING ACTION FROM:
action 4, numVisits=84037, meanQ=33.721608, numObservations: 9
action 2, numVisits=4, meanQ=14.270025, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.910062 0.873961 0.441617 0.394345 0.930545 0.591951 0.786782 0.94695 0.93061 0.847882 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 188
Initial state: 0 0.207563 0.278088 0.816082 0.804365 0.416983 0.823139 0.43208 0.457089 0.412864 0.551133 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 83074 episodes
GETTING ACTION FROM:
action 4, numVisits=83062, meanQ=35.127756, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=7, meanQ=-2.287143, numObservations: 4
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.207563 0.278088 0.816082 0.804365 0.416983 0.823139 0.43208 0.457089 0.412864 0.551133 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 189
Initial state: 0 0.821531 0.0118206 0.851582 0.815161 0.246386 0.726479 0.882317 0.377343 0.507032 0.450911 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 85872 episodes
GETTING ACTION FROM:
action 2, numVisits=85860, meanQ=33.302609, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=6, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.821531 0.0118206 0.851582 0.815161 0.246386 0.726479 0.882317 0.377343 0.507032 0.450911 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 190
Initial state: 0 0.796454 0.352981 0.493734 0.831351 0.0138096 0.415288 0.80045 0.625643 0.425762 0.445059 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87375 episodes
GETTING ACTION FROM:
action 5, numVisits=87361, meanQ=31.770316, numObservations: 9
action 1, numVisits=4, meanQ=21.500000, numObservations: 3
action 2, numVisits=6, meanQ=14.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.796454 0.352981 0.493734 0.831351 0.0138096 0.415288 0.80045 0.625643 0.425762 0.445059 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 191
Initial state: 0 0.0856715 0.759201 0.189634 0.091576 0.213813 0.899037 0.0402482 0.165257 0.402352 0.364797 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89994 episodes
GETTING ACTION FROM:
action 2, numVisits=89988, meanQ=33.021237, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.0856715 0.759201 0.189634 0.091576 0.213813 0.899037 0.0402482 0.165257 0.402352 0.364797 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=8138, meanQ=37.865248, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 30017 episodes
GETTING ACTION FROM:
action 4, numVisits=38155, meanQ=37.746280, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.0856715 0.759201 0.189634 0.091576 0.213813 0.899037 0.0402482 0.165257 0.402352 0.364797 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=641, meanQ=56.132291, numObservations: 9
action 3, numVisits=16, meanQ=20.249381, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 63028 episodes
GETTING ACTION FROM:
action 1, numVisits=63669, meanQ=49.059554, numObservations: 9
action 3, numVisits=16, meanQ=20.249381, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 1
Next state: 0 0.0856715 0.759201 0.189634 0.091576 0.213813 0.899037 0.0402482 0.165257 0.402352 0.364797 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=448, meanQ=67.031626, numObservations: 9
action 1, numVisits=2, meanQ=44.495000, numObservations: 1
action 5, numVisits=4, meanQ=21.747500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 53335 episodes
GETTING ACTION FROM:
action 3, numVisits=53781, meanQ=62.566572, numObservations: 9
action 1, numVisits=4, meanQ=21.747500, numObservations: 2
action 5, numVisits=4, meanQ=21.747500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 3
Next state: 1 0.0856715 0.759201 0.189634 0.091576 0.213813 0.899037 0.0402482 0.165257 0.402352 0.364797 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 63.3885
Run # 192
Initial state: 0 0.07736 0.980022 0.805262 0.183745 0.557008 0.360432 0.969997 0.494651 0.882852 0.948572 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88481 episodes
GETTING ACTION FROM:
action 3, numVisits=88473, meanQ=32.537104, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.07736 0.980022 0.805262 0.183745 0.557008 0.360432 0.969997 0.494651 0.882852 0.948572 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 193
Initial state: 0 0.348913 0.693113 0.0284306 0.267944 0.876877 0.698892 0.903869 0.574721 0.548601 0.411888 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 84017 episodes
GETTING ACTION FROM:
action 5, numVisits=84001, meanQ=33.882005, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=8, meanQ=-4.501250, numObservations: 5
action 2, numVisits=4, meanQ=-5.752500, numObservations: 4
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.348913 0.693113 0.0284306 0.267944 0.876877 0.698892 0.903869 0.574721 0.548601 0.411888 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 194
Initial state: 0 0.176411 0.757817 0.214635 0.607184 0.423502 0.359812 0.152713 0.530335 0.751081 0.442415 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48687 episodes
GETTING ACTION FROM:
action 0, numVisits=48629, meanQ=61.548812, numObservations: 243
action -1, numVisits=49, meanQ=-1.252853, numObservations: 43
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=3, meanQ=-34.333333, numObservations: 3
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.176411 0.757817 0.214635 0.607184 0.423502 0.359812 0.152713 0.530335 0.751081 0.442415 w: 1
Observation: 0 0 3 0 3 0 2 0 3 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=384, meanQ=86.970383, numObservations: 9
action 2, numVisits=4, meanQ=71.747500, numObservations: 2
action 4, numVisits=3, meanQ=62.663333, numObservations: 2
action 1, numVisits=3, meanQ=32.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 111984 episodes
GETTING ACTION FROM:
action 3, numVisits=112368, meanQ=90.771209, numObservations: 9
action 2, numVisits=4, meanQ=71.747500, numObservations: 2
action 4, numVisits=3, meanQ=62.663333, numObservations: 2
action 1, numVisits=3, meanQ=32.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 3
Next state: 1 0.176411 0.757817 0.214635 0.607184 0.423502 0.359812 0.152713 0.530335 0.751081 0.442415 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 195
Initial state: 0 0.400883 0.413913 0.0119912 0.980216 0.0657011 0.0231141 0.766952 0.530791 0.0797267 0.894429 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 84550 episodes
GETTING ACTION FROM:
action 4, numVisits=84543, meanQ=33.995913, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.400883 0.413913 0.0119912 0.980216 0.0657011 0.0231141 0.766952 0.530791 0.0797267 0.894429 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 196
Initial state: 0 0.472051 0.467707 0.0718557 0.68525 0.808216 0.661162 0.68038 0.977766 0.0012061 0.210474 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89431 episodes
GETTING ACTION FROM:
action 1, numVisits=89423, meanQ=31.901607, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.472051 0.467707 0.0718557 0.68525 0.808216 0.661162 0.68038 0.977766 0.0012061 0.210474 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1417, meanQ=75.866223, numObservations: 9
action 5, numVisits=4, meanQ=21.747500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 120992 episodes
GETTING ACTION FROM:
action 1, numVisits=122409, meanQ=86.299988, numObservations: 9
action 5, numVisits=4, meanQ=21.747500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.472051 0.467707 0.0718557 0.68525 0.808216 0.661162 0.68038 0.977766 0.0012061 0.210474 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 197
Initial state: 0 0.29713 0.431622 0.621036 0.0112742 0.96406 0.70521 0.128598 0.400194 0.472859 0.488268 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 82702 episodes
GETTING ACTION FROM:
action 2, numVisits=82695, meanQ=33.352474, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.29713 0.431622 0.621036 0.0112742 0.96406 0.70521 0.128598 0.400194 0.472859 0.488268 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 198
Initial state: 0 0.31617 0.705224 0.607681 0.753491 0.499197 0.392715 0.826773 0.394763 0.896992 0.705171 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87146 episodes
GETTING ACTION FROM:
action 4, numVisits=87093, meanQ=32.872628, numObservations: 9
action 1, numVisits=24, meanQ=23.879171, numObservations: 7
action 5, numVisits=3, meanQ=22.363367, numObservations: 2
action 2, numVisits=17, meanQ=20.175882, numObservations: 9
action 3, numVisits=7, meanQ=10.570000, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 4
Next state: 2 0.31617 0.705224 0.607681 0.753491 0.499197 0.392715 0.826773 0.394763 0.896992 0.705171 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 199
Initial state: 0 0.463866 0.38011 0.453726 0.688487 0.854042 0.493277 0.0121832 0.458747 0.13154 0.983739 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 85105 episodes
GETTING ACTION FROM:
action 3, numVisits=85095, meanQ=32.390719, numObservations: 9
action 4, numVisits=5, meanQ=19.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.463866 0.38011 0.453726 0.688487 0.854042 0.493277 0.0121832 0.458747 0.13154 0.983739 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 200
Initial state: 0 0.4876 0.974724 0.444299 0.628177 0.711825 0.127327 0.751326 0.605859 0.466448 0.487624 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 84581 episodes
GETTING ACTION FROM:
action 2, numVisits=84548, meanQ=33.846829, numObservations: 9
action 1, numVisits=19, meanQ=22.688432, numObservations: 6
action 5, numVisits=6, meanQ=14.000000, numObservations: 5
action 3, numVisits=4, meanQ=-1.000000, numObservations: 4
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.4876 0.974724 0.444299 0.628177 0.711825 0.127327 0.751326 0.605859 0.466448 0.487624 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
[32m ProblemEnvironment.hpp 351: Done.[39m
