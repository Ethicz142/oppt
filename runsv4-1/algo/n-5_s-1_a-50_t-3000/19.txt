Run # 1
Initial state: 0 0.476064 0.199091 0.820202 0.494947 0.327929 0.0926702 0.0522671 0.257075 0.325855 0.451687 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 93429 episodes
GETTING ACTION FROM:
action 3, numVisits=93410, meanQ=27.630549, numObservations: 9
action 2, numVisits=5, meanQ=15.000000, numObservations: 4
action 1, numVisits=9, meanQ=10.111111, numObservations: 5
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.476064 0.199091 0.820202 0.494947 0.327929 0.0926702 0.0522671 0.257075 0.325855 0.451687 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 2
Initial state: 0 0.773825 0.604198 0.735536 0.876122 0.993142 0.158398 0.312237 0.531298 0.259501 0.771241 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97466 episodes
GETTING ACTION FROM:
action 4, numVisits=97417, meanQ=25.841907, numObservations: 9
action 5, numVisits=44, meanQ=12.182507, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.773825 0.604198 0.735536 0.876122 0.993142 0.158398 0.312237 0.531298 0.259501 0.771241 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 3
Initial state: 0 0.769694 0.938758 0.839273 0.0389372 0.332444 0.525294 0.240441 0.692819 0.471775 0.215306 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 50492 episodes
GETTING ACTION FROM:
action 0, numVisits=50405, meanQ=64.774852, numObservations: 243
action -1, numVisits=74, meanQ=-2.696211, numObservations: 61
action 3, numVisits=6, meanQ=-4.333333, numObservations: 4
action 5, numVisits=4, meanQ=-28.500000, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.769694 0.938758 0.839273 0.0389372 0.332444 0.525294 0.240441 0.692819 0.471775 0.215306 w: 1
Observation: 0 0 3 0 1 0 2 0 3 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=272, meanQ=81.851966, numObservations: 9
action 1, numVisits=20, meanQ=67.499500, numObservations: 6
action 5, numVisits=2, meanQ=44.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 113797 episodes
GETTING ACTION FROM:
action 3, numVisits=114069, meanQ=91.009167, numObservations: 9
action 1, numVisits=20, meanQ=67.499500, numObservations: 6
action 5, numVisits=2, meanQ=44.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 3
Next state: 1 0.769694 0.938758 0.839273 0.0389372 0.332444 0.525294 0.240441 0.692819 0.471775 0.215306 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 4
Initial state: 0 0.260112 0.138168 0.430458 0.577261 0.299782 0.572628 0.365077 0.510863 0.775292 0.139195 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 96855 episodes
GETTING ACTION FROM:
action 4, numVisits=96849, meanQ=26.863645, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.260112 0.138168 0.430458 0.577261 0.299782 0.572628 0.365077 0.510863 0.775292 0.139195 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 5
Initial state: 0 0.327687 0.189144 0.494137 0.119571 0.370477 0.435125 0.236095 0.972379 0.263455 0.615162 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87841 episodes
GETTING ACTION FROM:
action 3, numVisits=87829, meanQ=30.836650, numObservations: 9
action 5, numVisits=5, meanQ=15.198000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.327687 0.189144 0.494137 0.119571 0.370477 0.435125 0.236095 0.972379 0.263455 0.615162 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 6
Initial state: 0 0.151874 0.114811 0.359555 0.519803 0.678753 0.940426 0.971552 0.421733 0.999813 0.51603 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89016 episodes
GETTING ACTION FROM:
action 2, numVisits=89007, meanQ=29.700260, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=3, meanQ=-4.333333, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.151874 0.114811 0.359555 0.519803 0.678753 0.940426 0.971552 0.421733 0.999813 0.51603 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 7
Initial state: 0 0.294181 0.437379 0.187242 0.356423 0.169127 0.455868 0.371502 0.460457 0.97712 0.375244 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97515 episodes
GETTING ACTION FROM:
action 3, numVisits=97455, meanQ=27.506519, numObservations: 9
action 1, numVisits=48, meanQ=24.958554, numObservations: 8
action 5, numVisits=6, meanQ=14.000000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.294181 0.437379 0.187242 0.356423 0.169127 0.455868 0.371502 0.460457 0.97712 0.375244 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=6439, meanQ=33.883349, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 108539 episodes
GETTING ACTION FROM:
action 1, numVisits=114978, meanQ=43.128219, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.294181 0.437379 0.187242 0.356423 0.169127 0.455868 0.371502 0.460457 0.97712 0.375244 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -110.99
Run # 8
Initial state: 0 0.357791 0.431419 0.851579 0.243524 0.842851 0.896866 0.79429 0.0381095 0.286592 0.636949 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97726 episodes
GETTING ACTION FROM:
action 4, numVisits=97708, meanQ=27.310897, numObservations: 9
action 3, numVisits=6, meanQ=12.001667, numObservations: 5
action 5, numVisits=7, meanQ=10.711429, numObservations: 6
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.357791 0.431419 0.851579 0.243524 0.842851 0.896866 0.79429 0.0381095 0.286592 0.636949 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 9
Initial state: 0 0.468728 0.241071 0.490284 0.494697 0.0123286 0.871583 0.289227 0.231303 0.352102 0.506312 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 93150 episodes
GETTING ACTION FROM:
action 1, numVisits=93111, meanQ=28.347754, numObservations: 9
action -1, numVisits=8, meanQ=-1.010000, numObservations: 8
action 0, numVisits=8, meanQ=-1.010000, numObservations: 8
action 3, numVisits=20, meanQ=-1.536980, numObservations: 8
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.468728 0.241071 0.490284 0.494697 0.0123286 0.871583 0.289227 0.231303 0.352102 0.506312 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 10
Initial state: 0 0.0562815 0.850291 0.365991 0.517441 0.540667 0.150953 0.981506 0.698192 0.0348723 0.0447567 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91472 episodes
GETTING ACTION FROM:
action 4, numVisits=91462, meanQ=28.010008, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.0562815 0.850291 0.365991 0.517441 0.540667 0.150953 0.981506 0.698192 0.0348723 0.0447567 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 11
Initial state: 0 0.114541 0.153543 0.404202 0.522387 0.529985 0.46628 0.410092 0.210211 0.796719 0.433326 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92142 episodes
GETTING ACTION FROM:
action 1, numVisits=92136, meanQ=27.584504, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.114541 0.153543 0.404202 0.522387 0.529985 0.46628 0.410092 0.210211 0.796719 0.433326 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=6534, meanQ=31.279549, numObservations: 9
action 2, numVisits=13, meanQ=20.690769, numObservations: 6
action 4, numVisits=18, meanQ=19.220000, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=5, meanQ=-2.802000, numObservations: 4
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 35569 episodes
GETTING ACTION FROM:
action 3, numVisits=42103, meanQ=31.174780, numObservations: 9
action 2, numVisits=13, meanQ=20.690769, numObservations: 6
action 4, numVisits=18, meanQ=19.220000, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=5, meanQ=-2.802000, numObservations: 4
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.114541 0.153543 0.404202 0.522387 0.529985 0.46628 0.410092 0.210211 0.796719 0.433326 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 12
Initial state: 0 0.727077 0.34339 0.784118 0.667234 0.313798 0.48429 0.37741 0.983442 0.35423 0.749786 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95681 episodes
GETTING ACTION FROM:
action 1, numVisits=95650, meanQ=27.182138, numObservations: 9
action 5, numVisits=17, meanQ=19.115882, numObservations: 8
action 2, numVisits=5, meanQ=19.000000, numObservations: 4
action 4, numVisits=6, meanQ=14.000000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.727077 0.34339 0.784118 0.667234 0.313798 0.48429 0.37741 0.983442 0.35423 0.749786 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 13
Initial state: 0 0.401189 0.91394 0.910203 0.483022 0.378617 0.411774 0.53722 0.694556 0.806778 0.155561 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 93126 episodes
GETTING ACTION FROM:
action 3, numVisits=93112, meanQ=28.681508, numObservations: 9
action 1, numVisits=4, meanQ=21.500000, numObservations: 4
action 5, numVisits=4, meanQ=21.500000, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.401189 0.91394 0.910203 0.483022 0.378617 0.411774 0.53722 0.694556 0.806778 0.155561 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 14
Initial state: 0 0.671167 0.886088 0.362634 0.437887 0.328229 0.0258007 0.5048 0.918438 0.190757 0.553519 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 96265 episodes
GETTING ACTION FROM:
action 4, numVisits=96228, meanQ=27.888799, numObservations: 9
action 1, numVisits=31, meanQ=12.905490, numObservations: 8
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.671167 0.886088 0.362634 0.437887 0.328229 0.0258007 0.5048 0.918438 0.190757 0.553519 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 15
Initial state: 0 0.374309 0.463534 0.205485 0.83994 0.647992 0.965499 0.374477 0.370781 0.506849 0.812862 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95997 episodes
GETTING ACTION FROM:
action 2, numVisits=95983, meanQ=27.046117, numObservations: 9
action 4, numVisits=9, meanQ=20.221111, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.374309 0.463534 0.205485 0.83994 0.647992 0.965499 0.374477 0.370781 0.506849 0.812862 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=6258, meanQ=32.234353, numObservations: 9
action 1, numVisits=47, meanQ=10.960649, numObservations: 7
action 4, numVisits=17, meanQ=10.234706, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 108901 episodes
GETTING ACTION FROM:
action 5, numVisits=115159, meanQ=43.448223, numObservations: 9
action 1, numVisits=47, meanQ=10.960649, numObservations: 7
action 4, numVisits=17, meanQ=10.234706, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 5
Next state: 1 0.374309 0.463534 0.205485 0.83994 0.647992 0.965499 0.374477 0.370781 0.506849 0.812862 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 16
Initial state: 0 0.350264 0.692267 0.11237 0.856466 0.64512 0.155655 0.583725 0.422833 0.359666 0.396601 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97297 episodes
GETTING ACTION FROM:
action 5, numVisits=97279, meanQ=26.797204, numObservations: 9
action 2, numVisits=13, meanQ=12.076923, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.350264 0.692267 0.11237 0.856466 0.64512 0.155655 0.583725 0.422833 0.359666 0.396601 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 17
Initial state: 0 0.142508 0.789532 0.75204 0.456629 0.148911 0.152871 0.839295 0.982742 0.326825 0.449298 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87933 episodes
GETTING ACTION FROM:
action 3, numVisits=87927, meanQ=29.918361, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.142508 0.789532 0.75204 0.456629 0.148911 0.152871 0.839295 0.982742 0.326825 0.449298 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=5877, meanQ=64.810244, numObservations: 240
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 4, numVisits=5, meanQ=-2.802000, numObservations: 3
action 1, numVisits=3, meanQ=-4.003333, numObservations: 3
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 57163 episodes
GETTING ACTION FROM:
action 0, numVisits=63040, meanQ=43.613720, numObservations: 243
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 4, numVisits=5, meanQ=-2.802000, numObservations: 3
action 1, numVisits=3, meanQ=-4.003333, numObservations: 3
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.142508 0.789532 0.75204 0.456629 0.148911 0.152871 0.839295 0.982742 0.326825 0.449298 w: 1
Observation: 0 0 3 0 2 0 1 0 3 0 2 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=93, meanQ=71.381959, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=5, meanQ=-2.802000, numObservations: 3
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 94846 episodes
GETTING ACTION FROM:
action 1, numVisits=94939, meanQ=75.527198, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=5, meanQ=-2.802000, numObservations: 3
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 1
Next state: 0 0.142508 0.789532 0.75204 0.456629 0.148911 0.152871 0.839295 0.982742 0.326825 0.449298 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=1795, meanQ=92.611775, numObservations: 9
action 4, numVisits=14, meanQ=56.142857, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 85128 episodes
GETTING ACTION FROM:
action 2, numVisits=86923, meanQ=88.698377, numObservations: 9
action 4, numVisits=14, meanQ=56.142857, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 2
Next state: 2 0.142508 0.789532 0.75204 0.456629 0.148911 0.152871 0.839295 0.982742 0.326825 0.449298 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -121.761
Run # 18
Initial state: 0 0.381994 0.417472 0.504545 0.522785 0.362374 0.749901 0.00733063 0.00221613 0.671392 0.970688 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 96879 episodes
GETTING ACTION FROM:
action 5, numVisits=96864, meanQ=27.442712, numObservations: 9
action 4, numVisits=9, meanQ=17.998889, numObservations: 6
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.381994 0.417472 0.504545 0.522785 0.362374 0.749901 0.00733063 0.00221613 0.671392 0.970688 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 19
Initial state: 0 0.0764103 0.686473 0.410157 0.95929 0.614233 0.237877 0.225741 0.470389 0.387018 0.516988 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 96442 episodes
GETTING ACTION FROM:
action 3, numVisits=96429, meanQ=27.348616, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=7, meanQ=-2.287143, numObservations: 5
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.0764103 0.686473 0.410157 0.95929 0.614233 0.237877 0.225741 0.470389 0.387018 0.516988 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 20
Initial state: 0 0.132099 0.0905847 0.987268 0.280511 0.502585 0.455379 0.142045 0.572869 0.418274 0.408532 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91802 episodes
GETTING ACTION FROM:
action 3, numVisits=91796, meanQ=28.635422, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.132099 0.0905847 0.987268 0.280511 0.502585 0.455379 0.142045 0.572869 0.418274 0.408532 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 21
Initial state: 0 0.893278 0.58131 0.341748 0.517086 0.530577 0.907954 0.081843 0.470994 0.588208 0.238567 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91136 episodes
GETTING ACTION FROM:
action 1, numVisits=91126, meanQ=28.990402, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.893278 0.58131 0.341748 0.517086 0.530577 0.907954 0.081843 0.470994 0.588208 0.238567 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 22
Initial state: 0 0.139181 0.558234 0.456276 0.351031 0.671393 0.553647 0.913611 0.823429 0.373347 0.453164 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92837 episodes
GETTING ACTION FROM:
action 2, numVisits=92828, meanQ=27.196867, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 3
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.139181 0.558234 0.456276 0.351031 0.671393 0.553647 0.913611 0.823429 0.373347 0.453164 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 23
Initial state: 0 0.3833 0.455592 0.535144 0.510602 0.0063234 0.977236 0.684141 0.936905 0.178512 0.841753 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92295 episodes
GETTING ACTION FROM:
action 2, numVisits=92250, meanQ=29.372877, numObservations: 9
action 4, numVisits=31, meanQ=3.612258, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=3, meanQ=-4.333333, numObservations: 3
action 3, numVisits=8, meanQ=-6.124987, numObservations: 6
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.3833 0.455592 0.535144 0.510602 0.0063234 0.977236 0.684141 0.936905 0.178512 0.841753 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 24
Initial state: 0 0.337671 0.449783 0.55206 0.219364 0.636224 0.665039 0.511416 0.265203 0.187224 0.636377 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97668 episodes
GETTING ACTION FROM:
action 1, numVisits=97622, meanQ=27.713449, numObservations: 9
action 5, numVisits=40, meanQ=24.524500, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.337671 0.449783 0.55206 0.219364 0.636224 0.665039 0.511416 0.265203 0.187224 0.636377 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 25
Initial state: 0 0.677866 0.598064 0.314529 0.53202 0.0181695 0.337315 0.894878 0.548559 0.435317 0.266217 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92426 episodes
GETTING ACTION FROM:
action 5, numVisits=92413, meanQ=29.052339, numObservations: 9
action 2, numVisits=6, meanQ=10.500017, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.677866 0.598064 0.314529 0.53202 0.0181695 0.337315 0.894878 0.548559 0.435317 0.266217 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=569, meanQ=22.825130, numObservations: 9
action 3, numVisits=6, meanQ=14.165000, numObservations: 4
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 108123 episodes
GETTING ACTION FROM:
action 1, numVisits=108692, meanQ=35.728676, numObservations: 9
action 3, numVisits=6, meanQ=14.165000, numObservations: 4
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.677866 0.598064 0.314529 0.53202 0.0181695 0.337315 0.894878 0.548559 0.435317 0.266217 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 26
Initial state: 0 0.735303 0.0668539 0.185343 0.424231 0.937811 0.905899 0.982802 0.589009 0.428336 0.450905 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 94937 episodes
GETTING ACTION FROM:
action 3, numVisits=94913, meanQ=27.989050, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 4, numVisits=7, meanQ=-2.287143, numObservations: 5
action 2, numVisits=11, meanQ=-4.637273, numObservations: 5
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.735303 0.0668539 0.185343 0.424231 0.937811 0.905899 0.982802 0.589009 0.428336 0.450905 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 27
Initial state: 0 0.939118 0.663152 0.381982 0.41552 0.998469 0.902892 0.680426 0.568923 0.927491 0.472879 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92166 episodes
GETTING ACTION FROM:
action 4, numVisits=92134, meanQ=28.243833, numObservations: 9
action 3, numVisits=24, meanQ=8.253754, numObservations: 8
action 1, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.939118 0.663152 0.381982 0.41552 0.998469 0.902892 0.680426 0.568923 0.927491 0.472879 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 28
Initial state: 0 0.0760962 0.164618 0.336061 0.422539 0.000509896 0.957252 0.683905 0.776315 0.112918 0.178205 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 93265 episodes
GETTING ACTION FROM:
action 5, numVisits=93254, meanQ=29.451408, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=5, meanQ=-3.000000, numObservations: 4
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.0760962 0.164618 0.336061 0.422539 0.000509896 0.957252 0.683905 0.776315 0.112918 0.178205 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=6640, meanQ=34.885630, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 30748 episodes
GETTING ACTION FROM:
action 2, numVisits=37388, meanQ=25.530034, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.0760962 0.164618 0.336061 0.422539 0.000509896 0.957252 0.683905 0.776315 0.112918 0.178205 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 29
Initial state: 0 0.612705 0.494687 0.959956 0.137984 0.07052 0.586007 0.288814 0.26865 0.32977 0.483587 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 98165 episodes
GETTING ACTION FROM:
action 4, numVisits=98152, meanQ=26.957776, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=6, meanQ=-4.499983, numObservations: 4
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.612705 0.494687 0.959956 0.137984 0.07052 0.586007 0.288814 0.26865 0.32977 0.483587 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=7062, meanQ=32.059189, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 33950 episodes
GETTING ACTION FROM:
action 2, numVisits=41012, meanQ=33.975190, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.612705 0.494687 0.959956 0.137984 0.07052 0.586007 0.288814 0.26865 0.32977 0.483587 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -110.99
Run # 30
Initial state: 0 0.747393 0.521401 0.653579 0.3254 0.250931 0.0113855 0.404662 0.463093 0.786784 0.263175 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 98036 episodes
GETTING ACTION FROM:
action 3, numVisits=98025, meanQ=28.043610, numObservations: 9
action 4, numVisits=6, meanQ=14.000000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.747393 0.521401 0.653579 0.3254 0.250931 0.0113855 0.404662 0.463093 0.786784 0.263175 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=7017, meanQ=34.048082, numObservations: 9
action 2, numVisits=5, meanQ=15.396000, numObservations: 4
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 31473 episodes
GETTING ACTION FROM:
action 5, numVisits=38490, meanQ=26.852752, numObservations: 9
action 2, numVisits=5, meanQ=15.396000, numObservations: 4
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 5
Next state: 2 0.747393 0.521401 0.653579 0.3254 0.250931 0.0113855 0.404662 0.463093 0.786784 0.263175 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -110.99
Run # 31
Initial state: 0 0.348527 0.440209 0.19787 0.125795 0.552053 0.274006 0.0986591 0.0924045 0.273411 0.334003 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91943 episodes
GETTING ACTION FROM:
action 3, numVisits=91934, meanQ=28.389664, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.348527 0.440209 0.19787 0.125795 0.552053 0.274006 0.0986591 0.0924045 0.273411 0.334003 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 32
Initial state: 0 0.0675449 0.0252407 0.851658 0.968465 0.401891 0.868929 0.392901 0.0511015 0.390823 0.509735 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 96489 episodes
GETTING ACTION FROM:
action 2, numVisits=96473, meanQ=27.375553, numObservations: 9
action 1, numVisits=9, meanQ=20.111111, numObservations: 7
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.0675449 0.0252407 0.851658 0.968465 0.401891 0.868929 0.392901 0.0511015 0.390823 0.509735 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 33
Initial state: 0 0.991502 0.420254 0.332893 0.280737 0.551212 0.608293 0.627269 0.945711 0.318443 0.448059 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 90956 episodes
GETTING ACTION FROM:
action 4, numVisits=90950, meanQ=28.419888, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.991502 0.420254 0.332893 0.280737 0.551212 0.608293 0.627269 0.945711 0.318443 0.448059 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 34
Initial state: 0 0.42381 0.47727 0.552841 0.0784428 0.0919284 0.137161 0.492346 0.297572 0.104475 0.631909 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 94687 episodes
GETTING ACTION FROM:
action 4, numVisits=94673, meanQ=27.647183, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=8, meanQ=-1.000000, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.42381 0.47727 0.552841 0.0784428 0.0919284 0.137161 0.492346 0.297572 0.104475 0.631909 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 35
Initial state: 0 0.175746 0.317807 0.338316 0.481321 0.950742 0.982553 0.864532 0.63601 0.379622 0.340892 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88588 episodes
GETTING ACTION FROM:
action 3, numVisits=88577, meanQ=29.326812, numObservations: 9
action 1, numVisits=6, meanQ=14.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.175746 0.317807 0.338316 0.481321 0.950742 0.982553 0.864532 0.63601 0.379622 0.340892 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 36
Initial state: 0 0.607546 0.533418 0.381967 0.493683 0.564599 0.0853519 0.302219 0.0998258 0.652917 0.923242 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49756 episodes
GETTING ACTION FROM:
action -1, numVisits=49693, meanQ=47.811308, numObservations: 243
action 5, numVisits=35, meanQ=-3.457997, numObservations: 9
action 0, numVisits=24, meanQ=-5.217500, numObservations: 23
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.607546 0.533418 0.381967 0.493683 0.564599 0.0853519 0.302219 0.0998258 0.652917 0.923242 w: 1
Observation: 0 3 0 2 0 3 0 2 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=377, meanQ=45.650560, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 110760 episodes
GETTING ACTION FROM:
action 4, numVisits=111137, meanQ=43.823379, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.607546 0.533418 0.381967 0.493683 0.564599 0.0853519 0.302219 0.0998258 0.652917 0.923242 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101.99
Run # 37
Initial state: 0 0.674862 0.0602041 0.0300863 0.155875 0.602005 0.841658 0.380811 0.488844 0.445104 0.979079 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 85649 episodes
GETTING ACTION FROM:
action 3, numVisits=85599, meanQ=29.917444, numObservations: 9
action 5, numVisits=44, meanQ=21.045234, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.674862 0.0602041 0.0300863 0.155875 0.602005 0.841658 0.380811 0.488844 0.445104 0.979079 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 38
Initial state: 0 0.0333792 0.309352 0.4234 0.538185 0.620436 0.0735978 0.126019 0.312953 0.344497 0.442516 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97284 episodes
GETTING ACTION FROM:
action 2, numVisits=97202, meanQ=27.237231, numObservations: 9
action 0, numVisits=40, meanQ=-3.633500, numObservations: 37
action -1, numVisits=34, meanQ=-4.038526, numObservations: 32
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=5, meanQ=-21.000000, numObservations: 4
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.0333792 0.309352 0.4234 0.538185 0.620436 0.0735978 0.126019 0.312953 0.344497 0.442516 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 39
Initial state: 0 0.336124 0.502717 0.738813 0.135599 0.126946 0.213873 0.522362 0.719033 0.314197 0.754551 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95633 episodes
GETTING ACTION FROM:
action 5, numVisits=95627, meanQ=26.970110, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.336124 0.502717 0.738813 0.135599 0.126946 0.213873 0.522362 0.719033 0.314197 0.754551 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 40
Initial state: 0 0.830501 0.390758 0.387994 0.529991 0.18196 0.175466 0.44128 0.659719 0.599511 0.482241 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97483 episodes
GETTING ACTION FROM:
action 2, numVisits=97468, meanQ=27.762302, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=8, meanQ=-3.500000, numObservations: 5
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.830501 0.390758 0.387994 0.529991 0.18196 0.175466 0.44128 0.659719 0.599511 0.482241 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 41
Initial state: 0 0.849055 0.44308 0.535124 0.0270712 0.814485 0.705017 0.429478 0.488234 0.746355 0.921259 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97900 episodes
GETTING ACTION FROM:
action 1, numVisits=97873, meanQ=27.273464, numObservations: 9
action 5, numVisits=21, meanQ=15.189529, numObservations: 8
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.849055 0.44308 0.535124 0.0270712 0.814485 0.705017 0.429478 0.488234 0.746355 0.921259 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 42
Initial state: 0 0.075607 0.480467 0.420906 0.521596 0.871599 0.698617 0.692792 0.50022 0.183523 0.395252 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 90973 episodes
GETTING ACTION FROM:
action 3, numVisits=90945, meanQ=29.031617, numObservations: 9
action 1, numVisits=18, meanQ=11.726678, numObservations: 6
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=5, meanQ=-2.802000, numObservations: 3
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.075607 0.480467 0.420906 0.521596 0.871599 0.698617 0.692792 0.50022 0.183523 0.395252 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 43
Initial state: 0 0.116774 0.459677 0.984476 0.428437 0.986974 0.816135 0.156351 0.936515 0.31654 0.530967 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92496 episodes
GETTING ACTION FROM:
action 4, numVisits=92482, meanQ=28.918375, numObservations: 9
action 5, numVisits=9, meanQ=20.221111, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.116774 0.459677 0.984476 0.428437 0.986974 0.816135 0.156351 0.936515 0.31654 0.530967 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 44
Initial state: 0 0.441214 0.638367 0.405464 0.446436 0.425356 0.964634 0.422146 0.220849 0.57467 0.553592 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49761 episodes
GETTING ACTION FROM:
action -1, numVisits=49738, meanQ=54.997769, numObservations: 243
action 0, numVisits=10, meanQ=-1.010000, numObservations: 10
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 5, numVisits=3, meanQ=-4.333333, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=3, meanQ=-34.333333, numObservations: 3
action: -1
Next state: 0 0.441214 0.638367 0.405464 0.446436 0.425356 0.964634 0.422146 0.220849 0.57467 0.553592 w: 1
Observation: 0 3 0 2 0 1 0 2 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=226, meanQ=53.364518, numObservations: 9
action 2, numVisits=8, meanQ=10.373750, numObservations: 6
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 104264 episodes
GETTING ACTION FROM:
action 4, numVisits=104490, meanQ=44.816201, numObservations: 9
action 2, numVisits=8, meanQ=10.373750, numObservations: 6
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 4
Next state: 2 0.441214 0.638367 0.405464 0.446436 0.425356 0.964634 0.422146 0.220849 0.57467 0.553592 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101.99
Run # 45
Initial state: 0 0.315739 0.40812 0.462822 0.440173 0.645205 0.374189 0.451423 0.383645 0.681362 0.297022 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 90620 episodes
GETTING ACTION FROM:
action 5, numVisits=90612, meanQ=28.374484, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.315739 0.40812 0.462822 0.440173 0.645205 0.374189 0.451423 0.383645 0.681362 0.297022 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 46
Initial state: 0 0.357259 0.522871 0.899239 0.495425 0.732103 0.035383 0.752479 0.076521 0.142608 0.899656 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95507 episodes
GETTING ACTION FROM:
action 3, numVisits=95498, meanQ=26.189057, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=3, meanQ=-4.333333, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.357259 0.522871 0.899239 0.495425 0.732103 0.035383 0.752479 0.076521 0.142608 0.899656 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 47
Initial state: 0 0.631008 0.031585 0.842392 0.638102 0.346415 0.47022 0.0393957 0.232768 0.662533 0.994708 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 93234 episodes
GETTING ACTION FROM:
action 1, numVisits=93223, meanQ=27.989484, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=4, meanQ=-1.000000, numObservations: 3
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.631008 0.031585 0.842392 0.638102 0.346415 0.47022 0.0393957 0.232768 0.662533 0.994708 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 48
Initial state: 0 0.0625648 0.154636 0.729687 0.988932 0.296765 0.1383 0.788354 0.673845 0.400316 0.500457 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 93104 episodes
GETTING ACTION FROM:
action 5, numVisits=93077, meanQ=29.543298, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=18, meanQ=-2.111111, numObservations: 7
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.0625648 0.154636 0.729687 0.988932 0.296765 0.1383 0.788354 0.673845 0.400316 0.500457 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 49
Initial state: 0 0.408107 0.416473 0.459433 0.578447 0.543492 0.193462 0.104726 0.674174 0.067531 0.493855 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92998 episodes
GETTING ACTION FROM:
action 3, numVisits=92976, meanQ=28.631051, numObservations: 9
action 2, numVisits=15, meanQ=3.065340, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.408107 0.416473 0.459433 0.578447 0.543492 0.193462 0.104726 0.674174 0.067531 0.493855 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 50
Initial state: 0 0.0306627 0.815443 0.434446 0.172678 0.367141 0.439524 0.967375 0.334899 0.163461 0.271114 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 94844 episodes
GETTING ACTION FROM:
action 1, numVisits=94836, meanQ=27.185067, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.0306627 0.815443 0.434446 0.172678 0.367141 0.439524 0.967375 0.334899 0.163461 0.271114 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=445, meanQ=30.492834, numObservations: 9
action 2, numVisits=9, meanQ=7.887789, numObservations: 7
action 5, numVisits=13, meanQ=6.692308, numObservations: 8
action 3, numVisits=16, meanQ=4.686875, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 79555 episodes
GETTING ACTION FROM:
action 4, numVisits=80000, meanQ=42.284524, numObservations: 9
action 2, numVisits=9, meanQ=7.887789, numObservations: 7
action 5, numVisits=13, meanQ=6.692308, numObservations: 8
action 3, numVisits=16, meanQ=4.686875, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 4
Next state: 0 0.0306627 0.815443 0.434446 0.172678 0.367141 0.439524 0.967375 0.334899 0.163461 0.271114 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=1, meanQ=99.000000, numObservations: 1
action 2, numVisits=162, meanQ=20.575707, numObservations: 9
action -1, numVisits=5, meanQ=-1.010000, numObservations: 5
action 0, numVisits=5, meanQ=-1.010000, numObservations: 5
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 76463 episodes
GETTING ACTION FROM:
action 1, numVisits=189, meanQ=45.978837, numObservations: 9
action 2, numVisits=1784, meanQ=2.474969, numObservations: 9
action 0, numVisits=74412, meanQ=-1.354762, numObservations: 243
action -1, numVisits=251, meanQ=-4.192516, numObservations: 87
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.0306627 0.815443 0.434446 0.172678 0.367141 0.439524 0.967375 0.334899 0.163461 0.271114 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 75.1399
Run # 51
Initial state: 0 0.305872 0.420776 0.671121 0.430816 0.179605 0.900896 0.0245293 0.282703 0.124377 0.299407 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49671 episodes
GETTING ACTION FROM:
action -1, numVisits=49655, meanQ=54.373185, numObservations: 243
action 0, numVisits=7, meanQ=-1.010000, numObservations: 7
action 1, numVisits=3, meanQ=-4.333333, numObservations: 2
action 3, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.305872 0.420776 0.671121 0.430816 0.179605 0.900896 0.0245293 0.282703 0.124377 0.299407 w: 1
Observation: 0 2 0 3 0 1 0 1 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=141, meanQ=82.801418, numObservations: 8
action 4, numVisits=2, meanQ=44.495000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 108716 episodes
GETTING ACTION FROM:
action 1, numVisits=108857, meanQ=79.901013, numObservations: 9
action 4, numVisits=2, meanQ=44.495000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 1
Next state: 1 0.305872 0.420776 0.671121 0.430816 0.179605 0.900896 0.0245293 0.282703 0.124377 0.299407 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 52
Initial state: 0 0.225297 0.10772 0.505288 0.590794 0.404375 0.486484 0.854421 0.155697 0.329408 0.967579 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95179 episodes
GETTING ACTION FROM:
action 3, numVisits=95169, meanQ=26.423209, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=5, meanQ=-3.000000, numObservations: 4
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.225297 0.10772 0.505288 0.590794 0.404375 0.486484 0.854421 0.155697 0.329408 0.967579 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 53
Initial state: 0 0.175734 0.337224 0.303379 0.505182 0.0348809 0.240146 0.0527666 0.262398 0.28681 0.753075 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 93104 episodes
GETTING ACTION FROM:
action 2, numVisits=93090, meanQ=28.130869, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=9, meanQ=-2.111111, numObservations: 2
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.175734 0.337224 0.303379 0.505182 0.0348809 0.240146 0.0527666 0.262398 0.28681 0.753075 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 54
Initial state: 0 0.491502 0.0468337 0.34833 0.528398 0.0645382 0.0439671 0.356659 0.300876 0.421686 0.688591 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 50403 episodes
GETTING ACTION FROM:
action 0, numVisits=50364, meanQ=64.383951, numObservations: 243
action 2, numVisits=20, meanQ=-2.000000, numObservations: 6
action -1, numVisits=15, meanQ=-7.742000, numObservations: 14
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.491502 0.0468337 0.34833 0.528398 0.0645382 0.0439671 0.356659 0.300876 0.421686 0.688591 w: 1
Observation: 0 0 1 0 3 0 1 0 1 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=124, meanQ=61.085345, numObservations: 8
action 4, numVisits=3, meanQ=32.333333, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 106405 episodes
GETTING ACTION FROM:
action 5, numVisits=106529, meanQ=68.138977, numObservations: 9
action 4, numVisits=3, meanQ=32.333333, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 5
Next state: 2 0.491502 0.0468337 0.34833 0.528398 0.0645382 0.0439671 0.356659 0.300876 0.421686 0.688591 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101.99
Run # 55
Initial state: 0 0.78296 0.596467 0.948636 0.196318 0.327978 0.525162 0.00301619 0.375957 0.935348 0.791501 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 96286 episodes
GETTING ACTION FROM:
action 2, numVisits=96231, meanQ=25.323497, numObservations: 9
action 3, numVisits=50, meanQ=21.799600, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.78296 0.596467 0.948636 0.196318 0.327978 0.525162 0.00301619 0.375957 0.935348 0.791501 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 56
Initial state: 0 0.32145 0.240848 0.142767 0.754569 0.301755 0.446846 0.789003 0.751386 0.994262 0.600914 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 93476 episodes
GETTING ACTION FROM:
action 4, numVisits=93464, meanQ=29.437566, numObservations: 9
action 3, numVisits=7, meanQ=10.428571, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.32145 0.240848 0.142767 0.754569 0.301755 0.446846 0.789003 0.751386 0.994262 0.600914 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 57
Initial state: 0 0.418262 0.401009 0.0870191 0.0689128 0.144809 0.584238 0.679794 0.625686 0.834393 0.204257 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49180 episodes
GETTING ACTION FROM:
action -1, numVisits=49158, meanQ=51.955760, numObservations: 243
action 0, numVisits=13, meanQ=-2.001523, numObservations: 11
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 5, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.418262 0.401009 0.0870191 0.0689128 0.144809 0.584238 0.679794 0.625686 0.834393 0.204257 w: 1
Observation: 0 2 0 1 0 1 0 1 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=112, meanQ=69.465005, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 111105 episodes
GETTING ACTION FROM:
action 1, numVisits=111217, meanQ=80.288177, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.418262 0.401009 0.0870191 0.0689128 0.144809 0.584238 0.679794 0.625686 0.834393 0.204257 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 58
Initial state: 0 0.938169 0.274196 0.704754 0.187965 0.346372 0.529 0.94332 0.682813 0.411336 0.0435552 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 50545 episodes
GETTING ACTION FROM:
action 0, numVisits=50531, meanQ=63.422181, numObservations: 243
action -1, numVisits=5, meanQ=-1.010000, numObservations: 5
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action 5, numVisits=3, meanQ=-4.333333, numObservations: 3
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.938169 0.274196 0.704754 0.187965 0.346372 0.529 0.94332 0.682813 0.411336 0.0435552 w: 1
Observation: 0 0 1 0 1 0 2 0 3 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=301, meanQ=89.161637, numObservations: 9
action 5, numVisits=4, meanQ=71.747500, numObservations: 3
action 4, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 113980 episodes
GETTING ACTION FROM:
action 3, numVisits=114281, meanQ=88.619864, numObservations: 9
action 5, numVisits=4, meanQ=71.747500, numObservations: 3
action 4, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 3
Next state: 1 0.938169 0.274196 0.704754 0.187965 0.346372 0.529 0.94332 0.682813 0.411336 0.0435552 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 59
Initial state: 0 0.887984 0.425336 0.245994 0.657955 0.716064 0.577697 0.517269 0.802391 0.342329 0.417495 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97428 episodes
GETTING ACTION FROM:
action 4, numVisits=97212, meanQ=26.901080, numObservations: 9
action 5, numVisits=144, meanQ=23.405072, numObservations: 9
action 3, numVisits=32, meanQ=21.780941, numObservations: 9
action 2, numVisits=37, meanQ=20.950546, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.887984 0.425336 0.245994 0.657955 0.716064 0.577697 0.517269 0.802391 0.342329 0.417495 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 60
Initial state: 0 0.759541 0.372889 0.863688 0.528447 0.453689 0.877429 0.254649 0.96092 0.325907 0.517536 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91686 episodes
GETTING ACTION FROM:
action 5, numVisits=91671, meanQ=28.962699, numObservations: 9
action 3, numVisits=6, meanQ=14.165000, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=4, meanQ=-6.000000, numObservations: 4
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.759541 0.372889 0.863688 0.528447 0.453689 0.877429 0.254649 0.96092 0.325907 0.517536 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 61
Initial state: 0 0.532635 0.0493526 0.400782 0.508564 0.851 0.229506 0.610024 0.277364 0.00121509 0.731314 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49575 episodes
GETTING ACTION FROM:
action -1, numVisits=49512, meanQ=54.328877, numObservations: 243
action 0, numVisits=42, meanQ=-1.199043, numObservations: 38
action 5, numVisits=9, meanQ=-2.111111, numObservations: 7
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 3, numVisits=5, meanQ=-21.000000, numObservations: 4
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.532635 0.0493526 0.400782 0.508564 0.851 0.229506 0.610024 0.277364 0.00121509 0.731314 w: 1
Observation: 0 3 0 2 0 3 0 3 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=462, meanQ=84.122382, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 114148 episodes
GETTING ACTION FROM:
action 2, numVisits=114610, meanQ=89.059636, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.532635 0.0493526 0.400782 0.508564 0.851 0.229506 0.610024 0.277364 0.00121509 0.731314 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 62
Initial state: 0 0.865736 0.35424 0.641247 0.953939 0.899376 0.183248 0.301993 0.491802 0.761978 0.213025 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92423 episodes
GETTING ACTION FROM:
action 3, numVisits=92411, meanQ=28.392492, numObservations: 9
action 1, numVisits=6, meanQ=-1.000000, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.865736 0.35424 0.641247 0.953939 0.899376 0.183248 0.301993 0.491802 0.761978 0.213025 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=2249, meanQ=33.484782, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=10, meanQ=-5.693990, numObservations: 7
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 93533 episodes
GETTING ACTION FROM:
action 4, numVisits=95782, meanQ=14.923660, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=10, meanQ=-5.693990, numObservations: 7
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.865736 0.35424 0.641247 0.953939 0.899376 0.183248 0.301993 0.491802 0.761978 0.213025 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 63
Initial state: 0 0.541872 0.955019 0.725995 0.659975 0.330339 0.4335 0.403643 0.172663 0.0346738 0.491927 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97643 episodes
GETTING ACTION FROM:
action 5, numVisits=97630, meanQ=27.552353, numObservations: 9
action 3, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=3, meanQ=-34.333333, numObservations: 2
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.541872 0.955019 0.725995 0.659975 0.330339 0.4335 0.403643 0.172663 0.0346738 0.491927 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=2562, meanQ=31.792021, numObservations: 9
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 53268 episodes
GETTING ACTION FROM:
action 2, numVisits=55830, meanQ=18.102887, numObservations: 9
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.541872 0.955019 0.725995 0.659975 0.330339 0.4335 0.403643 0.172663 0.0346738 0.491927 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 64
Initial state: 0 0.306699 0.477517 0.0545859 0.644636 0.00576171 0.414119 0.0528113 0.235499 0.548814 0.0992682 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 93060 episodes
GETTING ACTION FROM:
action 1, numVisits=93049, meanQ=28.559556, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=5, meanQ=-7.000000, numObservations: 4
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.306699 0.477517 0.0545859 0.644636 0.00576171 0.414119 0.0528113 0.235499 0.548814 0.0992682 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 65
Initial state: 0 0.278488 0.198676 0.372917 0.526842 0.559462 0.626195 0.563509 0.885947 0.970524 0.273613 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 93268 episodes
GETTING ACTION FROM:
action 5, numVisits=93244, meanQ=28.765167, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 1, numVisits=13, meanQ=-2.537692, numObservations: 6
action 3, numVisits=3, meanQ=-4.333333, numObservations: 3
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.278488 0.198676 0.372917 0.526842 0.559462 0.626195 0.563509 0.885947 0.970524 0.273613 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 66
Initial state: 0 0.54909 0.643429 0.407936 0.454769 0.868625 0.78406 0.203226 0.348164 0.587123 0.501315 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95309 episodes
GETTING ACTION FROM:
action 2, numVisits=95295, meanQ=27.320478, numObservations: 9
action 5, numVisits=8, meanQ=21.500000, numObservations: 7
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.54909 0.643429 0.407936 0.454769 0.868625 0.78406 0.203226 0.348164 0.587123 0.501315 w: 1
Observation: 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 67
Initial state: 0 0.223369 0.760903 0.624585 0.338495 0.428311 0.735689 0.344245 0.448877 0.165597 0.347381 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 50913 episodes
GETTING ACTION FROM:
action 0, numVisits=50887, meanQ=65.240108, numObservations: 243
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=11, meanQ=-11.180900, numObservations: 9
action 5, numVisits=8, meanQ=-14.750000, numObservations: 5
action 1, numVisits=4, meanQ=-28.500000, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.223369 0.760903 0.624585 0.338495 0.428311 0.735689 0.344245 0.448877 0.165597 0.347381 w: 1
Observation: 0 0 3 0 1 0 3 0 3 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=130, meanQ=61.853208, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 100601 episodes
GETTING ACTION FROM:
action 3, numVisits=100731, meanQ=73.845095, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 3
Next state: 1 0.223369 0.760903 0.624585 0.338495 0.428311 0.735689 0.344245 0.448877 0.165597 0.347381 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 68
Initial state: 0 0.165625 0.378527 0.35682 0.437064 0.248929 0.0441732 0.133906 0.142983 0.973923 0.895608 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 94020 episodes
GETTING ACTION FROM:
action 4, numVisits=93996, meanQ=27.670283, numObservations: 9
action 2, numVisits=6, meanQ=-1.000000, numObservations: 4
action 5, numVisits=4, meanQ=-1.000000, numObservations: 4
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 3, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=5, meanQ=-21.000000, numObservations: 3
action: 4
Next state: 0 0.165625 0.378527 0.35682 0.437064 0.248929 0.0441732 0.133906 0.142983 0.973923 0.895608 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=6614, meanQ=30.539630, numObservations: 9
action 2, numVisits=26, meanQ=16.421542, numObservations: 8
action 3, numVisits=6, meanQ=14.165000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=5, meanQ=-8.404000, numObservations: 3
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 44017 episodes
GETTING ACTION FROM:
action 5, numVisits=50631, meanQ=27.591768, numObservations: 9
action 2, numVisits=26, meanQ=16.421542, numObservations: 8
action 3, numVisits=6, meanQ=14.165000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=5, meanQ=-8.404000, numObservations: 3
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 5
Next state: 1 0.165625 0.378527 0.35682 0.437064 0.248929 0.0441732 0.133906 0.142983 0.973923 0.895608 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 69
Initial state: 0 0.256614 0.307858 0.269577 0.09312 0.429593 0.475504 0.465405 0.885839 0.185492 0.651447 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 90936 episodes
GETTING ACTION FROM:
action 5, numVisits=90904, meanQ=28.817740, numObservations: 9
action 1, numVisits=8, meanQ=-3.624988, numObservations: 4
action 0, numVisits=4, meanQ=-3.734975, numObservations: 3
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action -1, numVisits=15, meanQ=-7.874660, numObservations: 13
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.256614 0.307858 0.269577 0.09312 0.429593 0.475504 0.465405 0.885839 0.185492 0.651447 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 70
Initial state: 0 0.885662 0.498796 0.260921 0.199189 0.306655 0.443576 0.995449 0.739833 0.379558 0.222912 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97904 episodes
GETTING ACTION FROM:
action 3, numVisits=97893, meanQ=27.216060, numObservations: 9
action 4, numVisits=5, meanQ=19.000000, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.885662 0.498796 0.260921 0.199189 0.306655 0.443576 0.995449 0.739833 0.379558 0.222912 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 71
Initial state: 0 0.419519 0.397436 0.373687 0.900333 0.485749 0.975626 0.969293 0.192688 0.448011 0.326518 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 93522 episodes
GETTING ACTION FROM:
action 1, numVisits=93513, meanQ=27.207455, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.419519 0.397436 0.373687 0.900333 0.485749 0.975626 0.969293 0.192688 0.448011 0.326518 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 72
Initial state: 0 0.617327 0.84478 0.0662571 0.302192 0.305749 0.422049 0.250702 0.608151 0.149057 0.733376 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 96928 episodes
GETTING ACTION FROM:
action 4, numVisits=96905, meanQ=26.990252, numObservations: 9
action 2, numVisits=17, meanQ=14.293535, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.617327 0.84478 0.0662571 0.302192 0.305749 0.422049 0.250702 0.608151 0.149057 0.733376 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=6461, meanQ=33.142795, numObservations: 9
action 4, numVisits=3, meanQ=26.326667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=3, meanQ=-4.003333, numObservations: 2
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 109757 episodes
GETTING ACTION FROM:
action 1, numVisits=116218, meanQ=36.155500, numObservations: 9
action 4, numVisits=3, meanQ=26.326667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=3, meanQ=-4.003333, numObservations: 2
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 1
Next state: 1 0.617327 0.84478 0.0662571 0.302192 0.305749 0.422049 0.250702 0.608151 0.149057 0.733376 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 73
Initial state: 0 0.089298 0.720333 0.374223 0.454206 0.241952 0.736108 0.360417 0.307655 0.0227994 0.922774 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 50273 episodes
GETTING ACTION FROM:
action 0, numVisits=50230, meanQ=63.097700, numObservations: 243
action -1, numVisits=14, meanQ=-1.788564, numObservations: 13
action 3, numVisits=18, meanQ=-2.111111, numObservations: 8
action 4, numVisits=8, meanQ=-3.500000, numObservations: 6
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.089298 0.720333 0.374223 0.454206 0.241952 0.736108 0.360417 0.307655 0.0227994 0.922774 w: 1
Observation: 0 0 3 0 2 0 3 0 1 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=330, meanQ=66.338862, numObservations: 9
action 2, numVisits=2, meanQ=44.495000, numObservations: 2
action 5, numVisits=3, meanQ=32.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 99334 episodes
GETTING ACTION FROM:
action 3, numVisits=99664, meanQ=68.630846, numObservations: 9
action 2, numVisits=2, meanQ=44.495000, numObservations: 2
action 5, numVisits=3, meanQ=32.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.089298 0.720333 0.374223 0.454206 0.241952 0.736108 0.360417 0.307655 0.0227994 0.922774 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 74
Initial state: 0 0.511674 0.0811536 0.880252 0.406297 0.359933 0.534167 0.998243 0.590501 0.793745 0.319288 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 50784 episodes
GETTING ACTION FROM:
action 0, numVisits=50734, meanQ=64.099114, numObservations: 243
action -1, numVisits=37, meanQ=-1.117027, numObservations: 35
action 2, numVisits=5, meanQ=-3.000000, numObservations: 4
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=5, meanQ=-21.000000, numObservations: 3
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.511674 0.0811536 0.880252 0.406297 0.359933 0.534167 0.998243 0.590501 0.793745 0.319288 w: 1
Observation: 0 0 3 0 2 0 2 0 3 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=243, meanQ=67.622356, numObservations: 9
action 1, numVisits=8, meanQ=46.747500, numObservations: 4
action 4, numVisits=2, meanQ=44.495000, numObservations: 2
action 3, numVisits=3, meanQ=32.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 94633 episodes
GETTING ACTION FROM:
action 5, numVisits=94876, meanQ=67.563624, numObservations: 9
action 1, numVisits=8, meanQ=46.747500, numObservations: 4
action 4, numVisits=2, meanQ=44.495000, numObservations: 2
action 3, numVisits=3, meanQ=32.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.511674 0.0811536 0.880252 0.406297 0.359933 0.534167 0.998243 0.590501 0.793745 0.319288 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101.99
Run # 75
Initial state: 0 0.350955 0.116531 0.326005 0.486688 0.736415 0.39356 0.917595 0.505773 0.348484 0.888575 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95769 episodes
GETTING ACTION FROM:
action 5, numVisits=95746, meanQ=27.634818, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=16, meanQ=-2.312494, numObservations: 6
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.350955 0.116531 0.326005 0.486688 0.736415 0.39356 0.917595 0.505773 0.348484 0.888575 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 76
Initial state: 0 0.333452 0.60774 0.326909 0.452111 0.849822 0.6408 0.0809747 0.168216 0.935309 0.730066 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 96105 episodes
GETTING ACTION FROM:
action 5, numVisits=96089, meanQ=27.111588, numObservations: 9
action 4, numVisits=11, meanQ=16.362727, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.333452 0.60774 0.326909 0.452111 0.849822 0.6408 0.0809747 0.168216 0.935309 0.730066 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 77
Initial state: 0 0.352531 0.474488 0.0528043 0.244784 0.443694 0.819657 0.943292 0.701186 0.135317 0.7705 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95634 episodes
GETTING ACTION FROM:
action 5, numVisits=95628, meanQ=27.448894, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.352531 0.474488 0.0528043 0.244784 0.443694 0.819657 0.943292 0.701186 0.135317 0.7705 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=6396, meanQ=30.531673, numObservations: 9
action -1, numVisits=6, meanQ=-1.010000, numObservations: 6
action 0, numVisits=3, meanQ=-1.673300, numObservations: 2
action 1, numVisits=3, meanQ=-4.003333, numObservations: 3
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=5, meanQ=-21.000000, numObservations: 3
action 3, numVisits=3, meanQ=-34.333333, numObservations: 2
Sampled 103375 episodes
GETTING ACTION FROM:
action 2, numVisits=109771, meanQ=41.347070, numObservations: 9
action -1, numVisits=6, meanQ=-1.010000, numObservations: 6
action 0, numVisits=3, meanQ=-1.673300, numObservations: 2
action 1, numVisits=3, meanQ=-4.003333, numObservations: 3
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=5, meanQ=-21.000000, numObservations: 3
action 3, numVisits=3, meanQ=-34.333333, numObservations: 2
action: 2
Next state: 0 0.352531 0.474488 0.0528043 0.244784 0.443694 0.819657 0.943292 0.701186 0.135317 0.7705 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=5430, meanQ=58.653735, numObservations: 9
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 32161 episodes
GETTING ACTION FROM:
action 1, numVisits=37591, meanQ=40.819866, numObservations: 9
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.352531 0.474488 0.0528043 0.244784 0.443694 0.819657 0.943292 0.701186 0.135317 0.7705 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 75.1399
Run # 78
Initial state: 0 0.705022 0.934823 0.842933 0.0311571 0.218911 0.219619 0.982277 0.766411 0.297681 0.516761 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88441 episodes
GETTING ACTION FROM:
action 5, numVisits=88434, meanQ=30.575198, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.705022 0.934823 0.842933 0.0311571 0.218911 0.219619 0.982277 0.766411 0.297681 0.516761 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 79
Initial state: 0 0.566204 0.64282 0.62922 0.165261 0.304713 0.462686 0.0825218 0.475578 0.283805 0.344845 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 94706 episodes
GETTING ACTION FROM:
action 5, numVisits=94624, meanQ=27.819446, numObservations: 9
action 1, numVisits=63, meanQ=25.174763, numObservations: 9
action 3, numVisits=12, meanQ=23.166667, numObservations: 6
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action: 5
Next state: 2 0.566204 0.64282 0.62922 0.165261 0.304713 0.462686 0.0825218 0.475578 0.283805 0.344845 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 80
Initial state: 0 0.353695 0.39874 0.104235 0.95408 0.0643042 0.726972 0.161566 0.682236 0.755083 0.292066 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 94872 episodes
GETTING ACTION FROM:
action 2, numVisits=94866, meanQ=27.994371, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.353695 0.39874 0.104235 0.95408 0.0643042 0.726972 0.161566 0.682236 0.755083 0.292066 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=2520, meanQ=60.760967, numObservations: 240
action 5, numVisits=3, meanQ=-4.003333, numObservations: 3
action -1, numVisits=12, meanQ=-9.590825, numObservations: 10
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=5, meanQ=-21.000000, numObservations: 3
action 4, numVisits=3, meanQ=-34.333333, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 15056 episodes
GETTING ACTION FROM:
action 0, numVisits=17576, meanQ=39.991222, numObservations: 243
action 5, numVisits=3, meanQ=-4.003333, numObservations: 3
action -1, numVisits=12, meanQ=-9.590825, numObservations: 10
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=5, meanQ=-21.000000, numObservations: 3
action 4, numVisits=3, meanQ=-34.333333, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.353695 0.39874 0.104235 0.95408 0.0643042 0.726972 0.161566 0.682236 0.755083 0.292066 w: 1
Observation: 0 0 2 0 3 0 3 0 3 0 3 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=1, meanQ=99.000000, numObservations: 1
action 1, numVisits=28, meanQ=94.815580, numObservations: 7
action 5, numVisits=3, meanQ=59.295405, numObservations: 3
action 4, numVisits=5, meanQ=59.000000, numObservations: 3
action 3, numVisits=3, meanQ=32.333333, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 94200 episodes
GETTING ACTION FROM:
action 2, numVisits=14, meanQ=91.142857, numObservations: 5
action 1, numVisits=94215, meanQ=86.661484, numObservations: 9
action 5, numVisits=3, meanQ=59.295405, numObservations: 3
action 4, numVisits=5, meanQ=59.000000, numObservations: 3
action 3, numVisits=3, meanQ=32.333333, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.353695 0.39874 0.104235 0.95408 0.0643042 0.726972 0.161566 0.682236 0.755083 0.292066 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 114100 episodes
GETTING ACTION FROM:
action 1, numVisits=114078, meanQ=94.297707, numObservations: 9
action 2, numVisits=9, meanQ=86.777778, numObservations: 1
action 5, numVisits=5, meanQ=77.000000, numObservations: 3
action 4, numVisits=5, meanQ=59.000000, numObservations: 1
action -1, numVisits=1, meanQ=-2.000000, numObservations: 1
action 0, numVisits=1, meanQ=-2.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.353695 0.39874 0.104235 0.95408 0.0643042 0.726972 0.161566 0.682236 0.755083 0.292066 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 72.2985
Run # 81
Initial state: 0 0.680852 0.232912 0.729772 0.833185 0.215347 0.276396 0.386262 0.407647 0.571481 0.0177495 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91655 episodes
GETTING ACTION FROM:
action 5, numVisits=91648, meanQ=29.040128, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.680852 0.232912 0.729772 0.833185 0.215347 0.276396 0.386262 0.407647 0.571481 0.0177495 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 82
Initial state: 0 0.996403 0.470166 0.638596 0.672354 0.339965 0.43344 0.621152 0.0329467 0.0417855 0.443708 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88097 episodes
GETTING ACTION FROM:
action 4, numVisits=88090, meanQ=30.044013, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.996403 0.470166 0.638596 0.672354 0.339965 0.43344 0.621152 0.0329467 0.0417855 0.443708 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 83
Initial state: 0 0.367207 0.476885 0.387806 0.876104 0.42531 0.586502 0.131722 0.650733 0.203545 0.677956 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91562 episodes
GETTING ACTION FROM:
action 3, numVisits=91544, meanQ=28.535558, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 5, numVisits=8, meanQ=-3.500000, numObservations: 5
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.367207 0.476885 0.387806 0.876104 0.42531 0.586502 0.131722 0.650733 0.203545 0.677956 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 84
Initial state: 0 0.36078 0.934277 0.0111846 0.141231 0.375144 0.094169 0.650164 0.0759525 0.337291 0.430161 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97274 episodes
GETTING ACTION FROM:
action 4, numVisits=97262, meanQ=27.073202, numObservations: 9
action 3, numVisits=6, meanQ=14.000000, numObservations: 3
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.36078 0.934277 0.0111846 0.141231 0.375144 0.094169 0.650164 0.0759525 0.337291 0.430161 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 85
Initial state: 0 0.345927 0.430905 0.615665 0.0250369 0.598624 0.512939 0.992811 0.67704 0.953039 0.990343 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89574 episodes
GETTING ACTION FROM:
action 1, numVisits=89555, meanQ=28.860258, numObservations: 9
action 4, numVisits=14, meanQ=4.000000, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.345927 0.430905 0.615665 0.0250369 0.598624 0.512939 0.992811 0.67704 0.953039 0.990343 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 86
Initial state: 0 0.65279 0.35295 0.374349 0.416995 0.623512 0.401459 0.269125 0.950696 0.332149 0.1674 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97213 episodes
GETTING ACTION FROM:
action 5, numVisits=97205, meanQ=26.699885, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.65279 0.35295 0.374349 0.416995 0.623512 0.401459 0.269125 0.950696 0.332149 0.1674 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 87
Initial state: 0 0.0836126 0.695129 0.691225 0.846247 0.328732 0.439456 0.558693 0.275414 0.437603 0.0652587 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92385 episodes
GETTING ACTION FROM:
action 1, numVisits=92352, meanQ=27.645388, numObservations: 9
action -1, numVisits=15, meanQ=-8.468660, numObservations: 13
action 0, numVisits=12, meanQ=-10.333325, numObservations: 10
action 4, numVisits=3, meanQ=-34.333333, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.0836126 0.695129 0.691225 0.846247 0.328732 0.439456 0.558693 0.275414 0.437603 0.0652587 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 88
Initial state: 0 0.23468 0.835945 0.741102 0.420097 0.745374 0.888698 0.806605 0.534683 0.426099 0.491098 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97353 episodes
GETTING ACTION FROM:
action 5, numVisits=97347, meanQ=27.229884, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.23468 0.835945 0.741102 0.420097 0.745374 0.888698 0.806605 0.534683 0.426099 0.491098 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 89
Initial state: 0 0.218235 0.0221247 0.0323065 0.648248 0.160107 0.790764 0.3663 0.5286 0.187066 0.123243 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 94739 episodes
GETTING ACTION FROM:
action 3, numVisits=94732, meanQ=27.775218, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.218235 0.0221247 0.0323065 0.648248 0.160107 0.790764 0.3663 0.5286 0.187066 0.123243 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=6226, meanQ=32.055390, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 108008 episodes
GETTING ACTION FROM:
action 4, numVisits=114234, meanQ=38.787170, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.218235 0.0221247 0.0323065 0.648248 0.160107 0.790764 0.3663 0.5286 0.187066 0.123243 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 90
Initial state: 0 0.302117 0.406025 0.0307841 0.369809 0.103204 0.888697 0.4398 0.0338091 0.626121 0.398194 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92399 episodes
GETTING ACTION FROM:
action 1, numVisits=92379, meanQ=28.752780, numObservations: 9
action 2, numVisits=4, meanQ=21.747500, numObservations: 3
action 5, numVisits=12, meanQ=21.665000, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.302117 0.406025 0.0307841 0.369809 0.103204 0.888697 0.4398 0.0338091 0.626121 0.398194 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1437, meanQ=78.849027, numObservations: 9
action 2, numVisits=3, meanQ=32.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 124077 episodes
GETTING ACTION FROM:
action 1, numVisits=125514, meanQ=86.019137, numObservations: 9
action 2, numVisits=3, meanQ=32.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.302117 0.406025 0.0307841 0.369809 0.103204 0.888697 0.4398 0.0338091 0.626121 0.398194 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 91
Initial state: 0 0.0961364 0.939735 0.484569 0.291887 0.467973 0.684063 0.487709 0.577003 0.381785 0.464818 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 50101 episodes
GETTING ACTION FROM:
action -1, numVisits=50031, meanQ=53.903950, numObservations: 243
action 0, numVisits=56, meanQ=-2.884282, numObservations: 53
action 5, numVisits=8, meanQ=-3.624987, numObservations: 5
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=3, meanQ=-34.333333, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.0961364 0.939735 0.484569 0.291887 0.467973 0.684063 0.487709 0.577003 0.381785 0.464818 w: 1
Observation: 0 1 0 3 0 3 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=241, meanQ=45.494468, numObservations: 9
action 2, numVisits=26, meanQ=14.384615, numObservations: 7
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 75822 episodes
GETTING ACTION FROM:
action 1, numVisits=76063, meanQ=54.142517, numObservations: 9
action 2, numVisits=26, meanQ=14.384615, numObservations: 7
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 1
Next state: 0 0.0961364 0.939735 0.484569 0.291887 0.467973 0.684063 0.487709 0.577003 0.381785 0.464818 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action -1, numVisits=12425, meanQ=74.625979, numObservations: 163
action 2, numVisits=31, meanQ=-1.936126, numObservations: 8
action 0, numVisits=4, meanQ=-3.734975, numObservations: 3
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 57086 episodes
GETTING ACTION FROM:
action -1, numVisits=69511, meanQ=55.703244, numObservations: 220
action 2, numVisits=31, meanQ=-1.936126, numObservations: 8
action 0, numVisits=4, meanQ=-3.734975, numObservations: 3
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.0961364 0.939735 0.484569 0.291887 0.467973 0.684063 0.487709 0.577003 0.381785 0.464818 w: 1
Observation: 0 3 0 3 0 2 0 3 0 1 0 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=9, meanQ=48.776689, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 91801 episodes
GETTING ACTION FROM:
action 1, numVisits=91810, meanQ=76.985979, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.0961364 0.939735 0.484569 0.291887 0.467973 0.684063 0.487709 0.577003 0.381785 0.464818 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 3, numVisits=21859, meanQ=76.253790, numObservations: 9
action 4, numVisits=13, meanQ=52.846154, numObservations: 3
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 122074 episodes
GETTING ACTION FROM:
action 3, numVisits=143933, meanQ=77.088509, numObservations: 9
action 4, numVisits=13, meanQ=52.846154, numObservations: 3
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.0961364 0.939735 0.484569 0.291887 0.467973 0.684063 0.487709 0.577003 0.381785 0.464818 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 69.5755
Run # 92
Initial state: 0 0.483713 0.618686 0.420924 0.615593 0.31546 0.509851 0.394446 0.880296 0.49861 0.755211 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 96956 episodes
GETTING ACTION FROM:
action 5, numVisits=96945, meanQ=26.388317, numObservations: 9
action 1, numVisits=6, meanQ=10.666667, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.483713 0.618686 0.420924 0.615593 0.31546 0.509851 0.394446 0.880296 0.49861 0.755211 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 93
Initial state: 0 0.872606 0.832894 0.73233 0.0760027 0.110555 0.137426 0.331151 0.464715 0.791022 0.313206 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92036 episodes
GETTING ACTION FROM:
action 4, numVisits=92026, meanQ=28.287293, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.872606 0.832894 0.73233 0.0760027 0.110555 0.137426 0.331151 0.464715 0.791022 0.313206 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 94
Initial state: 0 0.426356 0.500146 0.379069 0.103483 0.5105 0.0128152 0.310237 0.864829 0.348668 0.216543 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95456 episodes
GETTING ACTION FROM:
action 5, numVisits=95442, meanQ=27.790096, numObservations: 9
action 4, numVisits=8, meanQ=10.373750, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.426356 0.500146 0.379069 0.103483 0.5105 0.0128152 0.310237 0.864829 0.348668 0.216543 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1383, meanQ=30.810668, numObservations: 9
action 1, numVisits=15, meanQ=21.936673, numObservations: 6
action 3, numVisits=5, meanQ=19.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 51236 episodes
GETTING ACTION FROM:
action 1, numVisits=45353, meanQ=19.050623, numObservations: 9
action 2, numVisits=7274, meanQ=14.627436, numObservations: 9
action 3, numVisits=10, meanQ=7.206581, numObservations: 6
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.426356 0.500146 0.379069 0.103483 0.5105 0.0128152 0.310237 0.864829 0.348668 0.216543 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 95
Initial state: 0 0.271136 0.489142 0.428791 0.554781 0.847378 0.411333 0.528913 0.348001 0.39653 0.525474 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 50047 episodes
GETTING ACTION FROM:
action -1, numVisits=50021, meanQ=50.414382, numObservations: 243
action 0, numVisits=10, meanQ=-2.099990, numObservations: 9
action 5, numVisits=5, meanQ=-3.000000, numObservations: 4
action 3, numVisits=8, meanQ=-3.500000, numObservations: 4
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.271136 0.489142 0.428791 0.554781 0.847378 0.411333 0.528913 0.348001 0.39653 0.525474 w: 1
Observation: 0 1 0 2 0 3 0 3 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=199, meanQ=51.684424, numObservations: 9
action 4, numVisits=13, meanQ=-10.078462, numObservations: 6
action 0, numVisits=10, meanQ=-11.108000, numObservations: 9
action -1, numVisits=6, meanQ=-17.840000, numObservations: 5
action 1, numVisits=2, meanQ=-55.505000, numObservations: 2
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 109198 episodes
GETTING ACTION FROM:
action 5, numVisits=109397, meanQ=59.687036, numObservations: 9
action 4, numVisits=13, meanQ=-10.078462, numObservations: 6
action 0, numVisits=10, meanQ=-11.108000, numObservations: 9
action -1, numVisits=6, meanQ=-17.840000, numObservations: 5
action 1, numVisits=2, meanQ=-55.505000, numObservations: 2
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.271136 0.489142 0.428791 0.554781 0.847378 0.411333 0.528913 0.348001 0.39653 0.525474 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 96
Initial state: 0 0.31562 0.496762 0.933186 0.740551 0.227672 0.638373 0.928128 0.268535 0.210475 0.481417 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 93627 episodes
GETTING ACTION FROM:
action 1, numVisits=93615, meanQ=28.207463, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=3, meanQ=-4.333333, numObservations: 3
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.31562 0.496762 0.933186 0.740551 0.227672 0.638373 0.928128 0.268535 0.210475 0.481417 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 97
Initial state: 0 0.338597 0.0887062 0.185347 0.53522 0.390562 0.427349 0.138687 0.102808 0.410135 0.5915 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92876 episodes
GETTING ACTION FROM:
action 3, numVisits=92869, meanQ=27.882330, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.338597 0.0887062 0.185347 0.53522 0.390562 0.427349 0.138687 0.102808 0.410135 0.5915 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 98
Initial state: 0 0.0147866 0.396983 0.388495 0.399434 0.300837 0.997264 0.138802 0.973141 0.948971 0.466687 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49397 episodes
GETTING ACTION FROM:
action -1, numVisits=49370, meanQ=55.791421, numObservations: 243
action 0, numVisits=7, meanQ=-1.010000, numObservations: 7
action 1, numVisits=10, meanQ=-3.000000, numObservations: 5
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=7, meanQ=-15.285714, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.0147866 0.396983 0.388495 0.399434 0.300837 0.997264 0.138802 0.973141 0.948971 0.466687 w: 1
Observation: 0 1 0 2 0 3 0 1 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=248, meanQ=78.851817, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 112243 episodes
GETTING ACTION FROM:
action 2, numVisits=112491, meanQ=81.790567, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.0147866 0.396983 0.388495 0.399434 0.300837 0.997264 0.138802 0.973141 0.948971 0.466687 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 99
Initial state: 0 0.117397 0.165138 0.644828 0.828168 0.419143 0.529884 0.637734 0.00130727 0.110326 0.733503 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 93277 episodes
GETTING ACTION FROM:
action 5, numVisits=93270, meanQ=27.327906, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.117397 0.165138 0.644828 0.828168 0.419143 0.529884 0.637734 0.00130727 0.110326 0.733503 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 100
Initial state: 0 0.634853 0.446807 0.785872 0.495368 0.684074 0.693674 0.37398 0.485034 0.426483 0.21002 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 96787 episodes
GETTING ACTION FROM:
action 3, numVisits=96780, meanQ=26.226057, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.634853 0.446807 0.785872 0.495368 0.684074 0.693674 0.37398 0.485034 0.426483 0.21002 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 101
Initial state: 0 0.332388 0.418959 0.747067 0.414451 0.594106 0.832783 0.233809 0.691668 0.135592 0.73605 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88034 episodes
GETTING ACTION FROM:
action 5, numVisits=88027, meanQ=29.663961, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.332388 0.418959 0.747067 0.414451 0.594106 0.832783 0.233809 0.691668 0.135592 0.73605 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=5858, meanQ=65.510469, numObservations: 242
action 2, numVisits=14, meanQ=-2.287143, numObservations: 9
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action -1, numVisits=7, meanQ=-15.435714, numObservations: 6
Sampled 58803 episodes
GETTING ACTION FROM:
action 0, numVisits=64661, meanQ=42.076985, numObservations: 243
action 2, numVisits=14, meanQ=-2.287143, numObservations: 9
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action -1, numVisits=7, meanQ=-15.435714, numObservations: 6
action: 0
Next state: 0 0.332388 0.418959 0.747067 0.414451 0.594106 0.832783 0.233809 0.691668 0.135592 0.73605 w: 1
Observation: 0 0 2 0 2 0 3 0 3 0 3 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=454, meanQ=63.945618, numObservations: 9
action 4, numVisits=5, meanQ=33.196020, numObservations: 4
action 3, numVisits=3, meanQ=32.333333, numObservations: 3
action 5, numVisits=3, meanQ=25.663367, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 122888 episodes
GETTING ACTION FROM:
action 2, numVisits=123342, meanQ=54.868074, numObservations: 9
action 4, numVisits=5, meanQ=33.196020, numObservations: 4
action 3, numVisits=3, meanQ=32.333333, numObservations: 3
action 5, numVisits=3, meanQ=25.663367, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.332388 0.418959 0.747067 0.414451 0.594106 0.832783 0.233809 0.691668 0.135592 0.73605 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 84.0499
Run # 102
Initial state: 0 0.263192 0.928369 0.924813 0.502617 0.0030763 0.352886 0.352962 0.506621 0.336777 0.54784 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 93174 episodes
GETTING ACTION FROM:
action 5, numVisits=93107, meanQ=28.856813, numObservations: 9
action 2, numVisits=57, meanQ=15.284568, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=6, meanQ=-4.333333, numObservations: 4
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.263192 0.928369 0.924813 0.502617 0.0030763 0.352886 0.352962 0.506621 0.336777 0.54784 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 103
Initial state: 0 0.723622 0.792893 0.328929 0.857948 0.381914 0.497013 0.885423 0.978562 0.202952 0.908578 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95414 episodes
GETTING ACTION FROM:
action 4, numVisits=95397, meanQ=26.562057, numObservations: 9
action 3, numVisits=7, meanQ=13.285714, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=6, meanQ=-4.333333, numObservations: 5
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.723622 0.792893 0.328929 0.857948 0.381914 0.497013 0.885423 0.978562 0.202952 0.908578 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 104
Initial state: 0 0.381244 0.530766 0.18792 0.859881 0.170844 0.559124 0.841871 0.00450875 0.213714 0.977445 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49936 episodes
GETTING ACTION FROM:
action -1, numVisits=49884, meanQ=52.923924, numObservations: 243
action 0, numVisits=47, meanQ=-3.664674, numObservations: 43
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.381244 0.530766 0.18792 0.859881 0.170844 0.559124 0.841871 0.00450875 0.213714 0.977445 w: 1
Observation: 0 2 0 1 0 1 0 3 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=137, meanQ=80.913067, numObservations: 9
action 5, numVisits=2, meanQ=44.495000, numObservations: 1
action 4, numVisits=10, meanQ=39.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 112075 episodes
GETTING ACTION FROM:
action 1, numVisits=112212, meanQ=77.469176, numObservations: 9
action 5, numVisits=2, meanQ=44.495000, numObservations: 1
action 4, numVisits=10, meanQ=39.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 1
Next state: 1 0.381244 0.530766 0.18792 0.859881 0.170844 0.559124 0.841871 0.00450875 0.213714 0.977445 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 105
Initial state: 0 0.208988 0.915531 0.158352 0.442922 0.150931 0.90338 0.342952 0.394848 0.341113 0.696013 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 90017 episodes
GETTING ACTION FROM:
action 4, numVisits=90003, meanQ=30.231836, numObservations: 9
action 5, numVisits=8, meanQ=10.250000, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.208988 0.915531 0.158352 0.442922 0.150931 0.90338 0.342952 0.394848 0.341113 0.696013 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 106
Initial state: 0 0.358535 0.444011 0.631365 0.811887 0.162901 0.395561 0.509838 0.778513 0.700056 0.578399 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 96877 episodes
GETTING ACTION FROM:
action 5, numVisits=96866, meanQ=26.675606, numObservations: 9
action 4, numVisits=4, meanQ=16.995000, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.358535 0.444011 0.631365 0.811887 0.162901 0.395561 0.509838 0.778513 0.700056 0.578399 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 107
Initial state: 0 0.213275 0.00429433 0.929172 0.56175 0.0248687 0.886472 0.167988 0.496791 0.398561 0.513351 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97881 episodes
GETTING ACTION FROM:
action 3, numVisits=97851, meanQ=27.531714, numObservations: 9
action 4, numVisits=20, meanQ=21.198500, numObservations: 9
action 2, numVisits=6, meanQ=14.165000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.213275 0.00429433 0.929172 0.56175 0.0248687 0.886472 0.167988 0.496791 0.398561 0.513351 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=6518, meanQ=33.564712, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 107096 episodes
GETTING ACTION FROM:
action 5, numVisits=113614, meanQ=37.065785, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.213275 0.00429433 0.929172 0.56175 0.0248687 0.886472 0.167988 0.496791 0.398561 0.513351 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 108
Initial state: 0 0.228123 0.242665 0.804783 0.796962 0.414507 0.396041 0.133694 0.332606 0.663369 0.689321 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 94114 episodes
GETTING ACTION FROM:
action 3, numVisits=94057, meanQ=27.866030, numObservations: 9
action 4, numVisits=52, meanQ=21.807315, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.228123 0.242665 0.804783 0.796962 0.414507 0.396041 0.133694 0.332606 0.663369 0.689321 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 109
Initial state: 0 0.0513458 0.239323 0.305025 0.431109 0.86516 0.322644 0.247452 0.806247 0.374562 0.944482 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95376 episodes
GETTING ACTION FROM:
action 5, numVisits=95312, meanQ=28.382703, numObservations: 9
action 1, numVisits=49, meanQ=15.206739, numObservations: 9
action 2, numVisits=6, meanQ=12.335000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=6, meanQ=-4.168333, numObservations: 6
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.0513458 0.239323 0.305025 0.431109 0.86516 0.322644 0.247452 0.806247 0.374562 0.944482 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 110
Initial state: 0 0.455333 0.680172 0.297609 0.501662 0.483333 0.444034 0.940881 0.2102 0.0235941 0.676571 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 50171 episodes
GETTING ACTION FROM:
action -1, numVisits=50128, meanQ=55.455324, numObservations: 243
action 0, numVisits=36, meanQ=-3.925550, numObservations: 33
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=3, meanQ=-34.333333, numObservations: 2
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.455333 0.680172 0.297609 0.501662 0.483333 0.444034 0.940881 0.2102 0.0235941 0.676571 w: 1
Observation: 0 3 0 2 0 3 0 3 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=481, meanQ=83.070741, numObservations: 9
action 1, numVisits=7, meanQ=41.857143, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 112735 episodes
GETTING ACTION FROM:
action 2, numVisits=113216, meanQ=87.238362, numObservations: 9
action 1, numVisits=7, meanQ=41.857143, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.455333 0.680172 0.297609 0.501662 0.483333 0.444034 0.940881 0.2102 0.0235941 0.676571 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 111
Initial state: 0 0.182659 0.691389 0.203792 0.106885 0.335817 0.460425 0.198103 0.183719 0.727264 0.166888 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 93476 episodes
GETTING ACTION FROM:
action 3, numVisits=93463, meanQ=28.805703, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=6, meanQ=-4.333333, numObservations: 5
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.182659 0.691389 0.203792 0.106885 0.335817 0.460425 0.198103 0.183719 0.727264 0.166888 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 112
Initial state: 0 0.200751 0.939712 0.165315 0.16123 0.885902 0.503827 0.36665 0.449612 0.688686 0.342057 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95194 episodes
GETTING ACTION FROM:
action 2, numVisits=95175, meanQ=27.904781, numObservations: 9
action 3, numVisits=6, meanQ=14.165000, numObservations: 4
action 5, numVisits=8, meanQ=9.001250, numObservations: 6
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.200751 0.939712 0.165315 0.16123 0.885902 0.503827 0.36665 0.449612 0.688686 0.342057 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=6695, meanQ=34.880499, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 30417 episodes
GETTING ACTION FROM:
action 4, numVisits=37112, meanQ=35.286144, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.200751 0.939712 0.165315 0.16123 0.885902 0.503827 0.36665 0.449612 0.688686 0.342057 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 113
Initial state: 0 0.447877 0.721373 0.34314 0.454376 0.862309 0.540533 0.053722 0.94459 0.243937 0.299685 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92198 episodes
GETTING ACTION FROM:
action 1, numVisits=92191, meanQ=29.024789, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.447877 0.721373 0.34314 0.454376 0.862309 0.540533 0.053722 0.94459 0.243937 0.299685 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 114
Initial state: 0 0.369647 0.511381 0.444436 0.902962 0.122922 0.944129 0.650179 0.949463 0.942475 0.624267 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95516 episodes
GETTING ACTION FROM:
action 2, numVisits=95503, meanQ=27.655122, numObservations: 9
action 3, numVisits=7, meanQ=10.428571, numObservations: 4
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.369647 0.511381 0.444436 0.902962 0.122922 0.944129 0.650179 0.949463 0.942475 0.624267 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 115
Initial state: 0 0.24386 0.376797 0.0472888 0.491576 0.459928 0.364704 0.950722 0.911529 0.408335 0.463803 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97999 episodes
GETTING ACTION FROM:
action 1, numVisits=97993, meanQ=26.811751, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.24386 0.376797 0.0472888 0.491576 0.459928 0.364704 0.950722 0.911529 0.408335 0.463803 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 116
Initial state: 0 0.316552 0.476598 0.871342 0.638518 0.407874 0.583674 0.515481 0.206087 0.528588 0.241897 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87070 episodes
GETTING ACTION FROM:
action 2, numVisits=87000, meanQ=30.652074, numObservations: 9
action 4, numVisits=52, meanQ=17.789815, numObservations: 9
action 3, numVisits=13, meanQ=12.229231, numObservations: 6
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.316552 0.476598 0.871342 0.638518 0.407874 0.583674 0.515481 0.206087 0.528588 0.241897 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 117
Initial state: 0 0.224764 0.516316 0.396287 0.473829 0.230552 0.998616 0.472261 0.968993 0.0183782 0.0763067 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 96407 episodes
GETTING ACTION FROM:
action 2, numVisits=96396, meanQ=27.001679, numObservations: 9
action 4, numVisits=6, meanQ=14.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.224764 0.516316 0.396287 0.473829 0.230552 0.998616 0.472261 0.968993 0.0183782 0.0763067 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 118
Initial state: 0 0.927692 0.60066 0.384738 0.968483 0.338064 0.439939 0.658653 0.375693 0.960986 0.456556 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49185 episodes
GETTING ACTION FROM:
action -1, numVisits=49148, meanQ=51.455300, numObservations: 243
action 0, numVisits=21, meanQ=-5.818571, numObservations: 20
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=8, meanQ=-14.750000, numObservations: 6
action 3, numVisits=5, meanQ=-21.000000, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.927692 0.60066 0.384738 0.968483 0.338064 0.439939 0.658653 0.375693 0.960986 0.456556 w: 1
Observation: 0 3 0 2 0 2 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=318, meanQ=51.412681, numObservations: 56
action 4, numVisits=58, meanQ=2.103278, numObservations: 5
action 1, numVisits=36, meanQ=0.972500, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 52467 episodes
GETTING ACTION FROM:
action -1, numVisits=52785, meanQ=62.359171, numObservations: 204
action 4, numVisits=58, meanQ=2.103278, numObservations: 5
action 1, numVisits=36, meanQ=0.972500, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: -1
Next state: 0 0.927692 0.60066 0.384738 0.968483 0.338064 0.439939 0.658653 0.375693 0.960986 0.456556 w: 1
Observation: 0 3 0 2 0 2 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=14979, meanQ=61.161760, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 5, numVisits=25, meanQ=-1.360400, numObservations: 4
action 1, numVisits=3, meanQ=-34.333333, numObservations: 2
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 118092 episodes
GETTING ACTION FROM:
action 2, numVisits=133071, meanQ=63.882766, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 5, numVisits=25, meanQ=-1.360400, numObservations: 4
action 1, numVisits=3, meanQ=-34.333333, numObservations: 2
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.927692 0.60066 0.384738 0.968483 0.338064 0.439939 0.658653 0.375693 0.960986 0.456556 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 93.0499
Run # 119
Initial state: 0 0.00712778 0.43171 0.711475 0.502654 0.318396 0.444655 0.849222 0.0702728 0.152041 0.527413 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49835 episodes
GETTING ACTION FROM:
action -1, numVisits=49805, meanQ=50.311003, numObservations: 243
action 0, numVisits=25, meanQ=-1.010000, numObservations: 25
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.00712778 0.43171 0.711475 0.502654 0.318396 0.444655 0.849222 0.0702728 0.152041 0.527413 w: 1
Observation: 0 1 0 3 0 2 0 3 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=288, meanQ=10.046045, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 4, numVisits=7, meanQ=-2.287143, numObservations: 5
action 1, numVisits=3, meanQ=-4.003333, numObservations: 2
action 0, numVisits=2, meanQ=-6.459950, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 121607 episodes
GETTING ACTION FROM:
action 2, numVisits=121895, meanQ=25.281800, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 4, numVisits=7, meanQ=-2.287143, numObservations: 5
action 1, numVisits=3, meanQ=-4.003333, numObservations: 2
action 0, numVisits=2, meanQ=-6.459950, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 2
Next state: 1 0.00712778 0.43171 0.711475 0.502654 0.318396 0.444655 0.849222 0.0702728 0.152041 0.527413 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 120
Initial state: 0 0.0914815 0.356634 0.937462 0.27982 0.46843 0.247631 0.336299 0.418793 0.991746 0.656332 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95774 episodes
GETTING ACTION FROM:
action 1, numVisits=95757, meanQ=26.257443, numObservations: 9
action 4, numVisits=11, meanQ=14.634545, numObservations: 8
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.0914815 0.356634 0.937462 0.27982 0.46843 0.247631 0.336299 0.418793 0.991746 0.656332 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=2619, meanQ=32.580598, numObservations: 9
action 3, numVisits=4, meanQ=21.747500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 49847 episodes
GETTING ACTION FROM:
action 4, numVisits=52465, meanQ=27.504527, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=5, meanQ=-2.802000, numObservations: 4
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 4
Next state: 1 0.0914815 0.356634 0.937462 0.27982 0.46843 0.247631 0.336299 0.418793 0.991746 0.656332 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 121
Initial state: 0 0.681927 0.774617 0.228051 0.744925 0.556148 0.990063 0.379566 0.401872 0.255271 0.318345 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95650 episodes
GETTING ACTION FROM:
action 1, numVisits=95642, meanQ=27.191866, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.681927 0.774617 0.228051 0.744925 0.556148 0.990063 0.379566 0.401872 0.255271 0.318345 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 122
Initial state: 0 0.719969 0.120498 0.309595 0.448942 0.419175 0.97246 0.582805 0.330696 0.216779 0.312899 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 96806 episodes
GETTING ACTION FROM:
action 4, numVisits=96800, meanQ=27.439880, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.719969 0.120498 0.309595 0.448942 0.419175 0.97246 0.582805 0.330696 0.216779 0.312899 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 123
Initial state: 0 0.612803 0.943836 0.751901 0.00654181 0.391046 0.454152 0.707191 0.0600708 0.0466575 0.946769 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 98077 episodes
GETTING ACTION FROM:
action 1, numVisits=73434, meanQ=26.838467, numObservations: 9
action 4, numVisits=24620, meanQ=25.464857, numObservations: 9
action 5, numVisits=4, meanQ=21.500000, numObservations: 4
action 3, numVisits=5, meanQ=19.000000, numObservations: 4
action 2, numVisits=12, meanQ=14.082500, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.612803 0.943836 0.751901 0.00654181 0.391046 0.454152 0.707191 0.0600708 0.0466575 0.946769 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 124
Initial state: 0 0.457381 0.261472 0.904909 0.270929 0.415001 0.436271 0.158235 0.340981 0.0590561 0.207858 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 96652 episodes
GETTING ACTION FROM:
action 3, numVisits=96646, meanQ=26.693577, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.457381 0.261472 0.904909 0.270929 0.415001 0.436271 0.158235 0.340981 0.0590561 0.207858 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=1432, meanQ=60.446521, numObservations: 198
action 2, numVisits=5, meanQ=-2.802000, numObservations: 5
action 1, numVisits=3, meanQ=-4.003333, numObservations: 3
action -1, numVisits=15, meanQ=-7.742000, numObservations: 14
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 76911 episodes
GETTING ACTION FROM:
action 0, numVisits=78343, meanQ=6.619761, numObservations: 243
action 2, numVisits=5, meanQ=-2.802000, numObservations: 5
action 1, numVisits=3, meanQ=-4.003333, numObservations: 3
action -1, numVisits=15, meanQ=-7.742000, numObservations: 14
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.457381 0.261472 0.904909 0.270929 0.415001 0.436271 0.158235 0.340981 0.0590561 0.207858 w: 1
Observation: 0 0 1 0 1 0 1 0 1 0 1 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=12, meanQ=54.915008, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 122650 episodes
GETTING ACTION FROM:
action 3, numVisits=122662, meanQ=74.987794, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.457381 0.261472 0.904909 0.270929 0.415001 0.436271 0.158235 0.340981 0.0590561 0.207858 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 84.0499
Run # 125
Initial state: 0 0.915177 0.442147 0.0770166 0.365177 0.386612 0.506908 0.369559 0.0946301 0.0510414 0.278787 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 94938 episodes
GETTING ACTION FROM:
action 3, numVisits=94896, meanQ=27.397439, numObservations: 9
action 2, numVisits=35, meanQ=7.799440, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.915177 0.442147 0.0770166 0.365177 0.386612 0.506908 0.369559 0.0946301 0.0510414 0.278787 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 126
Initial state: 0 0.81068 0.264863 0.0933905 0.436763 0.417525 0.39239 0.721003 0.354051 0.102565 0.893934 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91517 episodes
GETTING ACTION FROM:
action 1, numVisits=91500, meanQ=28.609213, numObservations: 9
action 2, numVisits=9, meanQ=10.111111, numObservations: 7
action 4, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.81068 0.264863 0.0933905 0.436763 0.417525 0.39239 0.721003 0.354051 0.102565 0.893934 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=2274, meanQ=32.889085, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 100858 episodes
GETTING ACTION FROM:
action 3, numVisits=103113, meanQ=7.925213, numObservations: 9
action 0, numVisits=7, meanQ=-1.717143, numObservations: 7
action -1, numVisits=7, meanQ=-1.858571, numObservations: 7
action 2, numVisits=9, meanQ=-2.774184, numObservations: 5
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.81068 0.264863 0.0933905 0.436763 0.417525 0.39239 0.721003 0.354051 0.102565 0.893934 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 127
Initial state: 0 0.35933 0.457155 0.812714 0.157526 0.121095 0.0850021 0.0287099 0.474801 0.647107 0.48428 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91657 episodes
GETTING ACTION FROM:
action 3, numVisits=91650, meanQ=29.104269, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.35933 0.457155 0.812714 0.157526 0.121095 0.0850021 0.0287099 0.474801 0.647107 0.48428 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=2448, meanQ=34.639107, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=3, meanQ=-4.003333, numObservations: 3
action 5, numVisits=3, meanQ=-4.003333, numObservations: 3
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 47266 episodes
GETTING ACTION FROM:
action 2, numVisits=49714, meanQ=27.748768, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=3, meanQ=-4.003333, numObservations: 3
action 5, numVisits=3, meanQ=-4.003333, numObservations: 3
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 2
Next state: 2 0.35933 0.457155 0.812714 0.157526 0.121095 0.0850021 0.0287099 0.474801 0.647107 0.48428 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -110.99
Run # 128
Initial state: 0 0.392325 0.520075 0.0492422 0.96288 0.951088 0.919004 0.311778 0.854963 0.0681159 0.578698 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 50256 episodes
GETTING ACTION FROM:
action 0, numVisits=50228, meanQ=63.360149, numObservations: 243
action 4, numVisits=5, meanQ=-3.000000, numObservations: 4
action 3, numVisits=3, meanQ=-4.333333, numObservations: 3
action -1, numVisits=17, meanQ=-6.950000, numObservations: 16
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.392325 0.520075 0.0492422 0.96288 0.951088 0.919004 0.311778 0.854963 0.0681159 0.578698 w: 1
Observation: 0 0 2 0 3 0 3 0 3 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=381, meanQ=90.560476, numObservations: 9
action 4, numVisits=3, meanQ=62.663333, numObservations: 3
action 5, numVisits=3, meanQ=62.663333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 115357 episodes
GETTING ACTION FROM:
action 1, numVisits=115738, meanQ=92.264108, numObservations: 9
action 4, numVisits=3, meanQ=62.663333, numObservations: 3
action 5, numVisits=3, meanQ=62.663333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.392325 0.520075 0.0492422 0.96288 0.951088 0.919004 0.311778 0.854963 0.0681159 0.578698 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 129
Initial state: 0 0.898292 0.592112 0.938806 0.702517 0.433568 0.721089 0.163019 0.697828 0.392737 0.47589 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 96910 episodes
GETTING ACTION FROM:
action 2, numVisits=96899, meanQ=27.572359, numObservations: 9
action 1, numVisits=6, meanQ=-1.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.898292 0.592112 0.938806 0.702517 0.433568 0.721089 0.163019 0.697828 0.392737 0.47589 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 130
Initial state: 0 0.0807036 0.0517995 0.402448 0.406431 0.294827 0.632598 0.856121 0.856694 0.166346 0.842416 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97381 episodes
GETTING ACTION FROM:
action 5, numVisits=97375, meanQ=27.543778, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.0807036 0.0517995 0.402448 0.406431 0.294827 0.632598 0.856121 0.856694 0.166346 0.842416 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=6404, meanQ=32.048519, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 106640 episodes
GETTING ACTION FROM:
action 3, numVisits=113044, meanQ=34.428654, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.0807036 0.0517995 0.402448 0.406431 0.294827 0.632598 0.856121 0.856694 0.166346 0.842416 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 0, numVisits=2461, meanQ=60.778668, numObservations: 200
action -1, numVisits=22, meanQ=-2.181800, numObservations: 18
action 4, numVisits=10, meanQ=-4.001000, numObservations: 5
action 2, numVisits=3, meanQ=-4.003333, numObservations: 3
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 67248 episodes
GETTING ACTION FROM:
action 0, numVisits=69709, meanQ=21.379591, numObservations: 243
action -1, numVisits=22, meanQ=-2.181800, numObservations: 18
action 4, numVisits=10, meanQ=-4.001000, numObservations: 5
action 2, numVisits=3, meanQ=-4.003333, numObservations: 3
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.0807036 0.0517995 0.402448 0.406431 0.294827 0.632598 0.856121 0.856694 0.166346 0.842416 w: 1
Observation: 0 0 1 0 2 0 3 0 1 0 3 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=127, meanQ=75.645988, numObservations: 8
action 5, numVisits=2, meanQ=44.495000, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 125644 episodes
GETTING ACTION FROM:
action 2, numVisits=125771, meanQ=86.516792, numObservations: 9
action 5, numVisits=2, meanQ=44.495000, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 2
Next state: 1 0.0807036 0.0517995 0.402448 0.406431 0.294827 0.632598 0.856121 0.856694 0.166346 0.842416 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 72.2094
Run # 131
Initial state: 0 0.407218 0.425027 0.121578 0.751318 0.196913 0.480108 0.0813059 0.546879 0.586405 0.631648 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 50186 episodes
GETTING ACTION FROM:
action 0, numVisits=50137, meanQ=61.549694, numObservations: 243
action -1, numVisits=39, meanQ=-4.031785, numObservations: 34
action 1, numVisits=4, meanQ=-5.752500, numObservations: 4
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=3, meanQ=-34.333333, numObservations: 2
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.407218 0.425027 0.121578 0.751318 0.196913 0.480108 0.0813059 0.546879 0.586405 0.631648 w: 1
Observation: 0 0 2 0 2 0 2 0 3 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=102, meanQ=64.324608, numObservations: 9
action 1, numVisits=2, meanQ=44.495000, numObservations: 2
action 2, numVisits=9, meanQ=41.111111, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 100479 episodes
GETTING ACTION FROM:
action 4, numVisits=100581, meanQ=63.752563, numObservations: 9
action 1, numVisits=2, meanQ=44.495000, numObservations: 2
action 2, numVisits=9, meanQ=41.111111, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 4
Next state: 0 0.407218 0.425027 0.121578 0.751318 0.196913 0.480108 0.0813059 0.546879 0.586405 0.631648 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=1409, meanQ=61.876217, numObservations: 9
action 2, numVisits=14, meanQ=24.218579, numObservations: 6
action 3, numVisits=4, meanQ=21.747500, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 45627 episodes
GETTING ACTION FROM:
action 5, numVisits=47036, meanQ=63.013748, numObservations: 9
action 2, numVisits=14, meanQ=24.218579, numObservations: 6
action 3, numVisits=4, meanQ=21.747500, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 5
Next state: 1 0.407218 0.425027 0.121578 0.751318 0.196913 0.480108 0.0813059 0.546879 0.586405 0.631648 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 84.1399
Run # 132
Initial state: 0 0.0739743 0.663875 0.741665 0.470077 0.990567 0.450603 0.324648 0.65739 0.376611 0.467277 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97701 episodes
GETTING ACTION FROM:
action 3, numVisits=97694, meanQ=27.902335, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.0739743 0.663875 0.741665 0.470077 0.990567 0.450603 0.324648 0.65739 0.376611 0.467277 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 133
Initial state: 0 0.397228 0.47015 0.0820173 0.356668 0.94143 0.495091 0.775361 0.75721 0.276515 0.82802 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97833 episodes
GETTING ACTION FROM:
action 3, numVisits=97824, meanQ=26.685861, numObservations: 9
action 2, numVisits=4, meanQ=21.500000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.397228 0.47015 0.0820173 0.356668 0.94143 0.495091 0.775361 0.75721 0.276515 0.82802 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 134
Initial state: 0 0.87337 0.955224 0.321593 0.453886 0.250542 0.093483 0.259907 0.491052 0.945577 0.701115 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 94152 episodes
GETTING ACTION FROM:
action 3, numVisits=94134, meanQ=27.403782, numObservations: 9
action 2, numVisits=8, meanQ=10.250000, numObservations: 5
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=5, meanQ=-2.802000, numObservations: 4
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.87337 0.955224 0.321593 0.453886 0.250542 0.093483 0.259907 0.491052 0.945577 0.701115 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=6717, meanQ=30.737557, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=3, meanQ=-4.003333, numObservations: 3
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 31313 episodes
GETTING ACTION FROM:
action 2, numVisits=38030, meanQ=25.654152, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=3, meanQ=-4.003333, numObservations: 3
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.87337 0.955224 0.321593 0.453886 0.250542 0.093483 0.259907 0.491052 0.945577 0.701115 w: 1
Observation: 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 135
Initial state: 0 0.335187 0.511273 0.729998 0.270513 0.867264 0.86354 0.497741 0.570082 0.740218 0.446418 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 90178 episodes
GETTING ACTION FROM:
action 2, numVisits=90172, meanQ=29.215317, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.335187 0.511273 0.729998 0.270513 0.867264 0.86354 0.497741 0.570082 0.740218 0.446418 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 136
Initial state: 0 0.429959 0.437804 0.0280566 0.69496 0.594718 0.307944 0.909656 0.457016 0.60047 0.816525 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 98065 episodes
GETTING ACTION FROM:
action 3, numVisits=98027, meanQ=26.807179, numObservations: 9
action 4, numVisits=24, meanQ=12.794592, numObservations: 9
action 5, numVisits=9, meanQ=7.888889, numObservations: 6
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.429959 0.437804 0.0280566 0.69496 0.594718 0.307944 0.909656 0.457016 0.60047 0.816525 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 137
Initial state: 0 0.693134 0.568424 0.496273 0.749611 0.329127 0.480308 0.941757 0.612114 0.0790709 0.653625 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92629 episodes
GETTING ACTION FROM:
action 3, numVisits=92587, meanQ=28.985917, numObservations: 9
action 1, numVisits=26, meanQ=24.664246, numObservations: 8
action 2, numVisits=12, meanQ=21.499175, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.693134 0.568424 0.496273 0.749611 0.329127 0.480308 0.941757 0.612114 0.0790709 0.653625 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 138
Initial state: 0 0.946398 0.34307 0.486827 0.319385 0.729575 0.127954 0.717208 0.450535 0.362133 0.459381 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92358 episodes
GETTING ACTION FROM:
action 5, numVisits=92339, meanQ=28.258742, numObservations: 9
action 4, numVisits=8, meanQ=21.623750, numObservations: 6
action 1, numVisits=7, meanQ=8.857143, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.946398 0.34307 0.486827 0.319385 0.729575 0.127954 0.717208 0.450535 0.362133 0.459381 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 139
Initial state: 0 0.0615841 0.15908 0.912133 0.96779 0.452665 0.655238 0.155432 0.369653 0.298575 0.416201 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 50620 episodes
GETTING ACTION FROM:
action 0, numVisits=50574, meanQ=62.952989, numObservations: 243
action -1, numVisits=21, meanQ=-5.818571, numObservations: 20
action 5, numVisits=21, meanQ=-6.714286, numObservations: 7
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.0615841 0.15908 0.912133 0.96779 0.452665 0.655238 0.155432 0.369653 0.298575 0.416201 w: 1
Observation: 0 0 1 0 3 0 3 0 1 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=156, meanQ=80.641351, numObservations: 9
action 3, numVisits=113, meanQ=64.159650, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 113620 episodes
GETTING ACTION FROM:
action 5, numVisits=113776, meanQ=87.341383, numObservations: 9
action 3, numVisits=113, meanQ=64.159650, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.0615841 0.15908 0.912133 0.96779 0.452665 0.655238 0.155432 0.369653 0.298575 0.416201 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 140
Initial state: 0 0.286099 0.00131256 0.300364 0.209552 0.820585 0.619707 0.412518 0.402694 0.3388 0.875553 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95088 episodes
GETTING ACTION FROM:
action 1, numVisits=95071, meanQ=27.774387, numObservations: 9
action 5, numVisits=8, meanQ=-1.000000, numObservations: 5
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.286099 0.00131256 0.300364 0.209552 0.820585 0.619707 0.412518 0.402694 0.3388 0.875553 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=6782, meanQ=30.852788, numObservations: 9
action 3, numVisits=4, meanQ=21.747500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 27509 episodes
GETTING ACTION FROM:
action 5, numVisits=34289, meanQ=25.632466, numObservations: 9
action 3, numVisits=6, meanQ=14.165000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.286099 0.00131256 0.300364 0.209552 0.820585 0.619707 0.412518 0.402694 0.3388 0.875553 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -110.99
Run # 141
Initial state: 0 0.560816 0.832621 0.876234 0.748482 0.376741 0.43087 0.499017 0.689268 0.768552 0.760772 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 50637 episodes
GETTING ACTION FROM:
action 0, numVisits=50583, meanQ=62.677262, numObservations: 243
action -1, numVisits=38, meanQ=-6.663942, numObservations: 34
action 3, numVisits=12, meanQ=-6.744150, numObservations: 6
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.560816 0.832621 0.876234 0.748482 0.376741 0.43087 0.499017 0.689268 0.768552 0.760772 w: 1
Observation: 0 0 3 0 3 0 1 0 3 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=153, meanQ=83.467578, numObservations: 9
action 2, numVisits=6, meanQ=65.666667, numObservations: 4
action 5, numVisits=6, meanQ=62.663333, numObservations: 3
action 1, numVisits=5, meanQ=59.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 103093 episodes
GETTING ACTION FROM:
action 4, numVisits=103246, meanQ=68.751608, numObservations: 9
action 2, numVisits=6, meanQ=65.666667, numObservations: 4
action 5, numVisits=6, meanQ=62.663333, numObservations: 3
action 1, numVisits=5, meanQ=59.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.560816 0.832621 0.876234 0.748482 0.376741 0.43087 0.499017 0.689268 0.768552 0.760772 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101.99
Run # 142
Initial state: 0 0.952739 0.545826 0.036115 0.182373 0.204153 0.699128 0.352754 0.435473 0.661413 0.0845997 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49818 episodes
GETTING ACTION FROM:
action -1, numVisits=49803, meanQ=54.037805, numObservations: 243
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=10, meanQ=-11.108000, numObservations: 9
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.952739 0.545826 0.036115 0.182373 0.204153 0.699128 0.352754 0.435473 0.661413 0.0845997 w: 1
Observation: 0 3 0 3 0 1 0 2 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=490, meanQ=84.980282, numObservations: 9
action 2, numVisits=4, meanQ=21.747500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 112759 episodes
GETTING ACTION FROM:
action 4, numVisits=113249, meanQ=88.629775, numObservations: 9
action 2, numVisits=4, meanQ=21.747500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.952739 0.545826 0.036115 0.182373 0.204153 0.699128 0.352754 0.435473 0.661413 0.0845997 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 143
Initial state: 0 0.260178 0.526325 0.330695 0.47099 0.286776 0.570992 0.643065 0.0437578 0.723147 0.548036 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 94102 episodes
GETTING ACTION FROM:
action 1, numVisits=94093, meanQ=28.407851, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.260178 0.526325 0.330695 0.47099 0.286776 0.570992 0.643065 0.0437578 0.723147 0.548036 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=2506, meanQ=35.358684, numObservations: 9
action 4, numVisits=7, meanQ=13.285714, numObservations: 6
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=3, meanQ=-4.003333, numObservations: 3
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 37342 episodes
GETTING ACTION FROM:
action 5, numVisits=39848, meanQ=30.730277, numObservations: 9
action 4, numVisits=7, meanQ=13.285714, numObservations: 6
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=3, meanQ=-4.003333, numObservations: 3
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 5
Next state: 1 0.260178 0.526325 0.330695 0.47099 0.286776 0.570992 0.643065 0.0437578 0.723147 0.548036 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 144
Initial state: 0 0.248699 0.812109 0.198355 0.630139 0.331109 0.413987 0.133492 0.643762 0.631628 0.765228 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 98110 episodes
GETTING ACTION FROM:
action 1, numVisits=98102, meanQ=27.124804, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.248699 0.812109 0.198355 0.630139 0.331109 0.413987 0.133492 0.643762 0.631628 0.765228 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=7028, meanQ=31.836026, numObservations: 9
action -1, numVisits=24, meanQ=-9.425000, numObservations: 22
action 2, numVisits=2, meanQ=-10.010000, numObservations: 2
action 1, numVisits=2, meanQ=-11.004950, numObservations: 1
action 0, numVisits=3, meanQ=-34.670000, numObservations: 2
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 26961 episodes
GETTING ACTION FROM:
action 3, numVisits=33989, meanQ=26.164014, numObservations: 9
action -1, numVisits=24, meanQ=-9.425000, numObservations: 22
action 2, numVisits=2, meanQ=-10.010000, numObservations: 2
action 1, numVisits=2, meanQ=-11.004950, numObservations: 1
action 0, numVisits=3, meanQ=-34.670000, numObservations: 2
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.248699 0.812109 0.198355 0.630139 0.331109 0.413987 0.133492 0.643762 0.631628 0.765228 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 145
Initial state: 0 0.513867 0.181989 0.481669 0.793208 0.173107 0.812447 0.379784 0.47474 0.0220908 0.266734 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97970 episodes
GETTING ACTION FROM:
action 4, numVisits=97961, meanQ=27.216692, numObservations: 9
action 5, numVisits=4, meanQ=21.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.513867 0.181989 0.481669 0.793208 0.173107 0.812447 0.379784 0.47474 0.0220908 0.266734 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 146
Initial state: 0 0.424605 0.406422 0.56914 0.988904 0.539987 0.252035 0.397546 0.593654 0.720076 0.153393 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92643 episodes
GETTING ACTION FROM:
action 2, numVisits=92634, meanQ=27.632886, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=4, meanQ=-6.000000, numObservations: 4
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.424605 0.406422 0.56914 0.988904 0.539987 0.252035 0.397546 0.593654 0.720076 0.153393 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 147
Initial state: 0 0.379373 0.486007 0.511647 0.727498 0.0428793 0.316571 0.247165 0.125628 0.844405 0.704578 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 96022 episodes
GETTING ACTION FROM:
action 5, numVisits=96015, meanQ=27.602299, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.379373 0.486007 0.511647 0.727498 0.0428793 0.316571 0.247165 0.125628 0.844405 0.704578 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 148
Initial state: 0 0.283242 0.347512 0.889804 0.850836 0.61461 0.156614 0.296982 0.399007 0.375933 0.499919 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88194 episodes
GETTING ACTION FROM:
action 3, numVisits=88186, meanQ=28.959677, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.283242 0.347512 0.889804 0.850836 0.61461 0.156614 0.296982 0.399007 0.375933 0.499919 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 149
Initial state: 0 0.385405 0.524089 0.192287 0.619189 0.913612 0.0289789 0.568131 0.933361 0.411793 0.84361 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 93513 episodes
GETTING ACTION FROM:
action 3, numVisits=93500, meanQ=27.136902, numObservations: 9
action 5, numVisits=6, meanQ=12.335000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.385405 0.524089 0.192287 0.619189 0.913612 0.0289789 0.568131 0.933361 0.411793 0.84361 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=6733, meanQ=33.308364, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 37176 episodes
GETTING ACTION FROM:
action 5, numVisits=43909, meanQ=32.190147, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 5
Next state: 1 0.385405 0.524089 0.192287 0.619189 0.913612 0.0289789 0.568131 0.933361 0.411793 0.84361 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 150
Initial state: 0 0.326433 0.610297 0.102365 0.841198 0.102562 0.940009 0.751952 0.933007 0.395393 0.4665 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49282 episodes
GETTING ACTION FROM:
action -1, numVisits=49238, meanQ=52.387553, numObservations: 243
action 0, numVisits=21, meanQ=-1.010000, numObservations: 21
action 1, numVisits=19, meanQ=-1.526316, numObservations: 6
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.326433 0.610297 0.102365 0.841198 0.102562 0.940009 0.751952 0.933007 0.395393 0.4665 w: 1
Observation: 0 2 0 3 0 1 0 3 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=235, meanQ=81.478343, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 113240 episodes
GETTING ACTION FROM:
action 1, numVisits=113475, meanQ=78.703320, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.326433 0.610297 0.102365 0.841198 0.102562 0.940009 0.751952 0.933007 0.395393 0.4665 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 151
Initial state: 0 0.3472 0.39636 0.556359 0.417651 0.993601 0.929582 0.68603 0.0700727 0.757525 0.370381 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97105 episodes
GETTING ACTION FROM:
action 1, numVisits=97088, meanQ=26.392392, numObservations: 9
action 3, numVisits=9, meanQ=7.998889, numObservations: 7
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.3472 0.39636 0.556359 0.417651 0.993601 0.929582 0.68603 0.0700727 0.757525 0.370381 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 152
Initial state: 0 0.283992 0.412305 0.412604 0.518746 0.654756 0.819603 0.154306 0.910867 0.455969 0.00476371 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91685 episodes
GETTING ACTION FROM:
action 1, numVisits=91678, meanQ=28.229192, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.283992 0.412305 0.412604 0.518746 0.654756 0.819603 0.154306 0.910867 0.455969 0.00476371 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 153
Initial state: 0 0.844003 0.45962 0.704466 0.656965 0.31394 0.44605 0.88744 0.196348 0.715632 0.0981377 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 50761 episodes
GETTING ACTION FROM:
action 0, numVisits=50734, meanQ=62.573001, numObservations: 243
action -1, numVisits=14, meanQ=-1.152136, numObservations: 13
action 4, numVisits=7, meanQ=-4.141429, numObservations: 4
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=3, meanQ=-34.333333, numObservations: 3
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.844003 0.45962 0.704466 0.656965 0.31394 0.44605 0.88744 0.196348 0.715632 0.0981377 w: 1
Observation: 0 0 2 0 3 0 1 0 3 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=271, meanQ=80.533434, numObservations: 9
action 3, numVisits=2, meanQ=44.495000, numObservations: 2
action 4, numVisits=2, meanQ=44.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 112963 episodes
GETTING ACTION FROM:
action 1, numVisits=113234, meanQ=91.994370, numObservations: 9
action 3, numVisits=2, meanQ=44.495000, numObservations: 2
action 4, numVisits=2, meanQ=44.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.844003 0.45962 0.704466 0.656965 0.31394 0.44605 0.88744 0.196348 0.715632 0.0981377 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 154
Initial state: 0 0.907239 0.963836 0.374334 0.43291 0.919064 0.134397 0.991832 0.701443 0.685595 0.750234 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97524 episodes
GETTING ACTION FROM:
action 3, numVisits=97515, meanQ=26.285799, numObservations: 9
action 1, numVisits=4, meanQ=21.747500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.907239 0.963836 0.374334 0.43291 0.919064 0.134397 0.991832 0.701443 0.685595 0.750234 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 155
Initial state: 0 0.34335 0.573439 0.39285 0.509874 0.795995 0.830108 0.72989 0.30922 0.317975 0.768069 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 96552 episodes
GETTING ACTION FROM:
action 2, numVisits=96534, meanQ=27.809883, numObservations: 9
action 4, numVisits=8, meanQ=21.500000, numObservations: 8
action 5, numVisits=5, meanQ=15.000000, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.34335 0.573439 0.39285 0.509874 0.795995 0.830108 0.72989 0.30922 0.317975 0.768069 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 156
Initial state: 0 0.170982 0.426597 0.368296 0.701461 0.338532 0.52153 0.659757 0.227074 0.630104 0.106783 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97178 episodes
GETTING ACTION FROM:
action 2, numVisits=97170, meanQ=27.676329, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.170982 0.426597 0.368296 0.701461 0.338532 0.52153 0.659757 0.227074 0.630104 0.106783 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 157
Initial state: 0 0.089942 0.925122 0.324611 0.513307 0.206611 0.329476 0.392212 0.544288 0.474099 0.184046 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 96599 episodes
GETTING ACTION FROM:
action 1, numVisits=96577, meanQ=26.852066, numObservations: 9
action 5, numVisits=9, meanQ=16.998889, numObservations: 6
action 3, numVisits=8, meanQ=7.997500, numObservations: 6
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.089942 0.925122 0.324611 0.513307 0.206611 0.329476 0.392212 0.544288 0.474099 0.184046 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=6376, meanQ=34.046426, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 112158 episodes
GETTING ACTION FROM:
action 5, numVisits=118534, meanQ=37.990196, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.089942 0.925122 0.324611 0.513307 0.206611 0.329476 0.392212 0.544288 0.474099 0.184046 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -110.99
Run # 158
Initial state: 0 0.243398 0.0127686 0.739068 0.957146 0.358728 0.519489 0.104249 0.479898 0.618089 0.12683 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88349 episodes
GETTING ACTION FROM:
action 5, numVisits=88342, meanQ=29.625884, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.243398 0.0127686 0.739068 0.957146 0.358728 0.519489 0.104249 0.479898 0.618089 0.12683 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 159
Initial state: 0 0.345622 0.453349 0.599188 0.114783 0.0297913 0.31409 0.164065 0.140976 0.980711 0.428848 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95114 episodes
GETTING ACTION FROM:
action 3, numVisits=95107, meanQ=27.646732, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.345622 0.453349 0.599188 0.114783 0.0297913 0.31409 0.164065 0.140976 0.980711 0.428848 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 160
Initial state: 0 0.0623969 0.0529059 0.130904 0.0379339 0.939767 0.627049 0.535946 0.928443 0.374459 0.403102 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95854 episodes
GETTING ACTION FROM:
action 3, numVisits=95844, meanQ=27.542408, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.0623969 0.0529059 0.130904 0.0379339 0.939767 0.627049 0.535946 0.928443 0.374459 0.403102 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 161
Initial state: 0 0.644477 0.225047 0.348685 0.457122 0.966817 0.676002 0.806413 0.0639721 0.0049652 0.579021 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97246 episodes
GETTING ACTION FROM:
action 5, numVisits=97239, meanQ=27.125089, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.644477 0.225047 0.348685 0.457122 0.966817 0.676002 0.806413 0.0639721 0.0049652 0.579021 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=6560, meanQ=34.582066, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=9, meanQ=-2.001111, numObservations: 6
action 2, numVisits=3, meanQ=-4.003333, numObservations: 2
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 109410 episodes
GETTING ACTION FROM:
action 4, numVisits=115970, meanQ=40.796789, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=9, meanQ=-2.001111, numObservations: 6
action 2, numVisits=3, meanQ=-4.003333, numObservations: 2
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.644477 0.225047 0.348685 0.457122 0.966817 0.676002 0.806413 0.0639721 0.0049652 0.579021 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -110.99
Run # 162
Initial state: 0 0.662396 0.514185 0.831693 0.248994 0.979877 0.813628 0.36727 0.519787 0.0379452 0.493423 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92509 episodes
GETTING ACTION FROM:
action 1, numVisits=92498, meanQ=28.758742, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=6, meanQ=-4.333333, numObservations: 5
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.662396 0.514185 0.831693 0.248994 0.979877 0.813628 0.36727 0.519787 0.0379452 0.493423 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 163
Initial state: 0 0.49611 0.652515 0.352303 0.546488 0.927073 0.861105 0.35091 0.533658 0.199825 0.705334 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95377 episodes
GETTING ACTION FROM:
action 3, numVisits=95367, meanQ=26.684008, numObservations: 9
action 2, numVisits=5, meanQ=15.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.49611 0.652515 0.352303 0.546488 0.927073 0.861105 0.35091 0.533658 0.199825 0.705334 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 164
Initial state: 0 0.66397 0.261039 0.500424 0.302235 0.657771 0.918939 0.377295 0.338303 0.331773 0.442811 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 96031 episodes
GETTING ACTION FROM:
action 2, numVisits=96002, meanQ=27.550240, numObservations: 9
action 4, numVisits=24, meanQ=21.210838, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.66397 0.261039 0.500424 0.302235 0.657771 0.918939 0.377295 0.338303 0.331773 0.442811 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 165
Initial state: 0 0.185582 0.668188 0.691654 0.995692 0.946912 0.770296 0.348679 0.456338 0.726371 0.336845 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 96830 episodes
GETTING ACTION FROM:
action 3, numVisits=96776, meanQ=28.214755, numObservations: 9
action 1, numVisits=41, meanQ=26.925854, numObservations: 9
action 2, numVisits=5, meanQ=19.000000, numObservations: 4
action 5, numVisits=5, meanQ=14.800020, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.185582 0.668188 0.691654 0.995692 0.946912 0.770296 0.348679 0.456338 0.726371 0.336845 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 166
Initial state: 0 0.747719 0.283098 0.802076 0.580275 0.337635 0.513682 0.536844 0.778071 0.123298 0.232986 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95167 episodes
GETTING ACTION FROM:
action 4, numVisits=95159, meanQ=27.476234, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.747719 0.283098 0.802076 0.580275 0.337635 0.513682 0.536844 0.778071 0.123298 0.232986 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 167
Initial state: 0 0.503594 0.94811 0.479387 0.149293 0.0965747 0.114275 0.00440942 0.309671 0.322656 0.406118 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97031 episodes
GETTING ACTION FROM:
action 5, numVisits=97003, meanQ=26.981104, numObservations: 9
action 4, numVisits=12, meanQ=20.750000, numObservations: 6
action 3, numVisits=11, meanQ=14.634545, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.503594 0.94811 0.479387 0.149293 0.0965747 0.114275 0.00440942 0.309671 0.322656 0.406118 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 168
Initial state: 0 0.906597 0.525315 0.304129 0.489 0.959159 0.189771 0.392075 0.582096 0.915146 0.360981 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 94016 episodes
GETTING ACTION FROM:
action 5, numVisits=93994, meanQ=28.553504, numObservations: 9
action 4, numVisits=15, meanQ=22.332673, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.906597 0.525315 0.304129 0.489 0.959159 0.189771 0.392075 0.582096 0.915146 0.360981 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 169
Initial state: 0 0.643459 0.43129 0.496596 0.196304 0.612901 0.357012 0.309794 0.400722 0.760033 0.294717 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51018 episodes
GETTING ACTION FROM:
action 0, numVisits=50898, meanQ=64.871885, numObservations: 243
action -1, numVisits=76, meanQ=-1.831439, numObservations: 58
action 5, numVisits=35, meanQ=-2.428571, numObservations: 8
action 3, numVisits=6, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.643459 0.43129 0.496596 0.196304 0.612901 0.357012 0.309794 0.400722 0.760033 0.294717 w: 1
Observation: 0 0 3 0 1 0 1 0 2 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=255, meanQ=84.560978, numObservations: 9
action 1, numVisits=2, meanQ=44.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 111094 episodes
GETTING ACTION FROM:
action 4, numVisits=111349, meanQ=87.163722, numObservations: 9
action 1, numVisits=2, meanQ=44.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.643459 0.43129 0.496596 0.196304 0.612901 0.357012 0.309794 0.400722 0.760033 0.294717 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=2391, meanQ=57.518103, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 51704 episodes
GETTING ACTION FROM:
action 1, numVisits=54095, meanQ=66.305220, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.643459 0.43129 0.496596 0.196304 0.612901 0.357012 0.309794 0.400722 0.760033 0.294717 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 84.1399
Run # 170
Initial state: 0 0.226351 0.356177 0.311234 0.445214 0.701847 0.209771 0.16885 0.113283 0.518793 0.671264 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 96404 episodes
GETTING ACTION FROM:
action 3, numVisits=96373, meanQ=27.758239, numObservations: 9
action 4, numVisits=25, meanQ=10.200000, numObservations: 7
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.226351 0.356177 0.311234 0.445214 0.701847 0.209771 0.16885 0.113283 0.518793 0.671264 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 171
Initial state: 0 0.386708 0.263405 0.409129 0.428473 0.375709 0.944137 0.707961 0.681905 0.416211 0.739812 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 96767 episodes
GETTING ACTION FROM:
action 4, numVisits=96750, meanQ=27.337743, numObservations: 9
action 2, numVisits=9, meanQ=20.111111, numObservations: 4
action 5, numVisits=4, meanQ=-1.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.386708 0.263405 0.409129 0.428473 0.375709 0.944137 0.707961 0.681905 0.416211 0.739812 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 172
Initial state: 0 0.484659 0.174838 0.323224 0.499601 0.684361 0.343542 0.688107 0.807456 0.921061 0.303401 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91670 episodes
GETTING ACTION FROM:
action 3, numVisits=91646, meanQ=29.285698, numObservations: 9
action 4, numVisits=16, meanQ=22.750000, numObservations: 8
action 2, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.484659 0.174838 0.323224 0.499601 0.684361 0.343542 0.688107 0.807456 0.921061 0.303401 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 173
Initial state: 0 0.357295 0.639544 0.708582 0.187383 0.357657 0.0734725 0.487941 0.547713 0.423637 0.471989 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 93438 episodes
GETTING ACTION FROM:
action 4, numVisits=93432, meanQ=28.611648, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.357295 0.639544 0.708582 0.187383 0.357657 0.0734725 0.487941 0.547713 0.423637 0.471989 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 174
Initial state: 0 0.389226 0.847408 0.73837 0.18578 0.995479 0.751492 0.449924 0.680799 0.364171 0.432363 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 96911 episodes
GETTING ACTION FROM:
action 4, numVisits=96891, meanQ=27.979013, numObservations: 9
action 5, numVisits=11, meanQ=22.726364, numObservations: 8
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=4, meanQ=-5.752500, numObservations: 4
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.389226 0.847408 0.73837 0.18578 0.995479 0.751492 0.449924 0.680799 0.364171 0.432363 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 175
Initial state: 0 0.842783 0.324711 0.471471 0.0493768 0.564366 0.824476 0.411874 0.404215 0.550786 0.550035 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48996 episodes
GETTING ACTION FROM:
action -1, numVisits=48958, meanQ=54.138289, numObservations: 243
action 4, numVisits=15, meanQ=-4.861993, numObservations: 7
action 0, numVisits=17, meanQ=-6.950000, numObservations: 16
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=3, meanQ=-34.333333, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.842783 0.324711 0.471471 0.0493768 0.564366 0.824476 0.411874 0.404215 0.550786 0.550035 w: 1
Observation: 0 3 0 3 0 3 0 2 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=412, meanQ=43.126954, numObservations: 9
action 3, numVisits=12, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=6, meanQ=-4.003333, numObservations: 4
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 104901 episodes
GETTING ACTION FROM:
action 5, numVisits=105313, meanQ=40.554373, numObservations: 9
action 3, numVisits=12, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=6, meanQ=-4.003333, numObservations: 4
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.842783 0.324711 0.471471 0.0493768 0.564366 0.824476 0.411874 0.404215 0.550786 0.550035 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 176
Initial state: 0 0.2222 0.0313444 0.273514 0.400117 0.679074 0.856994 0.146743 0.842032 0.370141 0.391863 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95187 episodes
GETTING ACTION FROM:
action 4, numVisits=95179, meanQ=27.759390, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.2222 0.0313444 0.273514 0.400117 0.679074 0.856994 0.146743 0.842032 0.370141 0.391863 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=6236, meanQ=41.596839, numObservations: 9
action 1, numVisits=185, meanQ=33.028240, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 82760 episodes
GETTING ACTION FROM:
action 4, numVisits=88996, meanQ=57.724409, numObservations: 9
action 1, numVisits=185, meanQ=33.028240, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.2222 0.0313444 0.273514 0.400117 0.679074 0.856994 0.146743 0.842032 0.370141 0.391863 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=25843, meanQ=26.648982, numObservations: 9
action 5, numVisits=16, meanQ=20.248144, numObservations: 7
action 2, numVisits=7, meanQ=13.285714, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=4, meanQ=-8.002500, numObservations: 3
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 105773 episodes
GETTING ACTION FROM:
action 1, numVisits=131616, meanQ=36.280195, numObservations: 9
action 5, numVisits=16, meanQ=20.248144, numObservations: 7
action 2, numVisits=7, meanQ=13.285714, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=4, meanQ=-8.002500, numObservations: 3
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.2222 0.0313444 0.273514 0.400117 0.679074 0.856994 0.146743 0.842032 0.370141 0.391863 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=8072, meanQ=58.602564, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=6, meanQ=-1.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 48947 episodes
GETTING ACTION FROM:
action 3, numVisits=57019, meanQ=45.920273, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=6, meanQ=-1.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 3
Next state: 1 0.2222 0.0313444 0.273514 0.400117 0.679074 0.856994 0.146743 0.842032 0.370141 0.391863 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 63.3885
Run # 177
Initial state: 0 0.382117 0.419441 0.326089 0.658177 0.473678 0.936853 0.249106 0.0431191 0.968343 0.763784 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95531 episodes
GETTING ACTION FROM:
action 3, numVisits=95507, meanQ=27.881090, numObservations: 9
action 5, numVisits=18, meanQ=22.666678, numObservations: 7
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.382117 0.419441 0.326089 0.658177 0.473678 0.936853 0.249106 0.0431191 0.968343 0.763784 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 178
Initial state: 0 0.223553 0.268019 0.787439 0.363931 0.300818 0.494469 0.663601 0.537878 0.905455 0.784516 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48925 episodes
GETTING ACTION FROM:
action -1, numVisits=48871, meanQ=54.797479, numObservations: 243
action 5, numVisits=3, meanQ=-4.003333, numObservations: 3
action 0, numVisits=33, meanQ=-4.070000, numObservations: 32
action 1, numVisits=15, meanQ=-4.333333, numObservations: 8
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.223553 0.268019 0.787439 0.363931 0.300818 0.494469 0.663601 0.537878 0.905455 0.784516 w: 1
Observation: 0 1 0 3 0 2 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=416, meanQ=12.132622, numObservations: 9
action 5, numVisits=19, meanQ=-7.211579, numObservations: 7
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 0, numVisits=11, meanQ=-10.190000, numObservations: 10
action 2, numVisits=10, meanQ=-11.901000, numObservations: 4
action -1, numVisits=3, meanQ=-34.670000, numObservations: 2
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 120085 episodes
GETTING ACTION FROM:
action 4, numVisits=120501, meanQ=7.989704, numObservations: 9
action 5, numVisits=19, meanQ=-7.211579, numObservations: 7
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 0, numVisits=11, meanQ=-10.190000, numObservations: 10
action 2, numVisits=10, meanQ=-11.901000, numObservations: 4
action -1, numVisits=3, meanQ=-34.670000, numObservations: 2
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.223553 0.268019 0.787439 0.363931 0.300818 0.494469 0.663601 0.537878 0.905455 0.784516 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 179
Initial state: 0 0.490793 0.506347 0.364025 0.418005 0.148435 0.476739 0.429617 0.0672348 0.672933 0.164651 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49711 episodes
GETTING ACTION FROM:
action -1, numVisits=49652, meanQ=56.344174, numObservations: 243
action 0, numVisits=54, meanQ=-5.135733, numObservations: 46
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.490793 0.506347 0.364025 0.418005 0.148435 0.476739 0.429617 0.0672348 0.672933 0.164651 w: 1
Observation: 0 3 0 2 0 1 0 2 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=102, meanQ=50.129909, numObservations: 9
action 2, numVisits=4, meanQ=21.747500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 99657 episodes
GETTING ACTION FROM:
action 4, numVisits=99759, meanQ=58.638114, numObservations: 9
action 2, numVisits=4, meanQ=21.747500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.490793 0.506347 0.364025 0.418005 0.148435 0.476739 0.429617 0.0672348 0.672933 0.164651 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101.99
Run # 180
Initial state: 0 0.606712 0.939219 0.384277 0.431821 0.451991 0.460499 0.109822 0.794774 0.207805 0.536437 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95229 episodes
GETTING ACTION FROM:
action 3, numVisits=95138, meanQ=26.541468, numObservations: 9
action 1, numVisits=79, meanQ=25.356848, numObservations: 9
action 5, numVisits=4, meanQ=21.500000, numObservations: 3
action 2, numVisits=4, meanQ=-1.000000, numObservations: 4
action 4, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.606712 0.939219 0.384277 0.431821 0.451991 0.460499 0.109822 0.794774 0.207805 0.536437 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 181
Initial state: 0 0.164866 0.185067 0.406508 0.50954 0.973228 0.145766 0.806126 0.266581 0.97428 0.56261 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92140 episodes
GETTING ACTION FROM:
action 4, numVisits=92125, meanQ=27.996167, numObservations: 9
action 3, numVisits=4, meanQ=-1.000000, numObservations: 4
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 5, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.164866 0.185067 0.406508 0.50954 0.973228 0.145766 0.806126 0.266581 0.97428 0.56261 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 182
Initial state: 0 0.8104 0.872258 0.494384 0.929382 0.855547 0.866954 0.424793 0.472946 0.249721 0.239879 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95043 episodes
GETTING ACTION FROM:
action 2, numVisits=95017, meanQ=27.672213, numObservations: 9
action 1, numVisits=21, meanQ=20.380952, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.8104 0.872258 0.494384 0.929382 0.855547 0.866954 0.424793 0.472946 0.249721 0.239879 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 183
Initial state: 0 0.303982 0.657134 0.910257 0.165151 0.334872 0.367926 0.510707 0.227062 0.389744 0.472143 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95626 episodes
GETTING ACTION FROM:
action 3, numVisits=95618, meanQ=27.918880, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.303982 0.657134 0.910257 0.165151 0.334872 0.367926 0.510707 0.227062 0.389744 0.472143 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 184
Initial state: 0 0.406665 0.517812 0.22016 0.890961 0.848811 0.817425 0.320906 0.65982 0.069652 0.0489958 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49000 episodes
GETTING ACTION FROM:
action -1, numVisits=48982, meanQ=51.249301, numObservations: 243
action 0, numVisits=11, meanQ=-10.190000, numObservations: 10
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=3, meanQ=-34.333333, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.406665 0.517812 0.22016 0.890961 0.848811 0.817425 0.320906 0.65982 0.069652 0.0489958 w: 1
Observation: 0 2 0 1 0 3 0 2 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=104, meanQ=33.307888, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 4, numVisits=17, meanQ=-1.530000, numObservations: 7
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 108638 episodes
GETTING ACTION FROM:
action 1, numVisits=108742, meanQ=34.574482, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 4, numVisits=17, meanQ=-1.530000, numObservations: 7
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 1
Next state: 1 0.406665 0.517812 0.22016 0.890961 0.848811 0.817425 0.320906 0.65982 0.069652 0.0489958 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 185
Initial state: 0 0.0461611 0.0654777 0.322337 0.32101 0.452599 0.264297 0.389738 0.528543 0.0808369 0.0844025 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92421 episodes
GETTING ACTION FROM:
action 1, numVisits=92410, meanQ=28.737340, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=5, meanQ=-4.998000, numObservations: 4
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.0461611 0.0654777 0.322337 0.32101 0.452599 0.264297 0.389738 0.528543 0.0808369 0.0844025 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=6579, meanQ=62.312429, numObservations: 235
action 2, numVisits=6, meanQ=-1.000000, numObservations: 4
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 9456 episodes
GETTING ACTION FROM:
action -1, numVisits=16035, meanQ=53.108560, numObservations: 242
action 2, numVisits=6, meanQ=-1.000000, numObservations: 4
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.0461611 0.0654777 0.322337 0.32101 0.452599 0.264297 0.389738 0.528543 0.0808369 0.0844025 w: 1
Observation: 0 1 0 3 0 3 0 2 0 2 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=254, meanQ=45.545472, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 70891 episodes
GETTING ACTION FROM:
action 5, numVisits=71145, meanQ=51.824017, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.0461611 0.0654777 0.322337 0.32101 0.452599 0.264297 0.389738 0.528543 0.0808369 0.0844025 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 4, numVisits=542, meanQ=88.080833, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-16.217332, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 1, numVisits=1, meanQ=-1079.111334, numObservations: 1
Sampled 67972 episodes
GETTING ACTION FROM:
action 4, numVisits=68514, meanQ=82.044304, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-16.217332, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 1, numVisits=1, meanQ=-1079.111334, numObservations: 1
action: 4
Next state: 0 0.0461611 0.0654777 0.322337 0.32101 0.452599 0.264297 0.389738 0.528543 0.0808369 0.0844025 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: -11
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 4, numVisits=2204, meanQ=95.558077, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-16.074087, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 1, numVisits=1, meanQ=-1080.337863, numObservations: 1
Sampled 118134 episodes
GETTING ACTION FROM:
action 4, numVisits=120338, meanQ=96.564484, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-16.074087, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 1, numVisits=1, meanQ=-1080.337863, numObservations: 1
action: 4
Next state: 1 0.0461611 0.0654777 0.322337 0.32101 0.452599 0.264297 0.389738 0.528543 0.0808369 0.0844025 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 60.6646
Run # 186
Initial state: 0 0.436303 0.926348 0.406285 0.360177 0.384579 0.492109 0.576238 0.440737 0.4851 0.18775 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91412 episodes
GETTING ACTION FROM:
action 4, numVisits=91406, meanQ=27.735742, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.436303 0.926348 0.406285 0.360177 0.384579 0.492109 0.576238 0.440737 0.4851 0.18775 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 187
Initial state: 0 0.69924 0.843604 0.634429 0.312255 0.8397 0.764081 0.549246 0.85476 0.428279 0.445971 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97512 episodes
GETTING ACTION FROM:
action 1, numVisits=97503, meanQ=26.614558, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=3, meanQ=-4.333333, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.69924 0.843604 0.634429 0.312255 0.8397 0.764081 0.549246 0.85476 0.428279 0.445971 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 188
Initial state: 0 0.561032 0.979182 0.609738 0.388569 0.339248 0.522716 0.696566 0.661133 0.1853 0.375869 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97737 episodes
GETTING ACTION FROM:
action 3, numVisits=97728, meanQ=26.763125, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.561032 0.979182 0.609738 0.388569 0.339248 0.522716 0.696566 0.661133 0.1853 0.375869 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 189
Initial state: 0 0.157003 0.227928 0.228283 0.536831 0.609831 0.112489 0.480712 0.144048 0.363836 0.498318 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97817 episodes
GETTING ACTION FROM:
action 4, numVisits=97747, meanQ=27.397626, numObservations: 9
action 1, numVisits=65, meanQ=20.415546, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.157003 0.227928 0.228283 0.536831 0.609831 0.112489 0.480712 0.144048 0.363836 0.498318 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 190
Initial state: 0 0.0867252 0.730851 0.343237 0.430614 0.856013 0.335027 0.152329 0.947553 0.56852 0.343881 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88166 episodes
GETTING ACTION FROM:
action 5, numVisits=88155, meanQ=28.961460, numObservations: 9
action 3, numVisits=5, meanQ=19.000000, numObservations: 4
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.0867252 0.730851 0.343237 0.430614 0.856013 0.335027 0.152329 0.947553 0.56852 0.343881 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 191
Initial state: 0 0.367444 0.416381 0.091636 0.0670246 0.645339 0.382456 0.862887 0.130063 0.586122 0.859066 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97738 episodes
GETTING ACTION FROM:
action 2, numVisits=97727, meanQ=26.753503, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=5, meanQ=-3.000000, numObservations: 4
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.367444 0.416381 0.091636 0.0670246 0.645339 0.382456 0.862887 0.130063 0.586122 0.859066 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 192
Initial state: 0 0.0212873 0.760991 0.145955 0.753843 0.252425 0.910298 0.331083 0.497263 0.0637329 0.253969 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91043 episodes
GETTING ACTION FROM:
action 1, numVisits=91031, meanQ=28.214002, numObservations: 9
action 5, numVisits=5, meanQ=15.000000, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.0212873 0.760991 0.145955 0.753843 0.252425 0.910298 0.331083 0.497263 0.0637329 0.253969 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=6160, meanQ=61.277745, numObservations: 234
action 4, numVisits=3, meanQ=-4.003333, numObservations: 3
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 0, numVisits=10, meanQ=-11.108000, numObservations: 9
Sampled 56024 episodes
GETTING ACTION FROM:
action -1, numVisits=62184, meanQ=39.798619, numObservations: 243
action 4, numVisits=3, meanQ=-4.003333, numObservations: 3
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 0, numVisits=10, meanQ=-11.108000, numObservations: 9
action: -1
Next state: 0 0.0212873 0.760991 0.145955 0.753843 0.252425 0.910298 0.331083 0.497263 0.0637329 0.253969 w: 1
Observation: 0 1 0 1 0 1 0 1 0 1 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=48, meanQ=59.840219, numObservations: 7
action 4, numVisits=2, meanQ=44.495000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 65795 episodes
GETTING ACTION FROM:
action 1, numVisits=65843, meanQ=68.831000, numObservations: 9
action 4, numVisits=2, meanQ=44.495000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.0212873 0.760991 0.145955 0.753843 0.252425 0.910298 0.331083 0.497263 0.0637329 0.253969 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=23140, meanQ=60.400286, numObservations: 9
action 5, numVisits=5, meanQ=37.198000, numObservations: 4
action 2, numVisits=5, meanQ=35.200000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 83776 episodes
GETTING ACTION FROM:
action 1, numVisits=106916, meanQ=75.881624, numObservations: 9
action 5, numVisits=5, meanQ=37.198000, numObservations: 4
action 2, numVisits=5, meanQ=35.200000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 1
Next state: 1 0.0212873 0.760991 0.145955 0.753843 0.252425 0.910298 0.331083 0.497263 0.0637329 0.253969 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 72.2985
Run # 193
Initial state: 0 0.961168 0.0622068 0.460888 0.176998 0.403163 0.405909 0.403289 0.554462 0.313758 0.32807 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95342 episodes
GETTING ACTION FROM:
action 4, numVisits=95335, meanQ=27.607461, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.961168 0.0622068 0.460888 0.176998 0.403163 0.405909 0.403289 0.554462 0.313758 0.32807 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 194
Initial state: 0 0.48113 0.261296 0.689622 0.71968 0.760668 0.586837 0.406558 0.454099 0.570455 0.967949 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 50339 episodes
GETTING ACTION FROM:
action 0, numVisits=50311, meanQ=62.772031, numObservations: 243
action 3, numVisits=9, meanQ=-2.111111, numObservations: 5
action -1, numVisits=15, meanQ=-7.742000, numObservations: 14
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.48113 0.261296 0.689622 0.71968 0.760668 0.586837 0.406558 0.454099 0.570455 0.967949 w: 1
Observation: 0 0 1 0 3 0 3 0 2 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=343, meanQ=63.202157, numObservations: 9
action 4, numVisits=2, meanQ=44.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 100872 episodes
GETTING ACTION FROM:
action 3, numVisits=101215, meanQ=68.295903, numObservations: 9
action 4, numVisits=2, meanQ=44.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.48113 0.261296 0.689622 0.71968 0.760668 0.586837 0.406558 0.454099 0.570455 0.967949 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 195
Initial state: 0 0.812982 0.745568 0.346178 0.160652 0.430876 0.49397 0.0996515 0.638832 0.25396 0.517701 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95480 episodes
GETTING ACTION FROM:
action 3, numVisits=95429, meanQ=27.022999, numObservations: 9
action 1, numVisits=39, meanQ=13.538467, numObservations: 9
action 4, numVisits=7, meanQ=10.428571, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.812982 0.745568 0.346178 0.160652 0.430876 0.49397 0.0996515 0.638832 0.25396 0.517701 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 196
Initial state: 0 0.0332003 0.863519 0.0123024 0.398716 0.317093 0.441614 0.491898 0.389166 0.580126 0.944111 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97658 episodes
GETTING ACTION FROM:
action 4, numVisits=97626, meanQ=27.421722, numObservations: 9
action 5, numVisits=22, meanQ=15.363636, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=6, meanQ=-4.333333, numObservations: 5
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.0332003 0.863519 0.0123024 0.398716 0.317093 0.441614 0.491898 0.389166 0.580126 0.944111 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 197
Initial state: 0 0.869922 0.244103 0.0273206 0.932355 0.59496 0.839972 0.376618 0.412495 0.0390072 0.731533 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92441 episodes
GETTING ACTION FROM:
action 2, numVisits=92432, meanQ=28.625576, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.869922 0.244103 0.0273206 0.932355 0.59496 0.839972 0.376618 0.412495 0.0390072 0.731533 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 198
Initial state: 0 0.932019 0.0769978 0.305133 0.522526 0.940884 0.568811 0.791269 0.813895 0.235348 0.65177 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97031 episodes
GETTING ACTION FROM:
action 2, numVisits=96998, meanQ=27.597042, numObservations: 9
action 5, numVisits=18, meanQ=22.832239, numObservations: 8
action 3, numVisits=11, meanQ=14.272745, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.932019 0.0769978 0.305133 0.522526 0.940884 0.568811 0.791269 0.813895 0.235348 0.65177 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 199
Initial state: 0 0.396484 0.047986 0.920286 0.106645 0.810148 0.635735 0.336069 0.470861 0.462681 0.197918 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95175 episodes
GETTING ACTION FROM:
action 2, numVisits=95134, meanQ=27.567116, numObservations: 9
action -1, numVisits=13, meanQ=-1.010000, numObservations: 13
action 0, numVisits=13, meanQ=-1.010000, numObservations: 13
action 4, numVisits=12, meanQ=-2.666667, numObservations: 6
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.396484 0.047986 0.920286 0.106645 0.810148 0.635735 0.336069 0.470861 0.462681 0.197918 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=2230, meanQ=59.228891, numObservations: 226
action 0, numVisits=32, meanQ=-4.568431, numObservations: 29
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=6, meanQ=-19.168333, numObservations: 3
action 4, numVisits=4, meanQ=-28.252500, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 44967 episodes
GETTING ACTION FROM:
action -1, numVisits=47197, meanQ=7.679914, numObservations: 243
action 0, numVisits=32, meanQ=-4.568431, numObservations: 29
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=6, meanQ=-19.168333, numObservations: 3
action 4, numVisits=4, meanQ=-28.252500, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.396484 0.047986 0.920286 0.106645 0.810148 0.635735 0.336069 0.470861 0.462681 0.197918 w: 1
Observation: 0 2 0 3 0 3 0 2 0 3 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=63, meanQ=31.449927, numObservations: 9
action 3, numVisits=4, meanQ=-1.000000, numObservations: 4
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 126288 episodes
GETTING ACTION FROM:
action 1, numVisits=126351, meanQ=29.716627, numObservations: 9
action 3, numVisits=4, meanQ=-1.000000, numObservations: 4
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.396484 0.047986 0.920286 0.106645 0.810148 0.635735 0.336069 0.470861 0.462681 0.197918 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 5, numVisits=8, meanQ=74.000000, numObservations: 3
action 4, numVisits=7, meanQ=66.192806, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-15.799812, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 133274 episodes
GETTING ACTION FROM:
action 4, numVisits=133280, meanQ=73.091627, numObservations: 9
action 5, numVisits=9, meanQ=54.555556, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-15.799812, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.396484 0.047986 0.920286 0.106645 0.810148 0.635735 0.336069 0.470861 0.462681 0.197918 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 72.2985
Run # 200
Initial state: 0 0.304376 0.517532 0.749098 0.034339 0.0583949 0.600997 0.362472 0.0214664 0.956604 0.618345 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49457 episodes
GETTING ACTION FROM:
action -1, numVisits=49430, meanQ=51.855727, numObservations: 243
action 0, numVisits=22, meanQ=-1.100450, numObservations: 21
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.304376 0.517532 0.749098 0.034339 0.0583949 0.600997 0.362472 0.0214664 0.956604 0.618345 w: 1
Observation: 0 2 0 3 0 1 0 2 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=195, meanQ=53.072412, numObservations: 9
action 5, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 111479 episodes
GETTING ACTION FROM:
action 1, numVisits=111674, meanQ=57.447447, numObservations: 9
action 5, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.304376 0.517532 0.749098 0.034339 0.0583949 0.600997 0.362472 0.0214664 0.956604 0.618345 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
[32m ProblemEnvironment.hpp 351: Done.[39m
