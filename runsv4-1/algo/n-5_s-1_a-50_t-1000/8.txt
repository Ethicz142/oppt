Run # 1
Initial state: 0 0.896284 0.595428 0.921223 0.0965991 0.776737 0.203361 0.597423 0.979396 0.476004 0.429257 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31725 episodes
GETTING ACTION FROM:
action 2, numVisits=31719, meanQ=38.173352, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.896284 0.595428 0.921223 0.0965991 0.776737 0.203361 0.597423 0.979396 0.476004 0.429257 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 2
Initial state: 0 0.245744 0.365285 0.393291 0.374982 0.426377 0.267653 0.350598 0.848835 0.639578 0.261817 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32679 episodes
GETTING ACTION FROM:
action 5, numVisits=32647, meanQ=38.539874, numObservations: 9
action -1, numVisits=14, meanQ=-1.010000, numObservations: 14
action 0, numVisits=14, meanQ=-1.010000, numObservations: 14
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.245744 0.365285 0.393291 0.374982 0.426377 0.267653 0.350598 0.848835 0.639578 0.261817 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 3
Initial state: 0 0.0327997 0.931313 0.424057 0.52633 0.12631 0.013688 0.467305 0.361128 0.558297 0.0790407 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30921 episodes
GETTING ACTION FROM:
action 4, numVisits=30911, meanQ=37.843178, numObservations: 9
action 3, numVisits=4, meanQ=21.500000, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.0327997 0.931313 0.424057 0.52633 0.12631 0.013688 0.467305 0.361128 0.558297 0.0790407 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=526, meanQ=76.479383, numObservations: 9
action 3, numVisits=3, meanQ=62.663333, numObservations: 2
action 2, numVisits=2, meanQ=44.495000, numObservations: 1
action 1, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 40937 episodes
GETTING ACTION FROM:
action 4, numVisits=41463, meanQ=86.147959, numObservations: 9
action 3, numVisits=3, meanQ=62.663333, numObservations: 2
action 2, numVisits=2, meanQ=44.495000, numObservations: 1
action 1, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.0327997 0.931313 0.424057 0.52633 0.12631 0.013688 0.467305 0.361128 0.558297 0.0790407 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 4
Initial state: 0 0.419849 0.264328 0.518575 0.174415 0.338237 0.31027 0.947664 0.281474 0.4655 0.555174 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32988 episodes
GETTING ACTION FROM:
action 1, numVisits=32155, meanQ=39.337496, numObservations: 9
action 4, numVisits=803, meanQ=38.589003, numObservations: 9
action 3, numVisits=24, meanQ=34.875000, numObservations: 9
action 2, numVisits=3, meanQ=25.996667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.419849 0.264328 0.518575 0.174415 0.338237 0.31027 0.947664 0.281474 0.4655 0.555174 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 5
Initial state: 0 0.923706 0.623113 0.787227 0.0633753 0.437192 0.915953 0.0508791 0.592633 0.345488 0.340588 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31963 episodes
GETTING ACTION FROM:
action 2, numVisits=31892, meanQ=40.039679, numObservations: 9
action 3, numVisits=56, meanQ=37.803579, numObservations: 9
action 4, numVisits=11, meanQ=32.636364, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.923706 0.623113 0.787227 0.0633753 0.437192 0.915953 0.0508791 0.592633 0.345488 0.340588 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 6
Initial state: 0 0.525692 0.686352 0.469342 0.17929 0.35586 0.351482 0.954803 0.316014 0.600938 0.808811 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31094 episodes
GETTING ACTION FROM:
action 4, numVisits=31088, meanQ=39.425725, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.525692 0.686352 0.469342 0.17929 0.35586 0.351482 0.954803 0.316014 0.600938 0.808811 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 7
Initial state: 0 0.683314 0.787626 0.833136 0.0176123 0.0314905 0.305283 0.437762 0.377853 0.889688 0.0387175 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32891 episodes
GETTING ACTION FROM:
action 2, numVisits=32834, meanQ=38.357749, numObservations: 9
action 5, numVisits=31, meanQ=30.000000, numObservations: 9
action 1, numVisits=22, meanQ=27.954555, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.683314 0.787626 0.833136 0.0176123 0.0314905 0.305283 0.437762 0.377853 0.889688 0.0387175 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 8
Initial state: 0 0.630615 0.682968 0.412956 0.952042 0.140921 0.367056 0.0934394 0.929887 0.339902 0.380788 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32736 episodes
GETTING ACTION FROM:
action 2, numVisits=32721, meanQ=38.046090, numObservations: 9
action 5, numVisits=6, meanQ=29.000000, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=4, meanQ=-1.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.630615 0.682968 0.412956 0.952042 0.140921 0.367056 0.0934394 0.929887 0.339902 0.380788 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 9
Initial state: 0 0.935413 0.88358 0.571906 0.96793 0.546909 0.943848 0.361874 0.425534 0.655689 0.58092 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32940 episodes
GETTING ACTION FROM:
action 2, numVisits=28945, meanQ=38.954252, numObservations: 9
action 5, numVisits=3990, meanQ=38.376671, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.935413 0.88358 0.571906 0.96793 0.546909 0.943848 0.361874 0.425534 0.655689 0.58092 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 10
Initial state: 0 0.234559 0.201468 0.528066 0.883735 0.20497 0.865886 0.433535 0.434404 0.657756 0.370191 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31192 episodes
GETTING ACTION FROM:
action 4, numVisits=31184, meanQ=38.480621, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.234559 0.201468 0.528066 0.883735 0.20497 0.865886 0.433535 0.434404 0.657756 0.370191 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 11
Initial state: 0 0.128712 0.895902 0.428083 0.312845 0.635502 0.467009 0.939584 0.0226173 0.544569 0.607603 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32121 episodes
GETTING ACTION FROM:
action 5, numVisits=32038, meanQ=38.834911, numObservations: 9
action 3, numVisits=55, meanQ=37.311280, numObservations: 9
action 4, numVisits=23, meanQ=35.956087, numObservations: 8
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.128712 0.895902 0.428083 0.312845 0.635502 0.467009 0.939584 0.0226173 0.544569 0.607603 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 12
Initial state: 0 0.920043 0.529977 0.184179 0.634491 0.327382 0.357991 0.519835 0.139652 0.905659 0.891246 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30853 episodes
GETTING ACTION FROM:
action 1, numVisits=30844, meanQ=39.249722, numObservations: 9
action 5, numVisits=4, meanQ=21.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.920043 0.529977 0.184179 0.634491 0.327382 0.357991 0.519835 0.139652 0.905659 0.891246 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 13
Initial state: 0 0.771997 0.813201 0.43458 0.975208 0.365034 0.382828 0.918381 0.741327 0.204084 0.409692 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32657 episodes
GETTING ACTION FROM:
action 3, numVisits=32649, meanQ=38.498292, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.771997 0.813201 0.43458 0.975208 0.365034 0.382828 0.918381 0.741327 0.204084 0.409692 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 14
Initial state: 0 0.892187 0.495205 0.459788 0.718795 0.201591 0.520996 0.394574 0.741974 0.455606 0.351893 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31159 episodes
GETTING ACTION FROM:
action 2, numVisits=31138, meanQ=38.840713, numObservations: 9
action 4, numVisits=5, meanQ=15.198000, numObservations: 4
action 3, numVisits=12, meanQ=14.165000, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.892187 0.495205 0.459788 0.718795 0.201591 0.520996 0.394574 0.741974 0.455606 0.351893 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 15
Initial state: 0 0.0225744 0.991953 0.357764 0.433203 0.793615 0.237826 0.147061 0.582265 0.962134 0.964439 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32725 episodes
GETTING ACTION FROM:
action 2, numVisits=32709, meanQ=38.416094, numObservations: 9
action 4, numVisits=10, meanQ=19.000000, numObservations: 6
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.0225744 0.991953 0.357764 0.433203 0.793615 0.237826 0.147061 0.582265 0.962134 0.964439 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 16
Initial state: 0 0.998684 0.890637 0.426798 0.111192 0.470885 0.402495 0.351839 0.811149 0.342455 0.726379 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18434 episodes
GETTING ACTION FROM:
action -1, numVisits=18384, meanQ=55.978996, numObservations: 243
action 3, numVisits=15, meanQ=-4.334653, numObservations: 6
action 0, numVisits=21, meanQ=-5.818571, numObservations: 20
action 4, numVisits=11, meanQ=-6.176355, numObservations: 6
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.998684 0.890637 0.426798 0.111192 0.470885 0.402495 0.351839 0.811149 0.342455 0.726379 w: 1
Observation: 0 3 0 2 0 3 0 1 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=83, meanQ=43.267714, numObservations: 8
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 38772 episodes
GETTING ACTION FROM:
action 2, numVisits=38855, meanQ=51.655526, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.998684 0.890637 0.426798 0.111192 0.470885 0.402495 0.351839 0.811149 0.342455 0.726379 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101.99
Run # 17
Initial state: 0 0.989609 0.858968 0.0327594 0.388051 0.92434 0.360427 0.815982 0.821087 0.362589 0.422605 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32769 episodes
GETTING ACTION FROM:
action 2, numVisits=32755, meanQ=38.776279, numObservations: 9
action 4, numVisits=9, meanQ=10.111111, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.989609 0.858968 0.0327594 0.388051 0.92434 0.360427 0.815982 0.821087 0.362589 0.422605 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 18
Initial state: 0 0.364045 0.261655 0.931231 0.166737 0.316 0.450089 0.473905 0.292234 0.250215 0.0993025 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18310 episodes
GETTING ACTION FROM:
action -1, numVisits=18287, meanQ=55.532606, numObservations: 243
action 0, numVisits=10, meanQ=-1.010000, numObservations: 10
action 4, numVisits=5, meanQ=-3.000000, numObservations: 5
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=5, meanQ=-21.000000, numObservations: 2
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.364045 0.261655 0.931231 0.166737 0.316 0.450089 0.473905 0.292234 0.250215 0.0993025 w: 1
Observation: 0 2 0 3 0 2 0 2 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=44, meanQ=51.206368, numObservations: 8
action 4, numVisits=9, meanQ=42.443333, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 35687 episodes
GETTING ACTION FROM:
action 3, numVisits=35720, meanQ=40.621147, numObservations: 9
action 4, numVisits=20, meanQ=32.648500, numObservations: 8
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 3
Next state: 1 0.364045 0.261655 0.931231 0.166737 0.316 0.450089 0.473905 0.292234 0.250215 0.0993025 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 19
Initial state: 0 0.348066 0.322931 0.214349 0.190674 0.272237 0.83195 0.15619 0.15461 0.187313 0.371461 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32632 episodes
GETTING ACTION FROM:
action 1, numVisits=32596, meanQ=37.644069, numObservations: 9
action 3, numVisits=30, meanQ=33.372340, numObservations: 8
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.348066 0.322931 0.214349 0.190674 0.272237 0.83195 0.15619 0.15461 0.187313 0.371461 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 20
Initial state: 0 0.793909 0.196384 0.0855288 0.0594546 0.668497 0.159701 0.958528 0.701959 0.392881 0.368816 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31950 episodes
GETTING ACTION FROM:
action 4, numVisits=31939, meanQ=39.288846, numObservations: 9
action 5, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.793909 0.196384 0.0855288 0.0594546 0.668497 0.159701 0.958528 0.701959 0.392881 0.368816 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 21
Initial state: 0 0.103076 0.661247 0.640185 0.233815 0.399505 0.243172 0.933392 0.506849 0.455919 0.438514 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32884 episodes
GETTING ACTION FROM:
action 4, numVisits=32856, meanQ=37.688368, numObservations: 9
action 5, numVisits=23, meanQ=34.655657, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.103076 0.661247 0.640185 0.233815 0.399505 0.243172 0.933392 0.506849 0.455919 0.438514 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 22
Initial state: 0 0.0544821 0.600763 0.117581 0.575814 0.733988 0.911258 0.507581 0.354106 0.482922 0.122368 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32789 episodes
GETTING ACTION FROM:
action 1, numVisits=32781, meanQ=39.469172, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.0544821 0.600763 0.117581 0.575814 0.733988 0.911258 0.507581 0.354106 0.482922 0.122368 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=232, meanQ=16.757086, numObservations: 127
action 0, numVisits=20, meanQ=-1.852490, numObservations: 16
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 16858 episodes
GETTING ACTION FROM:
action -1, numVisits=16690, meanQ=2.023567, numObservations: 243
action 0, numVisits=420, meanQ=-3.292506, numObservations: 124
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.0544821 0.600763 0.117581 0.575814 0.733988 0.911258 0.507581 0.354106 0.482922 0.122368 w: 1
Observation: 0 1 0 1 0 3 0 2 0 2 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=12, meanQ=76.231794, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 1, numVisits=1, meanQ=-1066.308073, numObservations: 1
Sampled 7422 episodes
GETTING ACTION FROM:
action 2, numVisits=7434, meanQ=70.787835, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 1, numVisits=1, meanQ=-1066.308073, numObservations: 1
action: 2
Next state: 0 0.0544821 0.600763 0.117581 0.575814 0.733988 0.911258 0.507581 0.354106 0.482922 0.122368 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=1, meanQ=99.000000, numObservations: 1
action 4, numVisits=1998, meanQ=80.709377, numObservations: 9
action 5, numVisits=4, meanQ=49.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-17.467655, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 32293 episodes
GETTING ACTION FROM:
action 4, numVisits=34289, meanQ=64.891335, numObservations: 9
action 1, numVisits=3, meanQ=62.333333, numObservations: 2
action 5, numVisits=4, meanQ=49.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-17.467655, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.0544821 0.600763 0.117581 0.575814 0.733988 0.911258 0.507581 0.354106 0.482922 0.122368 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 72.2985
Run # 23
Initial state: 0 0.404253 0.907456 0.376372 0.438197 0.193527 0.439548 0.50537 0.707536 0.96943 0.903785 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18469 episodes
GETTING ACTION FROM:
action -1, numVisits=18438, meanQ=55.150231, numObservations: 243
action 0, numVisits=26, meanQ=-4.893846, numObservations: 25
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.404253 0.907456 0.376372 0.438197 0.193527 0.439548 0.50537 0.707536 0.96943 0.903785 w: 1
Observation: 0 2 0 2 0 1 0 2 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=24, meanQ=56.582500, numObservations: 7
action 5, numVisits=37, meanQ=30.701892, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 35816 episodes
GETTING ACTION FROM:
action 2, numVisits=35829, meanQ=20.023892, numObservations: 9
action 5, numVisits=48, meanQ=16.542921, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.404253 0.907456 0.376372 0.438197 0.193527 0.439548 0.50537 0.707536 0.96943 0.903785 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 24
Initial state: 0 0.405583 0.306948 0.337257 0.681778 0.934539 0.104071 0.486362 0.782494 0.761058 0.26963 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32084 episodes
GETTING ACTION FROM:
action 1, numVisits=32074, meanQ=37.384587, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.405583 0.306948 0.337257 0.681778 0.934539 0.104071 0.486362 0.782494 0.761058 0.26963 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 25
Initial state: 0 0.488669 0.710587 0.401009 0.443012 0.12423 0.727253 0.0432871 0.56147 0.220445 0.348667 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32245 episodes
GETTING ACTION FROM:
action 3, numVisits=32214, meanQ=39.021671, numObservations: 9
action 1, numVisits=21, meanQ=27.475257, numObservations: 8
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action 5, numVisits=3, meanQ=-4.333333, numObservations: 3
action: 3
Next state: 0 0.488669 0.710587 0.401009 0.443012 0.12423 0.727253 0.0432871 0.56147 0.220445 0.348667 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=2768, meanQ=43.970297, numObservations: 9
action 5, numVisits=10, meanQ=37.198000, numObservations: 8
action 3, numVisits=5, meanQ=31.414020, numObservations: 3
action 2, numVisits=4, meanQ=21.747500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 33932 episodes
GETTING ACTION FROM:
action 4, numVisits=36700, meanQ=41.740674, numObservations: 9
action 5, numVisits=10, meanQ=37.198000, numObservations: 8
action 3, numVisits=5, meanQ=31.414020, numObservations: 3
action 2, numVisits=4, meanQ=21.747500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 4
Next state: 0 0.488669 0.710587 0.401009 0.443012 0.12423 0.727253 0.0432871 0.56147 0.220445 0.348667 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=245, meanQ=62.292491, numObservations: 9
action 2, numVisits=2, meanQ=44.495000, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 40449 episodes
GETTING ACTION FROM:
action 5, numVisits=40694, meanQ=55.679870, numObservations: 9
action 2, numVisits=2, meanQ=44.495000, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 5
Next state: 2 0.488669 0.710587 0.401009 0.443012 0.12423 0.727253 0.0432871 0.56147 0.220445 0.348667 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -120.88
Run # 26
Initial state: 0 0.507903 0.349494 0.0898938 0.632512 0.425782 0.516197 0.0295504 0.680053 0.278286 0.296276 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31658 episodes
GETTING ACTION FROM:
action 5, numVisits=31627, meanQ=38.646126, numObservations: 9
action 2, numVisits=21, meanQ=33.760962, numObservations: 9
action 3, numVisits=4, meanQ=21.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.507903 0.349494 0.0898938 0.632512 0.425782 0.516197 0.0295504 0.680053 0.278286 0.296276 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=915, meanQ=40.206797, numObservations: 9
action 1, numVisits=3, meanQ=32.333333, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 14498 episodes
GETTING ACTION FROM:
action 2, numVisits=15412, meanQ=34.272010, numObservations: 9
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.507903 0.349494 0.0898938 0.632512 0.425782 0.516197 0.0295504 0.680053 0.278286 0.296276 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=460, meanQ=41.047762, numObservations: 9
action 4, numVisits=6, meanQ=29.330000, numObservations: 5
action 1, numVisits=3, meanQ=26.326667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 10867 episodes
GETTING ACTION FROM:
action 2, numVisits=11327, meanQ=67.054653, numObservations: 9
action 4, numVisits=6, meanQ=29.330000, numObservations: 5
action 1, numVisits=3, meanQ=26.326667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.507903 0.349494 0.0898938 0.632512 0.425782 0.516197 0.0295504 0.680053 0.278286 0.296276 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 4, numVisits=1544, meanQ=34.785108, numObservations: 9
action 1, numVisits=18, meanQ=2.271471, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 24460 episodes
GETTING ACTION FROM:
action 4, numVisits=26004, meanQ=49.599348, numObservations: 9
action 1, numVisits=18, meanQ=2.271471, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.507903 0.349494 0.0898938 0.632512 0.425782 0.516197 0.0295504 0.680053 0.278286 0.296276 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: -11
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 1, numVisits=89, meanQ=74.508975, numObservations: 8
action 3, numVisits=5, meanQ=59.000000, numObservations: 4
action 4, numVisits=2, meanQ=38.981923, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-17.250587, numObservations: 1
action 5, numVisits=1, meanQ=-1065.857719, numObservations: 1
Sampled 35881 episodes
GETTING ACTION FROM:
action 1, numVisits=35965, meanQ=69.726344, numObservations: 9
action 3, numVisits=10, meanQ=59.000000, numObservations: 4
action 4, numVisits=2, meanQ=38.981923, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-17.250587, numObservations: 1
action 5, numVisits=1, meanQ=-1065.857719, numObservations: 1
action: 1
Next state: 1 0.507903 0.349494 0.0898938 0.632512 0.425782 0.516197 0.0295504 0.680053 0.278286 0.296276 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 51.7546
Run # 27
Initial state: 0 0.134642 0.521392 0.2502 0.273747 0.465471 0.353159 0.113299 0.795769 0.919275 0.320807 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32998 episodes
GETTING ACTION FROM:
action 1, numVisits=32971, meanQ=38.660626, numObservations: 9
action 5, numVisits=6, meanQ=32.333333, numObservations: 3
action 4, numVisits=16, meanQ=27.874375, numObservations: 7
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.134642 0.521392 0.2502 0.273747 0.465471 0.353159 0.113299 0.795769 0.919275 0.320807 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=2830, meanQ=45.567763, numObservations: 9
action 3, numVisits=7, meanQ=26.284286, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 36438 episodes
GETTING ACTION FROM:
action 5, numVisits=39268, meanQ=44.841609, numObservations: 9
action 3, numVisits=7, meanQ=26.284286, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.134642 0.521392 0.2502 0.273747 0.465471 0.353159 0.113299 0.795769 0.919275 0.320807 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 28
Initial state: 0 0.039192 0.629604 0.643782 0.282669 0.555502 0.375393 0.0579163 0.26686 0.496056 0.400185 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33184 episodes
GETTING ACTION FROM:
action 5, numVisits=33169, meanQ=38.031792, numObservations: 9
action 3, numVisits=4, meanQ=21.500000, numObservations: 4
action 4, numVisits=5, meanQ=19.000000, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 5
Next state: 1 0.039192 0.629604 0.643782 0.282669 0.555502 0.375393 0.0579163 0.26686 0.496056 0.400185 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 29
Initial state: 0 0.235655 0.0122711 0.480899 0.832535 0.501257 0.427829 0.810244 0.566927 0.283418 0.940552 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32637 episodes
GETTING ACTION FROM:
action 3, numVisits=32629, meanQ=38.220101, numObservations: 9
action 4, numVisits=3, meanQ=25.996667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.235655 0.0122711 0.480899 0.832535 0.501257 0.427829 0.810244 0.566927 0.283418 0.940552 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 30
Initial state: 0 0.0193832 0.0559589 0.629136 0.791887 0.440081 0.327137 0.826945 0.0471086 0.656009 0.325127 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18078 episodes
GETTING ACTION FROM:
action -1, numVisits=18036, meanQ=56.875679, numObservations: 243
action 0, numVisits=14, meanQ=-1.152136, numObservations: 13
action 4, numVisits=16, meanQ=-2.250000, numObservations: 9
action 1, numVisits=7, meanQ=-4.141429, numObservations: 4
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=3, meanQ=-34.333333, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.0193832 0.0559589 0.629136 0.791887 0.440081 0.327137 0.826945 0.0471086 0.656009 0.325127 w: 1
Observation: 0 1 0 2 0 1 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=77, meanQ=74.635844, numObservations: 9
action 5, numVisits=10, meanQ=59.000000, numObservations: 4
action 1, numVisits=2, meanQ=44.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37772 episodes
GETTING ACTION FROM:
action 2, numVisits=37849, meanQ=83.412147, numObservations: 9
action 5, numVisits=10, meanQ=59.000000, numObservations: 4
action 1, numVisits=2, meanQ=44.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.0193832 0.0559589 0.629136 0.791887 0.440081 0.327137 0.826945 0.0471086 0.656009 0.325127 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 31
Initial state: 0 0.465147 0.429522 0.858193 0.415332 0.261131 0.786468 0.738378 0.332871 0.761607 0.0963126 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32857 episodes
GETTING ACTION FROM:
action 1, numVisits=32850, meanQ=37.318178, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.465147 0.429522 0.858193 0.415332 0.261131 0.786468 0.738378 0.332871 0.761607 0.0963126 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 32
Initial state: 0 0.791058 0.266061 0.495499 0.69359 0.425197 0.30997 0.846578 0.521364 0.865106 0.540603 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31830 episodes
GETTING ACTION FROM:
action 5, numVisits=31780, meanQ=38.250172, numObservations: 9
action 4, numVisits=44, meanQ=33.434100, numObservations: 8
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.791058 0.266061 0.495499 0.69359 0.425197 0.30997 0.846578 0.521364 0.865106 0.540603 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 33
Initial state: 0 0.263699 0.462195 0.601482 0.953527 0.450792 0.399954 0.553193 0.680688 0.160152 0.232146 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31768 episodes
GETTING ACTION FROM:
action 2, numVisits=31759, meanQ=38.756188, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 2
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.263699 0.462195 0.601482 0.953527 0.450792 0.399954 0.553193 0.680688 0.160152 0.232146 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 34
Initial state: 0 0.395839 0.726266 0.914875 0.589314 0.107123 0.550722 0.408251 0.643334 0.344979 0.384369 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18030 episodes
GETTING ACTION FROM:
action 0, numVisits=18014, meanQ=65.798939, numObservations: 243
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 3, numVisits=5, meanQ=-3.000000, numObservations: 4
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.395839 0.726266 0.914875 0.589314 0.107123 0.550722 0.408251 0.643334 0.344979 0.384369 w: 1
Observation: 0 0 3 0 3 0 3 0 3 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=310, meanQ=82.368508, numObservations: 9
action 2, numVisits=2, meanQ=44.495000, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 38179 episodes
GETTING ACTION FROM:
action 5, numVisits=38489, meanQ=91.948511, numObservations: 9
action 2, numVisits=2, meanQ=44.495000, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.395839 0.726266 0.914875 0.589314 0.107123 0.550722 0.408251 0.643334 0.344979 0.384369 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 35
Initial state: 0 0.274274 0.405388 0.891243 0.946342 0.47472 0.332708 0.616292 0.711858 0.404817 0.00485871 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32591 episodes
GETTING ACTION FROM:
action 2, numVisits=32575, meanQ=38.112415, numObservations: 9
action 3, numVisits=6, meanQ=29.165000, numObservations: 5
action 5, numVisits=6, meanQ=27.348350, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.274274 0.405388 0.891243 0.946342 0.47472 0.332708 0.616292 0.711858 0.404817 0.00485871 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 36
Initial state: 0 0.553737 0.253895 0.376792 0.539965 0.449497 0.518468 0.394395 0.306853 0.310908 0.683566 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32283 episodes
GETTING ACTION FROM:
action 1, numVisits=32258, meanQ=38.454148, numObservations: 9
action 3, numVisits=12, meanQ=28.999175, numObservations: 7
action 4, numVisits=8, meanQ=21.747500, numObservations: 6
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.553737 0.253895 0.376792 0.539965 0.449497 0.518468 0.394395 0.306853 0.310908 0.683566 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 37
Initial state: 0 0.477449 0.334153 0.568489 0.974801 0.201583 0.306307 0.654529 0.0132175 0.613753 0.729471 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33047 episodes
GETTING ACTION FROM:
action 1, numVisits=33035, meanQ=39.290458, numObservations: 9
action 2, numVisits=4, meanQ=21.500000, numObservations: 4
action 4, numVisits=4, meanQ=21.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.477449 0.334153 0.568489 0.974801 0.201583 0.306307 0.654529 0.0132175 0.613753 0.729471 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 38
Initial state: 0 0.272841 0.606247 0.294595 0.657196 0.489692 0.319973 0.244593 0.347608 0.967642 0.366384 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18391 episodes
GETTING ACTION FROM:
action -1, numVisits=18381, meanQ=55.640236, numObservations: 243
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=5, meanQ=-21.206000, numObservations: 4
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.272841 0.606247 0.294595 0.657196 0.489692 0.319973 0.244593 0.347608 0.967642 0.366384 w: 1
Observation: 0 1 0 1 0 2 0 2 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=48, meanQ=57.311675, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 36846 episodes
GETTING ACTION FROM:
action 4, numVisits=36894, meanQ=52.032555, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.272841 0.606247 0.294595 0.657196 0.489692 0.319973 0.244593 0.347608 0.967642 0.366384 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=422, meanQ=62.841256, numObservations: 9
action 2, numVisits=3, meanQ=26.326667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 35812 episodes
GETTING ACTION FROM:
action 5, numVisits=36234, meanQ=43.536536, numObservations: 9
action 2, numVisits=3, meanQ=26.326667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 5
Next state: 1 0.272841 0.606247 0.294595 0.657196 0.489692 0.319973 0.244593 0.347608 0.967642 0.366384 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 84.1399
Run # 39
Initial state: 0 0.431851 0.662846 0.0639219 0.651386 0.0197029 0.278362 0.320083 0.444683 0.557386 0.41756 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32976 episodes
GETTING ACTION FROM:
action 3, numVisits=32969, meanQ=36.827760, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.431851 0.662846 0.0639219 0.651386 0.0197029 0.278362 0.320083 0.444683 0.557386 0.41756 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=1866, meanQ=44.017594, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 10857 episodes
GETTING ACTION FROM:
action 5, numVisits=12723, meanQ=39.872902, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.431851 0.662846 0.0639219 0.651386 0.0197029 0.278362 0.320083 0.444683 0.557386 0.41756 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -110.99
Run # 40
Initial state: 0 0.423883 0.348364 0.587964 0.157644 0.871498 0.512229 0.878405 0.796216 0.630296 0.922245 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32911 episodes
GETTING ACTION FROM:
action 1, numVisits=32875, meanQ=39.080910, numObservations: 9
action 3, numVisits=28, meanQ=24.717146, numObservations: 9
action 4, numVisits=4, meanQ=21.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.423883 0.348364 0.587964 0.157644 0.871498 0.512229 0.878405 0.796216 0.630296 0.922245 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 41
Initial state: 0 0.412987 0.862038 0.327672 0.382254 0.933086 0.10046 0.736359 0.617803 0.982594 0.479208 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33010 episodes
GETTING ACTION FROM:
action 2, numVisits=32966, meanQ=38.805370, numObservations: 9
action 5, numVisits=34, meanQ=37.566479, numObservations: 7
action 4, numVisits=5, meanQ=19.000000, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.412987 0.862038 0.327672 0.382254 0.933086 0.10046 0.736359 0.617803 0.982594 0.479208 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 42
Initial state: 0 0.707115 0.338917 0.978183 0.770418 0.103225 0.128953 0.794578 0.51246 0.479735 0.385638 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33170 episodes
GETTING ACTION FROM:
action 1, numVisits=33149, meanQ=38.552148, numObservations: 9
action 3, numVisits=10, meanQ=25.602000, numObservations: 6
action 4, numVisits=4, meanQ=-1.000000, numObservations: 3
action 5, numVisits=4, meanQ=-1.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.707115 0.338917 0.978183 0.770418 0.103225 0.128953 0.794578 0.51246 0.479735 0.385638 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 43
Initial state: 0 0.324581 0.442809 0.0827514 0.888885 0.551212 0.659031 0.725175 0.0178331 0.808404 0.866574 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32125 episodes
GETTING ACTION FROM:
action 1, numVisits=32118, meanQ=38.175120, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.324581 0.442809 0.0827514 0.888885 0.551212 0.659031 0.725175 0.0178331 0.808404 0.866574 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 44
Initial state: 0 0.987662 0.447197 0.446086 0.427702 0.630565 0.5101 0.838899 0.456225 0.878426 0.223785 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33190 episodes
GETTING ACTION FROM:
action 3, numVisits=33126, meanQ=39.454612, numObservations: 9
action 4, numVisits=39, meanQ=22.640256, numObservations: 9
action 5, numVisits=20, meanQ=22.500000, numObservations: 8
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.987662 0.447197 0.446086 0.427702 0.630565 0.5101 0.838899 0.456225 0.878426 0.223785 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 45
Initial state: 0 0.355403 0.407656 0.48738 0.251145 0.776908 0.793331 0.845262 0.554143 0.341386 0.464364 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32635 episodes
GETTING ACTION FROM:
action 4, numVisits=32627, meanQ=38.358211, numObservations: 9
action 2, numVisits=3, meanQ=25.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.355403 0.407656 0.48738 0.251145 0.776908 0.793331 0.845262 0.554143 0.341386 0.464364 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 46
Initial state: 0 0.282248 0.672861 0.531556 0.833846 0.47608 0.12872 0.504412 0.375988 0.133864 0.68002 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31792 episodes
GETTING ACTION FROM:
action 3, numVisits=31786, meanQ=38.672856, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.282248 0.672861 0.531556 0.833846 0.47608 0.12872 0.504412 0.375988 0.133864 0.68002 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 47
Initial state: 0 0.912457 0.524468 0.672593 0.511019 0.113499 0.271085 0.343425 0.288299 0.547631 0.590358 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31096 episodes
GETTING ACTION FROM:
action 3, numVisits=31083, meanQ=38.980289, numObservations: 9
action 4, numVisits=8, meanQ=10.373750, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.912457 0.524468 0.672593 0.511019 0.113499 0.271085 0.343425 0.288299 0.547631 0.590358 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 48
Initial state: 0 0.952451 0.969124 0.027894 0.119323 0.893554 0.453017 0.0010087 0.999769 0.404928 0.333925 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31460 episodes
GETTING ACTION FROM:
action 1, numVisits=31450, meanQ=39.029480, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.952451 0.969124 0.027894 0.119323 0.893554 0.453017 0.0010087 0.999769 0.404928 0.333925 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 49
Initial state: 0 0.616814 0.672279 0.82722 0.717427 0.40766 0.557516 0.303201 0.00153856 0.389079 0.351612 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32015 episodes
GETTING ACTION FROM:
action 5, numVisits=32007, meanQ=37.058368, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.616814 0.672279 0.82722 0.717427 0.40766 0.557516 0.303201 0.00153856 0.389079 0.351612 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 50
Initial state: 0 0.913028 0.680185 0.0137782 0.422928 0.932219 0.512179 0.821435 0.96786 0.418853 0.424639 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33014 episodes
GETTING ACTION FROM:
action 2, numVisits=32991, meanQ=38.564578, numObservations: 9
action 5, numVisits=3, meanQ=32.333333, numObservations: 1
action 4, numVisits=15, meanQ=29.666667, numObservations: 7
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.913028 0.680185 0.0137782 0.422928 0.932219 0.512179 0.821435 0.96786 0.418853 0.424639 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=966, meanQ=34.456090, numObservations: 9
action 5, numVisits=26, meanQ=16.037312, numObservations: 8
action 4, numVisits=5, meanQ=15.396000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 14016 episodes
GETTING ACTION FROM:
action 3, numVisits=14982, meanQ=35.149183, numObservations: 9
action 5, numVisits=26, meanQ=16.037312, numObservations: 8
action 4, numVisits=5, meanQ=15.396000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.913028 0.680185 0.0137782 0.422928 0.932219 0.512179 0.821435 0.96786 0.418853 0.424639 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 51
Initial state: 0 0.560996 0.685048 0.887047 0.791425 0.463735 0.399795 0.781823 0.965595 0.845365 0.690984 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33075 episodes
GETTING ACTION FROM:
action 5, numVisits=33042, meanQ=38.142417, numObservations: 9
action 3, numVisits=10, meanQ=26.297000, numObservations: 7
action 1, numVisits=15, meanQ=22.398673, numObservations: 8
action 4, numVisits=5, meanQ=19.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.560996 0.685048 0.887047 0.791425 0.463735 0.399795 0.781823 0.965595 0.845365 0.690984 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 52
Initial state: 0 0.426628 0.302793 0.567484 0.946319 0.195018 0.860293 0.295282 0.074199 0.849607 0.821943 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32815 episodes
GETTING ACTION FROM:
action 3, numVisits=32786, meanQ=37.004354, numObservations: 9
action 1, numVisits=23, meanQ=19.869565, numObservations: 8
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.426628 0.302793 0.567484 0.946319 0.195018 0.860293 0.295282 0.074199 0.849607 0.821943 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=2861, meanQ=42.813743, numObservations: 9
action 2, numVisits=3, meanQ=26.326667, numObservations: 3
action 5, numVisits=3, meanQ=26.326667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 36854 episodes
GETTING ACTION FROM:
action 1, numVisits=39715, meanQ=51.940979, numObservations: 9
action 2, numVisits=3, meanQ=26.326667, numObservations: 3
action 5, numVisits=3, meanQ=26.326667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.426628 0.302793 0.567484 0.946319 0.195018 0.860293 0.295282 0.074199 0.849607 0.821943 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 53
Initial state: 0 0.506226 0.318118 0.184692 0.460177 0.880847 0.705801 0.820333 0.540781 0.918963 0.0381929 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32102 episodes
GETTING ACTION FROM:
action 3, numVisits=32092, meanQ=38.299586, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.506226 0.318118 0.184692 0.460177 0.880847 0.705801 0.820333 0.540781 0.918963 0.0381929 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 54
Initial state: 0 0.280948 0.203119 0.339949 0.898984 0.0193168 0.95121 0.45868 0.343173 0.605532 0.76599 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32705 episodes
GETTING ACTION FROM:
action 3, numVisits=32693, meanQ=38.690655, numObservations: 9
action 1, numVisits=5, meanQ=14.800020, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.280948 0.203119 0.339949 0.898984 0.0193168 0.95121 0.45868 0.343173 0.605532 0.76599 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=2853, meanQ=46.896051, numObservations: 9
action 1, numVisits=40, meanQ=34.179507, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 35712 episodes
GETTING ACTION FROM:
action 5, numVisits=38565, meanQ=49.892411, numObservations: 9
action 1, numVisits=40, meanQ=34.179507, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.280948 0.203119 0.339949 0.898984 0.0193168 0.95121 0.45868 0.343173 0.605532 0.76599 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 55
Initial state: 0 0.700705 0.0606266 0.0244341 0.909632 0.500369 0.302418 0.0934467 0.464647 0.0744801 0.345411 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32934 episodes
GETTING ACTION FROM:
action 4, numVisits=32906, meanQ=38.973349, numObservations: 9
action 5, numVisits=20, meanQ=35.450000, numObservations: 8
action 1, numVisits=3, meanQ=32.333333, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.700705 0.0606266 0.0244341 0.909632 0.500369 0.302418 0.0934467 0.464647 0.0744801 0.345411 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=2856, meanQ=45.235452, numObservations: 9
action 1, numVisits=15, meanQ=30.332667, numObservations: 6
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 37246 episodes
GETTING ACTION FROM:
action 5, numVisits=40102, meanQ=43.297443, numObservations: 9
action 1, numVisits=15, meanQ=30.332667, numObservations: 6
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 5
Next state: 0 0.700705 0.0606266 0.0244341 0.909632 0.500369 0.302418 0.0934467 0.464647 0.0744801 0.345411 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 0, numVisits=61, meanQ=15.542313, numObservations: 39
action -1, numVisits=6, meanQ=-1.010000, numObservations: 6
action 2, numVisits=14, meanQ=-2.287143, numObservations: 9
action 1, numVisits=37, meanQ=-2.487568, numObservations: 9
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 24506 episodes
GETTING ACTION FROM:
action 0, numVisits=24527, meanQ=-0.441318, numObservations: 242
action 2, numVisits=14, meanQ=-2.287143, numObservations: 9
action 1, numVisits=37, meanQ=-2.487568, numObservations: 9
action -1, numVisits=46, meanQ=-4.001522, numObservations: 34
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 0
Next state: 0 0.700705 0.0606266 0.0244341 0.909632 0.500369 0.302418 0.0934467 0.464647 0.0744801 0.345411 w: 1
Observation: 0 0 1 0 3 0 2 0 3 0 3 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 46876 episodes
GETTING ACTION FROM:
action 3, numVisits=46841, meanQ=93.593440, numObservations: 9
action 4, numVisits=17, meanQ=87.235294, numObservations: 5
action 5, numVisits=14, meanQ=84.714286, numObservations: 2
action -1, numVisits=1, meanQ=-2.000000, numObservations: 1
action 0, numVisits=1, meanQ=-2.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.700705 0.0606266 0.0244341 0.909632 0.500369 0.302418 0.0934467 0.464647 0.0744801 0.345411 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 72.2094
Run # 56
Initial state: 0 0.474753 0.434629 0.23619 0.648315 0.893172 0.0186038 0.684618 0.542124 0.533321 0.987657 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31785 episodes
GETTING ACTION FROM:
action 1, numVisits=31767, meanQ=37.272720, numObservations: 9
action 4, numVisits=6, meanQ=14.000000, numObservations: 4
action 5, numVisits=8, meanQ=10.250000, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.474753 0.434629 0.23619 0.648315 0.893172 0.0186038 0.684618 0.542124 0.533321 0.987657 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 57
Initial state: 0 0.167019 0.85663 0.340645 0.303291 0.250132 0.628268 0.140887 0.367781 0.592053 0.661609 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33019 episodes
GETTING ACTION FROM:
action 1, numVisits=33010, meanQ=38.229215, numObservations: 9
action 2, numVisits=4, meanQ=21.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.167019 0.85663 0.340645 0.303291 0.250132 0.628268 0.140887 0.367781 0.592053 0.661609 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=2865, meanQ=44.702739, numObservations: 9
action 3, numVisits=5, meanQ=37.198000, numObservations: 4
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 35794 episodes
GETTING ACTION FROM:
action 2, numVisits=38659, meanQ=44.699510, numObservations: 9
action 3, numVisits=5, meanQ=37.198000, numObservations: 4
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 2
Next state: 1 0.167019 0.85663 0.340645 0.303291 0.250132 0.628268 0.140887 0.367781 0.592053 0.661609 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 58
Initial state: 0 0.772057 0.724095 0.380435 0.98988 0.37118 0.309473 0.784572 0.429436 0.357825 0.466431 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32769 episodes
GETTING ACTION FROM:
action 4, numVisits=32738, meanQ=38.996711, numObservations: 9
action 1, numVisits=11, meanQ=32.635464, numObservations: 5
action 5, numVisits=9, meanQ=30.111111, numObservations: 7
action 3, numVisits=4, meanQ=21.500000, numObservations: 3
action 2, numVisits=5, meanQ=19.000000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 4
Next state: 1 0.772057 0.724095 0.380435 0.98988 0.37118 0.309473 0.784572 0.429436 0.357825 0.466431 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 59
Initial state: 0 0.353306 0.327292 0.679624 0.398517 0.592268 0.615821 0.0666035 0.0758235 0.737358 0.822364 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31844 episodes
GETTING ACTION FROM:
action 1, numVisits=31833, meanQ=39.611308, numObservations: 9
action 4, numVisits=6, meanQ=14.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.353306 0.327292 0.679624 0.398517 0.592268 0.615821 0.0666035 0.0758235 0.737358 0.822364 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 60
Initial state: 0 0.326208 0.446806 0.173172 0.168821 0.202037 0.951048 0.437117 0.330428 0.67308 0.314913 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32906 episodes
GETTING ACTION FROM:
action 4, numVisits=32819, meanQ=38.249698, numObservations: 9
action 5, numVisits=76, meanQ=25.553422, numObservations: 9
action 3, numVisits=4, meanQ=21.747500, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action: 4
Next state: 1 0.326208 0.446806 0.173172 0.168821 0.202037 0.951048 0.437117 0.330428 0.67308 0.314913 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 61
Initial state: 0 0.16049 0.87955 0.257395 0.81177 0.0399383 0.0603846 0.65366 0.879515 0.366707 0.341253 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33089 episodes
GETTING ACTION FROM:
action 2, numVisits=33050, meanQ=38.371676, numObservations: 9
action 1, numVisits=11, meanQ=32.906364, numObservations: 6
action 5, numVisits=20, meanQ=31.300505, numObservations: 7
action 4, numVisits=4, meanQ=21.500000, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.16049 0.87955 0.257395 0.81177 0.0399383 0.0603846 0.65366 0.879515 0.366707 0.341253 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 62
Initial state: 0 0.923261 0.830575 0.540088 0.909144 0.490112 0.411867 0.829033 0.36455 0.49055 0.14236 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32592 episodes
GETTING ACTION FROM:
action 2, numVisits=32580, meanQ=38.588903, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=4, meanQ=-6.000000, numObservations: 4
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.923261 0.830575 0.540088 0.909144 0.490112 0.411867 0.829033 0.36455 0.49055 0.14236 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 63
Initial state: 0 0.80595 0.920632 0.719208 0.997952 0.940848 0.749746 0.397039 0.857219 0.429168 0.436981 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32588 episodes
GETTING ACTION FROM:
action 4, numVisits=32582, meanQ=38.653041, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.80595 0.920632 0.719208 0.997952 0.940848 0.749746 0.397039 0.857219 0.429168 0.436981 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 64
Initial state: 0 0.35493 0.285895 0.635158 0.447822 0.683574 0.924148 0.704656 0.315706 0.77128 0.937091 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32877 episodes
GETTING ACTION FROM:
action 5, numVisits=32828, meanQ=38.494462, numObservations: 9
action 1, numVisits=40, meanQ=31.974502, numObservations: 8
action 2, numVisits=5, meanQ=19.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.35493 0.285895 0.635158 0.447822 0.683574 0.924148 0.704656 0.315706 0.77128 0.937091 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 65
Initial state: 0 0.458591 0.333655 0.177805 0.0449485 0.268975 0.431563 0.263383 0.490139 0.677519 0.642687 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32431 episodes
GETTING ACTION FROM:
action 4, numVisits=32421, meanQ=37.926618, numObservations: 9
action 3, numVisits=5, meanQ=19.000000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.458591 0.333655 0.177805 0.0449485 0.268975 0.431563 0.263383 0.490139 0.677519 0.642687 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 66
Initial state: 0 0.00165651 0.372198 0.542996 0.833974 0.254175 0.55706 0.399874 0.390728 0.626359 0.05034 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32872 episodes
GETTING ACTION FROM:
action 2, numVisits=32866, meanQ=38.237103, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.00165651 0.372198 0.542996 0.833974 0.254175 0.55706 0.399874 0.390728 0.626359 0.05034 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 67
Initial state: 0 0.477272 0.313893 0.171975 0.93114 0.332114 0.700531 0.195629 0.50628 0.650516 0.0738442 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18457 episodes
GETTING ACTION FROM:
action -1, numVisits=18435, meanQ=57.856168, numObservations: 243
action 3, numVisits=5, meanQ=-3.000000, numObservations: 5
action 0, numVisits=11, meanQ=-10.370900, numObservations: 9
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=3, meanQ=-34.333333, numObservations: 3
action: -1
Next state: 0 0.477272 0.313893 0.171975 0.93114 0.332114 0.700531 0.195629 0.50628 0.650516 0.0738442 w: 1
Observation: 0 2 0 1 0 2 0 1 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=28, meanQ=14.215361, numObservations: 8
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37029 episodes
GETTING ACTION FROM:
action 3, numVisits=37057, meanQ=48.254089, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.477272 0.313893 0.171975 0.93114 0.332114 0.700531 0.195629 0.50628 0.650516 0.0738442 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 68
Initial state: 0 0.547842 0.0730323 0.23992 0.6455 0.873319 0.774379 0.0158763 0.295087 0.318547 0.385504 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32699 episodes
GETTING ACTION FROM:
action 3, numVisits=32679, meanQ=37.920559, numObservations: 9
action 1, numVisits=11, meanQ=32.726364, numObservations: 7
action 2, numVisits=4, meanQ=21.500000, numObservations: 4
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.547842 0.0730323 0.23992 0.6455 0.873319 0.774379 0.0158763 0.295087 0.318547 0.385504 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 69
Initial state: 0 0.685559 0.178603 0.387243 0.976776 0.337976 0.301026 0.093869 0.0339753 0.781215 0.359369 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32835 episodes
GETTING ACTION FROM:
action 2, numVisits=32817, meanQ=39.006495, numObservations: 9
action 4, numVisits=9, meanQ=20.111111, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action 5, numVisits=3, meanQ=-4.333333, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.685559 0.178603 0.387243 0.976776 0.337976 0.301026 0.093869 0.0339753 0.781215 0.359369 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 70
Initial state: 0 0.0480695 0.00868846 0.352 0.378132 0.689612 0.40858 0.415419 0.805617 0.363008 0.592509 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32976 episodes
GETTING ACTION FROM:
action 4, numVisits=32953, meanQ=39.095856, numObservations: 9
action 3, numVisits=18, meanQ=29.610561, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.0480695 0.00868846 0.352 0.378132 0.689612 0.40858 0.415419 0.805617 0.363008 0.592509 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 71
Initial state: 0 0.409202 0.276223 0.422828 0.324342 0.45315 0.923971 0.274966 0.495663 0.727249 0.951942 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32804 episodes
GETTING ACTION FROM:
action 3, numVisits=32784, meanQ=37.130112, numObservations: 9
action 5, numVisits=13, meanQ=29.000000, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.409202 0.276223 0.422828 0.324342 0.45315 0.923971 0.274966 0.495663 0.727249 0.951942 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 72
Initial state: 0 0.1756 0.662228 0.298811 0.874971 0.880589 0.905835 0.248488 0.729616 0.381582 0.392749 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31889 episodes
GETTING ACTION FROM:
action 2, numVisits=31880, meanQ=39.095915, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.1756 0.662228 0.298811 0.874971 0.880589 0.905835 0.248488 0.729616 0.381582 0.392749 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 73
Initial state: 0 0.724597 0.952202 0.373997 0.362692 0.556453 0.784653 0.260359 0.8882 0.594827 0.202327 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33005 episodes
GETTING ACTION FROM:
action 3, numVisits=32994, meanQ=37.514586, numObservations: 9
action 2, numVisits=6, meanQ=14.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.724597 0.952202 0.373997 0.362692 0.556453 0.784653 0.260359 0.8882 0.594827 0.202327 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 74
Initial state: 0 0.0684856 0.639478 0.299217 0.280624 0.28902 0.959372 0.483356 0.324753 0.300146 0.948845 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32961 episodes
GETTING ACTION FROM:
action 2, numVisits=32940, meanQ=38.854731, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 4, numVisits=14, meanQ=-3.787136, numObservations: 7
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.0684856 0.639478 0.299217 0.280624 0.28902 0.959372 0.483356 0.324753 0.300146 0.948845 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=935, meanQ=45.327070, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 14010 episodes
GETTING ACTION FROM:
action 1, numVisits=14945, meanQ=38.023044, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.0684856 0.639478 0.299217 0.280624 0.28902 0.959372 0.483356 0.324753 0.300146 0.948845 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 75
Initial state: 0 0.639304 0.903031 0.805751 0.952168 0.833898 0.597491 0.503909 0.40181 0.776315 0.856443 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32484 episodes
GETTING ACTION FROM:
action 1, numVisits=32285, meanQ=39.574805, numObservations: 9
action 4, numVisits=187, meanQ=38.600433, numObservations: 9
action 2, numVisits=3, meanQ=32.333333, numObservations: 1
action 3, numVisits=6, meanQ=29.165000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.639304 0.903031 0.805751 0.952168 0.833898 0.597491 0.503909 0.40181 0.776315 0.856443 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 76
Initial state: 0 0.849905 0.418861 0.127063 0.465245 0.423142 0.287974 0.116281 0.632223 0.376981 0.852234 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31635 episodes
GETTING ACTION FROM:
action 5, numVisits=31626, meanQ=38.833810, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.849905 0.418861 0.127063 0.465245 0.423142 0.287974 0.116281 0.632223 0.376981 0.852234 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 77
Initial state: 0 0.15618 0.145156 0.695144 0.827122 0.737966 0.413825 0.964279 0.409676 0.398395 0.38061 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32496 episodes
GETTING ACTION FROM:
action 4, numVisits=32484, meanQ=38.033126, numObservations: 9
action 5, numVisits=7, meanQ=26.142857, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.15618 0.145156 0.695144 0.827122 0.737966 0.413825 0.964279 0.409676 0.398395 0.38061 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 78
Initial state: 0 0.963702 0.067237 0.795933 0.481869 0.105016 0.989867 0.421391 0.411985 0.963847 0.300925 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32595 episodes
GETTING ACTION FROM:
action 1, numVisits=32577, meanQ=37.846505, numObservations: 9
action 5, numVisits=7, meanQ=22.141429, numObservations: 6
action 3, numVisits=7, meanQ=10.711429, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.963702 0.067237 0.795933 0.481869 0.105016 0.989867 0.421391 0.411985 0.963847 0.300925 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 79
Initial state: 0 0.782683 0.69401 0.297353 0.953782 0.999607 0.347297 0.391361 0.0444514 0.402924 0.440146 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30408 episodes
GETTING ACTION FROM:
action 3, numVisits=30401, meanQ=38.135779, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.782683 0.69401 0.297353 0.953782 0.999607 0.347297 0.391361 0.0444514 0.402924 0.440146 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 80
Initial state: 0 0.880615 0.670807 0.405219 0.427772 0.66282 0.76551 0.687442 0.0141867 0.947576 0.760448 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32580 episodes
GETTING ACTION FROM:
action 4, numVisits=32571, meanQ=38.114005, numObservations: 9
action 2, numVisits=4, meanQ=21.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.880615 0.670807 0.405219 0.427772 0.66282 0.76551 0.687442 0.0141867 0.947576 0.760448 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 81
Initial state: 0 0.368087 0.219289 0.4883 0.0398857 0.734112 0.0913141 0.457837 0.328589 0.770192 0.404041 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31715 episodes
GETTING ACTION FROM:
action 2, numVisits=31702, meanQ=38.644563, numObservations: 9
action 3, numVisits=7, meanQ=26.142857, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.368087 0.219289 0.4883 0.0398857 0.734112 0.0913141 0.457837 0.328589 0.770192 0.404041 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=191, meanQ=15.232479, numObservations: 112
action -1, numVisits=9, meanQ=-1.010000, numObservations: 9
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 14533 episodes
GETTING ACTION FROM:
action 0, numVisits=14710, meanQ=3.782907, numObservations: 241
action -1, numVisits=23, meanQ=-1.526522, numObservations: 20
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.368087 0.219289 0.4883 0.0398857 0.734112 0.0913141 0.457837 0.328589 0.770192 0.404041 w: 1
Observation: 0 0 1 0 1 0 1 0 2 0 2 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 36045 episodes
GETTING ACTION FROM:
action 5, numVisits=34717, meanQ=71.754559, numObservations: 9
action 2, numVisits=3, meanQ=32.333333, numObservations: 1
action 4, numVisits=1317, meanQ=24.038971, numObservations: 9
action 1, numVisits=4, meanQ=-1.000000, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-2.000000, numObservations: 1
action 0, numVisits=1, meanQ=-2.000000, numObservations: 1
action: 5
Next state: 2 0.368087 0.219289 0.4883 0.0398857 0.734112 0.0913141 0.457837 0.328589 0.770192 0.404041 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -111.97
Run # 82
Initial state: 0 0.608801 0.0973135 0.607519 0.333197 0.731638 0.166785 0.354416 0.310686 0.338288 0.856113 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32688 episodes
GETTING ACTION FROM:
action 4, numVisits=32681, meanQ=39.234387, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.608801 0.0973135 0.607519 0.333197 0.731638 0.166785 0.354416 0.310686 0.338288 0.856113 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 83
Initial state: 0 0.32594 0.780748 0.57698 0.395633 0.348669 0.570836 0.895855 0.909759 0.360518 0.365627 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32803 episodes
GETTING ACTION FROM:
action 1, numVisits=32797, meanQ=38.338420, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.32594 0.780748 0.57698 0.395633 0.348669 0.570836 0.895855 0.909759 0.360518 0.365627 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 84
Initial state: 0 0.960123 0.976825 0.505589 0.382098 0.0366781 0.227316 0.327228 0.0591336 0.596587 0.548202 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32969 episodes
GETTING ACTION FROM:
action 1, numVisits=32963, meanQ=38.738313, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.960123 0.976825 0.505589 0.382098 0.0366781 0.227316 0.327228 0.0591336 0.596587 0.548202 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 85
Initial state: 0 0.132431 0.675486 0.46913 0.319327 0.0343303 0.68855 0.363005 0.0848109 0.272151 0.595179 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31013 episodes
GETTING ACTION FROM:
action 4, numVisits=31002, meanQ=38.834409, numObservations: 9
action 1, numVisits=5, meanQ=19.000000, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.132431 0.675486 0.46913 0.319327 0.0343303 0.68855 0.363005 0.0848109 0.272151 0.595179 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 86
Initial state: 0 0.76253 0.222987 0.649344 0.342938 0.30495 0.494178 0.444716 0.362024 0.689799 0.962932 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30883 episodes
GETTING ACTION FROM:
action 1, numVisits=30874, meanQ=38.369652, numObservations: 9
action 5, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.76253 0.222987 0.649344 0.342938 0.30495 0.494178 0.444716 0.362024 0.689799 0.962932 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=430, meanQ=43.167743, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 33635 episodes
GETTING ACTION FROM:
action 5, numVisits=34065, meanQ=24.585433, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.76253 0.222987 0.649344 0.342938 0.30495 0.494178 0.444716 0.362024 0.689799 0.962932 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 87
Initial state: 0 0.956523 0.80081 0.849861 0.53976 0.612629 0.0287887 0.397523 0.32411 0.813934 0.737442 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17820 episodes
GETTING ACTION FROM:
action 0, numVisits=17791, meanQ=65.577528, numObservations: 243
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 2, numVisits=5, meanQ=-3.000000, numObservations: 5
action 5, numVisits=12, meanQ=-3.499167, numObservations: 7
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=3, meanQ=-34.333333, numObservations: 3
action: 0
Next state: 0 0.956523 0.80081 0.849861 0.53976 0.612629 0.0287887 0.397523 0.32411 0.813934 0.737442 w: 1
Observation: 0 0 3 0 3 0 1 0 3 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=87, meanQ=72.195862, numObservations: 9
action 4, numVisits=3, meanQ=62.663333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 35160 episodes
GETTING ACTION FROM:
action 5, numVisits=35247, meanQ=66.945862, numObservations: 9
action 4, numVisits=3, meanQ=62.663333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.956523 0.80081 0.849861 0.53976 0.612629 0.0287887 0.397523 0.32411 0.813934 0.737442 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 88
Initial state: 0 0.944887 0.697522 0.116725 0.243016 0.32951 0.295275 0.0365374 0.186105 0.38568 0.68523 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31446 episodes
GETTING ACTION FROM:
action 5, numVisits=31438, meanQ=39.607561, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.944887 0.697522 0.116725 0.243016 0.32951 0.295275 0.0365374 0.186105 0.38568 0.68523 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 89
Initial state: 0 0.944867 0.108856 0.239889 0.277639 0.892911 0.321895 0.36255 0.400156 0.106167 0.65394 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32906 episodes
GETTING ACTION FROM:
action 5, numVisits=32898, meanQ=39.092967, numObservations: 9
action 3, numVisits=3, meanQ=32.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.944867 0.108856 0.239889 0.277639 0.892911 0.321895 0.36255 0.400156 0.106167 0.65394 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=2892, meanQ=42.844125, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 36357 episodes
GETTING ACTION FROM:
action 2, numVisits=39249, meanQ=48.701074, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 2
Next state: 0 0.944867 0.108856 0.239889 0.277639 0.892911 0.321895 0.36255 0.400156 0.106167 0.65394 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=1196, meanQ=61.614991, numObservations: 9
action 5, numVisits=3, meanQ=26.326667, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 10639 episodes
GETTING ACTION FROM:
action 4, numVisits=11835, meanQ=60.751705, numObservations: 9
action 5, numVisits=3, meanQ=26.326667, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 4
Next state: 1 0.944867 0.108856 0.239889 0.277639 0.892911 0.321895 0.36255 0.400156 0.106167 0.65394 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 75.1399
Run # 90
Initial state: 0 0.407981 0.677725 0.686482 0.0368213 0.829402 0.611609 0.532358 0.529872 0.395622 0.335404 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33088 episodes
GETTING ACTION FROM:
action 1, numVisits=33064, meanQ=39.035828, numObservations: 9
action 5, numVisits=10, meanQ=17.000000, numObservations: 6
action 3, numVisits=9, meanQ=7.888889, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.407981 0.677725 0.686482 0.0368213 0.829402 0.611609 0.532358 0.529872 0.395622 0.335404 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 91
Initial state: 0 0.308714 0.257466 0.910204 0.198738 0.171753 0.572831 0.0627928 0.664225 0.479534 0.435124 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32933 episodes
GETTING ACTION FROM:
action 1, numVisits=32925, meanQ=38.822483, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.308714 0.257466 0.910204 0.198738 0.171753 0.572831 0.0627928 0.664225 0.479534 0.435124 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1833, meanQ=44.208187, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 10503 episodes
GETTING ACTION FROM:
action 2, numVisits=12336, meanQ=38.820897, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.308714 0.257466 0.910204 0.198738 0.171753 0.572831 0.0627928 0.664225 0.479534 0.435124 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -110.99
Run # 92
Initial state: 0 0.372626 0.495056 0.225785 0.0353313 0.612643 0.438021 0.943925 0.651712 0.323379 0.441884 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32503 episodes
GETTING ACTION FROM:
action 1, numVisits=32493, meanQ=37.006267, numObservations: 9
action 5, numVisits=4, meanQ=21.500000, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.372626 0.495056 0.225785 0.0353313 0.612643 0.438021 0.943925 0.651712 0.323379 0.441884 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 93
Initial state: 0 0.495155 0.139211 0.389434 0.435307 0.164102 0.847616 0.180064 0.484423 0.660644 0.144073 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31695 episodes
GETTING ACTION FROM:
action 1, numVisits=31688, meanQ=37.782832, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.495155 0.139211 0.389434 0.435307 0.164102 0.847616 0.180064 0.484423 0.660644 0.144073 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 94
Initial state: 0 0.721377 0.342669 0.394695 0.34649 0.298349 0.775582 0.0609635 0.488874 0.106608 0.981354 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32353 episodes
GETTING ACTION FROM:
action 1, numVisits=32347, meanQ=36.410665, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.721377 0.342669 0.394695 0.34649 0.298349 0.775582 0.0609635 0.488874 0.106608 0.981354 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 95
Initial state: 0 0.146121 0.182617 0.721731 0.0241204 0.393158 0.774802 0.60779 0.816418 0.381684 0.38365 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32896 episodes
GETTING ACTION FROM:
action 2, numVisits=32823, meanQ=39.233110, numObservations: 9
action 1, numVisits=52, meanQ=36.942696, numObservations: 9
action 3, numVisits=6, meanQ=29.165000, numObservations: 5
action 4, numVisits=12, meanQ=29.081675, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.146121 0.182617 0.721731 0.0241204 0.393158 0.774802 0.60779 0.816418 0.381684 0.38365 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 96
Initial state: 0 0.925823 0.0318224 0.358307 0.85891 0.477534 0.00564339 0.714455 0.723491 0.336279 0.367994 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32864 episodes
GETTING ACTION FROM:
action 2, numVisits=32818, meanQ=37.719755, numObservations: 9
action 4, numVisits=40, meanQ=26.301010, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.925823 0.0318224 0.358307 0.85891 0.477534 0.00564339 0.714455 0.723491 0.336279 0.367994 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 97
Initial state: 0 0.880509 0.698192 0.442874 0.745895 0.961199 0.0156523 0.452275 0.312013 0.960536 0.11046 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32662 episodes
GETTING ACTION FROM:
action 5, numVisits=32606, meanQ=38.260924, numObservations: 9
action 2, numVisits=25, meanQ=36.203608, numObservations: 8
action 3, numVisits=27, meanQ=33.073704, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.880509 0.698192 0.442874 0.745895 0.961199 0.0156523 0.452275 0.312013 0.960536 0.11046 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 98
Initial state: 0 0.289603 0.571085 0.402958 0.6453 0.52241 0.675245 0.432093 0.391294 0.312283 0.234165 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32786 episodes
GETTING ACTION FROM:
action 1, numVisits=32763, meanQ=37.188669, numObservations: 9
action 4, numVisits=16, meanQ=30.631262, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.289603 0.571085 0.402958 0.6453 0.52241 0.675245 0.432093 0.391294 0.312283 0.234165 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=2852, meanQ=44.144170, numObservations: 9
action 3, numVisits=3, meanQ=32.333333, numObservations: 3
action 4, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 35165 episodes
GETTING ACTION FROM:
action 5, numVisits=38017, meanQ=44.485878, numObservations: 9
action 3, numVisits=3, meanQ=32.333333, numObservations: 3
action 4, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 5
Next state: 0 0.289603 0.571085 0.402958 0.6453 0.52241 0.675245 0.432093 0.391294 0.312283 0.234165 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=1760, meanQ=46.551905, numObservations: 9
action 2, numVisits=64, meanQ=27.999845, numObservations: 9
action 4, numVisits=14, meanQ=26.284286, numObservations: 7
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 30405 episodes
GETTING ACTION FROM:
action 5, numVisits=32165, meanQ=67.327785, numObservations: 9
action 2, numVisits=64, meanQ=27.999845, numObservations: 9
action 4, numVisits=14, meanQ=26.284286, numObservations: 7
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 5
Next state: 0 0.289603 0.571085 0.402958 0.6453 0.52241 0.675245 0.432093 0.391294 0.312283 0.234165 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=675, meanQ=41.149128, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 12198 episodes
GETTING ACTION FROM:
action 2, numVisits=12873, meanQ=48.226676, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.289603 0.571085 0.402958 0.6453 0.52241 0.675245 0.432093 0.391294 0.312283 0.234165 w: 1
Observation: 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 63.3885
Run # 99
Initial state: 0 0.935686 0.0806095 0.973243 0.15585 0.17778 0.357648 0.399886 0.343887 0.596334 0.771983 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32975 episodes
GETTING ACTION FROM:
action 2, numVisits=32683, meanQ=38.711996, numObservations: 9
action 3, numVisits=281, meanQ=37.649417, numObservations: 9
action 1, numVisits=3, meanQ=32.333333, numObservations: 2
action 4, numVisits=3, meanQ=32.333333, numObservations: 3
action 5, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 2 0.935686 0.0806095 0.973243 0.15585 0.17778 0.357648 0.399886 0.343887 0.596334 0.771983 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 100
Initial state: 0 0.943218 0.81981 0.978288 0.953462 0.368169 0.557408 0.39377 0.344276 0.178279 0.866193 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32884 episodes
GETTING ACTION FROM:
action 4, numVisits=32862, meanQ=38.895748, numObservations: 9
action 2, numVisits=6, meanQ=28.833350, numObservations: 4
action 5, numVisits=4, meanQ=21.500000, numObservations: 3
action 1, numVisits=8, meanQ=18.626250, numObservations: 6
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 4
Next state: 0 0.943218 0.81981 0.978288 0.953462 0.368169 0.557408 0.39377 0.344276 0.178279 0.866193 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=195, meanQ=48.131491, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 27377 episodes
GETTING ACTION FROM:
action 3, numVisits=27572, meanQ=47.048448, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.943218 0.81981 0.978288 0.953462 0.368169 0.557408 0.39377 0.344276 0.178279 0.866193 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 101
Initial state: 0 0.371543 0.400572 0.237148 0.333261 0.116165 0.871186 0.890432 0.519046 0.0351343 0.630605 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32872 episodes
GETTING ACTION FROM:
action 4, numVisits=32855, meanQ=38.063406, numObservations: 9
action 3, numVisits=6, meanQ=28.833350, numObservations: 3
action 5, numVisits=7, meanQ=26.284286, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.371543 0.400572 0.237148 0.333261 0.116165 0.871186 0.890432 0.519046 0.0351343 0.630605 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 102
Initial state: 0 0.441707 0.425786 0.703867 0.167581 0.926523 0.568925 0.833992 0.603413 0.0243827 0.345466 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30728 episodes
GETTING ACTION FROM:
action 2, numVisits=30655, meanQ=38.819480, numObservations: 9
action 4, numVisits=67, meanQ=32.869258, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.441707 0.425786 0.703867 0.167581 0.926523 0.568925 0.833992 0.603413 0.0243827 0.345466 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 103
Initial state: 0 0.0522799 0.731653 0.943166 0.568769 0.307973 0.369983 0.0821906 0.173023 0.373683 0.311293 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32517 episodes
GETTING ACTION FROM:
action 3, numVisits=32500, meanQ=38.295079, numObservations: 9
action 5, numVisits=6, meanQ=29.000000, numObservations: 3
action 4, numVisits=7, meanQ=26.142857, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.0522799 0.731653 0.943166 0.568769 0.307973 0.369983 0.0821906 0.173023 0.373683 0.311293 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 104
Initial state: 0 0.146607 0.556456 0.496858 0.404663 0.840035 0.765119 0.701783 0.658077 0.274246 0.205511 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32143 episodes
GETTING ACTION FROM:
action 3, numVisits=32130, meanQ=37.614187, numObservations: 9
action 2, numVisits=7, meanQ=9.001429, numObservations: 6
action 4, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.146607 0.556456 0.496858 0.404663 0.840035 0.765119 0.701783 0.658077 0.274246 0.205511 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 105
Initial state: 0 0.0197392 0.595082 0.0304746 0.62514 0.428008 0.769585 0.119262 0.931232 0.480099 0.401815 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31664 episodes
GETTING ACTION FROM:
action 5, numVisits=31655, meanQ=38.033521, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.0197392 0.595082 0.0304746 0.62514 0.428008 0.769585 0.119262 0.931232 0.480099 0.401815 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 106
Initial state: 0 0.568644 0.936099 0.664634 0.573701 0.472348 0.372653 0.684386 0.0530834 0.495779 0.618416 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18176 episodes
GETTING ACTION FROM:
action -1, numVisits=18135, meanQ=57.022807, numObservations: 243
action 0, numVisits=33, meanQ=-4.851200, numObservations: 28
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=4, meanQ=-28.500000, numObservations: 4
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.568644 0.936099 0.664634 0.573701 0.472348 0.372653 0.684386 0.0530834 0.495779 0.618416 w: 1
Observation: 0 3 0 3 0 1 0 1 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=77, meanQ=43.721348, numObservations: 9
action 1, numVisits=3, meanQ=32.333333, numObservations: 2
action 4, numVisits=3, meanQ=25.663367, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 25388 episodes
GETTING ACTION FROM:
action 3, numVisits=25465, meanQ=58.467292, numObservations: 9
action 1, numVisits=3, meanQ=32.333333, numObservations: 2
action 4, numVisits=3, meanQ=25.663367, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.568644 0.936099 0.664634 0.573701 0.472348 0.372653 0.684386 0.0530834 0.495779 0.618416 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 107
Initial state: 0 0.211139 0.266522 0.847733 0.716408 0.0510891 0.32831 0.517354 0.532654 0.315288 0.369965 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32517 episodes
GETTING ACTION FROM:
action 2, numVisits=32509, meanQ=38.999936, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.211139 0.266522 0.847733 0.716408 0.0510891 0.32831 0.517354 0.532654 0.315288 0.369965 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 108
Initial state: 0 0.654299 0.0683785 0.330003 0.440722 0.101584 0.0337323 0.499592 0.893067 0.474667 0.795747 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32904 episodes
GETTING ACTION FROM:
action 4, numVisits=32857, meanQ=38.416577, numObservations: 9
action 3, numVisits=35, meanQ=24.345720, numObservations: 9
action 1, numVisits=6, meanQ=14.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 2
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.654299 0.0683785 0.330003 0.440722 0.101584 0.0337323 0.499592 0.893067 0.474667 0.795747 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 109
Initial state: 0 0.373381 0.444699 0.229549 0.942139 0.652257 0.427744 0.617639 0.941646 0.754077 0.703742 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31232 episodes
GETTING ACTION FROM:
action 4, numVisits=31163, meanQ=39.585949, numObservations: 9
action 2, numVisits=8, meanQ=35.250000, numObservations: 7
action 1, numVisits=55, meanQ=34.894373, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=3, meanQ=-4.333333, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.373381 0.444699 0.229549 0.942139 0.652257 0.427744 0.617639 0.941646 0.754077 0.703742 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 110
Initial state: 0 0.913568 0.329026 0.690863 0.377564 0.44603 0.331533 0.143504 0.426459 0.460846 0.137834 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31611 episodes
GETTING ACTION FROM:
action 5, numVisits=31595, meanQ=40.091236, numObservations: 9
action 2, numVisits=6, meanQ=32.333333, numObservations: 5
action 3, numVisits=6, meanQ=32.333333, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.913568 0.329026 0.690863 0.377564 0.44603 0.331533 0.143504 0.426459 0.460846 0.137834 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=460, meanQ=45.096088, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 16452 episodes
GETTING ACTION FROM:
action 1, numVisits=16912, meanQ=33.656523, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.913568 0.329026 0.690863 0.377564 0.44603 0.331533 0.143504 0.426459 0.460846 0.137834 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -110.99
Run # 111
Initial state: 0 0.0186121 0.588091 0.0629581 0.921327 0.104499 0.525133 0.381203 0.340927 0.225227 0.374339 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31453 episodes
GETTING ACTION FROM:
action 5, numVisits=31437, meanQ=38.218043, numObservations: 9
action 2, numVisits=4, meanQ=21.500000, numObservations: 3
action 3, numVisits=4, meanQ=21.500000, numObservations: 4
action 1, numVisits=5, meanQ=19.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.0186121 0.588091 0.0629581 0.921327 0.104499 0.525133 0.381203 0.340927 0.225227 0.374339 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=954, meanQ=44.813329, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 16395 episodes
GETTING ACTION FROM:
action 1, numVisits=17349, meanQ=46.459523, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.0186121 0.588091 0.0629581 0.921327 0.104499 0.525133 0.381203 0.340927 0.225227 0.374339 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=413, meanQ=57.526257, numObservations: 9
action 2, numVisits=70, meanQ=48.763049, numObservations: 9
action 4, numVisits=32, meanQ=44.718125, numObservations: 9
action 5, numVisits=2, meanQ=44.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 11658 episodes
GETTING ACTION FROM:
action 1, numVisits=12071, meanQ=68.290046, numObservations: 9
action 2, numVisits=70, meanQ=48.763049, numObservations: 9
action 4, numVisits=32, meanQ=44.718125, numObservations: 9
action 5, numVisits=2, meanQ=44.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 1
Next state: 1 0.0186121 0.588091 0.0629581 0.921327 0.104499 0.525133 0.381203 0.340927 0.225227 0.374339 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 75.1399
Run # 112
Initial state: 0 0.679522 0.616658 0.928197 0.835811 0.881046 0.404933 0.503164 0.785119 0.413329 0.348532 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33032 episodes
GETTING ACTION FROM:
action 5, numVisits=32994, meanQ=36.984411, numObservations: 9
action 2, numVisits=29, meanQ=34.380345, numObservations: 9
action 3, numVisits=4, meanQ=21.500000, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.679522 0.616658 0.928197 0.835811 0.881046 0.404933 0.503164 0.785119 0.413329 0.348532 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 113
Initial state: 0 0.634099 0.62272 0.455842 0.390083 0.312564 0.733441 0.258845 0.75216 0.590166 0.606428 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30934 episodes
GETTING ACTION FROM:
action 5, numVisits=30928, meanQ=38.379619, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.634099 0.62272 0.455842 0.390083 0.312564 0.733441 0.258845 0.75216 0.590166 0.606428 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 114
Initial state: 0 0.621718 0.104263 0.448476 0.283282 0.999131 0.664909 0.696502 0.410741 0.735543 0.541731 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32419 episodes
GETTING ACTION FROM:
action 3, numVisits=32406, meanQ=38.206860, numObservations: 9
action 5, numVisits=7, meanQ=26.142857, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.621718 0.104263 0.448476 0.283282 0.999131 0.664909 0.696502 0.410741 0.735543 0.541731 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 115
Initial state: 0 0.460745 0.38964 0.353656 0.186285 0.489889 0.206045 0.638697 0.19827 0.0892827 0.566198 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18219 episodes
GETTING ACTION FROM:
action 0, numVisits=18183, meanQ=67.707126, numObservations: 243
action -1, numVisits=23, meanQ=-1.182174, numObservations: 21
action 3, numVisits=5, meanQ=-3.000000, numObservations: 4
action 5, numVisits=5, meanQ=-3.000000, numObservations: 5
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.460745 0.38964 0.353656 0.186285 0.489889 0.206045 0.638697 0.19827 0.0892827 0.566198 w: 1
Observation: 0 0 2 0 1 0 1 0 1 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=38, meanQ=72.210000, numObservations: 6
action 3, numVisits=3, meanQ=62.663333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37732 episodes
GETTING ACTION FROM:
action 1, numVisits=37770, meanQ=82.184116, numObservations: 9
action 3, numVisits=3, meanQ=62.663333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.460745 0.38964 0.353656 0.186285 0.489889 0.206045 0.638697 0.19827 0.0892827 0.566198 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 116
Initial state: 0 0.506264 0.162767 0.36299 0.323857 0.884178 0.081278 0.146488 0.548545 0.181958 0.0575024 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31912 episodes
GETTING ACTION FROM:
action 3, numVisits=31904, meanQ=37.969846, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.506264 0.162767 0.36299 0.323857 0.884178 0.081278 0.146488 0.548545 0.181958 0.0575024 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 117
Initial state: 0 0.528295 0.456388 0.806103 0.467702 0.664431 0.990682 0.326513 0.363862 0.398268 0.0954246 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33011 episodes
GETTING ACTION FROM:
action 4, numVisits=33002, meanQ=38.295498, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.528295 0.456388 0.806103 0.467702 0.664431 0.990682 0.326513 0.363862 0.398268 0.0954246 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=504, meanQ=83.688354, numObservations: 9
action 2, numVisits=27, meanQ=39.670004, numObservations: 7
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 40983 episodes
GETTING ACTION FROM:
action 4, numVisits=41487, meanQ=86.996556, numObservations: 9
action 2, numVisits=27, meanQ=39.670004, numObservations: 7
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.528295 0.456388 0.806103 0.467702 0.664431 0.990682 0.326513 0.363862 0.398268 0.0954246 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 118
Initial state: 0 0.0377675 0.250357 0.566565 0.0168135 0.821265 0.402728 0.465085 0.385327 0.328669 0.208663 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30817 episodes
GETTING ACTION FROM:
action 3, numVisits=30810, meanQ=39.519151, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.0377675 0.250357 0.566565 0.0168135 0.821265 0.402728 0.465085 0.385327 0.328669 0.208663 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 119
Initial state: 0 0.102289 0.501112 0.614978 0.494389 0.457932 0.304429 0.95439 0.843195 0.0322955 0.204233 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31959 episodes
GETTING ACTION FROM:
action 1, numVisits=31946, meanQ=38.874089, numObservations: 9
action 3, numVisits=4, meanQ=21.500000, numObservations: 4
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action: 1
Next state: 0 0.102289 0.501112 0.614978 0.494389 0.457932 0.304429 0.95439 0.843195 0.0322955 0.204233 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=2669, meanQ=49.861989, numObservations: 9
action 4, numVisits=3, meanQ=32.333333, numObservations: 3
action 5, numVisits=3, meanQ=32.333333, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 33930 episodes
GETTING ACTION FROM:
action 3, numVisits=36599, meanQ=44.335744, numObservations: 9
action 4, numVisits=3, meanQ=32.333333, numObservations: 3
action 5, numVisits=3, meanQ=32.333333, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 3
Next state: 1 0.102289 0.501112 0.614978 0.494389 0.457932 0.304429 0.95439 0.843195 0.0322955 0.204233 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 120
Initial state: 0 0.367567 0.386191 0.0382714 0.105503 0.175174 0.102156 0.018465 0.691519 0.433996 0.172366 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32979 episodes
GETTING ACTION FROM:
action 3, numVisits=32969, meanQ=37.798943, numObservations: 9
action 4, numVisits=5, meanQ=19.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.367567 0.386191 0.0382714 0.105503 0.175174 0.102156 0.018465 0.691519 0.433996 0.172366 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=1984, meanQ=40.802323, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=3, meanQ=-4.003333, numObservations: 2
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 11792 episodes
GETTING ACTION FROM:
action 4, numVisits=13776, meanQ=35.914696, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=3, meanQ=-4.003333, numObservations: 2
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 4
Next state: 0 0.367567 0.386191 0.0382714 0.105503 0.175174 0.102156 0.018465 0.691519 0.433996 0.172366 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=651, meanQ=57.600073, numObservations: 8
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 6134 episodes
GETTING ACTION FROM:
action 4, numVisits=6785, meanQ=58.198315, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 4
Next state: 0 0.367567 0.386191 0.0382714 0.105503 0.175174 0.102156 0.018465 0.691519 0.433996 0.172366 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=1816, meanQ=55.146649, numObservations: 9
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action -1, numVisits=3, meanQ=-1.673300, numObservations: 2
action 1, numVisits=10, meanQ=-2.802000, numObservations: 4
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 18055 episodes
GETTING ACTION FROM:
action 2, numVisits=19871, meanQ=59.749309, numObservations: 9
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action -1, numVisits=3, meanQ=-1.673300, numObservations: 2
action 1, numVisits=10, meanQ=-2.802000, numObservations: 4
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.367567 0.386191 0.0382714 0.105503 0.175174 0.102156 0.018465 0.691519 0.433996 0.172366 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 5, numVisits=118, meanQ=67.248329, numObservations: 9
action 2, numVisits=2, meanQ=41.251057, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-14.615738, numObservations: 1
action 3, numVisits=1, meanQ=-1076.497678, numObservations: 1
Sampled 24449 episodes
GETTING ACTION FROM:
action 5, numVisits=24567, meanQ=62.234431, numObservations: 9
action 2, numVisits=2, meanQ=41.251057, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-14.615738, numObservations: 1
action 3, numVisits=1, meanQ=-1076.497678, numObservations: 1
action: 5
Next state: 2 0.367567 0.386191 0.0382714 0.105503 0.175174 0.102156 0.018465 0.691519 0.433996 0.172366 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -140.365
Run # 121
Initial state: 0 0.525901 0.87886 0.0539775 0.49593 0.916861 0.842019 0.481936 0.335551 0.587775 0.469186 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31800 episodes
GETTING ACTION FROM:
action 1, numVisits=31790, meanQ=39.560201, numObservations: 9
action 3, numVisits=4, meanQ=-1.000000, numObservations: 4
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.525901 0.87886 0.0539775 0.49593 0.916861 0.842019 0.481936 0.335551 0.587775 0.469186 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 122
Initial state: 0 0.860123 0.309134 0.281374 0.0486947 0.88232 0.223879 0.779842 0.405461 0.37001 0.378214 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31726 episodes
GETTING ACTION FROM:
action 5, numVisits=31720, meanQ=39.335728, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.860123 0.309134 0.281374 0.0486947 0.88232 0.223879 0.779842 0.405461 0.37001 0.378214 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 123
Initial state: 0 0.596856 0.979495 0.650111 0.571407 0.930106 0.0365301 0.624413 0.225 0.429943 0.284047 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31101 episodes
GETTING ACTION FROM:
action 3, numVisits=31094, meanQ=40.743291, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.596856 0.979495 0.650111 0.571407 0.930106 0.0365301 0.624413 0.225 0.429943 0.284047 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=491, meanQ=55.801599, numObservations: 9
action 5, numVisits=4, meanQ=21.747500, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 30705 episodes
GETTING ACTION FROM:
action 1, numVisits=31178, meanQ=19.901158, numObservations: 9
action 5, numVisits=22, meanQ=12.226818, numObservations: 8
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 1
Next state: 1 0.596856 0.979495 0.650111 0.571407 0.930106 0.0365301 0.624413 0.225 0.429943 0.284047 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 124
Initial state: 0 0.746125 0.542361 0.289727 0.31117 0.710604 0.284867 0.411736 0.282776 0.820322 0.73725 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33079 episodes
GETTING ACTION FROM:
action 4, numVisits=33064, meanQ=39.060785, numObservations: 9
action 5, numVisits=6, meanQ=14.000000, numObservations: 5
action 2, numVisits=5, meanQ=13.002000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.746125 0.542361 0.289727 0.31117 0.710604 0.284867 0.411736 0.282776 0.820322 0.73725 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 125
Initial state: 0 0.349673 0.389155 0.560544 0.349744 0.804639 0.255874 0.866415 0.731886 0.122898 0.366628 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18193 episodes
GETTING ACTION FROM:
action 0, numVisits=18170, meanQ=67.552072, numObservations: 243
action -1, numVisits=16, meanQ=-1.010000, numObservations: 16
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=3, meanQ=-34.333333, numObservations: 2
action: 0
Next state: 0 0.349673 0.389155 0.560544 0.349744 0.804639 0.255874 0.866415 0.731886 0.122898 0.366628 w: 1
Observation: 0 0 2 0 2 0 1 0 2 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=11, meanQ=89.090000, numObservations: 3
action 1, numVisits=9, meanQ=76.777778, numObservations: 3
action 2, numVisits=3, meanQ=62.663333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 31413 episodes
GETTING ACTION FROM:
action 5, numVisits=31421, meanQ=68.361410, numObservations: 9
action 2, numVisits=3, meanQ=62.663333, numObservations: 3
action 1, numVisits=12, meanQ=56.582500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.349673 0.389155 0.560544 0.349744 0.804639 0.255874 0.866415 0.731886 0.122898 0.366628 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101.99
Run # 126
Initial state: 0 0.408751 0.273846 0.0988492 0.630556 0.398698 0.324258 0.445892 0.606276 0.184288 0.635043 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31288 episodes
GETTING ACTION FROM:
action 1, numVisits=31279, meanQ=40.137703, numObservations: 9
action 4, numVisits=3, meanQ=32.333333, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.408751 0.273846 0.0988492 0.630556 0.398698 0.324258 0.445892 0.606276 0.184288 0.635043 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=426, meanQ=52.541790, numObservations: 9
action 5, numVisits=4, meanQ=44.495000, numObservations: 4
action 3, numVisits=5, meanQ=37.198000, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 21198 episodes
GETTING ACTION FROM:
action 4, numVisits=21598, meanQ=27.121687, numObservations: 9
action 3, numVisits=30, meanQ=24.761959, numObservations: 9
action 5, numVisits=5, meanQ=15.396000, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.408751 0.273846 0.0988492 0.630556 0.398698 0.324258 0.445892 0.606276 0.184288 0.635043 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 127
Initial state: 0 0.215418 0.719925 0.137137 0.0870478 0.138973 0.699685 0.0346115 0.28583 0.361618 0.299045 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32461 episodes
GETTING ACTION FROM:
action 5, numVisits=32436, meanQ=39.262802, numObservations: 9
action 2, numVisits=17, meanQ=32.000000, numObservations: 7
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.215418 0.719925 0.137137 0.0870478 0.138973 0.699685 0.0346115 0.28583 0.361618 0.299045 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 128
Initial state: 0 0.361096 0.428698 0.454916 0.0697755 0.811853 0.878997 0.386977 0.453175 0.0402934 0.620716 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18198 episodes
GETTING ACTION FROM:
action 0, numVisits=18164, meanQ=66.204372, numObservations: 243
action 2, numVisits=11, meanQ=-4.635455, numObservations: 7
action -1, numVisits=19, meanQ=-6.324737, numObservations: 18
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.361096 0.428698 0.454916 0.0697755 0.811853 0.878997 0.386977 0.453175 0.0402934 0.620716 w: 1
Observation: 0 0 2 0 1 0 3 0 3 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=183, meanQ=83.843117, numObservations: 9
action 4, numVisits=2, meanQ=44.495000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37259 episodes
GETTING ACTION FROM:
action 1, numVisits=37442, meanQ=87.481882, numObservations: 9
action 4, numVisits=2, meanQ=44.495000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.361096 0.428698 0.454916 0.0697755 0.811853 0.878997 0.386977 0.453175 0.0402934 0.620716 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 129
Initial state: 0 0.333081 0.949925 0.468852 0.412105 0.388818 0.879316 0.225012 0.881464 3.33589e-05 0.104067 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32835 episodes
GETTING ACTION FROM:
action 4, numVisits=32821, meanQ=38.299850, numObservations: 9
action 1, numVisits=8, meanQ=16.522525, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.333081 0.949925 0.468852 0.412105 0.388818 0.879316 0.225012 0.881464 3.33589e-05 0.104067 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=2765, meanQ=41.776673, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37084 episodes
GETTING ACTION FROM:
action 2, numVisits=39849, meanQ=46.706049, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.333081 0.949925 0.468852 0.412105 0.388818 0.879316 0.225012 0.881464 3.33589e-05 0.104067 w: 1
Observation: 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=211, meanQ=60.671274, numObservations: 9
action 5, numVisits=53, meanQ=42.887738, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 24382 episodes
GETTING ACTION FROM:
action 5, numVisits=23624, meanQ=34.991381, numObservations: 9
action 1, numVisits=1022, meanQ=31.957775, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 5
Next state: 0 0.333081 0.949925 0.468852 0.412105 0.388818 0.879316 0.225012 0.881464 3.33589e-05 0.104067 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=472, meanQ=87.618246, numObservations: 9
action 1, numVisits=26, meanQ=51.125644, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-15.731472, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 27513 episodes
GETTING ACTION FROM:
action 3, numVisits=27985, meanQ=60.899933, numObservations: 9
action 1, numVisits=26, meanQ=51.125644, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-15.731472, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.333081 0.949925 0.468852 0.412105 0.388818 0.879316 0.225012 0.881464 3.33589e-05 0.104067 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -130.671
Run # 130
Initial state: 0 0.514981 0.810498 0.536872 0.248313 0.522838 0.0726564 0.374942 0.345554 0.632237 0.873958 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31890 episodes
GETTING ACTION FROM:
action 5, numVisits=31875, meanQ=39.340357, numObservations: 9
action 4, numVisits=8, meanQ=21.623750, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.514981 0.810498 0.536872 0.248313 0.522838 0.0726564 0.374942 0.345554 0.632237 0.873958 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 131
Initial state: 0 0.768361 0.453037 0.740139 0.660666 0.471397 0.29476 0.652521 0.874736 0.954922 0.474231 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32965 episodes
GETTING ACTION FROM:
action 3, numVisits=32911, meanQ=38.968439, numObservations: 9
action 1, numVisits=20, meanQ=12.599000, numObservations: 8
action 4, numVisits=21, meanQ=10.476195, numObservations: 8
action 5, numVisits=10, meanQ=6.198000, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.768361 0.453037 0.740139 0.660666 0.471397 0.29476 0.652521 0.874736 0.954922 0.474231 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 132
Initial state: 0 0.917732 0.827825 0.306664 0.255152 0.573165 0.249421 0.454271 0.0809825 0.328086 0.413162 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32823 episodes
GETTING ACTION FROM:
action 3, numVisits=32811, meanQ=38.224267, numObservations: 9
action 4, numVisits=7, meanQ=23.285714, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.917732 0.827825 0.306664 0.255152 0.573165 0.249421 0.454271 0.0809825 0.328086 0.413162 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 133
Initial state: 0 0.914591 0.282072 0.302762 0.890594 0.368632 0.422844 0.24779 0.934445 0.211607 0.20147 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32977 episodes
GETTING ACTION FROM:
action 4, numVisits=32970, meanQ=39.259562, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.914591 0.282072 0.302762 0.890594 0.368632 0.422844 0.24779 0.934445 0.211607 0.20147 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=2842, meanQ=42.930211, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 36407 episodes
GETTING ACTION FROM:
action 1, numVisits=39249, meanQ=47.703840, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.914591 0.282072 0.302762 0.890594 0.368632 0.422844 0.24779 0.934445 0.211607 0.20147 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 134
Initial state: 0 0.304183 0.870751 0.143666 0.312094 0.21816 0.817206 0.439225 0.40854 0.945878 0.221896 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32975 episodes
GETTING ACTION FROM:
action 1, numVisits=32968, meanQ=38.130368, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.304183 0.870751 0.143666 0.312094 0.21816 0.817206 0.439225 0.40854 0.945878 0.221896 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 135
Initial state: 0 0.801916 0.531449 0.486103 0.815549 0.937373 0.799646 0.474236 0.41928 0.792996 0.894448 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32855 episodes
GETTING ACTION FROM:
action 5, numVisits=32790, meanQ=39.382050, numObservations: 9
action 3, numVisits=52, meanQ=31.849621, numObservations: 9
action 1, numVisits=6, meanQ=29.165000, numObservations: 3
action 4, numVisits=4, meanQ=21.747500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.801916 0.531449 0.486103 0.815549 0.937373 0.799646 0.474236 0.41928 0.792996 0.894448 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 136
Initial state: 0 0.344873 0.914942 0.82507 0.600139 0.189207 0.973727 0.51061 0.346607 0.8961 0.523591 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33156 episodes
GETTING ACTION FROM:
action 1, numVisits=33054, meanQ=38.730023, numObservations: 9
action 3, numVisits=59, meanQ=32.864242, numObservations: 9
action 2, numVisits=30, meanQ=32.636007, numObservations: 8
action 5, numVisits=10, meanQ=26.297000, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.344873 0.914942 0.82507 0.600139 0.189207 0.973727 0.51061 0.346607 0.8961 0.523591 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 137
Initial state: 0 0.181071 0.882995 0.780544 0.674078 0.488024 0.318166 0.000326532 0.190877 0.562808 0.998555 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32741 episodes
GETTING ACTION FROM:
action 3, numVisits=32718, meanQ=38.150654, numObservations: 9
action 2, numVisits=6, meanQ=14.000000, numObservations: 3
action 5, numVisits=13, meanQ=13.615385, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.181071 0.882995 0.780544 0.674078 0.488024 0.318166 0.000326532 0.190877 0.562808 0.998555 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 138
Initial state: 0 0.0156408 0.499393 0.813053 0.149307 0.847243 0.0578134 0.450292 0.298801 0.750927 0.0887565 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30875 episodes
GETTING ACTION FROM:
action 4, numVisits=30869, meanQ=40.416273, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.0156408 0.499393 0.813053 0.149307 0.847243 0.0578134 0.450292 0.298801 0.750927 0.0887565 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 139
Initial state: 0 0.877483 0.716434 0.410843 0.980992 0.188603 0.149567 0.783251 0.863832 0.469249 0.406826 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32163 episodes
GETTING ACTION FROM:
action 2, numVisits=32137, meanQ=39.002060, numObservations: 9
action 3, numVisits=14, meanQ=23.927864, numObservations: 6
action 4, numVisits=5, meanQ=15.198000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=4, meanQ=-5.752500, numObservations: 2
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.877483 0.716434 0.410843 0.980992 0.188603 0.149567 0.783251 0.863832 0.469249 0.406826 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 140
Initial state: 0 0.744215 0.399168 0.276042 0.47124 0.351016 0.435868 0.617831 0.293676 0.483383 0.647307 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32904 episodes
GETTING ACTION FROM:
action 2, numVisits=32890, meanQ=38.505032, numObservations: 9
action 3, numVisits=8, meanQ=20.251250, numObservations: 4
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.744215 0.399168 0.276042 0.47124 0.351016 0.435868 0.617831 0.293676 0.483383 0.647307 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=946, meanQ=44.023383, numObservations: 9
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 4, numVisits=3, meanQ=-34.333333, numObservations: 2
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 15916 episodes
GETTING ACTION FROM:
action 5, numVisits=16862, meanQ=34.381773, numObservations: 9
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 4, numVisits=3, meanQ=-34.333333, numObservations: 2
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.744215 0.399168 0.276042 0.47124 0.351016 0.435868 0.617831 0.293676 0.483383 0.647307 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 141
Initial state: 0 0.484031 0.286377 0.383515 0.0737489 0.139835 0.852057 0.181138 0.130044 0.680858 0.232667 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32109 episodes
GETTING ACTION FROM:
action 4, numVisits=32094, meanQ=38.680682, numObservations: 9
action 3, numVisits=9, meanQ=20.221111, numObservations: 6
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.484031 0.286377 0.383515 0.0737489 0.139835 0.852057 0.181138 0.130044 0.680858 0.232667 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=1763, meanQ=57.548950, numObservations: 215
action -1, numVisits=19, meanQ=-7.472095, numObservations: 16
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=14, meanQ=-10.215707, numObservations: 5
action 2, numVisits=8, meanQ=-14.626250, numObservations: 5
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 4394 episodes
GETTING ACTION FROM:
action 0, numVisits=6157, meanQ=53.062190, numObservations: 240
action -1, numVisits=19, meanQ=-7.472095, numObservations: 16
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=14, meanQ=-10.215707, numObservations: 5
action 2, numVisits=8, meanQ=-14.626250, numObservations: 5
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.484031 0.286377 0.383515 0.0737489 0.139835 0.852057 0.181138 0.130044 0.680858 0.232667 w: 1
Observation: 0 0 2 0 1 0 3 0 1 0 2 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=32, meanQ=63.393766, numObservations: 6
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 12635 episodes
GETTING ACTION FROM:
action 3, numVisits=12667, meanQ=62.601770, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.484031 0.286377 0.383515 0.0737489 0.139835 0.852057 0.181138 0.130044 0.680858 0.232667 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 5, numVisits=2621, meanQ=93.022498, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-16.438249, numObservations: 1
action 3, numVisits=1, meanQ=-16.498502, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-1077.532736, numObservations: 1
Sampled 31967 episodes
GETTING ACTION FROM:
action 5, numVisits=34588, meanQ=78.408213, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-16.438249, numObservations: 1
action 3, numVisits=1, meanQ=-16.498502, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-1077.532736, numObservations: 1
action: 5
Next state: 2 0.484031 0.286377 0.383515 0.0737489 0.139835 0.852057 0.181138 0.130044 0.680858 0.232667 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -121.761
Run # 142
Initial state: 0 0.361585 0.765815 0.721991 0.725551 0.329324 0.351373 0.777921 0.43753 0.320615 0.130413 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31776 episodes
GETTING ACTION FROM:
action 2, numVisits=31723, meanQ=39.075941, numObservations: 9
action 3, numVisits=11, meanQ=34.454545, numObservations: 7
action 4, numVisits=35, meanQ=33.800006, numObservations: 9
action 5, numVisits=3, meanQ=25.666667, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.361585 0.765815 0.721991 0.725551 0.329324 0.351373 0.777921 0.43753 0.320615 0.130413 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 143
Initial state: 0 0.512174 0.439094 0.105719 0.0011334 0.188678 0.240496 0.0253184 0.85081 0.382233 0.595293 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32869 episodes
GETTING ACTION FROM:
action 1, numVisits=32801, meanQ=36.911415, numObservations: 9
action 2, numVisits=28, meanQ=14.398936, numObservations: 9
action 3, numVisits=36, meanQ=14.249725, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.512174 0.439094 0.105719 0.0011334 0.188678 0.240496 0.0253184 0.85081 0.382233 0.595293 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 144
Initial state: 0 0.0852564 0.374155 0.551873 0.568413 0.422715 0.327284 0.0753245 0.00361898 0.491188 0.14757 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32276 episodes
GETTING ACTION FROM:
action 4, numVisits=32266, meanQ=38.421410, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.0852564 0.374155 0.551873 0.568413 0.422715 0.327284 0.0753245 0.00361898 0.491188 0.14757 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=1790, meanQ=61.712040, numObservations: 201
action 0, numVisits=15, meanQ=-1.010000, numObservations: 15
action 3, numVisits=15, meanQ=-2.802000, numObservations: 6
action 5, numVisits=7, meanQ=-4.000000, numObservations: 5
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 3639 episodes
GETTING ACTION FROM:
action -1, numVisits=5429, meanQ=49.313766, numObservations: 241
action 0, numVisits=15, meanQ=-1.010000, numObservations: 15
action 3, numVisits=15, meanQ=-2.802000, numObservations: 6
action 5, numVisits=7, meanQ=-4.000000, numObservations: 5
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.0852564 0.374155 0.551873 0.568413 0.422715 0.327284 0.0753245 0.00361898 0.491188 0.14757 w: 1
Observation: 0 1 0 3 0 2 0 1 0 2 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=7, meanQ=-1.294271, numObservations: 6
action 5, numVisits=7, meanQ=-2.287143, numObservations: 4
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 0, numVisits=10, meanQ=-11.108000, numObservations: 9
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 21298 episodes
GETTING ACTION FROM:
action 5, numVisits=21295, meanQ=55.825133, numObservations: 9
action -1, numVisits=7, meanQ=-1.294271, numObservations: 6
action 3, numVisits=12, meanQ=-2.666667, numObservations: 7
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 0, numVisits=10, meanQ=-11.108000, numObservations: 9
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.0852564 0.374155 0.551873 0.568413 0.422715 0.327284 0.0753245 0.00361898 0.491188 0.14757 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -111.97
Run # 145
Initial state: 0 0.503683 0.557037 0.50589 0.396741 0.513512 0.639738 0.93774 0.600853 0.943193 0.640237 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31515 episodes
GETTING ACTION FROM:
action 2, numVisits=31505, meanQ=39.205533, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 5, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.503683 0.557037 0.50589 0.396741 0.513512 0.639738 0.93774 0.600853 0.943193 0.640237 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 146
Initial state: 0 0.361084 0.363094 0.627098 0.518028 0.273002 0.0263836 0.0895796 0.799971 0.286815 0.958753 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32942 episodes
GETTING ACTION FROM:
action 3, numVisits=32936, meanQ=38.910051, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.361084 0.363094 0.627098 0.518028 0.273002 0.0263836 0.0895796 0.799971 0.286815 0.958753 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=2790, meanQ=44.123914, numObservations: 9
action 2, numVisits=3, meanQ=26.326667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 35988 episodes
GETTING ACTION FROM:
action 1, numVisits=38778, meanQ=48.968336, numObservations: 9
action 2, numVisits=3, meanQ=26.326667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 1
Next state: 1 0.361084 0.363094 0.627098 0.518028 0.273002 0.0263836 0.0895796 0.799971 0.286815 0.958753 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 147
Initial state: 0 0.145293 0.812147 0.475787 0.94669 0.544056 0.976018 0.432432 0.325562 0.982059 0.0933836 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33174 episodes
GETTING ACTION FROM:
action 1, numVisits=33131, meanQ=37.463188, numObservations: 9
action 4, numVisits=35, meanQ=25.970571, numObservations: 8
action 2, numVisits=4, meanQ=19.002500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.145293 0.812147 0.475787 0.94669 0.544056 0.976018 0.432432 0.325562 0.982059 0.0933836 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=2748, meanQ=45.892864, numObservations: 9
action 3, numVisits=8, meanQ=24.000000, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37271 episodes
GETTING ACTION FROM:
action 4, numVisits=40019, meanQ=47.862250, numObservations: 9
action 3, numVisits=8, meanQ=24.000000, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.145293 0.812147 0.475787 0.94669 0.544056 0.976018 0.432432 0.325562 0.982059 0.0933836 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=451, meanQ=79.233904, numObservations: 9
action 2, numVisits=2, meanQ=44.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 41899 episodes
GETTING ACTION FROM:
action 4, numVisits=42350, meanQ=89.262565, numObservations: 9
action 2, numVisits=2, meanQ=44.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.145293 0.812147 0.475787 0.94669 0.544056 0.976018 0.432432 0.325562 0.982059 0.0933836 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 75.1399
Run # 148
Initial state: 0 0.81384 0.982428 0.496061 0.304865 0.194172 0.105487 0.197059 0.972868 0.844909 0.588221 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32287 episodes
GETTING ACTION FROM:
action 1, numVisits=32274, meanQ=38.694283, numObservations: 9
action 2, numVisits=7, meanQ=13.285714, numObservations: 7
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.81384 0.982428 0.496061 0.304865 0.194172 0.105487 0.197059 0.972868 0.844909 0.588221 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 149
Initial state: 0 0.723189 0.708134 0.252388 0.121294 0.423461 0.422972 0.111711 0.122385 0.5055 0.629307 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32700 episodes
GETTING ACTION FROM:
action 4, numVisits=32679, meanQ=37.934885, numObservations: 9
action 2, numVisits=12, meanQ=21.500000, numObservations: 7
action 3, numVisits=4, meanQ=21.500000, numObservations: 4
action 5, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.723189 0.708134 0.252388 0.121294 0.423461 0.422972 0.111711 0.122385 0.5055 0.629307 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=1836, meanQ=41.477435, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 12554 episodes
GETTING ACTION FROM:
action 5, numVisits=14390, meanQ=36.396360, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 5
Next state: 1 0.723189 0.708134 0.252388 0.121294 0.423461 0.422972 0.111711 0.122385 0.5055 0.629307 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 150
Initial state: 0 0.564852 0.350185 0.352315 0.386961 0.317358 0.736755 0.878992 0.889382 0.247099 0.339385 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32805 episodes
GETTING ACTION FROM:
action 3, numVisits=32791, meanQ=37.318355, numObservations: 9
action 2, numVisits=3, meanQ=32.333333, numObservations: 3
action 5, numVisits=7, meanQ=26.142857, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.564852 0.350185 0.352315 0.386961 0.317358 0.736755 0.878992 0.889382 0.247099 0.339385 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 151
Initial state: 0 0.626256 0.17326 0.856826 0.460992 0.270734 0.0278434 0.410716 0.340383 0.97534 0.70725 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18528 episodes
GETTING ACTION FROM:
action -1, numVisits=18504, meanQ=55.443064, numObservations: 243
action 1, numVisits=4, meanQ=-5.752500, numObservations: 2
action 0, numVisits=14, meanQ=-8.222857, numObservations: 13
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=3, meanQ=-34.333333, numObservations: 3
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.626256 0.17326 0.856826 0.460992 0.270734 0.0278434 0.410716 0.340383 0.97534 0.70725 w: 1
Observation: 0 3 0 3 0 1 0 2 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=115, meanQ=74.192698, numObservations: 7
action 1, numVisits=9, meanQ=54.555556, numObservations: 3
action 5, numVisits=4, meanQ=49.000000, numObservations: 3
action 3, numVisits=2, meanQ=44.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 36634 episodes
GETTING ACTION FROM:
action 4, numVisits=36749, meanQ=86.153276, numObservations: 9
action 1, numVisits=9, meanQ=54.555556, numObservations: 3
action 5, numVisits=4, meanQ=49.000000, numObservations: 3
action 3, numVisits=2, meanQ=44.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.626256 0.17326 0.856826 0.460992 0.270734 0.0278434 0.410716 0.340383 0.97534 0.70725 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 152
Initial state: 0 0.0142668 0.394834 0.913938 0.68676 0.194691 0.0113827 0.0309905 0.817601 0.319951 0.34968 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32921 episodes
GETTING ACTION FROM:
action 3, numVisits=32853, meanQ=38.763213, numObservations: 9
action 1, numVisits=59, meanQ=36.474237, numObservations: 9
action 2, numVisits=5, meanQ=19.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.0142668 0.394834 0.913938 0.68676 0.194691 0.0113827 0.0309905 0.817601 0.319951 0.34968 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1783, meanQ=43.695911, numObservations: 9
action 1, numVisits=34, meanQ=38.000003, numObservations: 9
action 4, numVisits=5, meanQ=37.198000, numObservations: 4
action 5, numVisits=6, meanQ=32.333333, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 11246 episodes
GETTING ACTION FROM:
action 2, numVisits=13023, meanQ=35.108908, numObservations: 9
action 1, numVisits=38, meanQ=28.631582, numObservations: 9
action 4, numVisits=6, meanQ=28.577852, numObservations: 5
action 5, numVisits=7, meanQ=13.285714, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 2
Next state: 1 0.0142668 0.394834 0.913938 0.68676 0.194691 0.0113827 0.0309905 0.817601 0.319951 0.34968 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 153
Initial state: 0 0.535468 0.707764 0.322802 0.583877 0.345115 0.298778 0.173257 0.348784 0.133956 0.112898 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32774 episodes
GETTING ACTION FROM:
action 3, numVisits=32747, meanQ=37.639302, numObservations: 9
action 1, numVisits=6, meanQ=14.165000, numObservations: 6
action 5, numVisits=17, meanQ=13.885888, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.535468 0.707764 0.322802 0.583877 0.345115 0.298778 0.173257 0.348784 0.133956 0.112898 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 154
Initial state: 0 0.611887 0.320295 0.0683886 0.77138 0.326367 0.335988 0.0485709 0.637449 0.733166 0.58834 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32770 episodes
GETTING ACTION FROM:
action 2, numVisits=32764, meanQ=37.840904, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.611887 0.320295 0.0683886 0.77138 0.326367 0.335988 0.0485709 0.637449 0.733166 0.58834 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=158, meanQ=6.507045, numObservations: 103
action 4, numVisits=3, meanQ=-4.003333, numObservations: 3
action -1, numVisits=40, meanQ=-4.228737, numObservations: 34
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=10, meanQ=-11.901000, numObservations: 7
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 15835 episodes
GETTING ACTION FROM:
action 0, numVisits=15993, meanQ=3.321084, numObservations: 243
action 4, numVisits=3, meanQ=-4.003333, numObservations: 3
action -1, numVisits=40, meanQ=-4.228737, numObservations: 34
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=10, meanQ=-11.901000, numObservations: 7
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.611887 0.320295 0.0683886 0.77138 0.326367 0.335988 0.0485709 0.637449 0.733166 0.58834 w: 1
Observation: 0 0 2 0 3 0 2 0 3 0 2 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=8, meanQ=99.000000, numObservations: 4
action 3, numVisits=3, meanQ=59.595484, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-1065.745650, numObservations: 1
Sampled 38266 episodes
GETTING ACTION FROM:
action 1, numVisits=38269, meanQ=49.079174, numObservations: 9
action 3, numVisits=8, meanQ=34.223307, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-1065.745650, numObservations: 1
action: 1
Next state: 1 0.611887 0.320295 0.0683886 0.77138 0.326367 0.335988 0.0485709 0.637449 0.733166 0.58834 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 84.0499
Run # 155
Initial state: 0 0.137656 0.0601971 0.53859 0.765108 0.482618 0.611 0.479191 0.433268 0.905792 0.089796 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31873 episodes
GETTING ACTION FROM:
action 4, numVisits=31763, meanQ=37.920272, numObservations: 9
action 2, numVisits=45, meanQ=32.424671, numObservations: 8
action 3, numVisits=58, meanQ=31.363452, numObservations: 9
action 1, numVisits=4, meanQ=21.747500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.137656 0.0601971 0.53859 0.765108 0.482618 0.611 0.479191 0.433268 0.905792 0.089796 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 156
Initial state: 0 0.790066 0.994002 0.839548 0.867913 0.265499 0.0488107 0.154556 0.648545 0.484014 0.352187 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33072 episodes
GETTING ACTION FROM:
action 5, numVisits=33063, meanQ=37.661407, numObservations: 9
action 3, numVisits=4, meanQ=-1.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.790066 0.994002 0.839548 0.867913 0.265499 0.0488107 0.154556 0.648545 0.484014 0.352187 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 157
Initial state: 0 0.385555 0.373981 0.52422 0.902759 0.26641 0.844082 0.740774 0.360944 0.579578 0.135666 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31489 episodes
GETTING ACTION FROM:
action 3, numVisits=31463, meanQ=40.315215, numObservations: 9
action 2, numVisits=9, meanQ=30.110011, numObservations: 6
action 5, numVisits=12, meanQ=21.500000, numObservations: 7
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.385555 0.373981 0.52422 0.902759 0.26641 0.844082 0.740774 0.360944 0.579578 0.135666 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=2723, meanQ=55.501458, numObservations: 9
action 1, numVisits=7, meanQ=41.857143, numObservations: 5
action 2, numVisits=6, meanQ=29.330000, numObservations: 5
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 27841 episodes
GETTING ACTION FROM:
action 3, numVisits=30564, meanQ=64.481439, numObservations: 9
action 1, numVisits=7, meanQ=41.857143, numObservations: 5
action 2, numVisits=6, meanQ=29.330000, numObservations: 5
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.385555 0.373981 0.52422 0.902759 0.26641 0.844082 0.740774 0.360944 0.579578 0.135666 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=10068, meanQ=50.153243, numObservations: 9
action 2, numVisits=31, meanQ=42.643874, numObservations: 8
action 1, numVisits=13, meanQ=34.384615, numObservations: 7
action 4, numVisits=4, meanQ=21.747500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 36146 episodes
GETTING ACTION FROM:
action 5, numVisits=46214, meanQ=56.488619, numObservations: 9
action 2, numVisits=31, meanQ=42.643874, numObservations: 8
action 1, numVisits=13, meanQ=34.384615, numObservations: 7
action 4, numVisits=4, meanQ=21.747500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 5
Next state: 2 0.385555 0.373981 0.52422 0.902759 0.26641 0.844082 0.740774 0.360944 0.579578 0.135666 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -120.88
Run # 158
Initial state: 0 0.266052 0.916631 0.465523 0.313829 0.665469 0.891781 0.336823 0.119353 0.733542 0.557658 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32919 episodes
GETTING ACTION FROM:
action 2, numVisits=32913, meanQ=39.159820, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.266052 0.916631 0.465523 0.313829 0.665469 0.891781 0.336823 0.119353 0.733542 0.557658 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 159
Initial state: 0 0.206947 0.54232 0.0175481 0.52359 0.406939 0.0965681 0.334834 0.368014 0.807429 0.747587 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32416 episodes
GETTING ACTION FROM:
action 5, numVisits=32394, meanQ=39.180142, numObservations: 9
action 4, numVisits=7, meanQ=26.142857, numObservations: 5
action 2, numVisits=11, meanQ=24.454545, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.206947 0.54232 0.0175481 0.52359 0.406939 0.0965681 0.334834 0.368014 0.807429 0.747587 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 160
Initial state: 0 0.840602 0.769181 0.475082 0.414011 0.655421 0.409388 0.389572 0.975519 0.169943 0.77312 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31488 episodes
GETTING ACTION FROM:
action 5, numVisits=31471, meanQ=36.808981, numObservations: 9
action 1, numVisits=12, meanQ=13.167500, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.840602 0.769181 0.475082 0.414011 0.655421 0.409388 0.389572 0.975519 0.169943 0.77312 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=2634, meanQ=43.904046, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 35732 episodes
GETTING ACTION FROM:
action 2, numVisits=38366, meanQ=48.381028, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.840602 0.769181 0.475082 0.414011 0.655421 0.409388 0.389572 0.975519 0.169943 0.77312 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 161
Initial state: 0 0.197313 0.0276162 0.0679665 0.0295038 0.492362 0.435352 0.540459 0.396665 0.830719 0.0392911 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32959 episodes
GETTING ACTION FROM:
action 5, numVisits=32808, meanQ=38.192995, numObservations: 9
action 3, numVisits=126, meanQ=35.581436, numObservations: 9
action 1, numVisits=11, meanQ=34.454545, numObservations: 7
action 4, numVisits=7, meanQ=23.568571, numObservations: 6
action 2, numVisits=5, meanQ=15.198000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 5
Next state: 0 0.197313 0.0276162 0.0679665 0.0295038 0.492362 0.435352 0.540459 0.396665 0.830719 0.0392911 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=464, meanQ=52.773578, numObservations: 9
action 2, numVisits=17, meanQ=38.056471, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 33329 episodes
GETTING ACTION FROM:
action 4, numVisits=33781, meanQ=26.525788, numObservations: 9
action 2, numVisits=29, meanQ=21.550690, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.197313 0.0276162 0.0679665 0.0295038 0.492362 0.435352 0.540459 0.396665 0.830719 0.0392911 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 162
Initial state: 0 0.0728313 0.532122 0.819856 0.768051 0.51007 0.309997 0.45108 0.720658 0.335395 0.19315 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32822 episodes
GETTING ACTION FROM:
action 3, numVisits=32816, meanQ=38.843991, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.0728313 0.532122 0.819856 0.768051 0.51007 0.309997 0.45108 0.720658 0.335395 0.19315 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 163
Initial state: 0 0.412603 0.408352 0.805684 0.708248 0.0761736 0.398004 0.375097 0.625696 0.101355 0.145012 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18317 episodes
GETTING ACTION FROM:
action -1, numVisits=18287, meanQ=57.815385, numObservations: 243
action 0, numVisits=25, meanQ=-5.049200, numObservations: 24
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.412603 0.408352 0.805684 0.708248 0.0761736 0.398004 0.375097 0.625696 0.101355 0.145012 w: 1
Observation: 0 2 0 3 0 1 0 2 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=30, meanQ=45.066000, numObservations: 6
action 2, numVisits=16, meanQ=17.186875, numObservations: 5
action 3, numVisits=5, meanQ=9.612020, numObservations: 4
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 36591 episodes
GETTING ACTION FROM:
action 1, numVisits=36621, meanQ=63.653778, numObservations: 9
action 2, numVisits=16, meanQ=17.186875, numObservations: 5
action 3, numVisits=5, meanQ=9.612020, numObservations: 4
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 1
Next state: 1 0.412603 0.408352 0.805684 0.708248 0.0761736 0.398004 0.375097 0.625696 0.101355 0.145012 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 164
Initial state: 0 0.512258 0.292963 0.200513 0.153776 0.0648673 0.613444 0.705743 0.10767 0.804174 0.264247 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32926 episodes
GETTING ACTION FROM:
action 1, numVisits=32920, meanQ=38.442126, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.512258 0.292963 0.200513 0.153776 0.0648673 0.613444 0.705743 0.10767 0.804174 0.264247 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 165
Initial state: 0 0.337128 0.430104 0.0752431 0.648295 0.635869 0.849452 0.867589 0.204566 0.904867 0.805526 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32818 episodes
GETTING ACTION FROM:
action 1, numVisits=32809, meanQ=38.827717, numObservations: 9
action 5, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.337128 0.430104 0.0752431 0.648295 0.635869 0.849452 0.867589 0.204566 0.904867 0.805526 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=207, meanQ=50.473575, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 30836 episodes
GETTING ACTION FROM:
action 3, numVisits=31043, meanQ=37.202932, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.337128 0.430104 0.0752431 0.648295 0.635869 0.849452 0.867589 0.204566 0.904867 0.805526 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 166
Initial state: 0 0.930937 0.361958 0.242545 0.868818 0.200718 0.233731 0.453245 0.782183 0.467265 0.301268 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32646 episodes
GETTING ACTION FROM:
action 5, numVisits=32639, meanQ=37.509290, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.930937 0.361958 0.242545 0.868818 0.200718 0.233731 0.453245 0.782183 0.467265 0.301268 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 167
Initial state: 0 0.346545 0.351879 0.651566 0.923901 0.611781 0.0979923 0.0511987 0.21747 0.848712 0.342218 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33010 episodes
GETTING ACTION FROM:
action 5, numVisits=32994, meanQ=38.675214, numObservations: 9
action 4, numVisits=11, meanQ=24.544545, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.346545 0.351879 0.651566 0.923901 0.611781 0.0979923 0.0511987 0.21747 0.848712 0.342218 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 168
Initial state: 0 0.594451 0.706169 0.951151 0.428655 0.719779 0.441424 0.93182 0.809141 0.498343 0.367855 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18516 episodes
GETTING ACTION FROM:
action -1, numVisits=18482, meanQ=57.346197, numObservations: 243
action 0, numVisits=25, meanQ=-1.089596, numObservations: 24
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=5, meanQ=-21.000000, numObservations: 3
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.594451 0.706169 0.951151 0.428655 0.719779 0.441424 0.93182 0.809141 0.498343 0.367855 w: 1
Observation: 0 3 0 3 0 3 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=78, meanQ=45.590514, numObservations: 9
action 5, numVisits=3, meanQ=32.333333, numObservations: 3
action 3, numVisits=5, meanQ=19.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 40386 episodes
GETTING ACTION FROM:
action 2, numVisits=40436, meanQ=37.888041, numObservations: 9
action 5, numVisits=31, meanQ=30.967419, numObservations: 8
action 3, numVisits=5, meanQ=19.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.594451 0.706169 0.951151 0.428655 0.719779 0.441424 0.93182 0.809141 0.498343 0.367855 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 169
Initial state: 0 0.263468 0.843338 0.489499 0.442633 0.956379 0.958076 0.992905 0.332141 0.277817 0.259694 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32665 episodes
GETTING ACTION FROM:
action 1, numVisits=32658, meanQ=38.282442, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.263468 0.843338 0.489499 0.442633 0.956379 0.958076 0.992905 0.332141 0.277817 0.259694 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 170
Initial state: 0 0.89695 0.837865 0.327621 0.0541473 0.329482 0.33846 0.602986 0.201234 0.14782 0.0203756 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32937 episodes
GETTING ACTION FROM:
action 2, numVisits=32926, meanQ=37.324101, numObservations: 9
action 4, numVisits=6, meanQ=12.335000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.89695 0.837865 0.327621 0.0541473 0.329482 0.33846 0.602986 0.201234 0.14782 0.0203756 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 171
Initial state: 0 0.485001 0.329604 0.408233 0.243357 0.907914 0.611561 0.475546 0.171387 0.363624 0.671807 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32933 episodes
GETTING ACTION FROM:
action 4, numVisits=32925, meanQ=38.260045, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.485001 0.329604 0.408233 0.243357 0.907914 0.611561 0.475546 0.171387 0.363624 0.671807 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=471, meanQ=39.879427, numObservations: 9
action 1, numVisits=6, meanQ=-1.000000, numObservations: 4
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 22730 episodes
GETTING ACTION FROM:
action 5, numVisits=23201, meanQ=32.168411, numObservations: 9
action 1, numVisits=6, meanQ=-1.000000, numObservations: 4
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.485001 0.329604 0.408233 0.243357 0.907914 0.611561 0.475546 0.171387 0.363624 0.671807 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 172
Initial state: 0 0.843715 0.834963 0.332695 0.717648 0.102554 0.595002 0.480178 0.323102 0.0981429 0.351207 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33144 episodes
GETTING ACTION FROM:
action 4, numVisits=33126, meanQ=38.117987, numObservations: 9
action 3, numVisits=13, meanQ=19.616154, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.843715 0.834963 0.332695 0.717648 0.102554 0.595002 0.480178 0.323102 0.0981429 0.351207 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 173
Initial state: 0 0.594783 0.491771 0.610195 0.396958 0.370703 0.345627 0.959753 0.366088 0.290273 0.509034 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33240 episodes
GETTING ACTION FROM:
action 3, numVisits=33229, meanQ=38.518611, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=5, meanQ=-3.000000, numObservations: 4
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.594783 0.491771 0.610195 0.396958 0.370703 0.345627 0.959753 0.366088 0.290273 0.509034 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 174
Initial state: 0 0.146849 0.574846 0.351938 0.301616 0.188239 0.794716 0.32347 0.834106 0.299133 0.393266 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18130 episodes
GETTING ACTION FROM:
action 0, numVisits=18083, meanQ=64.859946, numObservations: 243
action -1, numVisits=30, meanQ=-4.376000, numObservations: 29
action 5, numVisits=13, meanQ=-10.230769, numObservations: 7
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.146849 0.574846 0.351938 0.301616 0.188239 0.794716 0.32347 0.834106 0.299133 0.393266 w: 1
Observation: 0 0 3 0 2 0 3 0 3 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=146, meanQ=63.319908, numObservations: 9
action 3, numVisits=9, meanQ=30.331111, numObservations: 5
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=3, meanQ=-4.003333, numObservations: 3
action 5, numVisits=3, meanQ=-7.333333, numObservations: 2
Sampled 33273 episodes
GETTING ACTION FROM:
action 1, numVisits=33419, meanQ=68.666006, numObservations: 9
action 3, numVisits=9, meanQ=30.331111, numObservations: 5
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=3, meanQ=-4.003333, numObservations: 3
action 5, numVisits=3, meanQ=-7.333333, numObservations: 2
action: 1
Next state: 0 0.146849 0.574846 0.351938 0.301616 0.188239 0.794716 0.32347 0.834106 0.299133 0.393266 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=6368, meanQ=68.747162, numObservations: 9
action 1, numVisits=5, meanQ=53.216020, numObservations: 1
action 4, numVisits=9, meanQ=52.553333, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 38013 episodes
GETTING ACTION FROM:
action 2, numVisits=44381, meanQ=67.326762, numObservations: 9
action 1, numVisits=5, meanQ=53.216020, numObservations: 1
action 4, numVisits=9, meanQ=52.553333, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 2
Next state: 1 0.146849 0.574846 0.351938 0.301616 0.188239 0.794716 0.32347 0.834106 0.299133 0.393266 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 84.1399
Run # 175
Initial state: 0 0.0517686 0.130975 0.0460269 0.840181 0.377593 0.170143 0.328658 0.289378 0.377905 0.697409 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33053 episodes
GETTING ACTION FROM:
action 3, numVisits=33027, meanQ=38.469974, numObservations: 9
action 1, numVisits=7, meanQ=26.142857, numObservations: 4
action 5, numVisits=11, meanQ=23.636364, numObservations: 7
action 4, numVisits=4, meanQ=21.500000, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.0517686 0.130975 0.0460269 0.840181 0.377593 0.170143 0.328658 0.289378 0.377905 0.697409 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=465, meanQ=43.288370, numObservations: 9
action 5, numVisits=22, meanQ=42.320914, numObservations: 7
action 2, numVisits=4, meanQ=21.747500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 19627 episodes
GETTING ACTION FROM:
action 1, numVisits=20088, meanQ=31.248442, numObservations: 9
action 5, numVisits=26, meanQ=27.963850, numObservations: 8
action 2, numVisits=4, meanQ=21.747500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 1
Next state: 0 0.0517686 0.130975 0.0460269 0.840181 0.377593 0.170143 0.328658 0.289378 0.377905 0.697409 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=307, meanQ=30.764536, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=3, meanQ=-4.003333, numObservations: 3
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 17113 episodes
GETTING ACTION FROM:
action 2, numVisits=17420, meanQ=41.467972, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=3, meanQ=-4.003333, numObservations: 3
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.0517686 0.130975 0.0460269 0.840181 0.377593 0.170143 0.328658 0.289378 0.377905 0.697409 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 5, numVisits=17, meanQ=7.858963, numObservations: 6
action -1, numVisits=24, meanQ=-6.573675, numObservations: 16
action 0, numVisits=13, meanQ=-10.556899, numObservations: 10
action 1, numVisits=1, meanQ=-18.572829, numObservations: 1
action 2, numVisits=1, meanQ=-19.744306, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 35643 episodes
GETTING ACTION FROM:
action 5, numVisits=35660, meanQ=58.767332, numObservations: 9
action -1, numVisits=24, meanQ=-6.573675, numObservations: 16
action 0, numVisits=13, meanQ=-10.556899, numObservations: 10
action 1, numVisits=1, meanQ=-18.572829, numObservations: 1
action 2, numVisits=1, meanQ=-19.744306, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.0517686 0.130975 0.0460269 0.840181 0.377593 0.170143 0.328658 0.289378 0.377905 0.697409 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -130.671
Run # 176
Initial state: 0 0.135806 0.0609128 0.125222 0.303054 0.470208 0.493389 0.331025 0.0825208 0.467665 0.328792 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32870 episodes
GETTING ACTION FROM:
action 5, numVisits=32855, meanQ=37.948093, numObservations: 9
action 2, numVisits=7, meanQ=10.428571, numObservations: 4
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.135806 0.0609128 0.125222 0.303054 0.470208 0.493389 0.331025 0.0825208 0.467665 0.328792 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 177
Initial state: 0 0.660616 0.940724 0.855882 0.224379 0.321734 0.813949 0.598784 0.0484713 0.478337 0.424555 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33065 episodes
GETTING ACTION FROM:
action 4, numVisits=33056, meanQ=38.763845, numObservations: 9
action 2, numVisits=3, meanQ=22.363367, numObservations: 1
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.660616 0.940724 0.855882 0.224379 0.321734 0.813949 0.598784 0.0484713 0.478337 0.424555 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=521, meanQ=40.271040, numObservations: 9
action 2, numVisits=11, meanQ=22.996364, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 34891 episodes
GETTING ACTION FROM:
action 5, numVisits=35412, meanQ=27.798952, numObservations: 9
action 2, numVisits=11, meanQ=22.996364, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.660616 0.940724 0.855882 0.224379 0.321734 0.813949 0.598784 0.0484713 0.478337 0.424555 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 178
Initial state: 0 0.479564 0.300972 0.468965 0.0857525 0.622782 0.778842 0.463977 0.646166 0.830253 0.918752 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33006 episodes
GETTING ACTION FROM:
action 2, numVisits=33000, meanQ=38.565109, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.479564 0.300972 0.468965 0.0857525 0.622782 0.778842 0.463977 0.646166 0.830253 0.918752 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=1859, meanQ=42.714345, numObservations: 9
action 3, numVisits=56, meanQ=40.661252, numObservations: 9
action 1, numVisits=8, meanQ=35.373750, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 11957 episodes
GETTING ACTION FROM:
action 3, numVisits=10062, meanQ=43.149858, numObservations: 9
action 4, numVisits=3810, meanQ=41.226407, numObservations: 9
action 1, numVisits=8, meanQ=35.373750, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.479564 0.300972 0.468965 0.0857525 0.622782 0.778842 0.463977 0.646166 0.830253 0.918752 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 179
Initial state: 0 0.599573 0.546727 0.551567 0.849243 0.726351 0.0644324 0.370361 0.43994 0.142129 0.4835 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32517 episodes
GETTING ACTION FROM:
action 5, numVisits=32494, meanQ=38.682669, numObservations: 9
action 4, numVisits=15, meanQ=29.732667, numObservations: 8
action 2, numVisits=4, meanQ=-1.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.599573 0.546727 0.551567 0.849243 0.726351 0.0644324 0.370361 0.43994 0.142129 0.4835 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=2770, meanQ=43.990156, numObservations: 9
action 2, numVisits=22, meanQ=29.499095, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 36447 episodes
GETTING ACTION FROM:
action 3, numVisits=39217, meanQ=40.539844, numObservations: 9
action 2, numVisits=22, meanQ=29.499095, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.599573 0.546727 0.551567 0.849243 0.726351 0.0644324 0.370361 0.43994 0.142129 0.4835 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -110.99
Run # 180
Initial state: 0 0.0454037 0.853063 0.882763 0.204447 0.990613 0.26905 0.471757 0.304576 0.716377 0.98453 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32891 episodes
GETTING ACTION FROM:
action 3, numVisits=32864, meanQ=37.453472, numObservations: 9
action 2, numVisits=21, meanQ=19.903824, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.0454037 0.853063 0.882763 0.204447 0.990613 0.26905 0.471757 0.304576 0.716377 0.98453 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 181
Initial state: 0 0.45935 0.509502 0.364942 0.420895 0.215811 0.220944 0.798654 0.0160398 0.602425 0.0806858 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31089 episodes
GETTING ACTION FROM:
action 2, numVisits=31051, meanQ=41.360705, numObservations: 9
action 5, numVisits=25, meanQ=36.599204, numObservations: 8
action 3, numVisits=7, meanQ=26.142857, numObservations: 4
action 4, numVisits=3, meanQ=25.996667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.45935 0.509502 0.364942 0.420895 0.215811 0.220944 0.798654 0.0160398 0.602425 0.0806858 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 182
Initial state: 0 0.501021 0.299909 0.562928 0.585077 0.723978 0.881972 0.542526 0.923549 0.0899908 0.982279 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18020 episodes
GETTING ACTION FROM:
action 0, numVisits=18000, meanQ=64.859894, numObservations: 243
action -1, numVisits=13, meanQ=-1.010000, numObservations: 13
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.501021 0.299909 0.562928 0.585077 0.723978 0.881972 0.542526 0.923549 0.0899908 0.982279 w: 1
Observation: 0 0 1 0 3 0 3 0 3 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=69, meanQ=73.089138, numObservations: 9
action 1, numVisits=6, meanQ=47.498333, numObservations: 3
action 5, numVisits=6, meanQ=47.498333, numObservations: 5
action 4, numVisits=2, meanQ=44.495000, numObservations: 2
action 3, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 30373 episodes
GETTING ACTION FROM:
action 2, numVisits=30442, meanQ=70.303162, numObservations: 9
action 1, numVisits=6, meanQ=47.498333, numObservations: 3
action 5, numVisits=6, meanQ=47.498333, numObservations: 5
action 4, numVisits=2, meanQ=44.495000, numObservations: 2
action 3, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.501021 0.299909 0.562928 0.585077 0.723978 0.881972 0.542526 0.923549 0.0899908 0.982279 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 183
Initial state: 0 0.344392 0.431534 0.855661 0.849899 0.992867 0.792323 0.860432 0.726257 0.207942 0.705054 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31794 episodes
GETTING ACTION FROM:
action 1, numVisits=31775, meanQ=39.723998, numObservations: 9
action 2, numVisits=5, meanQ=19.000000, numObservations: 4
action 4, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=4, meanQ=-6.249975, numObservations: 3
action 5, numVisits=4, meanQ=-6.249975, numObservations: 3
action: 1
Next state: 1 0.344392 0.431534 0.855661 0.849899 0.992867 0.792323 0.860432 0.726257 0.207942 0.705054 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 184
Initial state: 0 0.951072 0.448458 0.0999135 0.429198 0.991183 0.335113 0.866077 0.632185 0.509973 0.368899 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31768 episodes
GETTING ACTION FROM:
action 1, numVisits=31748, meanQ=39.225489, numObservations: 9
action 3, numVisits=6, meanQ=29.000000, numObservations: 5
action 2, numVisits=7, meanQ=26.142857, numObservations: 5
action 4, numVisits=4, meanQ=21.500000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.951072 0.448458 0.0999135 0.429198 0.991183 0.335113 0.866077 0.632185 0.509973 0.368899 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 185
Initial state: 0 0.488567 0.320193 0.186496 0.896614 0.121111 0.274048 0.875968 0.471283 0.292258 0.869658 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32736 episodes
GETTING ACTION FROM:
action 5, numVisits=32728, meanQ=38.781182, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.488567 0.320193 0.186496 0.896614 0.121111 0.274048 0.875968 0.471283 0.292258 0.869658 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=2792, meanQ=46.739229, numObservations: 9
action 3, numVisits=7, meanQ=10.427157, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 35009 episodes
GETTING ACTION FROM:
action 1, numVisits=37801, meanQ=46.564362, numObservations: 9
action 3, numVisits=7, meanQ=10.427157, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.488567 0.320193 0.186496 0.896614 0.121111 0.274048 0.875968 0.471283 0.292258 0.869658 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 186
Initial state: 0 0.950226 0.423632 0.982744 0.845251 0.331123 0.43024 0.623979 0.200708 0.869985 0.0305623 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18068 episodes
GETTING ACTION FROM:
action 0, numVisits=18050, meanQ=65.205200, numObservations: 243
action -1, numVisits=11, meanQ=-2.181800, numObservations: 9
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=3, meanQ=-34.333333, numObservations: 2
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.950226 0.423632 0.982744 0.845251 0.331123 0.43024 0.623979 0.200708 0.869985 0.0305623 w: 1
Observation: 0 0 1 0 3 0 2 0 1 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=32, meanQ=75.280316, numObservations: 8
action 2, numVisits=15, meanQ=63.467333, numObservations: 4
action 5, numVisits=2, meanQ=44.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37512 episodes
GETTING ACTION FROM:
action 3, numVisits=37544, meanQ=80.043702, numObservations: 9
action 2, numVisits=15, meanQ=63.467333, numObservations: 4
action 5, numVisits=2, meanQ=44.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.950226 0.423632 0.982744 0.845251 0.331123 0.43024 0.623979 0.200708 0.869985 0.0305623 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 187
Initial state: 0 0.0631696 0.145431 0.0547763 0.706155 0.819415 0.904225 0.422611 0.428217 0.79805 0.989615 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32753 episodes
GETTING ACTION FROM:
action 1, numVisits=32744, meanQ=38.895585, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.0631696 0.145431 0.0547763 0.706155 0.819415 0.904225 0.422611 0.428217 0.79805 0.989615 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1775, meanQ=45.206573, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 13269 episodes
GETTING ACTION FROM:
action 2, numVisits=15044, meanQ=37.872967, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.0631696 0.145431 0.0547763 0.706155 0.819415 0.904225 0.422611 0.428217 0.79805 0.989615 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=985, meanQ=57.755304, numObservations: 9
action 3, numVisits=26, meanQ=31.463465, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 24171 episodes
GETTING ACTION FROM:
action 5, numVisits=25156, meanQ=55.938750, numObservations: 9
action 3, numVisits=26, meanQ=31.463465, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 5
Next state: 1 0.0631696 0.145431 0.0547763 0.706155 0.819415 0.904225 0.422611 0.428217 0.79805 0.989615 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 75.1399
Run # 188
Initial state: 0 0.364374 0.428601 0.455088 0.595089 0.887743 0.292082 0.645862 0.653031 0.811311 0.803759 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32827 episodes
GETTING ACTION FROM:
action 3, numVisits=32816, meanQ=38.053654, numObservations: 9
action 2, numVisits=6, meanQ=12.001667, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.364374 0.428601 0.455088 0.595089 0.887743 0.292082 0.645862 0.653031 0.811311 0.803759 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 189
Initial state: 0 0.984504 0.982262 0.481614 0.998497 0.444204 0.604706 0.387604 0.4322 0.287711 0.490593 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31397 episodes
GETTING ACTION FROM:
action 3, numVisits=31385, meanQ=40.237990, numObservations: 9
action 5, numVisits=6, meanQ=14.000000, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.984504 0.982262 0.481614 0.998497 0.444204 0.604706 0.387604 0.4322 0.287711 0.490593 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 190
Initial state: 0 0.436006 0.41901 0.2346 0.82065 0.73628 0.131257 0.608367 0.235496 0.941203 0.555948 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32556 episodes
GETTING ACTION FROM:
action 3, numVisits=32509, meanQ=38.561768, numObservations: 9
action 2, numVisits=15, meanQ=30.266667, numObservations: 7
action 5, numVisits=28, meanQ=28.999650, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.436006 0.41901 0.2346 0.82065 0.73628 0.131257 0.608367 0.235496 0.941203 0.555948 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 191
Initial state: 0 0.919653 0.710422 0.501634 0.438991 0.332148 0.504674 0.161866 0.883823 0.655269 0.756494 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31753 episodes
GETTING ACTION FROM:
action 2, numVisits=31742, meanQ=39.754375, numObservations: 9
action 4, numVisits=3, meanQ=25.996667, numObservations: 3
action 1, numVisits=4, meanQ=-1.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.919653 0.710422 0.501634 0.438991 0.332148 0.504674 0.161866 0.883823 0.655269 0.756494 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 192
Initial state: 0 0.449294 0.339442 0.639127 0.0227663 0.451371 0.950673 0.862724 0.585707 0.310857 0.595157 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18174 episodes
GETTING ACTION FROM:
action -1, numVisits=18148, meanQ=56.127097, numObservations: 243
action 0, numVisits=19, meanQ=-1.114732, numObservations: 18
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=3, meanQ=-34.333333, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.449294 0.339442 0.639127 0.0227663 0.451371 0.950673 0.862724 0.585707 0.310857 0.595157 w: 1
Observation: 0 2 0 3 0 2 0 3 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=89, meanQ=51.113825, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 36735 episodes
GETTING ACTION FROM:
action 1, numVisits=36824, meanQ=54.036694, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.449294 0.339442 0.639127 0.0227663 0.451371 0.950673 0.862724 0.585707 0.310857 0.595157 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 193
Initial state: 0 0.5265 0.265892 0.263293 0.329347 0.946355 0.578461 0.61667 0.76351 0.349282 0.407032 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32959 episodes
GETTING ACTION FROM:
action 4, numVisits=32938, meanQ=39.079063, numObservations: 9
action 5, numVisits=4, meanQ=21.747500, numObservations: 4
action 1, numVisits=5, meanQ=19.000000, numObservations: 4
action 2, numVisits=9, meanQ=10.111111, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.5265 0.265892 0.263293 0.329347 0.946355 0.578461 0.61667 0.76351 0.349282 0.407032 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 194
Initial state: 0 0.703957 0.0468732 0.497194 0.367723 0.604662 0.264106 0.11006 0.153783 0.42101 0.586504 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31841 episodes
GETTING ACTION FROM:
action 3, numVisits=31834, meanQ=39.531689, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.703957 0.0468732 0.497194 0.367723 0.604662 0.264106 0.11006 0.153783 0.42101 0.586504 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 195
Initial state: 0 0.253896 0.499978 0.418036 0.401918 0.069397 0.772369 0.878299 0.859574 0.345002 0.64646 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32673 episodes
GETTING ACTION FROM:
action 2, numVisits=32646, meanQ=37.445443, numObservations: 9
action 4, numVisits=14, meanQ=29.712857, numObservations: 8
action 3, numVisits=4, meanQ=21.747500, numObservations: 4
action 1, numVisits=5, meanQ=19.000000, numObservations: 3
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.253896 0.499978 0.418036 0.401918 0.069397 0.772369 0.878299 0.859574 0.345002 0.64646 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 196
Initial state: 0 0.878594 0.47773 0.556249 0.0612428 0.342041 0.352587 0.888314 0.255793 0.594488 0.0333058 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32037 episodes
GETTING ACTION FROM:
action 3, numVisits=32013, meanQ=37.680551, numObservations: 9
action -1, numVisits=10, meanQ=-1.010000, numObservations: 10
action 0, numVisits=10, meanQ=-1.010000, numObservations: 10
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.878594 0.47773 0.556249 0.0612428 0.342041 0.352587 0.888314 0.255793 0.594488 0.0333058 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 197
Initial state: 0 0.46586 0.56133 0.588268 0.332957 0.420983 0.357825 0.174884 0.466048 0.769525 0.695418 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32715 episodes
GETTING ACTION FROM:
action 3, numVisits=32705, meanQ=38.025573, numObservations: 9
action 1, numVisits=4, meanQ=21.500000, numObservations: 4
action 4, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.46586 0.56133 0.588268 0.332957 0.420983 0.357825 0.174884 0.466048 0.769525 0.695418 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 198
Initial state: 0 0.264463 0.279752 0.789762 0.606882 0.238836 0.506503 0.511042 0.403531 0.876632 0.6378 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31263 episodes
GETTING ACTION FROM:
action 1, numVisits=31249, meanQ=39.432805, numObservations: 9
action 2, numVisits=9, meanQ=7.888889, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.264463 0.279752 0.789762 0.606882 0.238836 0.506503 0.511042 0.403531 0.876632 0.6378 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=1654, meanQ=42.613007, numObservations: 9
action 3, numVisits=14, meanQ=18.497857, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 12541 episodes
GETTING ACTION FROM:
action 4, numVisits=14195, meanQ=31.517220, numObservations: 9
action 3, numVisits=14, meanQ=18.497857, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.264463 0.279752 0.789762 0.606882 0.238836 0.506503 0.511042 0.403531 0.876632 0.6378 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 199
Initial state: 0 0.636706 0.324253 0.108102 0.0891314 0.466546 0.715444 0.34983 0.40483 0.711654 0.925026 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32998 episodes
GETTING ACTION FROM:
action 1, numVisits=32636, meanQ=37.656067, numObservations: 9
action 3, numVisits=356, meanQ=28.103369, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.636706 0.324253 0.108102 0.0891314 0.466546 0.715444 0.34983 0.40483 0.711654 0.925026 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 200
Initial state: 0 0.28617 0.125992 0.762945 0.71004 0.829512 0.200157 0.337921 0.416256 0.755575 0.513287 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32735 episodes
GETTING ACTION FROM:
action 4, numVisits=32713, meanQ=39.214845, numObservations: 9
action 3, numVisits=15, meanQ=35.732667, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.28617 0.125992 0.762945 0.71004 0.829512 0.200157 0.337921 0.416256 0.755575 0.513287 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
[32m ProblemEnvironment.hpp 351: Done.[39m
