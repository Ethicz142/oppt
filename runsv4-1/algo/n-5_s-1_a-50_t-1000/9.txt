Run # 1
Initial state: 0 0.882869 0.366972 0.89036 0.836778 0.842182 0.52658 0.886917 0.300398 0.324506 0.529791 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18068 episodes
GETTING ACTION FROM:
action 0, numVisits=18038, meanQ=63.923870, numObservations: 243
action -1, numVisits=20, meanQ=-1.554995, numObservations: 19
action 4, numVisits=4, meanQ=-28.500000, numObservations: 4
action 5, numVisits=3, meanQ=-34.333333, numObservations: 2
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.882869 0.366972 0.89036 0.836778 0.842182 0.52658 0.886917 0.300398 0.324506 0.529791 w: 1
Observation: 0 0 1 0 3 0 2 0 1 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=61, meanQ=43.545252, numObservations: 8
action 3, numVisits=10, meanQ=26.297000, numObservations: 7
action 2, numVisits=6, meanQ=14.165000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=3, meanQ=-4.003333, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 35547 episodes
GETTING ACTION FROM:
action 5, numVisits=35608, meanQ=59.585624, numObservations: 9
action 3, numVisits=10, meanQ=26.297000, numObservations: 7
action 2, numVisits=6, meanQ=14.165000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=3, meanQ=-4.003333, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.882869 0.366972 0.89036 0.836778 0.842182 0.52658 0.886917 0.300398 0.324506 0.529791 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 2
Initial state: 0 0.419151 0.690535 0.618149 0.583864 0.259714 0.453711 0.350802 0.580939 0.357293 0.255377 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17806 episodes
GETTING ACTION FROM:
action -1, numVisits=17764, meanQ=53.362388, numObservations: 243
action 0, numVisits=6, meanQ=-1.341650, numObservations: 5
action 4, numVisits=28, meanQ=-3.928918, numObservations: 9
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action 5, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.419151 0.690535 0.618149 0.583864 0.259714 0.453711 0.350802 0.580939 0.357293 0.255377 w: 1
Observation: 0 3 0 3 0 2 0 2 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=44, meanQ=42.211600, numObservations: 18
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action 4, numVisits=8, meanQ=-1.000000, numObservations: 5
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 3, numVisits=6, meanQ=-4.003333, numObservations: 4
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 18078 episodes
GETTING ACTION FROM:
action -1, numVisits=18122, meanQ=52.045949, numObservations: 200
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action 4, numVisits=8, meanQ=-1.000000, numObservations: 5
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 3, numVisits=6, meanQ=-4.003333, numObservations: 4
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: -1
Next state: 0 0.419151 0.690535 0.618149 0.583864 0.259714 0.453711 0.350802 0.580939 0.357293 0.255377 w: 1
Observation: 0 3 0 3 0 1 0 2 0 2 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=185, meanQ=49.051528, numObservations: 9
action 4, numVisits=5, meanQ=37.198000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 24906 episodes
GETTING ACTION FROM:
action 5, numVisits=25091, meanQ=50.780007, numObservations: 9
action 4, numVisits=5, meanQ=37.198000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.419151 0.690535 0.618149 0.583864 0.259714 0.453711 0.350802 0.580939 0.357293 0.255377 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 4, numVisits=642, meanQ=78.094519, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 31510 episodes
GETTING ACTION FROM:
action 4, numVisits=32152, meanQ=75.130315, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.419151 0.690535 0.618149 0.583864 0.259714 0.453711 0.350802 0.580939 0.357293 0.255377 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 81.2985
Run # 3
Initial state: 0 0.168082 0.416876 0.605184 0.559706 0.199204 0.700293 0.380428 0.428961 0.793282 0.382029 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18308 episodes
GETTING ACTION FROM:
action 0, numVisits=18268, meanQ=64.051827, numObservations: 243
action -1, numVisits=22, meanQ=-1.190000, numObservations: 20
action 3, numVisits=14, meanQ=-2.428571, numObservations: 6
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.168082 0.416876 0.605184 0.559706 0.199204 0.700293 0.380428 0.428961 0.793282 0.382029 w: 1
Observation: 0 0 1 0 2 0 3 0 2 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=66, meanQ=46.455914, numObservations: 9
action 3, numVisits=2, meanQ=44.495000, numObservations: 2
action 2, numVisits=14, meanQ=40.570000, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 36117 episodes
GETTING ACTION FROM:
action 4, numVisits=36182, meanQ=56.157335, numObservations: 9
action 2, numVisits=14, meanQ=40.570000, numObservations: 7
action 3, numVisits=3, meanQ=25.996667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.168082 0.416876 0.605184 0.559706 0.199204 0.700293 0.380428 0.428961 0.793282 0.382029 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 4
Initial state: 0 0.334626 0.0177008 0.314278 0.597455 0.0461122 0.150807 0.0133333 0.197895 0.329493 0.556839 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31302 episodes
GETTING ACTION FROM:
action 1, numVisits=31249, meanQ=24.401478, numObservations: 9
action 2, numVisits=32, meanQ=-2.616853, numObservations: 9
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=8, meanQ=-13.632500, numObservations: 7
action 4, numVisits=6, meanQ=-19.333333, numObservations: 4
action -1, numVisits=5, meanQ=-21.206000, numObservations: 4
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.334626 0.0177008 0.314278 0.597455 0.0461122 0.150807 0.0133333 0.197895 0.329493 0.556839 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 5
Initial state: 0 0.275787 0.956562 0.637051 0.059845 0.377104 0.534523 0.559305 0.559446 0.475719 0.652031 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32027 episodes
GETTING ACTION FROM:
action 1, numVisits=32013, meanQ=23.209975, numObservations: 9
action 2, numVisits=9, meanQ=17.998889, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.275787 0.956562 0.637051 0.059845 0.377104 0.534523 0.559305 0.559446 0.475719 0.652031 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 6
Initial state: 0 0.595649 0.430025 0.349957 0.526277 0.663223 0.0264527 0.718887 0.975747 0.202556 0.33636 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33043 episodes
GETTING ACTION FROM:
action 2, numVisits=33028, meanQ=23.004046, numObservations: 9
action 1, numVisits=10, meanQ=8.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.595649 0.430025 0.349957 0.526277 0.663223 0.0264527 0.718887 0.975747 0.202556 0.33636 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 7
Initial state: 0 0.746274 0.29382 0.389751 0.518912 0.0174667 0.166702 0.980325 0.1189 0.402083 0.902797 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32445 episodes
GETTING ACTION FROM:
action 1, numVisits=32359, meanQ=24.745396, numObservations: 9
action 3, numVisits=70, meanQ=13.414287, numObservations: 9
action 5, numVisits=12, meanQ=4.833333, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.746274 0.29382 0.389751 0.518912 0.0174667 0.166702 0.980325 0.1189 0.402083 0.902797 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 8
Initial state: 0 0.13007 0.338255 0.35058 0.496664 0.0856342 0.449269 0.284122 0.562241 0.267987 0.581709 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32320 episodes
GETTING ACTION FROM:
action 4, numVisits=32269, meanQ=23.032293, numObservations: 9
action 2, numVisits=44, meanQ=19.183416, numObservations: 8
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.13007 0.338255 0.35058 0.496664 0.0856342 0.449269 0.284122 0.562241 0.267987 0.581709 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 9
Initial state: 0 0.680892 0.158275 0.0350797 0.219558 0.391432 0.506908 0.503572 0.597524 0.847622 0.638903 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32569 episodes
GETTING ACTION FROM:
action 1, numVisits=32541, meanQ=22.485900, numObservations: 9
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action 3, numVisits=13, meanQ=-5.533062, numObservations: 6
action 4, numVisits=3, meanQ=-34.333333, numObservations: 3
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.680892 0.158275 0.0350797 0.219558 0.391432 0.506908 0.503572 0.597524 0.847622 0.638903 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 10
Initial state: 0 0.812069 0.233892 0.0424568 0.746897 0.132196 0.948423 0.353566 0.524672 0.0483211 0.988047 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18016 episodes
GETTING ACTION FROM:
action -1, numVisits=17993, meanQ=51.702759, numObservations: 243
action 0, numVisits=12, meanQ=-9.425000, numObservations: 11
action 3, numVisits=5, meanQ=-24.802000, numObservations: 3
action 5, numVisits=3, meanQ=-34.333333, numObservations: 2
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.812069 0.233892 0.0424568 0.746897 0.132196 0.948423 0.353566 0.524672 0.0483211 0.988047 w: 1
Observation: 0 3 0 1 0 1 0 2 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=43, meanQ=46.496617, numObservations: 7
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 25711 episodes
GETTING ACTION FROM:
action 2, numVisits=25754, meanQ=32.585843, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 2
Next state: 1 0.812069 0.233892 0.0424568 0.746897 0.132196 0.948423 0.353566 0.524672 0.0483211 0.988047 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 11
Initial state: 0 0.991266 0.95245 0.945506 0.988598 0.789378 0.231402 0.753551 0.571865 0.402338 0.541058 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32685 episodes
GETTING ACTION FROM:
action 4, numVisits=32616, meanQ=22.794166, numObservations: 9
action 1, numVisits=64, meanQ=13.333286, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.991266 0.95245 0.945506 0.988598 0.789378 0.231402 0.753551 0.571865 0.402338 0.541058 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 12
Initial state: 0 0.414538 0.113754 0.206965 0.241689 0.38008 0.443865 0.987546 0.0872169 0.896641 0.0820621 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32630 episodes
GETTING ACTION FROM:
action 2, numVisits=32609, meanQ=23.785652, numObservations: 9
action 5, numVisits=9, meanQ=8.108889, numObservations: 6
action 3, numVisits=8, meanQ=5.012512, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.414538 0.113754 0.206965 0.241689 0.38008 0.443865 0.987546 0.0872169 0.896641 0.0820621 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 13
Initial state: 0 0.768943 0.0426955 0.403053 0.549926 0.14705 0.895851 0.443071 0.870764 0.976008 0.371205 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32541 episodes
GETTING ACTION FROM:
action 2, numVisits=32532, meanQ=22.272749, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.768943 0.0426955 0.403053 0.549926 0.14705 0.895851 0.443071 0.870764 0.976008 0.371205 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 14
Initial state: 0 0.232846 0.633188 0.716932 0.16701 0.656893 0.942074 0.83733 0.145969 0.355053 0.516771 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32107 episodes
GETTING ACTION FROM:
action 3, numVisits=32089, meanQ=23.862867, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 2, numVisits=7, meanQ=-2.428571, numObservations: 5
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=3, meanQ=-34.333333, numObservations: 3
action: 3
Next state: 1 0.232846 0.633188 0.716932 0.16701 0.656893 0.942074 0.83733 0.145969 0.355053 0.516771 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 15
Initial state: 0 0.500408 0.666963 0.581828 0.840399 0.361706 0.450219 0.991193 0.31485 0.503641 0.265057 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31532 episodes
GETTING ACTION FROM:
action 2, numVisits=31526, meanQ=24.585376, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.500408 0.666963 0.581828 0.840399 0.361706 0.450219 0.991193 0.31485 0.503641 0.265057 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 16
Initial state: 0 0.0139347 0.0373801 0.444506 0.972398 0.712074 0.360406 0.399303 0.464008 0.756976 0.104603 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32519 episodes
GETTING ACTION FROM:
action 5, numVisits=32496, meanQ=22.421058, numObservations: 9
action 4, numVisits=10, meanQ=4.000000, numObservations: 8
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=8, meanQ=-1.000000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.0139347 0.0373801 0.444506 0.972398 0.712074 0.360406 0.399303 0.464008 0.756976 0.104603 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 17
Initial state: 0 0.309168 0.465356 0.141112 0.964455 0.577697 0.536382 0.0661637 0.639614 0.401641 0.90953 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17823 episodes
GETTING ACTION FROM:
action -1, numVisits=17791, meanQ=55.505170, numObservations: 243
action 0, numVisits=23, meanQ=-1.010000, numObservations: 23
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=5, meanQ=-21.000000, numObservations: 4
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.309168 0.465356 0.141112 0.964455 0.577697 0.536382 0.0661637 0.639614 0.401641 0.90953 w: 1
Observation: 0 2 0 1 0 3 0 1 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=39, meanQ=29.567700, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 36451 episodes
GETTING ACTION FROM:
action 1, numVisits=36490, meanQ=39.466160, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.309168 0.465356 0.141112 0.964455 0.577697 0.536382 0.0661637 0.639614 0.401641 0.90953 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=1267, meanQ=79.775983, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 41393 episodes
GETTING ACTION FROM:
action 1, numVisits=42660, meanQ=89.733995, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.309168 0.465356 0.141112 0.964455 0.577697 0.536382 0.0661637 0.639614 0.401641 0.90953 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 84.1399
Run # 18
Initial state: 0 0.273844 0.850037 0.793273 0.691425 0.36326 0.228336 0.30176 0.457431 0.326282 0.0546888 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31016 episodes
GETTING ACTION FROM:
action 3, numVisits=30975, meanQ=24.217074, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 5, numVisits=34, meanQ=-1.347932, numObservations: 8
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.273844 0.850037 0.793273 0.691425 0.36326 0.228336 0.30176 0.457431 0.326282 0.0546888 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=491, meanQ=36.890948, numObservations: 153
action 2, numVisits=5, meanQ=-2.802000, numObservations: 4
action -1, numVisits=19, meanQ=-6.324737, numObservations: 18
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 25726 episodes
GETTING ACTION FROM:
action 0, numVisits=26217, meanQ=6.199777, numObservations: 243
action 2, numVisits=5, meanQ=-2.802000, numObservations: 4
action -1, numVisits=19, meanQ=-6.324737, numObservations: 18
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.273844 0.850037 0.793273 0.691425 0.36326 0.228336 0.30176 0.457431 0.326282 0.0546888 w: 1
Observation: 0 0 3 0 3 0 1 0 2 0 1 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action -1, numVisits=5, meanQ=18.394000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 3, numVisits=5, meanQ=-6.406000, numObservations: 5
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 29312 episodes
GETTING ACTION FROM:
action -1, numVisits=29313, meanQ=6.890846, numObservations: 241
action 0, numVisits=8, meanQ=-1.381250, numObservations: 6
action 3, numVisits=5, meanQ=-6.406000, numObservations: 5
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.273844 0.850037 0.793273 0.691425 0.36326 0.228336 0.30176 0.457431 0.326282 0.0546888 w: 1
Observation: 0 1 0 3 0 2 0 2 0 1 0 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 62086 episodes
GETTING ACTION FROM:
action 2, numVisits=62073, meanQ=78.650818, numObservations: 9
action 4, numVisits=7, meanQ=41.857143, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-2.000000, numObservations: 1
action 0, numVisits=1, meanQ=-2.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.273844 0.850037 0.793273 0.691425 0.36326 0.228336 0.30176 0.457431 0.326282 0.0546888 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 81.1194
Run # 19
Initial state: 0 0.85763 0.583415 0.773917 0.118751 0.0506187 0.902338 0.109401 0.675646 0.407095 0.42087 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31447 episodes
GETTING ACTION FROM:
action 2, numVisits=31431, meanQ=23.597374, numObservations: 9
action 3, numVisits=5, meanQ=14.800020, numObservations: 3
action 4, numVisits=7, meanQ=13.285714, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.85763 0.583415 0.773917 0.118751 0.0506187 0.902338 0.109401 0.675646 0.407095 0.42087 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 20
Initial state: 0 0.042411 0.0815409 0.538581 0.420632 0.395394 0.523099 0.287858 0.206452 0.0135704 0.058905 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31241 episodes
GETTING ACTION FROM:
action 3, numVisits=31201, meanQ=23.997526, numObservations: 9
action 1, numVisits=28, meanQ=0.431789, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 4, numVisits=6, meanQ=-4.333333, numObservations: 5
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.042411 0.0815409 0.538581 0.420632 0.395394 0.523099 0.287858 0.206452 0.0135704 0.058905 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 21
Initial state: 0 0.847946 0.90088 0.31473 0.52058 0.734024 0.0431047 0.474494 0.452366 0.152852 0.688505 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32724 episodes
GETTING ACTION FROM:
action 5, numVisits=32709, meanQ=22.860255, numObservations: 9
action 3, numVisits=7, meanQ=10.570000, numObservations: 6
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.847946 0.90088 0.31473 0.52058 0.734024 0.0431047 0.474494 0.452366 0.152852 0.688505 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1960, meanQ=27.192994, numObservations: 9
action 4, numVisits=26, meanQ=14.540777, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 35107 episodes
GETTING ACTION FROM:
action 2, numVisits=37067, meanQ=33.659226, numObservations: 9
action 4, numVisits=26, meanQ=14.540777, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 2
Next state: 1 0.847946 0.90088 0.31473 0.52058 0.734024 0.0431047 0.474494 0.452366 0.152852 0.688505 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 22
Initial state: 0 0.736408 0.224041 0.806742 0.457429 0.0826731 0.812937 0.674119 0.030952 0.352617 0.572948 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31817 episodes
GETTING ACTION FROM:
action 4, numVisits=31806, meanQ=22.796571, numObservations: 9
action 3, numVisits=5, meanQ=19.000000, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.736408 0.224041 0.806742 0.457429 0.0826731 0.812937 0.674119 0.030952 0.352617 0.572948 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 23
Initial state: 0 0.302101 0.720575 0.0322158 0.537161 0.30215 0.30892 0.755653 0.713828 0.317796 0.421655 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32442 episodes
GETTING ACTION FROM:
action 2, numVisits=32435, meanQ=22.991184, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.302101 0.720575 0.0322158 0.537161 0.30215 0.30892 0.755653 0.713828 0.317796 0.421655 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=906, meanQ=51.576636, numObservations: 176
action 0, numVisits=14, meanQ=-1.152136, numObservations: 13
action 5, numVisits=11, meanQ=-1.819091, numObservations: 6
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 5782 episodes
GETTING ACTION FROM:
action -1, numVisits=6688, meanQ=34.438548, numObservations: 239
action 0, numVisits=14, meanQ=-1.152136, numObservations: 13
action 5, numVisits=11, meanQ=-1.819091, numObservations: 6
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action: -1
Next state: 0 0.302101 0.720575 0.0322158 0.537161 0.30215 0.30892 0.755653 0.713828 0.317796 0.421655 w: 1
Observation: 0 2 0 1 0 2 0 3 0 2 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=18, meanQ=59.112993, numObservations: 6
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 23634 episodes
GETTING ACTION FROM:
action 5, numVisits=23652, meanQ=29.101667, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.302101 0.720575 0.0322158 0.537161 0.30215 0.30892 0.755653 0.713828 0.317796 0.421655 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 84.0499
Run # 24
Initial state: 0 0.351694 0.553565 0.486827 0.138673 0.744314 0.516423 0.0137068 0.00163927 0.738676 0.97671 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32229 episodes
GETTING ACTION FROM:
action 4, numVisits=32152, meanQ=24.862669, numObservations: 9
action -1, numVisits=38, meanQ=-1.114732, numObservations: 36
action 0, numVisits=33, meanQ=-4.130300, numObservations: 31
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=3, meanQ=-34.333333, numObservations: 2
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.351694 0.553565 0.486827 0.138673 0.744314 0.516423 0.0137068 0.00163927 0.738676 0.97671 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=2433, meanQ=29.455198, numObservations: 9
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=3, meanQ=-34.333333, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 10122 episodes
GETTING ACTION FROM:
action 5, numVisits=12555, meanQ=24.244926, numObservations: 9
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=3, meanQ=-34.333333, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.351694 0.553565 0.486827 0.138673 0.744314 0.516423 0.0137068 0.00163927 0.738676 0.97671 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 25
Initial state: 0 0.0760803 0.115964 0.409805 0.556656 0.140837 0.288569 0.357333 0.912283 0.791742 0.621939 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32981 episodes
GETTING ACTION FROM:
action 5, numVisits=32964, meanQ=23.527094, numObservations: 9
action 1, numVisits=12, meanQ=5.500833, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.0760803 0.115964 0.409805 0.556656 0.140837 0.288569 0.357333 0.912283 0.791742 0.621939 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 26
Initial state: 0 0.355187 0.55019 0.908256 0.709138 0.234667 0.273967 0.109171 0.364003 0.0254495 0.283436 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31115 episodes
GETTING ACTION FROM:
action 4, numVisits=31070, meanQ=23.791216, numObservations: 9
action 2, numVisits=32, meanQ=17.974694, numObservations: 8
action 3, numVisits=8, meanQ=7.997500, numObservations: 7
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.355187 0.55019 0.908256 0.709138 0.234667 0.273967 0.109171 0.364003 0.0254495 0.283436 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 27
Initial state: 0 0.325217 0.825117 0.0873803 0.593557 0.36805 0.536005 0.0444145 0.0235417 0.497821 0.0220327 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31832 episodes
GETTING ACTION FROM:
action 2, numVisits=31011, meanQ=25.216406, numObservations: 9
action 1, numVisits=812, meanQ=23.629619, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=3, meanQ=-4.333333, numObservations: 2
action: 2
Next state: 0 0.325217 0.825117 0.0873803 0.593557 0.36805 0.536005 0.0444145 0.0235417 0.497821 0.0220327 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=262, meanQ=25.351628, numObservations: 9
action 1, numVisits=16, meanQ=22.873750, numObservations: 8
action 5, numVisits=4, meanQ=17.242500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 27545 episodes
GETTING ACTION FROM:
action 3, numVisits=27805, meanQ=33.588957, numObservations: 9
action 1, numVisits=18, meanQ=20.221111, numObservations: 8
action 5, numVisits=4, meanQ=17.242500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.325217 0.825117 0.0873803 0.593557 0.36805 0.536005 0.0444145 0.0235417 0.497821 0.0220327 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 28
Initial state: 0 0.387921 0.57024 0.0142828 0.768595 0.643876 0.00693314 0.425493 0.708231 0.876524 0.959915 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17956 episodes
GETTING ACTION FROM:
action -1, numVisits=17824, meanQ=58.498476, numObservations: 243
action 0, numVisits=123, meanQ=-0.970722, numObservations: 98
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=3, meanQ=-34.333333, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.387921 0.57024 0.0142828 0.768595 0.643876 0.00693314 0.425493 0.708231 0.876524 0.959915 w: 1
Observation: 0 2 0 2 0 3 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=126, meanQ=48.237266, numObservations: 32
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=3, meanQ=-34.333333, numObservations: 2
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 18227 episodes
GETTING ACTION FROM:
action -1, numVisits=18353, meanQ=58.513523, numObservations: 183
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=3, meanQ=-34.333333, numObservations: 2
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.387921 0.57024 0.0142828 0.768595 0.643876 0.00693314 0.425493 0.708231 0.876524 0.959915 w: 1
Observation: 0 2 0 1 0 3 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=1286, meanQ=37.738472, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 27070 episodes
GETTING ACTION FROM:
action 2, numVisits=28356, meanQ=46.322340, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.387921 0.57024 0.0142828 0.768595 0.643876 0.00693314 0.425493 0.708231 0.876524 0.959915 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=442, meanQ=89.930083, numObservations: 8
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 36060 episodes
GETTING ACTION FROM:
action 1, numVisits=36502, meanQ=85.983499, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.387921 0.57024 0.0142828 0.768595 0.643876 0.00693314 0.425493 0.708231 0.876524 0.959915 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 81.2985
Run # 29
Initial state: 0 0.403087 0.481446 0.473318 0.3519 0.870599 0.092843 0.408505 0.163235 0.250295 0.245604 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32972 episodes
GETTING ACTION FROM:
action 3, numVisits=32957, meanQ=23.820284, numObservations: 9
action 2, numVisits=6, meanQ=14.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=5, meanQ=-3.000000, numObservations: 4
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.403087 0.481446 0.473318 0.3519 0.870599 0.092843 0.408505 0.163235 0.250295 0.245604 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 30
Initial state: 0 0.750042 0.37174 0.317739 0.432143 0.293687 0.856328 0.559398 0.93289 0.96602 0.355417 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31196 episodes
GETTING ACTION FROM:
action 3, numVisits=31187, meanQ=23.091139, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.750042 0.37174 0.317739 0.432143 0.293687 0.856328 0.559398 0.93289 0.96602 0.355417 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 31
Initial state: 0 0.664045 0.913748 0.311146 0.498132 0.81538 0.668664 0.949024 0.643529 0.685785 0.376661 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17800 episodes
GETTING ACTION FROM:
action -1, numVisits=17730, meanQ=54.611038, numObservations: 243
action 0, numVisits=42, meanQ=-3.461664, numObservations: 40
action 3, numVisits=20, meanQ=-3.698500, numObservations: 5
action 5, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=3, meanQ=-34.333333, numObservations: 3
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.664045 0.913748 0.311146 0.498132 0.81538 0.668664 0.949024 0.643529 0.685785 0.376661 w: 1
Observation: 0 2 0 2 0 1 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=61, meanQ=32.837992, numObservations: 26
action 0, numVisits=10, meanQ=-1.010000, numObservations: 10
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 17431 episodes
GETTING ACTION FROM:
action -1, numVisits=17492, meanQ=68.299026, numObservations: 201
action 0, numVisits=10, meanQ=-1.010000, numObservations: 10
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.664045 0.913748 0.311146 0.498132 0.81538 0.668664 0.949024 0.643529 0.685785 0.376661 w: 1
Observation: 0 3 0 3 0 3 0 3 0 2 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=1, meanQ=99.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 39315 episodes
GETTING ACTION FROM:
action 2, numVisits=39311, meanQ=50.833948, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.664045 0.913748 0.311146 0.498132 0.81538 0.668664 0.949024 0.643529 0.685785 0.376661 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 93.0499
Run # 32
Initial state: 0 0.46457 0.268366 0.548903 0.764501 0.578376 0.0537302 0.347353 0.523131 0.739732 0.517931 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31378 episodes
GETTING ACTION FROM:
action 3, numVisits=31369, meanQ=24.973168, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.46457 0.268366 0.548903 0.764501 0.578376 0.0537302 0.347353 0.523131 0.739732 0.517931 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 33
Initial state: 0 0.371915 0.53229 0.714725 0.069105 0.132287 0.200432 0.0411955 0.700014 0.919083 0.743927 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31549 episodes
GETTING ACTION FROM:
action 4, numVisits=31542, meanQ=24.353598, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.371915 0.53229 0.714725 0.069105 0.132287 0.200432 0.0411955 0.700014 0.919083 0.743927 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=568, meanQ=76.635252, numObservations: 9
action 3, numVisits=8, meanQ=49.000000, numObservations: 5
action 5, numVisits=2, meanQ=44.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 39895 episodes
GETTING ACTION FROM:
action 4, numVisits=40463, meanQ=86.781157, numObservations: 9
action 3, numVisits=8, meanQ=49.000000, numObservations: 5
action 5, numVisits=2, meanQ=44.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.371915 0.53229 0.714725 0.069105 0.132287 0.200432 0.0411955 0.700014 0.919083 0.743927 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=104, meanQ=24.048944, numObservations: 9
action 4, numVisits=8, meanQ=15.385013, numObservations: 4
action 5, numVisits=8, meanQ=10.373750, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=3, meanQ=-4.003333, numObservations: 2
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 34055 episodes
GETTING ACTION FROM:
action 4, numVisits=34033, meanQ=75.755937, numObservations: 9
action 3, numVisits=134, meanQ=15.851644, numObservations: 9
action 5, numVisits=8, meanQ=10.373750, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=3, meanQ=-4.003333, numObservations: 2
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.371915 0.53229 0.714725 0.069105 0.132287 0.200432 0.0411955 0.700014 0.919083 0.743927 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action -1, numVisits=3518, meanQ=77.335861, numObservations: 151
action 1, numVisits=6, meanQ=-7.006667, numObservations: 5
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 0, numVisits=3, meanQ=-34.670000, numObservations: 2
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 23770 episodes
GETTING ACTION FROM:
action -1, numVisits=27288, meanQ=30.077050, numObservations: 237
action 1, numVisits=6, meanQ=-7.006667, numObservations: 5
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 0, numVisits=3, meanQ=-34.670000, numObservations: 2
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.371915 0.53229 0.714725 0.069105 0.132287 0.200432 0.0411955 0.700014 0.919083 0.743927 w: 1
Observation: 0 2 0 3 0 1 0 1 0 3 0 
Immediate reward: -2
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 1, numVisits=25, meanQ=44.718400, numObservations: 8
action 2, numVisits=13, meanQ=37.461538, numObservations: 4
action 5, numVisits=5, meanQ=19.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 39913 episodes
GETTING ACTION FROM:
action 1, numVisits=39936, meanQ=35.143622, numObservations: 9
action 2, numVisits=15, meanQ=32.333333, numObservations: 4
action 5, numVisits=5, meanQ=19.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 1
Next state: 1 0.371915 0.53229 0.714725 0.069105 0.132287 0.200432 0.0411955 0.700014 0.919083 0.743927 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 60.4873
Run # 34
Initial state: 0 0.376378 0.572398 0.399256 0.366481 0.96262 0.728042 0.748155 0.338456 0.963754 0.678826 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17757 episodes
GETTING ACTION FROM:
action 0, numVisits=17731, meanQ=62.929671, numObservations: 243
action -1, numVisits=21, meanQ=-5.818571, numObservations: 20
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.376378 0.572398 0.399256 0.366481 0.96262 0.728042 0.748155 0.338456 0.963754 0.678826 w: 1
Observation: 0 0 1 0 1 0 3 0 1 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=29, meanQ=74.137931, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 32278 episodes
GETTING ACTION FROM:
action 5, numVisits=32307, meanQ=69.019678, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.376378 0.572398 0.399256 0.366481 0.96262 0.728042 0.748155 0.338456 0.963754 0.678826 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 35
Initial state: 0 0.346246 0.431275 0.280946 0.961782 0.950907 0.838097 0.890517 0.350787 0.383356 0.332293 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32445 episodes
GETTING ACTION FROM:
action 1, numVisits=32435, meanQ=23.772785, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=4, meanQ=-6.249975, numObservations: 3
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.346246 0.431275 0.280946 0.961782 0.950907 0.838097 0.890517 0.350787 0.383356 0.332293 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 36
Initial state: 0 0.308094 0.562593 0.732991 0.915189 0.466682 0.467049 0.625332 0.980049 0.686288 0.0187804 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32820 episodes
GETTING ACTION FROM:
action 5, numVisits=32814, meanQ=23.856268, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.308094 0.562593 0.732991 0.915189 0.466682 0.467049 0.625332 0.980049 0.686288 0.0187804 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 37
Initial state: 0 0.794135 0.262215 0.522687 0.0197386 0.365295 0.430703 0.749954 0.505806 0.876882 0.897281 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17946 episodes
GETTING ACTION FROM:
action -1, numVisits=17908, meanQ=56.289408, numObservations: 242
action 0, numVisits=30, meanQ=-1.208330, numObservations: 27
action 3, numVisits=4, meanQ=-6.000000, numObservations: 4
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.794135 0.262215 0.522687 0.0197386 0.365295 0.430703 0.749954 0.505806 0.876882 0.897281 w: 1
Observation: 0 3 0 3 0 2 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=367, meanQ=84.034578, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 38509 episodes
GETTING ACTION FROM:
action 3, numVisits=38876, meanQ=92.387080, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.794135 0.262215 0.522687 0.0197386 0.365295 0.430703 0.749954 0.505806 0.876882 0.897281 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 38
Initial state: 0 0.0160665 0.400744 0.575449 0.748224 0.808603 0.744166 0.333503 0.836382 0.335073 0.421652 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32762 episodes
GETTING ACTION FROM:
action 2, numVisits=32725, meanQ=22.877816, numObservations: 9
action 1, numVisits=29, meanQ=17.241041, numObservations: 8
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=3, meanQ=-4.333333, numObservations: 3
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.0160665 0.400744 0.575449 0.748224 0.808603 0.744166 0.333503 0.836382 0.335073 0.421652 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 39
Initial state: 0 0.926235 0.628546 0.38164 0.526095 0.376369 0.137458 0.52473 0.0266466 0.793922 0.11597 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31430 episodes
GETTING ACTION FROM:
action 1, numVisits=31419, meanQ=24.171269, numObservations: 9
action 4, numVisits=5, meanQ=19.000000, numObservations: 4
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.926235 0.628546 0.38164 0.526095 0.376369 0.137458 0.52473 0.0266466 0.793922 0.11597 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 40
Initial state: 0 0.605624 0.22042 0.381957 0.455402 0.84538 0.264412 0.261538 0.835547 0.360042 0.338681 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31508 episodes
GETTING ACTION FROM:
action 1, numVisits=31500, meanQ=24.152452, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.605624 0.22042 0.381957 0.455402 0.84538 0.264412 0.261538 0.835547 0.360042 0.338681 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 41
Initial state: 0 0.341146 0.650649 0.308216 0.432168 0.484516 0.646419 0.913732 0.705341 0.797898 0.654352 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32417 episodes
GETTING ACTION FROM:
action 2, numVisits=32408, meanQ=22.481124, numObservations: 9
action 1, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.341146 0.650649 0.308216 0.432168 0.484516 0.646419 0.913732 0.705341 0.797898 0.654352 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 42
Initial state: 0 0.970747 0.835377 0.368108 0.517073 0.264462 0.202956 0.326436 0.172205 0.669898 0.430258 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31556 episodes
GETTING ACTION FROM:
action 2, numVisits=31521, meanQ=23.485214, numObservations: 9
action 4, numVisits=30, meanQ=20.002670, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.970747 0.835377 0.368108 0.517073 0.264462 0.202956 0.326436 0.172205 0.669898 0.430258 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 43
Initial state: 0 0.716806 0.196537 0.323317 0.460663 0.770922 0.40807 0.51707 0.484326 0.219817 0.0867079 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31752 episodes
GETTING ACTION FROM:
action 1, numVisits=31746, meanQ=24.480788, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.716806 0.196537 0.323317 0.460663 0.770922 0.40807 0.51707 0.484326 0.219817 0.0867079 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 44
Initial state: 0 0.480082 0.709915 0.0786657 0.831807 0.865478 0.559311 0.19152 0.344673 0.398377 0.555459 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18201 episodes
GETTING ACTION FROM:
action 0, numVisits=18154, meanQ=65.190816, numObservations: 243
action 5, numVisits=9, meanQ=-2.111111, numObservations: 5
action 2, numVisits=24, meanQ=-4.083321, numObservations: 9
action -1, numVisits=11, meanQ=-10.190000, numObservations: 10
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.480082 0.709915 0.0786657 0.831807 0.865478 0.559311 0.19152 0.344673 0.398377 0.555459 w: 1
Observation: 0 0 3 0 3 0 2 0 1 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=34, meanQ=69.735297, numObservations: 7
action 5, numVisits=38, meanQ=61.420789, numObservations: 7
action 2, numVisits=4, meanQ=43.997525, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 32762 episodes
GETTING ACTION FROM:
action 1, numVisits=32795, meanQ=63.362264, numObservations: 9
action 5, numVisits=39, meanQ=57.256154, numObservations: 7
action 2, numVisits=4, meanQ=43.997525, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 1
Next state: 1 0.480082 0.709915 0.0786657 0.831807 0.865478 0.559311 0.19152 0.344673 0.398377 0.555459 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 45
Initial state: 0 0.204703 0.184001 0.522274 0.808431 0.05325 0.638706 0.357774 0.495439 0.307043 0.00653554 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31636 episodes
GETTING ACTION FROM:
action 5, numVisits=31624, meanQ=23.357776, numObservations: 9
action 2, numVisits=7, meanQ=10.570000, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.204703 0.184001 0.522274 0.808431 0.05325 0.638706 0.357774 0.495439 0.307043 0.00653554 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 46
Initial state: 0 0.484771 0.736079 0.373655 0.492439 0.826408 0.571818 0.678886 0.969557 0.156446 0.192124 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31802 episodes
GETTING ACTION FROM:
action 3, numVisits=31790, meanQ=23.277710, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=7, meanQ=-5.144286, numObservations: 5
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.484771 0.736079 0.373655 0.492439 0.826408 0.571818 0.678886 0.969557 0.156446 0.192124 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 47
Initial state: 0 0.307188 0.506221 0.107405 0.562417 0.17484 0.648104 0.00546743 0.898129 0.853843 0.291454 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31382 episodes
GETTING ACTION FROM:
action 3, numVisits=31376, meanQ=24.042347, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.307188 0.506221 0.107405 0.562417 0.17484 0.648104 0.00546743 0.898129 0.853843 0.291454 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=268, meanQ=19.604349, numObservations: 135
action -1, numVisits=17, meanQ=-1.010000, numObservations: 17
action 2, numVisits=5, meanQ=-2.802000, numObservations: 4
action 5, numVisits=30, meanQ=-3.000990, numObservations: 8
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 12564 episodes
GETTING ACTION FROM:
action 0, numVisits=12832, meanQ=5.512473, numObservations: 243
action -1, numVisits=17, meanQ=-1.010000, numObservations: 17
action 2, numVisits=5, meanQ=-2.802000, numObservations: 4
action 5, numVisits=30, meanQ=-3.000990, numObservations: 8
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.307188 0.506221 0.107405 0.562417 0.17484 0.648104 0.00546743 0.898129 0.853843 0.291454 w: 1
Observation: 0 0 2 0 2 0 3 0 3 0 1 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=1, meanQ=99.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 35586 episodes
GETTING ACTION FROM:
action 1, numVisits=35579, meanQ=72.026117, numObservations: 9
action 4, numVisits=5, meanQ=59.000000, numObservations: 3
action 3, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.307188 0.506221 0.107405 0.562417 0.17484 0.648104 0.00546743 0.898129 0.853843 0.291454 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 84.0499
Run # 48
Initial state: 0 0.33484 0.435228 0.483518 0.212475 0.511378 0.967439 0.443838 0.380203 0.619176 0.153029 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32868 episodes
GETTING ACTION FROM:
action 4, numVisits=32862, meanQ=23.939930, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.33484 0.435228 0.483518 0.212475 0.511378 0.967439 0.443838 0.380203 0.619176 0.153029 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 49
Initial state: 0 0.868625 0.00837884 0.388493 0.460905 0.22997 0.120169 0.0639944 0.170491 0.919872 0.409163 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18210 episodes
GETTING ACTION FROM:
action 0, numVisits=18188, meanQ=64.695514, numObservations: 243
action 5, numVisits=12, meanQ=-11.834158, numObservations: 5
action -1, numVisits=6, meanQ=-17.840000, numObservations: 5
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.868625 0.00837884 0.388493 0.460905 0.22997 0.120169 0.0639944 0.170491 0.919872 0.409163 w: 1
Observation: 0 0 1 0 2 0 2 0 1 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=69, meanQ=55.103629, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 35586 episodes
GETTING ACTION FROM:
action 3, numVisits=35655, meanQ=68.954504, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.868625 0.00837884 0.388493 0.460905 0.22997 0.120169 0.0639944 0.170491 0.919872 0.409163 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 0, numVisits=264, meanQ=29.685196, numObservations: 64
action -1, numVisits=18, meanQ=-6.730550, numObservations: 16
action 3, numVisits=4, meanQ=-8.002500, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 11889 episodes
GETTING ACTION FROM:
action 0, numVisits=12153, meanQ=10.655578, numObservations: 192
action -1, numVisits=18, meanQ=-6.730550, numObservations: 16
action 3, numVisits=4, meanQ=-8.002500, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.868625 0.00837884 0.388493 0.460905 0.22997 0.120169 0.0639944 0.170491 0.919872 0.409163 w: 1
Observation: 0 0 1 0 2 0 1 0 1 0 1 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=595, meanQ=90.918103, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 36386 episodes
GETTING ACTION FROM:
action 2, numVisits=36981, meanQ=80.617372, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.868625 0.00837884 0.388493 0.460905 0.22997 0.120169 0.0639944 0.170491 0.919872 0.409163 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 81.2094
Run # 50
Initial state: 0 0.747886 0.0168038 0.312947 0.552257 0.778488 0.25359 0.688027 0.0861733 0.851207 0.880252 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32564 episodes
GETTING ACTION FROM:
action 4, numVisits=32549, meanQ=22.402153, numObservations: 9
action 1, numVisits=10, meanQ=19.000000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.747886 0.0168038 0.312947 0.552257 0.778488 0.25359 0.688027 0.0861733 0.851207 0.880252 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 51
Initial state: 0 0.532607 0.675207 0.339857 0.559304 0.175739 0.636559 0.551399 0.0813151 0.161375 0.29439 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31227 episodes
GETTING ACTION FROM:
action 4, numVisits=31218, meanQ=25.164304, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.532607 0.675207 0.339857 0.559304 0.175739 0.636559 0.551399 0.0813151 0.161375 0.29439 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 52
Initial state: 0 0.785632 0.256977 0.398945 0.995591 0.318578 0.575489 0.844704 0.512614 0.832152 0.846941 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32554 episodes
GETTING ACTION FROM:
action 5, numVisits=32399, meanQ=24.461629, numObservations: 9
action 4, numVisits=138, meanQ=20.993551, numObservations: 9
action 1, numVisits=13, meanQ=19.692308, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.785632 0.256977 0.398945 0.995591 0.318578 0.575489 0.844704 0.512614 0.832152 0.846941 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 53
Initial state: 0 0.279161 0.696812 0.396932 0.738143 0.303003 0.509153 0.027666 0.874373 0.51092 0.450635 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18262 episodes
GETTING ACTION FROM:
action 0, numVisits=18222, meanQ=63.869098, numObservations: 243
action -1, numVisits=28, meanQ=-1.859632, numObservations: 25
action 3, numVisits=6, meanQ=-4.499983, numObservations: 4
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=3, meanQ=-34.333333, numObservations: 2
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.279161 0.696812 0.396932 0.738143 0.303003 0.509153 0.027666 0.874373 0.51092 0.450635 w: 1
Observation: 0 0 3 0 3 0 2 0 3 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=48, meanQ=78.021044, numObservations: 8
action 3, numVisits=4, meanQ=43.997525, numObservations: 3
action 5, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 31274 episodes
GETTING ACTION FROM:
action 2, numVisits=31322, meanQ=63.059272, numObservations: 9
action 3, numVisits=4, meanQ=43.997525, numObservations: 3
action 5, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.279161 0.696812 0.396932 0.738143 0.303003 0.509153 0.027666 0.874373 0.51092 0.450635 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 54
Initial state: 0 0.0887882 0.436754 0.868603 0.684037 0.918401 0.839284 0.40144 0.57318 0.622248 0.433496 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31834 episodes
GETTING ACTION FROM:
action 5, numVisits=31824, meanQ=22.520032, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=5, meanQ=-3.000000, numObservations: 3
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.0887882 0.436754 0.868603 0.684037 0.918401 0.839284 0.40144 0.57318 0.622248 0.433496 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 55
Initial state: 0 0.867956 0.766158 0.246839 0.919455 0.976881 0.0737603 0.0724641 0.412409 0.367146 0.57052 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32507 episodes
GETTING ACTION FROM:
action 1, numVisits=32501, meanQ=23.977516, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.867956 0.766158 0.246839 0.919455 0.976881 0.0737603 0.0724641 0.412409 0.367146 0.57052 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 56
Initial state: 0 0.755794 0.854076 0.165537 0.111537 0.454084 0.0937906 0.940478 0.211644 0.342563 0.497642 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32822 episodes
GETTING ACTION FROM:
action 4, numVisits=32811, meanQ=23.741716, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 2
action 3, numVisits=4, meanQ=-5.752500, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.755794 0.854076 0.165537 0.111537 0.454084 0.0937906 0.940478 0.211644 0.342563 0.497642 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 57
Initial state: 0 0.0959483 0.172543 0.545625 0.940835 0.0207878 0.513268 0.142305 0.10122 0.371542 0.482224 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31279 episodes
GETTING ACTION FROM:
action 3, numVisits=31272, meanQ=24.587706, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.0959483 0.172543 0.545625 0.940835 0.0207878 0.513268 0.142305 0.10122 0.371542 0.482224 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=899, meanQ=38.468434, numObservations: 225
action -1, numVisits=34, meanQ=-1.622635, numObservations: 28
action 2, numVisits=3, meanQ=-4.003333, numObservations: 3
action 4, numVisits=3, meanQ=-4.003333, numObservations: 3
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=3, meanQ=-34.333333, numObservations: 2
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 5946 episodes
GETTING ACTION FROM:
action 0, numVisits=6845, meanQ=36.136603, numObservations: 243
action -1, numVisits=34, meanQ=-1.622635, numObservations: 28
action 2, numVisits=3, meanQ=-4.003333, numObservations: 3
action 4, numVisits=3, meanQ=-4.003333, numObservations: 3
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=3, meanQ=-34.333333, numObservations: 2
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.0959483 0.172543 0.545625 0.940835 0.0207878 0.513268 0.142305 0.10122 0.371542 0.482224 w: 1
Observation: 0 0 1 0 3 0 2 0 1 0 2 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=34, meanQ=88.087509, numObservations: 7
action 2, numVisits=6, meanQ=79.239550, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 34446 episodes
GETTING ACTION FROM:
action 5, numVisits=34472, meanQ=75.287890, numObservations: 9
action 2, numVisits=14, meanQ=61.959807, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.0959483 0.172543 0.545625 0.940835 0.0207878 0.513268 0.142305 0.10122 0.371542 0.482224 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 84.0499
Run # 58
Initial state: 0 0.116992 0.909949 0.020459 0.284883 0.371305 0.554936 0.450579 0.782775 0.918023 0.228291 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32521 episodes
GETTING ACTION FROM:
action 5, numVisits=32513, meanQ=23.393199, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.116992 0.909949 0.020459 0.284883 0.371305 0.554936 0.450579 0.782775 0.918023 0.228291 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 59
Initial state: 0 0.590808 0.1016 0.325721 0.45529 0.92691 0.320221 0.371197 0.150435 0.12391 0.636043 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32369 episodes
GETTING ACTION FROM:
action 2, numVisits=32362, meanQ=23.237607, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.590808 0.1016 0.325721 0.45529 0.92691 0.320221 0.371197 0.150435 0.12391 0.636043 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 60
Initial state: 0 0.274407 0.1843 0.13743 0.878469 0.355731 0.381374 0.227771 0.16779 0.325783 0.534748 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31152 episodes
GETTING ACTION FROM:
action 2, numVisits=31145, meanQ=23.634478, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.274407 0.1843 0.13743 0.878469 0.355731 0.381374 0.227771 0.16779 0.325783 0.534748 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=1828, meanQ=25.772488, numObservations: 9
action 3, numVisits=67, meanQ=14.851054, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 34276 episodes
GETTING ACTION FROM:
action 4, numVisits=36104, meanQ=30.689421, numObservations: 9
action 3, numVisits=67, meanQ=14.851054, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 4
Next state: 0 0.274407 0.1843 0.13743 0.878469 0.355731 0.381374 0.227771 0.16779 0.325783 0.534748 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action -1, numVisits=1723, meanQ=65.350322, numObservations: 158
action 0, numVisits=25, meanQ=-5.644388, numObservations: 21
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 6127 episodes
GETTING ACTION FROM:
action -1, numVisits=7850, meanQ=36.741655, numObservations: 230
action 0, numVisits=25, meanQ=-5.644388, numObservations: 21
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.274407 0.1843 0.13743 0.878469 0.355731 0.381374 0.227771 0.16779 0.325783 0.534748 w: 1
Observation: 0 1 0 1 0 2 0 1 0 1 0 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=19, meanQ=69.549911, numObservations: 4
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 26524 episodes
GETTING ACTION FROM:
action 3, numVisits=26543, meanQ=74.516258, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 3
Next state: 0 0.274407 0.1843 0.13743 0.878469 0.355731 0.381374 0.227771 0.16779 0.325783 0.534748 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action -1, numVisits=265, meanQ=33.172826, numObservations: 60
action 2, numVisits=1, meanQ=-14.386793, numObservations: 1
action 5, numVisits=1, meanQ=-16.767708, numObservations: 1
action 1, numVisits=1, meanQ=-17.448797, numObservations: 1
action 3, numVisits=1, meanQ=-18.553888, numObservations: 1
action 0, numVisits=20, meanQ=-36.063800, numObservations: 12
action 4, numVisits=1, meanQ=-1078.467999, numObservations: 1
Sampled 15104 episodes
GETTING ACTION FROM:
action -1, numVisits=15369, meanQ=9.167855, numObservations: 218
action 2, numVisits=1, meanQ=-14.386793, numObservations: 1
action 5, numVisits=1, meanQ=-16.767708, numObservations: 1
action 1, numVisits=1, meanQ=-17.448797, numObservations: 1
action 3, numVisits=1, meanQ=-18.553888, numObservations: 1
action 0, numVisits=20, meanQ=-36.063800, numObservations: 12
action 4, numVisits=1, meanQ=-1078.467999, numObservations: 1
action: -1
Next state: 0 0.274407 0.1843 0.13743 0.878469 0.355731 0.381374 0.227771 0.16779 0.325783 0.534748 w: 1
Observation: 0 1 0 1 0 3 0 1 0 2 0 
Immediate reward: -2
Updated belief

t = 5
Improving policy...
PLANNING FROM:
action 2, numVisits=7, meanQ=28.733226, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-15.331591, numObservations: 1
action 5, numVisits=1, meanQ=-19.844385, numObservations: 1
action 3, numVisits=1, meanQ=-545.756406, numObservations: 1
action 4, numVisits=1, meanQ=-545.797806, numObservations: 1
Sampled 30034 episodes
GETTING ACTION FROM:
action -1, numVisits=29996, meanQ=-0.029112, numObservations: 188
action 0, numVisits=33, meanQ=-1.970000, numObservations: 14
action 2, numVisits=14, meanQ=-7.561959, numObservations: 2
action 1, numVisits=1, meanQ=-15.331591, numObservations: 1
action 5, numVisits=1, meanQ=-19.844385, numObservations: 1
action 3, numVisits=1, meanQ=-545.756406, numObservations: 1
action 4, numVisits=1, meanQ=-545.797806, numObservations: 1
action: -1
Next state: 0 0.274407 0.1843 0.13743 0.878469 0.355731 0.381374 0.227771 0.16779 0.325783 0.534748 w: 1
Observation: 0 1 0 1 0 2 0 1 0 2 0 
Immediate reward: -2
Updated belief

t = 6
Improving policy...
PLANNING FROM:
action 0, numVisits=25, meanQ=43.443147, numObservations: 10
action -1, numVisits=2, meanQ=-9.538997, numObservations: 1
action 2, numVisits=1, meanQ=-14.661149, numObservations: 1
action 5, numVisits=1, meanQ=-25.081161, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-544.950443, numObservations: 1
action 4, numVisits=1, meanQ=-545.625784, numObservations: 1
Sampled 30997 episodes
GETTING ACTION FROM:
action 0, numVisits=31022, meanQ=0.088161, numObservations: 195
action -1, numVisits=2, meanQ=-9.538997, numObservations: 1
action 2, numVisits=1, meanQ=-14.661149, numObservations: 1
action 5, numVisits=1, meanQ=-25.081161, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-544.950443, numObservations: 1
action 4, numVisits=1, meanQ=-545.625784, numObservations: 1
action: 0
Next state: 0 0.274407 0.1843 0.13743 0.878469 0.355731 0.381374 0.227771 0.16779 0.325783 0.534748 w: 1
Observation: 0 0 1 0 3 0 1 0 1 0 2 
Immediate reward: -2
Updated belief

t = 7
Improving policy...
PLANNING FROM:
action 5, numVisits=65, meanQ=84.853434, numObservations: 7
action 2, numVisits=7, meanQ=22.770659, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-16.235645, numObservations: 1
action 3, numVisits=1, meanQ=-544.286903, numObservations: 1
action 4, numVisits=1, meanQ=-546.073967, numObservations: 1
Sampled 42524 episodes
GETTING ACTION FROM:
action 5, numVisits=42589, meanQ=82.093553, numObservations: 9
action 2, numVisits=7, meanQ=22.770659, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-16.235645, numObservations: 1
action 3, numVisits=1, meanQ=-544.286903, numObservations: 1
action 4, numVisits=1, meanQ=-546.073967, numObservations: 1
action: 5
Next state: 1 0.274407 0.1843 0.13743 0.878469 0.355731 0.381374 0.227771 0.16779 0.325783 0.534748 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 52.0448
Run # 61
Initial state: 0 0.463486 0.519979 0.105415 0.548324 0.593577 0.337947 0.179207 0.185345 0.397179 0.528151 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33062 episodes
GETTING ACTION FROM:
action 2, numVisits=33041, meanQ=23.499938, numObservations: 9
action 5, numVisits=16, meanQ=15.063131, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.463486 0.519979 0.105415 0.548324 0.593577 0.337947 0.179207 0.185345 0.397179 0.528151 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=834, meanQ=25.958336, numObservations: 9
action 5, numVisits=28, meanQ=13.008943, numObservations: 7
action 4, numVisits=9, meanQ=8.108889, numObservations: 5
action 3, numVisits=12, meanQ=6.582500, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 20028 episodes
GETTING ACTION FROM:
action 1, numVisits=20862, meanQ=27.665852, numObservations: 9
action 5, numVisits=28, meanQ=13.008943, numObservations: 7
action 4, numVisits=9, meanQ=8.108889, numObservations: 5
action 3, numVisits=12, meanQ=6.582500, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 1
Next state: 1 0.463486 0.519979 0.105415 0.548324 0.593577 0.337947 0.179207 0.185345 0.397179 0.528151 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 62
Initial state: 0 0.632001 0.278964 0.765856 0.75421 0.757022 0.869183 0.399763 0.452215 0.306329 0.743259 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17734 episodes
GETTING ACTION FROM:
action -1, numVisits=17720, meanQ=55.512530, numObservations: 243
action 5, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=7, meanQ=-15.435714, numObservations: 6
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.632001 0.278964 0.765856 0.75421 0.757022 0.869183 0.399763 0.452215 0.306329 0.743259 w: 1
Observation: 0 3 0 3 0 3 0 2 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=139, meanQ=35.741442, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37426 episodes
GETTING ACTION FROM:
action 4, numVisits=37565, meanQ=40.103696, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.632001 0.278964 0.765856 0.75421 0.757022 0.869183 0.399763 0.452215 0.306329 0.743259 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=343, meanQ=55.563996, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=3, meanQ=-4.003333, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 27597 episodes
GETTING ACTION FROM:
action 5, numVisits=27940, meanQ=45.737793, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=3, meanQ=-4.003333, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.632001 0.278964 0.765856 0.75421 0.757022 0.869183 0.399763 0.452215 0.306329 0.743259 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 84.1399
Run # 63
Initial state: 0 0.126292 0.688255 0.347504 0.560708 0.0098182 0.839544 0.555879 0.228441 0.134768 0.65434 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31473 episodes
GETTING ACTION FROM:
action 5, numVisits=31438, meanQ=24.599889, numObservations: 9
action 4, numVisits=30, meanQ=13.333003, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.126292 0.688255 0.347504 0.560708 0.0098182 0.839544 0.555879 0.228441 0.134768 0.65434 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=100, meanQ=20.724313, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 38401 episodes
GETTING ACTION FROM:
action 3, numVisits=38501, meanQ=37.689583, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.126292 0.688255 0.347504 0.560708 0.0098182 0.839544 0.555879 0.228441 0.134768 0.65434 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=20, meanQ=73.145374, numObservations: 4
action 4, numVisits=14, meanQ=68.106138, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-1075.162384, numObservations: 1
Sampled 45066 episodes
GETTING ACTION FROM:
action 2, numVisits=45050, meanQ=42.621613, numObservations: 9
action 4, numVisits=50, meanQ=26.349719, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-1075.162384, numObservations: 1
action: 2
Next state: 1 0.126292 0.688255 0.347504 0.560708 0.0098182 0.839544 0.555879 0.228441 0.134768 0.65434 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 75.1399
Run # 64
Initial state: 0 0.66897 0.176265 0.563919 0.569755 0.338126 0.484194 0.266563 0.113311 0.810575 0.473304 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18269 episodes
GETTING ACTION FROM:
action 0, numVisits=18200, meanQ=62.058314, numObservations: 243
action -1, numVisits=34, meanQ=-1.389112, numObservations: 32
action 2, numVisits=29, meanQ=-3.100338, numObservations: 8
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.66897 0.176265 0.563919 0.569755 0.338126 0.484194 0.266563 0.113311 0.810575 0.473304 w: 1
Observation: 0 0 1 0 2 0 2 0 1 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=29, meanQ=22.408621, numObservations: 22
action -1, numVisits=5, meanQ=-1.010000, numObservations: 5
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=3, meanQ=-34.333333, numObservations: 2
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 17891 episodes
GETTING ACTION FROM:
action 0, numVisits=17920, meanQ=53.432014, numObservations: 220
action -1, numVisits=5, meanQ=-1.010000, numObservations: 5
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=3, meanQ=-34.333333, numObservations: 2
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.66897 0.176265 0.563919 0.569755 0.338126 0.484194 0.266563 0.113311 0.810575 0.473304 w: 1
Observation: 0 0 1 0 2 0 3 0 1 0 2 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=808, meanQ=68.452120, numObservations: 9
action 2, numVisits=84, meanQ=57.047739, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 39123 episodes
GETTING ACTION FROM:
action 3, numVisits=39931, meanQ=69.273399, numObservations: 9
action 2, numVisits=84, meanQ=57.047739, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.66897 0.176265 0.563919 0.569755 0.338126 0.484194 0.266563 0.113311 0.810575 0.473304 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 93.0499
Run # 65
Initial state: 0 0.0574908 0.87602 0.0790559 0.219211 0.637546 0.96078 0.370138 0.577173 0.411886 0.135035 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30136 episodes
GETTING ACTION FROM:
action 2, numVisits=30130, meanQ=24.913342, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.0574908 0.87602 0.0790559 0.219211 0.637546 0.96078 0.370138 0.577173 0.411886 0.135035 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=2378, meanQ=55.221310, numObservations: 221
action -1, numVisits=14, meanQ=-1.788564, numObservations: 13
action 1, numVisits=5, meanQ=-2.802000, numObservations: 4
action 3, numVisits=3, meanQ=-4.003333, numObservations: 2
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 3460 episodes
GETTING ACTION FROM:
action 0, numVisits=5838, meanQ=49.332336, numObservations: 242
action -1, numVisits=14, meanQ=-1.788564, numObservations: 13
action 1, numVisits=5, meanQ=-2.802000, numObservations: 4
action 3, numVisits=3, meanQ=-4.003333, numObservations: 2
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 0
Next state: 0 0.0574908 0.87602 0.0790559 0.219211 0.637546 0.96078 0.370138 0.577173 0.411886 0.135035 w: 1
Observation: 0 0 3 0 2 0 2 0 2 0 1 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=1, meanQ=99.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-1076.072533, numObservations: 1
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 14792 episodes
GETTING ACTION FROM:
action 1, numVisits=14783, meanQ=62.847016, numObservations: 9
action 3, numVisits=6, meanQ=47.333333, numObservations: 5
action 4, numVisits=2, meanQ=44.000000, numObservations: 2
action 5, numVisits=2, meanQ=44.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-1076.072533, numObservations: 1
action: 1
Next state: 1 0.0574908 0.87602 0.0790559 0.219211 0.637546 0.96078 0.370138 0.577173 0.411886 0.135035 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 84.0499
Run # 66
Initial state: 0 0.335964 0.494188 0.627909 0.309876 0.417857 0.652354 0.229995 0.645526 0.335583 0.847573 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17969 episodes
GETTING ACTION FROM:
action 0, numVisits=17870, meanQ=61.353843, numObservations: 243
action -1, numVisits=90, meanQ=-1.571770, numObservations: 69
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 5, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.335964 0.494188 0.627909 0.309876 0.417857 0.652354 0.229995 0.645526 0.335583 0.847573 w: 1
Observation: 0 0 2 0 2 0 3 0 3 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=47, meanQ=80.620002, numObservations: 5
action 3, numVisits=12, meanQ=56.582500, numObservations: 4
action 1, numVisits=4, meanQ=49.000000, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 34579 episodes
GETTING ACTION FROM:
action 5, numVisits=34626, meanQ=64.276161, numObservations: 9
action 3, numVisits=12, meanQ=56.582500, numObservations: 4
action 1, numVisits=4, meanQ=49.000000, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 5
Next state: 1 0.335964 0.494188 0.627909 0.309876 0.417857 0.652354 0.229995 0.645526 0.335583 0.847573 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 67
Initial state: 0 0.966064 0.866493 0.00887864 0.412087 0.330819 0.466866 0.0151077 0.622672 0.359714 0.338962 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32739 episodes
GETTING ACTION FROM:
action 4, numVisits=32730, meanQ=22.209867, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.966064 0.866493 0.00887864 0.412087 0.330819 0.466866 0.0151077 0.622672 0.359714 0.338962 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1914, meanQ=31.386165, numObservations: 9
action 5, numVisits=4, meanQ=21.747500, numObservations: 3
action 2, numVisits=5, meanQ=15.396000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 36678 episodes
GETTING ACTION FROM:
action 1, numVisits=38592, meanQ=36.307190, numObservations: 9
action 5, numVisits=4, meanQ=21.747500, numObservations: 3
action 2, numVisits=5, meanQ=15.396000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.966064 0.866493 0.00887864 0.412087 0.330819 0.466866 0.0151077 0.622672 0.359714 0.338962 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 68
Initial state: 0 0.90225 0.950331 0.985649 0.910688 0.135074 0.358903 0.0607531 0.394557 0.381224 0.561951 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32271 episodes
GETTING ACTION FROM:
action 5, numVisits=32166, meanQ=21.729194, numObservations: 9
action 2, numVisits=25, meanQ=19.680404, numObservations: 8
action 4, numVisits=75, meanQ=19.056943, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.90225 0.950331 0.985649 0.910688 0.135074 0.358903 0.0607531 0.394557 0.381224 0.561951 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 69
Initial state: 0 0.0921702 0.666062 0.693128 0.449113 0.136731 0.583578 0.348212 0.557088 0.28559 0.327626 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32737 episodes
GETTING ACTION FROM:
action 2, numVisits=32724, meanQ=23.583791, numObservations: 9
action 4, numVisits=4, meanQ=-1.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=5, meanQ=-3.000000, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.0921702 0.666062 0.693128 0.449113 0.136731 0.583578 0.348212 0.557088 0.28559 0.327626 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 70
Initial state: 0 0.404603 0.49277 0.622816 0.574132 0.349039 0.136215 0.728392 0.8194 0.388323 0.0075672 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18068 episodes
GETTING ACTION FROM:
action 0, numVisits=18026, meanQ=60.529285, numObservations: 243
action -1, numVisits=32, meanQ=-1.195934, numObservations: 29
action 5, numVisits=3, meanQ=-4.333333, numObservations: 3
action 3, numVisits=4, meanQ=-6.000000, numObservations: 3
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.404603 0.49277 0.622816 0.574132 0.349039 0.136215 0.728392 0.8194 0.388323 0.0075672 w: 1
Observation: 0 0 2 0 2 0 1 0 3 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=59, meanQ=43.813220, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37656 episodes
GETTING ACTION FROM:
action 2, numVisits=37715, meanQ=67.223789, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.404603 0.49277 0.622816 0.574132 0.349039 0.136215 0.728392 0.8194 0.388323 0.0075672 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101.99
Run # 71
Initial state: 0 0.947303 0.0334509 0.263392 0.144956 0.83094 0.87198 0.677605 0.291089 0.330194 0.426522 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17722 episodes
GETTING ACTION FROM:
action -1, numVisits=17685, meanQ=53.698444, numObservations: 243
action 2, numVisits=25, meanQ=-0.597188, numObservations: 8
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 3, numVisits=5, meanQ=-8.998000, numObservations: 4
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.947303 0.0334509 0.263392 0.144956 0.83094 0.87198 0.677605 0.291089 0.330194 0.426522 w: 1
Observation: 0 3 0 3 0 3 0 3 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=346, meanQ=84.444413, numObservations: 9
action 3, numVisits=15, meanQ=11.732667, numObservations: 5
action 2, numVisits=13, meanQ=6.692308, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 38440 episodes
GETTING ACTION FROM:
action 5, numVisits=38786, meanQ=90.469172, numObservations: 9
action 3, numVisits=15, meanQ=11.732667, numObservations: 5
action 2, numVisits=13, meanQ=6.692308, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.947303 0.0334509 0.263392 0.144956 0.83094 0.87198 0.677605 0.291089 0.330194 0.426522 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 72
Initial state: 0 0.49607 0.744701 0.739473 0.798421 0.803462 0.807372 0.938828 0.702627 0.351321 0.541996 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32540 episodes
GETTING ACTION FROM:
action 5, numVisits=32517, meanQ=22.351536, numObservations: 9
action 2, numVisits=10, meanQ=16.009010, numObservations: 4
action 3, numVisits=9, meanQ=10.111111, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.49607 0.744701 0.739473 0.798421 0.803462 0.807372 0.938828 0.702627 0.351321 0.541996 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 73
Initial state: 0 0.0701058 0.357338 0.312061 0.810697 0.676319 0.282882 0.294277 0.814611 0.371577 0.506739 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17617 episodes
GETTING ACTION FROM:
action -1, numVisits=17553, meanQ=55.173122, numObservations: 242
action 3, numVisits=5, meanQ=-2.802000, numObservations: 3
action 5, numVisits=37, meanQ=-3.046203, numObservations: 7
action 0, numVisits=19, meanQ=-6.324737, numObservations: 18
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.0701058 0.357338 0.312061 0.810697 0.676319 0.282882 0.294277 0.814611 0.371577 0.506739 w: 1
Observation: 0 1 0 2 0 3 0 1 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=18, meanQ=36.387222, numObservations: 8
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 2, numVisits=9, meanQ=-2.001111, numObservations: 3
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 36190 episodes
GETTING ACTION FROM:
action 5, numVisits=36208, meanQ=50.996806, numObservations: 9
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 2, numVisits=9, meanQ=-2.001111, numObservations: 3
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.0701058 0.357338 0.312061 0.810697 0.676319 0.282882 0.294277 0.814611 0.371577 0.506739 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 74
Initial state: 0 0.733035 0.303581 0.939704 0.467529 0.306108 0.572599 0.303573 0.981146 0.543137 0.355634 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17678 episodes
GETTING ACTION FROM:
action -1, numVisits=17658, meanQ=57.266045, numObservations: 243
action 0, numVisits=7, meanQ=-1.010000, numObservations: 7
action 4, numVisits=7, meanQ=-2.428571, numObservations: 6
action 1, numVisits=3, meanQ=-4.333333, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.733035 0.303581 0.939704 0.467529 0.306108 0.572599 0.303573 0.981146 0.543137 0.355634 w: 1
Observation: 0 3 0 3 0 2 0 2 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=135, meanQ=39.275262, numObservations: 9
action 1, numVisits=8, meanQ=-1.000000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action -1, numVisits=3, meanQ=-1.673300, numObservations: 2
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 36496 episodes
GETTING ACTION FROM:
action 4, numVisits=36631, meanQ=52.199819, numObservations: 9
action 1, numVisits=8, meanQ=-1.000000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action -1, numVisits=3, meanQ=-1.673300, numObservations: 2
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.733035 0.303581 0.939704 0.467529 0.306108 0.572599 0.303573 0.981146 0.543137 0.355634 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101.99
Run # 75
Initial state: 0 0.409598 0.520185 0.0492414 0.0601959 0.779611 0.214407 0.270142 0.509717 0.0748741 0.941808 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31751 episodes
GETTING ACTION FROM:
action 1, numVisits=31741, meanQ=24.051517, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.409598 0.520185 0.0492414 0.0601959 0.779611 0.214407 0.270142 0.509717 0.0748741 0.941808 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 76
Initial state: 0 0.787163 0.778416 0.389207 0.472209 0.327213 0.614646 0.750141 0.484991 0.226987 0.450882 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32350 episodes
GETTING ACTION FROM:
action 1, numVisits=32344, meanQ=22.126608, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.787163 0.778416 0.389207 0.472209 0.327213 0.614646 0.750141 0.484991 0.226987 0.450882 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 77
Initial state: 0 0.674997 0.294698 0.464238 0.357483 0.396928 0.536141 0.199635 0.893158 0.772535 0.985784 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18148 episodes
GETTING ACTION FROM:
action 0, numVisits=18122, meanQ=62.704068, numObservations: 243
action -1, numVisits=14, meanQ=-9.143557, numObservations: 11
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=8, meanQ=-14.750000, numObservations: 5
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.674997 0.294698 0.464238 0.357483 0.396928 0.536141 0.199635 0.893158 0.772535 0.985784 w: 1
Observation: 0 0 1 0 1 0 1 0 3 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=24, meanQ=-1.092913, numObservations: 23
action 5, numVisits=5, meanQ=-2.802000, numObservations: 4
action 0, numVisits=12, meanQ=-9.425000, numObservations: 11
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 35856 episodes
GETTING ACTION FROM:
action 5, numVisits=35861, meanQ=66.367464, numObservations: 9
action -1, numVisits=24, meanQ=-1.092913, numObservations: 23
action 0, numVisits=12, meanQ=-9.425000, numObservations: 11
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.674997 0.294698 0.464238 0.357483 0.396928 0.536141 0.199635 0.893158 0.772535 0.985784 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 78
Initial state: 0 0.536184 0.375196 0.221492 0.718304 0.838228 0.774407 0.8121 0.871959 0.35684 0.495688 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31652 episodes
GETTING ACTION FROM:
action 5, numVisits=31635, meanQ=23.644201, numObservations: 9
action 3, numVisits=8, meanQ=18.998762, numObservations: 6
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=4, meanQ=-5.752500, numObservations: 4
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.536184 0.375196 0.221492 0.718304 0.838228 0.774407 0.8121 0.871959 0.35684 0.495688 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 79
Initial state: 0 0.781063 0.816116 0.315076 0.486189 0.913273 0.627819 0.507911 0.861221 0.641898 0.233026 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32776 episodes
GETTING ACTION FROM:
action 1, numVisits=32765, meanQ=23.380160, numObservations: 9
action 5, numVisits=5, meanQ=9.018020, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.781063 0.816116 0.315076 0.486189 0.913273 0.627819 0.507911 0.861221 0.641898 0.233026 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 80
Initial state: 0 0.205989 0.197776 0.521776 0.733414 0.368905 0.468298 0.171136 0.140647 0.565358 0.35301 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32312 episodes
GETTING ACTION FROM:
action 4, numVisits=32151, meanQ=24.195728, numObservations: 9
action 2, numVisits=154, meanQ=22.892539, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.205989 0.197776 0.521776 0.733414 0.368905 0.468298 0.171136 0.140647 0.565358 0.35301 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=2527, meanQ=25.482699, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 11421 episodes
GETTING ACTION FROM:
action 1, numVisits=13948, meanQ=24.543957, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.205989 0.197776 0.521776 0.733414 0.368905 0.468298 0.171136 0.140647 0.565358 0.35301 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=646, meanQ=50.254798, numObservations: 9
action 2, numVisits=12, meanQ=30.831667, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 7144 episodes
GETTING ACTION FROM:
action 5, numVisits=7789, meanQ=27.267245, numObservations: 9
action 2, numVisits=13, meanQ=20.690769, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 5
Next state: 2 0.205989 0.197776 0.521776 0.733414 0.368905 0.468298 0.171136 0.140647 0.565358 0.35301 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -120.88
Run # 81
Initial state: 0 0.275137 0.464261 0.827596 0.114548 0.315517 0.511861 0.818375 0.589774 0.322439 0.584539 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17818 episodes
GETTING ACTION FROM:
action -1, numVisits=17768, meanQ=55.051404, numObservations: 243
action 0, numVisits=20, meanQ=-1.010000, numObservations: 20
action 2, numVisits=7, meanQ=-2.428571, numObservations: 5
action 3, numVisits=20, meanQ=-4.094995, numObservations: 8
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.275137 0.464261 0.827596 0.114548 0.315517 0.511861 0.818375 0.589774 0.322439 0.584539 w: 1
Observation: 0 2 0 3 0 2 0 3 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=34, meanQ=34.916476, numObservations: 8
action 3, numVisits=7, meanQ=13.285714, numObservations: 6
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 34803 episodes
GETTING ACTION FROM:
action 5, numVisits=34836, meanQ=22.474210, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=8, meanQ=-1.000000, numObservations: 6
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.275137 0.464261 0.827596 0.114548 0.315517 0.511861 0.818375 0.589774 0.322439 0.584539 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 82
Initial state: 0 0.994114 0.101051 0.700367 0.165098 0.433618 0.852602 0.0669398 0.198828 0.392295 0.444054 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17624 episodes
GETTING ACTION FROM:
action -1, numVisits=17582, meanQ=56.392588, numObservations: 243
action 0, numVisits=25, meanQ=-1.604396, numObservations: 22
action 4, numVisits=5, meanQ=-3.000000, numObservations: 4
action 1, numVisits=9, meanQ=-5.443333, numObservations: 6
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.994114 0.101051 0.700367 0.165098 0.433618 0.852602 0.0669398 0.198828 0.392295 0.444054 w: 1
Observation: 0 3 0 3 0 2 0 1 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=61, meanQ=34.835743, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 34689 episodes
GETTING ACTION FROM:
action 3, numVisits=34750, meanQ=43.774540, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.994114 0.101051 0.700367 0.165098 0.433618 0.852602 0.0669398 0.198828 0.392295 0.444054 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 83
Initial state: 0 0.35159 0.601875 0.384986 0.539525 0.44261 0.998635 0.403769 0.899173 0.0787701 0.315464 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32896 episodes
GETTING ACTION FROM:
action 2, numVisits=32887, meanQ=23.062213, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.35159 0.601875 0.384986 0.539525 0.44261 0.998635 0.403769 0.899173 0.0787701 0.315464 w: 1
Observation: 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 84
Initial state: 0 0.495119 0.0796556 0.12961 0.947106 0.474179 0.773791 0.386701 0.537825 0.97364 0.222938 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32750 episodes
GETTING ACTION FROM:
action 5, numVisits=32670, meanQ=22.777032, numObservations: 9
action 0, numVisits=26, meanQ=-4.893846, numObservations: 25
action 4, numVisits=27, meanQ=-7.036293, numObservations: 8
action -1, numVisits=16, meanQ=-7.321250, numObservations: 15
action 3, numVisits=6, meanQ=-19.333333, numObservations: 3
action 2, numVisits=4, meanQ=-28.500000, numObservations: 4
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.495119 0.0796556 0.12961 0.947106 0.474179 0.773791 0.386701 0.537825 0.97364 0.222938 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 85
Initial state: 0 0.240455 0.284327 0.019949 0.156303 0.0955119 0.372785 0.853004 0.0456941 0.39371 0.57633 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31779 episodes
GETTING ACTION FROM:
action 4, numVisits=25351, meanQ=23.824104, numObservations: 9
action 1, numVisits=6422, meanQ=21.984612, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.240455 0.284327 0.019949 0.156303 0.0955119 0.372785 0.853004 0.0456941 0.39371 0.57633 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 86
Initial state: 0 0.391395 0.435856 0.65869 0.781721 0.531959 0.76499 0.371135 0.621484 0.513774 0.70516 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30506 episodes
GETTING ACTION FROM:
action 3, numVisits=30481, meanQ=26.265222, numObservations: 9
action 1, numVisits=18, meanQ=11.782228, numObservations: 8
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.391395 0.435856 0.65869 0.781721 0.531959 0.76499 0.371135 0.621484 0.513774 0.70516 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 87
Initial state: 0 0.32133 0.489936 0.536396 0.257678 0.281487 0.320615 0.367244 0.690523 0.474402 0.36718 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32633 episodes
GETTING ACTION FROM:
action 5, numVisits=32621, meanQ=23.362613, numObservations: 9
action 3, numVisits=6, meanQ=-1.000000, numObservations: 4
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.32133 0.489936 0.536396 0.257678 0.281487 0.320615 0.367244 0.690523 0.474402 0.36718 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 88
Initial state: 0 0.682744 0.762228 0.78754 0.808359 0.303045 0.564851 0.601499 0.644043 0.77852 0.479653 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32895 episodes
GETTING ACTION FROM:
action 2, numVisits=31993, meanQ=23.093707, numObservations: 9
action 3, numVisits=887, meanQ=22.853414, numObservations: 9
action 1, numVisits=11, meanQ=14.363645, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.682744 0.762228 0.78754 0.808359 0.303045 0.564851 0.601499 0.644043 0.77852 0.479653 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 89
Initial state: 0 0.619461 0.063907 0.229828 0.396087 0.218604 0.692295 0.411419 0.511032 0.631196 0.93119 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32885 episodes
GETTING ACTION FROM:
action 3, numVisits=32870, meanQ=23.672249, numObservations: 9
action 2, numVisits=6, meanQ=-1.000000, numObservations: 4
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.619461 0.063907 0.229828 0.396087 0.218604 0.692295 0.411419 0.511032 0.631196 0.93119 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=1990, meanQ=31.520685, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 35046 episodes
GETTING ACTION FROM:
action 4, numVisits=37036, meanQ=34.279743, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 4
Next state: 1 0.619461 0.063907 0.229828 0.396087 0.218604 0.692295 0.411419 0.511032 0.631196 0.93119 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 90
Initial state: 0 0.371525 0.461443 0.13141 0.822855 0.309972 0.269281 0.206852 0.0165033 0.763658 0.467154 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31394 episodes
GETTING ACTION FROM:
action 4, numVisits=31376, meanQ=23.729698, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=7, meanQ=-2.287143, numObservations: 6
action 2, numVisits=7, meanQ=-2.428571, numObservations: 5
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.371525 0.461443 0.13141 0.822855 0.309972 0.269281 0.206852 0.0165033 0.763658 0.467154 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=2453, meanQ=29.234805, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=3, meanQ=-4.003333, numObservations: 3
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 11845 episodes
GETTING ACTION FROM:
action 5, numVisits=14298, meanQ=24.089647, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=3, meanQ=-4.003333, numObservations: 3
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.371525 0.461443 0.13141 0.822855 0.309972 0.269281 0.206852 0.0165033 0.763658 0.467154 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 91
Initial state: 0 0.3729 0.298319 0.391816 0.581704 0.549233 0.104594 0.293693 0.156351 0.904201 0.710454 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18077 episodes
GETTING ACTION FROM:
action 0, numVisits=18053, meanQ=60.009066, numObservations: 243
action 1, numVisits=3, meanQ=-4.333333, numObservations: 2
action 5, numVisits=3, meanQ=-4.333333, numObservations: 3
action -1, numVisits=15, meanQ=-7.874660, numObservations: 13
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.3729 0.298319 0.391816 0.581704 0.549233 0.104594 0.293693 0.156351 0.904201 0.710454 w: 1
Observation: 0 0 1 0 2 0 1 0 1 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=94, meanQ=69.659472, numObservations: 9
action 5, numVisits=3, meanQ=32.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37362 episodes
GETTING ACTION FROM:
action 2, numVisits=37456, meanQ=87.720338, numObservations: 9
action 5, numVisits=3, meanQ=32.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.3729 0.298319 0.391816 0.581704 0.549233 0.104594 0.293693 0.156351 0.904201 0.710454 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 92
Initial state: 0 0.868846 0.449238 0.386107 0.849814 0.322182 0.431061 0.0263758 0.861689 0.673099 0.795158 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32039 episodes
GETTING ACTION FROM:
action 2, numVisits=32032, meanQ=23.998787, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.868846 0.449238 0.386107 0.849814 0.322182 0.431061 0.0263758 0.861689 0.673099 0.795158 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 93
Initial state: 0 0.511679 0.404824 0.732842 0.40369 0.316029 0.160979 0.380622 0.578233 0.445862 0.67454 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32625 episodes
GETTING ACTION FROM:
action 5, numVisits=32592, meanQ=23.098597, numObservations: 9
action 2, numVisits=6, meanQ=-1.000000, numObservations: 5
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=18, meanQ=-3.773322, numObservations: 7
action 3, numVisits=4, meanQ=-8.477475, numObservations: 3
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.511679 0.404824 0.732842 0.40369 0.316029 0.160979 0.380622 0.578233 0.445862 0.67454 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 94
Initial state: 0 0.22001 0.971489 0.46551 0.954894 0.684264 0.499249 0.323754 0.520316 0.0913605 0.997745 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32301 episodes
GETTING ACTION FROM:
action 1, numVisits=32265, meanQ=23.750578, numObservations: 9
action -1, numVisits=14, meanQ=-1.010000, numObservations: 14
action 0, numVisits=14, meanQ=-1.010000, numObservations: 14
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.22001 0.971489 0.46551 0.954894 0.684264 0.499249 0.323754 0.520316 0.0913605 0.997745 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=1860, meanQ=29.961432, numObservations: 9
action 5, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 34293 episodes
GETTING ACTION FROM:
action 3, numVisits=36153, meanQ=28.446455, numObservations: 9
action 5, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.22001 0.971489 0.46551 0.954894 0.684264 0.499249 0.323754 0.520316 0.0913605 0.997745 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 95
Initial state: 0 0.476 0.92386 0.168088 0.814559 0.186743 0.79592 0.374971 0.782944 0.409132 0.488894 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18094 episodes
GETTING ACTION FROM:
action -1, numVisits=18064, meanQ=58.019939, numObservations: 243
action 0, numVisits=21, meanQ=-5.818571, numObservations: 20
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=3, meanQ=-34.333333, numObservations: 3
action 4, numVisits=3, meanQ=-34.333333, numObservations: 3
action: -1
Next state: 0 0.476 0.92386 0.168088 0.814559 0.186743 0.79592 0.374971 0.782944 0.409132 0.488894 w: 1
Observation: 0 3 0 1 0 2 0 2 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=62, meanQ=44.983390, numObservations: 9
action 1, numVisits=5, meanQ=19.000000, numObservations: 3
action 5, numVisits=5, meanQ=19.000000, numObservations: 3
action 4, numVisits=16, meanQ=16.060625, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 35656 episodes
GETTING ACTION FROM:
action 3, numVisits=35718, meanQ=49.956118, numObservations: 9
action 1, numVisits=5, meanQ=19.000000, numObservations: 3
action 5, numVisits=5, meanQ=19.000000, numObservations: 3
action 4, numVisits=16, meanQ=16.060625, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 3
Next state: 1 0.476 0.92386 0.168088 0.814559 0.186743 0.79592 0.374971 0.782944 0.409132 0.488894 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 96
Initial state: 0 0.383622 0.454338 0.778696 0.0711289 0.50708 0.253605 0.842692 0.833432 0.787451 0.18986 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18310 episodes
GETTING ACTION FROM:
action 0, numVisits=18278, meanQ=60.940429, numObservations: 243
action -1, numVisits=24, meanQ=-5.300413, numObservations: 22
action 4, numVisits=4, meanQ=-6.000000, numObservations: 4
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.383622 0.454338 0.778696 0.0711289 0.50708 0.253605 0.842692 0.833432 0.787451 0.18986 w: 1
Observation: 0 0 2 0 1 0 3 0 3 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=92, meanQ=87.717066, numObservations: 8
action 3, numVisits=12, meanQ=54.915008, numObservations: 5
action 4, numVisits=2, meanQ=44.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 38187 episodes
GETTING ACTION FROM:
action 1, numVisits=38279, meanQ=86.030920, numObservations: 9
action 3, numVisits=12, meanQ=54.915008, numObservations: 5
action 4, numVisits=2, meanQ=44.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.383622 0.454338 0.778696 0.0711289 0.50708 0.253605 0.842692 0.833432 0.787451 0.18986 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 97
Initial state: 0 0.541159 0.549414 0.113052 0.55728 0.101256 0.265808 0.347697 0.440634 0.0418981 0.364808 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32001 episodes
GETTING ACTION FROM:
action 4, numVisits=31971, meanQ=23.998079, numObservations: 9
action 3, numVisits=22, meanQ=18.181364, numObservations: 9
action 5, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.541159 0.549414 0.113052 0.55728 0.101256 0.265808 0.347697 0.440634 0.0418981 0.364808 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=535, meanQ=75.667217, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 41255 episodes
GETTING ACTION FROM:
action 4, numVisits=41790, meanQ=88.709588, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.541159 0.549414 0.113052 0.55728 0.101256 0.265808 0.347697 0.440634 0.0418981 0.364808 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 98
Initial state: 0 0.801786 0.437818 0.0013907 0.130441 0.45359 0.485806 0.192386 0.0724989 0.383574 0.527882 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31839 episodes
GETTING ACTION FROM:
action 1, numVisits=31802, meanQ=24.363828, numObservations: 9
action 3, numVisits=24, meanQ=21.540425, numObservations: 9
action 5, numVisits=9, meanQ=7.998889, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.801786 0.437818 0.0013907 0.130441 0.45359 0.485806 0.192386 0.0724989 0.383574 0.527882 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 99
Initial state: 0 0.637356 0.281018 0.655186 0.0812867 0.725543 0.46334 0.37869 0.538528 0.517778 0.716912 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17987 episodes
GETTING ACTION FROM:
action 0, numVisits=17908, meanQ=63.190409, numObservations: 243
action 5, numVisits=12, meanQ=-4.250833, numObservations: 6
action -1, numVisits=63, meanQ=-4.373329, numObservations: 56
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.637356 0.281018 0.655186 0.0812867 0.725543 0.46334 0.37869 0.538528 0.517778 0.716912 w: 1
Observation: 0 0 1 0 1 0 2 0 2 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=79, meanQ=61.203042, numObservations: 8
action 4, numVisits=3, meanQ=26.326667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 35852 episodes
GETTING ACTION FROM:
action 5, numVisits=35931, meanQ=59.837897, numObservations: 9
action 4, numVisits=3, meanQ=26.326667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.637356 0.281018 0.655186 0.0812867 0.725543 0.46334 0.37869 0.538528 0.517778 0.716912 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 100
Initial state: 0 0.955316 0.159592 0.307959 0.498742 0.472673 0.708202 0.585273 0.50447 0.740633 0.0133955 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32049 episodes
GETTING ACTION FROM:
action 2, numVisits=31986, meanQ=24.063872, numObservations: 9
action -1, numVisits=26, meanQ=-1.010000, numObservations: 26
action 0, numVisits=26, meanQ=-1.010000, numObservations: 26
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=5, meanQ=-21.000000, numObservations: 2
action 4, numVisits=4, meanQ=-28.500000, numObservations: 4
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.955316 0.159592 0.307959 0.498742 0.472673 0.708202 0.585273 0.50447 0.740633 0.0133955 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 101
Initial state: 0 0.918159 0.534889 0.354009 0.490703 0.981435 0.417482 0.319517 0.642306 0.689044 0.76422 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30698 episodes
GETTING ACTION FROM:
action 1, numVisits=30690, meanQ=25.371284, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.918159 0.534889 0.354009 0.490703 0.981435 0.417482 0.319517 0.642306 0.689044 0.76422 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 102
Initial state: 0 0.330917 0.422563 0.712602 0.60765 0.950883 0.133061 0.858367 0.551914 0.369527 0.20775 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17680 episodes
GETTING ACTION FROM:
action -1, numVisits=17663, meanQ=52.908477, numObservations: 243
action 3, numVisits=4, meanQ=-5.752500, numObservations: 4
action 0, numVisits=7, meanQ=-15.435714, numObservations: 6
action 1, numVisits=3, meanQ=-34.333333, numObservations: 2
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.330917 0.422563 0.712602 0.60765 0.950883 0.133061 0.858367 0.551914 0.369527 0.20775 w: 1
Observation: 0 2 0 3 0 3 0 3 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=119, meanQ=37.591197, numObservations: 33
action 5, numVisits=4, meanQ=-1.000000, numObservations: 3
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 4, numVisits=9, meanQ=-2.001111, numObservations: 6
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 16862 episodes
GETTING ACTION FROM:
action -1, numVisits=16981, meanQ=62.031929, numObservations: 169
action 5, numVisits=4, meanQ=-1.000000, numObservations: 3
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 4, numVisits=9, meanQ=-2.001111, numObservations: 6
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.330917 0.422563 0.712602 0.60765 0.950883 0.133061 0.858367 0.551914 0.369527 0.20775 w: 1
Observation: 0 2 0 3 0 3 0 3 0 2 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 0, numVisits=4715, meanQ=78.195072, numObservations: 220
action 2, numVisits=18, meanQ=-2.606661, numObservations: 4
action 3, numVisits=5, meanQ=-2.802000, numObservations: 2
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action -1, numVisits=6, meanQ=-18.171650, numObservations: 4
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 17726 episodes
GETTING ACTION FROM:
action 0, numVisits=22441, meanQ=81.752908, numObservations: 240
action 2, numVisits=18, meanQ=-2.606661, numObservations: 4
action 3, numVisits=5, meanQ=-2.802000, numObservations: 2
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action -1, numVisits=6, meanQ=-18.171650, numObservations: 4
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.330917 0.422563 0.712602 0.60765 0.950883 0.133061 0.858367 0.551914 0.369527 0.20775 w: 1
Observation: 0 0 2 0 3 0 1 0 2 0 1 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=149, meanQ=78.865772, numObservations: 6
action 1, numVisits=2, meanQ=44.495000, numObservations: 1
action 4, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 50305 episodes
GETTING ACTION FROM:
action 2, numVisits=50454, meanQ=75.293452, numObservations: 9
action 1, numVisits=2, meanQ=44.495000, numObservations: 1
action 4, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.330917 0.422563 0.712602 0.60765 0.950883 0.133061 0.858367 0.551914 0.369527 0.20775 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 90.1194
Run # 103
Initial state: 0 0.0860034 0.870784 0.026011 0.84308 0.573249 0.978996 0.790215 0.311933 0.323054 0.484866 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18267 episodes
GETTING ACTION FROM:
action 0, numVisits=18163, meanQ=61.840972, numObservations: 243
action -1, numVisits=97, meanQ=-1.930088, numObservations: 70
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.0860034 0.870784 0.026011 0.84308 0.573249 0.978996 0.790215 0.311933 0.323054 0.484866 w: 1
Observation: 0 0 3 0 3 0 2 0 1 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=74, meanQ=45.378515, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37110 episodes
GETTING ACTION FROM:
action 3, numVisits=37184, meanQ=70.567971, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.0860034 0.870784 0.026011 0.84308 0.573249 0.978996 0.790215 0.311933 0.323054 0.484866 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 104
Initial state: 0 0.304311 0.468968 0.719261 0.26063 0.426695 0.416575 0.832276 0.195728 0.178528 0.322558 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32817 episodes
GETTING ACTION FROM:
action 4, numVisits=32811, meanQ=22.859282, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.304311 0.468968 0.719261 0.26063 0.426695 0.416575 0.832276 0.195728 0.178528 0.322558 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 105
Initial state: 0 0.176321 0.192152 0.924923 0.455716 0.33534 0.559104 0.553376 0.213173 0.871959 0.293643 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18200 episodes
GETTING ACTION FROM:
action 0, numVisits=18175, meanQ=61.075641, numObservations: 243
action 2, numVisits=4, meanQ=-5.752500, numObservations: 4
action -1, numVisits=17, meanQ=-6.950000, numObservations: 16
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.176321 0.192152 0.924923 0.455716 0.33534 0.559104 0.553376 0.213173 0.871959 0.293643 w: 1
Observation: 0 0 1 0 1 0 2 0 1 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=94, meanQ=83.330107, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 37484 episodes
GETTING ACTION FROM:
action 3, numVisits=37578, meanQ=86.876157, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 3
Next state: 1 0.176321 0.192152 0.924923 0.455716 0.33534 0.559104 0.553376 0.213173 0.871959 0.293643 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 106
Initial state: 0 0.335942 0.0789222 0.343968 0.496586 0.200324 0.926123 0.285712 0.927694 0.0750106 0.428242 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31625 episodes
GETTING ACTION FROM:
action 3, numVisits=31618, meanQ=25.319862, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.335942 0.0789222 0.343968 0.496586 0.200324 0.926123 0.285712 0.927694 0.0750106 0.428242 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1868, meanQ=32.600055, numObservations: 9
action 4, numVisits=10, meanQ=26.297000, numObservations: 5
action 5, numVisits=4, meanQ=21.747500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 35755 episodes
GETTING ACTION FROM:
action 2, numVisits=37623, meanQ=30.984911, numObservations: 9
action 4, numVisits=10, meanQ=26.297000, numObservations: 5
action 5, numVisits=4, meanQ=21.747500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.335942 0.0789222 0.343968 0.496586 0.200324 0.926123 0.285712 0.927694 0.0750106 0.428242 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 107
Initial state: 0 0.759261 0.67551 0.990409 0.333647 0.485547 0.541163 0.243548 0.955701 0.349384 0.525765 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31323 episodes
GETTING ACTION FROM:
action 1, numVisits=31195, meanQ=22.808181, numObservations: 9
action -1, numVisits=52, meanQ=-1.524610, numObservations: 43
action 0, numVisits=53, meanQ=-1.570751, numObservations: 47
action 5, numVisits=18, meanQ=-3.327772, numObservations: 6
action 2, numVisits=3, meanQ=-4.003333, numObservations: 2
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.759261 0.67551 0.990409 0.333647 0.485547 0.541163 0.243548 0.955701 0.349384 0.525765 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 108
Initial state: 0 0.334237 0.462046 0.212948 0.35452 0.0974482 0.908047 0.169971 0.637631 0.176716 0.143185 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32731 episodes
GETTING ACTION FROM:
action 3, numVisits=32711, meanQ=23.990861, numObservations: 9
action 2, numVisits=14, meanQ=11.857143, numObservations: 7
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.334237 0.462046 0.212948 0.35452 0.0974482 0.908047 0.169971 0.637631 0.176716 0.143185 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1026, meanQ=38.984856, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=3, meanQ=-4.003333, numObservations: 3
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 15299 episodes
GETTING ACTION FROM:
action 1, numVisits=16325, meanQ=26.926649, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=3, meanQ=-4.003333, numObservations: 3
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.334237 0.462046 0.212948 0.35452 0.0974482 0.908047 0.169971 0.637631 0.176716 0.143185 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 109
Initial state: 0 0.979344 0.872092 0.322999 0.502729 0.409829 0.396572 0.428434 0.449215 0.634494 0.0870476 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31460 episodes
GETTING ACTION FROM:
action 5, numVisits=31454, meanQ=22.869109, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.979344 0.872092 0.322999 0.502729 0.409829 0.396572 0.428434 0.449215 0.634494 0.0870476 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 110
Initial state: 0 0.673493 0.906757 0.0756118 0.684237 0.0213445 0.387473 0.991466 0.896578 0.399381 0.486273 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31772 episodes
GETTING ACTION FROM:
action 3, numVisits=31756, meanQ=22.841327, numObservations: 9
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 1, numVisits=5, meanQ=-3.000000, numObservations: 4
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.673493 0.906757 0.0756118 0.684237 0.0213445 0.387473 0.991466 0.896578 0.399381 0.486273 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=2376, meanQ=27.141961, numObservations: 9
action 1, numVisits=26, meanQ=23.729619, numObservations: 9
action 4, numVisits=4, meanQ=21.747500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 12939 episodes
GETTING ACTION FROM:
action 1, numVisits=11854, meanQ=25.243347, numObservations: 9
action 5, numVisits=3445, meanQ=23.602197, numObservations: 9
action 4, numVisits=46, meanQ=21.812343, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 1
Next state: 1 0.673493 0.906757 0.0756118 0.684237 0.0213445 0.387473 0.991466 0.896578 0.399381 0.486273 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 111
Initial state: 0 0.375722 0.997857 0.360433 0.443046 0.460395 0.0355436 0.235522 0.131539 0.630666 0.592917 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32994 episodes
GETTING ACTION FROM:
action 3, numVisits=32984, meanQ=22.982578, numObservations: 9
action 2, numVisits=5, meanQ=15.198000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.375722 0.997857 0.360433 0.443046 0.460395 0.0355436 0.235522 0.131539 0.630666 0.592917 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=630, meanQ=30.861316, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 29839 episodes
GETTING ACTION FROM:
action 1, numVisits=30461, meanQ=8.573877, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=6, meanQ=-1.505000, numObservations: 6
action 0, numVisits=6, meanQ=-1.505000, numObservations: 5
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.375722 0.997857 0.360433 0.443046 0.460395 0.0355436 0.235522 0.131539 0.630666 0.592917 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 112
Initial state: 0 0.790058 0.819634 0.544939 0.644234 0.389708 0.509425 0.707066 0.596449 0.981499 0.534586 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32894 episodes
GETTING ACTION FROM:
action 3, numVisits=32827, meanQ=22.727485, numObservations: 9
action 1, numVisits=25, meanQ=12.599608, numObservations: 8
action 5, numVisits=26, meanQ=12.537308, numObservations: 9
action 2, numVisits=13, meanQ=5.306154, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.790058 0.819634 0.544939 0.644234 0.389708 0.509425 0.707066 0.596449 0.981499 0.534586 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 113
Initial state: 0 0.386322 0.565796 0.357856 0.595896 0.0829291 0.892681 0.569405 0.455167 0.610914 0.23916 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32780 episodes
GETTING ACTION FROM:
action 5, numVisits=32768, meanQ=22.924863, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.386322 0.565796 0.357856 0.595896 0.0829291 0.892681 0.569405 0.455167 0.610914 0.23916 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 114
Initial state: 0 0.305417 0.451104 0.544699 0.997498 0.380723 0.746075 0.949167 0.382534 0.959168 0.433991 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31532 episodes
GETTING ACTION FROM:
action 2, numVisits=31522, meanQ=24.602798, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=4, meanQ=-5.752500, numObservations: 4
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.305417 0.451104 0.544699 0.997498 0.380723 0.746075 0.949167 0.382534 0.959168 0.433991 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 115
Initial state: 0 0.623787 0.7274 0.864626 0.298401 0.21428 0.818186 0.728581 0.635924 0.302331 0.518914 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18359 episodes
GETTING ACTION FROM:
action 0, numVisits=18327, meanQ=65.183850, numObservations: 243
action -1, numVisits=27, meanQ=-1.010000, numObservations: 27
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.623787 0.7274 0.864626 0.298401 0.21428 0.818186 0.728581 0.635924 0.302331 0.518914 w: 1
Observation: 0 0 3 0 3 0 3 0 1 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=84, meanQ=83.571548, numObservations: 7
action 1, numVisits=14, meanQ=70.428571, numObservations: 5
action 2, numVisits=3, meanQ=62.663333, numObservations: 2
action 3, numVisits=2, meanQ=44.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37962 episodes
GETTING ACTION FROM:
action 5, numVisits=38046, meanQ=86.237501, numObservations: 9
action 1, numVisits=14, meanQ=70.428571, numObservations: 5
action 2, numVisits=3, meanQ=62.663333, numObservations: 2
action 3, numVisits=2, meanQ=44.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.623787 0.7274 0.864626 0.298401 0.21428 0.818186 0.728581 0.635924 0.302331 0.518914 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 116
Initial state: 0 0.799606 0.00322155 0.962074 0.139725 0.380944 0.436043 0.282477 0.175319 0.362777 0.882435 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31558 episodes
GETTING ACTION FROM:
action 2, numVisits=31521, meanQ=23.357669, numObservations: 9
action 3, numVisits=24, meanQ=16.375833, numObservations: 8
action 1, numVisits=6, meanQ=14.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=4, meanQ=-8.477475, numObservations: 3
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.799606 0.00322155 0.962074 0.139725 0.380944 0.436043 0.282477 0.175319 0.362777 0.882435 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 117
Initial state: 0 0.333983 0.476203 0.00375861 0.754651 0.682878 0.553121 0.257491 0.987081 0.85388 0.760733 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32507 episodes
GETTING ACTION FROM:
action 1, numVisits=32420, meanQ=22.867768, numObservations: 9
action 2, numVisits=80, meanQ=15.889627, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.333983 0.476203 0.00375861 0.754651 0.682878 0.553121 0.257491 0.987081 0.85388 0.760733 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 118
Initial state: 0 0.384337 0.471544 0.306944 0.404483 0.613713 0.0546721 0.862983 0.935097 0.661843 0.965746 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17396 episodes
GETTING ACTION FROM:
action -1, numVisits=17348, meanQ=55.289083, numObservations: 243
action 0, numVisits=35, meanQ=-3.895143, numObservations: 34
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=9, meanQ=-12.111111, numObservations: 7
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.384337 0.471544 0.306944 0.404483 0.613713 0.0546721 0.862983 0.935097 0.661843 0.965746 w: 1
Observation: 0 2 0 2 0 3 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=146, meanQ=41.102947, numObservations: 9
action 3, numVisits=3, meanQ=32.333333, numObservations: 3
action 1, numVisits=5, meanQ=19.000000, numObservations: 4
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 36234 episodes
GETTING ACTION FROM:
action 2, numVisits=36380, meanQ=63.594623, numObservations: 9
action 3, numVisits=3, meanQ=32.333333, numObservations: 3
action 1, numVisits=5, meanQ=19.000000, numObservations: 4
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.384337 0.471544 0.306944 0.404483 0.613713 0.0546721 0.862983 0.935097 0.661843 0.965746 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101.99
Run # 119
Initial state: 0 0.332038 0.435595 0.292405 0.704887 0.817446 0.317544 0.769304 0.591489 0.574279 0.115981 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17996 episodes
GETTING ACTION FROM:
action -1, numVisits=17976, meanQ=55.312916, numObservations: 243
action 0, numVisits=11, meanQ=-1.010000, numObservations: 11
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=5, meanQ=-21.000000, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.332038 0.435595 0.292405 0.704887 0.817446 0.317544 0.769304 0.591489 0.574279 0.115981 w: 1
Observation: 0 1 0 1 0 3 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=27, meanQ=72.740370, numObservations: 6
action 1, numVisits=27, meanQ=36.628519, numObservations: 7
action 5, numVisits=3, meanQ=32.333333, numObservations: 3
action 4, numVisits=5, meanQ=19.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 28457 episodes
GETTING ACTION FROM:
action 1, numVisits=28452, meanQ=53.312430, numObservations: 9
action 3, numVisits=57, meanQ=24.982281, numObservations: 8
action 4, numVisits=5, meanQ=19.000000, numObservations: 3
action 5, numVisits=5, meanQ=19.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 1
Next state: 1 0.332038 0.435595 0.292405 0.704887 0.817446 0.317544 0.769304 0.591489 0.574279 0.115981 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 120
Initial state: 0 0.727419 0.285093 0.349456 0.549331 0.261061 0.716344 0.332759 0.590101 0.11401 0.0575109 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32568 episodes
GETTING ACTION FROM:
action 5, numVisits=32546, meanQ=24.072526, numObservations: 9
action 4, numVisits=13, meanQ=20.690769, numObservations: 6
action 1, numVisits=5, meanQ=19.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.727419 0.285093 0.349456 0.549331 0.261061 0.716344 0.332759 0.590101 0.11401 0.0575109 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=2572, meanQ=29.366089, numObservations: 9
action 1, numVisits=8, meanQ=21.747500, numObservations: 6
action 3, numVisits=4, meanQ=21.747500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 11969 episodes
GETTING ACTION FROM:
action 1, numVisits=10382, meanQ=27.227360, numObservations: 9
action 2, numVisits=4163, meanQ=21.551525, numObservations: 9
action 3, numVisits=8, meanQ=10.373750, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 1
Next state: 2 0.727419 0.285093 0.349456 0.549331 0.261061 0.716344 0.332759 0.590101 0.11401 0.0575109 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -110.99
Run # 121
Initial state: 0 0.563657 0.830817 0.784016 0.194496 0.312195 0.445617 0.167937 0.7328 0.265488 0.313223 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33124 episodes
GETTING ACTION FROM:
action 1, numVisits=33095, meanQ=21.988651, numObservations: 9
action 4, numVisits=21, meanQ=13.718576, numObservations: 8
action 2, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.563657 0.830817 0.784016 0.194496 0.312195 0.445617 0.167937 0.7328 0.265488 0.313223 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 122
Initial state: 0 0.460265 0.123845 0.899132 0.574266 0.689889 0.418425 0.39922 0.424239 0.595665 0.471548 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32745 episodes
GETTING ACTION FROM:
action 1, numVisits=32716, meanQ=23.101070, numObservations: 9
action 3, numVisits=17, meanQ=20.822941, numObservations: 7
action 5, numVisits=8, meanQ=8.751250, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.460265 0.123845 0.899132 0.574266 0.689889 0.418425 0.39922 0.424239 0.595665 0.471548 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 123
Initial state: 0 0.0995326 0.650034 0.372556 0.455654 0.206543 0.777998 0.904461 0.552964 0.756339 0.4245 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18255 episodes
GETTING ACTION FROM:
action 0, numVisits=18182, meanQ=64.161397, numObservations: 243
action -1, numVisits=62, meanQ=-1.538213, numObservations: 50
action 5, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=5, meanQ=-4.998000, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.0995326 0.650034 0.372556 0.455654 0.206543 0.777998 0.904461 0.552964 0.756339 0.4245 w: 1
Observation: 0 0 3 0 2 0 3 0 2 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=52, meanQ=52.521737, numObservations: 9
action 2, numVisits=18, meanQ=26.277222, numObservations: 5
action 5, numVisits=4, meanQ=21.747500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 36705 episodes
GETTING ACTION FROM:
action 4, numVisits=36757, meanQ=68.462495, numObservations: 9
action 2, numVisits=18, meanQ=26.277222, numObservations: 5
action 5, numVisits=4, meanQ=21.747500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 4
Next state: 2 0.0995326 0.650034 0.372556 0.455654 0.206543 0.777998 0.904461 0.552964 0.756339 0.4245 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101.99
Run # 124
Initial state: 0 0.321444 0.484461 0.129889 0.742145 0.584213 0.427241 0.107401 0.835782 0.74323 0.406268 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32980 episodes
GETTING ACTION FROM:
action 2, numVisits=32974, meanQ=24.727490, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.321444 0.484461 0.129889 0.742145 0.584213 0.427241 0.107401 0.835782 0.74323 0.406268 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=2022, meanQ=30.376059, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=3, meanQ=-4.003333, numObservations: 3
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 35947 episodes
GETTING ACTION FROM:
action 5, numVisits=37969, meanQ=37.356476, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=3, meanQ=-4.003333, numObservations: 3
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 5
Next state: 2 0.321444 0.484461 0.129889 0.742145 0.584213 0.427241 0.107401 0.835782 0.74323 0.406268 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -110.99
Run # 125
Initial state: 0 0.262699 0.0937832 0.277309 0.855153 0.340284 0.538748 0.889465 0.613528 0.66364 0.384191 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31714 episodes
GETTING ACTION FROM:
action 1, numVisits=31694, meanQ=23.821728, numObservations: 9
action 2, numVisits=14, meanQ=5.428571, numObservations: 7
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.262699 0.0937832 0.277309 0.855153 0.340284 0.538748 0.889465 0.613528 0.66364 0.384191 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=2383, meanQ=28.115395, numObservations: 9
action 4, numVisits=54, meanQ=26.945744, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 11728 episodes
GETTING ACTION FROM:
action 3, numVisits=14107, meanQ=26.255096, numObservations: 9
action 4, numVisits=58, meanQ=23.121900, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 3
Next state: 0 0.262699 0.0937832 0.277309 0.855153 0.340284 0.538748 0.889465 0.613528 0.66364 0.384191 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=76, meanQ=35.055247, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 21638 episodes
GETTING ACTION FROM:
action 2, numVisits=21714, meanQ=28.840652, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 2
Next state: 0 0.262699 0.0937832 0.277309 0.855153 0.340284 0.538748 0.889465 0.613528 0.66364 0.384191 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=1, meanQ=99.000000, numObservations: 1
action -1, numVisits=78, meanQ=18.089777, numObservations: 25
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 2, numVisits=1, meanQ=-17.883243, numObservations: 1
action 5, numVisits=6, meanQ=-66.602607, numObservations: 3
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 1, numVisits=1, meanQ=-544.348791, numObservations: 1
Sampled 15854 episodes
GETTING ACTION FROM:
action 3, numVisits=32, meanQ=85.308461, numObservations: 6
action -1, numVisits=15901, meanQ=3.374152, numObservations: 241
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 2, numVisits=1, meanQ=-17.883243, numObservations: 1
action 5, numVisits=6, meanQ=-66.602607, numObservations: 3
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 1, numVisits=1, meanQ=-544.348791, numObservations: 1
action: 3
Next state: 1 0.262699 0.0937832 0.277309 0.855153 0.340284 0.538748 0.889465 0.613528 0.66364 0.384191 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 63.3885
Run # 126
Initial state: 0 0.365259 0.528674 0.475151 0.0919436 0.666796 0.00518744 0.387736 0.00267723 0.126136 0.414018 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31610 episodes
GETTING ACTION FROM:
action 2, numVisits=31604, meanQ=24.324162, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.365259 0.528674 0.475151 0.0919436 0.666796 0.00518744 0.387736 0.00267723 0.126136 0.414018 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 127
Initial state: 0 0.0180558 0.990162 0.517924 0.326789 0.374958 0.709924 0.803148 0.408546 0.346596 0.489283 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32826 episodes
GETTING ACTION FROM:
action 2, numVisits=32818, meanQ=23.388642, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.0180558 0.990162 0.517924 0.326789 0.374958 0.709924 0.803148 0.408546 0.346596 0.489283 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 128
Initial state: 0 0.276083 0.283646 0.117559 0.941475 0.349855 0.965541 0.384832 0.539353 0.137007 0.728434 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32375 episodes
GETTING ACTION FROM:
action 3, numVisits=32367, meanQ=23.941516, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.276083 0.283646 0.117559 0.941475 0.349855 0.965541 0.384832 0.539353 0.137007 0.728434 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 129
Initial state: 0 0.660826 0.489433 0.121604 0.236699 0.431298 0.815358 0.349206 0.448645 0.514914 0.978395 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17642 episodes
GETTING ACTION FROM:
action -1, numVisits=17562, meanQ=55.716973, numObservations: 243
action 0, numVisits=37, meanQ=-4.141343, numObservations: 33
action 1, numVisits=29, meanQ=-6.138272, numObservations: 8
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=9, meanQ=-14.113333, numObservations: 7
action 3, numVisits=3, meanQ=-34.333333, numObservations: 3
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.660826 0.489433 0.121604 0.236699 0.431298 0.815358 0.349206 0.448645 0.514914 0.978395 w: 1
Observation: 0 3 0 1 0 3 0 2 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=160, meanQ=84.681376, numObservations: 9
action 2, numVisits=2, meanQ=44.495000, numObservations: 1
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 38080 episodes
GETTING ACTION FROM:
action 4, numVisits=38240, meanQ=88.862839, numObservations: 9
action 2, numVisits=2, meanQ=44.495000, numObservations: 1
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.660826 0.489433 0.121604 0.236699 0.431298 0.815358 0.349206 0.448645 0.514914 0.978395 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 130
Initial state: 0 0.889481 0.535681 0.309393 0.421955 0.513543 0.700385 0.596356 0.424746 0.26303 0.316758 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18318 episodes
GETTING ACTION FROM:
action 0, numVisits=18298, meanQ=63.325889, numObservations: 243
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action -1, numVisits=13, meanQ=-8.777692, numObservations: 12
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.889481 0.535681 0.309393 0.421955 0.513543 0.700385 0.596356 0.424746 0.26303 0.316758 w: 1
Observation: 0 0 2 0 2 0 3 0 3 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=62, meanQ=49.064521, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37028 episodes
GETTING ACTION FROM:
action 2, numVisits=37090, meanQ=54.562704, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.889481 0.535681 0.309393 0.421955 0.513543 0.700385 0.596356 0.424746 0.26303 0.316758 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=827, meanQ=86.824869, numObservations: 9
action 4, numVisits=45, meanQ=62.090671, numObservations: 6
action 3, numVisits=11, meanQ=52.726364, numObservations: 4
action 1, numVisits=4, meanQ=44.495000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 41354 episodes
GETTING ACTION FROM:
action 2, numVisits=42181, meanQ=88.951264, numObservations: 9
action 4, numVisits=45, meanQ=62.090671, numObservations: 6
action 3, numVisits=11, meanQ=52.726364, numObservations: 4
action 1, numVisits=4, meanQ=44.495000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 2
Next state: 1 0.889481 0.535681 0.309393 0.421955 0.513543 0.700385 0.596356 0.424746 0.26303 0.316758 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 84.1399
Run # 131
Initial state: 0 0.328522 0.530457 0.537342 0.319117 0.245449 0.424806 0.818412 0.169038 0.430431 0.269996 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32623 episodes
GETTING ACTION FROM:
action 1, numVisits=32614, meanQ=23.096761, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.328522 0.530457 0.537342 0.319117 0.245449 0.424806 0.818412 0.169038 0.430431 0.269996 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 132
Initial state: 0 0.683511 0.00981022 0.396297 0.46284 0.924864 0.430115 0.822182 0.185773 0.401817 0.348446 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18117 episodes
GETTING ACTION FROM:
action 0, numVisits=18057, meanQ=61.871831, numObservations: 243
action -1, numVisits=46, meanQ=-1.569996, numObservations: 42
action 1, numVisits=10, meanQ=-3.000000, numObservations: 4
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.683511 0.00981022 0.396297 0.46284 0.924864 0.430115 0.822182 0.185773 0.401817 0.348446 w: 1
Observation: 0 0 1 0 2 0 2 0 1 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=83, meanQ=60.409522, numObservations: 8
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37610 episodes
GETTING ACTION FROM:
action 3, numVisits=37693, meanQ=47.235858, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.683511 0.00981022 0.396297 0.46284 0.924864 0.430115 0.822182 0.185773 0.401817 0.348446 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 133
Initial state: 0 0.375289 0.800673 0.334585 0.0259596 0.198115 0.34345 0.31989 0.455084 0.705904 0.191752 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18338 episodes
GETTING ACTION FROM:
action 0, numVisits=18321, meanQ=63.143489, numObservations: 243
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=10, meanQ=-11.901000, numObservations: 6
action -1, numVisits=3, meanQ=-34.670000, numObservations: 2
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.375289 0.800673 0.334585 0.0259596 0.198115 0.34345 0.31989 0.455084 0.705904 0.191752 w: 1
Observation: 0 0 1 0 1 0 1 0 2 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=98, meanQ=74.737862, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37381 episodes
GETTING ACTION FROM:
action 4, numVisits=37479, meanQ=83.782660, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.375289 0.800673 0.334585 0.0259596 0.198115 0.34345 0.31989 0.455084 0.705904 0.191752 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=2295, meanQ=92.281476, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 41689 episodes
GETTING ACTION FROM:
action 4, numVisits=43984, meanQ=97.233993, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.375289 0.800673 0.334585 0.0259596 0.198115 0.34345 0.31989 0.455084 0.705904 0.191752 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 84.1399
Run # 134
Initial state: 0 0.999363 0.454562 0.980737 0.351415 0.398918 0.534286 0.250537 0.67112 0.945862 0.54527 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30253 episodes
GETTING ACTION FROM:
action 2, numVisits=30246, meanQ=25.968634, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.999363 0.454562 0.980737 0.351415 0.398918 0.534286 0.250537 0.67112 0.945862 0.54527 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 135
Initial state: 0 0.326165 0.566484 0.210814 0.138364 0.606596 0.0365717 0.917269 0.847648 0.313691 0.647307 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31587 episodes
GETTING ACTION FROM:
action 1, numVisits=31575, meanQ=23.987787, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=6, meanQ=-4.168333, numObservations: 6
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.326165 0.566484 0.210814 0.138364 0.606596 0.0365717 0.917269 0.847648 0.313691 0.647307 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 136
Initial state: 0 0.574685 0.719019 0.617396 0.0515079 0.521135 0.355703 0.404752 0.512733 0.385125 0.664348 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32026 episodes
GETTING ACTION FROM:
action 5, numVisits=31996, meanQ=23.221513, numObservations: 9
action 1, numVisits=25, meanQ=5.118800, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.574685 0.719019 0.617396 0.0515079 0.521135 0.355703 0.404752 0.512733 0.385125 0.664348 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 137
Initial state: 0 0.843958 0.0931258 0.229573 0.170198 0.376418 0.743352 0.940645 0.84162 0.385999 0.471354 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32864 episodes
GETTING ACTION FROM:
action 2, numVisits=32857, meanQ=23.654779, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.843958 0.0931258 0.229573 0.170198 0.376418 0.743352 0.940645 0.84162 0.385999 0.471354 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 138
Initial state: 0 0.0945173 0.494148 0.878433 0.250473 0.410672 0.507719 0.951253 0.356473 0.392388 0.719598 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31245 episodes
GETTING ACTION FROM:
action 3, numVisits=31238, meanQ=25.342207, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.0945173 0.494148 0.878433 0.250473 0.410672 0.507719 0.951253 0.356473 0.392388 0.719598 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 139
Initial state: 0 0.114756 0.78074 0.815119 0.577686 0.302293 0.460915 0.585673 0.0300819 0.729164 0.982308 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30149 episodes
GETTING ACTION FROM:
action 2, numVisits=30141, meanQ=24.845870, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.114756 0.78074 0.815119 0.577686 0.302293 0.460915 0.585673 0.0300819 0.729164 0.982308 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 140
Initial state: 0 0.974155 0.170403 0.685039 0.48054 0.597183 0.48575 0.79942 0.759555 0.300653 0.467414 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31138 episodes
GETTING ACTION FROM:
action 2, numVisits=31129, meanQ=23.252759, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.974155 0.170403 0.685039 0.48054 0.597183 0.48575 0.79942 0.759555 0.300653 0.467414 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 141
Initial state: 0 0.53235 0.291909 0.9282 0.776348 0.390813 0.554696 0.650261 0.639277 0.648068 0.429834 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32845 episodes
GETTING ACTION FROM:
action 5, numVisits=32789, meanQ=23.392993, numObservations: 9
action 3, numVisits=46, meanQ=21.413050, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=5, meanQ=-3.000000, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.53235 0.291909 0.9282 0.776348 0.390813 0.554696 0.650261 0.639277 0.648068 0.429834 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 142
Initial state: 0 0.0194033 0.496227 0.35804 0.479888 0.575848 0.702169 0.925107 0.993582 0.0613247 0.424116 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17777 episodes
GETTING ACTION FROM:
action -1, numVisits=17736, meanQ=58.464488, numObservations: 242
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action 0, numVisits=18, meanQ=-6.620000, numObservations: 17
action 4, numVisits=15, meanQ=-7.666667, numObservations: 7
action 1, numVisits=3, meanQ=-34.333333, numObservations: 2
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.0194033 0.496227 0.35804 0.479888 0.575848 0.702169 0.925107 0.993582 0.0613247 0.424116 w: 1
Observation: 0 2 0 2 0 3 0 3 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=58, meanQ=26.741381, numObservations: 8
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37611 episodes
GETTING ACTION FROM:
action 1, numVisits=37669, meanQ=62.377711, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.0194033 0.496227 0.35804 0.479888 0.575848 0.702169 0.925107 0.993582 0.0613247 0.424116 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=302, meanQ=58.841259, numObservations: 9
action 4, numVisits=8, meanQ=24.000000, numObservations: 4
action 2, numVisits=4, meanQ=21.747500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37367 episodes
GETTING ACTION FROM:
action 1, numVisits=312, meanQ=58.745607, numObservations: 9
action 4, numVisits=37365, meanQ=27.773580, numObservations: 9
action 2, numVisits=4, meanQ=21.747500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.0194033 0.496227 0.35804 0.479888 0.575848 0.702169 0.925107 0.993582 0.0613247 0.424116 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -111.88
Run # 143
Initial state: 0 0.328435 0.466628 0.0730608 0.720235 0.289276 0.116787 0.514617 0.04558 0.926552 0.792764 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30101 episodes
GETTING ACTION FROM:
action 1, numVisits=30093, meanQ=23.186404, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.328435 0.466628 0.0730608 0.720235 0.289276 0.116787 0.514617 0.04558 0.926552 0.792764 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=457, meanQ=34.826390, numObservations: 146
action -1, numVisits=5, meanQ=-1.010000, numObservations: 5
action 2, numVisits=4, meanQ=-5.505000, numObservations: 4
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 25749 episodes
GETTING ACTION FROM:
action 0, numVisits=26206, meanQ=7.056295, numObservations: 243
action -1, numVisits=5, meanQ=-1.010000, numObservations: 5
action 2, numVisits=4, meanQ=-5.505000, numObservations: 4
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.328435 0.466628 0.0730608 0.720235 0.289276 0.116787 0.514617 0.04558 0.926552 0.792764 w: 1
Observation: 0 0 2 0 3 0 1 0 1 0 2 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=8, meanQ=33.121250, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 42076 episodes
GETTING ACTION FROM:
action 2, numVisits=42084, meanQ=60.990616, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.328435 0.466628 0.0730608 0.720235 0.289276 0.116787 0.514617 0.04558 0.926552 0.792764 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 84.0499
Run # 144
Initial state: 0 0.110226 0.605142 0.704913 0.540533 0.366563 0.472371 0.18218 0.0540429 0.136746 0.906788 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18455 episodes
GETTING ACTION FROM:
action 0, numVisits=18386, meanQ=63.749025, numObservations: 243
action 2, numVisits=35, meanQ=-3.857429, numObservations: 9
action 5, numVisits=3, meanQ=-4.333333, numObservations: 3
action -1, numVisits=28, meanQ=-5.005711, numObservations: 26
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.110226 0.605142 0.704913 0.540533 0.366563 0.472371 0.18218 0.0540429 0.136746 0.906788 w: 1
Observation: 0 0 3 0 2 0 1 0 1 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=95, meanQ=87.222317, numObservations: 7
action 5, numVisits=14, meanQ=74.862150, numObservations: 4
action 1, numVisits=4, meanQ=49.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37852 episodes
GETTING ACTION FROM:
action 2, numVisits=37947, meanQ=87.656634, numObservations: 9
action 5, numVisits=14, meanQ=74.862150, numObservations: 4
action 1, numVisits=4, meanQ=49.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.110226 0.605142 0.704913 0.540533 0.366563 0.472371 0.18218 0.0540429 0.136746 0.906788 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 145
Initial state: 0 0.413067 0.233534 0.407985 0.581961 0.75544 0.0984258 0.109024 0.173763 0.869754 0.832032 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17868 episodes
GETTING ACTION FROM:
action -1, numVisits=17843, meanQ=53.674890, numObservations: 243
action 0, numVisits=18, meanQ=-1.230000, numObservations: 16
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.413067 0.233534 0.407985 0.581961 0.75544 0.0984258 0.109024 0.173763 0.869754 0.832032 w: 1
Observation: 0 1 0 2 0 3 0 1 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=76, meanQ=42.455957, numObservations: 24
action 0, numVisits=15, meanQ=-7.742000, numObservations: 14
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 18419 episodes
GETTING ACTION FROM:
action -1, numVisits=18495, meanQ=79.902351, numObservations: 180
action 0, numVisits=15, meanQ=-7.742000, numObservations: 14
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.413067 0.233534 0.407985 0.581961 0.75544 0.0984258 0.109024 0.173763 0.869754 0.832032 w: 1
Observation: 0 3 0 2 0 3 0 1 0 3 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=1238, meanQ=94.472252, numObservations: 9
action 4, numVisits=2, meanQ=44.495000, numObservations: 2
action 3, numVisits=3, meanQ=32.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 38652 episodes
GETTING ACTION FROM:
action 2, numVisits=39890, meanQ=96.686157, numObservations: 9
action 4, numVisits=2, meanQ=44.495000, numObservations: 2
action 3, numVisits=3, meanQ=32.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.413067 0.233534 0.407985 0.581961 0.75544 0.0984258 0.109024 0.173763 0.869754 0.832032 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 93.0499
Run # 146
Initial state: 0 0.885563 0.23211 0.356732 0.474128 0.282283 0.0764784 0.244896 0.999554 0.995311 0.871828 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32798 episodes
GETTING ACTION FROM:
action 2, numVisits=32782, meanQ=22.928343, numObservations: 9
action -1, numVisits=5, meanQ=-1.010000, numObservations: 5
action 0, numVisits=5, meanQ=-1.010000, numObservations: 5
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=3, meanQ=-34.333333, numObservations: 3
action: 2
Next state: 1 0.885563 0.23211 0.356732 0.474128 0.282283 0.0764784 0.244896 0.999554 0.995311 0.871828 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 147
Initial state: 0 0.21134 0.78388 0.304164 0.516514 0.573767 0.170395 0.886171 0.298108 0.712523 0.230744 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17753 episodes
GETTING ACTION FROM:
action -1, numVisits=17727, meanQ=57.071293, numObservations: 243
action 5, numVisits=13, meanQ=-3.307692, numObservations: 6
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=9, meanQ=-12.230000, numObservations: 8
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.21134 0.78388 0.304164 0.516514 0.573767 0.170395 0.886171 0.298108 0.712523 0.230744 w: 1
Observation: 0 1 0 2 0 3 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=207, meanQ=82.696088, numObservations: 9
action 4, numVisits=3, meanQ=32.333333, numObservations: 3
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 38368 episodes
GETTING ACTION FROM:
action 2, numVisits=38575, meanQ=87.876121, numObservations: 9
action 4, numVisits=3, meanQ=32.333333, numObservations: 3
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 2
Next state: 1 0.21134 0.78388 0.304164 0.516514 0.573767 0.170395 0.886171 0.298108 0.712523 0.230744 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 148
Initial state: 0 0.227538 0.850953 0.00899934 0.612161 0.178644 0.78367 0.409332 0.523736 0.525105 0.326294 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31630 episodes
GETTING ACTION FROM:
action 2, numVisits=31624, meanQ=22.504798, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.227538 0.850953 0.00899934 0.612161 0.178644 0.78367 0.409332 0.523736 0.525105 0.326294 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=228, meanQ=18.484055, numObservations: 113
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=9, meanQ=-15.223333, numObservations: 4
action 0, numVisits=5, meanQ=-21.206000, numObservations: 4
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 13329 episodes
GETTING ACTION FROM:
action -1, numVisits=13557, meanQ=5.906166, numObservations: 243
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=9, meanQ=-15.223333, numObservations: 4
action 0, numVisits=5, meanQ=-21.206000, numObservations: 4
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.227538 0.850953 0.00899934 0.612161 0.178644 0.78367 0.409332 0.523736 0.525105 0.326294 w: 1
Observation: 0 1 0 1 0 1 0 1 0 3 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-19.012648, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 8940 episodes
GETTING ACTION FROM:
action 4, numVisits=8924, meanQ=48.597506, numObservations: 9
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=6, meanQ=-18.170000, numObservations: 5
action 1, numVisits=1, meanQ=-19.012648, numObservations: 1
action -1, numVisits=12, meanQ=-91.048086, numObservations: 10
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.227538 0.850953 0.00899934 0.612161 0.178644 0.78367 0.409332 0.523736 0.525105 0.326294 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 84.0499
Run # 149
Initial state: 0 0.597834 0.621821 0.375032 0.472919 0.967643 0.794876 0.480718 0.650152 0.0305544 0.988127 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31648 episodes
GETTING ACTION FROM:
action 4, numVisits=31601, meanQ=24.570292, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 5, numVisits=22, meanQ=-2.125895, numObservations: 8
action 2, numVisits=19, meanQ=-2.527363, numObservations: 6
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.597834 0.621821 0.375032 0.472919 0.967643 0.794876 0.480718 0.650152 0.0305544 0.988127 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 150
Initial state: 0 0.953044 0.297498 0.749939 0.125947 0.331635 0.995587 0.154665 0.922246 0.37103 0.42444 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17778 episodes
GETTING ACTION FROM:
action -1, numVisits=17752, meanQ=56.461489, numObservations: 242
action 0, numVisits=17, meanQ=-1.651171, numObservations: 16
action 4, numVisits=5, meanQ=-3.000000, numObservations: 4
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.953044 0.297498 0.749939 0.125947 0.331635 0.995587 0.154665 0.922246 0.37103 0.42444 w: 1
Observation: 0 3 0 3 0 2 0 1 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=37, meanQ=-1.652965, numObservations: 34
action -1, numVisits=3, meanQ=-4.643300, numObservations: 2
action 4, numVisits=15, meanQ=-6.993987, numObservations: 4
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=5, meanQ=-21.000000, numObservations: 2
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 18187 episodes
GETTING ACTION FROM:
action 0, numVisits=18166, meanQ=76.182647, numObservations: 243
action 1, numVisits=59, meanQ=-1.828981, numObservations: 7
action -1, numVisits=3, meanQ=-4.643300, numObservations: 2
action 4, numVisits=15, meanQ=-6.993987, numObservations: 4
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=5, meanQ=-21.000000, numObservations: 2
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.953044 0.297498 0.749939 0.125947 0.331635 0.995587 0.154665 0.922246 0.37103 0.42444 w: 1
Observation: 0 0 1 0 1 0 3 0 3 0 2 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=136, meanQ=87.545518, numObservations: 9
action 3, numVisits=2, meanQ=44.495000, numObservations: 2
action 1, numVisits=3, meanQ=32.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37941 episodes
GETTING ACTION FROM:
action 5, numVisits=38077, meanQ=93.564578, numObservations: 9
action 3, numVisits=2, meanQ=44.495000, numObservations: 2
action 1, numVisits=3, meanQ=32.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.953044 0.297498 0.749939 0.125947 0.331635 0.995587 0.154665 0.922246 0.37103 0.42444 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 93.0499
Run # 151
Initial state: 0 0.381069 0.212335 0.7202 0.0262359 0.881634 0.481926 0.0604217 0.216939 0.352665 0.545335 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17967 episodes
GETTING ACTION FROM:
action 0, numVisits=17915, meanQ=63.973729, numObservations: 243
action 1, numVisits=5, meanQ=-2.802000, numObservations: 4
action 4, numVisits=3, meanQ=-4.003333, numObservations: 3
action 5, numVisits=20, meanQ=-4.549990, numObservations: 8
action -1, numVisits=20, meanQ=-6.059000, numObservations: 19
action 2, numVisits=3, meanQ=-34.333333, numObservations: 3
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.381069 0.212335 0.7202 0.0262359 0.881634 0.481926 0.0604217 0.216939 0.352665 0.545335 w: 1
Observation: 0 0 1 0 1 0 2 0 3 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=56, meanQ=59.196786, numObservations: 8
action 3, numVisits=20, meanQ=27.098505, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 32671 episodes
GETTING ACTION FROM:
action 4, numVisits=32727, meanQ=61.636918, numObservations: 9
action 3, numVisits=20, meanQ=27.098505, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.381069 0.212335 0.7202 0.0262359 0.881634 0.481926 0.0604217 0.216939 0.352665 0.545335 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action -1, numVisits=660, meanQ=54.770460, numObservations: 111
action 0, numVisits=8, meanQ=-1.010000, numObservations: 8
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=7, meanQ=-15.285714, numObservations: 5
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 4894 episodes
GETTING ACTION FROM:
action -1, numVisits=5554, meanQ=45.942283, numObservations: 216
action 0, numVisits=8, meanQ=-1.010000, numObservations: 8
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=7, meanQ=-15.285714, numObservations: 5
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.381069 0.212335 0.7202 0.0262359 0.881634 0.481926 0.0604217 0.216939 0.352665 0.545335 w: 1
Observation: 0 2 0 3 0 3 0 1 0 2 0 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 4, numVisits=1, meanQ=99.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action -1, numVisits=4, meanQ=-5.039374, numObservations: 3
action 5, numVisits=1, meanQ=-16.668400, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 25265 episodes
GETTING ACTION FROM:
action 4, numVisits=3, meanQ=25.333367, numObservations: 1
action 3, numVisits=25264, meanQ=16.696863, numObservations: 9
action 0, numVisits=5, meanQ=-1.010000, numObservations: 5
action -1, numVisits=4, meanQ=-5.039374, numObservations: 3
action 5, numVisits=1, meanQ=-16.668400, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.381069 0.212335 0.7202 0.0262359 0.881634 0.481926 0.0604217 0.216939 0.352665 0.545335 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: -11
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28877 episodes
GETTING ACTION FROM:
action 5, numVisits=28870, meanQ=75.546901, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.381069 0.212335 0.7202 0.0262359 0.881634 0.481926 0.0604217 0.216939 0.352665 0.545335 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 69.5755
Run # 152
Initial state: 0 0.393114 0.125588 0.402584 0.529405 0.718313 0.352467 0.449642 0.908374 0.288902 0.920869 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30777 episodes
GETTING ACTION FROM:
action 4, numVisits=30770, meanQ=26.065390, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.393114 0.125588 0.402584 0.529405 0.718313 0.352467 0.449642 0.908374 0.288902 0.920869 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 153
Initial state: 0 0.479678 0.157586 0.359068 0.553233 0.981194 0.969538 0.94935 0.774284 0.722916 0.225788 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32635 episodes
GETTING ACTION FROM:
action 2, numVisits=32548, meanQ=23.828216, numObservations: 9
action 0, numVisits=64, meanQ=-4.460305, numObservations: 57
action -1, numVisits=19, meanQ=-6.324737, numObservations: 18
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.479678 0.157586 0.359068 0.553233 0.981194 0.969538 0.94935 0.774284 0.722916 0.225788 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 154
Initial state: 0 0.343582 0.322772 0.258748 0.827411 0.123165 0.907591 0.795624 0.209829 0.382023 0.511933 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32644 episodes
GETTING ACTION FROM:
action 2, numVisits=32636, meanQ=22.779427, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.343582 0.322772 0.258748 0.827411 0.123165 0.907591 0.795624 0.209829 0.382023 0.511933 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=241, meanQ=12.342882, numObservations: 129
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=3, meanQ=-34.333333, numObservations: 3
action 4, numVisits=3, meanQ=-34.333333, numObservations: 3
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 13432 episodes
GETTING ACTION FROM:
action 0, numVisits=13670, meanQ=6.485281, numObservations: 243
action -1, numVisits=10, meanQ=-1.307000, numObservations: 10
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=3, meanQ=-34.333333, numObservations: 3
action 4, numVisits=3, meanQ=-34.333333, numObservations: 3
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.343582 0.322772 0.258748 0.827411 0.123165 0.907591 0.795624 0.209829 0.382023 0.511933 w: 1
Observation: 0 0 1 0 3 0 3 0 1 0 2 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=1, meanQ=99.000000, numObservations: 1
action 3, numVisits=3, meanQ=99.000000, numObservations: 1
action 5, numVisits=5, meanQ=99.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 38149 episodes
GETTING ACTION FROM:
action 5, numVisits=37849, meanQ=84.310389, numObservations: 9
action 3, numVisits=307, meanQ=71.280130, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.343582 0.322772 0.258748 0.827411 0.123165 0.907591 0.795624 0.209829 0.382023 0.511933 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 84.0499
Run # 155
Initial state: 0 0.124907 0.265652 0.960089 0.804657 0.372788 0.476229 0.448725 0.928977 0.10358 0.854356 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18283 episodes
GETTING ACTION FROM:
action 0, numVisits=18266, meanQ=62.035758, numObservations: 243
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=10, meanQ=-11.108000, numObservations: 9
action 5, numVisits=3, meanQ=-34.333333, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.124907 0.265652 0.960089 0.804657 0.372788 0.476229 0.448725 0.928977 0.10358 0.854356 w: 1
Observation: 0 0 2 0 3 0 2 0 3 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=54, meanQ=59.871854, numObservations: 9
action 5, numVisits=5, meanQ=55.396000, numObservations: 4
action 1, numVisits=9, meanQ=52.553333, numObservations: 4
action 3, numVisits=8, meanQ=46.747500, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 34057 episodes
GETTING ACTION FROM:
action 2, numVisits=34111, meanQ=63.982918, numObservations: 9
action 5, numVisits=5, meanQ=55.396000, numObservations: 4
action 1, numVisits=9, meanQ=52.553333, numObservations: 4
action 3, numVisits=8, meanQ=46.747500, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 2
Next state: 1 0.124907 0.265652 0.960089 0.804657 0.372788 0.476229 0.448725 0.928977 0.10358 0.854356 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 156
Initial state: 0 0.330766 0.471044 0.550957 0.352687 0.930478 0.0852997 0.51999 0.472792 0.991701 0.948747 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18276 episodes
GETTING ACTION FROM:
action 0, numVisits=18232, meanQ=61.347422, numObservations: 243
action -1, numVisits=23, meanQ=-1.010000, numObservations: 23
action 4, numVisits=15, meanQ=-5.654653, numObservations: 7
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=3, meanQ=-34.333333, numObservations: 3
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.330766 0.471044 0.550957 0.352687 0.930478 0.0852997 0.51999 0.472792 0.991701 0.948747 w: 1
Observation: 0 0 2 0 1 0 1 0 1 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=107, meanQ=84.701123, numObservations: 8
action 5, numVisits=2, meanQ=44.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37648 episodes
GETTING ACTION FROM:
action 1, numVisits=37755, meanQ=86.232017, numObservations: 9
action 5, numVisits=2, meanQ=44.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.330766 0.471044 0.550957 0.352687 0.930478 0.0852997 0.51999 0.472792 0.991701 0.948747 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=2219, meanQ=92.168334, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 41744 episodes
GETTING ACTION FROM:
action 1, numVisits=43963, meanQ=97.071245, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.330766 0.471044 0.550957 0.352687 0.930478 0.0852997 0.51999 0.472792 0.991701 0.948747 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 84.1399
Run # 157
Initial state: 0 0.564899 0.27061 0.672987 0.442251 0.414026 0.433496 0.366976 0.537888 0.506132 0.125629 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31968 episodes
GETTING ACTION FROM:
action 1, numVisits=31171, meanQ=24.277025, numObservations: 9
action 4, numVisits=790, meanQ=22.355732, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.564899 0.27061 0.672987 0.442251 0.414026 0.433496 0.366976 0.537888 0.506132 0.125629 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 158
Initial state: 0 0.769212 0.964166 0.656086 0.0254172 0.928619 0.42929 0.369486 0.472436 0.461499 0.584059 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17601 episodes
GETTING ACTION FROM:
action -1, numVisits=17564, meanQ=58.079151, numObservations: 243
action 0, numVisits=32, meanQ=-4.165625, numObservations: 31
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.769212 0.964166 0.656086 0.0254172 0.928619 0.42929 0.369486 0.472436 0.461499 0.584059 w: 1
Observation: 0 3 0 3 0 3 0 2 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=340, meanQ=85.450729, numObservations: 9
action 3, numVisits=5, meanQ=19.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 38202 episodes
GETTING ACTION FROM:
action 4, numVisits=38542, meanQ=88.225318, numObservations: 9
action 3, numVisits=5, meanQ=19.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 4
Next state: 1 0.769212 0.964166 0.656086 0.0254172 0.928619 0.42929 0.369486 0.472436 0.461499 0.584059 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 159
Initial state: 0 0.30245 0.533605 0.999554 0.301305 0.0305598 0.618824 0.905951 0.928194 0.508826 0.947504 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31639 episodes
GETTING ACTION FROM:
action 5, numVisits=31633, meanQ=22.642601, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.30245 0.533605 0.999554 0.301305 0.0305598 0.618824 0.905951 0.928194 0.508826 0.947504 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 160
Initial state: 0 0.975214 0.336783 0.34371 0.438394 0.504041 0.0208989 0.459581 0.32662 0.837792 0.41165 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31624 episodes
GETTING ACTION FROM:
action 4, numVisits=31603, meanQ=23.902337, numObservations: 9
action 1, numVisits=5, meanQ=19.000000, numObservations: 5
action 3, numVisits=10, meanQ=14.999010, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.975214 0.336783 0.34371 0.438394 0.504041 0.0208989 0.459581 0.32662 0.837792 0.41165 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 161
Initial state: 0 0.169843 0.958573 0.618065 0.895988 0.313703 0.530832 0.417949 0.744485 0.29405 0.946194 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17931 episodes
GETTING ACTION FROM:
action -1, numVisits=17910, meanQ=56.364220, numObservations: 243
action 0, numVisits=10, meanQ=-1.010000, numObservations: 10
action 4, numVisits=5, meanQ=-3.000000, numObservations: 4
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.169843 0.958573 0.618065 0.895988 0.313703 0.530832 0.417949 0.744485 0.29405 0.946194 w: 1
Observation: 0 1 0 3 0 2 0 3 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=94, meanQ=79.925322, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37952 episodes
GETTING ACTION FROM:
action 3, numVisits=38046, meanQ=87.292710, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.169843 0.958573 0.618065 0.895988 0.313703 0.530832 0.417949 0.744485 0.29405 0.946194 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 162
Initial state: 0 0.309657 0.479466 0.645923 0.542029 0.759037 0.304718 0.619219 0.750816 0.399264 0.13269 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31496 episodes
GETTING ACTION FROM:
action 5, numVisits=31490, meanQ=24.809408, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.309657 0.479466 0.645923 0.542029 0.759037 0.304718 0.619219 0.750816 0.399264 0.13269 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 163
Initial state: 0 0.149672 0.447433 0.390765 0.492625 0.324341 0.692191 0.82615 0.609378 0.630724 0.511661 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31910 episodes
GETTING ACTION FROM:
action 5, numVisits=31901, meanQ=23.853302, numObservations: 9
action 3, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.149672 0.447433 0.390765 0.492625 0.324341 0.692191 0.82615 0.609378 0.630724 0.511661 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 164
Initial state: 0 0.330255 0.113339 0.786291 0.872377 0.331705 0.445104 0.702001 0.399578 0.510839 0.731793 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18261 episodes
GETTING ACTION FROM:
action 0, numVisits=18218, meanQ=62.694912, numObservations: 243
action -1, numVisits=32, meanQ=-7.724056, numObservations: 28
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=7, meanQ=-15.285714, numObservations: 4
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.330255 0.113339 0.786291 0.872377 0.331705 0.445104 0.702001 0.399578 0.510839 0.731793 w: 1
Observation: 0 0 1 0 3 0 2 0 1 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=68, meanQ=64.735882, numObservations: 9
action 3, numVisits=29, meanQ=52.136900, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 33909 episodes
GETTING ACTION FROM:
action 2, numVisits=33977, meanQ=63.864629, numObservations: 9
action 3, numVisits=29, meanQ=52.136900, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.330255 0.113339 0.786291 0.872377 0.331705 0.445104 0.702001 0.399578 0.510839 0.731793 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101.99
Run # 165
Initial state: 0 0.220391 0.871242 0.274359 0.812454 0.40555 0.480998 0.930723 0.274801 0.74976 0.161784 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31758 episodes
GETTING ACTION FROM:
action 5, numVisits=31749, meanQ=23.311124, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.220391 0.871242 0.274359 0.812454 0.40555 0.480998 0.930723 0.274801 0.74976 0.161784 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 166
Initial state: 0 0.340572 0.446435 0.308332 0.20481 0.991171 0.798317 0.844737 0.585587 0.122765 0.0806777 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32440 episodes
GETTING ACTION FROM:
action 3, numVisits=32433, meanQ=22.592108, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.340572 0.446435 0.308332 0.20481 0.991171 0.798317 0.844737 0.585587 0.122765 0.0806777 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 167
Initial state: 0 0.530564 0.199142 0.686545 0.563677 0.328934 0.543486 0.630611 0.0586841 0.931986 0.207509 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17888 episodes
GETTING ACTION FROM:
action -1, numVisits=17842, meanQ=53.998309, numObservations: 243
action 0, numVisits=33, meanQ=-1.670600, numObservations: 31
action 1, numVisits=7, meanQ=-2.428571, numObservations: 5
action 3, numVisits=3, meanQ=-4.333333, numObservations: 2
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.530564 0.199142 0.686545 0.563677 0.328934 0.543486 0.630611 0.0586841 0.931986 0.207509 w: 1
Observation: 0 3 0 1 0 2 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=153, meanQ=82.837650, numObservations: 8
action 2, numVisits=2, meanQ=44.495000, numObservations: 2
action 1, numVisits=3, meanQ=32.333333, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 38420 episodes
GETTING ACTION FROM:
action 3, numVisits=38573, meanQ=88.321068, numObservations: 9
action 2, numVisits=2, meanQ=44.495000, numObservations: 2
action 1, numVisits=3, meanQ=32.333333, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 3
Next state: 0 0.530564 0.199142 0.686545 0.563677 0.328934 0.543486 0.630611 0.0586841 0.931986 0.207509 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=2398, meanQ=90.799305, numObservations: 9
action 4, numVisits=3, meanQ=32.333333, numObservations: 2
action 5, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 41866 episodes
GETTING ACTION FROM:
action 3, numVisits=44264, meanQ=97.119871, numObservations: 9
action 4, numVisits=3, meanQ=32.333333, numObservations: 2
action 5, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.530564 0.199142 0.686545 0.563677 0.328934 0.543486 0.630611 0.0586841 0.931986 0.207509 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 84.1399
Run # 168
Initial state: 0 0.383991 0.319983 0.850245 0.807508 0.616923 0.100978 0.331153 0.537337 0.913487 0.319831 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32863 episodes
GETTING ACTION FROM:
action 1, numVisits=32832, meanQ=24.330226, numObservations: 9
action 4, numVisits=6, meanQ=14.000000, numObservations: 4
action 3, numVisits=10, meanQ=13.010010, numObservations: 6
action 5, numVisits=10, meanQ=8.000000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action: 1
Next state: 2 0.383991 0.319983 0.850245 0.807508 0.616923 0.100978 0.331153 0.537337 0.913487 0.319831 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 169
Initial state: 0 0.322206 0.581857 0.415796 0.688382 0.294465 0.891456 0.754969 0.867773 0.174583 0.234056 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17908 episodes
GETTING ACTION FROM:
action -1, numVisits=17872, meanQ=56.233326, numObservations: 243
action 0, numVisits=18, meanQ=-1.010000, numObservations: 18
action 4, numVisits=12, meanQ=-3.583333, numObservations: 6
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.322206 0.581857 0.415796 0.688382 0.294465 0.891456 0.754969 0.867773 0.174583 0.234056 w: 1
Observation: 0 2 0 3 0 1 0 3 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=89, meanQ=88.045056, numObservations: 8
action 3, numVisits=2, meanQ=44.495000, numObservations: 2
action 4, numVisits=2, meanQ=44.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 38258 episodes
GETTING ACTION FROM:
action 1, numVisits=38347, meanQ=86.426402, numObservations: 9
action 3, numVisits=2, meanQ=44.495000, numObservations: 2
action 4, numVisits=2, meanQ=44.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.322206 0.581857 0.415796 0.688382 0.294465 0.891456 0.754969 0.867773 0.174583 0.234056 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 170
Initial state: 0 0.520353 0.914541 0.627535 0.706831 0.376714 0.430187 0.012472 0.584875 0.605424 0.0893246 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32272 episodes
GETTING ACTION FROM:
action 3, numVisits=32261, meanQ=24.286734, numObservations: 9
action 5, numVisits=6, meanQ=14.000000, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.520353 0.914541 0.627535 0.706831 0.376714 0.430187 0.012472 0.584875 0.605424 0.0893246 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 171
Initial state: 0 0.693784 0.354206 0.894099 0.370788 0.312159 0.218836 0.206361 0.319869 0.302031 0.581227 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32810 episodes
GETTING ACTION FROM:
action 1, numVisits=32800, meanQ=23.241187, numObservations: 9
action 2, numVisits=5, meanQ=15.000000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.693784 0.354206 0.894099 0.370788 0.312159 0.218836 0.206361 0.319869 0.302031 0.581227 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=720, meanQ=29.362596, numObservations: 9
action 4, numVisits=6, meanQ=14.165000, numObservations: 5
action 2, numVisits=14, meanQ=11.998571, numObservations: 6
action 3, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 18996 episodes
GETTING ACTION FROM:
action 0, numVisits=15669, meanQ=3.562182, numObservations: 243
action 5, numVisits=3916, meanQ=3.163340, numObservations: 9
action 2, numVisits=33, meanQ=1.484242, numObservations: 9
action 4, numVisits=17, meanQ=-1.530000, numObservations: 7
action -1, numVisits=102, meanQ=-12.312734, numObservations: 61
action 3, numVisits=5, meanQ=-21.000000, numObservations: 4
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.693784 0.354206 0.894099 0.370788 0.312159 0.218836 0.206361 0.319869 0.302031 0.581227 w: 1
Observation: 0 0 1 0 1 0 1 0 1 0 2 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-16.672452, numObservations: 1
action 5, numVisits=1, meanQ=-17.418214, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 30113 episodes
GETTING ACTION FROM:
action -1, numVisits=29958, meanQ=-1.128180, numObservations: 222
action 0, numVisits=158, meanQ=-3.234367, numObservations: 38
action 4, numVisits=1, meanQ=-16.672452, numObservations: 1
action 5, numVisits=1, meanQ=-17.418214, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.693784 0.354206 0.894099 0.370788 0.312159 0.218836 0.206361 0.319869 0.302031 0.581227 w: 1
Observation: 0 3 0 3 0 2 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 5, numVisits=1, meanQ=99.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 56696 episodes
GETTING ACTION FROM:
action 5, numVisits=56696, meanQ=71.759613, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.693784 0.354206 0.894099 0.370788 0.312159 0.218836 0.206361 0.319869 0.302031 0.581227 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 81.1194
Run # 172
Initial state: 0 0.323921 0.84934 0.0811545 0.700573 0.645736 0.544764 0.301931 0.482627 0.695301 0.300121 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33241 episodes
GETTING ACTION FROM:
action 3, numVisits=25158, meanQ=23.032915, numObservations: 9
action 5, numVisits=8073, meanQ=22.910132, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=5, meanQ=-3.000000, numObservations: 4
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.323921 0.84934 0.0811545 0.700573 0.645736 0.544764 0.301931 0.482627 0.695301 0.300121 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 173
Initial state: 0 0.361406 0.502118 0.332863 0.742926 0.646245 0.27457 0.868014 0.72782 0.759091 0.896132 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31693 episodes
GETTING ACTION FROM:
action 1, numVisits=31666, meanQ=24.694514, numObservations: 9
action 5, numVisits=22, meanQ=8.193195, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.361406 0.502118 0.332863 0.742926 0.646245 0.27457 0.868014 0.72782 0.759091 0.896132 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 174
Initial state: 0 0.383978 0.944629 0.343639 0.576715 0.0494261 0.0800753 0.451877 0.326215 0.898857 0.12861 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33012 episodes
GETTING ACTION FROM:
action 3, numVisits=33004, meanQ=23.246882, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.383978 0.944629 0.343639 0.576715 0.0494261 0.0800753 0.451877 0.326215 0.898857 0.12861 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=2409, meanQ=32.399331, numObservations: 9
action 2, numVisits=50, meanQ=18.939604, numObservations: 9
action 1, numVisits=61, meanQ=18.559851, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 9812 episodes
GETTING ACTION FROM:
action 1, numVisits=7029, meanQ=28.789512, numObservations: 9
action 5, numVisits=5252, meanQ=19.764912, numObservations: 9
action 2, numVisits=51, meanQ=16.587847, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 1
Next state: 2 0.383978 0.944629 0.343639 0.576715 0.0494261 0.0800753 0.451877 0.326215 0.898857 0.12861 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -110.99
Run # 175
Initial state: 0 0.835218 0.473093 0.324212 0.535562 0.735454 0.578669 0.275738 0.0036652 0.800501 0.301014 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31710 episodes
GETTING ACTION FROM:
action 4, numVisits=31704, meanQ=23.677347, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.835218 0.473093 0.324212 0.535562 0.735454 0.578669 0.275738 0.0036652 0.800501 0.301014 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=2519, meanQ=24.770133, numObservations: 9
action 5, numVisits=9, meanQ=8.108889, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=9, meanQ=-2.001111, numObservations: 5
action 1, numVisits=3, meanQ=-4.003333, numObservations: 3
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 9325 episodes
GETTING ACTION FROM:
action 2, numVisits=11844, meanQ=27.007344, numObservations: 9
action 5, numVisits=9, meanQ=8.108889, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=9, meanQ=-2.001111, numObservations: 5
action 1, numVisits=3, meanQ=-4.003333, numObservations: 3
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.835218 0.473093 0.324212 0.535562 0.735454 0.578669 0.275738 0.0036652 0.800501 0.301014 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 176
Initial state: 0 0.885162 0.482711 0.321973 0.515813 0.802264 0.796291 0.968316 0.960429 0.018318 0.503375 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32170 episodes
GETTING ACTION FROM:
action 3, numVisits=32134, meanQ=24.871485, numObservations: 9
action 2, numVisits=26, meanQ=12.883850, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=5, meanQ=-3.000000, numObservations: 4
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.885162 0.482711 0.321973 0.515813 0.802264 0.796291 0.968316 0.960429 0.018318 0.503375 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 177
Initial state: 0 0.339474 0.489619 0.756493 0.260703 0.875762 0.0167035 0.546531 0.714956 0.362325 0.818213 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32640 episodes
GETTING ACTION FROM:
action 1, numVisits=32634, meanQ=24.062307, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.339474 0.489619 0.756493 0.260703 0.875762 0.0167035 0.546531 0.714956 0.362325 0.818213 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=86, meanQ=33.190358, numObservations: 9
action 4, numVisits=26, meanQ=2.733481, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 38755 episodes
GETTING ACTION FROM:
action 3, numVisits=38841, meanQ=25.396542, numObservations: 9
action 4, numVisits=26, meanQ=2.733481, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.339474 0.489619 0.756493 0.260703 0.875762 0.0167035 0.546531 0.714956 0.362325 0.818213 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -110.99
Run # 178
Initial state: 0 0.419804 0.0152953 0.360678 0.790649 0.303788 0.428045 0.418949 0.734268 0.363456 0.346447 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32775 episodes
GETTING ACTION FROM:
action 5, numVisits=32765, meanQ=23.722299, numObservations: 9
action 2, numVisits=5, meanQ=15.198000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.419804 0.0152953 0.360678 0.790649 0.303788 0.428045 0.418949 0.734268 0.363456 0.346447 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 179
Initial state: 0 0.518941 0.399794 0.790158 0.0870083 0.658432 0.521639 0.364171 0.527674 0.583226 0.937749 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18307 episodes
GETTING ACTION FROM:
action 0, numVisits=18270, meanQ=63.091802, numObservations: 243
action -1, numVisits=32, meanQ=-4.289375, numObservations: 29
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.518941 0.399794 0.790158 0.0870083 0.658432 0.521639 0.364171 0.527674 0.583226 0.937749 w: 1
Observation: 0 0 1 0 1 0 3 0 2 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=92, meanQ=81.739786, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 36850 episodes
GETTING ACTION FROM:
action 4, numVisits=36942, meanQ=82.000870, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.518941 0.399794 0.790158 0.0870083 0.658432 0.521639 0.364171 0.527674 0.583226 0.937749 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=2236, meanQ=62.885302, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 41133 episodes
GETTING ACTION FROM:
action 3, numVisits=43369, meanQ=68.402792, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.518941 0.399794 0.790158 0.0870083 0.658432 0.521639 0.364171 0.527674 0.583226 0.937749 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 84.1399
Run # 180
Initial state: 0 0.329372 0.141913 0.713659 0.824955 0.184197 0.143764 0.389029 0.494342 0.178096 0.791385 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32667 episodes
GETTING ACTION FROM:
action 1, numVisits=32608, meanQ=22.413361, numObservations: 9
action 2, numVisits=54, meanQ=19.833520, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.329372 0.141913 0.713659 0.824955 0.184197 0.143764 0.389029 0.494342 0.178096 0.791385 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 181
Initial state: 0 0.409614 0.381893 0.341583 0.452341 0.832894 0.496188 0.27895 0.388249 0.596725 0.861371 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31143 episodes
GETTING ACTION FROM:
action 5, numVisits=31110, meanQ=23.982881, numObservations: 9
action 1, numVisits=28, meanQ=21.570007, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.409614 0.381893 0.341583 0.452341 0.832894 0.496188 0.27895 0.388249 0.596725 0.861371 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 182
Initial state: 0 0.427949 0.204287 0.333502 0.556748 0.00973576 0.757211 0.392226 0.635358 0.144859 0.448515 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32554 episodes
GETTING ACTION FROM:
action 4, numVisits=32541, meanQ=23.243010, numObservations: 9
action 2, numVisits=7, meanQ=13.285714, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.427949 0.204287 0.333502 0.556748 0.00973576 0.757211 0.392226 0.635358 0.144859 0.448515 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 183
Initial state: 0 0.344742 0.440065 0.0333044 0.576718 0.00926535 0.415167 0.487607 0.284289 0.686743 0.619728 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32614 episodes
GETTING ACTION FROM:
action 5, numVisits=32607, meanQ=21.678126, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.344742 0.440065 0.0333044 0.576718 0.00926535 0.415167 0.487607 0.284289 0.686743 0.619728 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 184
Initial state: 0 0.420669 0.199952 0.348606 0.759539 0.321987 0.51828 0.339944 0.105468 0.898746 0.541814 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32599 episodes
GETTING ACTION FROM:
action 1, numVisits=32587, meanQ=23.313941, numObservations: 9
action 5, numVisits=5, meanQ=19.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.420669 0.199952 0.348606 0.759539 0.321987 0.51828 0.339944 0.105468 0.898746 0.541814 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 185
Initial state: 0 0.305954 0.580737 0.302417 0.777248 0.27598 0.680433 0.989349 0.793517 0.685981 0.996242 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31019 episodes
GETTING ACTION FROM:
action 5, numVisits=31012, meanQ=23.480942, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.305954 0.580737 0.302417 0.777248 0.27598 0.680433 0.989349 0.793517 0.685981 0.996242 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 186
Initial state: 0 0.505481 0.31379 0.392571 0.450128 0.98292 0.363748 0.0645444 0.338078 0.824515 0.523483 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18010 episodes
GETTING ACTION FROM:
action 0, numVisits=17967, meanQ=63.394494, numObservations: 243
action -1, numVisits=12, meanQ=-9.425000, numObservations: 11
action 4, numVisits=15, meanQ=-10.332000, numObservations: 6
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=13, meanQ=-11.464615, numObservations: 6
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.505481 0.31379 0.392571 0.450128 0.98292 0.363748 0.0645444 0.338078 0.824515 0.523483 w: 1
Observation: 0 0 1 0 2 0 1 0 1 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=70, meanQ=3.967579, numObservations: 55
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 0, numVisits=4, meanQ=-26.255000, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 17849 episodes
GETTING ACTION FROM:
action -1, numVisits=17919, meanQ=71.998932, numObservations: 242
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 0, numVisits=4, meanQ=-26.255000, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.505481 0.31379 0.392571 0.450128 0.98292 0.363748 0.0645444 0.338078 0.824515 0.523483 w: 1
Observation: 0 3 0 2 0 2 0 1 0 3 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=43, meanQ=62.603258, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 38246 episodes
GETTING ACTION FROM:
action 2, numVisits=38289, meanQ=92.349809, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.505481 0.31379 0.392571 0.450128 0.98292 0.363748 0.0645444 0.338078 0.824515 0.523483 w: 1
Observation: 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 93.0499
Run # 187
Initial state: 0 0.406023 0.558073 0.124237 0.895552 0.991078 0.0935102 0.646752 0.733853 0.469119 0.750097 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30693 episodes
GETTING ACTION FROM:
action 4, numVisits=30679, meanQ=24.904224, numObservations: 9
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=3, meanQ=-34.333333, numObservations: 2
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.406023 0.558073 0.124237 0.895552 0.991078 0.0935102 0.646752 0.733853 0.469119 0.750097 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 188
Initial state: 0 0.0855838 0.116022 0.375139 0.437646 0.942821 0.251251 0.279835 0.4203 0.0731372 0.35815 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32905 episodes
GETTING ACTION FROM:
action 2, numVisits=32874, meanQ=22.720162, numObservations: 9
action 5, numVisits=25, meanQ=12.603604, numObservations: 7
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.0855838 0.116022 0.375139 0.437646 0.942821 0.251251 0.279835 0.4203 0.0731372 0.35815 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 189
Initial state: 0 0.517591 0.526767 0.166026 0.462417 0.0988046 0.12974 0.405891 0.531869 0.502515 0.577949 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18162 episodes
GETTING ACTION FROM:
action 0, numVisits=18140, meanQ=62.793174, numObservations: 243
action -1, numVisits=17, meanQ=-7.067053, numObservations: 15
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.517591 0.526767 0.166026 0.462417 0.0988046 0.12974 0.405891 0.531869 0.502515 0.577949 w: 1
Observation: 0 0 2 0 2 0 1 0 2 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=5, meanQ=-2.802000, numObservations: 3
action 4, numVisits=13, meanQ=-3.079231, numObservations: 6
action 3, numVisits=3, meanQ=-4.003333, numObservations: 2
action 1, numVisits=3, meanQ=-4.003333, numObservations: 2
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 17980 episodes
GETTING ACTION FROM:
action -1, numVisits=17980, meanQ=72.852622, numObservations: 236
action 2, numVisits=5, meanQ=-2.802000, numObservations: 3
action 4, numVisits=13, meanQ=-3.079231, numObservations: 6
action 3, numVisits=3, meanQ=-4.003333, numObservations: 2
action 1, numVisits=3, meanQ=-4.003333, numObservations: 2
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 0, numVisits=4, meanQ=-26.255000, numObservations: 3
action: -1
Next state: 0 0.517591 0.526767 0.166026 0.462417 0.0988046 0.12974 0.405891 0.531869 0.502515 0.577949 w: 1
Observation: 0 3 0 1 0 1 0 2 0 3 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=32, meanQ=86.500000, numObservations: 5
action 5, numVisits=3, meanQ=32.333333, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 39166 episodes
GETTING ACTION FROM:
action 4, numVisits=39198, meanQ=84.816331, numObservations: 9
action 5, numVisits=3, meanQ=32.333333, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.517591 0.526767 0.166026 0.462417 0.0988046 0.12974 0.405891 0.531869 0.502515 0.577949 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 4, numVisits=2199, meanQ=92.538202, numObservations: 9
action 1, numVisits=7, meanQ=70.428571, numObservations: 1
action 5, numVisits=4, meanQ=49.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 42001 episodes
GETTING ACTION FROM:
action 4, numVisits=44200, meanQ=96.482666, numObservations: 9
action 1, numVisits=7, meanQ=70.428571, numObservations: 1
action 5, numVisits=4, meanQ=49.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.517591 0.526767 0.166026 0.462417 0.0988046 0.12974 0.405891 0.531869 0.502515 0.577949 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 81.2985
Run # 190
Initial state: 0 0.39482 0.47721 0.61954 0.0838937 0.948535 0.72358 0.965033 0.790506 0.793543 0.125315 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30436 episodes
GETTING ACTION FROM:
action 3, numVisits=30422, meanQ=26.020486, numObservations: 9
action 4, numVisits=6, meanQ=14.165000, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.39482 0.47721 0.61954 0.0838937 0.948535 0.72358 0.965033 0.790506 0.793543 0.125315 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 191
Initial state: 0 0.0742089 0.24307 0.0992301 0.173577 0.372706 0.457869 0.564725 0.570683 0.427145 0.999157 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30839 episodes
GETTING ACTION FROM:
action 1, numVisits=30829, meanQ=25.053714, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=3, meanQ=-4.333333, numObservations: 2
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.0742089 0.24307 0.0992301 0.173577 0.372706 0.457869 0.564725 0.570683 0.427145 0.999157 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=2432, meanQ=57.467929, numObservations: 220
action 3, numVisits=7, meanQ=-4.861429, numObservations: 5
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action -1, numVisits=4, meanQ=-26.255000, numObservations: 3
action 5, numVisits=3, meanQ=-34.333333, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 3531 episodes
GETTING ACTION FROM:
action 0, numVisits=5963, meanQ=50.063735, numObservations: 238
action 3, numVisits=7, meanQ=-4.861429, numObservations: 5
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action -1, numVisits=4, meanQ=-26.255000, numObservations: 3
action 5, numVisits=3, meanQ=-34.333333, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.0742089 0.24307 0.0992301 0.173577 0.372706 0.457869 0.564725 0.570683 0.427145 0.999157 w: 1
Observation: 0 0 1 0 1 0 2 0 2 0 3 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=27, meanQ=59.805742, numObservations: 5
action 3, numVisits=56, meanQ=42.398315, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 16311 episodes
GETTING ACTION FROM:
action 5, numVisits=16338, meanQ=69.375504, numObservations: 9
action 3, numVisits=56, meanQ=42.398315, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.0742089 0.24307 0.0992301 0.173577 0.372706 0.457869 0.564725 0.570683 0.427145 0.999157 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 84.0499
Run # 192
Initial state: 0 0.498714 0.775279 0.0482823 0.307149 0.704596 0.67796 0.32385 0.436931 0.299475 0.770937 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17911 episodes
GETTING ACTION FROM:
action -1, numVisits=17871, meanQ=57.234642, numObservations: 243
action 4, numVisits=5, meanQ=-3.000000, numObservations: 4
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action 0, numVisits=29, meanQ=-4.628621, numObservations: 26
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.498714 0.775279 0.0482823 0.307149 0.704596 0.67796 0.32385 0.436931 0.299475 0.770937 w: 1
Observation: 0 3 0 1 0 3 0 2 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=102, meanQ=89.059611, numObservations: 8
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37929 episodes
GETTING ACTION FROM:
action 4, numVisits=38031, meanQ=87.593150, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.498714 0.775279 0.0482823 0.307149 0.704596 0.67796 0.32385 0.436931 0.299475 0.770937 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 193
Initial state: 0 0.511322 0.0613652 0.349883 0.453059 0.500032 0.635269 0.969115 0.820868 0.765882 0.42587 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30309 episodes
GETTING ACTION FROM:
action 4, numVisits=30261, meanQ=25.470415, numObservations: 9
action -1, numVisits=7, meanQ=-2.567129, numObservations: 6
action 5, numVisits=12, meanQ=-4.168333, numObservations: 7
action 0, numVisits=22, meanQ=-5.600000, numObservations: 21
action 3, numVisits=5, meanQ=-6.802000, numObservations: 4
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.511322 0.0613652 0.349883 0.453059 0.500032 0.635269 0.969115 0.820868 0.765882 0.42587 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 194
Initial state: 0 0.655962 0.866914 0.267364 0.776335 0.166737 0.609137 0.630227 0.533241 0.397579 0.538167 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31443 episodes
GETTING ACTION FROM:
action 4, numVisits=31434, meanQ=23.038901, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.655962 0.866914 0.267364 0.776335 0.166737 0.609137 0.630227 0.533241 0.397579 0.538167 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 195
Initial state: 0 0.157686 0.410225 0.34676 0.469494 0.112162 0.852303 0.963859 0.821736 0.439812 0.885294 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32838 episodes
GETTING ACTION FROM:
action 5, numVisits=32831, meanQ=22.126342, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.157686 0.410225 0.34676 0.469494 0.112162 0.852303 0.963859 0.821736 0.439812 0.885294 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 196
Initial state: 0 0.878239 0.077778 0.531674 0.818138 0.312598 0.694677 0.362322 0.531594 0.636267 0.0385075 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30386 episodes
GETTING ACTION FROM:
action 3, numVisits=30313, meanQ=26.354082, numObservations: 9
action 1, numVisits=50, meanQ=22.501804, numObservations: 9
action 5, numVisits=14, meanQ=16.361436, numObservations: 9
action 2, numVisits=5, meanQ=15.198000, numObservations: 3
action 4, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 2 0.878239 0.077778 0.531674 0.818138 0.312598 0.694677 0.362322 0.531594 0.636267 0.0385075 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 197
Initial state: 0 0.103687 0.288809 0.548113 0.242096 0.296309 0.628067 0.35835 0.550416 0.460009 0.958265 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32257 episodes
GETTING ACTION FROM:
action 2, numVisits=32245, meanQ=23.834845, numObservations: 9
action 3, numVisits=4, meanQ=-1.000000, numObservations: 3
action 4, numVisits=4, meanQ=-1.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.103687 0.288809 0.548113 0.242096 0.296309 0.628067 0.35835 0.550416 0.460009 0.958265 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 198
Initial state: 0 0.171399 0.218925 0.422239 0.454591 0.221184 0.626446 0.804035 0.684874 0.356239 0.51509 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17750 episodes
GETTING ACTION FROM:
action -1, numVisits=17720, meanQ=57.325647, numObservations: 243
action 1, numVisits=6, meanQ=-5.984983, numObservations: 5
action 2, numVisits=18, meanQ=-8.772772, numObservations: 7
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=3, meanQ=-34.670000, numObservations: 2
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.171399 0.218925 0.422239 0.454591 0.221184 0.626446 0.804035 0.684874 0.356239 0.51509 w: 1
Observation: 0 2 0 3 0 1 0 3 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=76, meanQ=51.251846, numObservations: 9
action 1, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 35755 episodes
GETTING ACTION FROM:
action 5, numVisits=35831, meanQ=38.086877, numObservations: 9
action 1, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.171399 0.218925 0.422239 0.454591 0.221184 0.626446 0.804035 0.684874 0.356239 0.51509 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 199
Initial state: 0 0.731014 0.983845 0.821598 0.723678 0.897759 0.583854 0.0268168 0.673212 0.389644 0.580502 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17948 episodes
GETTING ACTION FROM:
action -1, numVisits=17908, meanQ=53.012476, numObservations: 243
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 5, numVisits=12, meanQ=-4.499983, numObservations: 6
action 0, numVisits=22, meanQ=-5.600000, numObservations: 21
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.731014 0.983845 0.821598 0.723678 0.897759 0.583854 0.0268168 0.673212 0.389644 0.580502 w: 1
Observation: 0 3 0 3 0 3 0 1 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=178, meanQ=78.883484, numObservations: 9
action 1, numVisits=4, meanQ=49.000000, numObservations: 3
action 4, numVisits=2, meanQ=44.495000, numObservations: 2
action 3, numVisits=3, meanQ=32.333333, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 38250 episodes
GETTING ACTION FROM:
action 5, numVisits=38428, meanQ=88.454880, numObservations: 9
action 1, numVisits=4, meanQ=49.000000, numObservations: 3
action 4, numVisits=2, meanQ=44.495000, numObservations: 2
action 3, numVisits=3, meanQ=32.333333, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 5
Next state: 1 0.731014 0.983845 0.821598 0.723678 0.897759 0.583854 0.0268168 0.673212 0.389644 0.580502 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 200
Initial state: 0 0.565383 0.0493506 0.406646 0.529861 0.725765 0.859531 0.854948 0.039263 0.565278 0.148495 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32978 episodes
GETTING ACTION FROM:
action 1, numVisits=32966, meanQ=23.621541, numObservations: 9
action 4, numVisits=5, meanQ=15.198000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.565383 0.0493506 0.406646 0.529861 0.725765 0.859531 0.854948 0.039263 0.565278 0.148495 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
[32m ProblemEnvironment.hpp 351: Done.[39m
