Run # 1
Initial state: 0 0.793356 0.366632 0.580603 0.728134 0.510488 0.266122 0.795626 0.485044 0.386243 0.556483 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17375 episodes
GETTING ACTION FROM:
action 0, numVisits=17336, meanQ=63.704600, numObservations: 243
action -1, numVisits=27, meanQ=-1.010000, numObservations: 27
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=5, meanQ=-21.000000, numObservations: 4
action 3, numVisits=4, meanQ=-28.500000, numObservations: 4
action: 0
Next state: 0 0.793356 0.366632 0.580603 0.728134 0.510488 0.266122 0.795626 0.485044 0.386243 0.556483 w: 1
Observation: 0 0 1 0 3 0 1 0 2 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=79, meanQ=45.565065, numObservations: 9
action 5, numVisits=5, meanQ=15.396000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 32521 episodes
GETTING ACTION FROM:
action 2, numVisits=32600, meanQ=60.388555, numObservations: 9
action 5, numVisits=5, meanQ=15.396000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.793356 0.366632 0.580603 0.728134 0.510488 0.266122 0.795626 0.485044 0.386243 0.556483 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 2
Initial state: 0 0.792377 0.730563 0.285552 0.197373 0.285514 0.434456 0.988032 0.804931 0.521725 0.588565 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30050 episodes
GETTING ACTION FROM:
action 3, numVisits=29892, meanQ=20.727589, numObservations: 9
action 5, numVisits=151, meanQ=16.966837, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.792377 0.730563 0.285552 0.197373 0.285514 0.434456 0.988032 0.804931 0.521725 0.588565 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 3
Initial state: 0 0.551192 0.664115 0.488454 0.568354 0.101303 0.525072 0.406412 0.734116 0.974325 0.633528 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17883 episodes
GETTING ACTION FROM:
action 0, numVisits=17814, meanQ=64.304643, numObservations: 243
action -1, numVisits=59, meanQ=-4.718641, numObservations: 53
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=4, meanQ=-28.500000, numObservations: 4
action 1, numVisits=3, meanQ=-34.333333, numObservations: 3
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.551192 0.664115 0.488454 0.568354 0.101303 0.525072 0.406412 0.734116 0.974325 0.633528 w: 1
Observation: 0 0 3 0 2 0 3 0 3 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=43, meanQ=78.907442, numObservations: 6
action 5, numVisits=16, meanQ=60.373750, numObservations: 4
action 3, numVisits=19, meanQ=60.104211, numObservations: 7
action 1, numVisits=2, meanQ=44.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37267 episodes
GETTING ACTION FROM:
action 2, numVisits=37310, meanQ=87.004479, numObservations: 9
action 5, numVisits=16, meanQ=60.373750, numObservations: 4
action 3, numVisits=19, meanQ=60.104211, numObservations: 7
action 1, numVisits=2, meanQ=44.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.551192 0.664115 0.488454 0.568354 0.101303 0.525072 0.406412 0.734116 0.974325 0.633528 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 4
Initial state: 0 0.181376 0.635011 0.902601 0.780899 0.99445 0.330224 0.85512 0.266403 0.395612 0.517677 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30938 episodes
GETTING ACTION FROM:
action 3, numVisits=30932, meanQ=19.047096, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.181376 0.635011 0.902601 0.780899 0.99445 0.330224 0.85512 0.266403 0.395612 0.517677 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 5
Initial state: 0 0.792071 0.708713 0.0829103 0.634502 0.526413 0.557951 0.797488 0.711471 0.829885 0.147263 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17704 episodes
GETTING ACTION FROM:
action 0, numVisits=17615, meanQ=62.523662, numObservations: 243
action -1, numVisits=84, meanQ=-0.503686, numObservations: 69
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.792071 0.708713 0.0829103 0.634502 0.526413 0.557951 0.797488 0.711471 0.829885 0.147263 w: 1
Observation: 0 0 3 0 1 0 2 0 3 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=42, meanQ=30.621679, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=3, meanQ=-4.003333, numObservations: 3
action 4, numVisits=4, meanQ=-8.002500, numObservations: 3
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 33031 episodes
GETTING ACTION FROM:
action 1, numVisits=33073, meanQ=58.624859, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=3, meanQ=-4.003333, numObservations: 3
action 4, numVisits=4, meanQ=-8.002500, numObservations: 3
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.792071 0.708713 0.0829103 0.634502 0.526413 0.557951 0.797488 0.711471 0.829885 0.147263 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 6
Initial state: 0 0.379896 0.511247 0.711153 0.184184 0.277357 0.522231 0.910907 0.0915099 0.210885 0.122121 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29751 episodes
GETTING ACTION FROM:
action 3, numVisits=29740, meanQ=19.983286, numObservations: 9
action 2, numVisits=6, meanQ=10.665017, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.379896 0.511247 0.711153 0.184184 0.277357 0.522231 0.910907 0.0915099 0.210885 0.122121 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 7
Initial state: 0 0.348403 0.967999 0.244159 0.501775 0.41595 0.5658 0.466087 0.984395 0.160169 0.777579 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17887 episodes
GETTING ACTION FROM:
action 0, numVisits=17851, meanQ=63.072040, numObservations: 243
action -1, numVisits=22, meanQ=-1.010000, numObservations: 22
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=6, meanQ=-19.333333, numObservations: 3
action 1, numVisits=5, meanQ=-21.000000, numObservations: 3
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.348403 0.967999 0.244159 0.501775 0.41595 0.5658 0.466087 0.984395 0.160169 0.777579 w: 1
Observation: 0 0 3 0 2 0 2 0 3 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=45, meanQ=62.380004, numObservations: 7
action 3, numVisits=2, meanQ=44.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 33328 episodes
GETTING ACTION FROM:
action 5, numVisits=33373, meanQ=55.035618, numObservations: 9
action 3, numVisits=2, meanQ=44.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.348403 0.967999 0.244159 0.501775 0.41595 0.5658 0.466087 0.984395 0.160169 0.777579 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=5844, meanQ=65.319342, numObservations: 9
action 3, numVisits=7, meanQ=50.568571, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 38218 episodes
GETTING ACTION FROM:
action 1, numVisits=44062, meanQ=67.958474, numObservations: 9
action 3, numVisits=7, meanQ=50.568571, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.348403 0.967999 0.244159 0.501775 0.41595 0.5658 0.466087 0.984395 0.160169 0.777579 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 84.1399
Run # 8
Initial state: 0 0.485812 0.559103 0.650021 0.0811612 0.470786 0.666753 0.897578 0.989653 0.749548 0.892853 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30033 episodes
GETTING ACTION FROM:
action 1, numVisits=29998, meanQ=19.586290, numObservations: 9
action 5, numVisits=28, meanQ=1.570714, numObservations: 8
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.485812 0.559103 0.650021 0.0811612 0.470786 0.666753 0.897578 0.989653 0.749548 0.892853 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 9
Initial state: 0 0.726465 0.654672 0.125814 0.0197853 0.283024 0.438686 0.993138 0.50249 0.518084 0.565511 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30667 episodes
GETTING ACTION FROM:
action 3, numVisits=30659, meanQ=17.122142, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=3, meanQ=-4.333333, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.726465 0.654672 0.125814 0.0197853 0.283024 0.438686 0.993138 0.50249 0.518084 0.565511 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 10
Initial state: 0 0.943895 0.29965 0.38642 0.531033 0.964435 0.448115 0.866825 0.782499 0.847367 0.162106 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29565 episodes
GETTING ACTION FROM:
action 4, numVisits=29559, meanQ=19.586626, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.943895 0.29965 0.38642 0.531033 0.964435 0.448115 0.866825 0.782499 0.847367 0.162106 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 11
Initial state: 0 0.513741 0.104659 0.381328 0.540996 0.31445 0.0553564 0.0864468 0.20652 0.922125 0.211526 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28884 episodes
GETTING ACTION FROM:
action 4, numVisits=28869, meanQ=20.395189, numObservations: 9
action 2, numVisits=7, meanQ=10.428571, numObservations: 5
action 5, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.513741 0.104659 0.381328 0.540996 0.31445 0.0553564 0.0864468 0.20652 0.922125 0.211526 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=3081, meanQ=48.802989, numObservations: 231
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 3653 episodes
GETTING ACTION FROM:
action -1, numVisits=6734, meanQ=40.102612, numObservations: 243
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.513741 0.104659 0.381328 0.540996 0.31445 0.0553564 0.0864468 0.20652 0.922125 0.211526 w: 1
Observation: 0 1 0 2 0 1 0 1 0 3 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=88, meanQ=85.490752, numObservations: 6
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 24338 episodes
GETTING ACTION FROM:
action 2, numVisits=24426, meanQ=93.159820, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.513741 0.104659 0.381328 0.540996 0.31445 0.0553564 0.0864468 0.20652 0.922125 0.211526 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 84.0499
Run # 12
Initial state: 0 0.0912137 0.835315 0.931468 0.235048 0.67519 0.020133 0.51902 0.485673 0.523896 0.8844 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29628 episodes
GETTING ACTION FROM:
action 2, numVisits=29606, meanQ=19.423846, numObservations: 9
action 5, numVisits=16, meanQ=10.250000, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.0912137 0.835315 0.931468 0.235048 0.67519 0.020133 0.51902 0.485673 0.523896 0.8844 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 13
Initial state: 0 0.859339 0.546525 0.408016 0.541887 0.51744 0.789414 0.869411 0.754286 0.753764 0.425318 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30870 episodes
GETTING ACTION FROM:
action 5, numVisits=30863, meanQ=18.049305, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.859339 0.546525 0.408016 0.541887 0.51744 0.789414 0.869411 0.754286 0.753764 0.425318 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 14
Initial state: 0 0.745095 0.157942 0.589537 0.879502 0.868 0.582538 0.439602 0.0371923 0.483929 0.499301 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29035 episodes
GETTING ACTION FROM:
action 4, numVisits=29019, meanQ=19.365682, numObservations: 9
action 3, numVisits=11, meanQ=14.363645, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.745095 0.157942 0.589537 0.879502 0.868 0.582538 0.439602 0.0371923 0.483929 0.499301 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 15
Initial state: 0 0.901315 0.127859 0.149004 0.30181 0.348075 0.0471716 0.168789 0.875718 0.404943 0.514632 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17567 episodes
GETTING ACTION FROM:
action -1, numVisits=17519, meanQ=46.489847, numObservations: 243
action 0, numVisits=41, meanQ=-1.735356, numObservations: 35
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=3, meanQ=-34.333333, numObservations: 2
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.901315 0.127859 0.149004 0.30181 0.348075 0.0471716 0.168789 0.875718 0.404943 0.514632 w: 1
Observation: 0 3 0 1 0 2 0 1 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=39, meanQ=43.742564, numObservations: 7
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 36301 episodes
GETTING ACTION FROM:
action 5, numVisits=36340, meanQ=44.328646, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.901315 0.127859 0.149004 0.30181 0.348075 0.0471716 0.168789 0.875718 0.404943 0.514632 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 16
Initial state: 0 0.309386 0.571418 0.782466 0.582734 0.887167 0.616874 0.100471 0.526501 0.366636 0.559226 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29669 episodes
GETTING ACTION FROM:
action 5, numVisits=29638, meanQ=19.425967, numObservations: 9
action 2, numVisits=22, meanQ=4.503645, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=5, meanQ=-3.000000, numObservations: 5
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.309386 0.571418 0.782466 0.582734 0.887167 0.616874 0.100471 0.526501 0.366636 0.559226 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 17
Initial state: 0 0.4118 0.0689029 0.498214 0.585921 0.153595 0.1612 0.62662 0.290749 0.356494 0.252108 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29857 episodes
GETTING ACTION FROM:
action 3, numVisits=29840, meanQ=19.450415, numObservations: 9
action 4, numVisits=11, meanQ=6.362727, numObservations: 6
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.4118 0.0689029 0.498214 0.585921 0.153595 0.1612 0.62662 0.290749 0.356494 0.252108 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 18
Initial state: 0 0.297563 0.809518 0.877715 0.260561 0.851943 0.297762 0.674252 0.179452 0.445099 0.56599 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28402 episodes
GETTING ACTION FROM:
action 1, numVisits=28336, meanQ=21.692695, numObservations: 9
action 4, numVisits=13, meanQ=10.460769, numObservations: 5
action 3, numVisits=48, meanQ=9.692717, numObservations: 8
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.297563 0.809518 0.877715 0.260561 0.851943 0.297762 0.674252 0.179452 0.445099 0.56599 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=1963, meanQ=59.801494, numObservations: 216
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 19675 episodes
GETTING ACTION FROM:
action 0, numVisits=21638, meanQ=41.944129, numObservations: 243
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.297563 0.809518 0.877715 0.260561 0.851943 0.297762 0.674252 0.179452 0.445099 0.56599 w: 1
Observation: 0 0 3 0 1 0 1 0 1 0 2 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=197, meanQ=90.345431, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 39194 episodes
GETTING ACTION FROM:
action 5, numVisits=39391, meanQ=91.841986, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.297563 0.809518 0.877715 0.260561 0.851943 0.297762 0.674252 0.179452 0.445099 0.56599 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 84.0499
Run # 19
Initial state: 0 0.150035 0.808727 0.500695 0.550648 0.83505 0.413936 0.71962 0.426131 0.226893 0.863724 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30896 episodes
GETTING ACTION FROM:
action 2, numVisits=30890, meanQ=18.401895, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.150035 0.808727 0.500695 0.550648 0.83505 0.413936 0.71962 0.426131 0.226893 0.863724 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 20
Initial state: 0 0.232746 0.801092 0.833059 0.614807 0.478674 0.527392 0.95819 0.722158 0.514686 0.720058 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30349 episodes
GETTING ACTION FROM:
action 5, numVisits=30320, meanQ=18.598953, numObservations: 9
action 3, numVisits=17, meanQ=12.353535, numObservations: 8
action 4, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=5, meanQ=-3.000000, numObservations: 4
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.232746 0.801092 0.833059 0.614807 0.478674 0.527392 0.95819 0.722158 0.514686 0.720058 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 21
Initial state: 0 0.376664 0.494454 0.900931 0.259761 0.64278 0.0883976 0.991668 0.896982 0.165749 0.270827 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17461 episodes
GETTING ACTION FROM:
action -1, numVisits=17417, meanQ=48.266039, numObservations: 243
action 0, numVisits=37, meanQ=-1.063781, numObservations: 36
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=3, meanQ=-34.333333, numObservations: 3
action: -1
Next state: 0 0.376664 0.494454 0.900931 0.259761 0.64278 0.0883976 0.991668 0.896982 0.165749 0.270827 w: 1
Observation: 0 2 0 3 0 3 0 3 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=91, meanQ=41.144729, numObservations: 9
action 3, numVisits=15, meanQ=19.000000, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=4, meanQ=-1.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 36147 episodes
GETTING ACTION FROM:
action 1, numVisits=36238, meanQ=52.699465, numObservations: 9
action 3, numVisits=15, meanQ=19.000000, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=4, meanQ=-1.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.376664 0.494454 0.900931 0.259761 0.64278 0.0883976 0.991668 0.896982 0.165749 0.270827 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 22
Initial state: 0 0.571243 0.878898 0.1288 0.82909 0.213629 0.338054 0.0812533 0.963787 0.377558 0.577964 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28680 episodes
GETTING ACTION FROM:
action 4, numVisits=28670, meanQ=18.232422, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=5, meanQ=-7.199980, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.571243 0.878898 0.1288 0.82909 0.213629 0.338054 0.0812533 0.963787 0.377558 0.577964 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=1950, meanQ=24.314589, numObservations: 9
action 5, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 34698 episodes
GETTING ACTION FROM:
action 3, numVisits=36648, meanQ=28.204223, numObservations: 9
action 5, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 3
Next state: 2 0.571243 0.878898 0.1288 0.82909 0.213629 0.338054 0.0812533 0.963787 0.377558 0.577964 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -110.99
Run # 23
Initial state: 0 0.511904 0.551928 0.618531 0.210971 0.78513 0.769483 0.577549 0.961632 0.247245 0.825014 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28906 episodes
GETTING ACTION FROM:
action 2, numVisits=28891, meanQ=20.597089, numObservations: 9
action 3, numVisits=4, meanQ=-1.000000, numObservations: 4
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 4, numVisits=5, meanQ=-3.000000, numObservations: 4
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.511904 0.551928 0.618531 0.210971 0.78513 0.769483 0.577549 0.961632 0.247245 0.825014 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 24
Initial state: 0 0.39362 0.967503 0.35852 0.816623 0.42956 0.363081 0.433722 0.571149 0.201243 0.279615 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29755 episodes
GETTING ACTION FROM:
action 1, numVisits=29720, meanQ=19.634309, numObservations: 9
action 2, numVisits=19, meanQ=11.422105, numObservations: 7
action 5, numVisits=12, meanQ=6.500000, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.39362 0.967503 0.35852 0.816623 0.42956 0.363081 0.433722 0.571149 0.201243 0.279615 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 25
Initial state: 0 0.14837 0.277802 0.122008 0.678511 0.917875 0.525131 0.509164 0.519078 0.149441 0.0655941 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30848 episodes
GETTING ACTION FROM:
action 4, numVisits=30807, meanQ=17.232626, numObservations: 9
action 3, numVisits=36, meanQ=5.476394, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.14837 0.277802 0.122008 0.678511 0.917875 0.525131 0.509164 0.519078 0.149441 0.0655941 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 26
Initial state: 0 0.622521 0.965705 0.973796 0.961984 0.386345 0.485067 0.330092 0.306252 0.00195914 0.333796 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31140 episodes
GETTING ACTION FROM:
action 3, numVisits=31133, meanQ=18.008559, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.622521 0.965705 0.973796 0.961984 0.386345 0.485067 0.330092 0.306252 0.00195914 0.333796 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 27
Initial state: 0 0.425082 0.659369 0.661713 0.870552 0.697005 0.955732 0.81813 0.665945 0.49813 0.578919 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17492 episodes
GETTING ACTION FROM:
action -1, numVisits=17447, meanQ=48.466096, numObservations: 243
action 0, numVisits=38, meanQ=-4.006574, numObservations: 35
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.425082 0.659369 0.661713 0.870552 0.697005 0.955732 0.81813 0.665945 0.49813 0.578919 w: 1
Observation: 0 1 0 3 0 3 0 3 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=118, meanQ=79.730396, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37299 episodes
GETTING ACTION FROM:
action 5, numVisits=37417, meanQ=83.718812, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.425082 0.659369 0.661713 0.870552 0.697005 0.955732 0.81813 0.665945 0.49813 0.578919 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 28
Initial state: 0 0.505199 0.505175 0.883257 0.733728 0.295851 0.130721 0.851232 0.485533 0.993104 0.283401 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17623 episodes
GETTING ACTION FROM:
action -1, numVisits=17609, meanQ=46.639513, numObservations: 243
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=7, meanQ=-15.435714, numObservations: 6
action 4, numVisits=3, meanQ=-34.333333, numObservations: 2
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.505199 0.505175 0.883257 0.733728 0.295851 0.130721 0.851232 0.485533 0.993104 0.283401 w: 1
Observation: 0 2 0 3 0 1 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=92, meanQ=79.837066, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 36738 episodes
GETTING ACTION FROM:
action 1, numVisits=36830, meanQ=78.267494, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.505199 0.505175 0.883257 0.733728 0.295851 0.130721 0.851232 0.485533 0.993104 0.283401 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 29
Initial state: 0 0.450806 0.571148 0.860782 0.0911691 0.784542 0.45131 0.10112 0.605607 0.236768 0.386931 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30455 episodes
GETTING ACTION FROM:
action 4, numVisits=30431, meanQ=18.030318, numObservations: 9
action -1, numVisits=10, meanQ=-1.010000, numObservations: 10
action 0, numVisits=10, meanQ=-1.010000, numObservations: 10
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.450806 0.571148 0.860782 0.0911691 0.784542 0.45131 0.10112 0.605607 0.236768 0.386931 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 30
Initial state: 0 0.0953056 0.717348 0.633544 0.471865 0.938566 0.378291 0.665577 0.67427 0.523858 0.559982 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17627 episodes
GETTING ACTION FROM:
action 0, numVisits=17594, meanQ=61.839607, numObservations: 243
action -1, numVisits=19, meanQ=-1.583679, numObservations: 18
action 3, numVisits=8, meanQ=-3.500000, numObservations: 6
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=3, meanQ=-34.333333, numObservations: 2
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.0953056 0.717348 0.633544 0.471865 0.938566 0.378291 0.665577 0.67427 0.523858 0.559982 w: 1
Observation: 0 0 3 0 1 0 1 0 3 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=45, meanQ=5.127780, numObservations: 39
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 1, numVisits=3, meanQ=-4.003333, numObservations: 3
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 17592 episodes
GETTING ACTION FROM:
action -1, numVisits=17637, meanQ=64.294370, numObservations: 243
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 1, numVisits=3, meanQ=-4.003333, numObservations: 3
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.0953056 0.717348 0.633544 0.471865 0.938566 0.378291 0.665577 0.67427 0.523858 0.559982 w: 1
Observation: 0 1 0 3 0 3 0 3 0 2 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=337, meanQ=88.026689, numObservations: 9
action 4, numVisits=9, meanQ=76.777778, numObservations: 3
action 1, numVisits=2, meanQ=44.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 38171 episodes
GETTING ACTION FROM:
action 5, numVisits=38508, meanQ=93.117927, numObservations: 9
action 4, numVisits=9, meanQ=76.777778, numObservations: 3
action 1, numVisits=2, meanQ=44.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.0953056 0.717348 0.633544 0.471865 0.938566 0.378291 0.665577 0.67427 0.523858 0.559982 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 93.0499
Run # 31
Initial state: 0 0.632829 0.203207 0.783116 0.749583 0.865884 0.96878 0.392966 0.56256 0.190678 0.102946 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28385 episodes
GETTING ACTION FROM:
action 2, numVisits=28377, meanQ=20.747170, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.632829 0.203207 0.783116 0.749583 0.865884 0.96878 0.392966 0.56256 0.190678 0.102946 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 32
Initial state: 0 0.406905 0.558531 0.518417 0.308553 0.194062 0.371857 0.240371 0.765338 0.993743 0.585033 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17640 episodes
GETTING ACTION FROM:
action -1, numVisits=17599, meanQ=45.419488, numObservations: 243
action 0, numVisits=30, meanQ=-4.376000, numObservations: 29
action 1, numVisits=4, meanQ=-28.500000, numObservations: 4
action 4, numVisits=4, meanQ=-28.500000, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.406905 0.558531 0.518417 0.308553 0.194062 0.371857 0.240371 0.765338 0.993743 0.585033 w: 1
Observation: 0 2 0 2 0 1 0 1 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=61, meanQ=6.600990, numObservations: 50
action -1, numVisits=10, meanQ=-2.099990, numObservations: 9
action 1, numVisits=5, meanQ=-6.803980, numObservations: 4
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 17930 episodes
GETTING ACTION FROM:
action 0, numVisits=17991, meanQ=77.619985, numObservations: 243
action -1, numVisits=10, meanQ=-2.099990, numObservations: 9
action 1, numVisits=5, meanQ=-6.803980, numObservations: 4
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.406905 0.558531 0.518417 0.308553 0.194062 0.371857 0.240371 0.765338 0.993743 0.585033 w: 1
Observation: 0 0 2 0 1 0 2 0 2 0 2 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=1, meanQ=99.000000, numObservations: 1
action 5, numVisits=1, meanQ=99.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 37641 episodes
GETTING ACTION FROM:
action 1, numVisits=37637, meanQ=91.312502, numObservations: 9
action 3, numVisits=2, meanQ=44.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.406905 0.558531 0.518417 0.308553 0.194062 0.371857 0.240371 0.765338 0.993743 0.585033 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 93.0499
Run # 33
Initial state: 0 0.457822 0.54459 0.55807 0.0646655 0.71608 0.813664 0.503377 0.185401 0.0611305 0.435792 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30566 episodes
GETTING ACTION FROM:
action 5, numVisits=30524, meanQ=17.520071, numObservations: 9
action 0, numVisits=22, meanQ=-5.600000, numObservations: 21
action -1, numVisits=16, meanQ=-7.445619, numObservations: 14
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.457822 0.54459 0.55807 0.0646655 0.71608 0.813664 0.503377 0.185401 0.0611305 0.435792 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=3184, meanQ=25.401994, numObservations: 9
action -1, numVisits=22, meanQ=-6.185900, numObservations: 19
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 0, numVisits=9, meanQ=-12.230000, numObservations: 8
action 4, numVisits=9, meanQ=-14.113333, numObservations: 4
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 11280 episodes
GETTING ACTION FROM:
action 2, numVisits=14464, meanQ=17.559215, numObservations: 9
action -1, numVisits=22, meanQ=-6.185900, numObservations: 19
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 0, numVisits=9, meanQ=-12.230000, numObservations: 8
action 4, numVisits=9, meanQ=-14.113333, numObservations: 4
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.457822 0.54459 0.55807 0.0646655 0.71608 0.813664 0.503377 0.185401 0.0611305 0.435792 w: 1
Observation: 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -110.99
Run # 34
Initial state: 0 0.699484 0.494629 0.3976 0.715567 0.397806 0.571647 0.104843 0.0953099 0.704964 0.0645644 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28891 episodes
GETTING ACTION FROM:
action 2, numVisits=28884, meanQ=20.453936, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.699484 0.494629 0.3976 0.715567 0.397806 0.571647 0.104843 0.0953099 0.704964 0.0645644 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 35
Initial state: 0 0.346256 0.97978 0.391404 0.572995 0.250345 0.343239 0.602446 0.121462 0.769967 0.564623 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31184 episodes
GETTING ACTION FROM:
action 3, numVisits=31103, meanQ=18.474824, numObservations: 9
action 0, numVisits=42, meanQ=-1.718086, numObservations: 36
action -1, numVisits=35, meanQ=-3.951997, numObservations: 33
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.346256 0.97978 0.391404 0.572995 0.250345 0.343239 0.602446 0.121462 0.769967 0.564623 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=858, meanQ=24.650325, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 29962 episodes
GETTING ACTION FROM:
action 0, numVisits=3571, meanQ=3.111254, numObservations: 226
action 1, numVisits=23421, meanQ=1.364386, numObservations: 9
action 5, numVisits=3735, meanQ=1.057465, numObservations: 9
action -1, numVisits=95, meanQ=-3.969579, numObservations: 62
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=3, meanQ=-34.333333, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.346256 0.97978 0.391404 0.572995 0.250345 0.343239 0.602446 0.121462 0.769967 0.564623 w: 1
Observation: 0 0 1 0 2 0 1 0 3 0 2 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=1, meanQ=99.000000, numObservations: 1
action 2, numVisits=1, meanQ=99.000000, numObservations: 1
action 4, numVisits=1, meanQ=99.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31136 episodes
GETTING ACTION FROM:
action 2, numVisits=31095, meanQ=45.098642, numObservations: 9
action 4, numVisits=17, meanQ=33.705882, numObservations: 6
action 5, numVisits=25, meanQ=33.240924, numObservations: 7
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.346256 0.97978 0.391404 0.572995 0.250345 0.343239 0.602446 0.121462 0.769967 0.564623 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 84.0499
Run # 36
Initial state: 0 0.228566 0.443735 0.0996562 0.587347 0.358409 0.584898 0.776914 0.451995 0.0239714 0.24865 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17879 episodes
GETTING ACTION FROM:
action 0, numVisits=17828, meanQ=61.822857, numObservations: 243
action -1, numVisits=42, meanQ=-3.555950, numObservations: 38
action 1, numVisits=3, meanQ=-4.333333, numObservations: 2
action 5, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.228566 0.443735 0.0996562 0.587347 0.358409 0.584898 0.776914 0.451995 0.0239714 0.24865 w: 1
Observation: 0 0 1 0 2 0 2 0 1 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=60, meanQ=52.085505, numObservations: 9
action 2, numVisits=20, meanQ=27.999505, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 33189 episodes
GETTING ACTION FROM:
action 3, numVisits=33249, meanQ=54.645853, numObservations: 9
action 2, numVisits=20, meanQ=27.999505, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.228566 0.443735 0.0996562 0.587347 0.358409 0.584898 0.776914 0.451995 0.0239714 0.24865 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 37
Initial state: 0 0.520582 0.512152 0.258935 0.781758 0.270913 0.614942 0.507468 0.0730011 0.23192 0.0643188 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31224 episodes
GETTING ACTION FROM:
action 4, numVisits=31194, meanQ=19.369781, numObservations: 9
action 5, numVisits=6, meanQ=-1.000000, numObservations: 5
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=18, meanQ=-2.111111, numObservations: 6
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.520582 0.512152 0.258935 0.781758 0.270913 0.614942 0.507468 0.0730011 0.23192 0.0643188 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 38
Initial state: 0 0.31158 0.592831 0.656072 0.475794 0.397177 0.67292 0.522489 0.549025 0.748583 0.950644 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30457 episodes
GETTING ACTION FROM:
action 1, numVisits=30450, meanQ=18.764954, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.31158 0.592831 0.656072 0.475794 0.397177 0.67292 0.522489 0.549025 0.748583 0.950644 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=812, meanQ=34.496481, numObservations: 212
action -1, numVisits=15, meanQ=-1.010000, numObservations: 15
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 5442 episodes
GETTING ACTION FROM:
action 0, numVisits=6254, meanQ=36.717899, numObservations: 242
action -1, numVisits=15, meanQ=-1.010000, numObservations: 15
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.31158 0.592831 0.656072 0.475794 0.397177 0.67292 0.522489 0.549025 0.748583 0.950644 w: 1
Observation: 0 0 2 0 1 0 3 0 2 0 3 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=9, meanQ=85.760440, numObservations: 3
action 5, numVisits=27, meanQ=79.795991, numObservations: 4
action 3, numVisits=3, meanQ=59.787451, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 40202 episodes
GETTING ACTION FROM:
action 5, numVisits=40196, meanQ=63.857446, numObservations: 9
action 4, numVisits=41, meanQ=50.241225, numObservations: 8
action 3, numVisits=4, meanQ=19.590588, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.31158 0.592831 0.656072 0.475794 0.397177 0.67292 0.522489 0.549025 0.748583 0.950644 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 84.0499
Run # 39
Initial state: 0 0.432538 0.310955 0.505643 0.0668531 0.908722 0.711871 0.573746 0.832135 0.402591 0.505607 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29256 episodes
GETTING ACTION FROM:
action 2, numVisits=29193, meanQ=21.493476, numObservations: 9
action 1, numVisits=52, meanQ=13.002898, numObservations: 9
action 4, numVisits=6, meanQ=12.335000, numObservations: 4
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.432538 0.310955 0.505643 0.0668531 0.908722 0.711871 0.573746 0.832135 0.402591 0.505607 w: 1
Observation: 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 40
Initial state: 0 0.00109005 0.862131 0.334316 0.9905 0.0497755 0.559321 0.202883 0.81637 0.524937 0.554671 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29133 episodes
GETTING ACTION FROM:
action 2, numVisits=29086, meanQ=21.153871, numObservations: 9
action -1, numVisits=13, meanQ=-1.010000, numObservations: 13
action 0, numVisits=13, meanQ=-1.010000, numObservations: 13
action 4, numVisits=18, meanQ=-7.111111, numObservations: 6
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.00109005 0.862131 0.334316 0.9905 0.0497755 0.559321 0.202883 0.81637 0.524937 0.554671 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 41
Initial state: 0 0.241848 0.203621 0.348716 0.902734 0.409476 0.545593 0.53184 0.147 0.157387 0.343806 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28393 episodes
GETTING ACTION FROM:
action 2, numVisits=28387, meanQ=22.650609, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.241848 0.203621 0.348716 0.902734 0.409476 0.545593 0.53184 0.147 0.157387 0.343806 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 42
Initial state: 0 0.116284 0.623498 0.297187 0.211539 0.923327 0.886681 0.741033 0.315721 0.401892 0.525718 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17618 episodes
GETTING ACTION FROM:
action -1, numVisits=17587, meanQ=47.321886, numObservations: 243
action 0, numVisits=21, meanQ=-1.010000, numObservations: 21
action 3, numVisits=6, meanQ=-4.333333, numObservations: 5
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.116284 0.623498 0.297187 0.211539 0.923327 0.886681 0.741033 0.315721 0.401892 0.525718 w: 1
Observation: 0 1 0 1 0 3 0 3 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=94, meanQ=74.279898, numObservations: 8
action 4, numVisits=6, meanQ=32.333333, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 37424 episodes
GETTING ACTION FROM:
action 5, numVisits=37518, meanQ=84.809001, numObservations: 9
action 4, numVisits=6, meanQ=32.333333, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 5
Next state: 1 0.116284 0.623498 0.297187 0.211539 0.923327 0.886681 0.741033 0.315721 0.401892 0.525718 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 43
Initial state: 0 0.467475 0.887762 0.304734 0.34502 0.471372 0.564453 0.551649 0.79084 0.941946 0.387814 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30546 episodes
GETTING ACTION FROM:
action 3, numVisits=30540, meanQ=17.987891, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.467475 0.887762 0.304734 0.34502 0.471372 0.564453 0.551649 0.79084 0.941946 0.387814 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 44
Initial state: 0 0.0247449 0.774703 0.36738 0.519289 0.922269 0.813426 0.536729 0.960385 0.661896 0.272719 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17878 episodes
GETTING ACTION FROM:
action 0, numVisits=17825, meanQ=62.217688, numObservations: 242
action -1, numVisits=48, meanQ=-1.670619, numObservations: 41
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.0247449 0.774703 0.36738 0.519289 0.922269 0.813426 0.536729 0.960385 0.661896 0.272719 w: 1
Observation: 0 0 2 0 2 0 3 0 3 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=27, meanQ=49.109633, numObservations: 7
action 4, numVisits=11, meanQ=44.454545, numObservations: 5
action 3, numVisits=26, meanQ=42.964235, numObservations: 8
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 34531 episodes
GETTING ACTION FROM:
action 4, numVisits=34449, meanQ=58.568297, numObservations: 9
action 1, numVisits=119, meanQ=38.441436, numObservations: 9
action 3, numVisits=27, meanQ=37.632226, numObservations: 8
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 4
Next state: 1 0.0247449 0.774703 0.36738 0.519289 0.922269 0.813426 0.536729 0.960385 0.661896 0.272719 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 45
Initial state: 0 0.511901 0.652961 0.195048 0.544938 0.41377 0.529803 0.955497 8.47738e-06 0.776971 0.184302 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30436 episodes
GETTING ACTION FROM:
action 4, numVisits=30422, meanQ=17.509001, numObservations: 9
action 3, numVisits=7, meanQ=10.428571, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.511901 0.652961 0.195048 0.544938 0.41377 0.529803 0.955497 8.47738e-06 0.776971 0.184302 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 46
Initial state: 0 0.287354 0.813863 0.391526 0.532998 0.15345 0.444279 0.289729 0.773697 0.00021503 0.599044 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17894 episodes
GETTING ACTION FROM:
action 0, numVisits=17854, meanQ=64.489523, numObservations: 243
action 3, numVisits=25, meanQ=-4.515996, numObservations: 7
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=9, meanQ=-12.230000, numObservations: 8
action 5, numVisits=3, meanQ=-34.333333, numObservations: 3
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.287354 0.813863 0.391526 0.532998 0.15345 0.444279 0.289729 0.773697 0.00021503 0.599044 w: 1
Observation: 0 0 3 0 2 0 1 0 3 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=89, meanQ=62.394608, numObservations: 9
action 2, numVisits=4, meanQ=49.000000, numObservations: 3
action 4, numVisits=4, meanQ=21.747500, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 31563 episodes
GETTING ACTION FROM:
action 1, numVisits=31652, meanQ=67.489680, numObservations: 9
action 2, numVisits=4, meanQ=49.000000, numObservations: 3
action 4, numVisits=4, meanQ=21.747500, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.287354 0.813863 0.391526 0.532998 0.15345 0.444279 0.289729 0.773697 0.00021503 0.599044 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 47
Initial state: 0 0.440112 0.50001 0.146168 0.746999 0.997639 0.707595 0.41952 0.601196 0.830154 0.62113 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30542 episodes
GETTING ACTION FROM:
action 2, numVisits=30527, meanQ=17.091666, numObservations: 9
action 3, numVisits=9, meanQ=7.888889, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.440112 0.50001 0.146168 0.746999 0.997639 0.707595 0.41952 0.601196 0.830154 0.62113 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=2088, meanQ=28.530701, numObservations: 9
action 2, numVisits=11, meanQ=20.008200, numObservations: 3
action 1, numVisits=4, meanQ=-1.000000, numObservations: 4
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 34143 episodes
GETTING ACTION FROM:
action 5, numVisits=36231, meanQ=33.430798, numObservations: 9
action 2, numVisits=11, meanQ=20.008200, numObservations: 3
action 1, numVisits=4, meanQ=-1.000000, numObservations: 4
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 5
Next state: 1 0.440112 0.50001 0.146168 0.746999 0.997639 0.707595 0.41952 0.601196 0.830154 0.62113 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 48
Initial state: 0 0.156622 0.876567 0.660398 0.232068 0.464576 0.563763 0.223491 0.522382 0.0522574 0.191846 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31038 episodes
GETTING ACTION FROM:
action 4, numVisits=31021, meanQ=18.066267, numObservations: 9
action 2, numVisits=11, meanQ=14.454545, numObservations: 7
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.156622 0.876567 0.660398 0.232068 0.464576 0.563763 0.223491 0.522382 0.0522574 0.191846 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=797, meanQ=26.375309, numObservations: 9
action 2, numVisits=5, meanQ=19.000000, numObservations: 4
action 1, numVisits=15, meanQ=16.597333, numObservations: 8
action 3, numVisits=6, meanQ=14.165000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 11675 episodes
GETTING ACTION FROM:
action 5, numVisits=12381, meanQ=16.388863, numObservations: 9
action 2, numVisits=86, meanQ=15.609336, numObservations: 9
action 1, numVisits=22, meanQ=10.136250, numObservations: 8
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 3, numVisits=7, meanQ=-2.287143, numObservations: 4
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.156622 0.876567 0.660398 0.232068 0.464576 0.563763 0.223491 0.522382 0.0522574 0.191846 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=553, meanQ=33.924616, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 7130 episodes
GETTING ACTION FROM:
action 2, numVisits=7683, meanQ=31.119223, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.156622 0.876567 0.660398 0.232068 0.464576 0.563763 0.223491 0.522382 0.0522574 0.191846 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -120.88
Run # 49
Initial state: 0 0.626856 0.140653 0.549472 0.764717 0.0133821 0.253487 0.393614 0.517068 0.423824 0.70089 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30472 episodes
GETTING ACTION FROM:
action 3, numVisits=30466, meanQ=18.352934, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.626856 0.140653 0.549472 0.764717 0.0133821 0.253487 0.393614 0.517068 0.423824 0.70089 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=3200, meanQ=24.106673, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 9039 episodes
GETTING ACTION FROM:
action 4, numVisits=12239, meanQ=20.579868, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 4
Next state: 1 0.626856 0.140653 0.549472 0.764717 0.0133821 0.253487 0.393614 0.517068 0.423824 0.70089 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 50
Initial state: 0 0.662428 0.800371 0.696529 0.201584 0.469928 0.521076 0.980178 0.465072 0.263587 0.757593 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30835 episodes
GETTING ACTION FROM:
action 4, numVisits=30809, meanQ=19.443304, numObservations: 9
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 1, numVisits=3, meanQ=-4.333333, numObservations: 2
action 3, numVisits=13, meanQ=-4.383831, numObservations: 6
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.662428 0.800371 0.696529 0.201584 0.469928 0.521076 0.980178 0.465072 0.263587 0.757593 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 51
Initial state: 0 0.315307 0.159645 0.527336 0.861468 0.901753 0.70258 0.522688 0.552847 0.81599 0.328569 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30834 episodes
GETTING ACTION FROM:
action 4, numVisits=30779, meanQ=18.356162, numObservations: 9
action 2, numVisits=38, meanQ=17.289482, numObservations: 9
action 1, numVisits=13, meanQ=9.998462, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.315307 0.159645 0.527336 0.861468 0.901753 0.70258 0.522688 0.552847 0.81599 0.328569 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 52
Initial state: 0 0.446301 0.910767 0.336649 0.817699 0.352834 0.320355 0.551667 0.874219 0.391966 0.587807 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28290 episodes
GETTING ACTION FROM:
action 3, numVisits=28257, meanQ=21.316276, numObservations: 9
action 5, numVisits=24, meanQ=14.040838, numObservations: 8
action 2, numVisits=4, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.446301 0.910767 0.336649 0.817699 0.352834 0.320355 0.551667 0.874219 0.391966 0.587807 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 53
Initial state: 0 0.0351723 0.475541 0.110447 0.0201008 0.949087 0.203918 0.191692 0.0352446 0.447429 0.59192 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17733 episodes
GETTING ACTION FROM:
action 0, numVisits=17671, meanQ=64.019878, numObservations: 243
action -1, numVisits=51, meanQ=-3.359406, numObservations: 45
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=5, meanQ=-21.000000, numObservations: 4
action 3, numVisits=3, meanQ=-34.333333, numObservations: 3
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.0351723 0.475541 0.110447 0.0201008 0.949087 0.203918 0.191692 0.0352446 0.447429 0.59192 w: 1
Observation: 0 0 1 0 1 0 1 0 1 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=158, meanQ=79.512787, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37399 episodes
GETTING ACTION FROM:
action 5, numVisits=37557, meanQ=88.676156, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.0351723 0.475541 0.110447 0.0201008 0.949087 0.203918 0.191692 0.0352446 0.447429 0.59192 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 54
Initial state: 0 0.981738 0.845453 0.71226 0.698605 0.0334981 0.0397664 0.510332 0.517003 0.664658 0.586294 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30954 episodes
GETTING ACTION FROM:
action 2, numVisits=30942, meanQ=16.660443, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=7, meanQ=-2.428571, numObservations: 4
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.981738 0.845453 0.71226 0.698605 0.0334981 0.0397664 0.510332 0.517003 0.664658 0.586294 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 55
Initial state: 0 0.680076 0.989421 0.143734 0.354783 0.625426 0.544436 0.875957 0.874178 0.495927 0.551217 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17893 episodes
GETTING ACTION FROM:
action 0, numVisits=17841, meanQ=63.751197, numObservations: 243
action -1, numVisits=42, meanQ=-3.673807, numObservations: 40
action 4, numVisits=6, meanQ=-4.499983, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.680076 0.989421 0.143734 0.354783 0.625426 0.544436 0.875957 0.874178 0.495927 0.551217 w: 1
Observation: 0 0 3 0 1 0 3 0 3 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=83, meanQ=59.314704, numObservations: 7
action 3, numVisits=4, meanQ=49.000000, numObservations: 2
action 4, numVisits=2, meanQ=44.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 32807 episodes
GETTING ACTION FROM:
action 1, numVisits=32890, meanQ=68.131246, numObservations: 9
action 3, numVisits=4, meanQ=49.000000, numObservations: 2
action 4, numVisits=2, meanQ=44.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.680076 0.989421 0.143734 0.354783 0.625426 0.544436 0.875957 0.874178 0.495927 0.551217 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 56
Initial state: 0 0.431215 0.825305 0.470907 0.155616 0.429394 0.564225 0.782821 0.645942 0.673706 0.346484 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30162 episodes
GETTING ACTION FROM:
action 4, numVisits=30144, meanQ=19.059088, numObservations: 9
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 1, numVisits=7, meanQ=-2.287143, numObservations: 4
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.431215 0.825305 0.470907 0.155616 0.429394 0.564225 0.782821 0.645942 0.673706 0.346484 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 57
Initial state: 0 0.0793989 0.269335 0.911222 0.487021 0.610575 0.648248 0.44184 0.511986 0.0856465 0.525417 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30916 episodes
GETTING ACTION FROM:
action 4, numVisits=30907, meanQ=17.244368, numObservations: 9
action 1, numVisits=4, meanQ=-1.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.0793989 0.269335 0.911222 0.487021 0.610575 0.648248 0.44184 0.511986 0.0856465 0.525417 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=478, meanQ=37.604760, numObservations: 149
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 25768 episodes
GETTING ACTION FROM:
action -1, numVisits=26246, meanQ=5.712166, numObservations: 243
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.0793989 0.269335 0.911222 0.487021 0.610575 0.648248 0.44184 0.511986 0.0856465 0.525417 w: 1
Observation: 0 1 0 2 0 3 0 2 0 1 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=37, meanQ=49.028924, numObservations: 6
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 41560 episodes
GETTING ACTION FROM:
action 4, numVisits=41597, meanQ=92.168375, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.0793989 0.269335 0.911222 0.487021 0.610575 0.648248 0.44184 0.511986 0.0856465 0.525417 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 84.0499
Run # 58
Initial state: 0 0.0363824 0.468769 0.576156 0.537897 0.143646 0.689894 0.380638 0.535743 0.50959 0.799814 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29827 episodes
GETTING ACTION FROM:
action 3, numVisits=29813, meanQ=18.492264, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=5, meanQ=-3.000000, numObservations: 5
action 4, numVisits=5, meanQ=-3.000000, numObservations: 5
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.0363824 0.468769 0.576156 0.537897 0.143646 0.689894 0.380638 0.535743 0.50959 0.799814 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=2045, meanQ=59.656439, numObservations: 220
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action -1, numVisits=9, meanQ=-12.230000, numObservations: 8
action 4, numVisits=6, meanQ=-19.168333, numObservations: 4
Sampled 19421 episodes
GETTING ACTION FROM:
action 0, numVisits=21466, meanQ=44.704200, numObservations: 243
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action -1, numVisits=9, meanQ=-12.230000, numObservations: 8
action 4, numVisits=6, meanQ=-19.168333, numObservations: 4
action: 0
Next state: 0 0.0363824 0.468769 0.576156 0.537897 0.143646 0.689894 0.380638 0.535743 0.50959 0.799814 w: 1
Observation: 0 0 1 0 2 0 3 0 2 0 3 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=116, meanQ=71.493578, numObservations: 6
action 2, numVisits=4, meanQ=21.747500, numObservations: 3
action 5, numVisits=4, meanQ=21.747500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 31668 episodes
GETTING ACTION FROM:
action 3, numVisits=31784, meanQ=79.816742, numObservations: 9
action 2, numVisits=4, meanQ=21.747500, numObservations: 3
action 5, numVisits=4, meanQ=21.747500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.0363824 0.468769 0.576156 0.537897 0.143646 0.689894 0.380638 0.535743 0.50959 0.799814 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 4, numVisits=7468, meanQ=66.883639, numObservations: 9
action 3, numVisits=2, meanQ=44.495000, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 40167 episodes
GETTING ACTION FROM:
action 4, numVisits=47635, meanQ=62.452125, numObservations: 9
action 3, numVisits=2, meanQ=44.495000, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.0363824 0.468769 0.576156 0.537897 0.143646 0.689894 0.380638 0.535743 0.50959 0.799814 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 72.2985
Run # 59
Initial state: 0 0.215091 0.476932 0.843491 0.363384 0.582159 0.317065 0.462448 0.555586 0.276144 0.36396 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29576 episodes
GETTING ACTION FROM:
action 1, numVisits=29570, meanQ=19.034250, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.215091 0.476932 0.843491 0.363384 0.582159 0.317065 0.462448 0.555586 0.276144 0.36396 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=2941, meanQ=23.442808, numObservations: 9
action -1, numVisits=39, meanQ=-6.849477, numObservations: 33
action 0, numVisits=16, meanQ=-7.321250, numObservations: 15
action 1, numVisits=2, meanQ=-10.010000, numObservations: 2
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 9181 episodes
GETTING ACTION FROM:
action 3, numVisits=12122, meanQ=21.438924, numObservations: 9
action -1, numVisits=39, meanQ=-6.849477, numObservations: 33
action 0, numVisits=16, meanQ=-7.321250, numObservations: 15
action 1, numVisits=2, meanQ=-10.010000, numObservations: 2
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.215091 0.476932 0.843491 0.363384 0.582159 0.317065 0.462448 0.555586 0.276144 0.36396 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -110.99
Run # 60
Initial state: 0 0.461013 0.531519 0.400805 0.674344 0.18922 0.642749 0.561191 0.677533 0.156868 0.464844 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17839 episodes
GETTING ACTION FROM:
action 0, numVisits=17728, meanQ=63.533830, numObservations: 242
action -1, numVisits=104, meanQ=-4.809506, numObservations: 77
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=3, meanQ=-34.333333, numObservations: 2
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.461013 0.531519 0.400805 0.674344 0.18922 0.642749 0.561191 0.677533 0.156868 0.464844 w: 1
Observation: 0 0 2 0 3 0 3 0 3 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=15, meanQ=55.263340, numObservations: 7
action 3, numVisits=21, meanQ=53.048100, numObservations: 3
action 2, numVisits=13, meanQ=51.306931, numObservations: 4
action 4, numVisits=5, meanQ=37.198000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 34113 episodes
GETTING ACTION FROM:
action 2, numVisits=34084, meanQ=63.919788, numObservations: 9
action 3, numVisits=34, meanQ=51.735591, numObservations: 7
action 5, numVisits=44, meanQ=51.296598, numObservations: 9
action 4, numVisits=5, meanQ=37.198000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.461013 0.531519 0.400805 0.674344 0.18922 0.642749 0.561191 0.677533 0.156868 0.464844 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 61
Initial state: 0 0.356367 0.570943 0.916479 0.0427094 0.442317 0.302621 0.0360065 0.67009 0.617905 0.88157 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17818 episodes
GETTING ACTION FROM:
action -1, numVisits=17794, meanQ=44.972782, numObservations: 243
action 0, numVisits=16, meanQ=-1.010000, numObservations: 16
action 5, numVisits=4, meanQ=-6.000000, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.356367 0.570943 0.916479 0.0427094 0.442317 0.302621 0.0360065 0.67009 0.617905 0.88157 w: 1
Observation: 0 2 0 3 0 2 0 1 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=29, meanQ=13.963793, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 35449 episodes
GETTING ACTION FROM:
action 5, numVisits=35478, meanQ=44.755567, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.356367 0.570943 0.916479 0.0427094 0.442317 0.302621 0.0360065 0.67009 0.617905 0.88157 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 62
Initial state: 0 0.364076 0.587653 0.971623 0.22947 0.304598 0.147375 0.483968 0.646314 0.585371 0.314699 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30044 episodes
GETTING ACTION FROM:
action 4, numVisits=30022, meanQ=19.031623, numObservations: 9
action 3, numVisits=6, meanQ=14.000000, numObservations: 6
action 1, numVisits=11, meanQ=5.272727, numObservations: 7
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.364076 0.587653 0.971623 0.22947 0.304598 0.147375 0.483968 0.646314 0.585371 0.314699 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 63
Initial state: 0 0.713309 0.0145329 0.663869 0.531826 0.394501 0.487892 0.266768 0.516809 0.0501621 0.392637 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28296 episodes
GETTING ACTION FROM:
action 1, numVisits=28290, meanQ=21.437318, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.713309 0.0145329 0.663869 0.531826 0.394501 0.487892 0.266768 0.516809 0.0501621 0.392637 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 64
Initial state: 0 0.72022 0.18466 0.40848 0.517306 0.236476 0.708968 0.77952 0.499498 0.35943 0.364302 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30564 episodes
GETTING ACTION FROM:
action 1, numVisits=30549, meanQ=18.207960, numObservations: 9
action 2, numVisits=9, meanQ=6.787789, numObservations: 6
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.72022 0.18466 0.40848 0.517306 0.236476 0.708968 0.77952 0.499498 0.35943 0.364302 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 65
Initial state: 0 0.0499883 0.989319 0.749012 0.61842 0.267786 0.743405 0.425844 0.52811 0.257054 0.292115 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30287 episodes
GETTING ACTION FROM:
action 5, numVisits=30264, meanQ=18.952529, numObservations: 9
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action -1, numVisits=6, meanQ=-2.826650, numObservations: 5
action 1, numVisits=6, meanQ=-4.499983, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=3, meanQ=-34.333333, numObservations: 3
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.0499883 0.989319 0.749012 0.61842 0.267786 0.743405 0.425844 0.52811 0.257054 0.292115 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=3133, meanQ=22.784856, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 10302 episodes
GETTING ACTION FROM:
action 4, numVisits=13435, meanQ=20.468762, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.0499883 0.989319 0.749012 0.61842 0.267786 0.743405 0.425844 0.52811 0.257054 0.292115 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=199, meanQ=67.896797, numObservations: 8
action 3, numVisits=6, meanQ=32.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 35591 episodes
GETTING ACTION FROM:
action 4, numVisits=35790, meanQ=86.232301, numObservations: 9
action 3, numVisits=6, meanQ=32.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.0499883 0.989319 0.749012 0.61842 0.267786 0.743405 0.425844 0.52811 0.257054 0.292115 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 75.1399
Run # 66
Initial state: 0 0.477356 0.586551 0.264324 0.969711 0.523837 0.376785 0.528573 0.509309 0.241448 0.22049 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30469 episodes
GETTING ACTION FROM:
action 4, numVisits=30441, meanQ=17.650533, numObservations: 9
action 2, numVisits=17, meanQ=10.598271, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=5, meanQ=-2.802000, numObservations: 4
action 3, numVisits=3, meanQ=-4.333333, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.477356 0.586551 0.264324 0.969711 0.523837 0.376785 0.528573 0.509309 0.241448 0.22049 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 67
Initial state: 0 0.146722 0.898729 0.782479 0.109958 0.542375 0.559601 0.523674 0.493392 0.51466 0.0485846 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30158 episodes
GETTING ACTION FROM:
action 5, numVisits=30104, meanQ=20.490145, numObservations: 9
action 3, numVisits=48, meanQ=16.670423, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.146722 0.898729 0.782479 0.109958 0.542375 0.559601 0.523674 0.493392 0.51466 0.0485846 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 68
Initial state: 0 0.456174 0.505592 0.976818 0.261243 0.648322 0.0727637 0.373693 0.136761 0.754053 0.0814136 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28382 episodes
GETTING ACTION FROM:
action 2, numVisits=28357, meanQ=17.011666, numObservations: 9
action 5, numVisits=9, meanQ=7.888889, numObservations: 7
action 3, numVisits=12, meanQ=4.833333, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.456174 0.505592 0.976818 0.261243 0.648322 0.0727637 0.373693 0.136761 0.754053 0.0814136 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 69
Initial state: 0 0.0312975 0.681324 0.249132 0.926929 0.537735 0.441507 0.652198 0.655677 0.369745 0.522492 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29780 episodes
GETTING ACTION FROM:
action 1, numVisits=29762, meanQ=20.480617, numObservations: 9
action 3, numVisits=12, meanQ=4.915833, numObservations: 5
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.0312975 0.681324 0.249132 0.926929 0.537735 0.441507 0.652198 0.655677 0.369745 0.522492 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 70
Initial state: 0 0.824289 0.735335 0.794919 0.973212 0.583472 0.234452 0.937123 0.0242736 0.402971 0.519496 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30023 episodes
GETTING ACTION FROM:
action 5, numVisits=30013, meanQ=18.808514, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.824289 0.735335 0.794919 0.973212 0.583472 0.234452 0.937123 0.0242736 0.402971 0.519496 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=452, meanQ=13.283627, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 40343 episodes
GETTING ACTION FROM:
action 4, numVisits=40795, meanQ=22.675668, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 4
Next state: 2 0.824289 0.735335 0.794919 0.973212 0.583472 0.234452 0.937123 0.0242736 0.402971 0.519496 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -110.99
Run # 71
Initial state: 0 0.387559 0.00529545 0.862994 0.472769 0.124535 0.848514 0.509666 0.525536 0.13427 0.742486 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29049 episodes
GETTING ACTION FROM:
action 5, numVisits=29035, meanQ=19.541167, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 4, numVisits=6, meanQ=-5.984983, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.387559 0.00529545 0.862994 0.472769 0.124535 0.848514 0.509666 0.525536 0.13427 0.742486 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=3062, meanQ=46.407182, numObservations: 226
action 0, numVisits=32, meanQ=-4.909053, numObservations: 28
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 3474 episodes
GETTING ACTION FROM:
action -1, numVisits=6536, meanQ=40.516007, numObservations: 242
action 0, numVisits=32, meanQ=-4.909053, numObservations: 28
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.387559 0.00529545 0.862994 0.472769 0.124535 0.848514 0.509666 0.525536 0.13427 0.742486 w: 1
Observation: 0 2 0 3 0 1 0 2 0 3 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=1, meanQ=99.000000, numObservations: 1
action 4, numVisits=1, meanQ=99.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-17.807807, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 0, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 5940 episodes
GETTING ACTION FROM:
action 3, numVisits=5877, meanQ=29.372386, numObservations: 9
action 0, numVisits=29, meanQ=-9.387459, numObservations: 22
action 4, numVisits=3, meanQ=-34.333333, numObservations: 3
action -1, numVisits=22, meanQ=-50.048356, numObservations: 20
action 1, numVisits=13, meanQ=-70.505258, numObservations: 7
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.387559 0.00529545 0.862994 0.472769 0.124535 0.848514 0.509666 0.525536 0.13427 0.742486 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 84.0499
Run # 72
Initial state: 0 0.772998 0.552923 0.0351496 0.673878 0.403167 0.593791 0.704167 0.00705557 0.551524 0.249016 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17955 episodes
GETTING ACTION FROM:
action 0, numVisits=17903, meanQ=64.611937, numObservations: 243
action -1, numVisits=47, meanQ=-3.158511, numObservations: 46
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.772998 0.552923 0.0351496 0.673878 0.403167 0.593791 0.704167 0.00705557 0.551524 0.249016 w: 1
Observation: 0 0 2 0 3 0 1 0 1 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=119, meanQ=85.445462, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 37721 episodes
GETTING ACTION FROM:
action 1, numVisits=37840, meanQ=89.309311, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 1
Next state: 1 0.772998 0.552923 0.0351496 0.673878 0.403167 0.593791 0.704167 0.00705557 0.551524 0.249016 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 73
Initial state: 0 0.497343 0.956697 0.820806 0.39609 0.408382 0.579791 0.0172172 0.302179 0.17168 0.613253 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28578 episodes
GETTING ACTION FROM:
action 1, numVisits=28572, meanQ=21.625326, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.497343 0.956697 0.820806 0.39609 0.408382 0.579791 0.0172172 0.302179 0.17168 0.613253 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 74
Initial state: 0 0.54856 0.842787 0.62076 0.387346 0.402017 0.567316 0.440963 0.0176483 0.750299 0.666762 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29257 episodes
GETTING ACTION FROM:
action 5, numVisits=29236, meanQ=20.886428, numObservations: 9
action 2, numVisits=16, meanQ=6.938144, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.54856 0.842787 0.62076 0.387346 0.402017 0.567316 0.440963 0.0176483 0.750299 0.666762 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 75
Initial state: 0 0.307836 0.442889 0.908195 0.626571 0.401363 0.536896 0.0508257 0.419106 0.830203 0.959255 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29584 episodes
GETTING ACTION FROM:
action 5, numVisits=29571, meanQ=19.370015, numObservations: 9
action 4, numVisits=4, meanQ=-1.000000, numObservations: 4
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.307836 0.442889 0.908195 0.626571 0.401363 0.536896 0.0508257 0.419106 0.830203 0.959255 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 76
Initial state: 0 0.198905 0.176354 0.281454 0.744952 0.811455 0.774214 0.609688 0.640376 0.471916 0.513873 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17752 episodes
GETTING ACTION FROM:
action 0, numVisits=17684, meanQ=62.607347, numObservations: 242
action -1, numVisits=60, meanQ=-3.040160, numObservations: 53
action 4, numVisits=4, meanQ=-8.477475, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.198905 0.176354 0.281454 0.744952 0.811455 0.774214 0.609688 0.640376 0.471916 0.513873 w: 1
Observation: 0 0 1 0 3 0 3 0 1 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=119, meanQ=83.463447, numObservations: 8
action 3, numVisits=2, meanQ=44.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37941 episodes
GETTING ACTION FROM:
action 5, numVisits=38060, meanQ=91.264261, numObservations: 9
action 3, numVisits=2, meanQ=44.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.198905 0.176354 0.281454 0.744952 0.811455 0.774214 0.609688 0.640376 0.471916 0.513873 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 77
Initial state: 0 0.929774 0.0799453 0.816111 0.885719 0.729101 0.44954 0.451277 0.639102 0.390067 0.583513 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29817 episodes
GETTING ACTION FROM:
action 2, numVisits=29772, meanQ=19.453654, numObservations: 9
action 1, numVisits=34, meanQ=4.654126, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=7, meanQ=-6.712857, numObservations: 5
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.929774 0.0799453 0.816111 0.885719 0.729101 0.44954 0.451277 0.639102 0.390067 0.583513 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 78
Initial state: 0 0.449008 0.548897 0.690948 0.406001 0.330775 0.890638 0.3658 0.830688 0.409575 0.161643 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30599 episodes
GETTING ACTION FROM:
action 5, numVisits=30583, meanQ=18.393413, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=5, meanQ=-3.000000, numObservations: 3
action 4, numVisits=5, meanQ=-3.000000, numObservations: 5
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.449008 0.548897 0.690948 0.406001 0.330775 0.890638 0.3658 0.830688 0.409575 0.161643 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 79
Initial state: 0 0.758684 0.904392 0.71792 0.454582 0.489811 0.59378 0.858442 0.671685 0.711371 0.753138 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29364 episodes
GETTING ACTION FROM:
action 3, numVisits=29358, meanQ=19.975684, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.758684 0.904392 0.71792 0.454582 0.489811 0.59378 0.858442 0.671685 0.711371 0.753138 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 80
Initial state: 0 0.426063 0.530206 0.592281 0.228537 0.796441 0.204041 0.685059 0.423498 0.404532 0.602927 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30177 episodes
GETTING ACTION FROM:
action 1, numVisits=30165, meanQ=19.311361, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 5, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.426063 0.530206 0.592281 0.228537 0.796441 0.204041 0.685059 0.423498 0.404532 0.602927 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 81
Initial state: 0 0.155266 0.573199 0.395875 0.127258 0.363729 0.695849 0.462437 0.557115 0.399294 0.208289 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28026 episodes
GETTING ACTION FROM:
action 5, numVisits=28020, meanQ=20.474399, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.155266 0.573199 0.395875 0.127258 0.363729 0.695849 0.462437 0.557115 0.399294 0.208289 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 82
Initial state: 0 0.134058 0.471991 0.161166 0.99415 0.290236 0.676423 0.0956485 0.507524 0.441718 0.551089 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28095 episodes
GETTING ACTION FROM:
action 3, numVisits=28040, meanQ=20.631745, numObservations: 9
action 4, numVisits=49, meanQ=13.938986, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.134058 0.471991 0.161166 0.99415 0.290236 0.676423 0.0956485 0.507524 0.441718 0.551089 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=260, meanQ=49.415212, numObservations: 9
action 4, numVisits=3, meanQ=26.326667, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 39995 episodes
GETTING ACTION FROM:
action 3, numVisits=288, meanQ=51.956154, numObservations: 9
action 4, numVisits=39970, meanQ=38.160881, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.134058 0.471991 0.161166 0.99415 0.290236 0.676423 0.0956485 0.507524 0.441718 0.551089 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=97, meanQ=53.956888, numObservations: 6
action 4, numVisits=15, meanQ=32.333333, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=3, meanQ=-4.003333, numObservations: 2
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 22901 episodes
GETTING ACTION FROM:
action 3, numVisits=101, meanQ=52.667593, numObservations: 7
action 4, numVisits=22912, meanQ=43.385494, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=3, meanQ=-4.003333, numObservations: 2
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.134058 0.471991 0.161166 0.99415 0.290236 0.676423 0.0956485 0.507524 0.441718 0.551089 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=33, meanQ=-0.395139, numObservations: 8
action -1, numVisits=6, meanQ=-1.010000, numObservations: 6
action 0, numVisits=5, meanQ=-1.010000, numObservations: 5
action 4, numVisits=6, meanQ=-4.003333, numObservations: 4
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 25225 episodes
GETTING ACTION FROM:
action 1, numVisits=25255, meanQ=42.156422, numObservations: 9
action -1, numVisits=7, meanQ=-1.151429, numObservations: 7
action 0, numVisits=7, meanQ=-1.292857, numObservations: 7
action 4, numVisits=6, meanQ=-4.003333, numObservations: 4
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.134058 0.471991 0.161166 0.99415 0.290236 0.676423 0.0956485 0.507524 0.441718 0.551089 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 3, numVisits=1, meanQ=99.000000, numObservations: 1
action 2, numVisits=220, meanQ=51.638299, numObservations: 9
action 4, numVisits=8, meanQ=30.875483, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-16.411634, numObservations: 1
action 5, numVisits=1, meanQ=-16.670864, numObservations: 1
Sampled 35690 episodes
GETTING ACTION FROM:
action 2, numVisits=35908, meanQ=51.212680, numObservations: 9
action 3, numVisits=3, meanQ=32.333333, numObservations: 1
action 4, numVisits=8, meanQ=30.875483, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-16.411634, numObservations: 1
action 5, numVisits=1, meanQ=-16.670864, numObservations: 1
action: 2
Next state: 0 0.134058 0.471991 0.161166 0.99415 0.290236 0.676423 0.0956485 0.507524 0.441718 0.551089 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 5
Improving policy...
PLANNING FROM:
action 5, numVisits=22, meanQ=32.088712, numObservations: 6
action 2, numVisits=3, meanQ=21.981968, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-15.984748, numObservations: 1
action 1, numVisits=1, meanQ=-16.595422, numObservations: 1
action 3, numVisits=1, meanQ=-1078.356968, numObservations: 1
Sampled 27316 episodes
GETTING ACTION FROM:
action 2, numVisits=27317, meanQ=43.698662, numObservations: 9
action 5, numVisits=24, meanQ=20.997986, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-15.984748, numObservations: 1
action 1, numVisits=1, meanQ=-16.595422, numObservations: 1
action 3, numVisits=1, meanQ=-1078.356968, numObservations: 1
action: 2
Next state: 0 0.134058 0.471991 0.161166 0.99415 0.290236 0.676423 0.0956485 0.507524 0.441718 0.551089 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 6
Improving policy...
PLANNING FROM:
action 0, numVisits=31, meanQ=45.321028, numObservations: 14
action 2, numVisits=1, meanQ=-16.106806, numObservations: 1
action 4, numVisits=1, meanQ=-16.990561, numObservations: 1
action 5, numVisits=1, meanQ=-17.875819, numObservations: 1
action -1, numVisits=7, meanQ=-116.138455, numObservations: 6
action 3, numVisits=1, meanQ=-280.684589, numObservations: 1
action 1, numVisits=1, meanQ=-812.418339, numObservations: 1
Sampled 13927 episodes
GETTING ACTION FROM:
action 0, numVisits=13958, meanQ=4.688049, numObservations: 207
action 2, numVisits=1, meanQ=-16.106806, numObservations: 1
action 4, numVisits=1, meanQ=-16.990561, numObservations: 1
action 5, numVisits=1, meanQ=-17.875819, numObservations: 1
action -1, numVisits=7, meanQ=-116.138455, numObservations: 6
action 3, numVisits=1, meanQ=-280.684589, numObservations: 1
action 1, numVisits=1, meanQ=-812.418339, numObservations: 1
action: 0
Next state: 0 0.134058 0.471991 0.161166 0.99415 0.290236 0.676423 0.0956485 0.507524 0.441718 0.551089 w: 1
Observation: 0 0 1 0 3 0 3 0 2 0 2 
Immediate reward: -2
Updated belief

t = 7
Improving policy...
PLANNING FROM:
action 5, numVisits=29, meanQ=76.970759, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-18.041784, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-167.009800, numObservations: 1
action 2, numVisits=1, meanQ=-470.208689, numObservations: 1
Sampled 43039 episodes
GETTING ACTION FROM:
action 5, numVisits=43068, meanQ=44.508911, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-18.041784, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-167.009800, numObservations: 1
action 2, numVisits=1, meanQ=-470.208689, numObservations: 1
action: 5
Next state: 1 0.134058 0.471991 0.161166 0.99415 0.290236 0.676423 0.0956485 0.507524 0.441718 0.551089 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 26.0197
Run # 83
Initial state: 0 0.255041 0.0443956 0.663886 0.378029 0.707701 0.338613 0.194011 0.467633 0.378368 0.556438 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17963 episodes
GETTING ACTION FROM:
action 0, numVisits=17922, meanQ=63.764459, numObservations: 243
action -1, numVisits=34, meanQ=-6.950000, numObservations: 32
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=3, meanQ=-34.333333, numObservations: 2
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.255041 0.0443956 0.663886 0.378029 0.707701 0.338613 0.194011 0.467633 0.378368 0.556438 w: 1
Observation: 0 0 1 0 2 0 1 0 1 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=69, meanQ=45.044643, numObservations: 8
action 2, numVisits=4, meanQ=21.747500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 32490 episodes
GETTING ACTION FROM:
action 5, numVisits=32559, meanQ=47.209725, numObservations: 9
action 2, numVisits=4, meanQ=21.747500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.255041 0.0443956 0.663886 0.378029 0.707701 0.338613 0.194011 0.467633 0.378368 0.556438 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 84
Initial state: 0 0.203995 0.40146 0.22724 0.933964 0.14752 0.0462354 0.497143 0.568643 0.308638 0.379406 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17982 episodes
GETTING ACTION FROM:
action 0, numVisits=17931, meanQ=63.108255, numObservations: 243
action 2, numVisits=3, meanQ=-4.003333, numObservations: 3
action -1, numVisits=37, meanQ=-4.007024, numObservations: 31
action 3, numVisits=8, meanQ=-4.738738, numObservations: 6
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.203995 0.40146 0.22724 0.933964 0.14752 0.0462354 0.497143 0.568643 0.308638 0.379406 w: 1
Observation: 0 0 1 0 3 0 1 0 2 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=155, meanQ=89.911486, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37473 episodes
GETTING ACTION FROM:
action 4, numVisits=37628, meanQ=89.414704, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.203995 0.40146 0.22724 0.933964 0.14752 0.0462354 0.497143 0.568643 0.308638 0.379406 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 85
Initial state: 0 0.40684 0.566479 0.885343 0.131122 0.204798 0.631615 0.211415 0.887321 0.664539 0.392979 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17781 episodes
GETTING ACTION FROM:
action -1, numVisits=17725, meanQ=45.146740, numObservations: 243
action 0, numVisits=37, meanQ=-4.033781, numObservations: 35
action 4, numVisits=7, meanQ=-5.002857, numObservations: 5
action 3, numVisits=7, meanQ=-5.428557, numObservations: 4
action 5, numVisits=3, meanQ=-34.333333, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.40684 0.566479 0.885343 0.131122 0.204798 0.631615 0.211415 0.887321 0.664539 0.392979 w: 1
Observation: 0 2 0 3 0 1 0 1 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=63, meanQ=9.140643, numObservations: 45
action -1, numVisits=7, meanQ=-1.294271, numObservations: 6
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=3, meanQ=-34.333333, numObservations: 2
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 17848 episodes
GETTING ACTION FROM:
action 0, numVisits=17911, meanQ=80.582958, numObservations: 243
action -1, numVisits=7, meanQ=-1.294271, numObservations: 6
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=3, meanQ=-34.333333, numObservations: 2
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.40684 0.566479 0.885343 0.131122 0.204798 0.631615 0.211415 0.887321 0.664539 0.392979 w: 1
Observation: 0 0 2 0 1 0 3 0 3 0 1 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=244, meanQ=93.062132, numObservations: 9
action 3, numVisits=3, meanQ=62.663333, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 38240 episodes
GETTING ACTION FROM:
action 1, numVisits=38484, meanQ=96.866407, numObservations: 9
action 3, numVisits=3, meanQ=62.663333, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.40684 0.566479 0.885343 0.131122 0.204798 0.631615 0.211415 0.887321 0.664539 0.392979 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 93.0499
Run # 86
Initial state: 0 0.50817 0.378466 0.686075 0.098604 0.520095 0.518115 0.236607 0.285989 0.327273 0.522757 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30714 episodes
GETTING ACTION FROM:
action 2, numVisits=30685, meanQ=16.608774, numObservations: 9
action 1, numVisits=18, meanQ=12.998339, numObservations: 7
action 3, numVisits=6, meanQ=10.996667, numObservations: 5
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.50817 0.378466 0.686075 0.098604 0.520095 0.518115 0.236607 0.285989 0.327273 0.522757 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 87
Initial state: 0 0.503936 0.534583 0.785061 0.69326 0.356621 0.63734 0.402127 0.333949 0.0459321 0.147385 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31326 episodes
GETTING ACTION FROM:
action 1, numVisits=31292, meanQ=18.429541, numObservations: 9
action -1, numVisits=14, meanQ=-1.010000, numObservations: 14
action 0, numVisits=14, meanQ=-1.010000, numObservations: 14
action 5, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.503936 0.534583 0.785061 0.69326 0.356621 0.63734 0.402127 0.333949 0.0459321 0.147385 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 88
Initial state: 0 0.440316 0.577357 0.774101 0.266008 0.814245 0.384264 0.919791 0.89224 0.213307 0.663728 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17596 episodes
GETTING ACTION FROM:
action -1, numVisits=17549, meanQ=41.717922, numObservations: 243
action 0, numVisits=39, meanQ=-3.878715, numObservations: 37
action 2, numVisits=4, meanQ=-6.000000, numObservations: 3
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.440316 0.577357 0.774101 0.266008 0.814245 0.384264 0.919791 0.89224 0.213307 0.663728 w: 1
Observation: 0 2 0 3 0 3 0 3 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=139, meanQ=38.659325, numObservations: 43
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 18029 episodes
GETTING ACTION FROM:
action -1, numVisits=18168, meanQ=72.562733, numObservations: 198
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.440316 0.577357 0.774101 0.266008 0.814245 0.384264 0.919791 0.89224 0.213307 0.663728 w: 1
Observation: 0 2 0 3 0 3 0 3 0 1 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=5711, meanQ=95.995199, numObservations: 9
action 5, numVisits=2, meanQ=44.495000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37215 episodes
GETTING ACTION FROM:
action 1, numVisits=42926, meanQ=96.369824, numObservations: 9
action 5, numVisits=2, meanQ=44.495000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.440316 0.577357 0.774101 0.266008 0.814245 0.384264 0.919791 0.89224 0.213307 0.663728 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 93.0499
Run # 89
Initial state: 0 0.856555 0.858745 0.902615 0.589436 0.0759034 0.67567 0.425498 0.0251149 0.438743 0.492197 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27519 episodes
GETTING ACTION FROM:
action 1, numVisits=27513, meanQ=22.319446, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.856555 0.858745 0.902615 0.589436 0.0759034 0.67567 0.425498 0.0251149 0.438743 0.492197 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 90
Initial state: 0 0.154852 0.244617 0.794605 0.20461 0.929238 0.512031 0.35391 0.549772 0.553087 0.239792 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28205 episodes
GETTING ACTION FROM:
action 4, numVisits=27956, meanQ=22.133108, numObservations: 9
action 2, numVisits=168, meanQ=10.972627, numObservations: 9
action 5, numVisits=76, meanQ=10.648429, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.154852 0.244617 0.794605 0.20461 0.929238 0.512031 0.35391 0.549772 0.553087 0.239792 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=399, meanQ=75.196148, numObservations: 9
action 5, numVisits=2, meanQ=44.495000, numObservations: 2
action 1, numVisits=3, meanQ=26.326667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 40653 episodes
GETTING ACTION FROM:
action 4, numVisits=41052, meanQ=85.158163, numObservations: 9
action 5, numVisits=2, meanQ=44.495000, numObservations: 2
action 1, numVisits=3, meanQ=26.326667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.154852 0.244617 0.794605 0.20461 0.929238 0.512031 0.35391 0.549772 0.553087 0.239792 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 91
Initial state: 0 0.388898 0.00494064 0.406814 0.535549 0.924186 0.308413 0.217823 0.139741 0.19123 0.917775 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17780 episodes
GETTING ACTION FROM:
action 0, numVisits=17741, meanQ=62.181521, numObservations: 243
action -1, numVisits=34, meanQ=-3.980000, numObservations: 33
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.388898 0.00494064 0.406814 0.535549 0.924186 0.308413 0.217823 0.139741 0.19123 0.917775 w: 1
Observation: 0 0 2 0 2 0 1 0 1 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=56, meanQ=52.089289, numObservations: 9
action 5, numVisits=4, meanQ=21.747500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 32769 episodes
GETTING ACTION FROM:
action 2, numVisits=32825, meanQ=54.980311, numObservations: 9
action 5, numVisits=4, meanQ=21.747500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.388898 0.00494064 0.406814 0.535549 0.924186 0.308413 0.217823 0.139741 0.19123 0.917775 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 92
Initial state: 0 0.558153 0.639773 0.370544 0.822202 0.830558 0.90691 0.349074 0.582322 0.873932 0.334156 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30785 episodes
GETTING ACTION FROM:
action 3, numVisits=30773, meanQ=17.850041, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 4, numVisits=5, meanQ=-3.000000, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.558153 0.639773 0.370544 0.822202 0.830558 0.90691 0.349074 0.582322 0.873932 0.334156 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 93
Initial state: 0 0.261164 0.898887 0.471301 0.556663 0.400129 0.14236 0.0274697 0.254447 0.149048 0.7837 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17621 episodes
GETTING ACTION FROM:
action -1, numVisits=17553, meanQ=46.547684, numObservations: 243
action 0, numVisits=21, meanQ=-1.010000, numObservations: 21
action 3, numVisits=12, meanQ=-2.501667, numObservations: 6
action 5, numVisits=5, meanQ=-2.802000, numObservations: 4
action 2, numVisits=23, meanQ=-3.045213, numObservations: 9
action 1, numVisits=3, meanQ=-4.333333, numObservations: 2
action 4, numVisits=4, meanQ=-6.249975, numObservations: 3
action: -1
Next state: 0 0.261164 0.898887 0.471301 0.556663 0.400129 0.14236 0.0274697 0.254447 0.149048 0.7837 w: 1
Observation: 0 1 0 1 0 2 0 1 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=52, meanQ=54.061931, numObservations: 9
action 1, numVisits=6, meanQ=25.995017, numObservations: 3
action 5, numVisits=5, meanQ=15.396000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37033 episodes
GETTING ACTION FROM:
action 3, numVisits=37085, meanQ=82.939332, numObservations: 9
action 1, numVisits=6, meanQ=25.995017, numObservations: 3
action 5, numVisits=5, meanQ=15.396000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.261164 0.898887 0.471301 0.556663 0.400129 0.14236 0.0274697 0.254447 0.149048 0.7837 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101.99
Run # 94
Initial state: 0 0.102166 0.166746 0.152218 0.405238 0.187925 0.341492 0.255736 0.301276 0.514288 0.506304 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30790 episodes
GETTING ACTION FROM:
action 4, numVisits=30782, meanQ=19.004585, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.102166 0.166746 0.152218 0.405238 0.187925 0.341492 0.255736 0.301276 0.514288 0.506304 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=3264, meanQ=23.821153, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 8711 episodes
GETTING ACTION FROM:
action 3, numVisits=11975, meanQ=21.399541, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.102166 0.166746 0.152218 0.405238 0.187925 0.341492 0.255736 0.301276 0.514288 0.506304 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -110.99
Run # 95
Initial state: 0 0.182009 0.103868 0.483705 0.735546 0.326925 0.0617486 0.719578 0.778452 0.424453 0.569082 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29666 episodes
GETTING ACTION FROM:
action 2, numVisits=29653, meanQ=16.793207, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=7, meanQ=-2.287143, numObservations: 5
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.182009 0.103868 0.483705 0.735546 0.326925 0.0617486 0.719578 0.778452 0.424453 0.569082 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 96
Initial state: 0 0.733179 0.728772 0.19788 0.0148176 0.0545078 0.492925 0.890043 0.841103 0.368997 0.550501 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28472 episodes
GETTING ACTION FROM:
action 5, numVisits=28430, meanQ=22.745324, numObservations: 9
action 0, numVisits=18, meanQ=-1.120550, numObservations: 17
action -1, numVisits=20, meanQ=-6.059000, numObservations: 19
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.733179 0.728772 0.19788 0.0148176 0.0545078 0.492925 0.890043 0.841103 0.368997 0.550501 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 97
Initial state: 0 0.0174137 0.798731 0.391713 0.573472 0.377739 0.0267672 0.868714 0.680744 0.792389 0.484732 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17746 episodes
GETTING ACTION FROM:
action -1, numVisits=17714, meanQ=48.097200, numObservations: 243
action 0, numVisits=27, meanQ=-5.153700, numObservations: 25
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.0174137 0.798731 0.391713 0.573472 0.377739 0.0267672 0.868714 0.680744 0.792389 0.484732 w: 1
Observation: 0 1 0 2 0 2 0 1 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=67, meanQ=39.822542, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 35758 episodes
GETTING ACTION FROM:
action 2, numVisits=35825, meanQ=48.482332, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.0174137 0.798731 0.391713 0.573472 0.377739 0.0267672 0.868714 0.680744 0.792389 0.484732 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 98
Initial state: 0 0.269167 0.546417 0.970938 0.221658 0.933521 0.325078 0.512767 0.500353 0.962683 0.868105 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17933 episodes
GETTING ACTION FROM:
action 0, numVisits=17902, meanQ=61.182294, numObservations: 243
action -1, numVisits=24, meanQ=-5.217500, numObservations: 23
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=3, meanQ=-34.333333, numObservations: 3
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.269167 0.546417 0.970938 0.221658 0.933521 0.325078 0.512767 0.500353 0.962683 0.868105 w: 1
Observation: 0 0 2 0 1 0 1 0 2 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=57, meanQ=49.351935, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 30781 episodes
GETTING ACTION FROM:
action 1, numVisits=30838, meanQ=54.914614, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 1
Next state: 2 0.269167 0.546417 0.970938 0.221658 0.933521 0.325078 0.512767 0.500353 0.962683 0.868105 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101.99
Run # 99
Initial state: 0 0.744578 0.793996 0.773027 0.842797 0.857661 0.0652641 0.520497 0.151888 0.390968 0.567825 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17344 episodes
GETTING ACTION FROM:
action -1, numVisits=17325, meanQ=47.998751, numObservations: 243
action 1, numVisits=5, meanQ=-3.000000, numObservations: 5
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=10, meanQ=-11.108000, numObservations: 9
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.744578 0.793996 0.773027 0.842797 0.857661 0.0652641 0.520497 0.151888 0.390968 0.567825 w: 1
Observation: 0 3 0 3 0 2 0 2 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=44, meanQ=13.137957, numObservations: 9
action 1, numVisits=3, meanQ=-4.003333, numObservations: 3
action 0, numVisits=22, meanQ=-5.600000, numObservations: 21
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=8, meanQ=-14.626250, numObservations: 3
action -1, numVisits=3, meanQ=-34.670000, numObservations: 2
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 35055 episodes
GETTING ACTION FROM:
action 3, numVisits=35099, meanQ=36.930407, numObservations: 9
action 1, numVisits=3, meanQ=-4.003333, numObservations: 3
action 0, numVisits=22, meanQ=-5.600000, numObservations: 21
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=8, meanQ=-14.626250, numObservations: 3
action -1, numVisits=3, meanQ=-34.670000, numObservations: 2
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.744578 0.793996 0.773027 0.842797 0.857661 0.0652641 0.520497 0.151888 0.390968 0.567825 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101.99
Run # 100
Initial state: 0 0.204813 0.0637768 0.4036 0.557501 0.885542 0.522697 0.157602 0.0841162 0.889114 0.455759 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17402 episodes
GETTING ACTION FROM:
action -1, numVisits=17368, meanQ=45.034545, numObservations: 243
action 0, numVisits=12, meanQ=-1.175825, numObservations: 11
action 2, numVisits=13, meanQ=-3.079231, numObservations: 8
action 3, numVisits=4, meanQ=-8.497500, numObservations: 3
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=3, meanQ=-34.333333, numObservations: 3
action: -1
Next state: 0 0.204813 0.0637768 0.4036 0.557501 0.885542 0.522697 0.157602 0.0841162 0.889114 0.455759 w: 1
Observation: 0 2 0 1 0 3 0 1 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=17, meanQ=36.012371, numObservations: 5
action 3, numVisits=67, meanQ=11.984925, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 24411 episodes
GETTING ACTION FROM:
action 4, numVisits=24428, meanQ=50.132304, numObservations: 9
action 3, numVisits=67, meanQ=11.984925, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.204813 0.0637768 0.4036 0.557501 0.885542 0.522697 0.157602 0.0841162 0.889114 0.455759 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=8135, meanQ=88.743731, numObservations: 9
action 2, numVisits=2, meanQ=44.495000, numObservations: 2
action 3, numVisits=2, meanQ=44.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 21132 episodes
GETTING ACTION FROM:
action 1, numVisits=29267, meanQ=85.592493, numObservations: 9
action 2, numVisits=2, meanQ=44.495000, numObservations: 2
action 3, numVisits=2, meanQ=44.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.204813 0.0637768 0.4036 0.557501 0.885542 0.522697 0.157602 0.0841162 0.889114 0.455759 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 5, numVisits=110, meanQ=52.913987, numObservations: 8
action 2, numVisits=2, meanQ=44.495000, numObservations: 2
action 3, numVisits=13, meanQ=44.460769, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 30237 episodes
GETTING ACTION FROM:
action 3, numVisits=30113, meanQ=36.583927, numObservations: 9
action 5, numVisits=244, meanQ=32.690732, numObservations: 9
action 2, numVisits=5, meanQ=15.198000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 3
Next state: 1 0.204813 0.0637768 0.4036 0.557501 0.885542 0.522697 0.157602 0.0841162 0.889114 0.455759 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 72.3885
Run # 101
Initial state: 0 0.395564 0.507781 0.445717 0.637893 0.490793 0.388885 0.96633 0.165933 0.297838 0.877075 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17878 episodes
GETTING ACTION FROM:
action 0, numVisits=17847, meanQ=62.897177, numObservations: 243
action -1, numVisits=23, meanQ=-5.400435, numObservations: 22
action 2, numVisits=4, meanQ=-6.000000, numObservations: 4
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.395564 0.507781 0.445717 0.637893 0.490793 0.388885 0.96633 0.165933 0.297838 0.877075 w: 1
Observation: 0 0 2 0 3 0 1 0 1 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=114, meanQ=81.764389, numObservations: 8
action 2, numVisits=6, meanQ=65.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37773 episodes
GETTING ACTION FROM:
action 1, numVisits=37887, meanQ=92.119050, numObservations: 9
action 2, numVisits=6, meanQ=65.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.395564 0.507781 0.445717 0.637893 0.490793 0.388885 0.96633 0.165933 0.297838 0.877075 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 102
Initial state: 0 0.446552 0.538679 0.036957 0.33548 0.636002 0.896132 0.744962 0.613264 0.160874 0.826884 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29907 episodes
GETTING ACTION FROM:
action 4, numVisits=29889, meanQ=19.674161, numObservations: 9
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=3, meanQ=-7.663333, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=3, meanQ=-34.333333, numObservations: 3
action: 4
Next state: 1 0.446552 0.538679 0.036957 0.33548 0.636002 0.896132 0.744962 0.613264 0.160874 0.826884 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 103
Initial state: 0 0.432357 0.561189 0.893692 0.228397 0.759391 0.629782 0.159997 0.402041 0.274762 0.511961 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17672 episodes
GETTING ACTION FROM:
action 0, numVisits=17638, meanQ=63.441864, numObservations: 243
action -1, numVisits=29, meanQ=-1.146552, numObservations: 27
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.432357 0.561189 0.893692 0.228397 0.759391 0.629782 0.159997 0.402041 0.274762 0.511961 w: 1
Observation: 0 0 2 0 1 0 3 0 1 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=57, meanQ=48.579835, numObservations: 9
action 5, numVisits=17, meanQ=36.121194, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 36387 episodes
GETTING ACTION FROM:
action 1, numVisits=36444, meanQ=55.872731, numObservations: 9
action 5, numVisits=17, meanQ=36.121194, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.432357 0.561189 0.893692 0.228397 0.759391 0.629782 0.159997 0.402041 0.274762 0.511961 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 104
Initial state: 0 0.792409 0.482088 0.642846 0.549879 0.384256 0.530705 0.962172 0.518334 0.77896 0.577024 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17775 episodes
GETTING ACTION FROM:
action -1, numVisits=17683, meanQ=48.319549, numObservations: 243
action 1, numVisits=5, meanQ=-2.802000, numObservations: 4
action 4, numVisits=29, meanQ=-3.033793, numObservations: 9
action 2, numVisits=38, meanQ=-3.395518, numObservations: 9
action 0, numVisits=18, meanQ=-6.620000, numObservations: 17
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.792409 0.482088 0.642846 0.549879 0.384256 0.530705 0.962172 0.518334 0.77896 0.577024 w: 1
Observation: 0 3 0 3 0 2 0 3 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=101, meanQ=84.366634, numObservations: 8
action 1, numVisits=2, meanQ=44.495000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 37002 episodes
GETTING ACTION FROM:
action 3, numVisits=37103, meanQ=80.952079, numObservations: 9
action 1, numVisits=2, meanQ=44.495000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 3
Next state: 1 0.792409 0.482088 0.642846 0.549879 0.384256 0.530705 0.962172 0.518334 0.77896 0.577024 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 105
Initial state: 0 0.437662 0.0625203 0.504187 0.490043 0.951311 0.354108 0.044425 0.325946 0.231766 0.0524399 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30858 episodes
GETTING ACTION FROM:
action 5, numVisits=30843, meanQ=17.523470, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 2
action 2, numVisits=6, meanQ=-4.333333, numObservations: 6
action 3, numVisits=3, meanQ=-4.333333, numObservations: 2
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.437662 0.0625203 0.504187 0.490043 0.951311 0.354108 0.044425 0.325946 0.231766 0.0524399 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 106
Initial state: 0 0.652043 0.128782 0.652055 0.0586267 0.47805 0.0825512 0.166135 0.829085 0.493043 0.577223 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29446 episodes
GETTING ACTION FROM:
action 3, numVisits=29397, meanQ=18.812131, numObservations: 9
action 4, numVisits=43, meanQ=12.302344, numObservations: 8
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.652043 0.128782 0.652055 0.0586267 0.47805 0.0825512 0.166135 0.829085 0.493043 0.577223 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=668, meanQ=44.646912, numObservations: 152
action -1, numVisits=14, meanQ=-15.577850, numObservations: 11
action 1, numVisits=3, meanQ=-34.333333, numObservations: 3
action 2, numVisits=3, meanQ=-34.333333, numObservations: 2
action 5, numVisits=2, meanQ=-55.505000, numObservations: 2
action 4, numVisits=2, meanQ=-60.500000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 8221 episodes
GETTING ACTION FROM:
action 0, numVisits=8889, meanQ=18.947862, numObservations: 241
action -1, numVisits=14, meanQ=-15.577850, numObservations: 11
action 1, numVisits=3, meanQ=-34.333333, numObservations: 3
action 2, numVisits=3, meanQ=-34.333333, numObservations: 2
action 5, numVisits=2, meanQ=-55.505000, numObservations: 2
action 4, numVisits=2, meanQ=-60.500000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.652043 0.128782 0.652055 0.0586267 0.47805 0.0825512 0.166135 0.829085 0.493043 0.577223 w: 1
Observation: 0 0 1 0 1 0 1 0 3 0 2 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=30, meanQ=77.506155, numObservations: 7
action 4, numVisits=4, meanQ=69.219944, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 25390 episodes
GETTING ACTION FROM:
action 5, numVisits=25419, meanQ=74.457464, numObservations: 9
action 4, numVisits=5, meanQ=35.175955, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.652043 0.128782 0.652055 0.0586267 0.47805 0.0825512 0.166135 0.829085 0.493043 0.577223 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 84.0499
Run # 107
Initial state: 0 0.121659 0.403438 0.721555 0.83977 0.398704 0.577916 0.633591 0.620612 0.595222 0.244233 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30214 episodes
GETTING ACTION FROM:
action 3, numVisits=30201, meanQ=20.278987, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=6, meanQ=-4.499983, numObservations: 5
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.121659 0.403438 0.721555 0.83977 0.398704 0.577916 0.633591 0.620612 0.595222 0.244233 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 108
Initial state: 0 0.435896 0.560462 0.873681 0.889802 0.0661444 0.106723 0.74483 0.218175 0.761443 0.93146 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17793 episodes
GETTING ACTION FROM:
action -1, numVisits=17776, meanQ=46.547258, numObservations: 243
action 0, numVisits=12, meanQ=-9.425000, numObservations: 11
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.435896 0.560462 0.873681 0.889802 0.0661444 0.106723 0.74483 0.218175 0.761443 0.93146 w: 1
Observation: 0 2 0 1 0 1 0 1 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=59, meanQ=69.204410, numObservations: 9
action 2, numVisits=2, meanQ=44.495000, numObservations: 2
action 5, numVisits=4, meanQ=21.747500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37110 episodes
GETTING ACTION FROM:
action 1, numVisits=37169, meanQ=84.343721, numObservations: 9
action 2, numVisits=2, meanQ=44.495000, numObservations: 2
action 5, numVisits=4, meanQ=21.747500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.435896 0.560462 0.873681 0.889802 0.0661444 0.106723 0.74483 0.218175 0.761443 0.93146 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 109
Initial state: 0 0.923296 0.69362 0.868939 0.919811 0.766567 0.822039 0.907229 0.968645 0.358287 0.588435 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28723 episodes
GETTING ACTION FROM:
action 5, numVisits=28707, meanQ=20.865933, numObservations: 9
action 2, numVisits=11, meanQ=13.553645, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.923296 0.69362 0.868939 0.919811 0.766567 0.822039 0.907229 0.968645 0.358287 0.588435 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 110
Initial state: 0 0.997312 0.473111 0.798814 0.601779 0.0163165 0.229294 0.24431 0.6242 0.474282 0.5568 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29738 episodes
GETTING ACTION FROM:
action 5, numVisits=29723, meanQ=19.677372, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=9, meanQ=-2.111111, numObservations: 6
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.997312 0.473111 0.798814 0.601779 0.0163165 0.229294 0.24431 0.6242 0.474282 0.5568 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 111
Initial state: 0 0.945068 0.835424 0.921072 0.537519 0.139259 0.0741525 0.421453 0.567463 0.294929 0.973267 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17705 episodes
GETTING ACTION FROM:
action -1, numVisits=17662, meanQ=45.351987, numObservations: 243
action 0, numVisits=32, meanQ=-4.165625, numObservations: 31
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=4, meanQ=-28.500000, numObservations: 4
action 2, numVisits=4, meanQ=-30.997500, numObservations: 2
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.945068 0.835424 0.921072 0.537519 0.139259 0.0741525 0.421453 0.567463 0.294929 0.973267 w: 1
Observation: 0 3 0 3 0 3 0 2 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=96, meanQ=36.604274, numObservations: 9
action 1, numVisits=21, meanQ=22.809524, numObservations: 4
action 2, numVisits=4, meanQ=-1.000000, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 34956 episodes
GETTING ACTION FROM:
action 4, numVisits=35052, meanQ=43.731225, numObservations: 9
action 1, numVisits=21, meanQ=22.809524, numObservations: 4
action 2, numVisits=4, meanQ=-1.000000, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 4
Next state: 1 0.945068 0.835424 0.921072 0.537519 0.139259 0.0741525 0.421453 0.567463 0.294929 0.973267 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 112
Initial state: 0 0.345231 0.457695 0.247103 0.0924227 0.397799 0.411571 0.475482 0.580771 0.149204 0.638987 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30605 episodes
GETTING ACTION FROM:
action 1, numVisits=30581, meanQ=17.730171, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=7, meanQ=-1.010000, numObservations: 7
action 2, numVisits=5, meanQ=-2.802000, numObservations: 4
action 4, numVisits=3, meanQ=-4.003333, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.345231 0.457695 0.247103 0.0924227 0.397799 0.411571 0.475482 0.580771 0.149204 0.638987 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=3230, meanQ=24.217710, numObservations: 9
action 0, numVisits=26, meanQ=-5.046154, numObservations: 23
action -1, numVisits=18, meanQ=-7.336100, numObservations: 15
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 9163 episodes
GETTING ACTION FROM:
action 3, numVisits=12393, meanQ=17.397707, numObservations: 9
action 0, numVisits=26, meanQ=-5.046154, numObservations: 23
action -1, numVisits=18, meanQ=-7.336100, numObservations: 15
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.345231 0.457695 0.247103 0.0924227 0.397799 0.411571 0.475482 0.580771 0.149204 0.638987 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=231, meanQ=13.124840, numObservations: 9
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=22, meanQ=-12.480322, numObservations: 9
action 0, numVisits=29, meanQ=-39.034529, numObservations: 25
action -1, numVisits=19, meanQ=-52.550533, numObservations: 15
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 15726 episodes
GETTING ACTION FROM:
action 2, numVisits=15957, meanQ=5.901392, numObservations: 9
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=22, meanQ=-12.480322, numObservations: 9
action 0, numVisits=29, meanQ=-39.034529, numObservations: 25
action -1, numVisits=19, meanQ=-52.550533, numObservations: 15
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.345231 0.457695 0.247103 0.0924227 0.397799 0.411571 0.475482 0.580771 0.149204 0.638987 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 0, numVisits=188, meanQ=31.070451, numObservations: 41
action -1, numVisits=68, meanQ=-7.882173, numObservations: 32
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-17.190667, numObservations: 1
action 4, numVisits=1, meanQ=-17.485577, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 1, numVisits=1, meanQ=-1073.959081, numObservations: 1
Sampled 10709 episodes
GETTING ACTION FROM:
action 0, numVisits=10897, meanQ=6.088725, numObservations: 199
action -1, numVisits=68, meanQ=-7.882173, numObservations: 32
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-17.190667, numObservations: 1
action 4, numVisits=1, meanQ=-17.485577, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 1, numVisits=1, meanQ=-1073.959081, numObservations: 1
action: 0
Next state: 0 0.345231 0.457695 0.247103 0.0924227 0.397799 0.411571 0.475482 0.580771 0.149204 0.638987 w: 1
Observation: 0 0 1 0 1 0 1 0 1 0 3 
Immediate reward: -2
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 4, numVisits=19, meanQ=27.690279, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-18.022815, numObservations: 1
action 3, numVisits=1, meanQ=-366.575027, numObservations: 1
action 2, numVisits=1, meanQ=-370.000688, numObservations: 1
action 1, numVisits=1, meanQ=-370.080256, numObservations: 1
Sampled 12152 episodes
GETTING ACTION FROM:
action 0, numVisits=12078, meanQ=9.384182, numObservations: 176
action 4, numVisits=29, meanQ=-6.685679, numObservations: 7
action -1, numVisits=66, meanQ=-7.423514, numObservations: 38
action 5, numVisits=1, meanQ=-18.022815, numObservations: 1
action 3, numVisits=1, meanQ=-366.575027, numObservations: 1
action 2, numVisits=1, meanQ=-370.000688, numObservations: 1
action 1, numVisits=1, meanQ=-370.080256, numObservations: 1
action: 0
Next state: 0 0.345231 0.457695 0.247103 0.0924227 0.397799 0.411571 0.475482 0.580771 0.149204 0.638987 w: 1
Observation: 0 0 1 0 1 0 1 0 3 0 3 
Immediate reward: -2
Updated belief

t = 5
Improving policy...
PLANNING FROM:
action 5, numVisits=30, meanQ=71.300640, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-19.962953, numObservations: 1
action 3, numVisits=1, meanQ=-368.303790, numObservations: 1
action 1, numVisits=1, meanQ=-369.500791, numObservations: 1
action 2, numVisits=1, meanQ=-371.195046, numObservations: 1
Sampled 40987 episodes
GETTING ACTION FROM:
action 5, numVisits=41017, meanQ=70.938694, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-19.962953, numObservations: 1
action 3, numVisits=1, meanQ=-368.303790, numObservations: 1
action 1, numVisits=1, meanQ=-369.500791, numObservations: 1
action 2, numVisits=1, meanQ=-371.195046, numObservations: 1
action: 5
Next state: 1 0.345231 0.457695 0.247103 0.0924227 0.397799 0.411571 0.475482 0.580771 0.149204 0.638987 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 57.6151
Run # 113
Initial state: 0 0.509918 0.547887 0.603138 0.437805 0.158788 0.888731 0.32127 0.809967 0.628152 0.0841163 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17900 episodes
GETTING ACTION FROM:
action 0, numVisits=17863, meanQ=64.345436, numObservations: 243
action 3, numVisits=27, meanQ=-1.360726, numObservations: 8
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=6, meanQ=-17.840000, numObservations: 5
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.509918 0.547887 0.603138 0.437805 0.158788 0.888731 0.32127 0.809967 0.628152 0.0841163 w: 1
Observation: 0 0 2 0 1 0 3 0 3 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=18, meanQ=46.386672, numObservations: 6
action 5, numVisits=25, meanQ=45.119600, numObservations: 7
action 4, numVisits=2, meanQ=44.495000, numObservations: 2
action 3, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 34281 episodes
GETTING ACTION FROM:
action 1, numVisits=34298, meanQ=66.423393, numObservations: 9
action 5, numVisits=25, meanQ=45.119600, numObservations: 7
action 3, numVisits=3, meanQ=32.333333, numObservations: 2
action 4, numVisits=3, meanQ=25.996667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 1
Next state: 1 0.509918 0.547887 0.603138 0.437805 0.158788 0.888731 0.32127 0.809967 0.628152 0.0841163 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 114
Initial state: 0 0.134719 0.924385 0.997817 0.0646503 0.143527 0.0593916 0.743555 0.540682 0.514332 0.591739 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17787 episodes
GETTING ACTION FROM:
action 0, numVisits=17709, meanQ=62.985409, numObservations: 243
action -1, numVisits=35, meanQ=-1.435134, numObservations: 32
action 2, numVisits=39, meanQ=-1.948444, numObservations: 9
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.134719 0.924385 0.997817 0.0646503 0.143527 0.0593916 0.743555 0.540682 0.514332 0.591739 w: 1
Observation: 0 0 3 0 1 0 1 0 2 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=127, meanQ=82.315358, numObservations: 9
action 1, numVisits=8, meanQ=60.373750, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37356 episodes
GETTING ACTION FROM:
action 4, numVisits=37483, meanQ=88.527748, numObservations: 9
action 1, numVisits=8, meanQ=60.373750, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.134719 0.924385 0.997817 0.0646503 0.143527 0.0593916 0.743555 0.540682 0.514332 0.591739 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 115
Initial state: 0 0.518651 0.501177 0.576857 0.962574 0.196972 0.231154 0.81533 0.973993 0.846018 0.147282 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30859 episodes
GETTING ACTION FROM:
action 4, numVisits=30824, meanQ=17.432946, numObservations: 9
action 3, numVisits=19, meanQ=12.578958, numObservations: 9
action 1, numVisits=12, meanQ=3.916667, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.518651 0.501177 0.576857 0.962574 0.196972 0.231154 0.81533 0.973993 0.846018 0.147282 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 116
Initial state: 0 0.599228 0.0488414 0.946402 0.451275 0.483318 0.57921 0.0416534 0.542456 0.105208 0.194374 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29952 episodes
GETTING ACTION FROM:
action 5, numVisits=29936, meanQ=18.414190, numObservations: 9
action -1, numVisits=6, meanQ=-1.010000, numObservations: 6
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.599228 0.0488414 0.946402 0.451275 0.483318 0.57921 0.0416534 0.542456 0.105208 0.194374 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=3101, meanQ=25.035808, numObservations: 9
action 1, numVisits=16, meanQ=2.936250, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 11671 episodes
GETTING ACTION FROM:
action 2, numVisits=14772, meanQ=19.887670, numObservations: 9
action 1, numVisits=16, meanQ=2.936250, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.599228 0.0488414 0.946402 0.451275 0.483318 0.57921 0.0416534 0.542456 0.105208 0.194374 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -110.99
Run # 117
Initial state: 0 0.51422 0.460849 0.168554 0.274281 0.482119 0.565754 0.565834 0.370578 0.976821 0.768252 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17858 episodes
GETTING ACTION FROM:
action 0, numVisits=17787, meanQ=60.940064, numObservations: 243
action -1, numVisits=64, meanQ=-6.177336, numObservations: 56
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=3, meanQ=-34.333333, numObservations: 3
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.51422 0.460849 0.168554 0.274281 0.482119 0.565754 0.565834 0.370578 0.976821 0.768252 w: 1
Observation: 0 0 1 0 1 0 2 0 1 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=33, meanQ=11.947300, numObservations: 17
action -1, numVisits=57, meanQ=-3.442968, numObservations: 46
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 17683 episodes
GETTING ACTION FROM:
action 0, numVisits=17716, meanQ=61.309261, numObservations: 189
action -1, numVisits=57, meanQ=-3.442968, numObservations: 46
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.51422 0.460849 0.168554 0.274281 0.482119 0.565754 0.565834 0.370578 0.976821 0.768252 w: 1
Observation: 0 0 1 0 1 0 2 0 1 0 3 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=1283, meanQ=85.679244, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 36495 episodes
GETTING ACTION FROM:
action 3, numVisits=37778, meanQ=89.426783, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.51422 0.460849 0.168554 0.274281 0.482119 0.565754 0.565834 0.370578 0.976821 0.768252 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 93.0499
Run # 118
Initial state: 0 0.25923 0.709035 0.783481 0.501113 0.151016 0.634864 0.435541 0.498617 0.848815 0.742134 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17543 episodes
GETTING ACTION FROM:
action 0, numVisits=17522, meanQ=62.829676, numObservations: 243
action -1, numVisits=13, meanQ=-8.777692, numObservations: 12
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=4, meanQ=-28.500000, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.25923 0.709035 0.783481 0.501113 0.151016 0.634864 0.435541 0.498617 0.848815 0.742134 w: 1
Observation: 0 0 3 0 2 0 3 0 2 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=33, meanQ=41.969097, numObservations: 7
action 5, numVisits=6, meanQ=14.165000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 34843 episodes
GETTING ACTION FROM:
action 4, numVisits=34876, meanQ=64.458188, numObservations: 9
action 5, numVisits=6, meanQ=14.165000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.25923 0.709035 0.783481 0.501113 0.151016 0.634864 0.435541 0.498617 0.848815 0.742134 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 119
Initial state: 0 0.463343 0.523328 0.536413 0.80258 0.630554 0.148449 0.334106 0.629448 0.642006 0.904311 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28467 episodes
GETTING ACTION FROM:
action 2, numVisits=28458, meanQ=18.742945, numObservations: 9
action 5, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.463343 0.523328 0.536413 0.80258 0.630554 0.148449 0.334106 0.629448 0.642006 0.904311 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 120
Initial state: 0 0.530269 0.913569 0.346044 0.813546 0.87738 0.176816 0.451135 0.541605 0.931371 0.770603 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17789 episodes
GETTING ACTION FROM:
action 0, numVisits=17750, meanQ=62.637738, numObservations: 243
action -1, numVisits=27, meanQ=-4.750000, numObservations: 26
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=6, meanQ=-19.333333, numObservations: 5
action 1, numVisits=3, meanQ=-34.333333, numObservations: 2
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.530269 0.913569 0.346044 0.813546 0.87738 0.176816 0.451135 0.541605 0.931371 0.770603 w: 1
Observation: 0 0 3 0 3 0 1 0 3 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=28, meanQ=62.571075, numObservations: 7
action 1, numVisits=4, meanQ=41.770025, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 33530 episodes
GETTING ACTION FROM:
action 4, numVisits=33558, meanQ=64.391497, numObservations: 9
action 1, numVisits=4, meanQ=41.770025, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 4
Next state: 1 0.530269 0.913569 0.346044 0.813546 0.87738 0.176816 0.451135 0.541605 0.931371 0.770603 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 121
Initial state: 0 0.195771 0.12923 0.708328 0.571042 0.50681 0.316493 0.747575 0.834447 0.453963 0.516064 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30001 episodes
GETTING ACTION FROM:
action 2, numVisits=29994, meanQ=20.578072, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.195771 0.12923 0.708328 0.571042 0.50681 0.316493 0.747575 0.834447 0.453963 0.516064 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 122
Initial state: 0 0.667733 0.29419 0.406699 0.172336 0.42225 0.432921 0.877752 0.567021 0.500029 0.565902 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30989 episodes
GETTING ACTION FROM:
action 5, numVisits=30938, meanQ=19.037711, numObservations: 9
action -1, numVisits=21, meanQ=-1.010000, numObservations: 21
action 0, numVisits=21, meanQ=-1.010000, numObservations: 21
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=6, meanQ=-19.333333, numObservations: 5
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.667733 0.29419 0.406699 0.172336 0.42225 0.432921 0.877752 0.567021 0.500029 0.565902 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 123
Initial state: 0 0.924624 0.314754 0.322762 0.982402 0.411777 0.577933 0.983085 0.543178 0.349973 0.966694 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30581 episodes
GETTING ACTION FROM:
action 3, numVisits=30557, meanQ=16.463397, numObservations: 9
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 5, numVisits=11, meanQ=-3.727273, numObservations: 6
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.924624 0.314754 0.322762 0.982402 0.411777 0.577933 0.983085 0.543178 0.349973 0.966694 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 124
Initial state: 0 0.530179 0.218117 0.107339 0.149235 0.309024 0.893871 0.392742 0.518547 0.111943 0.648964 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30929 episodes
GETTING ACTION FROM:
action 2, numVisits=30903, meanQ=17.900850, numObservations: 9
action -1, numVisits=11, meanQ=-1.010000, numObservations: 11
action 0, numVisits=11, meanQ=-1.010000, numObservations: 11
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.530179 0.218117 0.107339 0.149235 0.309024 0.893871 0.392742 0.518547 0.111943 0.648964 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=3258, meanQ=28.410602, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 10381 episodes
GETTING ACTION FROM:
action 3, numVisits=13639, meanQ=22.315154, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.530179 0.218117 0.107339 0.149235 0.309024 0.893871 0.392742 0.518547 0.111943 0.648964 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 125
Initial state: 0 0.150086 0.230751 0.306952 0.738198 0.242049 0.56598 0.32502 0.743697 0.427743 0.548654 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28578 episodes
GETTING ACTION FROM:
action 1, numVisits=28502, meanQ=21.957176, numObservations: 9
action 4, numVisits=63, meanQ=9.018106, numObservations: 9
action 5, numVisits=9, meanQ=7.998889, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.150086 0.230751 0.306952 0.738198 0.242049 0.56598 0.32502 0.743697 0.427743 0.548654 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=3012, meanQ=48.815426, numObservations: 208
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 0, numVisits=9, meanQ=-12.230000, numObservations: 8
action 2, numVisits=3, meanQ=-34.333333, numObservations: 2
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 3581 episodes
GETTING ACTION FROM:
action -1, numVisits=6593, meanQ=42.342316, numObservations: 243
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 0, numVisits=9, meanQ=-12.230000, numObservations: 8
action 2, numVisits=3, meanQ=-34.333333, numObservations: 2
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.150086 0.230751 0.306952 0.738198 0.242049 0.56598 0.32502 0.743697 0.427743 0.548654 w: 1
Observation: 0 1 0 1 0 1 0 3 0 2 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=65, meanQ=89.281488, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 21837 episodes
GETTING ACTION FROM:
action 5, numVisits=21902, meanQ=80.166755, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.150086 0.230751 0.306952 0.738198 0.242049 0.56598 0.32502 0.743697 0.427743 0.548654 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 84.0499
Run # 126
Initial state: 0 0.69623 0.383819 0.728636 0.371732 0.690038 0.46249 0.879766 0.784148 0.481852 0.555661 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17739 episodes
GETTING ACTION FROM:
action -1, numVisits=17715, meanQ=46.084158, numObservations: 243
action 0, numVisits=17, meanQ=-1.768224, numObservations: 15
action 3, numVisits=3, meanQ=-34.333333, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.69623 0.383819 0.728636 0.371732 0.690038 0.46249 0.879766 0.784148 0.481852 0.555661 w: 1
Observation: 0 3 0 3 0 3 0 3 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=179, meanQ=79.447155, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 36262 episodes
GETTING ACTION FROM:
action 5, numVisits=36441, meanQ=80.998805, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.69623 0.383819 0.728636 0.371732 0.690038 0.46249 0.879766 0.784148 0.481852 0.555661 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 127
Initial state: 0 0.542498 0.607962 0.310293 0.391586 0.508024 0.921148 0.420196 0.559347 0.0628527 0.289115 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17994 episodes
GETTING ACTION FROM:
action 0, numVisits=17967, meanQ=65.129845, numObservations: 243
action -1, numVisits=22, meanQ=-5.600000, numObservations: 21
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.542498 0.607962 0.310293 0.391586 0.508024 0.921148 0.420196 0.559347 0.0628527 0.289115 w: 1
Observation: 0 0 3 0 1 0 3 0 2 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=103, meanQ=83.951556, numObservations: 7
action 3, numVisits=3, meanQ=62.663333, numObservations: 3
action 1, numVisits=3, meanQ=32.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37892 episodes
GETTING ACTION FROM:
action 4, numVisits=37995, meanQ=92.711812, numObservations: 9
action 3, numVisits=3, meanQ=62.663333, numObservations: 3
action 1, numVisits=3, meanQ=32.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.542498 0.607962 0.310293 0.391586 0.508024 0.921148 0.420196 0.559347 0.0628527 0.289115 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 128
Initial state: 0 0.124095 0.14854 0.511487 0.522801 0.933608 0.295459 0.384519 0.373127 0.920176 0.133744 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29864 episodes
GETTING ACTION FROM:
action 1, numVisits=29853, meanQ=19.846748, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.124095 0.14854 0.511487 0.522801 0.933608 0.295459 0.384519 0.373127 0.920176 0.133744 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=2032, meanQ=61.511771, numObservations: 219
action -1, numVisits=16, meanQ=-1.010000, numObservations: 16
action 4, numVisits=10, meanQ=-2.802000, numObservations: 5
action 5, numVisits=5, meanQ=-2.802000, numObservations: 3
action 3, numVisits=8, meanQ=-5.753738, numObservations: 6
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 19678 episodes
GETTING ACTION FROM:
action 0, numVisits=21710, meanQ=43.837628, numObservations: 243
action -1, numVisits=16, meanQ=-1.010000, numObservations: 16
action 4, numVisits=10, meanQ=-2.802000, numObservations: 5
action 5, numVisits=5, meanQ=-2.802000, numObservations: 3
action 3, numVisits=8, meanQ=-5.753738, numObservations: 6
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 0
Next state: 0 0.124095 0.14854 0.511487 0.522801 0.933608 0.295459 0.384519 0.373127 0.920176 0.133744 w: 1
Observation: 0 0 1 0 3 0 1 0 1 0 1 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 4, numVisits=5, meanQ=-2.802000, numObservations: 3
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 19196 episodes
GETTING ACTION FROM:
action -1, numVisits=19179, meanQ=41.818616, numObservations: 243
action 0, numVisits=22, meanQ=-2.315900, numObservations: 17
action 4, numVisits=6, meanQ=-4.334983, numObservations: 3
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.124095 0.14854 0.511487 0.522801 0.933608 0.295459 0.384519 0.373127 0.920176 0.133744 w: 1
Observation: 0 1 0 2 0 3 0 2 0 3 0 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 4, numVisits=24, meanQ=4.172508, numObservations: 6
action -1, numVisits=15, meanQ=-8.007320, numObservations: 12
action 1, numVisits=2, meanQ=-10.010000, numObservations: 2
action 0, numVisits=6, meanQ=-21.473300, numObservations: 3
action 3, numVisits=4, meanQ=-28.252500, numObservations: 3
action 2, numVisits=2, meanQ=-55.505000, numObservations: 2
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 35436 episodes
GETTING ACTION FROM:
action 4, numVisits=35460, meanQ=6.099306, numObservations: 9
action -1, numVisits=15, meanQ=-8.007320, numObservations: 12
action 1, numVisits=2, meanQ=-10.010000, numObservations: 2
action 0, numVisits=6, meanQ=-21.473300, numObservations: 3
action 3, numVisits=4, meanQ=-28.252500, numObservations: 3
action 2, numVisits=2, meanQ=-55.505000, numObservations: 2
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.124095 0.14854 0.511487 0.522801 0.933608 0.295459 0.384519 0.373127 0.920176 0.133744 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -112.94
Run # 129
Initial state: 0 0.522186 0.576122 0.27587 0.872072 0.0187357 0.13079 0.447694 0.664114 0.638275 0.395051 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17869 episodes
GETTING ACTION FROM:
action 0, numVisits=17811, meanQ=65.710135, numObservations: 243
action -1, numVisits=49, meanQ=-3.333873, numObservations: 46
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=3, meanQ=-34.333333, numObservations: 2
action 5, numVisits=3, meanQ=-34.333333, numObservations: 2
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.522186 0.576122 0.27587 0.872072 0.0187357 0.13079 0.447694 0.664114 0.638275 0.395051 w: 1
Observation: 0 0 2 0 1 0 1 0 3 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=94, meanQ=86.372553, numObservations: 8
action 4, numVisits=5, meanQ=59.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37004 episodes
GETTING ACTION FROM:
action 1, numVisits=37098, meanQ=87.672165, numObservations: 9
action 4, numVisits=5, meanQ=59.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.522186 0.576122 0.27587 0.872072 0.0187357 0.13079 0.447694 0.664114 0.638275 0.395051 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 130
Initial state: 0 0.416087 0.407197 0.883677 0.877192 0.669227 0.786666 0.37876 0.576616 0.764752 0.348713 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17958 episodes
GETTING ACTION FROM:
action 0, numVisits=17799, meanQ=62.384442, numObservations: 243
action -1, numVisits=134, meanQ=-1.764690, numObservations: 101
action 2, numVisits=3, meanQ=-4.003333, numObservations: 2
action 3, numVisits=19, meanQ=-4.210516, numObservations: 7
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.416087 0.407197 0.883677 0.877192 0.669227 0.786666 0.37876 0.576616 0.764752 0.348713 w: 1
Observation: 0 0 3 0 3 0 3 0 2 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=89, meanQ=84.505172, numObservations: 9
action 2, numVisits=3, meanQ=62.663333, numObservations: 3
action 1, numVisits=2, meanQ=44.495000, numObservations: 2
action 3, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 37880 episodes
GETTING ACTION FROM:
action 4, numVisits=37969, meanQ=91.632807, numObservations: 9
action 2, numVisits=3, meanQ=62.663333, numObservations: 3
action 1, numVisits=2, meanQ=44.495000, numObservations: 2
action 3, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 4
Next state: 1 0.416087 0.407197 0.883677 0.877192 0.669227 0.786666 0.37876 0.576616 0.764752 0.348713 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 131
Initial state: 0 0.3528 0.83941 0.0284061 0.0840223 0.55721 0.573957 0.347267 0.567995 4.89985e-05 0.93222 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28685 episodes
GETTING ACTION FROM:
action 3, numVisits=28621, meanQ=21.183031, numObservations: 9
action 4, numVisits=58, meanQ=10.277428, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.3528 0.83941 0.0284061 0.0840223 0.55721 0.573957 0.347267 0.567995 4.89985e-05 0.93222 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 132
Initial state: 0 0.363425 0.528996 0.360424 0.261019 0.355201 0.919728 0.578597 0.0952838 0.32106 0.0259915 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17564 episodes
GETTING ACTION FROM:
action -1, numVisits=17533, meanQ=47.418574, numObservations: 243
action 0, numVisits=7, meanQ=-1.010000, numObservations: 7
action 3, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=18, meanQ=-4.883883, numObservations: 8
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.363425 0.528996 0.360424 0.261019 0.355201 0.919728 0.578597 0.0952838 0.32106 0.0259915 w: 1
Observation: 0 2 0 2 0 2 0 3 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=19, meanQ=-1.010000, numObservations: 19
action 2, numVisits=25, meanQ=-2.160796, numObservations: 7
action 5, numVisits=4, meanQ=-8.229975, numObservations: 3
action -1, numVisits=4, meanQ=-26.255000, numObservations: 3
action 3, numVisits=3, meanQ=-34.333333, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 34003 episodes
GETTING ACTION FROM:
action 2, numVisits=34007, meanQ=23.868284, numObservations: 9
action 0, numVisits=40, meanQ=-6.158495, numObservations: 36
action 5, numVisits=4, meanQ=-8.229975, numObservations: 3
action -1, numVisits=4, meanQ=-26.255000, numObservations: 3
action 3, numVisits=3, meanQ=-34.333333, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.363425 0.528996 0.360424 0.261019 0.355201 0.919728 0.578597 0.0952838 0.32106 0.0259915 w: 1
Observation: 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101.99
Run # 133
Initial state: 0 0.380247 0.565656 0.411852 0.099786 0.985063 0.0665219 0.293917 0.263723 0.949857 0.692119 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17734 episodes
GETTING ACTION FROM:
action 0, numVisits=17682, meanQ=62.677938, numObservations: 243
action -1, numVisits=45, meanQ=-3.298220, numObservations: 43
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=3, meanQ=-34.333333, numObservations: 2
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.380247 0.565656 0.411852 0.099786 0.985063 0.0665219 0.293917 0.263723 0.949857 0.692119 w: 1
Observation: 0 0 2 0 1 0 1 0 1 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=135, meanQ=58.888593, numObservations: 8
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 35851 episodes
GETTING ACTION FROM:
action 5, numVisits=35986, meanQ=59.452907, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.380247 0.565656 0.411852 0.099786 0.985063 0.0665219 0.293917 0.263723 0.949857 0.692119 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 134
Initial state: 0 0.555725 0.00197162 0.836527 0.0796657 0.260342 0.715326 0.388075 0.590669 0.799983 0.0343838 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17710 episodes
GETTING ACTION FROM:
action -1, numVisits=17675, meanQ=45.049172, numObservations: 243
action 2, numVisits=6, meanQ=-4.333333, numObservations: 4
action 3, numVisits=11, meanQ=-4.628173, numObservations: 6
action 0, numVisits=13, meanQ=-8.777692, numObservations: 12
action 5, numVisits=3, meanQ=-34.333333, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.555725 0.00197162 0.836527 0.0796657 0.260342 0.715326 0.388075 0.590669 0.799983 0.0343838 w: 1
Observation: 0 3 0 3 0 1 0 1 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=26, meanQ=33.695023, numObservations: 8
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 22536 episodes
GETTING ACTION FROM:
action 5, numVisits=22562, meanQ=53.090473, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.555725 0.00197162 0.836527 0.0796657 0.260342 0.715326 0.388075 0.590669 0.799983 0.0343838 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101.99
Run # 135
Initial state: 0 0.147395 0.0946885 0.991151 0.201142 0.294959 0.895962 0.85854 0.506594 0.419766 0.530084 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17831 episodes
GETTING ACTION FROM:
action 0, numVisits=17731, meanQ=64.547333, numObservations: 243
action -1, numVisits=74, meanQ=-1.746614, numObservations: 60
action 1, numVisits=22, meanQ=-4.363182, numObservations: 9
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.147395 0.0946885 0.991151 0.201142 0.294959 0.895962 0.85854 0.506594 0.419766 0.530084 w: 1
Observation: 0 0 1 0 1 0 3 0 2 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=44, meanQ=54.392057, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 32636 episodes
GETTING ACTION FROM:
action 4, numVisits=32680, meanQ=50.858295, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.147395 0.0946885 0.991151 0.201142 0.294959 0.895962 0.85854 0.506594 0.419766 0.530084 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 136
Initial state: 0 0.207875 0.217515 0.149703 0.761083 0.135734 0.867258 0.05579 0.765644 0.357762 0.571672 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29450 episodes
GETTING ACTION FROM:
action 5, numVisits=29427, meanQ=17.882991, numObservations: 9
action 1, numVisits=18, meanQ=12.894450, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.207875 0.217515 0.149703 0.761083 0.135734 0.867258 0.05579 0.765644 0.357762 0.571672 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 137
Initial state: 0 0.664879 0.132447 0.201993 0.0127007 0.69272 0.0606944 0.481036 0.894984 0.451246 0.489035 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28720 episodes
GETTING ACTION FROM:
action 3, numVisits=28635, meanQ=21.047626, numObservations: 9
action -1, numVisits=67, meanQ=-3.079543, numObservations: 56
action 5, numVisits=7, meanQ=-4.141429, numObservations: 5
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=8, meanQ=-13.632500, numObservations: 7
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.664879 0.132447 0.201993 0.0127007 0.69272 0.0606944 0.481036 0.894984 0.451246 0.489035 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 138
Initial state: 0 0.666682 0.417731 0.841729 0.744202 0.289487 0.219613 0.460041 0.498299 0.34982 0.307544 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17845 episodes
GETTING ACTION FROM:
action -1, numVisits=17788, meanQ=46.507833, numObservations: 243
action 0, numVisits=49, meanQ=-5.293669, numObservations: 43
action 1, numVisits=4, meanQ=-6.000000, numObservations: 4
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.666682 0.417731 0.841729 0.744202 0.289487 0.219613 0.460041 0.498299 0.34982 0.307544 w: 1
Observation: 0 3 0 3 0 1 0 2 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=56, meanQ=17.588752, numObservations: 7
action 1, numVisits=13, meanQ=6.692308, numObservations: 5
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 36826 episodes
GETTING ACTION FROM:
action 5, numVisits=36803, meanQ=46.532175, numObservations: 9
action 2, numVisits=75, meanQ=2.079601, numObservations: 8
action 1, numVisits=14, meanQ=-1.000000, numObservations: 5
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=3, meanQ=-34.333333, numObservations: 3
action: 5
Next state: 0 0.666682 0.417731 0.841729 0.744202 0.289487 0.219613 0.460041 0.498299 0.34982 0.307544 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=1428, meanQ=74.566573, numObservations: 9
action 2, numVisits=4, meanQ=49.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 33899 episodes
GETTING ACTION FROM:
action 4, numVisits=35327, meanQ=64.669203, numObservations: 9
action 2, numVisits=4, meanQ=49.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.666682 0.417731 0.841729 0.744202 0.289487 0.219613 0.460041 0.498299 0.34982 0.307544 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 84.1399
Run # 139
Initial state: 0 0.878763 0.25035 0.835109 0.869938 0.293977 0.497815 0.338689 0.294138 0.473531 0.536366 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17895 episodes
GETTING ACTION FROM:
action 0, numVisits=17869, meanQ=63.387512, numObservations: 243
action -1, numVisits=15, meanQ=-1.010000, numObservations: 15
action 3, numVisits=7, meanQ=-5.285714, numObservations: 6
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.878763 0.25035 0.835109 0.869938 0.293977 0.497815 0.338689 0.294138 0.473531 0.536366 w: 1
Observation: 0 0 1 0 3 0 2 0 1 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=113, meanQ=83.106550, numObservations: 9
action 5, numVisits=3, meanQ=62.663333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37513 episodes
GETTING ACTION FROM:
action 3, numVisits=37626, meanQ=91.781348, numObservations: 9
action 5, numVisits=3, meanQ=62.663333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.878763 0.25035 0.835109 0.869938 0.293977 0.497815 0.338689 0.294138 0.473531 0.536366 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101.99
Run # 140
Initial state: 0 0.387357 0.619318 0.847394 0.30186 0.439263 0.500092 0.646465 0.169476 0.0928962 0.0968903 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29294 episodes
GETTING ACTION FROM:
action 3, numVisits=29283, meanQ=21.463614, numObservations: 9
action 1, numVisits=6, meanQ=10.996667, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.387357 0.619318 0.847394 0.30186 0.439263 0.500092 0.646465 0.169476 0.0928962 0.0968903 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 141
Initial state: 0 0.703594 0.985848 0.341708 0.778486 0.963424 0.180607 0.504181 0.491083 0.556843 0.371537 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29730 episodes
GETTING ACTION FROM:
action 2, numVisits=29722, meanQ=18.382434, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 2
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.703594 0.985848 0.341708 0.778486 0.963424 0.180607 0.504181 0.491083 0.556843 0.371537 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=2047, meanQ=41.442662, numObservations: 9
action 3, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=5, meanQ=-2.802000, numObservations: 3
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 21234 episodes
GETTING ACTION FROM:
action 2, numVisits=23281, meanQ=57.571762, numObservations: 9
action 3, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=5, meanQ=-2.802000, numObservations: 3
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.703594 0.985848 0.341708 0.778486 0.963424 0.180607 0.504181 0.491083 0.556843 0.371537 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 142
Initial state: 0 0.416162 0.8095 0.814827 0.341602 0.709274 0.994781 0.196123 0.996804 0.5252 0.55869 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17535 episodes
GETTING ACTION FROM:
action -1, numVisits=17520, meanQ=45.998266, numObservations: 243
action 0, numVisits=10, meanQ=-1.010000, numObservations: 10
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.416162 0.8095 0.814827 0.341602 0.709274 0.994781 0.196123 0.996804 0.5252 0.55869 w: 1
Observation: 0 2 0 3 0 3 0 1 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=51, meanQ=6.229618, numObservations: 42
action 1, numVisits=3, meanQ=-4.003333, numObservations: 3
action 2, numVisits=31, meanQ=-4.225806, numObservations: 6
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action -1, numVisits=7, meanQ=-15.719986, numObservations: 5
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 17745 episodes
GETTING ACTION FROM:
action 0, numVisits=17796, meanQ=76.047899, numObservations: 242
action 1, numVisits=3, meanQ=-4.003333, numObservations: 3
action 2, numVisits=31, meanQ=-4.225806, numObservations: 6
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action -1, numVisits=7, meanQ=-15.719986, numObservations: 5
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.416162 0.8095 0.814827 0.341602 0.709274 0.994781 0.196123 0.996804 0.5252 0.55869 w: 1
Observation: 0 0 3 0 1 0 3 0 3 0 2 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=185, meanQ=91.378757, numObservations: 9
action 4, numVisits=4, meanQ=71.747500, numObservations: 4
action 1, numVisits=5, meanQ=59.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 38045 episodes
GETTING ACTION FROM:
action 5, numVisits=38230, meanQ=95.983884, numObservations: 9
action 4, numVisits=4, meanQ=71.747500, numObservations: 4
action 1, numVisits=5, meanQ=59.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.416162 0.8095 0.814827 0.341602 0.709274 0.994781 0.196123 0.996804 0.5252 0.55869 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 93.0499
Run # 143
Initial state: 0 0.424626 0.542993 0.427405 0.0696446 0.118059 0.830715 0.587211 0.727639 0.0835592 0.911524 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17884 episodes
GETTING ACTION FROM:
action 0, numVisits=17751, meanQ=62.428685, numObservations: 243
action -1, numVisits=121, meanQ=-1.093045, numObservations: 93
action 2, numVisits=8, meanQ=-3.500000, numObservations: 6
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.424626 0.542993 0.427405 0.0696446 0.118059 0.830715 0.587211 0.727639 0.0835592 0.911524 w: 1
Observation: 0 0 2 0 1 0 3 0 3 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=107, meanQ=6.047497, numObservations: 70
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 0, numVisits=4, meanQ=-26.255000, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 17801 episodes
GETTING ACTION FROM:
action -1, numVisits=17908, meanQ=79.888611, numObservations: 243
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 0, numVisits=4, meanQ=-26.255000, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.424626 0.542993 0.427405 0.0696446 0.118059 0.830715 0.587211 0.727639 0.0835592 0.911524 w: 1
Observation: 0 1 0 2 0 1 0 3 0 1 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=8, meanQ=71.747500, numObservations: 5
action 4, numVisits=6, meanQ=47.498333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 34023 episodes
GETTING ACTION FROM:
action 1, numVisits=34031, meanQ=80.433451, numObservations: 9
action 4, numVisits=6, meanQ=47.498333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 1
Next state: 1 0.424626 0.542993 0.427405 0.0696446 0.118059 0.830715 0.587211 0.727639 0.0835592 0.911524 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 93.0499
Run # 144
Initial state: 0 0.0905976 0.981741 0.407706 0.688026 0.486004 0.578631 0.48898 0.677479 0.990473 0.58282 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17808 episodes
GETTING ACTION FROM:
action 0, numVisits=17776, meanQ=63.616571, numObservations: 243
action -1, numVisits=15, meanQ=-1.736660, numObservations: 14
action 3, numVisits=8, meanQ=-3.500000, numObservations: 6
action 1, numVisits=6, meanQ=-4.333333, numObservations: 4
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.0905976 0.981741 0.407706 0.688026 0.486004 0.578631 0.48898 0.677479 0.990473 0.58282 w: 1
Observation: 0 0 3 0 3 0 2 0 3 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=28, meanQ=50.534286, numObservations: 8
action 3, numVisits=6, meanQ=47.498333, numObservations: 5
action 4, numVisits=2, meanQ=44.495000, numObservations: 1
action 1, numVisits=4, meanQ=41.770025, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 34426 episodes
GETTING ACTION FROM:
action 5, numVisits=34443, meanQ=53.721622, numObservations: 9
action 1, numVisits=12, meanQ=27.513350, numObservations: 5
action 3, numVisits=7, meanQ=26.284286, numObservations: 6
action 4, numVisits=4, meanQ=21.747500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.0905976 0.981741 0.407706 0.688026 0.486004 0.578631 0.48898 0.677479 0.990473 0.58282 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101.99
Run # 145
Initial state: 0 0.457813 0.530292 0.0618199 0.501946 0.534284 0.92242 0.624289 0.684209 0.607409 0.554553 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29693 episodes
GETTING ACTION FROM:
action 2, numVisits=29637, meanQ=19.563218, numObservations: 9
action 1, numVisits=48, meanQ=0.354171, numObservations: 8
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.457813 0.530292 0.0618199 0.501946 0.534284 0.92242 0.624289 0.684209 0.607409 0.554553 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=487, meanQ=26.780185, numObservations: 9
action 5, numVisits=316, meanQ=21.496024, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 10711 episodes
GETTING ACTION FROM:
action 5, numVisits=10558, meanQ=21.453839, numObservations: 9
action 1, numVisits=956, meanQ=20.746154, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.457813 0.530292 0.0618199 0.501946 0.534284 0.92242 0.624289 0.684209 0.607409 0.554553 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -110.99
Run # 146
Initial state: 0 0.53672 0.594887 0.350004 0.547108 0.609694 0.606942 0.802914 0.970086 0.0486792 0.357033 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30665 episodes
GETTING ACTION FROM:
action 3, numVisits=30659, meanQ=19.546972, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.53672 0.594887 0.350004 0.547108 0.609694 0.606942 0.802914 0.970086 0.0486792 0.357033 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 147
Initial state: 0 0.463327 0.0405655 0.0710922 0.719295 0.49373 0.53958 0.720915 0.34632 0.951457 0.50925 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17523 episodes
GETTING ACTION FROM:
action -1, numVisits=17485, meanQ=44.806638, numObservations: 243
action 0, numVisits=14, meanQ=-1.010000, numObservations: 14
action 5, numVisits=12, meanQ=-2.666667, numObservations: 7
action 1, numVisits=6, meanQ=-4.333333, numObservations: 5
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=4, meanQ=-28.500000, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.463327 0.0405655 0.0710922 0.719295 0.49373 0.53958 0.720915 0.34632 0.951457 0.50925 w: 1
Observation: 0 2 0 1 0 2 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=31, meanQ=35.741297, numObservations: 6
action 1, numVisits=46, meanQ=29.934348, numObservations: 9
action 2, numVisits=3, meanQ=25.663367, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 36581 episodes
GETTING ACTION FROM:
action 3, numVisits=36612, meanQ=61.960130, numObservations: 9
action 1, numVisits=46, meanQ=29.934348, numObservations: 9
action 2, numVisits=3, meanQ=25.663367, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.463327 0.0405655 0.0710922 0.719295 0.49373 0.53958 0.720915 0.34632 0.951457 0.50925 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 148
Initial state: 0 0.682672 0.0778639 0.434641 0.565361 0.334516 0.291704 0.275704 0.761116 0.462054 0.239168 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31097 episodes
GETTING ACTION FROM:
action 4, numVisits=31065, meanQ=19.882456, numObservations: 9
action 3, numVisits=6, meanQ=9.166667, numObservations: 4
action 2, numVisits=8, meanQ=6.635013, numObservations: 7
action 5, numVisits=15, meanQ=3.733333, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.682672 0.0778639 0.434641 0.565361 0.334516 0.291704 0.275704 0.761116 0.462054 0.239168 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 149
Initial state: 0 0.457552 0.589182 0.112303 0.375527 0.335515 0.880804 0.622341 0.812852 0.272965 0.198465 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17644 episodes
GETTING ACTION FROM:
action -1, numVisits=17629, meanQ=47.193830, numObservations: 243
action 0, numVisits=10, meanQ=-1.010000, numObservations: 10
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.457552 0.589182 0.112303 0.375527 0.335515 0.880804 0.622341 0.812852 0.272965 0.198465 w: 1
Observation: 0 1 0 1 0 3 0 3 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=28, meanQ=46.048239, numObservations: 7
action 2, numVisits=3, meanQ=25.663367, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 21585 episodes
GETTING ACTION FROM:
action 5, numVisits=21612, meanQ=36.612214, numObservations: 9
action 2, numVisits=4, meanQ=16.745025, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.457552 0.589182 0.112303 0.375527 0.335515 0.880804 0.622341 0.812852 0.272965 0.198465 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=5257, meanQ=54.657561, numObservations: 9
action -1, numVisits=13, meanQ=-8.930762, numObservations: 11
action 1, numVisits=2, meanQ=-10.010000, numObservations: 2
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=12, meanQ=-10.084167, numObservations: 4
action 0, numVisits=20, meanQ=-11.207495, numObservations: 17
action 4, numVisits=3, meanQ=-34.333333, numObservations: 2
Sampled 5907 episodes
GETTING ACTION FROM:
action 2, numVisits=11164, meanQ=51.198946, numObservations: 9
action -1, numVisits=13, meanQ=-8.930762, numObservations: 11
action 1, numVisits=2, meanQ=-10.010000, numObservations: 2
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=12, meanQ=-10.084167, numObservations: 4
action 0, numVisits=20, meanQ=-11.207495, numObservations: 17
action 4, numVisits=3, meanQ=-34.333333, numObservations: 2
action: 2
Next state: 0 0.457552 0.589182 0.112303 0.375527 0.335515 0.880804 0.622341 0.812852 0.272965 0.198465 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action -1, numVisits=2045, meanQ=68.072188, numObservations: 126
action 3, numVisits=42, meanQ=-1.429048, numObservations: 7
action 0, numVisits=4, meanQ=-3.734975, numObservations: 3
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 5108 episodes
GETTING ACTION FROM:
action -1, numVisits=7153, meanQ=63.215877, numObservations: 173
action 3, numVisits=42, meanQ=-1.429048, numObservations: 7
action 0, numVisits=4, meanQ=-3.734975, numObservations: 3
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.457552 0.589182 0.112303 0.375527 0.335515 0.880804 0.622341 0.812852 0.272965 0.198465 w: 1
Observation: 0 2 0 2 0 1 0 3 0 1 0 
Immediate reward: -2
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 1, numVisits=1, meanQ=99.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-14.319405, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-546.997239, numObservations: 1
action 2, numVisits=1, meanQ=-547.029906, numObservations: 1
Sampled 24751 episodes
GETTING ACTION FROM:
action 1, numVisits=24752, meanQ=84.442844, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-14.319405, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-546.997239, numObservations: 1
action 2, numVisits=1, meanQ=-547.029906, numObservations: 1
action: 1
Next state: 1 0.457552 0.589182 0.112303 0.375527 0.335515 0.880804 0.622341 0.812852 0.272965 0.198465 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 69.4873
Run # 150
Initial state: 0 0.218308 0.987615 0.631032 0.997788 0.812314 0.032095 0.977228 0.164678 0.473568 0.501383 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30509 episodes
GETTING ACTION FROM:
action 3, numVisits=30503, meanQ=18.062653, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.218308 0.987615 0.631032 0.997788 0.812314 0.032095 0.977228 0.164678 0.473568 0.501383 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 151
Initial state: 0 0.741078 0.75554 0.42657 0.50913 0.32584 0.616758 0.638828 0.50527 0.618089 0.106842 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30362 episodes
GETTING ACTION FROM:
action 4, numVisits=30356, meanQ=19.106743, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.741078 0.75554 0.42657 0.50913 0.32584 0.616758 0.638828 0.50527 0.618089 0.106842 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 152
Initial state: 0 0.83494 0.398462 0.990092 0.626072 0.580308 0.21111 0.0868199 0.832337 0.478053 0.508652 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30967 episodes
GETTING ACTION FROM:
action 1, numVisits=30821, meanQ=18.752833, numObservations: 9
action 5, numVisits=138, meanQ=1.668199, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.83494 0.398462 0.990092 0.626072 0.580308 0.21111 0.0868199 0.832337 0.478053 0.508652 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 153
Initial state: 0 0.686381 0.0464412 0.402785 0.577453 0.947252 0.158255 0.113487 0.0637431 0.143867 0.511634 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29266 episodes
GETTING ACTION FROM:
action 2, numVisits=29239, meanQ=19.597635, numObservations: 9
action 1, numVisits=19, meanQ=16.951063, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=4, meanQ=-5.752500, numObservations: 4
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.686381 0.0464412 0.402785 0.577453 0.947252 0.158255 0.113487 0.0637431 0.143867 0.511634 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 154
Initial state: 0 0.448124 0.51517 0.651362 0.585907 0.428221 0.693234 0.911031 0.501796 0.382142 0.29289 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29401 episodes
GETTING ACTION FROM:
action 5, numVisits=29384, meanQ=20.153176, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=12, meanQ=-4.251658, numObservations: 6
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.448124 0.51517 0.651362 0.585907 0.428221 0.693234 0.911031 0.501796 0.382142 0.29289 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 155
Initial state: 0 0.680639 0.682324 0.724057 0.569032 0.466252 0.526268 0.449588 0.643975 0.761889 0.437807 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30797 episodes
GETTING ACTION FROM:
action 2, numVisits=30756, meanQ=18.631738, numObservations: 9
action 4, numVisits=18, meanQ=2.498889, numObservations: 7
action 1, numVisits=16, meanQ=2.061887, numObservations: 8
action 3, numVisits=4, meanQ=-1.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.680639 0.682324 0.724057 0.569032 0.466252 0.526268 0.449588 0.643975 0.761889 0.437807 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 156
Initial state: 0 0.291175 0.797197 0.23593 0.0777337 0.955095 0.911613 0.466079 0.273271 0.368416 0.531541 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30681 episodes
GETTING ACTION FROM:
action 3, numVisits=30674, meanQ=19.135863, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.291175 0.797197 0.23593 0.0777337 0.955095 0.911613 0.466079 0.273271 0.368416 0.531541 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 157
Initial state: 0 0.453583 0.578411 0.502376 0.812483 0.961435 0.325329 0.201829 0.849068 0.590113 0.36427 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17420 episodes
GETTING ACTION FROM:
action -1, numVisits=17391, meanQ=45.394403, numObservations: 243
action 1, numVisits=5, meanQ=-3.000000, numObservations: 4
action 5, numVisits=10, meanQ=-3.000000, numObservations: 5
action 0, numVisits=11, meanQ=-10.190000, numObservations: 10
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.453583 0.578411 0.502376 0.812483 0.961435 0.325329 0.201829 0.849068 0.590113 0.36427 w: 1
Observation: 0 2 0 2 0 3 0 1 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=80, meanQ=33.737003, numObservations: 9
action 1, numVisits=4, meanQ=-1.000000, numObservations: 4
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action -1, numVisits=2, meanQ=-51.500000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 36631 episodes
GETTING ACTION FROM:
action 2, numVisits=36711, meanQ=47.127545, numObservations: 9
action 1, numVisits=4, meanQ=-1.000000, numObservations: 4
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action -1, numVisits=2, meanQ=-51.500000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.453583 0.578411 0.502376 0.812483 0.961435 0.325329 0.201829 0.849068 0.590113 0.36427 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 158
Initial state: 0 0.699169 0.175914 0.461235 0.624117 0.835353 0.680309 0.390875 0.188757 0.518205 0.593294 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17477 episodes
GETTING ACTION FROM:
action -1, numVisits=17451, meanQ=45.509713, numObservations: 243
action 2, numVisits=7, meanQ=-5.285714, numObservations: 7
action 0, numVisits=15, meanQ=-8.006000, numObservations: 12
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.699169 0.175914 0.461235 0.624117 0.835353 0.680309 0.390875 0.188757 0.518205 0.593294 w: 1
Observation: 0 3 0 1 0 1 0 1 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=59, meanQ=89.763051, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 36905 episodes
GETTING ACTION FROM:
action 5, numVisits=36964, meanQ=80.267660, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.699169 0.175914 0.461235 0.624117 0.835353 0.680309 0.390875 0.188757 0.518205 0.593294 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 159
Initial state: 0 0.722626 0.823571 0.687739 0.538657 0.552444 0.610141 0.525532 0.505932 0.813364 0.399607 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30630 episodes
GETTING ACTION FROM:
action 5, numVisits=30623, meanQ=17.439454, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.722626 0.823571 0.687739 0.538657 0.552444 0.610141 0.525532 0.505932 0.813364 0.399607 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 160
Initial state: 0 0.0582975 0.607272 0.288621 0.285707 0.164602 0.528866 0.448239 0.540492 0.212692 0.86105 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17479 episodes
GETTING ACTION FROM:
action -1, numVisits=17462, meanQ=44.798141, numObservations: 243
action 0, numVisits=12, meanQ=-1.010000, numObservations: 12
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.0582975 0.607272 0.288621 0.285707 0.164602 0.528866 0.448239 0.540492 0.212692 0.86105 w: 1
Observation: 0 2 0 1 0 1 0 1 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=32, meanQ=34.691256, numObservations: 18
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 5, numVisits=4, meanQ=-5.505000, numObservations: 4
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=3, meanQ=-34.333333, numObservations: 3
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 17413 episodes
GETTING ACTION FROM:
action -1, numVisits=17445, meanQ=68.477021, numObservations: 231
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 5, numVisits=4, meanQ=-5.505000, numObservations: 4
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=3, meanQ=-34.333333, numObservations: 3
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.0582975 0.607272 0.288621 0.285707 0.164602 0.528866 0.448239 0.540492 0.212692 0.86105 w: 1
Observation: 0 2 0 1 0 2 0 2 0 3 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=5, meanQ=37.198000, numObservations: 3
action 1, numVisits=7, meanQ=36.012871, numObservations: 3
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 38320 episodes
GETTING ACTION FROM:
action 1, numVisits=38326, meanQ=61.321746, numObservations: 9
action 5, numVisits=6, meanQ=29.165000, numObservations: 4
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.0582975 0.607272 0.288621 0.285707 0.164602 0.528866 0.448239 0.540492 0.212692 0.86105 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 5, numVisits=55, meanQ=57.567458, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 29008 episodes
GETTING ACTION FROM:
action 0, numVisits=28172, meanQ=1.558622, numObservations: 240
action 5, numVisits=766, meanQ=-1.770975, numObservations: 9
action -1, numVisits=127, meanQ=-2.756142, numObservations: 48
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.0582975 0.607272 0.288621 0.285707 0.164602 0.528866 0.448239 0.540492 0.212692 0.86105 w: 1
Observation: 0 0 2 0 1 0 2 0 2 0 3 
Immediate reward: -2
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 42530 episodes
GETTING ACTION FROM:
action 5, numVisits=42498, meanQ=71.674726, numObservations: 9
action 4, numVisits=16, meanQ=67.125000, numObservations: 6
action 1, numVisits=6, meanQ=65.666667, numObservations: 3
action 3, numVisits=5, meanQ=59.000000, numObservations: 3
action 2, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-2.000000, numObservations: 1
action 0, numVisits=1, meanQ=-2.000000, numObservations: 1
action: 5
Next state: 0 0.0582975 0.607272 0.288621 0.285707 0.164602 0.528866 0.448239 0.540492 0.212692 0.86105 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: -11
Updated belief

t = 5
Improving policy...
PLANNING FROM:
action 3, numVisits=5, meanQ=77.198000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 48005 episodes
GETTING ACTION FROM:
action 3, numVisits=48010, meanQ=66.396794, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 3
Next state: 2 0.0582975 0.607272 0.288621 0.285707 0.164602 0.528866 0.448239 0.540492 0.212692 0.86105 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -123.318
Run # 161
Initial state: 0 0.824701 0.858553 0.146932 0.464643 0.561402 0.896256 0.414094 0.544143 0.704133 0.0595512 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17638 episodes
GETTING ACTION FROM:
action 0, numVisits=17613, meanQ=64.289491, numObservations: 243
action -1, numVisits=16, meanQ=-7.321250, numObservations: 15
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=3, meanQ=-34.333333, numObservations: 3
action 3, numVisits=3, meanQ=-34.333333, numObservations: 2
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.824701 0.858553 0.146932 0.464643 0.561402 0.896256 0.414094 0.544143 0.704133 0.0595512 w: 1
Observation: 0 0 2 0 1 0 3 0 2 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=50, meanQ=44.286210, numObservations: 8
action 3, numVisits=5, meanQ=37.198000, numObservations: 4
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 33690 episodes
GETTING ACTION FROM:
action 4, numVisits=33740, meanQ=56.649104, numObservations: 9
action 3, numVisits=5, meanQ=37.198000, numObservations: 4
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 4
Next state: 1 0.824701 0.858553 0.146932 0.464643 0.561402 0.896256 0.414094 0.544143 0.704133 0.0595512 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 162
Initial state: 0 0.915505 0.936392 0.53407 0.416845 0.438693 0.572778 0.901761 0.878512 0.379412 0.271413 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17789 episodes
GETTING ACTION FROM:
action -1, numVisits=17751, meanQ=47.236015, numObservations: 243
action 0, numVisits=27, meanQ=-1.083700, numObservations: 26
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=5, meanQ=-21.000000, numObservations: 4
action 2, numVisits=3, meanQ=-34.333333, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.915505 0.936392 0.53407 0.416845 0.438693 0.572778 0.901761 0.878512 0.379412 0.271413 w: 1
Observation: 0 3 0 3 0 2 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=164, meanQ=83.348051, numObservations: 9
action 2, numVisits=3, meanQ=32.333333, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 36069 episodes
GETTING ACTION FROM:
action 3, numVisits=36233, meanQ=81.087955, numObservations: 9
action 2, numVisits=3, meanQ=32.333333, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.915505 0.936392 0.53407 0.416845 0.438693 0.572778 0.901761 0.878512 0.379412 0.271413 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action -1, numVisits=2076, meanQ=78.623550, numObservations: 108
action 0, numVisits=8, meanQ=-1.010000, numObservations: 8
action 2, numVisits=3, meanQ=-4.003333, numObservations: 2
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=9, meanQ=-12.111111, numObservations: 4
action 5, numVisits=9, meanQ=-12.111111, numObservations: 4
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 28578 episodes
GETTING ACTION FROM:
action -1, numVisits=30654, meanQ=11.938253, numObservations: 175
action 0, numVisits=8, meanQ=-1.010000, numObservations: 8
action 2, numVisits=3, meanQ=-4.003333, numObservations: 2
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=9, meanQ=-12.111111, numObservations: 4
action 5, numVisits=9, meanQ=-12.111111, numObservations: 4
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.915505 0.936392 0.53407 0.416845 0.438693 0.572778 0.901761 0.878512 0.379412 0.271413 w: 1
Observation: 0 3 0 3 0 2 0 3 0 2 0 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=184, meanQ=76.250382, numObservations: 8
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 41609 episodes
GETTING ACTION FROM:
action 3, numVisits=41793, meanQ=95.086635, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.915505 0.936392 0.53407 0.416845 0.438693 0.572778 0.901761 0.878512 0.379412 0.271413 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 81.2094
Run # 163
Initial state: 0 0.92442 0.769459 0.441926 0.413747 0.369026 0.557109 0.9091 0.888805 0.91004 0.133454 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17645 episodes
GETTING ACTION FROM:
action -1, numVisits=17627, meanQ=46.380740, numObservations: 243
action 0, numVisits=11, meanQ=-1.010000, numObservations: 11
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=3, meanQ=-34.333333, numObservations: 2
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.92442 0.769459 0.441926 0.413747 0.369026 0.557109 0.9091 0.888805 0.91004 0.133454 w: 1
Observation: 0 3 0 3 0 2 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=169, meanQ=86.244441, numObservations: 9
action 1, numVisits=4, meanQ=49.000000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37500 episodes
GETTING ACTION FROM:
action 3, numVisits=37669, meanQ=88.428911, numObservations: 9
action 1, numVisits=4, meanQ=49.000000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.92442 0.769459 0.441926 0.413747 0.369026 0.557109 0.9091 0.888805 0.91004 0.133454 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 164
Initial state: 0 0.793836 0.223074 0.630328 0.31216 0.451458 0.593168 0.399116 0.750977 0.884559 0.575469 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30531 episodes
GETTING ACTION FROM:
action 1, numVisits=30489, meanQ=18.829855, numObservations: 9
action 3, numVisits=18, meanQ=7.888339, numObservations: 8
action 5, numVisits=14, meanQ=3.999293, numObservations: 7
action 2, numVisits=4, meanQ=-1.000000, numObservations: 4
action 4, numVisits=4, meanQ=-1.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 2 0.793836 0.223074 0.630328 0.31216 0.451458 0.593168 0.399116 0.750977 0.884559 0.575469 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 165
Initial state: 0 0.921778 0.123737 0.204573 0.431462 0.402408 0.590737 0.335639 0.960948 0.248975 0.351578 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17292 episodes
GETTING ACTION FROM:
action -1, numVisits=17282, meanQ=45.703780, numObservations: 243
action 3, numVisits=2, meanQ=-15.954950, numObservations: 1
action 0, numVisits=3, meanQ=-34.670000, numObservations: 2
action 5, numVisits=2, meanQ=-60.995000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.921778 0.123737 0.204573 0.431462 0.402408 0.590737 0.335639 0.960948 0.248975 0.351578 w: 1
Observation: 0 3 0 1 0 2 0 1 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=44, meanQ=67.502502, numObservations: 7
action 5, numVisits=2, meanQ=44.495000, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 36307 episodes
GETTING ACTION FROM:
action 3, numVisits=36351, meanQ=69.181502, numObservations: 9
action 5, numVisits=2, meanQ=44.495000, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 3
Next state: 1 0.921778 0.123737 0.204573 0.431462 0.402408 0.590737 0.335639 0.960948 0.248975 0.351578 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 166
Initial state: 0 0.222024 0.696688 0.425741 0.755562 0.588321 0.946455 0.365955 0.52088 0.958773 0.121878 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31013 episodes
GETTING ACTION FROM:
action 4, numVisits=31001, meanQ=16.724403, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=7, meanQ=-2.428571, numObservations: 5
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.222024 0.696688 0.425741 0.755562 0.588321 0.946455 0.365955 0.52088 0.958773 0.121878 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=435, meanQ=34.885656, numObservations: 146
action 1, numVisits=13, meanQ=-3.079231, numObservations: 8
action 2, numVisits=3, meanQ=-4.003333, numObservations: 2
action 4, numVisits=3, meanQ=-4.003333, numObservations: 3
action -1, numVisits=27, meanQ=-5.227400, numObservations: 24
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 25879 episodes
GETTING ACTION FROM:
action 0, numVisits=26314, meanQ=5.783608, numObservations: 243
action 1, numVisits=13, meanQ=-3.079231, numObservations: 8
action 2, numVisits=3, meanQ=-4.003333, numObservations: 2
action 4, numVisits=3, meanQ=-4.003333, numObservations: 3
action -1, numVisits=27, meanQ=-5.227400, numObservations: 24
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.222024 0.696688 0.425741 0.755562 0.588321 0.946455 0.365955 0.52088 0.958773 0.121878 w: 1
Observation: 0 0 3 0 3 0 3 0 2 0 1 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=35, meanQ=88.971143, numObservations: 5
action 2, numVisits=2, meanQ=44.495000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 42365 episodes
GETTING ACTION FROM:
action 4, numVisits=42400, meanQ=97.960035, numObservations: 9
action 2, numVisits=2, meanQ=44.495000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.222024 0.696688 0.425741 0.755562 0.588321 0.946455 0.365955 0.52088 0.958773 0.121878 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 84.0499
Run # 167
Initial state: 0 0.325183 0.255208 0.938667 0.0955224 0.028449 0.292764 0.738162 0.342528 0.433564 0.532793 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17456 episodes
GETTING ACTION FROM:
action -1, numVisits=17430, meanQ=48.109129, numObservations: 243
action 0, numVisits=14, meanQ=-1.010000, numObservations: 14
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=6, meanQ=-19.333333, numObservations: 2
action 3, numVisits=3, meanQ=-34.333333, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.325183 0.255208 0.938667 0.0955224 0.028449 0.292764 0.738162 0.342528 0.433564 0.532793 w: 1
Observation: 0 1 0 2 0 1 0 3 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=66, meanQ=33.880005, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 35803 episodes
GETTING ACTION FROM:
action 2, numVisits=35869, meanQ=34.582630, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.325183 0.255208 0.938667 0.0955224 0.028449 0.292764 0.738162 0.342528 0.433564 0.532793 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=479, meanQ=77.076753, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 32552 episodes
GETTING ACTION FROM:
action 5, numVisits=33031, meanQ=64.680812, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.325183 0.255208 0.938667 0.0955224 0.028449 0.292764 0.738162 0.342528 0.433564 0.532793 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 84.1399
Run # 168
Initial state: 0 0.232639 0.47506 0.232296 0.910608 0.877912 0.618444 0.464894 0.586247 0.743681 0.57597 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30845 episodes
GETTING ACTION FROM:
action 3, numVisits=30832, meanQ=18.089612, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=5, meanQ=-3.000000, numObservations: 5
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.232639 0.47506 0.232296 0.910608 0.877912 0.618444 0.464894 0.586247 0.743681 0.57597 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 169
Initial state: 0 0.505576 0.82553 0.946992 0.681675 0.92298 0.866489 0.728815 0.617395 0.383984 0.504373 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28271 episodes
GETTING ACTION FROM:
action 5, numVisits=28263, meanQ=21.141139, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.505576 0.82553 0.946992 0.681675 0.92298 0.866489 0.728815 0.617395 0.383984 0.504373 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 170
Initial state: 0 0.430309 0.513746 0.74591 0.0307173 0.0965156 0.899108 0.940989 0.998946 0.85233 0.721512 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29005 episodes
GETTING ACTION FROM:
action 1, numVisits=28998, meanQ=20.878281, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.430309 0.513746 0.74591 0.0307173 0.0965156 0.899108 0.940989 0.998946 0.85233 0.721512 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 171
Initial state: 0 0.525602 0.593501 0.84637 0.548138 0.201512 0.634456 0.114046 0.476238 0.592977 0.92711 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30418 episodes
GETTING ACTION FROM:
action 1, numVisits=30412, meanQ=19.658690, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.525602 0.593501 0.84637 0.548138 0.201512 0.634456 0.114046 0.476238 0.592977 0.92711 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 172
Initial state: 0 0.176081 0.113108 0.397656 0.554458 0.912109 0.973965 0.458484 0.0880143 0.103581 0.372156 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30647 episodes
GETTING ACTION FROM:
action 1, numVisits=30640, meanQ=18.969637, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.176081 0.113108 0.397656 0.554458 0.912109 0.973965 0.458484 0.0880143 0.103581 0.372156 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=3182, meanQ=26.872670, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 10198 episodes
GETTING ACTION FROM:
action 2, numVisits=13378, meanQ=13.545972, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 2
Next state: 1 0.176081 0.113108 0.397656 0.554458 0.912109 0.973965 0.458484 0.0880143 0.103581 0.372156 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 173
Initial state: 0 0.352822 0.535119 0.941765 0.368939 0.7749 0.216974 0.758556 0.694147 0.20255 0.129648 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28919 episodes
GETTING ACTION FROM:
action 4, numVisits=28905, meanQ=20.290728, numObservations: 9
action 2, numVisits=7, meanQ=9.012871, numObservations: 6
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.352822 0.535119 0.941765 0.368939 0.7749 0.216974 0.758556 0.694147 0.20255 0.129648 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 174
Initial state: 0 0.967145 0.894658 0.775806 0.241315 0.0387999 0.837356 0.781656 0.683842 0.422458 0.5226 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29289 episodes
GETTING ACTION FROM:
action 2, numVisits=29282, meanQ=19.251909, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.967145 0.894658 0.775806 0.241315 0.0387999 0.837356 0.781656 0.683842 0.422458 0.5226 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 175
Initial state: 0 0.892506 0.350803 0.429247 0.505099 0.410905 0.452604 0.00741943 0.126877 0.7929 0.268562 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17690 episodes
GETTING ACTION FROM:
action -1, numVisits=17674, meanQ=46.004360, numObservations: 243
action 0, numVisits=11, meanQ=-1.010000, numObservations: 11
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.892506 0.350803 0.429247 0.505099 0.410905 0.452604 0.00741943 0.126877 0.7929 0.268562 w: 1
Observation: 0 3 0 2 0 3 0 1 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=90, meanQ=79.022779, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37640 episodes
GETTING ACTION FROM:
action 2, numVisits=37730, meanQ=89.067921, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.892506 0.350803 0.429247 0.505099 0.410905 0.452604 0.00741943 0.126877 0.7929 0.268562 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 176
Initial state: 0 0.799217 0.911896 0.574372 0.583426 0.523925 0.714314 0.81607 0.36279 0.357729 0.541533 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30658 episodes
GETTING ACTION FROM:
action 3, numVisits=30616, meanQ=18.674013, numObservations: 9
action 2, numVisits=36, meanQ=15.002233, numObservations: 8
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.799217 0.911896 0.574372 0.583426 0.523925 0.714314 0.81607 0.36279 0.357729 0.541533 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 177
Initial state: 0 0.388803 0.527123 0.762811 0.812103 0.695035 0.485478 0.892743 0.803999 0.722103 0.512861 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28246 episodes
GETTING ACTION FROM:
action 2, numVisits=28238, meanQ=22.685441, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.388803 0.527123 0.762811 0.812103 0.695035 0.485478 0.892743 0.803999 0.722103 0.512861 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 178
Initial state: 0 0.339107 0.182533 0.365844 0.519152 0.327615 0.723374 0.487868 0.230184 0.798636 0.0391741 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30959 episodes
GETTING ACTION FROM:
action 4, numVisits=30953, meanQ=17.588315, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.339107 0.182533 0.365844 0.519152 0.327615 0.723374 0.487868 0.230184 0.798636 0.0391741 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 179
Initial state: 0 0.957305 0.327808 0.312924 0.64716 0.549041 0.681493 0.0396452 0.306501 0.374632 0.538788 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30828 episodes
GETTING ACTION FROM:
action 4, numVisits=30478, meanQ=18.411028, numObservations: 9
action 2, numVisits=307, meanQ=17.353046, numObservations: 9
action 5, numVisits=38, meanQ=14.447637, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.957305 0.327808 0.312924 0.64716 0.549041 0.681493 0.0396452 0.306501 0.374632 0.538788 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=3147, meanQ=21.912793, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 10150 episodes
GETTING ACTION FROM:
action 1, numVisits=13295, meanQ=15.003673, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.957305 0.327808 0.312924 0.64716 0.549041 0.681493 0.0396452 0.306501 0.374632 0.538788 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -110.99
Run # 180
Initial state: 0 0.453698 0.333454 0.473802 0.514045 0.138248 0.437057 0.970779 0.83781 0.218063 0.0853381 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17791 episodes
GETTING ACTION FROM:
action -1, numVisits=17778, meanQ=45.480954, numObservations: 243
action 0, numVisits=6, meanQ=-2.826650, numObservations: 5
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.453698 0.333454 0.473802 0.514045 0.138248 0.437057 0.970779 0.83781 0.218063 0.0853381 w: 1
Observation: 0 2 0 2 0 3 0 3 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=95, meanQ=41.516001, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 34401 episodes
GETTING ACTION FROM:
action 1, numVisits=34496, meanQ=28.477888, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.453698 0.333454 0.473802 0.514045 0.138248 0.437057 0.970779 0.83781 0.218063 0.0853381 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101.99
Run # 181
Initial state: 0 0.344852 0.0295092 0.747402 0.463099 0.701959 0.349121 0.451089 0.500091 0.44358 0.324638 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30796 episodes
GETTING ACTION FROM:
action 2, numVisits=30788, meanQ=17.427525, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.344852 0.0295092 0.747402 0.463099 0.701959 0.349121 0.451089 0.500091 0.44358 0.324638 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 182
Initial state: 0 0.759993 0.308357 0.509665 0.178657 0.548602 0.736681 0.561806 0.156137 0.479237 0.530718 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17533 episodes
GETTING ACTION FROM:
action -1, numVisits=17462, meanQ=47.073873, numObservations: 243
action 0, numVisits=63, meanQ=-3.226657, numObservations: 56
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=4, meanQ=-28.500000, numObservations: 2
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.759993 0.308357 0.509665 0.178657 0.548602 0.736681 0.561806 0.156137 0.479237 0.530718 w: 1
Observation: 0 3 0 2 0 3 0 3 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=99, meanQ=73.112426, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37238 episodes
GETTING ACTION FROM:
action 2, numVisits=37337, meanQ=86.015811, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.759993 0.308357 0.509665 0.178657 0.548602 0.736681 0.561806 0.156137 0.479237 0.530718 w: 1
Observation: 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101.99
Run # 183
Initial state: 0 0.5904 0.84106 0.97583 0.455341 0.302676 0.220295 0.444709 0.517008 0.411173 0.990253 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31019 episodes
GETTING ACTION FROM:
action 3, numVisits=30991, meanQ=17.917441, numObservations: 9
action 4, numVisits=23, meanQ=14.303478, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.5904 0.84106 0.97583 0.455341 0.302676 0.220295 0.444709 0.517008 0.411173 0.990253 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=3189, meanQ=24.964755, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=5, meanQ=-2.802000, numObservations: 4
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 11797 episodes
GETTING ACTION FROM:
action 5, numVisits=14986, meanQ=19.956365, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=5, meanQ=-2.802000, numObservations: 4
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.5904 0.84106 0.97583 0.455341 0.302676 0.220295 0.444709 0.517008 0.411173 0.990253 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 184
Initial state: 0 0.715511 0.0951055 0.902849 0.551608 0.993887 0.952699 0.507307 0.580453 0.556958 0.63248 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30614 episodes
GETTING ACTION FROM:
action 4, numVisits=30606, meanQ=17.782601, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.715511 0.0951055 0.902849 0.551608 0.993887 0.952699 0.507307 0.580453 0.556958 0.63248 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 185
Initial state: 0 0.568352 0.141894 0.71352 0.696157 0.493865 0.544123 0.847068 0.959457 0.625622 0.578275 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29719 episodes
GETTING ACTION FROM:
action 5, numVisits=28490, meanQ=19.355783, numObservations: 9
action 2, numVisits=1217, meanQ=16.288784, numObservations: 9
action 3, numVisits=8, meanQ=10.250000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.568352 0.141894 0.71352 0.696157 0.493865 0.544123 0.847068 0.959457 0.625622 0.578275 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 186
Initial state: 0 0.595206 0.820953 0.39632 0.517238 0.99332 0.833084 0.661278 0.206307 0.891963 0.101827 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28305 episodes
GETTING ACTION FROM:
action 2, numVisits=28296, meanQ=16.853298, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.595206 0.820953 0.39632 0.517238 0.99332 0.833084 0.661278 0.206307 0.891963 0.101827 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 187
Initial state: 0 0.413255 0.489685 0.119894 0.938409 0.17062 0.691367 0.14409 0.267498 0.159414 0.873912 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17812 episodes
GETTING ACTION FROM:
action 0, numVisits=17756, meanQ=63.043252, numObservations: 243
action 2, numVisits=9, meanQ=-4.334433, numObservations: 4
action 3, numVisits=11, meanQ=-4.633636, numObservations: 7
action -1, numVisits=30, meanQ=-4.739330, numObservations: 28
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=4, meanQ=-28.500000, numObservations: 4
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.413255 0.489685 0.119894 0.938409 0.17062 0.691367 0.14409 0.267498 0.159414 0.873912 w: 1
Observation: 0 0 2 0 3 0 3 0 1 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=78, meanQ=82.706155, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37917 episodes
GETTING ACTION FROM:
action 1, numVisits=37995, meanQ=91.532307, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.413255 0.489685 0.119894 0.938409 0.17062 0.691367 0.14409 0.267498 0.159414 0.873912 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 188
Initial state: 0 0.42522 0.5897 0.600148 0.597967 0.555731 0.504604 0.164721 0.982473 0.66158 0.544281 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17806 episodes
GETTING ACTION FROM:
action -1, numVisits=17677, meanQ=47.404403, numObservations: 243
action 0, numVisits=95, meanQ=-2.782204, numObservations: 78
action 5, numVisits=10, meanQ=-4.100000, numObservations: 8
action 3, numVisits=16, meanQ=-4.119369, numObservations: 6
action 4, numVisits=6, meanQ=-4.333333, numObservations: 4
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.42522 0.5897 0.600148 0.597967 0.555731 0.504604 0.164721 0.982473 0.66158 0.544281 w: 1
Observation: 0 2 0 3 0 2 0 1 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=69, meanQ=10.997839, numObservations: 51
action 2, numVisits=5, meanQ=-2.802000, numObservations: 3
action -1, numVisits=5, meanQ=-3.189980, numObservations: 4
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=3, meanQ=-34.333333, numObservations: 2
Sampled 17598 episodes
GETTING ACTION FROM:
action 0, numVisits=17667, meanQ=75.858510, numObservations: 242
action 2, numVisits=5, meanQ=-2.802000, numObservations: 3
action -1, numVisits=5, meanQ=-3.189980, numObservations: 4
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=3, meanQ=-34.333333, numObservations: 2
action: 0
Next state: 0 0.42522 0.5897 0.600148 0.597967 0.555731 0.504604 0.164721 0.982473 0.66158 0.544281 w: 1
Observation: 0 0 2 0 3 0 2 0 2 0 2 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 38700 episodes
GETTING ACTION FROM:
action 1, numVisits=38679, meanQ=56.216167, numObservations: 9
action 0, numVisits=9, meanQ=-1.231100, numObservations: 8
action -1, numVisits=2, meanQ=-6.459950, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=7, meanQ=-15.285714, numObservations: 3
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.42522 0.5897 0.600148 0.597967 0.555731 0.504604 0.164721 0.982473 0.66158 0.544281 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 93.0499
Run # 189
Initial state: 0 0.785228 0.400563 0.517816 0.958025 0.444901 0.566199 0.995346 0.215323 0.694202 0.352429 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30412 episodes
GETTING ACTION FROM:
action 4, numVisits=30401, meanQ=16.127109, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=6, meanQ=-4.333333, numObservations: 4
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.785228 0.400563 0.517816 0.958025 0.444901 0.566199 0.995346 0.215323 0.694202 0.352429 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 190
Initial state: 0 0.0753446 0.935285 0.891239 0.344644 0.400503 0.770085 0.304954 0.429678 0.502491 0.548314 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17563 episodes
GETTING ACTION FROM:
action -1, numVisits=17525, meanQ=45.257760, numObservations: 243
action 0, numVisits=25, meanQ=-1.010000, numObservations: 25
action 5, numVisits=5, meanQ=-5.398000, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=5, meanQ=-21.000000, numObservations: 3
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.0753446 0.935285 0.891239 0.344644 0.400503 0.770085 0.304954 0.429678 0.502491 0.548314 w: 1
Observation: 0 1 0 3 0 2 0 1 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=57, meanQ=14.514937, numObservations: 31
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 17039 episodes
GETTING ACTION FROM:
action -1, numVisits=17096, meanQ=42.045104, numObservations: 223
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.0753446 0.935285 0.891239 0.344644 0.400503 0.770085 0.304954 0.429678 0.502491 0.548314 w: 1
Observation: 0 1 0 3 0 2 0 1 0 2 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=3640, meanQ=38.495309, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 35096 episodes
GETTING ACTION FROM:
action 3, numVisits=38736, meanQ=39.361943, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.0753446 0.935285 0.891239 0.344644 0.400503 0.770085 0.304954 0.429678 0.502491 0.548314 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 93.0499
Run # 191
Initial state: 0 0.674505 0.843246 0.501873 0.544022 0.491814 0.014414 0.521292 0.0547722 0.439823 0.758145 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17680 episodes
GETTING ACTION FROM:
action 0, numVisits=17641, meanQ=63.658101, numObservations: 243
action -1, numVisits=25, meanQ=-5.049200, numObservations: 24
action 1, numVisits=6, meanQ=-19.333333, numObservations: 4
action 4, numVisits=5, meanQ=-21.000000, numObservations: 5
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.674505 0.843246 0.501873 0.544022 0.491814 0.014414 0.521292 0.0547722 0.439823 0.758145 w: 1
Observation: 0 0 2 0 2 0 1 0 1 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=55, meanQ=41.109640, numObservations: 8
action 1, numVisits=7, meanQ=23.710000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 32718 episodes
GETTING ACTION FROM:
action 5, numVisits=32773, meanQ=56.322045, numObservations: 9
action 1, numVisits=7, meanQ=23.710000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.674505 0.843246 0.501873 0.544022 0.491814 0.014414 0.521292 0.0547722 0.439823 0.758145 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101.99
Run # 192
Initial state: 0 0.204798 0.542995 0.444917 0.52573 0.197747 0.0458096 0.39529 0.871962 0.678843 0.795224 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17691 episodes
GETTING ACTION FROM:
action -1, numVisits=17579, meanQ=43.589094, numObservations: 243
action 0, numVisits=105, meanQ=-1.067891, numObservations: 88
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=3, meanQ=-34.333333, numObservations: 3
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.204798 0.542995 0.444917 0.52573 0.197747 0.0458096 0.39529 0.871962 0.678843 0.795224 w: 1
Observation: 0 2 0 2 0 1 0 2 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=44, meanQ=28.817730, numObservations: 8
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 33636 episodes
GETTING ACTION FROM:
action 4, numVisits=33680, meanQ=15.615399, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.204798 0.542995 0.444917 0.52573 0.197747 0.0458096 0.39529 0.871962 0.678843 0.795224 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 193
Initial state: 0 0.784482 0.48411 0.588646 0.127102 0.45027 0.553705 0.272106 0.396884 0.719556 0.917355 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17629 episodes
GETTING ACTION FROM:
action -1, numVisits=17615, meanQ=44.542502, numObservations: 243
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=9, meanQ=-12.230000, numObservations: 8
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.784482 0.48411 0.588646 0.127102 0.45027 0.553705 0.272106 0.396884 0.719556 0.917355 w: 1
Observation: 0 3 0 3 0 2 0 1 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=63, meanQ=80.508097, numObservations: 8
action 1, numVisits=2, meanQ=44.495000, numObservations: 2
action 5, numVisits=2, meanQ=44.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 36951 episodes
GETTING ACTION FROM:
action 3, numVisits=37014, meanQ=79.735501, numObservations: 9
action 1, numVisits=2, meanQ=44.495000, numObservations: 2
action 5, numVisits=2, meanQ=44.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.784482 0.48411 0.588646 0.127102 0.45027 0.553705 0.272106 0.396884 0.719556 0.917355 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 194
Initial state: 0 0.803686 0.01866 0.404296 0.523754 0.593356 0.885795 0.632187 0.375984 0.309681 0.463942 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30553 episodes
GETTING ACTION FROM:
action 2, numVisits=30547, meanQ=18.643848, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.803686 0.01866 0.404296 0.523754 0.593356 0.885795 0.632187 0.375984 0.309681 0.463942 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 195
Initial state: 0 0.323451 0.717538 0.0780395 0.845937 0.477868 0.519682 0.346727 0.762829 0.762567 0.419117 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30977 episodes
GETTING ACTION FROM:
action 2, numVisits=30235, meanQ=17.751915, numObservations: 9
action 1, numVisits=736, meanQ=15.787588, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.323451 0.717538 0.0780395 0.845937 0.477868 0.519682 0.346727 0.762829 0.762567 0.419117 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 196
Initial state: 0 0.0760781 0.102261 0.460955 0.492189 0.80976 0.587141 0.284923 0.758016 0.152162 0.474828 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29694 episodes
GETTING ACTION FROM:
action 1, numVisits=29683, meanQ=18.984912, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action 3, numVisits=4, meanQ=-6.000000, numObservations: 4
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.0760781 0.102261 0.460955 0.492189 0.80976 0.587141 0.284923 0.758016 0.152162 0.474828 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=3197, meanQ=24.917578, numObservations: 9
action 2, numVisits=33, meanQ=-0.117255, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=3, meanQ=-4.003333, numObservations: 3
action 4, numVisits=3, meanQ=-4.003333, numObservations: 3
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 9282 episodes
GETTING ACTION FROM:
action 5, numVisits=12479, meanQ=21.004212, numObservations: 9
action 2, numVisits=33, meanQ=-0.117255, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=3, meanQ=-4.003333, numObservations: 3
action 4, numVisits=3, meanQ=-4.003333, numObservations: 3
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 5
Next state: 2 0.0760781 0.102261 0.460955 0.492189 0.80976 0.587141 0.284923 0.758016 0.152162 0.474828 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -110.99
Run # 197
Initial state: 0 0.135022 0.877632 0.470332 0.643728 0.727572 0.174474 0.412307 0.902467 0.479643 0.556444 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28170 episodes
GETTING ACTION FROM:
action 4, numVisits=28135, meanQ=21.106663, numObservations: 9
action 5, numVisits=30, meanQ=6.600337, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.135022 0.877632 0.470332 0.643728 0.727572 0.174474 0.412307 0.902467 0.479643 0.556444 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 198
Initial state: 0 0.592856 0.576042 0.123333 0.731136 0.110752 0.117211 0.51225 0.411798 0.38684 0.503422 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29203 episodes
GETTING ACTION FROM:
action 3, numVisits=29193, meanQ=19.626513, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action 5, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.592856 0.576042 0.123333 0.731136 0.110752 0.117211 0.51225 0.411798 0.38684 0.503422 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=3005, meanQ=47.748292, numObservations: 228
action 0, numVisits=13, meanQ=-9.616146, numObservations: 11
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=3, meanQ=-34.333333, numObservations: 3
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 3755 episodes
GETTING ACTION FROM:
action -1, numVisits=6760, meanQ=41.456133, numObservations: 242
action 0, numVisits=13, meanQ=-9.616146, numObservations: 11
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=3, meanQ=-34.333333, numObservations: 3
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.592856 0.576042 0.123333 0.731136 0.110752 0.117211 0.51225 0.411798 0.38684 0.503422 w: 1
Observation: 0 3 0 1 0 2 0 2 0 2 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=1, meanQ=99.000000, numObservations: 1
action 5, numVisits=1, meanQ=99.000000, numObservations: 1
action 4, numVisits=2, meanQ=41.071619, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-17.308117, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 23101 episodes
GETTING ACTION FROM:
action 5, numVisits=23049, meanQ=47.455116, numObservations: 9
action 1, numVisits=53, meanQ=13.805379, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=3, meanQ=-6.285588, numObservations: 3
action 2, numVisits=1, meanQ=-17.308117, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.592856 0.576042 0.123333 0.731136 0.110752 0.117211 0.51225 0.411798 0.38684 0.503422 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 84.0499
Run # 199
Initial state: 0 0.38794 0.544191 0.541802 0.771939 0.778904 0.826292 0.412696 0.265564 0.457143 0.836615 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30646 episodes
GETTING ACTION FROM:
action 5, numVisits=30632, meanQ=18.583904, numObservations: 9
action 1, numVisits=6, meanQ=14.000000, numObservations: 2
action 2, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.38794 0.544191 0.541802 0.771939 0.778904 0.826292 0.412696 0.265564 0.457143 0.836615 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 200
Initial state: 0 0.708237 0.0220799 0.623238 0.340157 0.162219 0.72046 0.0108876 0.867668 0.464422 0.503243 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29792 episodes
GETTING ACTION FROM:
action 5, numVisits=29757, meanQ=20.601236, numObservations: 9
action -1, numVisits=14, meanQ=-1.010000, numObservations: 14
action 0, numVisits=14, meanQ=-1.010000, numObservations: 14
action 2, numVisits=4, meanQ=-6.000000, numObservations: 4
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.708237 0.0220799 0.623238 0.340157 0.162219 0.72046 0.0108876 0.867668 0.464422 0.503243 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
[32m ProblemEnvironment.hpp 351: Done.[39m
