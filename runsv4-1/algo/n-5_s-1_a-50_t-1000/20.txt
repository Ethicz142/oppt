Run # 1
Initial state: 0 0.406826 0.390589 0.732457 0.182175 0.634119 0.148824 0.993614 0.210936 0.30924 0.339234 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32415 episodes
GETTING ACTION FROM:
action 3, numVisits=32307, meanQ=31.782307, numObservations: 9
action 5, numVisits=95, meanQ=11.717267, numObservations: 9
action 1, numVisits=8, meanQ=10.250000, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.406826 0.390589 0.732457 0.182175 0.634119 0.148824 0.993614 0.210936 0.30924 0.339234 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 2
Initial state: 0 0.279083 0.378829 0.269813 0.700095 0.0313193 0.700547 0.173212 0.288972 0.634261 0.0649107 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34095 episodes
GETTING ACTION FROM:
action 2, numVisits=34071, meanQ=30.257194, numObservations: 9
action 5, numVisits=14, meanQ=5.428571, numObservations: 6
action 1, numVisits=6, meanQ=-1.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.279083 0.378829 0.269813 0.700095 0.0313193 0.700547 0.173212 0.288972 0.634261 0.0649107 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 3
Initial state: 0 0.744785 0.513717 0.255048 0.354043 0.912106 0.0980562 0.937384 0.962348 0.263933 0.5321 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34218 episodes
GETTING ACTION FROM:
action 4, numVisits=34190, meanQ=32.240948, numObservations: 9
action 2, numVisits=17, meanQ=20.764706, numObservations: 5
action 1, numVisits=7, meanQ=13.285714, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.744785 0.513717 0.255048 0.354043 0.912106 0.0980562 0.937384 0.962348 0.263933 0.5321 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 4
Initial state: 0 0.299873 0.480084 0.614322 0.0697455 0.575343 0.418877 0.126887 0.6543 0.834302 0.633742 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34506 episodes
GETTING ACTION FROM:
action 2, numVisits=34491, meanQ=31.381251, numObservations: 9
action 1, numVisits=9, meanQ=17.888889, numObservations: 6
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.299873 0.480084 0.614322 0.0697455 0.575343 0.418877 0.126887 0.6543 0.834302 0.633742 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 5
Initial state: 0 0.0386924 0.50369 0.323837 0.415949 0.466355 0.440899 0.926602 0.634269 0.120253 0.637882 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18682 episodes
GETTING ACTION FROM:
action 0, numVisits=18637, meanQ=63.853108, numObservations: 243
action 2, numVisits=3, meanQ=-4.333333, numObservations: 2
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action -1, numVisits=29, meanQ=-4.492069, numObservations: 28
action 1, numVisits=8, meanQ=-15.998750, numObservations: 6
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.0386924 0.50369 0.323837 0.415949 0.466355 0.440899 0.926602 0.634269 0.120253 0.637882 w: 1
Observation: 0 0 2 0 2 0 2 0 3 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=61, meanQ=56.163449, numObservations: 7
action 5, numVisits=2, meanQ=44.495000, numObservations: 2
action 4, numVisits=3, meanQ=32.333333, numObservations: 3
action 3, numVisits=5, meanQ=19.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 35767 episodes
GETTING ACTION FROM:
action 1, numVisits=35822, meanQ=49.017836, numObservations: 9
action 5, numVisits=8, meanQ=46.498762, numObservations: 4
action 4, numVisits=3, meanQ=32.333333, numObservations: 3
action 3, numVisits=5, meanQ=19.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.0386924 0.50369 0.323837 0.415949 0.466355 0.440899 0.926602 0.634269 0.120253 0.637882 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101.99
Run # 6
Initial state: 0 0.908721 0.15375 0.496779 0.0387863 0.380858 0.242955 0.484152 0.695566 0.277841 0.514708 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32986 episodes
GETTING ACTION FROM:
action 3, numVisits=32924, meanQ=32.022037, numObservations: 9
action 5, numVisits=55, meanQ=28.072545, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.908721 0.15375 0.496779 0.0387863 0.380858 0.242955 0.484152 0.695566 0.277841 0.514708 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 7
Initial state: 0 0.432635 0.946728 0.159795 0.101899 0.266465 0.455755 0.439495 0.492222 0.34393 0.814372 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33920 episodes
GETTING ACTION FROM:
action 4, numVisits=33905, meanQ=30.744051, numObservations: 9
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=6, meanQ=-17.840000, numObservations: 5
action -1, numVisits=5, meanQ=-21.206000, numObservations: 4
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.432635 0.946728 0.159795 0.101899 0.266465 0.455755 0.439495 0.492222 0.34393 0.814372 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 8
Initial state: 0 0.163664 0.805303 0.935341 0.0120903 0.720751 0.528127 0.306628 0.389526 0.938212 0.752614 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33800 episodes
GETTING ACTION FROM:
action 3, numVisits=33783, meanQ=30.967574, numObservations: 9
action 2, numVisits=12, meanQ=19.749183, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.163664 0.805303 0.935341 0.0120903 0.720751 0.528127 0.306628 0.389526 0.938212 0.752614 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 9
Initial state: 0 0.504058 0.686921 0.614828 0.806368 0.173766 0.0215955 0.295245 0.387054 0.179805 0.776392 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18562 episodes
GETTING ACTION FROM:
action 0, numVisits=18501, meanQ=65.600359, numObservations: 243
action -1, numVisits=40, meanQ=-1.554995, numObservations: 38
action 5, numVisits=10, meanQ=-3.000000, numObservations: 7
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=6, meanQ=-19.333333, numObservations: 4
action 4, numVisits=3, meanQ=-34.333333, numObservations: 3
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.504058 0.686921 0.614828 0.806368 0.173766 0.0215955 0.295245 0.387054 0.179805 0.776392 w: 1
Observation: 0 0 3 0 3 0 2 0 2 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=137, meanQ=61.942994, numObservations: 9
action 5, numVisits=2, meanQ=44.495000, numObservations: 2
action 2, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 37677 episodes
GETTING ACTION FROM:
action 3, numVisits=37814, meanQ=60.293438, numObservations: 9
action 5, numVisits=2, meanQ=44.495000, numObservations: 2
action 2, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 3
Next state: 0 0.504058 0.686921 0.614828 0.806368 0.173766 0.0215955 0.295245 0.387054 0.179805 0.776392 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=1082, meanQ=75.819662, numObservations: 9
action 2, numVisits=10, meanQ=48.099000, numObservations: 3
action 4, numVisits=2, meanQ=44.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 26462 episodes
GETTING ACTION FROM:
action 1, numVisits=27544, meanQ=74.317653, numObservations: 9
action 2, numVisits=10, meanQ=48.099000, numObservations: 3
action 4, numVisits=2, meanQ=44.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 1
Next state: 1 0.504058 0.686921 0.614828 0.806368 0.173766 0.0215955 0.295245 0.387054 0.179805 0.776392 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 84.1399
Run # 10
Initial state: 0 0.671702 0.775823 0.243392 0.615617 0.504104 0.910743 0.315934 0.378191 0.546188 0.319924 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34525 episodes
GETTING ACTION FROM:
action 5, numVisits=34390, meanQ=30.955710, numObservations: 9
action 2, numVisits=88, meanQ=16.034092, numObservations: 9
action 4, numVisits=22, meanQ=11.407727, numObservations: 8
action 3, numVisits=21, meanQ=11.093810, numObservations: 8
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 5
Next state: 2 0.671702 0.775823 0.243392 0.615617 0.504104 0.910743 0.315934 0.378191 0.546188 0.319924 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 11
Initial state: 0 0.486279 0.459858 0.433063 0.1054 0.432415 0.720459 0.227228 0.584481 0.295397 0.451646 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32704 episodes
GETTING ACTION FROM:
action 2, numVisits=32689, meanQ=30.687581, numObservations: 9
action 1, numVisits=6, meanQ=-1.000000, numObservations: 4
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.486279 0.459858 0.433063 0.1054 0.432415 0.720459 0.227228 0.584481 0.295397 0.451646 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 12
Initial state: 0 0.87471 0.581091 0.679895 0.00373468 0.633105 0.276648 0.329455 0.473163 0.996256 0.42138 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33842 episodes
GETTING ACTION FROM:
action 3, numVisits=33816, meanQ=31.369777, numObservations: 9
action 4, numVisits=16, meanQ=26.938125, numObservations: 7
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=4, meanQ=-6.249975, numObservations: 3
action: 3
Next state: 2 0.87471 0.581091 0.679895 0.00373468 0.633105 0.276648 0.329455 0.473163 0.996256 0.42138 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 13
Initial state: 0 0.645193 0.0704072 0.0845447 0.700251 0.96115 0.799336 0.325294 0.481082 0.373736 0.271648 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34266 episodes
GETTING ACTION FROM:
action 5, numVisits=34256, meanQ=30.752128, numObservations: 9
action 4, numVisits=3, meanQ=25.666667, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.645193 0.0704072 0.0845447 0.700251 0.96115 0.799336 0.325294 0.481082 0.373736 0.271648 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 14
Initial state: 0 0.485508 0.266358 0.319861 0.476903 0.0758901 0.71717 0.438088 0.469345 0.774043 0.367065 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34393 episodes
GETTING ACTION FROM:
action 1, numVisits=34365, meanQ=31.800731, numObservations: 9
action 4, numVisits=11, meanQ=8.090909, numObservations: 5
action 2, numVisits=10, meanQ=8.000000, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=4, meanQ=-6.000000, numObservations: 4
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.485508 0.266358 0.319861 0.476903 0.0758901 0.71717 0.438088 0.469345 0.774043 0.367065 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 15
Initial state: 0 0.841938 0.978409 0.952491 0.694317 0.675934 0.413062 0.746886 0.784966 0.346248 0.501888 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17470 episodes
GETTING ACTION FROM:
action -1, numVisits=17432, meanQ=59.199353, numObservations: 243
action 5, numVisits=9, meanQ=-4.333333, numObservations: 6
action 0, numVisits=23, meanQ=-5.400435, numObservations: 22
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=3, meanQ=-34.333333, numObservations: 3
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.841938 0.978409 0.952491 0.694317 0.675934 0.413062 0.746886 0.784966 0.346248 0.501888 w: 1
Observation: 0 3 0 3 0 1 0 3 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=169, meanQ=65.935139, numObservations: 32
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 18845 episodes
GETTING ACTION FROM:
action -1, numVisits=19014, meanQ=82.932239, numObservations: 168
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.841938 0.978409 0.952491 0.694317 0.675934 0.413062 0.746886 0.784966 0.346248 0.501888 w: 1
Observation: 0 3 0 2 0 3 0 3 0 2 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=76, meanQ=84.777374, numObservations: 6
action 2, numVisits=4, meanQ=49.000000, numObservations: 3
action 4, numVisits=4, meanQ=49.000000, numObservations: 4
action 3, numVisits=3, meanQ=32.333333, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 39104 episodes
GETTING ACTION FROM:
action 5, numVisits=39180, meanQ=91.324479, numObservations: 9
action 2, numVisits=4, meanQ=49.000000, numObservations: 3
action 4, numVisits=4, meanQ=49.000000, numObservations: 4
action 3, numVisits=3, meanQ=32.333333, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 5
Next state: 1 0.841938 0.978409 0.952491 0.694317 0.675934 0.413062 0.746886 0.784966 0.346248 0.501888 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 93.0499
Run # 16
Initial state: 0 0.338515 0.668755 0.028829 0.0755863 0.57661 0.286898 0.345048 0.435932 0.0851894 0.00407801 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33571 episodes
GETTING ACTION FROM:
action 2, numVisits=33562, meanQ=33.039833, numObservations: 9
action 4, numVisits=4, meanQ=21.500000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.338515 0.668755 0.028829 0.0755863 0.57661 0.286898 0.345048 0.435932 0.0851894 0.00407801 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=1757, meanQ=36.091302, numObservations: 9
action 5, numVisits=6, meanQ=14.165000, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 15079 episodes
GETTING ACTION FROM:
action 3, numVisits=16836, meanQ=34.156728, numObservations: 9
action 5, numVisits=6, meanQ=14.165000, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 3
Next state: 2 0.338515 0.668755 0.028829 0.0755863 0.57661 0.286898 0.345048 0.435932 0.0851894 0.00407801 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -110.99
Run # 17
Initial state: 0 0.615169 0.853737 0.181576 0.241864 0.283465 0.417582 0.459788 0.418714 0.919806 0.963667 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34041 episodes
GETTING ACTION FROM:
action 2, numVisits=33838, meanQ=30.528094, numObservations: 9
action 4, numVisits=194, meanQ=27.584677, numObservations: 9
action 1, numVisits=5, meanQ=19.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.615169 0.853737 0.181576 0.241864 0.283465 0.417582 0.459788 0.418714 0.919806 0.963667 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1689, meanQ=39.182824, numObservations: 9
action 5, numVisits=4, meanQ=21.747500, numObservations: 4
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 16207 episodes
GETTING ACTION FROM:
action 1, numVisits=17896, meanQ=35.617254, numObservations: 9
action 5, numVisits=4, meanQ=21.747500, numObservations: 4
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.615169 0.853737 0.181576 0.241864 0.283465 0.417582 0.459788 0.418714 0.919806 0.963667 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 18
Initial state: 0 0.48112 0.137165 0.614815 0.268194 0.519493 0.322011 0.93985 0.538398 0.298138 0.513485 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18056 episodes
GETTING ACTION FROM:
action -1, numVisits=18008, meanQ=58.221172, numObservations: 243
action 0, numVisits=24, meanQ=-1.464163, numObservations: 23
action 5, numVisits=18, meanQ=-3.222772, numObservations: 7
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.48112 0.137165 0.614815 0.268194 0.519493 0.322011 0.93985 0.538398 0.298138 0.513485 w: 1
Observation: 0 3 0 3 0 3 0 3 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=529, meanQ=90.107907, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 38711 episodes
GETTING ACTION FROM:
action 5, numVisits=39240, meanQ=92.671663, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.48112 0.137165 0.614815 0.268194 0.519493 0.322011 0.93985 0.538398 0.298138 0.513485 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 19
Initial state: 0 0.847003 0.701431 0.909278 0.544033 0.295772 0.378556 0.589868 0.629662 0.733854 0.110981 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33466 episodes
GETTING ACTION FROM:
action 5, numVisits=33447, meanQ=32.038245, numObservations: 9
action 2, numVisits=7, meanQ=10.428571, numObservations: 6
action 4, numVisits=7, meanQ=10.428571, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.847003 0.701431 0.909278 0.544033 0.295772 0.378556 0.589868 0.629662 0.733854 0.110981 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 20
Initial state: 0 0.056461 0.933824 0.710132 0.157441 0.281114 0.517875 0.556127 0.688465 0.261589 0.125875 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18569 episodes
GETTING ACTION FROM:
action 0, numVisits=18531, meanQ=65.335049, numObservations: 243
action 5, numVisits=3, meanQ=-4.333333, numObservations: 2
action -1, numVisits=31, meanQ=-4.395800, numObservations: 28
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.056461 0.933824 0.710132 0.157441 0.281114 0.517875 0.556127 0.688465 0.261589 0.125875 w: 1
Observation: 0 0 3 0 1 0 2 0 3 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=81, meanQ=62.641358, numObservations: 9
action 1, numVisits=5, meanQ=59.000000, numObservations: 1
action 3, numVisits=5, meanQ=59.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 31041 episodes
GETTING ACTION FROM:
action 4, numVisits=31117, meanQ=68.865665, numObservations: 9
action 1, numVisits=7, meanQ=54.855714, numObservations: 2
action 3, numVisits=8, meanQ=49.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.056461 0.933824 0.710132 0.157441 0.281114 0.517875 0.556127 0.688465 0.261589 0.125875 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 21
Initial state: 0 0.241408 0.53005 0.0528849 0.75129 0.368031 0.844402 0.21443 0.388402 0.339747 0.377282 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34035 episodes
GETTING ACTION FROM:
action 3, numVisits=34024, meanQ=31.664105, numObservations: 9
action 1, numVisits=4, meanQ=21.500000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=3, meanQ=-4.333333, numObservations: 2
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.241408 0.53005 0.0528849 0.75129 0.368031 0.844402 0.21443 0.388402 0.339747 0.377282 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 22
Initial state: 0 0.256129 0.420013 0.154769 0.774459 0.886776 0.862665 0.827529 0.536825 0.0967818 0.131825 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33484 episodes
GETTING ACTION FROM:
action 2, numVisits=33460, meanQ=31.263957, numObservations: 9
action 3, numVisits=15, meanQ=23.798667, numObservations: 7
action 1, numVisits=5, meanQ=19.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.256129 0.420013 0.154769 0.774459 0.886776 0.862665 0.827529 0.536825 0.0967818 0.131825 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1907, meanQ=45.961893, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 28780 episodes
GETTING ACTION FROM:
action 2, numVisits=30687, meanQ=58.854472, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.256129 0.420013 0.154769 0.774459 0.886776 0.862665 0.827529 0.536825 0.0967818 0.131825 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=8797, meanQ=27.395470, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=3, meanQ=-4.003333, numObservations: 3
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37482 episodes
GETTING ACTION FROM:
action 1, numVisits=46279, meanQ=30.932653, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=3, meanQ=-4.003333, numObservations: 3
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.256129 0.420013 0.154769 0.774459 0.886776 0.862665 0.827529 0.536825 0.0967818 0.131825 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 75.1399
Run # 23
Initial state: 0 0.943537 0.0681138 0.737887 0.575239 0.0473004 0.0202073 0.21656 0.850301 0.328765 0.518702 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33506 episodes
GETTING ACTION FROM:
action 2, numVisits=33488, meanQ=32.039080, numObservations: 9
action 5, numVisits=6, meanQ=10.831667, numObservations: 5
action 3, numVisits=8, meanQ=10.373750, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.943537 0.0681138 0.737887 0.575239 0.0473004 0.0202073 0.21656 0.850301 0.328765 0.518702 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 24
Initial state: 0 0.966742 0.986975 0.337664 0.472238 0.811482 0.95967 0.0321593 0.55498 0.424701 0.471516 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34312 episodes
GETTING ACTION FROM:
action 5, numVisits=34299, meanQ=30.770355, numObservations: 9
action 3, numVisits=8, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.966742 0.986975 0.337664 0.472238 0.811482 0.95967 0.0321593 0.55498 0.424701 0.471516 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 25
Initial state: 0 0.378177 0.00930255 0.995995 0.166894 0.278702 0.386128 0.214791 0.782197 0.575771 0.430371 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33258 episodes
GETTING ACTION FROM:
action 2, numVisits=33246, meanQ=32.383159, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=5, meanQ=-3.000000, numObservations: 3
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.378177 0.00930255 0.995995 0.166894 0.278702 0.386128 0.214791 0.782197 0.575771 0.430371 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 26
Initial state: 0 0.320103 0.514126 0.883844 0.00951379 0.877443 0.00218921 0.761868 0.44411 0.757256 0.189307 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34365 episodes
GETTING ACTION FROM:
action 2, numVisits=34354, meanQ=32.243202, numObservations: 9
action 5, numVisits=5, meanQ=15.000000, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.320103 0.514126 0.883844 0.00951379 0.877443 0.00218921 0.761868 0.44411 0.757256 0.189307 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 27
Initial state: 0 0.541821 0.861043 0.533154 0.468198 0.671879 0.298481 0.586306 0.0796456 0.299692 0.3879 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34059 episodes
GETTING ACTION FROM:
action 4, numVisits=33966, meanQ=31.558263, numObservations: 9
action 3, numVisits=72, meanQ=16.041668, numObservations: 8
action 2, numVisits=15, meanQ=10.399333, numObservations: 6
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 4
Next state: 2 0.541821 0.861043 0.533154 0.468198 0.671879 0.298481 0.586306 0.0796456 0.299692 0.3879 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 28
Initial state: 0 0.342276 0.465392 0.4375 0.512252 0.859904 0.0708548 0.656552 0.394798 0.879563 0.223026 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33093 episodes
GETTING ACTION FROM:
action 4, numVisits=33079, meanQ=31.781837, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=7, meanQ=-6.701414, numObservations: 5
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.342276 0.465392 0.4375 0.512252 0.859904 0.0708548 0.656552 0.394798 0.879563 0.223026 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 29
Initial state: 0 0.348196 0.90997 0.33438 0.506536 0.644538 0.0511387 0.622642 0.305825 0.843631 0.469409 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34318 episodes
GETTING ACTION FROM:
action 2, numVisits=34311, meanQ=33.085239, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.348196 0.90997 0.33438 0.506536 0.644538 0.0511387 0.622642 0.305825 0.843631 0.469409 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 30
Initial state: 0 0.966098 0.728319 0.174668 0.90645 0.272716 0.509634 0.582856 0.35551 0.864407 0.44119 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34318 episodes
GETTING ACTION FROM:
action 2, numVisits=34307, meanQ=31.467908, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.966098 0.728319 0.174668 0.90645 0.272716 0.509634 0.582856 0.35551 0.864407 0.44119 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=989, meanQ=37.659049, numObservations: 9
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=2, meanQ=-6.459950, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 17518 episodes
GETTING ACTION FROM:
action 1, numVisits=18507, meanQ=36.162689, numObservations: 9
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=2, meanQ=-6.459950, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.966098 0.728319 0.174668 0.90645 0.272716 0.509634 0.582856 0.35551 0.864407 0.44119 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 31
Initial state: 0 0.393055 0.229272 0.679133 0.78528 0.191258 0.600354 0.260171 0.411888 0.629718 0.465817 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33457 episodes
GETTING ACTION FROM:
action 1, numVisits=33438, meanQ=31.533847, numObservations: 9
action 5, numVisits=7, meanQ=10.570000, numObservations: 6
action 4, numVisits=8, meanQ=10.373750, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.393055 0.229272 0.679133 0.78528 0.191258 0.600354 0.260171 0.411888 0.629718 0.465817 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 32
Initial state: 0 0.0223925 0.785076 0.277588 0.466218 0.515281 0.400973 0.874423 0.841225 0.378891 0.967461 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33329 episodes
GETTING ACTION FROM:
action 5, numVisits=33315, meanQ=32.348721, numObservations: 9
action 2, numVisits=6, meanQ=14.000000, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=3, meanQ=-7.663333, numObservations: 2
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.0223925 0.785076 0.277588 0.466218 0.515281 0.400973 0.874423 0.841225 0.378891 0.967461 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 33
Initial state: 0 0.44072 0.759142 0.264304 0.426394 0.668149 0.815623 0.686867 0.0897926 0.688178 0.285394 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33478 episodes
GETTING ACTION FROM:
action 3, numVisits=33461, meanQ=32.997113, numObservations: 9
action 4, numVisits=6, meanQ=-1.000000, numObservations: 5
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=5, meanQ=-3.000000, numObservations: 4
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.44072 0.759142 0.264304 0.426394 0.668149 0.815623 0.686867 0.0897926 0.688178 0.285394 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 34
Initial state: 0 0.492465 0.824689 0.713243 0.358952 0.715821 0.337083 0.332962 0.376318 0.646078 0.541553 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33340 episodes
GETTING ACTION FROM:
action 4, numVisits=33332, meanQ=32.183105, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.492465 0.824689 0.713243 0.358952 0.715821 0.337083 0.332962 0.376318 0.646078 0.541553 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 35
Initial state: 0 0.999223 0.819946 0.324277 0.489811 0.0115779 0.434074 0.584556 0.506207 0.480854 0.920432 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32970 episodes
GETTING ACTION FROM:
action 4, numVisits=32949, meanQ=32.680536, numObservations: 9
action 3, numVisits=10, meanQ=17.198000, numObservations: 6
action 2, numVisits=7, meanQ=13.285714, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.999223 0.819946 0.324277 0.489811 0.0115779 0.434074 0.584556 0.506207 0.480854 0.920432 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 36
Initial state: 0 0.303495 0.409079 0.817116 0.410979 0.773951 0.107954 0.307769 0.766818 0.0634403 0.460984 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34235 episodes
GETTING ACTION FROM:
action 1, numVisits=34226, meanQ=32.081319, numObservations: 9
action 5, numVisits=4, meanQ=21.500000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.303495 0.409079 0.817116 0.410979 0.773951 0.107954 0.307769 0.766818 0.0634403 0.460984 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 37
Initial state: 0 0.973217 0.415214 0.88257 0.982234 0.328344 0.361576 0.939882 0.787391 0.11233 0.957161 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18608 episodes
GETTING ACTION FROM:
action 0, numVisits=18523, meanQ=66.274468, numObservations: 243
action -1, numVisits=31, meanQ=-4.619029, numObservations: 29
action 5, numVisits=8, meanQ=-4.625000, numObservations: 5
action 3, numVisits=37, meanQ=-5.081349, numObservations: 8
action 2, numVisits=5, meanQ=-21.000000, numObservations: 4
action 1, numVisits=3, meanQ=-34.333333, numObservations: 2
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.973217 0.415214 0.88257 0.982234 0.328344 0.361576 0.939882 0.787391 0.11233 0.957161 w: 1
Observation: 0 0 2 0 1 0 2 0 3 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=81, meanQ=60.555557, numObservations: 7
action 5, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=3, meanQ=-4.003333, numObservations: 3
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 35778 episodes
GETTING ACTION FROM:
action 4, numVisits=35859, meanQ=64.658441, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=3, meanQ=-4.003333, numObservations: 3
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.973217 0.415214 0.88257 0.982234 0.328344 0.361576 0.939882 0.787391 0.11233 0.957161 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 38
Initial state: 0 0.895386 0.797414 0.196556 0.765496 0.340542 0.366646 0.780926 0.52691 0.17333 0.71358 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33118 episodes
GETTING ACTION FROM:
action 2, numVisits=33107, meanQ=32.820286, numObservations: 9
action 3, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.895386 0.797414 0.196556 0.765496 0.340542 0.366646 0.780926 0.52691 0.17333 0.71358 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1900, meanQ=52.796338, numObservations: 9
action 4, numVisits=7, meanQ=13.285714, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 28803 episodes
GETTING ACTION FROM:
action 2, numVisits=30703, meanQ=61.164364, numObservations: 9
action 4, numVisits=7, meanQ=13.285714, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.895386 0.797414 0.196556 0.765496 0.340542 0.366646 0.780926 0.52691 0.17333 0.71358 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=8993, meanQ=34.101262, numObservations: 9
action 4, numVisits=47, meanQ=32.639157, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 38019 episodes
GETTING ACTION FROM:
action 1, numVisits=47010, meanQ=43.765779, numObservations: 9
action 4, numVisits=49, meanQ=31.266131, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.895386 0.797414 0.196556 0.765496 0.340542 0.366646 0.780926 0.52691 0.17333 0.71358 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 75.1399
Run # 39
Initial state: 0 0.348101 0.423729 0.483926 0.474579 0.768903 0.665538 0.271213 0.961799 0.599725 0.709099 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34259 episodes
GETTING ACTION FROM:
action 3, numVisits=34251, meanQ=32.063108, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.348101 0.423729 0.483926 0.474579 0.768903 0.665538 0.271213 0.961799 0.599725 0.709099 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 40
Initial state: 0 0.175877 0.777711 0.585955 0.809796 0.0659907 0.113613 0.509285 0.169952 0.310928 0.361233 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34397 episodes
GETTING ACTION FROM:
action 5, numVisits=34386, meanQ=32.224885, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=5, meanQ=-3.000000, numObservations: 4
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.175877 0.777711 0.585955 0.809796 0.0659907 0.113613 0.509285 0.169952 0.310928 0.361233 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 41
Initial state: 0 0.792091 0.168439 0.297091 0.55021 0.781859 0.789008 0.545246 0.523066 0.333647 0.394674 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34150 episodes
GETTING ACTION FROM:
action 5, numVisits=34137, meanQ=30.229380, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 4, numVisits=6, meanQ=-4.333333, numObservations: 5
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.792091 0.168439 0.297091 0.55021 0.781859 0.789008 0.545246 0.523066 0.333647 0.394674 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 42
Initial state: 0 0.083656 0.273804 0.278613 0.39736 0.368969 0.412968 0.154691 0.72022 0.0694511 0.721734 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18690 episodes
GETTING ACTION FROM:
action 0, numVisits=18645, meanQ=63.952661, numObservations: 243
action -1, numVisits=33, meanQ=-1.250000, numObservations: 29
action 3, numVisits=6, meanQ=-4.333333, numObservations: 4
action 5, numVisits=3, meanQ=-4.333333, numObservations: 2
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.083656 0.273804 0.278613 0.39736 0.368969 0.412968 0.154691 0.72022 0.0694511 0.721734 w: 1
Observation: 0 0 1 0 2 0 2 0 3 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=106, meanQ=55.623208, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37319 episodes
GETTING ACTION FROM:
action 2, numVisits=37425, meanQ=71.406224, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.083656 0.273804 0.278613 0.39736 0.368969 0.412968 0.154691 0.72022 0.0694511 0.721734 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 43
Initial state: 0 0.318856 0.499243 0.0230869 0.722418 0.994739 0.461388 0.451123 0.573888 0.422771 0.293617 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18129 episodes
GETTING ACTION FROM:
action -1, numVisits=18090, meanQ=61.620947, numObservations: 243
action 0, numVisits=32, meanQ=-1.072184, numObservations: 31
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.318856 0.499243 0.0230869 0.722418 0.994739 0.461388 0.451123 0.573888 0.422771 0.293617 w: 1
Observation: 0 2 0 1 0 3 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=209, meanQ=83.440480, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 38626 episodes
GETTING ACTION FROM:
action 1, numVisits=38835, meanQ=87.981468, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.318856 0.499243 0.0230869 0.722418 0.994739 0.461388 0.451123 0.573888 0.422771 0.293617 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 44
Initial state: 0 0.867282 0.0680393 0.331646 0.378996 0.668181 0.331695 0.0635748 0.046485 0.218503 0.234322 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33120 episodes
GETTING ACTION FROM:
action 5, numVisits=33111, meanQ=31.993687, numObservations: 9
action 3, numVisits=3, meanQ=25.996667, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.867282 0.0680393 0.331646 0.378996 0.668181 0.331695 0.0635748 0.046485 0.218503 0.234322 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 45
Initial state: 0 0.445718 0.212687 0.50541 0.467482 0.594193 0.31089 0.352785 0.358946 0.734492 0.751639 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34568 episodes
GETTING ACTION FROM:
action 1, numVisits=34514, meanQ=31.166245, numObservations: 9
action 2, numVisits=10, meanQ=28.000000, numObservations: 6
action 5, numVisits=36, meanQ=27.360836, numObservations: 7
action 4, numVisits=4, meanQ=21.500000, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 2 0.445718 0.212687 0.50541 0.467482 0.594193 0.31089 0.352785 0.358946 0.734492 0.751639 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 46
Initial state: 0 0.911753 0.346911 0.656393 0.0366626 0.54043 0.398551 0.555413 0.507552 0.301002 0.467909 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34338 episodes
GETTING ACTION FROM:
action 2, numVisits=34328, meanQ=32.213992, numObservations: 9
action 4, numVisits=4, meanQ=21.500000, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.911753 0.346911 0.656393 0.0366626 0.54043 0.398551 0.555413 0.507552 0.301002 0.467909 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 47
Initial state: 0 0.601205 0.95707 0.430294 0.164629 0.317553 0.443839 0.10122 0.643095 0.838388 0.260234 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18616 episodes
GETTING ACTION FROM:
action 0, numVisits=18593, meanQ=66.100326, numObservations: 243
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 2, numVisits=11, meanQ=-5.728155, numObservations: 6
action 3, numVisits=3, meanQ=-34.333333, numObservations: 2
action 5, numVisits=3, meanQ=-34.333333, numObservations: 2
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.601205 0.95707 0.430294 0.164629 0.317553 0.443839 0.10122 0.643095 0.838388 0.260234 w: 1
Observation: 0 0 3 0 1 0 2 0 3 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=88, meanQ=90.033637, numObservations: 6
action 4, numVisits=4, meanQ=71.747500, numObservations: 3
action 1, numVisits=7, meanQ=70.428571, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 38115 episodes
GETTING ACTION FROM:
action 3, numVisits=38203, meanQ=86.620732, numObservations: 9
action 4, numVisits=4, meanQ=71.747500, numObservations: 3
action 1, numVisits=7, meanQ=70.428571, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.601205 0.95707 0.430294 0.164629 0.317553 0.443839 0.10122 0.643095 0.838388 0.260234 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=216, meanQ=88.446273, numObservations: 8
action 1, numVisits=27, meanQ=42.039633, numObservations: 4
action 4, numVisits=7, meanQ=41.857143, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 39086 episodes
GETTING ACTION FROM:
action 3, numVisits=253, meanQ=89.942312, numObservations: 8
action 1, numVisits=39073, meanQ=72.532074, numObservations: 9
action 4, numVisits=10, meanQ=39.000000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.601205 0.95707 0.430294 0.164629 0.317553 0.443839 0.10122 0.643095 0.838388 0.260234 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 84.1399
Run # 48
Initial state: 0 0.564866 0.952986 0.912381 0.761961 0.933982 0.339851 0.33948 0.407839 0.51992 0.131772 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33573 episodes
GETTING ACTION FROM:
action 2, numVisits=33535, meanQ=31.195466, numObservations: 9
action 5, numVisits=21, meanQ=25.666671, numObservations: 8
action 1, numVisits=12, meanQ=21.747500, numObservations: 7
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.564866 0.952986 0.912381 0.761961 0.933982 0.339851 0.33948 0.407839 0.51992 0.131772 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 49
Initial state: 0 0.282491 0.4999 0.6945 0.272201 0.13973 0.506725 0.37824 0.0814226 0.786614 0.42211 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33974 episodes
GETTING ACTION FROM:
action 3, numVisits=33967, meanQ=31.656174, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.282491 0.4999 0.6945 0.272201 0.13973 0.506725 0.37824 0.0814226 0.786614 0.42211 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=938, meanQ=57.236611, numObservations: 167
action 0, numVisits=19, meanQ=-1.688411, numObservations: 17
action 4, numVisits=8, meanQ=-3.252500, numObservations: 6
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 5642 episodes
GETTING ACTION FROM:
action -1, numVisits=6580, meanQ=34.892938, numObservations: 239
action 0, numVisits=19, meanQ=-1.688411, numObservations: 17
action 4, numVisits=8, meanQ=-3.252500, numObservations: 6
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.282491 0.4999 0.6945 0.272201 0.13973 0.506725 0.37824 0.0814226 0.786614 0.42211 w: 1
Observation: 0 1 0 3 0 2 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=2, meanQ=99.000000, numObservations: 2
action 3, numVisits=1, meanQ=99.000000, numObservations: 1
action 4, numVisits=2, meanQ=99.000000, numObservations: 1
action 5, numVisits=1, meanQ=99.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-19.060687, numObservations: 1
Sampled 23839 episodes
GETTING ACTION FROM:
action 3, numVisits=132, meanQ=91.113637, numObservations: 8
action 1, numVisits=23708, meanQ=76.319989, numObservations: 9
action 4, numVisits=3, meanQ=32.333333, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-19.060687, numObservations: 1
action: 3
Next state: 0 0.282491 0.4999 0.6945 0.272201 0.13973 0.506725 0.37824 0.0814226 0.786614 0.42211 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34726 episodes
GETTING ACTION FROM:
action 1, numVisits=34721, meanQ=74.335250, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-2.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.282491 0.4999 0.6945 0.272201 0.13973 0.506725 0.37824 0.0814226 0.786614 0.42211 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 72.2985
Run # 50
Initial state: 0 0.910262 0.64867 0.399293 0.952876 0.305836 0.518892 0.152706 0.277764 0.891723 0.24119 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34657 episodes
GETTING ACTION FROM:
action 4, numVisits=34632, meanQ=32.822528, numObservations: 9
action 2, numVisits=12, meanQ=28.173350, numObservations: 5
action 3, numVisits=4, meanQ=21.747500, numObservations: 4
action 5, numVisits=6, meanQ=14.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.910262 0.64867 0.399293 0.952876 0.305836 0.518892 0.152706 0.277764 0.891723 0.24119 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=1816, meanQ=33.838155, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 13469 episodes
GETTING ACTION FROM:
action 3, numVisits=15285, meanQ=29.152140, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.910262 0.64867 0.399293 0.952876 0.305836 0.518892 0.152706 0.277764 0.891723 0.24119 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 51
Initial state: 0 0.341538 0.466551 0.039692 0.46116 0.681585 0.927948 0.224104 0.807103 0.906841 0.105111 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34188 episodes
GETTING ACTION FROM:
action 5, numVisits=34172, meanQ=33.154057, numObservations: 9
action 4, numVisits=10, meanQ=7.100000, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.341538 0.466551 0.039692 0.46116 0.681585 0.927948 0.224104 0.807103 0.906841 0.105111 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 52
Initial state: 0 0.947351 0.577156 0.704231 0.831023 0.852836 0.645447 0.347496 0.472326 0.561962 0.608302 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33520 episodes
GETTING ACTION FROM:
action 3, numVisits=33510, meanQ=33.153229, numObservations: 9
action 2, numVisits=5, meanQ=15.198000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.947351 0.577156 0.704231 0.831023 0.852836 0.645447 0.347496 0.472326 0.561962 0.608302 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 53
Initial state: 0 0.818817 0.841425 0.245347 0.310364 0.283595 0.724376 0.316577 0.491612 0.942349 0.747794 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34596 episodes
GETTING ACTION FROM:
action 1, numVisits=34497, meanQ=31.893951, numObservations: 9
action 2, numVisits=85, meanQ=26.624128, numObservations: 9
action 4, numVisits=10, meanQ=17.099000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.818817 0.841425 0.245347 0.310364 0.283595 0.724376 0.316577 0.491612 0.942349 0.747794 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 54
Initial state: 0 0.255848 0.361209 0.726663 0.101333 0.482176 0.419815 0.434285 0.65679 0.570999 0.608755 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33278 episodes
GETTING ACTION FROM:
action 3, numVisits=33266, meanQ=32.583414, numObservations: 9
action 4, numVisits=4, meanQ=21.500000, numObservations: 4
action 2, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.255848 0.361209 0.726663 0.101333 0.482176 0.419815 0.434285 0.65679 0.570999 0.608755 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 55
Initial state: 0 0.352784 0.500852 0.241522 0.397442 0.387493 0.29394 0.694922 0.00400406 0.322782 0.167414 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34325 episodes
GETTING ACTION FROM:
action 3, numVisits=34312, meanQ=31.545833, numObservations: 9
action 5, numVisits=7, meanQ=13.285714, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.352784 0.500852 0.241522 0.397442 0.387493 0.29394 0.694922 0.00400406 0.322782 0.167414 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 56
Initial state: 0 0.659547 0.487924 0.327744 0.458335 0.544252 0.553901 0.00223736 0.26838 0.582103 0.297347 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18370 episodes
GETTING ACTION FROM:
action -1, numVisits=18332, meanQ=61.379544, numObservations: 243
action 2, numVisits=7, meanQ=-2.428571, numObservations: 5
action 4, numVisits=5, meanQ=-2.802000, numObservations: 3
action 0, numVisits=21, meanQ=-5.818571, numObservations: 20
action 1, numVisits=3, meanQ=-7.663333, numObservations: 2
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.659547 0.487924 0.327744 0.458335 0.544252 0.553901 0.00223736 0.26838 0.582103 0.297347 w: 1
Observation: 0 3 0 2 0 3 0 1 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=60, meanQ=34.666333, numObservations: 9
action 5, numVisits=4, meanQ=21.747500, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37111 episodes
GETTING ACTION FROM:
action 2, numVisits=37171, meanQ=65.795903, numObservations: 9
action 5, numVisits=4, meanQ=21.747500, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.659547 0.487924 0.327744 0.458335 0.544252 0.553901 0.00223736 0.26838 0.582103 0.297347 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 57
Initial state: 0 0.179485 0.972407 0.876527 0.88065 0.527065 0.565028 0.320727 0.422979 0.608902 0.709941 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34245 episodes
GETTING ACTION FROM:
action 4, numVisits=34232, meanQ=31.075995, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=7, meanQ=-3.855714, numObservations: 6
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.179485 0.972407 0.876527 0.88065 0.527065 0.565028 0.320727 0.422979 0.608902 0.709941 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 58
Initial state: 0 0.957397 0.71708 0.454536 0.17262 0.798999 0.190728 0.272901 0.339121 0.800557 0.569388 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34393 episodes
GETTING ACTION FROM:
action 1, numVisits=34381, meanQ=30.929973, numObservations: 9
action 3, numVisits=7, meanQ=13.285714, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.957397 0.71708 0.454536 0.17262 0.798999 0.190728 0.272901 0.339121 0.800557 0.569388 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 59
Initial state: 0 0.849714 0.285238 0.336675 0.43985 0.479907 0.972638 0.0601053 0.106056 0.973831 0.119543 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34521 episodes
GETTING ACTION FROM:
action 5, numVisits=34491, meanQ=32.328244, numObservations: 9
action 3, numVisits=23, meanQ=4.043922, numObservations: 8
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.849714 0.285238 0.336675 0.43985 0.479907 0.972638 0.0601053 0.106056 0.973831 0.119543 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 60
Initial state: 0 0.238627 0.343712 0.332746 0.489718 0.621784 0.711544 0.646289 0.594861 0.489014 0.0444346 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34868 episodes
GETTING ACTION FROM:
action 4, numVisits=34862, meanQ=31.011019, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.238627 0.343712 0.332746 0.489718 0.621784 0.711544 0.646289 0.594861 0.489014 0.0444346 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 61
Initial state: 0 0.500488 0.979555 0.134078 0.490713 0.348 0.357467 0.408085 0.0341922 0.426808 0.868863 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18017 episodes
GETTING ACTION FROM:
action -1, numVisits=17919, meanQ=61.338045, numObservations: 243
action 0, numVisits=84, meanQ=-2.613564, numObservations: 75
action 2, numVisits=10, meanQ=-3.000000, numObservations: 5
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.500488 0.979555 0.134078 0.490713 0.348 0.357467 0.408085 0.0341922 0.426808 0.868863 w: 1
Observation: 0 3 0 1 0 2 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=195, meanQ=78.933641, numObservations: 9
action 4, numVisits=4, meanQ=49.000000, numObservations: 3
action 2, numVisits=2, meanQ=44.495000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 38772 episodes
GETTING ACTION FROM:
action 3, numVisits=38967, meanQ=90.193579, numObservations: 9
action 4, numVisits=4, meanQ=49.000000, numObservations: 3
action 2, numVisits=2, meanQ=44.495000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.500488 0.979555 0.134078 0.490713 0.348 0.357467 0.408085 0.0341922 0.426808 0.868863 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=2495, meanQ=90.854422, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 42029 episodes
GETTING ACTION FROM:
action 3, numVisits=44524, meanQ=97.972482, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.500488 0.979555 0.134078 0.490713 0.348 0.357467 0.408085 0.0341922 0.426808 0.868863 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 84.1399
Run # 62
Initial state: 0 0.279845 0.441358 0.785207 0.074471 0.680176 0.130639 0.0361674 0.365815 0.90055 0.898671 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34022 episodes
GETTING ACTION FROM:
action 2, numVisits=33992, meanQ=33.599975, numObservations: 9
action 4, numVisits=16, meanQ=21.561875, numObservations: 6
action 3, numVisits=7, meanQ=13.285714, numObservations: 5
action 5, numVisits=4, meanQ=-1.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.279845 0.441358 0.785207 0.074471 0.680176 0.130639 0.0361674 0.365815 0.90055 0.898671 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 63
Initial state: 0 0.281212 0.471712 0.634414 0.50772 0.246617 0.873396 0.151471 0.867944 0.860118 0.398501 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32875 episodes
GETTING ACTION FROM:
action 1, numVisits=32868, meanQ=32.038175, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.281212 0.471712 0.634414 0.50772 0.246617 0.873396 0.151471 0.867944 0.860118 0.398501 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 64
Initial state: 0 0.505999 0.442813 0.0172769 0.5719 0.292062 0.681696 0.664018 0.506915 0.305877 0.420402 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33563 episodes
GETTING ACTION FROM:
action 1, numVisits=33528, meanQ=32.692392, numObservations: 9
action 2, numVisits=23, meanQ=27.565230, numObservations: 7
action 4, numVisits=7, meanQ=23.285714, numObservations: 5
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.505999 0.442813 0.0172769 0.5719 0.292062 0.681696 0.664018 0.506915 0.305877 0.420402 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 65
Initial state: 0 0.418743 0.0287811 0.862555 0.0269884 0.312076 0.342859 0.909242 0.0870802 0.329063 0.89906 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34250 episodes
GETTING ACTION FROM:
action 1, numVisits=34086, meanQ=30.505112, numObservations: 9
action 3, numVisits=149, meanQ=29.156246, numObservations: 9
action 4, numVisits=10, meanQ=26.198000, numObservations: 7
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.418743 0.0287811 0.862555 0.0269884 0.312076 0.342859 0.909242 0.0870802 0.329063 0.89906 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 66
Initial state: 0 0.319788 0.360816 0.834246 0.588999 0.702227 0.723262 0.804818 0.901531 0.526547 0.800743 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34846 episodes
GETTING ACTION FROM:
action 3, numVisits=29255, meanQ=31.610982, numObservations: 9
action 2, numVisits=5586, meanQ=31.426408, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.319788 0.360816 0.834246 0.588999 0.702227 0.723262 0.804818 0.901531 0.526547 0.800743 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 67
Initial state: 0 0.268301 0.50634 0.714034 0.389586 0.263286 0.947147 0.607875 0.00107373 0.85727 0.0231421 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32498 episodes
GETTING ACTION FROM:
action 1, numVisits=32486, meanQ=31.965925, numObservations: 9
action 4, numVisits=4, meanQ=21.500000, numObservations: 4
action 2, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.268301 0.50634 0.714034 0.389586 0.263286 0.947147 0.607875 0.00107373 0.85727 0.0231421 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 68
Initial state: 0 0.852751 0.0038027 0.283564 0.353057 0.360556 0.599802 0.188012 0.351318 0.324734 0.555322 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33864 episodes
GETTING ACTION FROM:
action 4, numVisits=33849, meanQ=32.272655, numObservations: 9
action 3, numVisits=8, meanQ=24.000000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 2
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.852751 0.0038027 0.283564 0.353057 0.360556 0.599802 0.188012 0.351318 0.324734 0.555322 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=869, meanQ=35.415485, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 17359 episodes
GETTING ACTION FROM:
action 5, numVisits=18228, meanQ=34.504919, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.852751 0.0038027 0.283564 0.353057 0.360556 0.599802 0.188012 0.351318 0.324734 0.555322 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 69
Initial state: 0 0.316548 0.522884 0.466059 0.0641092 0.572888 0.170256 0.715144 0.939076 0.935893 0.851413 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34102 episodes
GETTING ACTION FROM:
action 1, numVisits=34087, meanQ=31.083782, numObservations: 9
action 2, numVisits=10, meanQ=17.099000, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.316548 0.522884 0.466059 0.0641092 0.572888 0.170256 0.715144 0.939076 0.935893 0.851413 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 70
Initial state: 0 0.473152 0.461446 0.398019 0.128018 0.346932 0.420985 0.129596 0.49652 0.812425 0.129058 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33914 episodes
GETTING ACTION FROM:
action 3, numVisits=33900, meanQ=31.963285, numObservations: 9
action 1, numVisits=4, meanQ=21.747500, numObservations: 4
action 5, numVisits=4, meanQ=-1.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=3, meanQ=-4.333333, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.473152 0.461446 0.398019 0.128018 0.346932 0.420985 0.129596 0.49652 0.812425 0.129058 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 71
Initial state: 0 0.22648 0.132177 0.673571 0.435189 0.325919 0.350988 0.270007 0.660453 0.588903 0.319772 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34813 episodes
GETTING ACTION FROM:
action 5, numVisits=34788, meanQ=31.986712, numObservations: 9
action 1, numVisits=10, meanQ=19.000000, numObservations: 4
action 4, numVisits=5, meanQ=19.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=5, meanQ=-3.000000, numObservations: 4
action 3, numVisits=3, meanQ=-4.333333, numObservations: 3
action: 5
Next state: 2 0.22648 0.132177 0.673571 0.435189 0.325919 0.350988 0.270007 0.660453 0.588903 0.319772 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 72
Initial state: 0 0.544229 0.360753 0.355047 0.342995 0.706871 0.259745 0.0254003 0.113166 0.714681 0.473413 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34298 episodes
GETTING ACTION FROM:
action 5, numVisits=34162, meanQ=30.847342, numObservations: 9
action 2, numVisits=130, meanQ=29.508467, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.544229 0.360753 0.355047 0.342995 0.706871 0.259745 0.0254003 0.113166 0.714681 0.473413 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 73
Initial state: 0 0.606642 0.252229 0.337758 0.441727 0.306772 0.746068 0.507878 0.743077 0.722093 0.318878 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34250 episodes
GETTING ACTION FROM:
action 2, numVisits=34234, meanQ=32.184287, numObservations: 9
action 4, numVisits=8, meanQ=24.000000, numObservations: 5
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.606642 0.252229 0.337758 0.441727 0.306772 0.746068 0.507878 0.743077 0.722093 0.318878 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=510, meanQ=81.541462, numObservations: 9
action 5, numVisits=6, meanQ=65.666667, numObservations: 5
action 4, numVisits=4, meanQ=49.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 41565 episodes
GETTING ACTION FROM:
action 2, numVisits=42075, meanQ=88.759686, numObservations: 9
action 5, numVisits=6, meanQ=65.666667, numObservations: 5
action 4, numVisits=4, meanQ=49.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.606642 0.252229 0.337758 0.441727 0.306772 0.746068 0.507878 0.743077 0.722093 0.318878 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 74
Initial state: 0 0.293671 0.486001 0.183243 0.892661 0.178311 0.439604 0.568882 0.292324 0.143482 0.427913 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32734 episodes
GETTING ACTION FROM:
action 2, numVisits=32646, meanQ=33.196124, numObservations: 9
action 4, numVisits=82, meanQ=20.625252, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.293671 0.486001 0.183243 0.892661 0.178311 0.439604 0.568882 0.292324 0.143482 0.427913 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 75
Initial state: 0 0.39782 0.67216 0.111226 0.85869 0.311155 0.412513 0.916751 0.331487 0.203462 0.394234 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33619 episodes
GETTING ACTION FROM:
action 5, numVisits=33377, meanQ=31.971411, numObservations: 9
action 3, numVisits=233, meanQ=30.058070, numObservations: 9
action 4, numVisits=5, meanQ=19.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.39782 0.67216 0.111226 0.85869 0.311155 0.412513 0.916751 0.331487 0.203462 0.394234 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=881, meanQ=34.751769, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 14672 episodes
GETTING ACTION FROM:
action 2, numVisits=15553, meanQ=23.280466, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.39782 0.67216 0.111226 0.85869 0.311155 0.412513 0.916751 0.331487 0.203462 0.394234 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 0, numVisits=462, meanQ=36.427407, numObservations: 114
action 1, numVisits=6, meanQ=-1.000000, numObservations: 5
action -1, numVisits=6, meanQ=-1.010000, numObservations: 6
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 7647 episodes
GETTING ACTION FROM:
action 0, numVisits=8109, meanQ=21.035579, numObservations: 235
action 1, numVisits=6, meanQ=-1.000000, numObservations: 5
action -1, numVisits=6, meanQ=-1.010000, numObservations: 6
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.39782 0.67216 0.111226 0.85869 0.311155 0.412513 0.916751 0.331487 0.203462 0.394234 w: 1
Observation: 0 0 3 0 3 0 2 0 1 0 2 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=21, meanQ=61.378728, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=3, meanQ=-10.678251, numObservations: 2
action 3, numVisits=1, meanQ=-19.448470, numObservations: 1
action 4, numVisits=1, meanQ=-20.803329, numObservations: 1
action 5, numVisits=1, meanQ=-1065.928152, numObservations: 1
Sampled 14528 episodes
GETTING ACTION FROM:
action 2, numVisits=14549, meanQ=80.460444, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=3, meanQ=-10.678251, numObservations: 2
action 3, numVisits=1, meanQ=-19.448470, numObservations: 1
action 4, numVisits=1, meanQ=-20.803329, numObservations: 1
action 5, numVisits=1, meanQ=-1065.928152, numObservations: 1
action: 2
Next state: 0 0.39782 0.67216 0.111226 0.85869 0.311155 0.412513 0.916751 0.331487 0.203462 0.394234 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 1, numVisits=2824, meanQ=80.461799, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-17.885807, numObservations: 1
action 3, numVisits=1, meanQ=-17.927351, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-1067.052242, numObservations: 1
Sampled 34970 episodes
GETTING ACTION FROM:
action 1, numVisits=37794, meanQ=80.011255, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-17.885807, numObservations: 1
action 3, numVisits=1, meanQ=-17.927351, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-1067.052242, numObservations: 1
action: 1
Next state: 2 0.39782 0.67216 0.111226 0.85869 0.311155 0.412513 0.916751 0.331487 0.203462 0.394234 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -131.544
Run # 76
Initial state: 0 0.330967 0.345448 0.0733926 0.0742167 0.207885 0.308802 0.227316 0.941999 0.110953 0.0170146 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33630 episodes
GETTING ACTION FROM:
action 1, numVisits=33623, meanQ=33.022898, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.330967 0.345448 0.0733926 0.0742167 0.207885 0.308802 0.227316 0.941999 0.110953 0.0170146 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 77
Initial state: 0 0.399184 0.00619039 0.0495817 0.695059 0.310759 0.976245 0.901728 0.629175 0.343954 0.490641 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18615 episodes
GETTING ACTION FROM:
action 0, numVisits=18599, meanQ=63.323549, numObservations: 243
action -1, numVisits=11, meanQ=-1.190900, numObservations: 10
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.399184 0.00619039 0.0495817 0.695059 0.310759 0.976245 0.901728 0.629175 0.343954 0.490641 w: 1
Observation: 0 0 1 0 3 0 3 0 3 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=9, meanQ=76.777778, numObservations: 3
action 4, numVisits=17, meanQ=74.410588, numObservations: 6
action 2, numVisits=18, meanQ=70.721667, numObservations: 7
action 1, numVisits=5, meanQ=59.000000, numObservations: 3
action 5, numVisits=2, meanQ=44.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 36862 episodes
GETTING ACTION FROM:
action 4, numVisits=36847, meanQ=73.491446, numObservations: 9
action 3, numVisits=38, meanQ=68.736842, numObservations: 8
action 2, numVisits=21, meanQ=65.237619, numObservations: 7
action 1, numVisits=5, meanQ=59.000000, numObservations: 3
action 5, numVisits=2, meanQ=44.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 4
Next state: 2 0.399184 0.00619039 0.0495817 0.695059 0.310759 0.976245 0.901728 0.629175 0.343954 0.490641 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101.99
Run # 78
Initial state: 0 0.734996 0.564555 0.123888 0.855746 0.281635 0.514114 0.0694811 0.0737966 0.0246314 0.836584 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33799 episodes
GETTING ACTION FROM:
action 1, numVisits=33789, meanQ=30.973607, numObservations: 9
action 3, numVisits=5, meanQ=15.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.734996 0.564555 0.123888 0.855746 0.281635 0.514114 0.0694811 0.0737966 0.0246314 0.836584 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 79
Initial state: 0 0.894373 0.71897 0.314024 0.243501 0.903424 0.771579 0.759547 0.972994 0.299547 0.498098 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18533 episodes
GETTING ACTION FROM:
action 0, numVisits=18483, meanQ=63.143842, numObservations: 243
action 2, numVisits=3, meanQ=-4.003333, numObservations: 2
action 4, numVisits=16, meanQ=-4.181863, numObservations: 8
action -1, numVisits=26, meanQ=-4.970381, numObservations: 24
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=3, meanQ=-34.333333, numObservations: 3
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.894373 0.71897 0.314024 0.243501 0.903424 0.771579 0.759547 0.972994 0.299547 0.498098 w: 1
Observation: 0 0 3 0 1 0 2 0 3 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=89, meanQ=57.900115, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=5, meanQ=-2.802000, numObservations: 5
action 3, numVisits=3, meanQ=-4.003333, numObservations: 2
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37596 episodes
GETTING ACTION FROM:
action 1, numVisits=37685, meanQ=69.342966, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=5, meanQ=-2.802000, numObservations: 5
action 3, numVisits=3, meanQ=-4.003333, numObservations: 2
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.894373 0.71897 0.314024 0.243501 0.903424 0.771579 0.759547 0.972994 0.299547 0.498098 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 80
Initial state: 0 0.799275 0.748965 0.319084 0.513343 0.95628 0.721795 0.36695 0.0191901 0.839126 0.847665 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34281 episodes
GETTING ACTION FROM:
action 2, numVisits=34274, meanQ=32.182957, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.799275 0.748965 0.319084 0.513343 0.95628 0.721795 0.36695 0.0191901 0.839126 0.847665 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=547, meanQ=79.127879, numObservations: 9
action 5, numVisits=2, meanQ=44.495000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 41798 episodes
GETTING ACTION FROM:
action 2, numVisits=42345, meanQ=89.032479, numObservations: 9
action 5, numVisits=2, meanQ=44.495000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.799275 0.748965 0.319084 0.513343 0.95628 0.721795 0.36695 0.0191901 0.839126 0.847665 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 81
Initial state: 0 0.700473 0.311294 0.803949 0.298328 0.183631 0.571666 0.350626 0.410519 0.960298 0.634866 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34495 episodes
GETTING ACTION FROM:
action 5, numVisits=34466, meanQ=32.601972, numObservations: 9
action 3, numVisits=21, meanQ=20.429048, numObservations: 8
action 2, numVisits=4, meanQ=-1.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.700473 0.311294 0.803949 0.298328 0.183631 0.571666 0.350626 0.410519 0.960298 0.634866 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 82
Initial state: 0 0.359239 0.0490916 0.0383724 0.44567 0.258484 0.441613 0.458164 0.633816 0.74813 0.129352 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34505 episodes
GETTING ACTION FROM:
action 4, numVisits=34457, meanQ=31.105683, numObservations: 9
action 3, numVisits=38, meanQ=17.657374, numObservations: 9
action 5, numVisits=6, meanQ=-1.000000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.359239 0.0490916 0.0383724 0.44567 0.258484 0.441613 0.458164 0.633816 0.74813 0.129352 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 83
Initial state: 0 0.955836 0.495012 0.11489 0.0294972 0.329287 0.921816 0.274667 0.184592 0.338952 0.458895 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34121 episodes
GETTING ACTION FROM:
action 1, numVisits=34111, meanQ=31.923442, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.955836 0.495012 0.11489 0.0294972 0.329287 0.921816 0.274667 0.184592 0.338952 0.458895 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 84
Initial state: 0 0.732843 0.427839 0.318635 0.348888 0.767108 0.341252 0.881992 0.598441 0.272371 0.298081 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18523 episodes
GETTING ACTION FROM:
action 0, numVisits=18492, meanQ=65.587454, numObservations: 243
action -1, numVisits=17, meanQ=-2.001165, numObservations: 13
action 1, numVisits=4, meanQ=-6.000000, numObservations: 4
action 3, numVisits=5, meanQ=-21.000000, numObservations: 4
action 5, numVisits=3, meanQ=-34.333333, numObservations: 2
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.732843 0.427839 0.318635 0.348888 0.767108 0.341252 0.881992 0.598441 0.272371 0.298081 w: 1
Observation: 0 0 1 0 2 0 2 0 3 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=46, meanQ=60.546963, numObservations: 7
action 2, numVisits=3, meanQ=26.326667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 36192 episodes
GETTING ACTION FROM:
action 4, numVisits=36238, meanQ=62.658790, numObservations: 9
action 2, numVisits=3, meanQ=26.326667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.732843 0.427839 0.318635 0.348888 0.767108 0.341252 0.881992 0.598441 0.272371 0.298081 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 85
Initial state: 0 0.803337 0.893018 0.869462 0.196298 0.319387 0.415257 0.0231711 0.144435 0.600656 0.900501 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33588 episodes
GETTING ACTION FROM:
action 1, numVisits=33541, meanQ=32.917629, numObservations: 9
action 2, numVisits=36, meanQ=30.389453, numObservations: 9
action 4, numVisits=7, meanQ=20.428571, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.803337 0.893018 0.869462 0.196298 0.319387 0.415257 0.0231711 0.144435 0.600656 0.900501 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 86
Initial state: 0 0.804075 0.772711 0.309492 0.714141 0.601974 0.506111 0.23394 0.235155 0.345799 0.420616 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34510 episodes
GETTING ACTION FROM:
action 4, numVisits=34498, meanQ=31.394329, numObservations: 9
action 1, numVisits=4, meanQ=21.500000, numObservations: 3
action 3, numVisits=4, meanQ=21.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.804075 0.772711 0.309492 0.714141 0.601974 0.506111 0.23394 0.235155 0.345799 0.420616 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 87
Initial state: 0 0.892783 0.433628 0.33252 0.368583 0.0789459 0.862113 0.0177359 0.58201 0.546493 0.117455 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34298 episodes
GETTING ACTION FROM:
action 2, numVisits=34272, meanQ=32.303421, numObservations: 9
action 3, numVisits=21, meanQ=15.571429, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.892783 0.433628 0.33252 0.368583 0.0789459 0.862113 0.0177359 0.58201 0.546493 0.117455 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 88
Initial state: 0 0.0721046 0.39687 0.506676 0.623949 0.221998 0.415825 0.335208 0.470775 0.855719 0.303303 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33289 episodes
GETTING ACTION FROM:
action 1, numVisits=33281, meanQ=32.707544, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.0721046 0.39687 0.506676 0.623949 0.221998 0.415825 0.335208 0.470775 0.855719 0.303303 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 89
Initial state: 0 0.390659 0.344028 0.72711 0.884988 0.318963 0.350029 0.476612 0.00440792 0.467985 0.92303 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33888 episodes
GETTING ACTION FROM:
action 5, numVisits=33864, meanQ=31.290836, numObservations: 9
action 0, numVisits=10, meanQ=-1.010000, numObservations: 10
action -1, numVisits=10, meanQ=-1.208990, numObservations: 9
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.390659 0.344028 0.72711 0.884988 0.318963 0.350029 0.476612 0.00440792 0.467985 0.92303 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 90
Initial state: 0 0.324185 0.0367286 0.279918 0.527436 0.0947889 0.804478 0.229475 0.692552 0.89293 0.47963 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34311 episodes
GETTING ACTION FROM:
action 5, numVisits=34260, meanQ=30.934747, numObservations: 9
action 3, numVisits=42, meanQ=27.237860, numObservations: 8
action 1, numVisits=5, meanQ=19.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.324185 0.0367286 0.279918 0.527436 0.0947889 0.804478 0.229475 0.692552 0.89293 0.47963 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 91
Initial state: 0 0.547656 0.517804 0.243646 0.607114 0.0588953 0.843496 0.288654 0.366493 0.587462 0.31326 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34357 episodes
GETTING ACTION FROM:
action 2, numVisits=34351, meanQ=32.762443, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.547656 0.517804 0.243646 0.607114 0.0588953 0.843496 0.288654 0.366493 0.587462 0.31326 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 92
Initial state: 0 0.164335 0.245942 0.25846 0.361425 0.890566 0.587436 0.972274 0.526451 0.640541 0.175372 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34411 episodes
GETTING ACTION FROM:
action 4, numVisits=34340, meanQ=30.321646, numObservations: 9
action 1, numVisits=20, meanQ=21.999500, numObservations: 8
action 5, numVisits=47, meanQ=21.148513, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.164335 0.245942 0.25846 0.361425 0.890566 0.587436 0.972274 0.526451 0.640541 0.175372 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 93
Initial state: 0 0.00356833 0.994434 0.31407 0.136648 0.302215 0.512055 0.819427 0.697496 0.032214 0.669761 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33154 episodes
GETTING ACTION FROM:
action 5, numVisits=33138, meanQ=32.170317, numObservations: 9
action 1, numVisits=9, meanQ=5.996667, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.00356833 0.994434 0.31407 0.136648 0.302215 0.512055 0.819427 0.697496 0.032214 0.669761 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=1918, meanQ=48.007737, numObservations: 9
action 3, numVisits=3, meanQ=32.333333, numObservations: 3
action 4, numVisits=7, meanQ=26.284286, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 28350 episodes
GETTING ACTION FROM:
action 5, numVisits=30268, meanQ=59.774152, numObservations: 9
action 3, numVisits=3, meanQ=32.333333, numObservations: 3
action 4, numVisits=7, meanQ=26.284286, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.00356833 0.994434 0.31407 0.136648 0.302215 0.512055 0.819427 0.697496 0.032214 0.669761 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 94
Initial state: 0 0.497992 0.987159 0.279285 0.482889 0.766307 0.478747 0.685029 0.696467 0.841363 0.933425 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32956 episodes
GETTING ACTION FROM:
action 5, numVisits=32941, meanQ=32.001496, numObservations: 9
action 4, numVisits=5, meanQ=15.198000, numObservations: 4
action 2, numVisits=6, meanQ=10.665017, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.497992 0.987159 0.279285 0.482889 0.766307 0.478747 0.685029 0.696467 0.841363 0.933425 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 95
Initial state: 0 0.296493 0.453279 0.648899 0.40513 0.865739 0.168276 0.127015 0.224061 0.263768 0.22426 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31843 episodes
GETTING ACTION FROM:
action 5, numVisits=31834, meanQ=33.131105, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.296493 0.453279 0.648899 0.40513 0.865739 0.168276 0.127015 0.224061 0.263768 0.22426 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 96
Initial state: 0 0.535334 0.96639 0.335461 0.408077 0.0912742 0.780963 0.854046 0.363087 0.717975 0.00289171 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34093 episodes
GETTING ACTION FROM:
action 5, numVisits=34064, meanQ=31.221027, numObservations: 9
action 3, numVisits=21, meanQ=21.286190, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=4, meanQ=-6.000000, numObservations: 4
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.535334 0.96639 0.335461 0.408077 0.0912742 0.780963 0.854046 0.363087 0.717975 0.00289171 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 97
Initial state: 0 0.0191827 0.337556 0.212661 0.0930087 0.3529 0.357731 0.899424 0.421648 0.065032 0.4007 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33088 episodes
GETTING ACTION FROM:
action 1, numVisits=33077, meanQ=30.613369, numObservations: 9
action 4, numVisits=5, meanQ=19.000000, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.0191827 0.337556 0.212661 0.0930087 0.3529 0.357731 0.899424 0.421648 0.065032 0.4007 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=921, meanQ=44.045930, numObservations: 210
action 4, numVisits=13, meanQ=-5.456908, numObservations: 7
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action -1, numVisits=12, meanQ=-10.333325, numObservations: 10
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 5850 episodes
GETTING ACTION FROM:
action 0, numVisits=6771, meanQ=35.983937, numObservations: 243
action 4, numVisits=13, meanQ=-5.456908, numObservations: 7
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action -1, numVisits=12, meanQ=-10.333325, numObservations: 10
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.0191827 0.337556 0.212661 0.0930087 0.3529 0.357731 0.899424 0.421648 0.065032 0.4007 w: 1
Observation: 0 0 2 0 1 0 2 0 2 0 2 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=8, meanQ=6.614704, numObservations: 5
action 0, numVisits=5, meanQ=-1.010000, numObservations: 5
action 4, numVisits=3, meanQ=-7.856828, numObservations: 1
action -1, numVisits=3, meanQ=-8.070919, numObservations: 2
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 21982 episodes
GETTING ACTION FROM:
action 5, numVisits=21990, meanQ=46.484410, numObservations: 9
action 0, numVisits=5, meanQ=-1.010000, numObservations: 5
action 4, numVisits=3, meanQ=-7.856828, numObservations: 1
action -1, numVisits=3, meanQ=-8.070919, numObservations: 2
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.0191827 0.337556 0.212661 0.0930087 0.3529 0.357731 0.899424 0.421648 0.065032 0.4007 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -111.97
Run # 98
Initial state: 0 0.941028 0.324676 0.940663 0.183038 0.0551046 0.872166 0.711375 0.166648 0.349298 0.426204 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34327 episodes
GETTING ACTION FROM:
action 2, numVisits=34319, meanQ=32.026633, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=3, meanQ=-4.333333, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.941028 0.324676 0.940663 0.183038 0.0551046 0.872166 0.711375 0.166648 0.349298 0.426204 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 99
Initial state: 0 0.31243 0.410998 0.664311 0.677653 0.335232 0.14332 0.710478 0.0294214 0.26895 0.289182 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18241 episodes
GETTING ACTION FROM:
action -1, numVisits=18229, meanQ=60.603232, numObservations: 243
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=7, meanQ=-15.435714, numObservations: 6
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.31243 0.410998 0.664311 0.677653 0.335232 0.14332 0.710478 0.0294214 0.26895 0.289182 w: 1
Observation: 0 2 0 3 0 2 0 3 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=38, meanQ=31.026055, numObservations: 7
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37470 episodes
GETTING ACTION FROM:
action 3, numVisits=37508, meanQ=45.104512, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.31243 0.410998 0.664311 0.677653 0.335232 0.14332 0.710478 0.0294214 0.26895 0.289182 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=854, meanQ=77.614471, numObservations: 9
action 2, numVisits=4, meanQ=49.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 30104 episodes
GETTING ACTION FROM:
action 5, numVisits=30951, meanQ=47.552125, numObservations: 9
action 2, numVisits=11, meanQ=26.272727, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.31243 0.410998 0.664311 0.677653 0.335232 0.14332 0.710478 0.0294214 0.26895 0.289182 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -111.88
Run # 100
Initial state: 0 0.84186 0.998556 0.740859 0.845337 0.326733 0.451779 0.90459 0.348952 0.285391 0.584887 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34905 episodes
GETTING ACTION FROM:
action 3, numVisits=34899, meanQ=32.047076, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.84186 0.998556 0.740859 0.845337 0.326733 0.451779 0.90459 0.348952 0.285391 0.584887 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 101
Initial state: 0 0.0896885 0.702519 0.27759 0.373481 0.0269709 0.521053 0.226105 0.897 0.322638 0.937356 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34848 episodes
GETTING ACTION FROM:
action 4, numVisits=34816, meanQ=31.329934, numObservations: 9
action 1, numVisits=26, meanQ=16.268854, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.0896885 0.702519 0.27759 0.373481 0.0269709 0.521053 0.226105 0.897 0.322638 0.937356 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=129, meanQ=35.474032, numObservations: 9
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 3, numVisits=3, meanQ=-4.003333, numObservations: 3
action 1, numVisits=6, meanQ=-5.819983, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 31182 episodes
GETTING ACTION FROM:
action 5, numVisits=31311, meanQ=43.554286, numObservations: 9
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 3, numVisits=3, meanQ=-4.003333, numObservations: 3
action 1, numVisits=6, meanQ=-5.819983, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.0896885 0.702519 0.27759 0.373481 0.0269709 0.521053 0.226105 0.897 0.322638 0.937356 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -110.99
Run # 102
Initial state: 0 0.815726 0.266462 0.178706 0.50619 0.334548 0.395113 0.877569 0.345566 0.775675 0.557437 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34374 episodes
GETTING ACTION FROM:
action 2, numVisits=34330, meanQ=30.372611, numObservations: 9
action 5, numVisits=37, meanQ=17.351354, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.815726 0.266462 0.178706 0.50619 0.334548 0.395113 0.877569 0.345566 0.775675 0.557437 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=965, meanQ=40.408529, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 18278 episodes
GETTING ACTION FROM:
action 1, numVisits=19243, meanQ=30.026244, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.815726 0.266462 0.178706 0.50619 0.334548 0.395113 0.877569 0.345566 0.775675 0.557437 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -110.99
Run # 103
Initial state: 0 0.640892 0.725502 0.307984 0.359087 0.322049 0.193476 0.877291 0.615843 0.783306 0.391995 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18006 episodes
GETTING ACTION FROM:
action -1, numVisits=17984, meanQ=60.508646, numObservations: 243
action 0, numVisits=9, meanQ=-1.010000, numObservations: 9
action 4, numVisits=5, meanQ=-3.000000, numObservations: 4
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=3, meanQ=-34.333333, numObservations: 2
action 3, numVisits=3, meanQ=-34.333333, numObservations: 3
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.640892 0.725502 0.307984 0.359087 0.322049 0.193476 0.877291 0.615843 0.783306 0.391995 w: 1
Observation: 0 3 0 2 0 2 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=102, meanQ=44.559514, numObservations: 9
action 2, numVisits=57, meanQ=39.457019, numObservations: 9
action 5, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37742 episodes
GETTING ACTION FROM:
action 3, numVisits=37844, meanQ=45.706244, numObservations: 9
action 2, numVisits=57, meanQ=39.457019, numObservations: 9
action 5, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.640892 0.725502 0.307984 0.359087 0.322049 0.193476 0.877291 0.615843 0.783306 0.391995 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=1013, meanQ=75.699330, numObservations: 9
action 5, numVisits=3, meanQ=32.333333, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 41919 episodes
GETTING ACTION FROM:
action 3, numVisits=42932, meanQ=88.076105, numObservations: 9
action 5, numVisits=3, meanQ=32.333333, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 3
Next state: 0 0.640892 0.725502 0.307984 0.359087 0.322049 0.193476 0.877291 0.615843 0.783306 0.391995 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=136, meanQ=70.080956, numObservations: 4
action 5, numVisits=3, meanQ=32.333333, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 61843 episodes
GETTING ACTION FROM:
action 1, numVisits=61979, meanQ=49.206459, numObservations: 9
action 5, numVisits=3, meanQ=32.333333, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.640892 0.725502 0.307984 0.359087 0.322049 0.193476 0.877291 0.615843 0.783306 0.391995 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 72.3885
Run # 104
Initial state: 0 0.138724 0.508491 0.572875 0.736687 0.399273 0.742839 0.488552 0.217505 0.288972 0.520767 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32877 episodes
GETTING ACTION FROM:
action 1, numVisits=32863, meanQ=32.191775, numObservations: 9
action 4, numVisits=8, meanQ=24.000000, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.138724 0.508491 0.572875 0.736687 0.399273 0.742839 0.488552 0.217505 0.288972 0.520767 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=908, meanQ=38.006907, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=3, meanQ=-4.003333, numObservations: 2
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 18377 episodes
GETTING ACTION FROM:
action 3, numVisits=19285, meanQ=33.605004, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=3, meanQ=-4.003333, numObservations: 2
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.138724 0.508491 0.572875 0.736687 0.399273 0.742839 0.488552 0.217505 0.288972 0.520767 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 105
Initial state: 0 0.179845 0.778737 0.0939643 0.110781 0.265004 0.437465 0.105923 0.0831834 0.494946 0.278597 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34805 episodes
GETTING ACTION FROM:
action 3, numVisits=34760, meanQ=30.626020, numObservations: 9
action 4, numVisits=37, meanQ=18.268657, numObservations: 8
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.179845 0.778737 0.0939643 0.110781 0.265004 0.437465 0.105923 0.0831834 0.494946 0.278597 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 106
Initial state: 0 0.14302 0.491156 0.32475 0.506815 0.422612 0.236439 0.892342 0.711414 0.57543 0.863106 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33458 episodes
GETTING ACTION FROM:
action 2, numVisits=33404, meanQ=31.779317, numObservations: 9
action 5, numVisits=43, meanQ=18.813491, numObservations: 8
action 4, numVisits=6, meanQ=14.000000, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.14302 0.491156 0.32475 0.506815 0.422612 0.236439 0.892342 0.711414 0.57543 0.863106 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 107
Initial state: 0 0.800338 0.21765 0.127722 0.971347 0.780873 0.800112 0.358087 0.16314 0.331807 0.514264 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34225 episodes
GETTING ACTION FROM:
action 3, numVisits=34214, meanQ=32.175564, numObservations: 9
action 2, numVisits=6, meanQ=14.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.800338 0.21765 0.127722 0.971347 0.780873 0.800112 0.358087 0.16314 0.331807 0.514264 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 108
Initial state: 0 0.818982 0.65352 0.683306 0.160961 0.271056 0.410276 0.737009 0.00115143 0.147995 0.0457528 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34112 episodes
GETTING ACTION FROM:
action 4, numVisits=34080, meanQ=30.897244, numObservations: 9
action 1, numVisits=22, meanQ=24.863636, numObservations: 7
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=4, meanQ=-6.000000, numObservations: 3
action: 4
Next state: 0 0.818982 0.65352 0.683306 0.160961 0.271056 0.410276 0.737009 0.00115143 0.147995 0.0457528 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=693, meanQ=43.785267, numObservations: 9
action 2, numVisits=4, meanQ=21.747500, numObservations: 3
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 34381 episodes
GETTING ACTION FROM:
action 3, numVisits=35065, meanQ=17.254956, numObservations: 9
action 2, numVisits=11, meanQ=5.741654, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.818982 0.65352 0.683306 0.160961 0.271056 0.410276 0.737009 0.00115143 0.147995 0.0457528 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 109
Initial state: 0 0.764457 0.938202 0.357604 0.422178 0.194318 0.368362 0.44879 0.0101079 0.445245 0.133748 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33347 episodes
GETTING ACTION FROM:
action 4, numVisits=33328, meanQ=31.689147, numObservations: 9
action 3, numVisits=5, meanQ=19.000000, numObservations: 3
action 1, numVisits=10, meanQ=17.000000, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.764457 0.938202 0.357604 0.422178 0.194318 0.368362 0.44879 0.0101079 0.445245 0.133748 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 110
Initial state: 0 0.63127 0.756447 0.523587 0.94094 0.276995 0.523888 0.89492 0.711786 0.578843 0.191129 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34315 episodes
GETTING ACTION FROM:
action 3, numVisits=34255, meanQ=32.137789, numObservations: 9
action 2, numVisits=55, meanQ=30.368736, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.63127 0.756447 0.523587 0.94094 0.276995 0.523888 0.89492 0.711786 0.578843 0.191129 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 111
Initial state: 0 0.300866 0.490491 0.284895 0.547378 0.1191 0.550728 0.426774 0.62353 0.821423 0.852955 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33377 episodes
GETTING ACTION FROM:
action 2, numVisits=33363, meanQ=31.840509, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=7, meanQ=-2.287143, numObservations: 5
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.300866 0.490491 0.284895 0.547378 0.1191 0.550728 0.426774 0.62353 0.821423 0.852955 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 112
Initial state: 0 0.486619 0.994464 0.270296 0.352411 0.447952 0.538623 0.285685 0.634849 0.57978 0.814436 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33425 episodes
GETTING ACTION FROM:
action 5, numVisits=33410, meanQ=31.933213, numObservations: 9
action 4, numVisits=8, meanQ=-1.000000, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=3, meanQ=-7.663333, numObservations: 2
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.486619 0.994464 0.270296 0.352411 0.447952 0.538623 0.285685 0.634849 0.57978 0.814436 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 113
Initial state: 0 0.836257 0.643867 0.797467 0.745927 0.32118 0.410522 0.785676 0.688287 0.113399 0.670439 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33678 episodes
GETTING ACTION FROM:
action 1, numVisits=33657, meanQ=30.367143, numObservations: 9
action 5, numVisits=12, meanQ=22.334167, numObservations: 4
action 3, numVisits=4, meanQ=21.747500, numObservations: 4
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.836257 0.643867 0.797467 0.745927 0.32118 0.410522 0.785676 0.688287 0.113399 0.670439 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 114
Initial state: 0 0.805415 0.213173 0.319919 0.401426 0.671615 0.79537 0.620766 0.109792 0.600494 0.172649 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32787 episodes
GETTING ACTION FROM:
action 1, numVisits=32757, meanQ=31.165589, numObservations: 9
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 5, numVisits=11, meanQ=-1.909091, numObservations: 5
action 3, numVisits=9, meanQ=-4.444433, numObservations: 4
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.805415 0.213173 0.319919 0.401426 0.671615 0.79537 0.620766 0.109792 0.600494 0.172649 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 115
Initial state: 0 0.38538 0.261046 0.175761 0.820854 0.26791 0.474288 0.929995 0.54999 0.463842 0.496633 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34107 episodes
GETTING ACTION FROM:
action 3, numVisits=34100, meanQ=33.023169, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.38538 0.261046 0.175761 0.820854 0.26791 0.474288 0.929995 0.54999 0.463842 0.496633 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 116
Initial state: 0 0.927052 0.302687 0.420003 0.0278969 0.266333 0.501936 0.64087 0.555972 0.132384 0.765321 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33566 episodes
GETTING ACTION FROM:
action 2, numVisits=33542, meanQ=32.079018, numObservations: 9
action 3, numVisits=15, meanQ=23.798667, numObservations: 7
action 4, numVisits=5, meanQ=19.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.927052 0.302687 0.420003 0.0278969 0.266333 0.501936 0.64087 0.555972 0.132384 0.765321 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 117
Initial state: 0 0.387595 0.344787 0.15324 0.776889 0.314995 0.843154 0.338866 0.479635 0.744592 0.943969 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18243 episodes
GETTING ACTION FROM:
action -1, numVisits=18235, meanQ=61.303900, numObservations: 243
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.387595 0.344787 0.15324 0.776889 0.314995 0.843154 0.338866 0.479635 0.744592 0.943969 w: 1
Observation: 0 3 0 1 0 1 0 2 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=82, meanQ=83.194272, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 38251 episodes
GETTING ACTION FROM:
action 4, numVisits=38333, meanQ=78.285710, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.387595 0.344787 0.15324 0.776889 0.314995 0.843154 0.338866 0.479635 0.744592 0.943969 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 118
Initial state: 0 0.595014 0.984471 0.136922 0.315112 0.350381 0.364395 0.73873 0.311305 0.758474 0.85681 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30786 episodes
GETTING ACTION FROM:
action 4, numVisits=30722, meanQ=31.871858, numObservations: 9
action 2, numVisits=57, meanQ=18.052458, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=3, meanQ=-4.333333, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.595014 0.984471 0.136922 0.315112 0.350381 0.364395 0.73873 0.311305 0.758474 0.85681 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 119
Initial state: 0 0.190368 0.173405 0.22762 0.132077 0.196987 0.644892 0.582471 0.635997 0.266681 0.433674 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34221 episodes
GETTING ACTION FROM:
action 3, numVisits=34214, meanQ=30.974664, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.190368 0.173405 0.22762 0.132077 0.196987 0.644892 0.582471 0.635997 0.266681 0.433674 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=2008, meanQ=37.682090, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37613 episodes
GETTING ACTION FROM:
action 5, numVisits=39621, meanQ=40.827899, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.190368 0.173405 0.22762 0.132077 0.196987 0.644892 0.582471 0.635997 0.266681 0.433674 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 120
Initial state: 0 0.470361 0.287894 0.277419 0.451656 0.985133 0.873915 0.190468 0.731821 0.603361 0.652753 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18124 episodes
GETTING ACTION FROM:
action -1, numVisits=18055, meanQ=58.661020, numObservations: 243
action 3, numVisits=42, meanQ=-0.995948, numObservations: 9
action 0, numVisits=18, meanQ=-1.120550, numObservations: 17
action 1, numVisits=4, meanQ=-6.000000, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=3, meanQ=-34.333333, numObservations: 2
action: -1
Next state: 0 0.470361 0.287894 0.277419 0.451656 0.985133 0.873915 0.190468 0.731821 0.603361 0.652753 w: 1
Observation: 0 3 0 2 0 3 0 1 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=201, meanQ=86.582589, numObservations: 9
action 3, numVisits=6, meanQ=32.333333, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 38704 episodes
GETTING ACTION FROM:
action 2, numVisits=38905, meanQ=91.068256, numObservations: 9
action 3, numVisits=6, meanQ=32.333333, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.470361 0.287894 0.277419 0.451656 0.985133 0.873915 0.190468 0.731821 0.603361 0.652753 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 121
Initial state: 0 0.359083 0.891628 0.815473 0.797801 0.290768 0.450148 0.235699 0.663049 0.0547551 0.94444 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34258 episodes
GETTING ACTION FROM:
action 5, numVisits=34248, meanQ=31.556452, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.359083 0.891628 0.815473 0.797801 0.290768 0.450148 0.235699 0.663049 0.0547551 0.94444 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1959, meanQ=33.870499, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 38069 episodes
GETTING ACTION FROM:
action 1, numVisits=40028, meanQ=45.954884, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.359083 0.891628 0.815473 0.797801 0.290768 0.450148 0.235699 0.663049 0.0547551 0.94444 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 122
Initial state: 0 0.606598 0.700143 0.618975 0.607518 0.0233864 0.61385 0.368903 0.964688 0.320044 0.512544 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32626 episodes
GETTING ACTION FROM:
action 1, numVisits=32585, meanQ=33.140151, numObservations: 9
action 4, numVisits=28, meanQ=22.214286, numObservations: 8
action 5, numVisits=5, meanQ=19.000000, numObservations: 3
action 2, numVisits=5, meanQ=15.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.606598 0.700143 0.618975 0.607518 0.0233864 0.61385 0.368903 0.964688 0.320044 0.512544 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 123
Initial state: 0 0.616497 0.115355 0.644404 0.924191 0.731121 0.940102 0.248769 0.617249 0.342894 0.496834 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34232 episodes
GETTING ACTION FROM:
action 4, numVisits=34223, meanQ=31.648133, numObservations: 9
action 1, numVisits=4, meanQ=16.497525, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.616497 0.115355 0.644404 0.924191 0.731121 0.940102 0.248769 0.617249 0.342894 0.496834 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=1956, meanQ=37.637262, numObservations: 9
action 1, numVisits=11, meanQ=22.996364, numObservations: 7
action 2, numVisits=4, meanQ=21.747500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 36748 episodes
GETTING ACTION FROM:
action 5, numVisits=38704, meanQ=43.109901, numObservations: 9
action 1, numVisits=11, meanQ=22.996364, numObservations: 7
action 2, numVisits=4, meanQ=21.747500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 5
Next state: 1 0.616497 0.115355 0.644404 0.924191 0.731121 0.940102 0.248769 0.617249 0.342894 0.496834 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 124
Initial state: 0 0.667853 0.258997 0.10272 0.367306 0.279014 0.382451 0.971781 0.0228836 0.126372 0.689286 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33528 episodes
GETTING ACTION FROM:
action 5, numVisits=33514, meanQ=31.177257, numObservations: 9
action 2, numVisits=8, meanQ=10.250000, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.667853 0.258997 0.10272 0.367306 0.279014 0.382451 0.971781 0.0228836 0.126372 0.689286 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=1951, meanQ=37.498986, numObservations: 9
action 2, numVisits=6, meanQ=-1.000000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 37151 episodes
GETTING ACTION FROM:
action 4, numVisits=39102, meanQ=34.734434, numObservations: 9
action 2, numVisits=6, meanQ=-1.000000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 4
Next state: 2 0.667853 0.258997 0.10272 0.367306 0.279014 0.382451 0.971781 0.0228836 0.126372 0.689286 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -110.99
Run # 125
Initial state: 0 0.278903 0.920652 0.802745 0.283489 0.191043 0.923639 0.0857111 0.441132 0.306109 0.501336 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33551 episodes
GETTING ACTION FROM:
action 3, numVisits=33541, meanQ=31.360473, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.278903 0.920652 0.802745 0.283489 0.191043 0.923639 0.0857111 0.441132 0.306109 0.501336 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 126
Initial state: 0 0.750446 0.656989 0.273948 0.250642 0.938091 0.71414 0.479663 0.0053596 0.291462 0.475568 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33927 episodes
GETTING ACTION FROM:
action 1, numVisits=33898, meanQ=32.442416, numObservations: 9
action 0, numVisits=12, meanQ=-1.010000, numObservations: 12
action -1, numVisits=10, meanQ=-1.406000, numObservations: 8
action 2, numVisits=4, meanQ=-6.000000, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.750446 0.656989 0.273948 0.250642 0.938091 0.71414 0.479663 0.0053596 0.291462 0.475568 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 127
Initial state: 0 0.965193 0.987889 0.116664 0.335249 0.324366 0.42129 0.232767 0.554643 0.0438443 0.369641 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33304 episodes
GETTING ACTION FROM:
action 5, numVisits=33279, meanQ=32.804145, numObservations: 9
action 1, numVisits=7, meanQ=26.142857, numObservations: 5
action 4, numVisits=14, meanQ=26.071436, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.965193 0.987889 0.116664 0.335249 0.324366 0.42129 0.232767 0.554643 0.0438443 0.369641 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 128
Initial state: 0 0.991723 0.416794 0.340805 0.45689 0.375286 0.316781 0.39344 0.38788 0.101011 0.452151 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34088 episodes
GETTING ACTION FROM:
action 1, numVisits=34072, meanQ=30.733438, numObservations: 9
action 2, numVisits=4, meanQ=21.500000, numObservations: 4
action 4, numVisits=7, meanQ=13.285714, numObservations: 4
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.991723 0.416794 0.340805 0.45689 0.375286 0.316781 0.39344 0.38788 0.101011 0.452151 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 129
Initial state: 0 0.501314 0.269943 0.288794 0.472188 0.465983 0.341047 0.524885 0.151108 0.549755 0.356587 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34329 episodes
GETTING ACTION FROM:
action 2, numVisits=34310, meanQ=31.923472, numObservations: 9
action 3, numVisits=14, meanQ=3.999293, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.501314 0.269943 0.288794 0.472188 0.465983 0.341047 0.524885 0.151108 0.549755 0.356587 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 130
Initial state: 0 0.969586 0.106951 0.512114 0.476353 0.266975 0.50711 0.136919 0.66302 0.406772 0.232358 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34591 episodes
GETTING ACTION FROM:
action 2, numVisits=34572, meanQ=30.536068, numObservations: 9
action 4, numVisits=7, meanQ=13.285714, numObservations: 5
action 3, numVisits=7, meanQ=10.570000, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.969586 0.106951 0.512114 0.476353 0.266975 0.50711 0.136919 0.66302 0.406772 0.232358 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 131
Initial state: 0 0.614995 0.316098 0.276973 0.482371 0.743612 0.195317 0.846602 0.171845 0.840293 0.581758 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33421 episodes
GETTING ACTION FROM:
action 4, numVisits=33402, meanQ=31.283364, numObservations: 9
action 3, numVisits=14, meanQ=11.857143, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.614995 0.316098 0.276973 0.482371 0.743612 0.195317 0.846602 0.171845 0.840293 0.581758 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 132
Initial state: 0 0.301333 0.464236 0.854217 0.511522 0.0487553 0.42397 0.342737 0.173697 0.192808 0.232449 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34169 episodes
GETTING ACTION FROM:
action 3, numVisits=34153, meanQ=30.842710, numObservations: 9
action 1, numVisits=9, meanQ=20.111111, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.301333 0.464236 0.854217 0.511522 0.0487553 0.42397 0.342737 0.173697 0.192808 0.232449 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=951, meanQ=35.465892, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 4, numVisits=5, meanQ=-2.802000, numObservations: 4
action 5, numVisits=8, meanQ=-3.252500, numObservations: 7
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 15455 episodes
GETTING ACTION FROM:
action 1, numVisits=16406, meanQ=28.247151, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 4, numVisits=5, meanQ=-2.802000, numObservations: 4
action 5, numVisits=8, meanQ=-3.252500, numObservations: 7
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.301333 0.464236 0.854217 0.511522 0.0487553 0.42397 0.342737 0.173697 0.192808 0.232449 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 133
Initial state: 0 0.26763 0.339307 0.171942 0.456609 0.563904 0.76522 0.422832 0.980006 0.578335 0.217174 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33066 episodes
GETTING ACTION FROM:
action 3, numVisits=33044, meanQ=29.786459, numObservations: 9
action 1, numVisits=4, meanQ=-1.000000, numObservations: 4
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=9, meanQ=-2.001111, numObservations: 6
action 2, numVisits=5, meanQ=-3.000000, numObservations: 4
action: 3
Next state: 1 0.26763 0.339307 0.171942 0.456609 0.563904 0.76522 0.422832 0.980006 0.578335 0.217174 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 134
Initial state: 0 0.0744588 0.255461 0.895942 0.0201858 0.0376462 0.184261 0.285121 0.428873 0.48112 0.123777 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34416 episodes
GETTING ACTION FROM:
action 3, numVisits=34410, meanQ=32.149277, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.0744588 0.255461 0.895942 0.0201858 0.0376462 0.184261 0.285121 0.428873 0.48112 0.123777 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1744, meanQ=37.548103, numObservations: 9
action 5, numVisits=15, meanQ=10.531333, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 14385 episodes
GETTING ACTION FROM:
action 1, numVisits=16129, meanQ=32.492732, numObservations: 9
action 5, numVisits=15, meanQ=10.531333, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.0744588 0.255461 0.895942 0.0201858 0.0376462 0.184261 0.285121 0.428873 0.48112 0.123777 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action -1, numVisits=535, meanQ=51.864139, numObservations: 93
action 0, numVisits=5, meanQ=-1.010000, numObservations: 5
action 2, numVisits=6, meanQ=-4.003333, numObservations: 5
action 4, numVisits=6, meanQ=-4.003333, numObservations: 5
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 3890 episodes
GETTING ACTION FROM:
action -1, numVisits=4425, meanQ=32.933939, numObservations: 216
action 0, numVisits=5, meanQ=-1.010000, numObservations: 5
action 2, numVisits=6, meanQ=-4.003333, numObservations: 5
action 4, numVisits=6, meanQ=-4.003333, numObservations: 5
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.0744588 0.255461 0.895942 0.0201858 0.0376462 0.184261 0.285121 0.428873 0.48112 0.123777 w: 1
Observation: 0 1 0 3 0 1 0 2 0 3 0 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 4, numVisits=17, meanQ=85.310822, numObservations: 5
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-17.269230, numObservations: 1
Sampled 38098 episodes
GETTING ACTION FROM:
action 4, numVisits=38115, meanQ=79.940763, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-17.269230, numObservations: 1
action: 4
Next state: 1 0.0744588 0.255461 0.895942 0.0201858 0.0376462 0.184261 0.285121 0.428873 0.48112 0.123777 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 72.2094
Run # 135
Initial state: 0 0.312009 0.367256 0.558185 0.760543 0.554835 0.795524 0.597016 0.469325 0.336903 0.967481 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33388 episodes
GETTING ACTION FROM:
action 3, numVisits=33375, meanQ=31.519389, numObservations: 9
action 4, numVisits=5, meanQ=19.000000, numObservations: 3
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.312009 0.367256 0.558185 0.760543 0.554835 0.795524 0.597016 0.469325 0.336903 0.967481 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 136
Initial state: 0 0.887134 0.841385 0.295648 0.680804 0.954074 0.469924 0.0389685 0.355065 0.276124 0.414694 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18460 episodes
GETTING ACTION FROM:
action 0, numVisits=18414, meanQ=64.650920, numObservations: 243
action -1, numVisits=36, meanQ=-1.395825, numObservations: 29
action 1, numVisits=6, meanQ=-4.333333, numObservations: 4
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.887134 0.841385 0.295648 0.680804 0.954074 0.469924 0.0389685 0.355065 0.276124 0.414694 w: 1
Observation: 0 0 3 0 3 0 2 0 2 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=72, meanQ=67.792639, numObservations: 8
action 3, numVisits=3, meanQ=32.333333, numObservations: 3
action 5, numVisits=7, meanQ=26.284286, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 35305 episodes
GETTING ACTION FROM:
action 2, numVisits=35377, meanQ=70.201447, numObservations: 9
action 3, numVisits=3, meanQ=32.333333, numObservations: 3
action 5, numVisits=7, meanQ=26.284286, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.887134 0.841385 0.295648 0.680804 0.954074 0.469924 0.0389685 0.355065 0.276124 0.414694 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101.99
Run # 137
Initial state: 0 0.342426 0.423399 0.396931 0.392891 0.837317 0.635949 0.764303 0.901299 0.838901 0.677229 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32701 episodes
GETTING ACTION FROM:
action 1, numVisits=32695, meanQ=31.830855, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.342426 0.423399 0.396931 0.392891 0.837317 0.635949 0.764303 0.901299 0.838901 0.677229 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 138
Initial state: 0 0.330273 0.98804 0.271747 0.169007 0.00592033 0.314735 0.1751 0.273771 0.311778 0.376735 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34022 episodes
GETTING ACTION FROM:
action 3, numVisits=34012, meanQ=32.477080, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.330273 0.98804 0.271747 0.169007 0.00592033 0.314735 0.1751 0.273771 0.311778 0.376735 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=1817, meanQ=38.651898, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 12002 episodes
GETTING ACTION FROM:
action 4, numVisits=13819, meanQ=34.150216, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.330273 0.98804 0.271747 0.169007 0.00592033 0.314735 0.1751 0.273771 0.311778 0.376735 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=598, meanQ=35.728806, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=5, meanQ=-2.802000, numObservations: 5
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 9843 episodes
GETTING ACTION FROM:
action 1, numVisits=10441, meanQ=30.756297, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=5, meanQ=-2.802000, numObservations: 5
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.330273 0.98804 0.271747 0.169007 0.00592033 0.314735 0.1751 0.273771 0.311778 0.376735 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 75.1399
Run # 139
Initial state: 0 0.275948 0.513924 0.49342 0.936248 0.023043 0.675806 0.881871 0.176301 0.87873 0.127514 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32723 episodes
GETTING ACTION FROM:
action 1, numVisits=32498, meanQ=33.945327, numObservations: 9
action 3, numVisits=152, meanQ=29.140268, numObservations: 9
action 2, numVisits=68, meanQ=28.680007, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.275948 0.513924 0.49342 0.936248 0.023043 0.675806 0.881871 0.176301 0.87873 0.127514 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 140
Initial state: 0 0.603088 0.90073 0.879852 0.973998 0.358352 0.528161 0.125052 0.613329 0.469982 0.700893 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18161 episodes
GETTING ACTION FROM:
action -1, numVisits=18123, meanQ=61.828342, numObservations: 242
action 0, numVisits=12, meanQ=-1.175825, numObservations: 11
action 3, numVisits=20, meanQ=-2.000000, numObservations: 7
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.603088 0.90073 0.879852 0.973998 0.358352 0.528161 0.125052 0.613329 0.469982 0.700893 w: 1
Observation: 0 3 0 3 0 2 0 1 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=161, meanQ=86.230374, numObservations: 9
action 2, numVisits=36, meanQ=42.888614, numObservations: 5
action 4, numVisits=5, meanQ=37.198000, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 38737 episodes
GETTING ACTION FROM:
action 3, numVisits=38898, meanQ=90.233465, numObservations: 9
action 2, numVisits=36, meanQ=42.888614, numObservations: 5
action 4, numVisits=5, meanQ=37.198000, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 3
Next state: 1 0.603088 0.90073 0.879852 0.973998 0.358352 0.528161 0.125052 0.613329 0.469982 0.700893 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 141
Initial state: 0 0.729709 0.0811348 0.725114 0.249425 0.320264 0.827718 0.345576 0.357428 0.912802 0.505588 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33214 episodes
GETTING ACTION FROM:
action 5, numVisits=33203, meanQ=33.221638, numObservations: 9
action 4, numVisits=6, meanQ=14.165000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.729709 0.0811348 0.725114 0.249425 0.320264 0.827718 0.345576 0.357428 0.912802 0.505588 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 142
Initial state: 0 0.281419 0.503168 0.969872 0.856043 0.771017 0.45325 0.973785 0.508584 0.778808 0.628553 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34370 episodes
GETTING ACTION FROM:
action 3, numVisits=34333, meanQ=31.642936, numObservations: 9
action 2, numVisits=32, meanQ=12.409066, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.281419 0.503168 0.969872 0.856043 0.771017 0.45325 0.973785 0.508584 0.778808 0.628553 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 143
Initial state: 0 0.682374 0.560181 0.905053 0.964577 0.293647 0.471306 0.215998 0.0857956 0.974354 0.825742 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33895 episodes
GETTING ACTION FROM:
action 3, numVisits=33871, meanQ=30.970004, numObservations: 9
action 4, numVisits=16, meanQ=8.999381, numObservations: 8
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.682374 0.560181 0.905053 0.964577 0.293647 0.471306 0.215998 0.0857956 0.974354 0.825742 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 144
Initial state: 0 0.581671 0.954362 0.889376 0.631353 0.303707 0.464157 0.637884 0.0359875 0.42286 0.69299 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17834 episodes
GETTING ACTION FROM:
action -1, numVisits=17810, meanQ=62.879400, numObservations: 243
action 0, numVisits=19, meanQ=-1.010000, numObservations: 19
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.581671 0.954362 0.889376 0.631353 0.303707 0.464157 0.637884 0.0359875 0.42286 0.69299 w: 1
Observation: 0 3 0 3 0 2 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=514, meanQ=90.820157, numObservations: 9
action 4, numVisits=2, meanQ=44.495000, numObservations: 2
action 1, numVisits=3, meanQ=32.333333, numObservations: 2
action 2, numVisits=3, meanQ=32.333333, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 38807 episodes
GETTING ACTION FROM:
action 3, numVisits=39321, meanQ=92.311052, numObservations: 9
action 4, numVisits=2, meanQ=44.495000, numObservations: 2
action 1, numVisits=3, meanQ=32.333333, numObservations: 2
action 2, numVisits=3, meanQ=32.333333, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.581671 0.954362 0.889376 0.631353 0.303707 0.464157 0.637884 0.0359875 0.42286 0.69299 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 145
Initial state: 0 0.974197 0.883586 0.640824 0.637799 0.312787 0.510944 0.942714 0.222704 0.164862 0.104139 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17925 episodes
GETTING ACTION FROM:
action -1, numVisits=17908, meanQ=64.156933, numObservations: 243
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 1, numVisits=3, meanQ=-4.333333, numObservations: 2
action 3, numVisits=3, meanQ=-4.333333, numObservations: 3
action 5, numVisits=3, meanQ=-34.333333, numObservations: 2
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.974197 0.883586 0.640824 0.637799 0.312787 0.510944 0.942714 0.222704 0.164862 0.104139 w: 1
Observation: 0 3 0 3 0 1 0 3 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=57, meanQ=21.490877, numObservations: 8
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 40488 episodes
GETTING ACTION FROM:
action 4, numVisits=40545, meanQ=18.245278, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.974197 0.883586 0.640824 0.637799 0.312787 0.510944 0.942714 0.222704 0.164862 0.104139 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101.99
Run # 146
Initial state: 0 0.056025 0.253436 0.320347 0.436669 0.0988175 0.642544 0.424241 0.906069 0.197803 0.669007 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32894 episodes
GETTING ACTION FROM:
action 1, numVisits=32880, meanQ=31.965023, numObservations: 9
action 3, numVisits=4, meanQ=-1.000000, numObservations: 3
action 4, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.056025 0.253436 0.320347 0.436669 0.0988175 0.642544 0.424241 0.906069 0.197803 0.669007 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=1686, meanQ=57.031934, numObservations: 211
action -1, numVisits=12, meanQ=-2.084150, numObservations: 10
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 4150 episodes
GETTING ACTION FROM:
action 0, numVisits=5836, meanQ=46.274080, numObservations: 242
action -1, numVisits=12, meanQ=-2.084150, numObservations: 10
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.056025 0.253436 0.320347 0.436669 0.0988175 0.642544 0.424241 0.906069 0.197803 0.669007 w: 1
Observation: 0 0 1 0 2 0 3 0 3 0 3 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=44, meanQ=78.879210, numObservations: 7
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 12444 episodes
GETTING ACTION FROM:
action 5, numVisits=12488, meanQ=60.770540, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.056025 0.253436 0.320347 0.436669 0.0988175 0.642544 0.424241 0.906069 0.197803 0.669007 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=2932, meanQ=95.046400, numObservations: 9
action 3, numVisits=4, meanQ=49.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-16.746504, numObservations: 1
action 5, numVisits=1, meanQ=-17.481014, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 33934 episodes
GETTING ACTION FROM:
action 2, numVisits=36866, meanQ=93.603087, numObservations: 9
action 3, numVisits=4, meanQ=49.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-16.746504, numObservations: 1
action 5, numVisits=1, meanQ=-17.481014, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.056025 0.253436 0.320347 0.436669 0.0988175 0.642544 0.424241 0.906069 0.197803 0.669007 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 72.2985
Run # 147
Initial state: 0 0.941551 0.772836 0.731759 0.109163 0.345154 0.499796 0.0152716 0.608721 0.61965 0.782958 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32612 episodes
GETTING ACTION FROM:
action 3, numVisits=32601, meanQ=32.483398, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=3, meanQ=-34.333333, numObservations: 3
action: 3
Next state: 1 0.941551 0.772836 0.731759 0.109163 0.345154 0.499796 0.0152716 0.608721 0.61965 0.782958 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 148
Initial state: 0 0.11713 0.342675 0.663859 0.846445 0.619423 0.83321 0.30416 0.510389 0.520724 0.832117 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34897 episodes
GETTING ACTION FROM:
action 4, numVisits=34882, meanQ=31.629274, numObservations: 9
action 1, numVisits=10, meanQ=6.000000, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.11713 0.342675 0.663859 0.846445 0.619423 0.83321 0.30416 0.510389 0.520724 0.832117 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 149
Initial state: 0 0.425463 0.592311 0.297358 0.516585 0.24301 0.279208 0.832703 0.0749952 0.00443124 0.381197 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18097 episodes
GETTING ACTION FROM:
action -1, numVisits=18076, meanQ=60.066028, numObservations: 243
action 0, numVisits=11, meanQ=-1.010000, numObservations: 11
action 2, numVisits=6, meanQ=-4.333333, numObservations: 4
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.425463 0.592311 0.297358 0.516585 0.24301 0.279208 0.832703 0.0749952 0.00443124 0.381197 w: 1
Observation: 0 3 0 2 0 2 0 3 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=71, meanQ=47.140566, numObservations: 9
action 4, numVisits=6, meanQ=14.165000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37242 episodes
GETTING ACTION FROM:
action 3, numVisits=37313, meanQ=53.844722, numObservations: 9
action 4, numVisits=6, meanQ=14.165000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.425463 0.592311 0.297358 0.516585 0.24301 0.279208 0.832703 0.0749952 0.00443124 0.381197 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=1313, meanQ=91.260461, numObservations: 9
action 4, numVisits=5, meanQ=59.000000, numObservations: 2
action 5, numVisits=2, meanQ=44.495000, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 40181 episodes
GETTING ACTION FROM:
action 2, numVisits=41494, meanQ=85.310393, numObservations: 9
action 4, numVisits=5, meanQ=59.000000, numObservations: 2
action 5, numVisits=2, meanQ=44.495000, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 2
Next state: 1 0.425463 0.592311 0.297358 0.516585 0.24301 0.279208 0.832703 0.0749952 0.00443124 0.381197 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 84.1399
Run # 150
Initial state: 0 0.538378 0.567937 0.652589 0.14559 0.285677 0.400772 0.552787 0.878858 0.804477 0.84218 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34149 episodes
GETTING ACTION FROM:
action 2, numVisits=34138, meanQ=31.352413, numObservations: 9
action 4, numVisits=5, meanQ=19.000000, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.538378 0.567937 0.652589 0.14559 0.285677 0.400772 0.552787 0.878858 0.804477 0.84218 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 151
Initial state: 0 0.566478 0.292835 0.422526 0.453371 0.192627 0.102368 0.262658 0.466689 0.628618 0.173217 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33075 episodes
GETTING ACTION FROM:
action 5, numVisits=33061, meanQ=31.525916, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=7, meanQ=-2.428571, numObservations: 5
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.566478 0.292835 0.422526 0.453371 0.192627 0.102368 0.262658 0.466689 0.628618 0.173217 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 152
Initial state: 0 0.503144 0.22739 0.510436 0.00760494 0.356259 0.495342 0.105048 0.298294 0.87905 0.728015 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18276 episodes
GETTING ACTION FROM:
action -1, numVisits=18241, meanQ=62.870981, numObservations: 243
action 3, numVisits=24, meanQ=-1.833333, numObservations: 7
action 0, numVisits=7, meanQ=-15.435714, numObservations: 6
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.503144 0.22739 0.510436 0.00760494 0.356259 0.495342 0.105048 0.298294 0.87905 0.728015 w: 1
Observation: 0 3 0 3 0 2 0 1 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=160, meanQ=17.806064, numObservations: 9
action 5, numVisits=44, meanQ=5.203864, numObservations: 7
action 2, numVisits=17, meanQ=3.822353, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 40920 episodes
GETTING ACTION FROM:
action 1, numVisits=41080, meanQ=10.488452, numObservations: 9
action 5, numVisits=44, meanQ=5.203864, numObservations: 7
action 2, numVisits=17, meanQ=3.822353, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 1
Next state: 2 0.503144 0.22739 0.510436 0.00760494 0.356259 0.495342 0.105048 0.298294 0.87905 0.728015 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101.99
Run # 153
Initial state: 0 0.922681 0.665749 0.114967 0.616143 0.266393 0.656787 0.303353 0.510969 0.886164 0.548759 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34320 episodes
GETTING ACTION FROM:
action 1, numVisits=34311, meanQ=31.298117, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=4, meanQ=-6.000000, numObservations: 4
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.922681 0.665749 0.114967 0.616143 0.266393 0.656787 0.303353 0.510969 0.886164 0.548759 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 154
Initial state: 0 0.345415 0.424529 0.141198 0.786624 0.559787 0.134201 0.222475 0.780209 0.998147 0.773298 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34212 episodes
GETTING ACTION FROM:
action 5, numVisits=34160, meanQ=31.720503, numObservations: 9
action 2, numVisits=17, meanQ=27.351765, numObservations: 9
action 3, numVisits=31, meanQ=26.454197, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.345415 0.424529 0.141198 0.786624 0.559787 0.134201 0.222475 0.780209 0.998147 0.773298 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 155
Initial state: 0 0.128635 0.806222 0.527571 0.801212 0.255887 0.412198 0.993106 0.733415 0.598133 0.0628648 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18090 episodes
GETTING ACTION FROM:
action -1, numVisits=18076, meanQ=60.470506, numObservations: 243
action 0, numVisits=5, meanQ=-1.010000, numObservations: 5
action 2, numVisits=5, meanQ=-3.000000, numObservations: 5
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.128635 0.806222 0.527571 0.801212 0.255887 0.412198 0.993106 0.733415 0.598133 0.0628648 w: 1
Observation: 0 1 0 3 0 2 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=189, meanQ=67.811605, numObservations: 35
action 5, numVisits=8, meanQ=-1.000000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 18818 episodes
GETTING ACTION FROM:
action -1, numVisits=19007, meanQ=83.080043, numObservations: 168
action 5, numVisits=8, meanQ=-1.000000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.128635 0.806222 0.527571 0.801212 0.255887 0.412198 0.993106 0.733415 0.598133 0.0628648 w: 1
Observation: 0 1 0 3 0 2 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=7314, meanQ=96.272428, numObservations: 9
action 5, numVisits=4, meanQ=49.000000, numObservations: 2
action 2, numVisits=3, meanQ=32.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 38525 episodes
GETTING ACTION FROM:
action 3, numVisits=45839, meanQ=97.012298, numObservations: 9
action 5, numVisits=4, meanQ=49.000000, numObservations: 2
action 2, numVisits=3, meanQ=32.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.128635 0.806222 0.527571 0.801212 0.255887 0.412198 0.993106 0.733415 0.598133 0.0628648 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 93.0499
Run # 156
Initial state: 0 0.343665 0.509553 0.33601 0.672098 0.151689 0.732819 0.290653 0.582741 0.915763 0.841306 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34030 episodes
GETTING ACTION FROM:
action 4, numVisits=34014, meanQ=31.054426, numObservations: 9
action 2, numVisits=10, meanQ=19.000000, numObservations: 6
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.343665 0.509553 0.33601 0.672098 0.151689 0.732819 0.290653 0.582741 0.915763 0.841306 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 157
Initial state: 0 0.910633 0.675385 0.82687 0.550273 0.275559 0.369759 0.67781 0.586165 0.767194 0.0782734 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34092 episodes
GETTING ACTION FROM:
action 2, numVisits=34083, meanQ=31.622738, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.910633 0.675385 0.82687 0.550273 0.275559 0.369759 0.67781 0.586165 0.767194 0.0782734 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 158
Initial state: 0 0.139005 0.651036 0.981648 0.633923 0.88319 0.562256 0.695801 0.490505 0.320159 0.402672 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17973 episodes
GETTING ACTION FROM:
action -1, numVisits=17953, meanQ=61.696538, numObservations: 243
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 5, numVisits=11, meanQ=-3.727273, numObservations: 6
action 2, numVisits=3, meanQ=-4.333333, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.139005 0.651036 0.981648 0.633923 0.88319 0.562256 0.695801 0.490505 0.320159 0.402672 w: 1
Observation: 0 1 0 3 0 3 0 3 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=197, meanQ=84.070614, numObservations: 9
action 1, numVisits=3, meanQ=26.326667, numObservations: 3
action 4, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 38350 episodes
GETTING ACTION FROM:
action 5, numVisits=38547, meanQ=89.341800, numObservations: 9
action 1, numVisits=3, meanQ=26.326667, numObservations: 3
action 4, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.139005 0.651036 0.981648 0.633923 0.88319 0.562256 0.695801 0.490505 0.320159 0.402672 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 159
Initial state: 0 0.946837 0.287193 0.283546 0.404117 0.235236 0.18991 0.632609 0.894575 0.91851 0.405778 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34236 episodes
GETTING ACTION FROM:
action 1, numVisits=34216, meanQ=31.980696, numObservations: 9
action 3, numVisits=6, meanQ=29.000000, numObservations: 4
action 5, numVisits=10, meanQ=17.000000, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.946837 0.287193 0.283546 0.404117 0.235236 0.18991 0.632609 0.894575 0.91851 0.405778 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=655, meanQ=39.989095, numObservations: 9
action 4, numVisits=27, meanQ=20.518519, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 31560 episodes
GETTING ACTION FROM:
action 4, numVisits=12832, meanQ=16.007396, numObservations: 9
action 2, numVisits=19408, meanQ=14.188607, numObservations: 9
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.946837 0.287193 0.283546 0.404117 0.235236 0.18991 0.632609 0.894575 0.91851 0.405778 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 160
Initial state: 0 0.336419 0.313864 0.262661 0.38407 0.850487 0.734151 0.336245 0.268499 0.793499 0.91138 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33791 episodes
GETTING ACTION FROM:
action 2, numVisits=33782, meanQ=31.707223, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.336419 0.313864 0.262661 0.38407 0.850487 0.734151 0.336245 0.268499 0.793499 0.91138 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 161
Initial state: 0 0.658595 0.257124 0.441131 0.224858 0.442313 0.474165 0.321914 0.350219 0.984711 0.599631 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34010 episodes
GETTING ACTION FROM:
action 2, numVisits=34001, meanQ=30.836579, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.658595 0.257124 0.441131 0.224858 0.442313 0.474165 0.321914 0.350219 0.984711 0.599631 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 162
Initial state: 0 0.726589 0.0868552 0.259807 0.378041 0.506038 0.218056 0.946756 0.611268 0.645899 0.427083 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33286 episodes
GETTING ACTION FROM:
action 5, numVisits=33219, meanQ=31.270150, numObservations: 9
action 4, numVisits=55, meanQ=28.036549, numObservations: 9
action 2, numVisits=7, meanQ=26.284286, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.726589 0.0868552 0.259807 0.378041 0.506038 0.218056 0.946756 0.611268 0.645899 0.427083 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 163
Initial state: 0 0.76163 0.830721 0.292179 0.338571 0.490575 0.113944 0.385257 0.555872 0.83597 0.612587 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34339 episodes
GETTING ACTION FROM:
action 5, numVisits=34302, meanQ=32.477183, numObservations: 9
action 3, numVisits=31, meanQ=29.161935, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.76163 0.830721 0.292179 0.338571 0.490575 0.113944 0.385257 0.555872 0.83597 0.612587 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 164
Initial state: 0 0.0624686 0.319196 0.296372 0.161179 0.573677 0.614646 0.256861 0.459432 0.202372 0.0820595 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32431 episodes
GETTING ACTION FROM:
action 4, numVisits=32423, meanQ=32.198822, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.0624686 0.319196 0.296372 0.161179 0.573677 0.614646 0.256861 0.459432 0.202372 0.0820595 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 165
Initial state: 0 0.284592 0.514755 0.58935 0.34861 0.195979 0.0904745 0.148158 0.230593 0.438651 0.266509 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33370 episodes
GETTING ACTION FROM:
action 1, numVisits=33346, meanQ=32.178506, numObservations: 9
action 3, numVisits=18, meanQ=7.998889, numObservations: 7
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.284592 0.514755 0.58935 0.34861 0.195979 0.0904745 0.148158 0.230593 0.438651 0.266509 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 166
Initial state: 0 0.357886 0.73753 0.0406503 0.889976 0.278012 0.528757 0.612024 0.423753 0.921994 0.0539568 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34640 episodes
GETTING ACTION FROM:
action 4, numVisits=34618, meanQ=32.134551, numObservations: 9
action 5, numVisits=17, meanQ=26.000006, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.357886 0.73753 0.0406503 0.889976 0.278012 0.528757 0.612024 0.423753 0.921994 0.0539568 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 167
Initial state: 0 0.279892 0.38841 0.182583 0.453468 0.728487 0.132004 0.0679897 0.34515 0.0964595 0.514837 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34817 episodes
GETTING ACTION FROM:
action 5, numVisits=34810, meanQ=32.993194, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.279892 0.38841 0.182583 0.453468 0.728487 0.132004 0.0679897 0.34515 0.0964595 0.514837 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 168
Initial state: 0 0.401071 0.825573 0.3583 0.508443 0.589411 0.542038 0.73114 0.0241688 0.880901 0.0572555 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34303 episodes
GETTING ACTION FROM:
action 5, numVisits=34297, meanQ=30.697849, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.401071 0.825573 0.3583 0.508443 0.589411 0.542038 0.73114 0.0241688 0.880901 0.0572555 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 169
Initial state: 0 0.354713 0.713242 0.37112 0.877947 0.610244 0.574359 0.0502893 0.99177 0.256042 0.377725 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18227 episodes
GETTING ACTION FROM:
action -1, numVisits=18207, meanQ=60.096411, numObservations: 243
action 0, numVisits=13, meanQ=-1.010000, numObservations: 13
action 1, numVisits=3, meanQ=-4.333333, numObservations: 2
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.354713 0.713242 0.37112 0.877947 0.610244 0.574359 0.0502893 0.99177 0.256042 0.377725 w: 1
Observation: 0 2 0 3 0 3 0 2 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=34, meanQ=30.507068, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=6, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 36899 episodes
GETTING ACTION FROM:
action 1, numVisits=36933, meanQ=48.411493, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=6, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.354713 0.713242 0.37112 0.877947 0.610244 0.574359 0.0502893 0.99177 0.256042 0.377725 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 170
Initial state: 0 0.391336 0.113877 0.727079 0.811829 0.950675 0.536368 0.313679 0.3718 0.25097 0.118866 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34134 episodes
GETTING ACTION FROM:
action 3, numVisits=34126, meanQ=31.520111, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.391336 0.113877 0.727079 0.811829 0.950675 0.536368 0.313679 0.3718 0.25097 0.118866 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 171
Initial state: 0 0.699745 0.641569 0.921589 0.580706 0.838916 0.55612 0.16187 0.485865 0.319257 0.343088 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34394 episodes
GETTING ACTION FROM:
action 1, numVisits=34381, meanQ=31.662879, numObservations: 9
action 3, numVisits=4, meanQ=19.002500, numObservations: 3
action 5, numVisits=5, meanQ=19.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.699745 0.641569 0.921589 0.580706 0.838916 0.55612 0.16187 0.485865 0.319257 0.343088 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 172
Initial state: 0 0.400536 0.46859 0.708089 0.814134 0.273925 0.473396 0.420405 0.350182 0.370664 0.00907447 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33387 episodes
GETTING ACTION FROM:
action 1, numVisits=33376, meanQ=31.884041, numObservations: 9
action 5, numVisits=6, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.400536 0.46859 0.708089 0.814134 0.273925 0.473396 0.420405 0.350182 0.370664 0.00907447 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 173
Initial state: 0 0.503679 0.406602 0.103193 0.518006 0.283407 0.518998 0.534492 0.979918 0.199451 0.259541 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33391 episodes
GETTING ACTION FROM:
action 1, numVisits=33385, meanQ=32.372894, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.503679 0.406602 0.103193 0.518006 0.283407 0.518998 0.534492 0.979918 0.199451 0.259541 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 174
Initial state: 0 0.28794 0.473849 0.650553 0.404984 0.907639 0.912214 0.685757 0.354024 0.561596 0.377886 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34074 episodes
GETTING ACTION FROM:
action 5, numVisits=34048, meanQ=31.352003, numObservations: 9
action -1, numVisits=8, meanQ=-1.010000, numObservations: 8
action 0, numVisits=8, meanQ=-1.010000, numObservations: 8
action 4, numVisits=7, meanQ=-2.287143, numObservations: 5
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.28794 0.473849 0.650553 0.404984 0.907639 0.912214 0.685757 0.354024 0.561596 0.377886 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 175
Initial state: 0 0.232825 0.689541 0.0931157 0.72334 0.346994 0.449899 0.0907086 0.725101 0.200397 0.136107 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32618 episodes
GETTING ACTION FROM:
action 4, numVisits=32609, meanQ=31.618872, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.232825 0.689541 0.0931157 0.72334 0.346994 0.449899 0.0907086 0.725101 0.200397 0.136107 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 176
Initial state: 0 0.472234 0.496312 0.292715 0.204028 0.281657 0.35439 0.330297 0.914266 0.204466 0.22117 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34332 episodes
GETTING ACTION FROM:
action 2, numVisits=34326, meanQ=31.869290, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.472234 0.496312 0.292715 0.204028 0.281657 0.35439 0.330297 0.914266 0.204466 0.22117 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 177
Initial state: 0 0.720546 0.367028 0.540834 0.598309 0.367991 0.940061 0.152423 0.162684 0.352152 0.376924 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34285 episodes
GETTING ACTION FROM:
action 2, numVisits=34262, meanQ=30.839013, numObservations: 9
action 1, numVisits=15, meanQ=3.667333, numObservations: 7
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 3
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.720546 0.367028 0.540834 0.598309 0.367991 0.940061 0.152423 0.162684 0.352152 0.376924 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 178
Initial state: 0 0.729071 0.664638 0.347693 0.409549 0.685817 0.258504 0.7524 0.537672 0.0991802 0.90427 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34054 episodes
GETTING ACTION FROM:
action 3, numVisits=34038, meanQ=32.063075, numObservations: 9
action 4, numVisits=5, meanQ=19.000000, numObservations: 2
action 5, numVisits=6, meanQ=14.000000, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.729071 0.664638 0.347693 0.409549 0.685817 0.258504 0.7524 0.537672 0.0991802 0.90427 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1854, meanQ=40.241071, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=3, meanQ=-4.003333, numObservations: 2
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 12104 episodes
GETTING ACTION FROM:
action 2, numVisits=13774, meanQ=33.467597, numObservations: 9
action -1, numVisits=132, meanQ=1.500067, numObservations: 72
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 0, numVisits=53, meanQ=-15.756099, numObservations: 43
action 5, numVisits=4, meanQ=-28.252500, numObservations: 2
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.729071 0.664638 0.347693 0.409549 0.685817 0.258504 0.7524 0.537672 0.0991802 0.90427 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 179
Initial state: 0 0.29297 0.50478 0.638751 0.370921 0.256487 0.145568 0.117756 0.644453 0.460233 0.785357 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34028 episodes
GETTING ACTION FROM:
action 4, numVisits=34018, meanQ=32.444208, numObservations: 9
action 1, numVisits=4, meanQ=-1.000000, numObservations: 3
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.29297 0.50478 0.638751 0.370921 0.256487 0.145568 0.117756 0.644453 0.460233 0.785357 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1955, meanQ=38.018014, numObservations: 9
action 5, numVisits=21, meanQ=26.284286, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37755 episodes
GETTING ACTION FROM:
action 2, numVisits=39710, meanQ=45.356579, numObservations: 9
action 5, numVisits=21, meanQ=26.284286, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.29297 0.50478 0.638751 0.370921 0.256487 0.145568 0.117756 0.644453 0.460233 0.785357 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 180
Initial state: 0 0.476326 0.565657 0.673465 0.933825 0.410896 0.161995 0.326413 0.427906 0.982216 0.116339 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31797 episodes
GETTING ACTION FROM:
action 4, numVisits=31763, meanQ=32.231008, numObservations: 9
action 1, numVisits=20, meanQ=27.450000, numObservations: 6
action 3, numVisits=8, meanQ=21.500000, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 4
Next state: 1 0.476326 0.565657 0.673465 0.933825 0.410896 0.161995 0.326413 0.427906 0.982216 0.116339 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 181
Initial state: 0 0.620431 0.0404669 0.657572 0.658902 0.883141 0.10476 0.614547 0.206303 0.279882 0.422501 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34482 episodes
GETTING ACTION FROM:
action 4, numVisits=34463, meanQ=32.018324, numObservations: 9
action 5, numVisits=10, meanQ=4.098010, numObservations: 7
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.620431 0.0404669 0.657572 0.658902 0.883141 0.10476 0.614547 0.206303 0.279882 0.422501 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 182
Initial state: 0 0.135198 0.045997 0.882732 0.955957 0.339578 0.420176 0.655042 0.803274 0.638966 0.93052 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33973 episodes
GETTING ACTION FROM:
action 4, numVisits=33965, meanQ=31.273278, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.135198 0.045997 0.882732 0.955957 0.339578 0.420176 0.655042 0.803274 0.638966 0.93052 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 183
Initial state: 0 0.903657 0.10631 0.585481 0.256506 0.503659 0.666253 0.355905 0.394337 0.112214 0.735319 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33922 episodes
GETTING ACTION FROM:
action 4, numVisits=33858, meanQ=30.925628, numObservations: 9
action 2, numVisits=41, meanQ=21.001710, numObservations: 7
action 5, numVisits=16, meanQ=16.375625, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=4, meanQ=-6.249975, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.903657 0.10631 0.585481 0.256506 0.503659 0.666253 0.355905 0.394337 0.112214 0.735319 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 184
Initial state: 0 0.140811 0.157137 0.645229 0.565586 0.348629 0.345668 0.604859 0.536153 0.0662925 0.807975 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34358 episodes
GETTING ACTION FROM:
action 1, numVisits=34223, meanQ=32.552056, numObservations: 9
action 2, numVisits=130, meanQ=29.747388, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.140811 0.157137 0.645229 0.565586 0.348629 0.345668 0.604859 0.536153 0.0662925 0.807975 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=1769, meanQ=36.750507, numObservations: 9
action 5, numVisits=57, meanQ=33.509833, numObservations: 9
action 3, numVisits=3, meanQ=32.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 14432 episodes
GETTING ACTION FROM:
action 4, numVisits=16153, meanQ=32.195246, numObservations: 9
action 5, numVisits=101, meanQ=28.846328, numObservations: 9
action 3, numVisits=7, meanQ=26.142857, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 4
Next state: 1 0.140811 0.157137 0.645229 0.565586 0.348629 0.345668 0.604859 0.536153 0.0662925 0.807975 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 185
Initial state: 0 0.901858 0.217675 0.302603 0.271478 0.99175 0.216332 0.255589 0.376564 0.171279 0.0815717 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18201 episodes
GETTING ACTION FROM:
action -1, numVisits=18173, meanQ=61.178793, numObservations: 243
action 0, numVisits=12, meanQ=-1.010000, numObservations: 12
action 4, numVisits=10, meanQ=-3.000000, numObservations: 7
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.901858 0.217675 0.302603 0.271478 0.99175 0.216332 0.255589 0.376564 0.171279 0.0815717 w: 1
Observation: 0 3 0 2 0 3 0 1 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=69, meanQ=81.057538, numObservations: 6
action 1, numVisits=6, meanQ=47.498333, numObservations: 3
action 3, numVisits=3, meanQ=32.333333, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37187 episodes
GETTING ACTION FROM:
action 2, numVisits=37256, meanQ=86.567279, numObservations: 9
action 1, numVisits=6, meanQ=47.498333, numObservations: 3
action 3, numVisits=3, meanQ=32.333333, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.901858 0.217675 0.302603 0.271478 0.99175 0.216332 0.255589 0.376564 0.171279 0.0815717 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=27, meanQ=39.298896, numObservations: 6
action 0, numVisits=17, meanQ=-8.232341, numObservations: 14
action -1, numVisits=13, meanQ=-8.930762, numObservations: 11
action 1, numVisits=3, meanQ=-34.333333, numObservations: 2
action 2, numVisits=2, meanQ=-55.505000, numObservations: 2
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 23962 episodes
GETTING ACTION FROM:
action 0, numVisits=23732, meanQ=-0.355731, numObservations: 243
action -1, numVisits=13, meanQ=-8.930762, numObservations: 11
action 5, numVisits=274, meanQ=-9.193138, numObservations: 9
action 1, numVisits=3, meanQ=-34.333333, numObservations: 2
action 2, numVisits=2, meanQ=-55.505000, numObservations: 2
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.901858 0.217675 0.302603 0.271478 0.99175 0.216332 0.255589 0.376564 0.171279 0.0815717 w: 1
Observation: 0 0 1 0 1 0 1 0 2 0 1 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-15.901674, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48275 episodes
GETTING ACTION FROM:
action -1, numVisits=46000, meanQ=-1.789659, numObservations: 161
action 0, numVisits=2275, meanQ=-2.042651, numObservations: 95
action 4, numVisits=1, meanQ=-15.901674, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.901858 0.217675 0.302603 0.271478 0.99175 0.216332 0.255589 0.376564 0.171279 0.0815717 w: 1
Observation: 0 3 0 3 0 3 0 2 0 1 0 
Immediate reward: -2
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 74630 episodes
GETTING ACTION FROM:
action 4, numVisits=74624, meanQ=79.022513, numObservations: 9
action -1, numVisits=1, meanQ=-2.000000, numObservations: 1
action 0, numVisits=1, meanQ=-2.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.901858 0.217675 0.302603 0.271478 0.99175 0.216332 0.255589 0.376564 0.171279 0.0815717 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 78.3082
Run # 186
Initial state: 0 0.232191 0.251807 0.468041 0.223029 0.4051 0.13192 0.973331 0.549498 0.306684 0.394777 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34001 episodes
GETTING ACTION FROM:
action 5, numVisits=33985, meanQ=31.741069, numObservations: 9
action 3, numVisits=7, meanQ=26.142857, numObservations: 4
action 2, numVisits=4, meanQ=21.500000, numObservations: 4
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.232191 0.251807 0.468041 0.223029 0.4051 0.13192 0.973331 0.549498 0.306684 0.394777 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 187
Initial state: 0 0.60825 0.861095 0.504259 0.345201 0.273327 0.355766 0.594153 0.688393 0.710327 0.0449775 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34570 episodes
GETTING ACTION FROM:
action 2, numVisits=34549, meanQ=30.701146, numObservations: 9
action 3, numVisits=10, meanQ=8.000000, numObservations: 7
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=6, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.60825 0.861095 0.504259 0.345201 0.273327 0.355766 0.594153 0.688393 0.710327 0.0449775 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 188
Initial state: 0 0.280416 0.0374221 0.0737608 0.424848 0.363395 0.709921 0.412567 0.398505 0.28796 0.512959 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34628 episodes
GETTING ACTION FROM:
action 4, numVisits=34615, meanQ=32.135965, numObservations: 9
action 3, numVisits=8, meanQ=10.250000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.280416 0.0374221 0.0737608 0.424848 0.363395 0.709921 0.412567 0.398505 0.28796 0.512959 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 189
Initial state: 0 0.870861 0.588507 0.394295 0.788464 0.333119 0.868716 0.925552 0.732254 0.272331 0.410508 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33980 episodes
GETTING ACTION FROM:
action 2, numVisits=33965, meanQ=31.904688, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=10, meanQ=-3.000000, numObservations: 6
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.870861 0.588507 0.394295 0.788464 0.333119 0.868716 0.925552 0.732254 0.272331 0.410508 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 190
Initial state: 0 0.427139 0.846656 0.884193 0.637157 0.348733 0.371941 0.70436 0.210501 0.00780727 0.635244 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33151 episodes
GETTING ACTION FROM:
action 5, numVisits=33109, meanQ=31.071488, numObservations: 9
action 4, numVisits=31, meanQ=16.450648, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=6, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.427139 0.846656 0.884193 0.637157 0.348733 0.371941 0.70436 0.210501 0.00780727 0.635244 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=1815, meanQ=42.151057, numObservations: 9
action 2, numVisits=43, meanQ=33.956749, numObservations: 9
action 3, numVisits=6, meanQ=29.330000, numObservations: 3
action 1, numVisits=7, meanQ=23.141457, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 29043 episodes
GETTING ACTION FROM:
action 5, numVisits=30858, meanQ=57.846475, numObservations: 9
action 2, numVisits=43, meanQ=33.956749, numObservations: 9
action 3, numVisits=6, meanQ=29.330000, numObservations: 3
action 1, numVisits=7, meanQ=23.141457, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.427139 0.846656 0.884193 0.637157 0.348733 0.371941 0.70436 0.210501 0.00780727 0.635244 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=803, meanQ=29.307220, numObservations: 9
action 3, numVisits=27, meanQ=14.668522, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 19300 episodes
GETTING ACTION FROM:
action 4, numVisits=20103, meanQ=30.020150, numObservations: 9
action 3, numVisits=27, meanQ=14.668522, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.427139 0.846656 0.884193 0.637157 0.348733 0.371941 0.70436 0.210501 0.00780727 0.635244 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -120.88
Run # 191
Initial state: 0 0.65421 0.51557 0.670276 0.622488 0.249119 0.531587 0.74941 0.880986 0.267193 0.409996 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33313 episodes
GETTING ACTION FROM:
action 5, numVisits=33301, meanQ=31.287443, numObservations: 9
action 3, numVisits=4, meanQ=21.747500, numObservations: 4
action 1, numVisits=4, meanQ=21.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.65421 0.51557 0.670276 0.622488 0.249119 0.531587 0.74941 0.880986 0.267193 0.409996 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 192
Initial state: 0 0.302934 0.471272 0.320054 0.892216 0.929817 0.127776 0.0920407 0.68711 0.791054 0.671151 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34349 episodes
GETTING ACTION FROM:
action 4, numVisits=34341, meanQ=31.909403, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.302934 0.471272 0.320054 0.892216 0.929817 0.127776 0.0920407 0.68711 0.791054 0.671151 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=1896, meanQ=36.516177, numObservations: 9
action 3, numVisits=3, meanQ=26.326667, numObservations: 3
action 1, numVisits=4, meanQ=-1.000000, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 36570 episodes
GETTING ACTION FROM:
action 5, numVisits=38466, meanQ=40.731598, numObservations: 9
action 3, numVisits=3, meanQ=26.326667, numObservations: 3
action 1, numVisits=4, meanQ=-1.000000, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 5
Next state: 1 0.302934 0.471272 0.320054 0.892216 0.929817 0.127776 0.0920407 0.68711 0.791054 0.671151 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 87.01
Run # 193
Initial state: 0 0.39438 0.232535 0.335119 0.497357 0.552546 0.784705 0.48672 0.826029 0.468738 0.60169 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34422 episodes
GETTING ACTION FROM:
action 1, numVisits=34395, meanQ=32.203246, numObservations: 9
action 3, numVisits=19, meanQ=12.684211, numObservations: 8
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=3, meanQ=-4.333333, numObservations: 2
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.39438 0.232535 0.335119 0.497357 0.552546 0.784705 0.48672 0.826029 0.468738 0.60169 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 194
Initial state: 0 0.257548 0.44996 0.270583 0.668243 0.00504047 0.110954 0.795982 0.299755 0.932092 0.00739022 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17893 episodes
GETTING ACTION FROM:
action -1, numVisits=17884, meanQ=57.279847, numObservations: 243
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=3, meanQ=-4.333333, numObservations: 2
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.257548 0.44996 0.270583 0.668243 0.00504047 0.110954 0.795982 0.299755 0.932092 0.00739022 w: 1
Observation: 0 2 0 2 0 2 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=29, meanQ=36.309655, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 36402 episodes
GETTING ACTION FROM:
action 3, numVisits=36431, meanQ=24.233817, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.257548 0.44996 0.270583 0.668243 0.00504047 0.110954 0.795982 0.299755 0.932092 0.00739022 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=1014, meanQ=38.013769, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 1
action 5, numVisits=6, meanQ=-1.000000, numObservations: 3
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 40197 episodes
GETTING ACTION FROM:
action 1, numVisits=41211, meanQ=53.770168, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 1
action 5, numVisits=6, meanQ=-1.000000, numObservations: 3
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.257548 0.44996 0.270583 0.668243 0.00504047 0.110954 0.795982 0.299755 0.932092 0.00739022 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 84.1399
Run # 195
Initial state: 0 0.703542 0.695017 0.572552 0.879741 0.871654 0.172039 0.958247 0.963412 0.272463 0.415016 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34592 episodes
GETTING ACTION FROM:
action 1, numVisits=34580, meanQ=31.564060, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 2
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.703542 0.695017 0.572552 0.879741 0.871654 0.172039 0.958247 0.963412 0.272463 0.415016 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 196
Initial state: 0 0.660179 0.838288 0.0854824 0.602619 0.296647 0.428811 0.451688 0.477191 0.374469 0.140982 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18254 episodes
GETTING ACTION FROM:
action -1, numVisits=18214, meanQ=61.090734, numObservations: 242
action 0, numVisits=16, meanQ=-1.010000, numObservations: 16
action 1, numVisits=20, meanQ=-2.499500, numObservations: 6
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.660179 0.838288 0.0854824 0.602619 0.296647 0.428811 0.451688 0.477191 0.374469 0.140982 w: 1
Observation: 0 3 0 1 0 1 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=46, meanQ=26.673261, numObservations: 7
action 4, numVisits=9, meanQ=20.221111, numObservations: 4
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 40646 episodes
GETTING ACTION FROM:
action 1, numVisits=40648, meanQ=9.337554, numObservations: 9
action 4, numVisits=51, meanQ=2.313533, numObservations: 6
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 1
Next state: 1 0.660179 0.838288 0.0854824 0.602619 0.296647 0.428811 0.451688 0.477191 0.374469 0.140982 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 197
Initial state: 0 0.860587 0.324222 0.322133 0.345749 0.669639 0.43638 0.664175 0.412409 0.821776 0.540505 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34228 episodes
GETTING ACTION FROM:
action 5, numVisits=34202, meanQ=31.749017, numObservations: 9
action 4, numVisits=20, meanQ=17.000000, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.860587 0.324222 0.322133 0.345749 0.669639 0.43638 0.664175 0.412409 0.821776 0.540505 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 198
Initial state: 0 0.542188 0.722027 0.340443 0.812963 0.92614 0.202642 0.257599 0.348681 0.860455 0.809764 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18075 episodes
GETTING ACTION FROM:
action -1, numVisits=18036, meanQ=63.122113, numObservations: 243
action 0, numVisits=29, meanQ=-1.522410, numObservations: 26
action 2, numVisits=6, meanQ=-4.499983, numObservations: 4
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.542188 0.722027 0.340443 0.812963 0.92614 0.202642 0.257599 0.348681 0.860455 0.809764 w: 1
Observation: 0 3 0 2 0 3 0 1 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=194, meanQ=84.923043, numObservations: 9
action 3, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 38382 episodes
GETTING ACTION FROM:
action 2, numVisits=38576, meanQ=90.550618, numObservations: 9
action 3, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.010000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.542188 0.722027 0.340443 0.812963 0.92614 0.202642 0.257599 0.348681 0.860455 0.809764 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
Run # 199
Initial state: 0 0.340686 0.822657 0.261214 0.418028 0.694747 0.441527 0.412536 0.498237 0.303162 0.723419 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34144 episodes
GETTING ACTION FROM:
action 3, numVisits=33994, meanQ=31.095650, numObservations: 9
action 1, numVisits=145, meanQ=23.443383, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.340686 0.822657 0.261214 0.418028 0.694747 0.441527 0.412536 0.498237 0.303162 0.723419 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 200
Initial state: 0 0.791431 0.893973 0.285353 0.501578 0.589424 0.682813 0.275106 0.87102 0.110838 0.670049 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18408 episodes
GETTING ACTION FROM:
action 0, numVisits=18384, meanQ=64.031971, numObservations: 243
action -1, numVisits=19, meanQ=-6.324737, numObservations: 18
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.791431 0.893973 0.285353 0.501578 0.589424 0.682813 0.275106 0.87102 0.110838 0.670049 w: 1
Observation: 0 0 3 0 1 0 3 0 3 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=30, meanQ=77.600000, numObservations: 7
action 3, numVisits=12, meanQ=73.249167, numObservations: 5
action 4, numVisits=3, meanQ=62.663333, numObservations: 2
action 5, numVisits=4, meanQ=49.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
Sampled 35625 episodes
GETTING ACTION FROM:
action 1, numVisits=35653, meanQ=71.075253, numObservations: 9
action 4, numVisits=3, meanQ=62.663333, numObservations: 2
action 3, numVisits=14, meanQ=62.642143, numObservations: 5
action 5, numVisits=4, meanQ=49.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.010000, numObservations: 1
action: 1
Next state: 1 0.791431 0.893973 0.285353 0.501578 0.589424 0.682813 0.275106 0.87102 0.110838 0.670049 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 96.01
[32m ProblemEnvironment.hpp 351: Done.[39m
