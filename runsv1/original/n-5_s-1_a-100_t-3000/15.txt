Run # 1
Initial state: 0 0.583609 0.934265 0.0704008 0.528472 0.132195 0.626066 0.988203 0.794078 0.510462 0.297498 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 393834 episodes
GETTING ACTION FROM:
action 4, numVisits=393824, meanQ=13.213044, numObservations: 9
action 1, numVisits=4, meanQ=8.497500, numObservations: 3
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.583609 0.934265 0.0704008 0.528472 0.132195 0.626066 0.988203 0.794078 0.510462 0.297498 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 2
Initial state: 0 0.627272 0.170721 0.881267 0.133699 0.488156 0.359489 0.994891 0.23127 0.24102 0.172754 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 421052 episodes
GETTING ACTION FROM:
action 4, numVisits=421012, meanQ=13.332008, numObservations: 9
action 3, numVisits=30, meanQ=10.016337, numObservations: 9
action 1, numVisits=6, meanQ=9.163333, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 2 0.627272 0.170721 0.881267 0.133699 0.488156 0.359489 0.994891 0.23127 0.24102 0.172754 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 3
Initial state: 0 0.591964 0.688891 0.574701 0.274836 0.377751 0.957516 0.0169125 0.815955 0.472222 0.296969 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 422859 episodes
GETTING ACTION FROM:
action 1, numVisits=422851, meanQ=13.240531, numObservations: 9
action 4, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.591964 0.688891 0.574701 0.274836 0.377751 0.957516 0.0169125 0.815955 0.472222 0.296969 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 4
Initial state: 0 0.391587 0.6572 0.382035 0.918398 0.431681 0.345233 0.67218 0.598827 0.983933 0.247238 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 422829 episodes
GETTING ACTION FROM:
action 4, numVisits=422816, meanQ=13.265655, numObservations: 9
action 5, numVisits=6, meanQ=9.163333, numObservations: 3
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 2 0.391587 0.6572 0.382035 0.918398 0.431681 0.345233 0.67218 0.598827 0.983933 0.247238 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 5
Initial state: 0 0.832408 0.877127 0.360001 0.836575 0.400794 0.391141 0.629189 0.508097 0.0844847 0.09823 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 395096 episodes
GETTING ACTION FROM:
action 2, numVisits=395083, meanQ=13.327290, numObservations: 9
action 5, numVisits=6, meanQ=10.163350, numObservations: 2
action 1, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.832408 0.877127 0.360001 0.836575 0.400794 0.391141 0.629189 0.508097 0.0844847 0.09823 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=50418, meanQ=13.789027, numObservations: 9
action 4, numVisits=4, meanQ=6.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 369773 episodes
GETTING ACTION FROM:
action 2, numVisits=420191, meanQ=16.449086, numObservations: 9
action 4, numVisits=4, meanQ=6.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.832408 0.877127 0.360001 0.836575 0.400794 0.391141 0.629189 0.508097 0.0844847 0.09823 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 6
Initial state: 0 0.162011 0.0341388 0.470427 0.390632 0.586127 0.430986 0.287764 0.923446 0.144123 0.814856 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 423389 episodes
GETTING ACTION FROM:
action 2, numVisits=423371, meanQ=13.358986, numObservations: 9
action 4, numVisits=13, meanQ=9.536931, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.162011 0.0341388 0.470427 0.390632 0.586127 0.430986 0.287764 0.923446 0.144123 0.814856 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 7
Initial state: 0 0.530599 0.584983 0.523891 0.330111 0.853656 0.829562 0.370558 0.834918 0.356868 0.625137 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 419332 episodes
GETTING ACTION FROM:
action 1, numVisits=419318, meanQ=13.341813, numObservations: 9
action 4, numVisits=7, meanQ=0.141429, numObservations: 5
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.530599 0.584983 0.523891 0.330111 0.853656 0.829562 0.370558 0.834918 0.356868 0.625137 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 8
Initial state: 0 0.476799 0.405863 0.764938 0.47241 0.926749 0.669522 0.270885 0.653083 0.26637 0.967293 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 422695 episodes
GETTING ACTION FROM:
action 4, numVisits=422688, meanQ=13.146645, numObservations: 9
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 1 0.476799 0.405863 0.764938 0.47241 0.926749 0.669522 0.270885 0.653083 0.26637 0.967293 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 9
Initial state: 0 0.442033 0.298945 0.261508 0.727267 0.0893198 0.0103765 0.134639 0.895289 0.198536 0.0854629 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 421798 episodes
GETTING ACTION FROM:
action 2, numVisits=421678, meanQ=13.185828, numObservations: 9
action 5, numVisits=57, meanQ=10.961823, numObservations: 9
action 3, numVisits=54, meanQ=10.835007, numObservations: 9
action 4, numVisits=4, meanQ=8.497500, numObservations: 4
action 1, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.442033 0.298945 0.261508 0.727267 0.0893198 0.0103765 0.134639 0.895289 0.198536 0.0854629 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=53639, meanQ=14.146158, numObservations: 9
action 2, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 514561 episodes
GETTING ACTION FROM:
action 1, numVisits=568200, meanQ=14.744107, numObservations: 9
action 2, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.442033 0.298945 0.261508 0.727267 0.0893198 0.0103765 0.134639 0.895289 0.198536 0.0854629 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 10
Initial state: 0 0.57443 0.678767 0.172708 0.47338 0.269789 0.579491 0.738081 0.783125 0.474631 0.393284 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 422702 episodes
GETTING ACTION FROM:
action 5, numVisits=422685, meanQ=13.293406, numObservations: 9
action 2, numVisits=12, meanQ=4.915000, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 1 0.57443 0.678767 0.172708 0.47338 0.269789 0.579491 0.738081 0.783125 0.474631 0.393284 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 11
Initial state: 0 0.461299 0.395368 0.205213 0.582485 0.426033 0.857471 0.0628535 0.781463 0.675929 0.411962 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 421285 episodes
GETTING ACTION FROM:
action 2, numVisits=421269, meanQ=13.238824, numObservations: 9
action 5, numVisits=9, meanQ=10.220000, numObservations: 5
action 4, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.461299 0.395368 0.205213 0.582485 0.426033 0.857471 0.0628535 0.781463 0.675929 0.411962 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=53830, meanQ=14.063583, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 499315 episodes
GETTING ACTION FROM:
action 5, numVisits=553145, meanQ=14.540692, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.461299 0.395368 0.205213 0.582485 0.426033 0.857471 0.0628535 0.781463 0.675929 0.411962 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 12
Initial state: 0 0.012592 0.431293 0.422002 0.0357827 0.495868 0.313396 0.0212717 0.862601 0.0304475 0.372775 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 419392 episodes
GETTING ACTION FROM:
action 3, numVisits=419383, meanQ=13.334336, numObservations: 9
action 1, numVisits=4, meanQ=0.752525, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.012592 0.431293 0.422002 0.0357827 0.495868 0.313396 0.0212717 0.862601 0.0304475 0.372775 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 13
Initial state: 0 0.493219 0.386967 0.160673 0.437872 0.34399 0.791546 0.277136 0.0776337 0.147734 0.165254 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 421296 episodes
GETTING ACTION FROM:
action 2, numVisits=421279, meanQ=13.313949, numObservations: 9
action 3, numVisits=4, meanQ=8.497500, numObservations: 3
action 1, numVisits=9, meanQ=8.106667, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.493219 0.386967 0.160673 0.437872 0.34399 0.791546 0.277136 0.0776337 0.147734 0.165254 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=5329, meanQ=14.197224, numObservations: 9
action 3, numVisits=4, meanQ=10.495000, numObservations: 4
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 552997 episodes
GETTING ACTION FROM:
action 2, numVisits=558326, meanQ=16.815792, numObservations: 9
action 3, numVisits=4, meanQ=10.495000, numObservations: 4
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.493219 0.386967 0.160673 0.437872 0.34399 0.791546 0.277136 0.0776337 0.147734 0.165254 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=4095, meanQ=13.225105, numObservations: 9
action 5, numVisits=4, meanQ=8.497500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 536749 episodes
GETTING ACTION FROM:
action 1, numVisits=540844, meanQ=14.177783, numObservations: 9
action 5, numVisits=4, meanQ=8.497500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.493219 0.386967 0.160673 0.437872 0.34399 0.791546 0.277136 0.0776337 0.147734 0.165254 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 14
Initial state: 0 0.22783 0.387697 0.0179209 0.521672 0.490614 0.325065 0.710013 0.142337 0.333757 0.162275 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 419471 episodes
GETTING ACTION FROM:
action 2, numVisits=419463, meanQ=13.297463, numObservations: 9
action 5, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.22783 0.387697 0.0179209 0.521672 0.490614 0.325065 0.710013 0.142337 0.333757 0.162275 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=53695, meanQ=14.140025, numObservations: 9
action 4, numVisits=14, meanQ=8.499293, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 510416 episodes
GETTING ACTION FROM:
action 1, numVisits=564111, meanQ=15.798937, numObservations: 9
action 4, numVisits=14, meanQ=8.499293, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.22783 0.387697 0.0179209 0.521672 0.490614 0.325065 0.710013 0.142337 0.333757 0.162275 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 15
Initial state: 0 0.259887 0.868835 0.394776 0.0713162 0.520287 0.346697 0.304451 0.911378 0.279288 0.18232 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 423616 episodes
GETTING ACTION FROM:
action 2, numVisits=423598, meanQ=13.327539, numObservations: 9
action 5, numVisits=11, meanQ=7.088182, numObservations: 6
action 3, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.259887 0.868835 0.394776 0.0713162 0.520287 0.346697 0.304451 0.911378 0.279288 0.18232 w: 1
Observation: 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=5711, meanQ=13.411042, numObservations: 9
action 3, numVisits=12, meanQ=9.663342, numObservations: 6
action 4, numVisits=11, meanQ=9.543636, numObservations: 6
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 563013 episodes
GETTING ACTION FROM:
action 5, numVisits=568724, meanQ=11.958566, numObservations: 9
action 3, numVisits=12, meanQ=9.663342, numObservations: 6
action 4, numVisits=11, meanQ=9.543636, numObservations: 6
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.259887 0.868835 0.394776 0.0713162 0.520287 0.346697 0.304451 0.911378 0.279288 0.18232 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=13723, meanQ=12.842596, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 562847 episodes
GETTING ACTION FROM:
action 1, numVisits=576570, meanQ=13.514102, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.259887 0.868835 0.394776 0.0713162 0.520287 0.346697 0.304451 0.911378 0.279288 0.18232 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=12049, meanQ=17.413717, numObservations: 9
action 4, numVisits=20, meanQ=8.290520, numObservations: 8
action 2, numVisits=7, meanQ=6.282857, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 604429 episodes
GETTING ACTION FROM:
action 3, numVisits=616478, meanQ=15.832222, numObservations: 9
action 4, numVisits=20, meanQ=8.290520, numObservations: 8
action 2, numVisits=7, meanQ=6.282857, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.259887 0.868835 0.394776 0.0713162 0.520287 0.346697 0.304451 0.911378 0.279288 0.18232 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 11.4068
Run # 16
Initial state: 0 0.596299 0.927731 0.183905 0.951174 0.428816 0.568323 0.48852 0.34188 0.942385 0.0689191 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 421347 episodes
GETTING ACTION FROM:
action 4, numVisits=421341, meanQ=13.123742, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 1 0.596299 0.927731 0.183905 0.951174 0.428816 0.568323 0.48852 0.34188 0.942385 0.0689191 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 17
Initial state: 0 0.720609 0.476616 0.199669 0.690055 0.526121 0.354842 0.746981 0.178325 0.186872 0.393459 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 419965 episodes
GETTING ACTION FROM:
action 2, numVisits=419959, meanQ=13.381726, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.720609 0.476616 0.199669 0.690055 0.526121 0.354842 0.746981 0.178325 0.186872 0.393459 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 18
Initial state: 0 0.506075 0.317919 0.959148 0.518634 0.0129307 0.0528787 0.341756 0.488349 0.176804 0.479285 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 326594 episodes
GETTING ACTION FROM:
action 4, numVisits=326588, meanQ=13.533957, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.506075 0.317919 0.959148 0.518634 0.0129307 0.0528787 0.341756 0.488349 0.176804 0.479285 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=41262, meanQ=16.517274, numObservations: 243
action -1, numVisits=5, meanQ=-1.407980, numObservations: 4
action 3, numVisits=5, meanQ=-2.402000, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 137160 episodes
GETTING ACTION FROM:
action 0, numVisits=178422, meanQ=11.308677, numObservations: 243
action -1, numVisits=5, meanQ=-1.407980, numObservations: 4
action 3, numVisits=5, meanQ=-2.402000, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.506075 0.317919 0.959148 0.518634 0.0129307 0.0528787 0.341756 0.488349 0.176804 0.479285 w: 1
Observation: 0 0 3 0 3 0 1 0 3 0 3 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=1180, meanQ=18.759156, numObservations: 9
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 521011 episodes
GETTING ACTION FROM:
action 2, numVisits=522191, meanQ=20.785869, numObservations: 9
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.506075 0.317919 0.959148 0.518634 0.0129307 0.0528787 0.341756 0.488349 0.176804 0.479285 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 17.5424
Run # 19
Initial state: 0 0.470789 0.129615 0.419448 0.395507 0.77534 0.930019 0.211205 0.609261 0.379586 0.919245 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 422200 episodes
GETTING ACTION FROM:
action 4, numVisits=422190, meanQ=13.168238, numObservations: 9
action 5, numVisits=3, meanQ=3.330000, numObservations: 3
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.470789 0.129615 0.419448 0.395507 0.77534 0.930019 0.211205 0.609261 0.379586 0.919245 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=3355, meanQ=14.229273, numObservations: 9
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action 5, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 613647 episodes
GETTING ACTION FROM:
action 2, numVisits=617002, meanQ=16.493487, numObservations: 9
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action 5, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.470789 0.129615 0.419448 0.395507 0.77534 0.930019 0.211205 0.609261 0.379586 0.919245 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 20
Initial state: 0 0.285541 0.301034 0.501375 0.375093 0.626338 0.0651964 0.537873 0.0413325 0.0611168 0.0823156 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 399867 episodes
GETTING ACTION FROM:
action 1, numVisits=399858, meanQ=13.318953, numObservations: 9
action 4, numVisits=4, meanQ=8.497500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.285541 0.301034 0.501375 0.375093 0.626338 0.0651964 0.537873 0.0413325 0.0611168 0.0823156 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=5227, meanQ=13.385444, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 558720 episodes
GETTING ACTION FROM:
action 5, numVisits=563947, meanQ=12.640661, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.285541 0.301034 0.501375 0.375093 0.626338 0.0651964 0.537873 0.0413325 0.0611168 0.0823156 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=11710, meanQ=10.830459, numObservations: 9
action 4, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 585382 episodes
GETTING ACTION FROM:
action 2, numVisits=597092, meanQ=13.177860, numObservations: 9
action 4, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.285541 0.301034 0.501375 0.375093 0.626338 0.0651964 0.537873 0.0413325 0.0611168 0.0823156 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 21
Initial state: 0 0.927445 0.211518 0.815915 0.458075 0.441447 0.408466 0.622712 0.654979 0.572303 0.585715 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 402423 episodes
GETTING ACTION FROM:
action 1, numVisits=402417, meanQ=13.211723, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.927445 0.211518 0.815915 0.458075 0.441447 0.408466 0.622712 0.654979 0.572303 0.585715 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 22
Initial state: 0 0.693694 0.285089 0.464806 0.317106 0.405255 0.177264 0.995038 0.597925 0.970743 0.138302 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 407687 episodes
GETTING ACTION FROM:
action 1, numVisits=407670, meanQ=13.231629, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.341650, numObservations: 5
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.693694 0.285089 0.464806 0.317106 0.405255 0.177264 0.995038 0.597925 0.970743 0.138302 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 23
Initial state: 0 0.367087 0.418467 0.534288 0.371223 0.0263595 0.501402 0.324245 0.177309 0.370052 0.693962 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 402253 episodes
GETTING ACTION FROM:
action 3, numVisits=402229, meanQ=13.034860, numObservations: 9
action 5, numVisits=11, meanQ=6.361818, numObservations: 6
action 1, numVisits=7, meanQ=5.141429, numObservations: 5
action 4, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.367087 0.418467 0.534288 0.371223 0.0263595 0.501402 0.324245 0.177309 0.370052 0.693962 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=51114, meanQ=13.695087, numObservations: 9
action 1, numVisits=127, meanQ=12.526329, numObservations: 9
action 2, numVisits=12, meanQ=11.749175, numObservations: 6
action 5, numVisits=4, meanQ=8.497500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 403325 episodes
GETTING ACTION FROM:
action 3, numVisits=454439, meanQ=16.548734, numObservations: 9
action 1, numVisits=127, meanQ=12.526329, numObservations: 9
action 2, numVisits=12, meanQ=11.749175, numObservations: 6
action 5, numVisits=4, meanQ=8.497500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.367087 0.418467 0.534288 0.371223 0.0263595 0.501402 0.324245 0.177309 0.370052 0.693962 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 24
Initial state: 0 0.279949 0.733478 0.358363 0.802982 0.631746 0.611582 0.73432 0.805563 0.491956 0.394478 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 423444 episodes
GETTING ACTION FROM:
action 3, numVisits=423434, meanQ=13.367866, numObservations: 9
action 1, numVisits=5, meanQ=6.196000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.279949 0.733478 0.358363 0.802982 0.631746 0.611582 0.73432 0.805563 0.491956 0.394478 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 25
Initial state: 0 0.445747 0.301671 0.897702 0.718199 0.921268 0.349741 0.585371 0.102012 0.407114 0.0957168 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 416739 episodes
GETTING ACTION FROM:
action 2, numVisits=416720, meanQ=13.266410, numObservations: 9
action 1, numVisits=14, meanQ=7.631429, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.445747 0.301671 0.897702 0.718199 0.921268 0.349741 0.585371 0.102012 0.407114 0.0957168 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 26
Initial state: 0 0.755508 0.899272 0.851332 0.862869 0.405891 0.985344 0.695868 0.671334 0.525956 0.392637 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 419591 episodes
GETTING ACTION FROM:
action 4, numVisits=419538, meanQ=13.165617, numObservations: 9
action 2, numVisits=48, meanQ=11.832708, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.755508 0.899272 0.851332 0.862869 0.405891 0.985344 0.695868 0.671334 0.525956 0.392637 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 27
Initial state: 0 0.0253224 0.645215 0.166086 0.831296 0.763596 0.381524 0.873459 0.824997 0.469609 0.335582 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 405178 episodes
GETTING ACTION FROM:
action 2, numVisits=404787, meanQ=13.271393, numObservations: 9
action 3, numVisits=382, meanQ=11.918957, numObservations: 9
action 1, numVisits=3, meanQ=5.993333, numObservations: 3
action 5, numVisits=3, meanQ=5.330033, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.0253224 0.645215 0.166086 0.831296 0.763596 0.381524 0.873459 0.824997 0.469609 0.335582 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=51437, meanQ=13.734004, numObservations: 9
action 4, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 415854 episodes
GETTING ACTION FROM:
action 2, numVisits=467291, meanQ=16.684800, numObservations: 9
action 4, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.0253224 0.645215 0.166086 0.831296 0.763596 0.381524 0.873459 0.824997 0.469609 0.335582 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 28
Initial state: 0 0.45657 0.296221 0.578869 0.819848 0.624211 0.480959 0.849667 0.55161 0.239348 0.762191 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 416872 episodes
GETTING ACTION FROM:
action 3, numVisits=416855, meanQ=13.360198, numObservations: 9
action 1, numVisits=8, meanQ=8.470012, numObservations: 5
action 2, numVisits=5, meanQ=6.196000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.45657 0.296221 0.578869 0.819848 0.624211 0.480959 0.849667 0.55161 0.239348 0.762191 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 29
Initial state: 0 0.178426 0.242531 0.195996 0.543329 0.463507 0.306931 0.303073 0.975585 0.12809 0.446223 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 415888 episodes
GETTING ACTION FROM:
action 2, numVisits=415844, meanQ=13.278080, numObservations: 9
action 5, numVisits=36, meanQ=11.770567, numObservations: 9
action 4, numVisits=4, meanQ=8.497500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.178426 0.242531 0.195996 0.543329 0.463507 0.306931 0.303073 0.975585 0.12809 0.446223 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 30
Initial state: 0 0.427924 0.353491 0.932918 0.0685095 0.934509 0.91625 0.786316 0.258745 0.130154 0.796514 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 418848 episodes
GETTING ACTION FROM:
action 1, numVisits=418838, meanQ=13.166831, numObservations: 9
action 4, numVisits=5, meanQ=4.598000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.427924 0.353491 0.932918 0.0685095 0.934509 0.91625 0.786316 0.258745 0.130154 0.796514 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 31
Initial state: 0 0.0305681 0.762022 0.499682 0.352987 0.539803 0.699454 0.256936 0.212568 0.134463 0.0405517 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 421263 episodes
GETTING ACTION FROM:
action 4, numVisits=421257, meanQ=13.142786, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.0305681 0.762022 0.499682 0.352987 0.539803 0.699454 0.256936 0.212568 0.134463 0.0405517 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=33352, meanQ=14.057259, numObservations: 9
action 2, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 506756 episodes
GETTING ACTION FROM:
action 5, numVisits=540108, meanQ=13.051400, numObservations: 9
action 2, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.0305681 0.762022 0.499682 0.352987 0.539803 0.699454 0.256936 0.212568 0.134463 0.0405517 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=31920, meanQ=17.889628, numObservations: 9
action 3, numVisits=15, meanQ=8.732000, numObservations: 7
action 2, numVisits=4, meanQ=6.500000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 547172 episodes
GETTING ACTION FROM:
action 1, numVisits=579092, meanQ=15.917815, numObservations: 9
action 3, numVisits=15, meanQ=8.732000, numObservations: 7
action 2, numVisits=4, meanQ=6.500000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.0305681 0.762022 0.499682 0.352987 0.539803 0.699454 0.256936 0.212568 0.134463 0.0405517 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=5679, meanQ=11.733680, numObservations: 9
action 3, numVisits=5, meanQ=6.196000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 598932 episodes
GETTING ACTION FROM:
action 2, numVisits=604611, meanQ=15.417180, numObservations: 9
action 3, numVisits=5, meanQ=6.196000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.0305681 0.762022 0.499682 0.352987 0.539803 0.699454 0.256936 0.212568 0.134463 0.0405517 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 11.4068
Run # 32
Initial state: 0 0.39395 0.727296 0.540191 0.870445 0.355783 0.795846 0.509715 0.398232 0.158812 0.783027 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 420684 episodes
GETTING ACTION FROM:
action 1, numVisits=420678, meanQ=13.317368, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.39395 0.727296 0.540191 0.870445 0.355783 0.795846 0.509715 0.398232 0.158812 0.783027 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 33
Initial state: 0 0.932888 0.986106 0.0769808 0.4758 0.329204 0.630216 0.755267 0.242464 0.397186 0.356706 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 418846 episodes
GETTING ACTION FROM:
action 4, numVisits=418827, meanQ=13.321457, numObservations: 9
action 3, numVisits=11, meanQ=7.633645, numObservations: 6
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action 1, numVisits=3, meanQ=5.330033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 2 0.932888 0.986106 0.0769808 0.4758 0.329204 0.630216 0.755267 0.242464 0.397186 0.356706 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 34
Initial state: 0 0.463174 0.32276 0.423529 0.112085 0.810966 0.940539 0.148587 0.693462 0.178734 0.506304 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 421564 episodes
GETTING ACTION FROM:
action 1, numVisits=421511, meanQ=13.371267, numObservations: 9
action 2, numVisits=28, meanQ=10.998939, numObservations: 8
action 4, numVisits=13, meanQ=9.700008, numObservations: 6
action 5, numVisits=8, meanQ=8.497500, numObservations: 5
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.463174 0.32276 0.423529 0.112085 0.810966 0.940539 0.148587 0.693462 0.178734 0.506304 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 35
Initial state: 0 0.730547 0.521317 0.520988 0.403291 0.754141 0.104849 0.430986 0.85828 0.409985 0.179373 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 408296 episodes
GETTING ACTION FROM:
action 1, numVisits=408283, meanQ=13.141523, numObservations: 9
action 5, numVisits=3, meanQ=3.330000, numObservations: 3
action 3, numVisits=6, meanQ=2.350017, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.730547 0.521317 0.520988 0.403291 0.754141 0.104849 0.430986 0.85828 0.409985 0.179373 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 36
Initial state: 0 0.314511 0.345721 0.573961 0.220138 0.870627 0.687671 0.194436 0.82519 0.442762 0.39337 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 324626 episodes
GETTING ACTION FROM:
action 3, numVisits=324619, meanQ=13.511087, numObservations: 9
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.314511 0.345721 0.573961 0.220138 0.870627 0.687671 0.194436 0.82519 0.442762 0.39337 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 37
Initial state: 0 0.555017 0.0415076 0.412957 0.310901 0.225035 0.823393 0.85479 0.741613 0.252692 0.169602 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 418409 episodes
GETTING ACTION FROM:
action 4, numVisits=418399, meanQ=13.206664, numObservations: 9
action 5, numVisits=4, meanQ=8.497500, numObservations: 3
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.555017 0.0415076 0.412957 0.310901 0.225035 0.823393 0.85479 0.741613 0.252692 0.169602 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 38
Initial state: 0 0.488658 0.371358 0.59324 0.950747 0.789506 0.216641 0.326293 0.471706 0.826176 0.596289 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 403765 episodes
GETTING ACTION FROM:
action 1, numVisits=403759, meanQ=13.288027, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.488658 0.371358 0.59324 0.950747 0.789506 0.216641 0.326293 0.471706 0.826176 0.596289 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 39
Initial state: 0 0.87018 0.87162 0.125295 0.944397 0.381033 0.107666 0.743298 0.20337 0.452416 0.360082 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 420334 episodes
GETTING ACTION FROM:
action 2, numVisits=420318, meanQ=13.345501, numObservations: 9
action 5, numVisits=6, meanQ=7.831667, numObservations: 5
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action 3, numVisits=5, meanQ=5.798020, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.87018 0.87162 0.125295 0.944397 0.381033 0.107666 0.743298 0.20337 0.452416 0.360082 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 40
Initial state: 0 0.162285 0.336431 0.999773 0.0510356 0.155615 0.00107621 0.17194 0.553473 0.435756 0.327764 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 421100 episodes
GETTING ACTION FROM:
action 3, numVisits=421083, meanQ=13.277051, numObservations: 9
action 1, numVisits=4, meanQ=8.497500, numObservations: 4
action 5, numVisits=7, meanQ=7.424286, numObservations: 5
action 4, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.162285 0.336431 0.999773 0.0510356 0.155615 0.00107621 0.17194 0.553473 0.435756 0.327764 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 41
Initial state: 0 0.216788 0.673433 0.49606 0.650198 0.288941 0.745771 0.967867 0.895638 0.500152 0.350945 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 397927 episodes
GETTING ACTION FROM:
action 1, numVisits=397886, meanQ=13.090819, numObservations: 9
action 5, numVisits=27, meanQ=6.559259, numObservations: 8
action 2, numVisits=8, meanQ=5.623763, numObservations: 5
action 3, numVisits=3, meanQ=4.670033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.216788 0.673433 0.49606 0.650198 0.288941 0.745771 0.967867 0.895638 0.500152 0.350945 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=2503, meanQ=14.529580, numObservations: 9
action 4, numVisits=335, meanQ=14.234791, numObservations: 9
action 5, numVisits=2, meanQ=10.495000, numObservations: 2
action 2, numVisits=4, meanQ=8.497500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 612191 episodes
GETTING ACTION FROM:
action 3, numVisits=614694, meanQ=16.559779, numObservations: 9
action 4, numVisits=335, meanQ=14.234791, numObservations: 9
action 5, numVisits=2, meanQ=10.495000, numObservations: 2
action 2, numVisits=4, meanQ=8.497500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.216788 0.673433 0.49606 0.650198 0.288941 0.745771 0.967867 0.895638 0.500152 0.350945 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=2519, meanQ=17.390598, numObservations: 9
action 1, numVisits=14, meanQ=12.874286, numObservations: 5
action 2, numVisits=6, meanQ=12.333333, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 615940 episodes
GETTING ACTION FROM:
action 5, numVisits=618459, meanQ=18.137417, numObservations: 9
action 1, numVisits=14, meanQ=12.874286, numObservations: 5
action 2, numVisits=6, meanQ=12.333333, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 1 0.216788 0.673433 0.49606 0.650198 0.288941 0.745771 0.967867 0.895638 0.500152 0.350945 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 42
Initial state: 0 0.405463 0.143554 0.321182 0.76276 0.4851 0.393639 0.986964 0.494401 0.404052 0.709032 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 398468 episodes
GETTING ACTION FROM:
action 5, numVisits=398462, meanQ=13.234663, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 1 0.405463 0.143554 0.321182 0.76276 0.4851 0.393639 0.986964 0.494401 0.404052 0.709032 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 43
Initial state: 0 0.289393 0.553014 0.41257 0.308452 0.965476 0.413239 0.0183292 0.295103 0.380486 0.0590657 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 417216 episodes
GETTING ACTION FROM:
action 4, numVisits=417196, meanQ=13.235068, numObservations: 9
action 2, numVisits=9, meanQ=10.220000, numObservations: 6
action 1, numVisits=6, meanQ=8.456667, numObservations: 5
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 0 0.289393 0.553014 0.41257 0.308452 0.965476 0.413239 0.0183292 0.295103 0.380486 0.0590657 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=53176, meanQ=14.018559, numObservations: 9
action 2, numVisits=21, meanQ=8.178100, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 517516 episodes
GETTING ACTION FROM:
action 5, numVisits=570692, meanQ=15.788491, numObservations: 9
action 2, numVisits=21, meanQ=8.178100, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 0 0.289393 0.553014 0.41257 0.308452 0.965476 0.413239 0.0183292 0.295103 0.380486 0.0590657 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=5459, meanQ=13.705831, numObservations: 9
action 3, numVisits=4, meanQ=8.497500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 556942 episodes
GETTING ACTION FROM:
action 4, numVisits=562401, meanQ=13.665372, numObservations: 9
action 3, numVisits=4, meanQ=8.497500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.289393 0.553014 0.41257 0.308452 0.965476 0.413239 0.0183292 0.295103 0.380486 0.0590657 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 0, numVisits=137, meanQ=6.619287, numObservations: 62
action 4, numVisits=12, meanQ=-0.663292, numObservations: 4
action -1, numVisits=5, meanQ=-1.010000, numObservations: 5
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 603455 episodes
GETTING ACTION FROM:
action 1, numVisits=603183, meanQ=16.050467, numObservations: 9
action 0, numVisits=410, meanQ=1.669001, numObservations: 111
action 4, numVisits=12, meanQ=-0.663292, numObservations: 4
action -1, numVisits=5, meanQ=-1.010000, numObservations: 5
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.289393 0.553014 0.41257 0.308452 0.965476 0.413239 0.0183292 0.295103 0.380486 0.0590657 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 3, numVisits=4756, meanQ=16.906861, numObservations: 9
action 0, numVisits=7, meanQ=-1.010000, numObservations: 7
action -1, numVisits=3, meanQ=-1.673300, numObservations: 2
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 593958 episodes
GETTING ACTION FROM:
action 3, numVisits=598714, meanQ=18.654423, numObservations: 9
action 0, numVisits=7, meanQ=-1.010000, numObservations: 7
action -1, numVisits=3, meanQ=-1.673300, numObservations: 2
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.289393 0.553014 0.41257 0.308452 0.965476 0.413239 0.0183292 0.295103 0.380486 0.0590657 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.29271
Run # 44
Initial state: 0 0.750286 0.773144 0.783998 0.398298 0.0445385 0.793822 0.749271 0.905382 0.536675 0.337148 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 422537 episodes
GETTING ACTION FROM:
action 1, numVisits=422526, meanQ=13.320259, numObservations: 9
action 2, numVisits=6, meanQ=10.163350, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.750286 0.773144 0.783998 0.398298 0.0445385 0.793822 0.749271 0.905382 0.536675 0.337148 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 45
Initial state: 0 0.683467 0.415984 0.726152 0.451933 0.0864731 0.755479 0.766415 0.514148 0.462271 0.310506 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 420843 episodes
GETTING ACTION FROM:
action 2, numVisits=420828, meanQ=13.325293, numObservations: 9
action 4, numVisits=8, meanQ=9.000012, numObservations: 6
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.683467 0.415984 0.726152 0.451933 0.0864731 0.755479 0.766415 0.514148 0.462271 0.310506 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 46
Initial state: 0 0.421646 0.388849 0.404067 0.163097 0.549056 0.556407 0.53186 0.08727 0.855496 0.440638 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 405108 episodes
GETTING ACTION FROM:
action 5, numVisits=405091, meanQ=13.295291, numObservations: 9
action 3, numVisits=4, meanQ=8.497500, numObservations: 4
action 1, numVisits=7, meanQ=7.714314, numObservations: 5
action 4, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 2 0.421646 0.388849 0.404067 0.163097 0.549056 0.556407 0.53186 0.08727 0.855496 0.440638 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 47
Initial state: 0 0.90999 0.64355 0.795404 0.724277 0.468426 0.637358 0.479259 0.372757 0.0190641 0.611671 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 418892 episodes
GETTING ACTION FROM:
action 5, numVisits=418881, meanQ=13.250031, numObservations: 9
action 3, numVisits=6, meanQ=2.681667, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.90999 0.64355 0.795404 0.724277 0.468426 0.637358 0.479259 0.372757 0.0190641 0.611671 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=52956, meanQ=13.960906, numObservations: 9
action 2, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 488533 episodes
GETTING ACTION FROM:
action 1, numVisits=541489, meanQ=14.768079, numObservations: 9
action 2, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.90999 0.64355 0.795404 0.724277 0.468426 0.637358 0.479259 0.372757 0.0190641 0.611671 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 48
Initial state: 0 0.597386 0.820106 0.734795 0.866511 0.151904 0.121677 0.0780855 0.274868 0.410404 0.39776 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 420293 episodes
GETTING ACTION FROM:
action 2, numVisits=420259, meanQ=13.362848, numObservations: 9
action 4, numVisits=18, meanQ=9.763894, numObservations: 8
action 3, numVisits=6, meanQ=6.500000, numObservations: 4
action 1, numVisits=7, meanQ=6.301443, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.597386 0.820106 0.734795 0.866511 0.151904 0.121677 0.0780855 0.274868 0.410404 0.39776 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 49
Initial state: 0 0.534604 0.311176 0.134296 0.45878 0.423182 0.811956 0.695884 0.868833 0.678158 0.573857 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 423451 episodes
GETTING ACTION FROM:
action 4, numVisits=423442, meanQ=13.301127, numObservations: 9
action 5, numVisits=4, meanQ=-0.252500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.534604 0.311176 0.134296 0.45878 0.423182 0.811956 0.695884 0.868833 0.678158 0.573857 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 50
Initial state: 0 0.907837 0.948133 0.205322 0.880768 0.0457268 0.0753061 0.406088 0.393804 0.0506369 0.454485 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 422786 episodes
GETTING ACTION FROM:
action 1, numVisits=422777, meanQ=13.337552, numObservations: 9
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action 4, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.907837 0.948133 0.205322 0.880768 0.0457268 0.0753061 0.406088 0.393804 0.0506369 0.454485 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
[32m ProblemEnvironment.hpp 351: Done.[39m
