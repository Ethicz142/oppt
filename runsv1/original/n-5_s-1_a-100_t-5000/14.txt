Run # 1
Initial state: 0 0.428604 0.541604 0.456305 0.713641 0.833343 0.130303 0.300794 0.136762 0.377522 0.502701 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 661558 episodes
GETTING ACTION FROM:
action 4, numVisits=661210, meanQ=11.613536, numObservations: 9
action 1, numVisits=337, meanQ=11.212594, numObservations: 9
action 2, numVisits=5, meanQ=6.196000, numObservations: 3
action 5, numVisits=3, meanQ=5.330033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 0 0.428604 0.541604 0.456305 0.713641 0.833343 0.130303 0.300794 0.136762 0.377522 0.502701 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=59126, meanQ=12.588490, numObservations: 9
action 1, numVisits=1252, meanQ=12.389809, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 843793 episodes
GETTING ACTION FROM:
action 2, numVisits=902669, meanQ=12.165075, numObservations: 9
action 1, numVisits=1502, meanQ=11.969818, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.428604 0.541604 0.456305 0.713641 0.833343 0.130303 0.300794 0.136762 0.377522 0.502701 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 2
Initial state: 0 0.244742 0.726806 0.77828 0.745008 0.791287 0.813537 0.485093 0.50044 0.114146 0.905415 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 694752 episodes
GETTING ACTION FROM:
action 2, numVisits=694738, meanQ=11.797435, numObservations: 9
action 5, numVisits=9, meanQ=3.330000, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.244742 0.726806 0.77828 0.745008 0.791287 0.813537 0.485093 0.50044 0.114146 0.905415 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 3
Initial state: 0 0.344817 0.0543466 0.472231 0.43382 0.533454 0.65049 0.536507 0.945213 0.114905 0.769558 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 700694 episodes
GETTING ACTION FROM:
action 5, numVisits=700681, meanQ=11.844735, numObservations: 9
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action 3, numVisits=5, meanQ=6.196000, numObservations: 4
action 2, numVisits=3, meanQ=4.670033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 1 0.344817 0.0543466 0.472231 0.43382 0.533454 0.65049 0.536507 0.945213 0.114905 0.769558 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 4
Initial state: 0 0.420454 0.0923239 0.448545 0.461348 0.65528 0.583884 0.62796 0.687206 0.88 0.381378 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 701807 episodes
GETTING ACTION FROM:
action 1, numVisits=701795, meanQ=11.775129, numObservations: 9
action 4, numVisits=7, meanQ=5.998586, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.420454 0.0923239 0.448545 0.461348 0.65528 0.583884 0.62796 0.687206 0.88 0.381378 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 5
Initial state: 0 0.43069 0.403354 0.0442753 0.878393 0.997076 0.839287 0.718841 0.787085 0.939856 0.983338 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 692874 episodes
GETTING ACTION FROM:
action 3, numVisits=692868, meanQ=11.717313, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.43069 0.403354 0.0442753 0.878393 0.997076 0.839287 0.718841 0.787085 0.939856 0.983338 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 6
Initial state: 0 0.989416 0.148231 0.477126 0.484516 0.00394321 0.463325 0.256438 0.773936 0.172834 0.106016 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 702560 episodes
GETTING ACTION FROM:
action 1, numVisits=702553, meanQ=11.792467, numObservations: 9
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.989416 0.148231 0.477126 0.484516 0.00394321 0.463325 0.256438 0.773936 0.172834 0.106016 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 7
Initial state: 0 0.601372 0.736094 0.221945 0.534143 0.403885 0.137895 0.39839 0.41826 0.65811 0.312043 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 695305 episodes
GETTING ACTION FROM:
action 2, numVisits=695298, meanQ=11.766763, numObservations: 9
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.601372 0.736094 0.221945 0.534143 0.403885 0.137895 0.39839 0.41826 0.65811 0.312043 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=71988, meanQ=12.840258, numObservations: 9
action 3, numVisits=7, meanQ=6.282857, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 844247 episodes
GETTING ACTION FROM:
action 5, numVisits=916235, meanQ=14.253798, numObservations: 9
action 3, numVisits=7, meanQ=6.282857, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.601372 0.736094 0.221945 0.534143 0.403885 0.137895 0.39839 0.41826 0.65811 0.312043 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 8
Initial state: 0 0.490496 0.441324 0.557467 0.91101 0.169593 0.332451 0.665428 0.980285 0.558976 0.0206321 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 688200 episodes
GETTING ACTION FROM:
action 3, numVisits=688183, meanQ=11.745020, numObservations: 9
action 1, numVisits=12, meanQ=8.144167, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.490496 0.441324 0.557467 0.91101 0.169593 0.332451 0.665428 0.980285 0.558976 0.0206321 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 9
Initial state: 0 0.692735 0.323051 0.302312 0.993825 0.424368 0.446973 0.629838 0.613926 0.95 0.739901 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 703680 episodes
GETTING ACTION FROM:
action 4, numVisits=703671, meanQ=11.812451, numObservations: 9
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action 3, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 1 0.692735 0.323051 0.302312 0.993825 0.424368 0.446973 0.629838 0.613926 0.95 0.739901 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 10
Initial state: 0 0.744944 0.697695 0.0197822 0.109866 0.196345 0.108918 0.455376 0.367657 0.779694 0.770022 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 694921 episodes
GETTING ACTION FROM:
action 3, numVisits=694896, meanQ=11.676915, numObservations: 9
action 5, numVisits=18, meanQ=9.116111, numObservations: 8
action 4, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.744944 0.697695 0.0197822 0.109866 0.196345 0.108918 0.455376 0.367657 0.779694 0.770022 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=15575, meanQ=12.611812, numObservations: 9
action 2, numVisits=19, meanQ=8.313689, numObservations: 7
action 1, numVisits=8, meanQ=7.498750, numObservations: 5
action 5, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 945128 episodes
GETTING ACTION FROM:
action 4, numVisits=954956, meanQ=8.111687, numObservations: 9
action 2, numVisits=5721, meanQ=8.012938, numObservations: 9
action 1, numVisits=52, meanQ=7.038271, numObservations: 9
action 5, numVisits=4, meanQ=3.742500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.744944 0.697695 0.0197822 0.109866 0.196345 0.108918 0.455376 0.367657 0.779694 0.770022 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 11
Initial state: 0 0.86137 0.666431 0.14348 0.801506 0.414803 0.93658 0.357578 0.846608 0.418599 0.415056 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 681924 episodes
GETTING ACTION FROM:
action 1, numVisits=681910, meanQ=11.609121, numObservations: 9
action 4, numVisits=5, meanQ=-0.804000, numObservations: 4
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.86137 0.666431 0.14348 0.801506 0.414803 0.93658 0.357578 0.846608 0.418599 0.415056 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 12
Initial state: 0 0.498625 0.356095 0.502864 0.889549 0.206237 0.185535 0.810647 0.0125145 0.810119 0.962669 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 703209 episodes
GETTING ACTION FROM:
action 4, numVisits=703203, meanQ=11.687039, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.498625 0.356095 0.502864 0.889549 0.206237 0.185535 0.810647 0.0125145 0.810119 0.962669 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 13
Initial state: 0 0.107009 0.94816 0.390916 0.460588 0.233401 0.647914 0.930417 0.59845 0.969397 0.503467 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 703175 episodes
GETTING ACTION FROM:
action 5, numVisits=703142, meanQ=11.747645, numObservations: 9
action 2, numVisits=18, meanQ=9.555561, numObservations: 8
action 4, numVisits=11, meanQ=8.463636, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.107009 0.94816 0.390916 0.460588 0.233401 0.647914 0.930417 0.59845 0.969397 0.503467 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 14
Initial state: 0 0.0717 0.200127 0.631195 0.325975 0.259087 0.50649 0.40675 0.400745 0.0583743 0.728477 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 705862 episodes
GETTING ACTION FROM:
action 5, numVisits=705849, meanQ=11.780270, numObservations: 9
action 2, numVisits=8, meanQ=8.011250, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 0 0.0717 0.200127 0.631195 0.325975 0.259087 0.50649 0.40675 0.400745 0.0583743 0.728477 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=72648, meanQ=12.765196, numObservations: 9
action 5, numVisits=270, meanQ=12.354666, numObservations: 7
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 861132 episodes
GETTING ACTION FROM:
action 4, numVisits=933780, meanQ=14.862638, numObservations: 9
action 5, numVisits=270, meanQ=12.354666, numObservations: 7
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.0717 0.200127 0.631195 0.325975 0.259087 0.50649 0.40675 0.400745 0.0583743 0.728477 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 15
Initial state: 0 0.645798 0.352768 0.445863 0.447941 0.2035 0.330382 0.755078 0.0867412 0.872599 0.667637 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 695810 episodes
GETTING ACTION FROM:
action 5, numVisits=695803, meanQ=11.696002, numObservations: 9
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 2 0.645798 0.352768 0.445863 0.447941 0.2035 0.330382 0.755078 0.0867412 0.872599 0.667637 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 16
Initial state: 0 0.498119 0.351378 0.0656482 0.750905 0.408707 0.272386 0.173368 0.221772 0.0543911 0.112384 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 702173 episodes
GETTING ACTION FROM:
action 2, numVisits=702164, meanQ=11.812867, numObservations: 9
action 5, numVisits=4, meanQ=2.750025, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.498119 0.351378 0.0656482 0.750905 0.408707 0.272386 0.173368 0.221772 0.0543911 0.112384 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=73361, meanQ=12.728451, numObservations: 9
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action 2, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 871505 episodes
GETTING ACTION FROM:
action 5, numVisits=944866, meanQ=15.355549, numObservations: 9
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action 2, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.498119 0.351378 0.0656482 0.750905 0.408707 0.272386 0.173368 0.221772 0.0543911 0.112384 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=53554, meanQ=16.398237, numObservations: 9
action 4, numVisits=6, meanQ=10.163350, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 925084 episodes
GETTING ACTION FROM:
action 1, numVisits=978638, meanQ=15.842910, numObservations: 9
action 4, numVisits=6, meanQ=10.163350, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.498119 0.351378 0.0656482 0.750905 0.408707 0.272386 0.173368 0.221772 0.0543911 0.112384 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=1992, meanQ=14.498704, numObservations: 9
action 3, numVisits=9, meanQ=6.997789, numObservations: 4
action 4, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1026523 episodes
GETTING ACTION FROM:
action 1, numVisits=1028515, meanQ=14.398565, numObservations: 9
action 3, numVisits=9, meanQ=6.997789, numObservations: 4
action 4, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.498119 0.351378 0.0656482 0.750905 0.408707 0.272386 0.173368 0.221772 0.0543911 0.112384 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 11.4068
Run # 17
Initial state: 0 0.671229 0.575302 0.401625 0.484495 0.746401 0.805757 0.65763 0.452361 0.976825 0.155941 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 703730 episodes
GETTING ACTION FROM:
action 1, numVisits=703724, meanQ=11.789131, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.671229 0.575302 0.401625 0.484495 0.746401 0.805757 0.65763 0.452361 0.976825 0.155941 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 18
Initial state: 0 0.854905 0.582775 0.136435 0.839464 0.209511 0.152128 0.408123 0.250234 0.495302 0.359518 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 695487 episodes
GETTING ACTION FROM:
action 4, numVisits=695456, meanQ=11.724872, numObservations: 9
action 2, numVisits=17, meanQ=-0.648229, numObservations: 7
action -1, numVisits=5, meanQ=-1.010000, numObservations: 5
action 0, numVisits=5, meanQ=-1.010000, numObservations: 5
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.854905 0.582775 0.136435 0.839464 0.209511 0.152128 0.408123 0.250234 0.495302 0.359518 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 19
Initial state: 0 0.621204 0.5813 0.482327 0.368563 0.872966 0.54244 0.763143 0.235953 0.194189 0.845508 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 696474 episodes
GETTING ACTION FROM:
action 2, numVisits=696468, meanQ=11.788788, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.621204 0.5813 0.482327 0.368563 0.872966 0.54244 0.763143 0.235953 0.194189 0.845508 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 20
Initial state: 0 0.427634 0.42385 0.0227001 0.157529 0.574358 0.69951 0.271194 0.0968142 0.296894 0.975062 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 674065 episodes
GETTING ACTION FROM:
action 2, numVisits=674055, meanQ=11.772564, numObservations: 9
action 5, numVisits=3, meanQ=5.993333, numObservations: 3
action 1, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.427634 0.42385 0.0227001 0.157529 0.574358 0.69951 0.271194 0.0968142 0.296894 0.975062 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 21
Initial state: 0 0.782053 0.246968 0.405324 0.411776 0.511582 0.151512 0.732403 0.639239 0.558501 0.0639467 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 699082 episodes
GETTING ACTION FROM:
action 4, numVisits=699062, meanQ=11.724502, numObservations: 9
action 3, numVisits=15, meanQ=7.982007, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.782053 0.246968 0.405324 0.411776 0.511582 0.151512 0.732403 0.639239 0.558501 0.0639467 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 22
Initial state: 0 0.235764 0.534856 0.184504 0.617054 0.0382112 0.120325 0.691043 0.582247 0.39456 0.488748 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 698735 episodes
GETTING ACTION FROM:
action 4, numVisits=698722, meanQ=11.606799, numObservations: 9
action 2, numVisits=8, meanQ=3.123750, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.235764 0.534856 0.184504 0.617054 0.0382112 0.120325 0.691043 0.582247 0.39456 0.488748 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 23
Initial state: 0 0.121868 0.0751979 0.450455 0.505838 0.770089 0.103156 0.98668 0.0808454 0.208635 0.324571 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 698136 episodes
GETTING ACTION FROM:
action 4, numVisits=698122, meanQ=11.657892, numObservations: 9
action 1, numVisits=7, meanQ=6.282857, numObservations: 6
action 2, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 2 0.121868 0.0751979 0.450455 0.505838 0.770089 0.103156 0.98668 0.0808454 0.208635 0.324571 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 24
Initial state: 0 0.835577 0.290095 0.49713 0.395715 0.133847 0.144909 0.554866 0.790173 0.372255 0.824594 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 686616 episodes
GETTING ACTION FROM:
action 2, numVisits=686606, meanQ=11.774819, numObservations: 9
action 4, numVisits=3, meanQ=3.330000, numObservations: 3
action 1, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.835577 0.290095 0.49713 0.395715 0.133847 0.144909 0.554866 0.790173 0.372255 0.824594 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 25
Initial state: 0 0.724784 0.12044 0.651615 0.708315 0.429215 0.504731 0.718293 0.334888 0.734691 0.454769 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 699242 episodes
GETTING ACTION FROM:
action 3, numVisits=699233, meanQ=11.764582, numObservations: 9
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.724784 0.12044 0.651615 0.708315 0.429215 0.504731 0.718293 0.334888 0.734691 0.454769 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 26
Initial state: 0 0.478063 0.451781 0.216288 0.915682 0.701007 0.546311 0.136165 0.24163 0.976447 0.178226 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 701821 episodes
GETTING ACTION FROM:
action 2, numVisits=701815, meanQ=11.832499, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.478063 0.451781 0.216288 0.915682 0.701007 0.546311 0.136165 0.24163 0.976447 0.178226 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=5206, meanQ=11.348781, numObservations: 9
action 4, numVisits=19, meanQ=6.851579, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 987166 episodes
GETTING ACTION FROM:
action 1, numVisits=992372, meanQ=14.430682, numObservations: 9
action 4, numVisits=19, meanQ=6.851579, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.478063 0.451781 0.216288 0.915682 0.701007 0.546311 0.136165 0.24163 0.976447 0.178226 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 27
Initial state: 0 0.52475 0.22184 0.230451 0.922501 0.19956 0.198179 0.0966235 0.59623 0.483655 0.420181 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 697573 episodes
GETTING ACTION FROM:
action 4, numVisits=697552, meanQ=11.722398, numObservations: 9
action -1, numVisits=8, meanQ=-1.010000, numObservations: 8
action 0, numVisits=8, meanQ=-1.010000, numObservations: 8
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.52475 0.22184 0.230451 0.922501 0.19956 0.198179 0.0966235 0.59623 0.483655 0.420181 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=64372, meanQ=12.841665, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 779502 episodes
GETTING ACTION FROM:
action 3, numVisits=843874, meanQ=11.758252, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.52475 0.22184 0.230451 0.922501 0.19956 0.198179 0.0966235 0.59623 0.483655 0.420181 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=10660, meanQ=12.268660, numObservations: 9
action 1, numVisits=5, meanQ=4.598000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 943216 episodes
GETTING ACTION FROM:
action 5, numVisits=953876, meanQ=8.600162, numObservations: 9
action 1, numVisits=5, meanQ=4.598000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.52475 0.22184 0.230451 0.922501 0.19956 0.198179 0.0966235 0.59623 0.483655 0.420181 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 28
Initial state: 0 0.0599062 0.144849 0.773715 0.268632 0.51685 0.259392 0.482022 0.461642 0.29494 0.586548 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 696438 episodes
GETTING ACTION FROM:
action 4, numVisits=696408, meanQ=11.793450, numObservations: 9
action 5, numVisits=23, meanQ=9.977835, numObservations: 7
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 1 0.0599062 0.144849 0.773715 0.268632 0.51685 0.259392 0.482022 0.461642 0.29494 0.586548 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 29
Initial state: 0 0.116604 0.720826 0.48371 0.602247 0.62353 0.065185 0.0183445 0.0872568 0.472668 0.367311 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 698325 episodes
GETTING ACTION FROM:
action 5, numVisits=698306, meanQ=11.788907, numObservations: 9
action 3, numVisits=11, meanQ=9.543636, numObservations: 5
action 1, numVisits=4, meanQ=6.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.116604 0.720826 0.48371 0.602247 0.62353 0.065185 0.0183445 0.0872568 0.472668 0.367311 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 30
Initial state: 0 0.751031 0.741835 0.739913 0.983173 0.555449 0.321413 0.377619 0.908424 0.492028 0.480487 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 691144 episodes
GETTING ACTION FROM:
action 5, numVisits=691124, meanQ=11.797403, numObservations: 9
action 3, numVisits=6, meanQ=7.831667, numObservations: 6
action 4, numVisits=4, meanQ=7.525000, numObservations: 2
action 1, numVisits=5, meanQ=6.196000, numObservations: 4
action 2, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 5
Next state: 1 0.751031 0.741835 0.739913 0.983173 0.555449 0.321413 0.377619 0.908424 0.492028 0.480487 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 31
Initial state: 0 0.49734 0.39817 0.680629 0.25375 0.875915 0.996029 0.0458451 0.62003 0.938911 0.928331 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 696089 episodes
GETTING ACTION FROM:
action 4, numVisits=695977, meanQ=11.799253, numObservations: 9
action 5, numVisits=78, meanQ=7.969496, numObservations: 9
action 3, numVisits=30, meanQ=7.826010, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 0 0.49734 0.39817 0.680629 0.25375 0.875915 0.996029 0.0458451 0.62003 0.938911 0.928331 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=72561, meanQ=12.704613, numObservations: 9
action 1, numVisits=17, meanQ=7.470012, numObservations: 8
action 2, numVisits=7, meanQ=5.141429, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 831963 episodes
GETTING ACTION FROM:
action 3, numVisits=904524, meanQ=13.636945, numObservations: 9
action 1, numVisits=17, meanQ=7.470012, numObservations: 8
action 2, numVisits=7, meanQ=5.141429, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.49734 0.39817 0.680629 0.25375 0.875915 0.996029 0.0458451 0.62003 0.938911 0.928331 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 32
Initial state: 0 0.723623 0.150454 0.591168 0.50123 0.73377 0.794552 0.237378 0.383749 0.382989 0.466606 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 696142 episodes
GETTING ACTION FROM:
action 4, numVisits=696107, meanQ=11.785476, numObservations: 9
action 1, numVisits=28, meanQ=9.887514, numObservations: 9
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.723623 0.150454 0.591168 0.50123 0.73377 0.794552 0.237378 0.383749 0.382989 0.466606 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=18718, meanQ=12.571399, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 858781 episodes
GETTING ACTION FROM:
action 1, numVisits=877499, meanQ=11.864784, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.723623 0.150454 0.591168 0.50123 0.73377 0.794552 0.237378 0.383749 0.382989 0.466606 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 33
Initial state: 0 0.216724 0.325003 0.815452 0.160778 0.473591 0.398761 0.624118 0.103864 0.0498969 0.836048 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 699722 episodes
GETTING ACTION FROM:
action 1, numVisits=699704, meanQ=11.837504, numObservations: 9
action 4, numVisits=13, meanQ=2.227692, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.216724 0.325003 0.815452 0.160778 0.473591 0.398761 0.624118 0.103864 0.0498969 0.836048 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=64154, meanQ=12.811834, numObservations: 9
action 4, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 815028 episodes
GETTING ACTION FROM:
action 3, numVisits=879182, meanQ=12.559470, numObservations: 9
action 4, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.216724 0.325003 0.815452 0.160778 0.473591 0.398761 0.624118 0.103864 0.0498969 0.836048 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 34
Initial state: 0 0.555489 0.782338 0.205618 0.0662865 0.358862 0.853511 0.0313438 0.933807 0.482342 0.347428 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 568879 episodes
GETTING ACTION FROM:
action 4, numVisits=568864, meanQ=11.988828, numObservations: 9
action 5, numVisits=8, meanQ=0.216250, numObservations: 6
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.555489 0.782338 0.205618 0.0662865 0.358862 0.853511 0.0313438 0.933807 0.482342 0.347428 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 35
Initial state: 0 0.113411 0.210878 0.0199183 0.85096 0.486948 0.400998 0.351609 0.20433 0.518753 0.539714 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 676962 episodes
GETTING ACTION FROM:
action 2, numVisits=676956, meanQ=11.767678, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.113411 0.210878 0.0199183 0.85096 0.486948 0.400998 0.351609 0.20433 0.518753 0.539714 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=70193, meanQ=12.594575, numObservations: 9
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 698527 episodes
GETTING ACTION FROM:
action 2, numVisits=768720, meanQ=16.081016, numObservations: 9
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.113411 0.210878 0.0199183 0.85096 0.486948 0.400998 0.351609 0.20433 0.518753 0.539714 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=271119, meanQ=13.396975, numObservations: 9
action 3, numVisits=19, meanQ=7.669484, numObservations: 6
action 5, numVisits=18, meanQ=7.111128, numObservations: 8
action 4, numVisits=11, meanQ=7.100009, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 890292 episodes
GETTING ACTION FROM:
action 1, numVisits=1161411, meanQ=14.957870, numObservations: 9
action 3, numVisits=19, meanQ=7.669484, numObservations: 6
action 5, numVisits=18, meanQ=7.111128, numObservations: 8
action 4, numVisits=11, meanQ=7.100009, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.113411 0.210878 0.0199183 0.85096 0.486948 0.400998 0.351609 0.20433 0.518753 0.539714 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=46952, meanQ=14.380425, numObservations: 9
action 4, numVisits=4, meanQ=6.500000, numObservations: 4
action 3, numVisits=5, meanQ=5.798020, numObservations: 3
action 5, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 867981 episodes
GETTING ACTION FROM:
action 2, numVisits=914933, meanQ=20.123572, numObservations: 9
action 4, numVisits=4, meanQ=6.500000, numObservations: 4
action 3, numVisits=5, meanQ=5.798020, numObservations: 3
action 5, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.113411 0.210878 0.0199183 0.85096 0.486948 0.400998 0.351609 0.20433 0.518753 0.539714 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 4, numVisits=158759, meanQ=17.091527, numObservations: 9
action 2, numVisits=4, meanQ=1.757550, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 981587 episodes
GETTING ACTION FROM:
action 4, numVisits=1140346, meanQ=16.256085, numObservations: 9
action 2, numVisits=4, meanQ=1.757550, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.113411 0.210878 0.0199183 0.85096 0.486948 0.400998 0.351609 0.20433 0.518753 0.539714 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 5
Improving policy...
PLANNING FROM:
action 5, numVisits=3509, meanQ=17.227147, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 3, numVisits=2, meanQ=-3.010000, numObservations: 2
action 4, numVisits=2, meanQ=-3.010000, numObservations: 2
action 2, numVisits=2, meanQ=-4.994950, numObservations: 1
Sampled 1019779 episodes
GETTING ACTION FROM:
action 5, numVisits=1023288, meanQ=20.313465, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 3, numVisits=2, meanQ=-3.010000, numObservations: 2
action 4, numVisits=2, meanQ=-3.010000, numObservations: 2
action 2, numVisits=2, meanQ=-4.994950, numObservations: 1
action: 5
Next state: 1 0.113411 0.210878 0.0199183 0.85096 0.486948 0.400998 0.351609 0.20433 0.518753 0.539714 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 3.21978
Run # 36
Initial state: 0 0.947069 0.485976 0.762953 0.0402466 0.478994 0.349996 0.810913 0.0626203 0.619959 0.979445 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 674969 episodes
GETTING ACTION FROM:
action 3, numVisits=674961, meanQ=11.665932, numObservations: 9
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.947069 0.485976 0.762953 0.0402466 0.478994 0.349996 0.810913 0.0626203 0.619959 0.979445 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 37
Initial state: 0 0.222087 0.777586 0.907689 0.0247865 0.33909 0.301894 0.480176 0.490117 0.0197245 0.144148 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 696590 episodes
GETTING ACTION FROM:
action 1, numVisits=696575, meanQ=11.760470, numObservations: 9
action 2, numVisits=6, meanQ=7.831667, numObservations: 3
action 4, numVisits=5, meanQ=6.196000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.222087 0.777586 0.907689 0.0247865 0.33909 0.301894 0.480176 0.490117 0.0197245 0.144148 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=63686, meanQ=12.784638, numObservations: 9
action 2, numVisits=7, meanQ=7.140014, numObservations: 6
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 818620 episodes
GETTING ACTION FROM:
action 4, numVisits=882304, meanQ=11.463185, numObservations: 9
action 2, numVisits=7, meanQ=7.140014, numObservations: 6
action 3, numVisits=4, meanQ=6.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.222087 0.777586 0.907689 0.0247865 0.33909 0.301894 0.480176 0.490117 0.0197245 0.144148 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 38
Initial state: 0 0.507925 0.792854 0.443992 0.468428 0.893934 0.445059 0.567816 0.962947 0.281298 0.218077 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 673742 episodes
GETTING ACTION FROM:
action 1, numVisits=673713, meanQ=11.696213, numObservations: 9
action 3, numVisits=20, meanQ=7.899505, numObservations: 7
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action 5, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.507925 0.792854 0.443992 0.468428 0.893934 0.445059 0.567816 0.962947 0.281298 0.218077 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 39
Initial state: 0 0.639186 0.38876 0.172203 0.679019 0.103689 0.221892 0.495071 0.358461 0.145241 0.82548 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 687432 episodes
GETTING ACTION FROM:
action 2, numVisits=687424, meanQ=11.767488, numObservations: 9
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action 4, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.639186 0.38876 0.172203 0.679019 0.103689 0.221892 0.495071 0.358461 0.145241 0.82548 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 40
Initial state: 0 0.395086 0.47451 0.328222 0.766421 0.918462 0.563519 0.238152 0.887102 0.0423616 0.563155 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 696727 episodes
GETTING ACTION FROM:
action 3, numVisits=696712, meanQ=11.751258, numObservations: 9
action 2, numVisits=6, meanQ=-0.171650, numObservations: 4
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.395086 0.47451 0.328222 0.766421 0.918462 0.563519 0.238152 0.887102 0.0423616 0.563155 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 41
Initial state: 0 0.879777 0.452472 0.872075 0.26025 0.442299 0.492129 0.00635085 0.251379 0.951868 0.017807 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 696179 episodes
GETTING ACTION FROM:
action 3, numVisits=696139, meanQ=11.740094, numObservations: 9
action 2, numVisits=34, meanQ=9.764712, numObservations: 9
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.879777 0.452472 0.872075 0.26025 0.442299 0.492129 0.00635085 0.251379 0.951868 0.017807 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 42
Initial state: 0 0.246983 0.729167 0.557197 0.0156617 0.534243 0.742683 0.440354 0.422269 0.191749 0.460183 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 694410 episodes
GETTING ACTION FROM:
action 2, numVisits=688589, meanQ=11.779242, numObservations: 9
action 1, numVisits=5816, meanQ=11.686200, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.246983 0.729167 0.557197 0.0156617 0.534243 0.742683 0.440354 0.422269 0.191749 0.460183 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 43
Initial state: 0 0.166122 0.114916 0.946696 0.287462 0.517354 0.910381 0.178922 0.269992 0.420868 0.504989 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 694651 episodes
GETTING ACTION FROM:
action 2, numVisits=694629, meanQ=11.758244, numObservations: 9
action 1, numVisits=15, meanQ=6.798673, numObservations: 6
action 4, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.166122 0.114916 0.946696 0.287462 0.517354 0.910381 0.178922 0.269992 0.420868 0.504989 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 44
Initial state: 0 0.403652 0.403501 0.82468 0.964389 0.533051 0.803472 0.48414 0.636649 0.775291 0.7388 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 206930 episodes
GETTING ACTION FROM:
action 0, numVisits=206837, meanQ=16.388925, numObservations: 243
action -1, numVisits=80, meanQ=-0.912114, numObservations: 68
action 5, numVisits=7, meanQ=-2.285686, numObservations: 3
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action 2, numVisits=2, meanQ=-8.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.403652 0.403501 0.82468 0.964389 0.533051 0.803472 0.48414 0.636649 0.775291 0.7388 w: 1
Observation: 0 0 2 0 3 0 3 0 3 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=2701, meanQ=21.886148, numObservations: 9
action 4, numVisits=7, meanQ=15.998586, numObservations: 4
action 5, numVisits=3, meanQ=14.996667, numObservations: 2
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 936840 episodes
GETTING ACTION FROM:
action 1, numVisits=939541, meanQ=22.410012, numObservations: 9
action 4, numVisits=7, meanQ=15.998586, numObservations: 4
action 5, numVisits=3, meanQ=14.996667, numObservations: 2
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.403652 0.403501 0.82468 0.964389 0.533051 0.803472 0.48414 0.636649 0.775291 0.7388 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 45
Initial state: 0 0.114063 0.79825 0.761897 0.272618 0.653428 0.102611 0.414934 0.432933 0.492855 0.256092 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 698952 episodes
GETTING ACTION FROM:
action 4, numVisits=698945, meanQ=11.788688, numObservations: 9
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.114063 0.79825 0.761897 0.272618 0.653428 0.102611 0.414934 0.432933 0.492855 0.256092 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 46
Initial state: 0 0.781731 0.512862 0.0701501 0.632723 0.66007 0.702562 0.474881 0.419147 0.299472 0.0384748 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 692338 episodes
GETTING ACTION FROM:
action 2, numVisits=692321, meanQ=11.797393, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.781731 0.512862 0.0701501 0.632723 0.66007 0.702562 0.474881 0.419147 0.299472 0.0384748 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=71943, meanQ=12.881040, numObservations: 9
action 1, numVisits=5, meanQ=6.196000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 831002 episodes
GETTING ACTION FROM:
action 3, numVisits=902945, meanQ=14.427216, numObservations: 9
action 1, numVisits=5, meanQ=6.196000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.781731 0.512862 0.0701501 0.632723 0.66007 0.702562 0.474881 0.419147 0.299472 0.0384748 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 47
Initial state: 0 0.440564 0.452533 0.162689 0.925713 0.985428 0.960484 0.708568 0.34289 0.380651 0.0430785 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 694746 episodes
GETTING ACTION FROM:
action 3, numVisits=694738, meanQ=11.722128, numObservations: 9
action 1, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.440564 0.452533 0.162689 0.925713 0.985428 0.960484 0.708568 0.34289 0.380651 0.0430785 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 48
Initial state: 0 0.433408 0.381272 0.760045 0.020143 0.252526 0.743646 0.452489 0.285238 0.945569 0.0947898 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 697106 episodes
GETTING ACTION FROM:
action 4, numVisits=697095, meanQ=11.781741, numObservations: 9
action 2, numVisits=6, meanQ=3.330000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.433408 0.381272 0.760045 0.020143 0.252526 0.743646 0.452489 0.285238 0.945569 0.0947898 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 49
Initial state: 0 0.432483 0.552652 0.138317 0.273387 0.950698 0.554514 0.758001 0.762286 0.478726 0.358627 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 675768 episodes
GETTING ACTION FROM:
action 3, numVisits=675743, meanQ=11.622585, numObservations: 9
action 1, numVisits=18, meanQ=9.748889, numObservations: 7
action 4, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.432483 0.552652 0.138317 0.273387 0.950698 0.554514 0.758001 0.762286 0.478726 0.358627 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 50
Initial state: 0 0.351635 0.912436 0.503738 0.372577 0.553879 0.176634 0.999562 0.950974 0.0311294 0.0301535 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 696830 episodes
GETTING ACTION FROM:
action 2, numVisits=696821, meanQ=11.841886, numObservations: 9
action 4, numVisits=4, meanQ=1.745000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.351635 0.912436 0.503738 0.372577 0.553879 0.176634 0.999562 0.950974 0.0311294 0.0301535 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
[32m ProblemEnvironment.hpp 351: Done.[39m
