Run # 1
Initial state: 0 0.266852 0.0148034 0.371753 0.847125 0.808277 0.584539 0.385841 0.279893 0.376172 0.534694 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 649769 episodes
GETTING ACTION FROM:
action 4, numVisits=649763, meanQ=9.869532, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.266852 0.0148034 0.371753 0.847125 0.808277 0.584539 0.385841 0.279893 0.376172 0.534694 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 2
Initial state: 0 0.751602 0.84394 0.748778 0.216022 0.531416 0.457499 0.196005 0.312366 0.114463 0.0146206 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 680680 episodes
GETTING ACTION FROM:
action 3, numVisits=680662, meanQ=9.997181, numObservations: 9
action 4, numVisits=9, meanQ=-0.113311, numObservations: 5
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.751602 0.84394 0.748778 0.216022 0.531416 0.457499 0.196005 0.312366 0.114463 0.0146206 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 3
Initial state: 0 0.926172 0.877637 0.208472 0.215135 0.461051 0.54044 0.430766 0.182622 0.329835 0.912493 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 691569 episodes
GETTING ACTION FROM:
action 1, numVisits=691557, meanQ=10.033008, numObservations: 9
action 2, numVisits=5, meanQ=6.196000, numObservations: 4
action 5, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.926172 0.877637 0.208472 0.215135 0.461051 0.54044 0.430766 0.182622 0.329835 0.912493 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 4
Initial state: 0 0.0698928 0.677939 0.966534 0.666605 0.506681 0.488093 0.943793 0.75869 0.988586 0.89127 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 684268 episodes
GETTING ACTION FROM:
action 1, numVisits=684262, meanQ=9.998623, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.0698928 0.677939 0.966534 0.666605 0.506681 0.488093 0.943793 0.75869 0.988586 0.89127 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=62509, meanQ=11.246925, numObservations: 9
action 5, numVisits=3, meanQ=3.330000, numObservations: 3
action 1, numVisits=4, meanQ=3.245025, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 853637 episodes
GETTING ACTION FROM:
action 3, numVisits=916146, meanQ=12.831515, numObservations: 9
action 5, numVisits=3, meanQ=3.330000, numObservations: 3
action 1, numVisits=4, meanQ=3.245025, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.0698928 0.677939 0.966534 0.666605 0.506681 0.488093 0.943793 0.75869 0.988586 0.89127 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=20697, meanQ=10.697656, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 909370 episodes
GETTING ACTION FROM:
action 4, numVisits=930067, meanQ=13.884441, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.0698928 0.677939 0.966534 0.666605 0.506681 0.488093 0.943793 0.75869 0.988586 0.89127 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 5
Initial state: 0 0.155457 0.12408 0.642146 0.820132 0.0947201 0.874964 0.294065 0.0442407 0.506709 0.450509 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 687508 episodes
GETTING ACTION FROM:
action 3, numVisits=687441, meanQ=10.005634, numObservations: 9
action 5, numVisits=27, meanQ=6.110011, numObservations: 7
action 2, numVisits=36, meanQ=5.946956, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.155457 0.12408 0.642146 0.820132 0.0947201 0.874964 0.294065 0.0442407 0.506709 0.450509 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=62279, meanQ=11.347241, numObservations: 9
action -1, numVisits=5, meanQ=-1.010000, numObservations: 5
action 0, numVisits=5, meanQ=-1.010000, numObservations: 5
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 839119 episodes
GETTING ACTION FROM:
action 1, numVisits=901398, meanQ=13.145677, numObservations: 9
action -1, numVisits=5, meanQ=-1.010000, numObservations: 5
action 0, numVisits=5, meanQ=-1.010000, numObservations: 5
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.155457 0.12408 0.642146 0.820132 0.0947201 0.874964 0.294065 0.0442407 0.506709 0.450509 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=69217, meanQ=13.983669, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 863799 episodes
GETTING ACTION FROM:
action 4, numVisits=933016, meanQ=12.462284, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.155457 0.12408 0.642146 0.820132 0.0947201 0.874964 0.294065 0.0442407 0.506709 0.450509 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=65791, meanQ=22.397479, numObservations: 9
action 5, numVisits=40, meanQ=11.809507, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 999713 episodes
GETTING ACTION FROM:
action 2, numVisits=1065504, meanQ=18.630753, numObservations: 9
action 5, numVisits=40, meanQ=11.809507, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.155457 0.12408 0.642146 0.820132 0.0947201 0.874964 0.294065 0.0442407 0.506709 0.450509 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 11.4068
Run # 6
Initial state: 0 0.989777 0.611645 0.546132 0.0720818 0.00171085 0.286569 0.497512 0.545246 0.483935 0.366304 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 690060 episodes
GETTING ACTION FROM:
action 5, numVisits=689988, meanQ=9.960298, numObservations: 9
action -1, numVisits=42, meanQ=-0.939757, numObservations: 38
action 0, numVisits=26, meanQ=-1.086535, numObservations: 25
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.989777 0.611645 0.546132 0.0720818 0.00171085 0.286569 0.497512 0.545246 0.483935 0.366304 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 7
Initial state: 0 0.435749 0.498889 0.0481771 0.390878 0.370671 0.775095 0.967767 0.437096 0.713923 0.404698 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 683277 episodes
GETTING ACTION FROM:
action 2, numVisits=683271, meanQ=9.883972, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.435749 0.498889 0.0481771 0.390878 0.370671 0.775095 0.967767 0.437096 0.713923 0.404698 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=78886, meanQ=11.242173, numObservations: 9
action 1, numVisits=22, meanQ=8.602273, numObservations: 7
action 3, numVisits=3, meanQ=3.330000, numObservations: 3
action 5, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 809466 episodes
GETTING ACTION FROM:
action 4, numVisits=888352, meanQ=10.605011, numObservations: 9
action 1, numVisits=22, meanQ=8.602273, numObservations: 7
action 3, numVisits=3, meanQ=3.330000, numObservations: 3
action 5, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 2 0.435749 0.498889 0.0481771 0.390878 0.370671 0.775095 0.967767 0.437096 0.713923 0.404698 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 8
Initial state: 0 0.884732 0.242306 0.429737 0.488005 0.415224 0.168691 0.736192 0.158352 0.728515 0.395403 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 687176 episodes
GETTING ACTION FROM:
action 2, numVisits=687130, meanQ=10.003952, numObservations: 9
action 1, numVisits=37, meanQ=5.958932, numObservations: 8
action 5, numVisits=5, meanQ=4.598000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.884732 0.242306 0.429737 0.488005 0.415224 0.168691 0.736192 0.158352 0.728515 0.395403 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 9
Initial state: 0 0.722267 0.172814 0.521186 0.451001 0.256132 0.0869193 0.699113 0.296771 0.925388 0.654291 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 686955 episodes
GETTING ACTION FROM:
action 4, numVisits=686941, meanQ=9.825479, numObservations: 9
action 3, numVisits=7, meanQ=5.141429, numObservations: 4
action 1, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.722267 0.172814 0.521186 0.451001 0.256132 0.0869193 0.699113 0.296771 0.925388 0.654291 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 10
Initial state: 0 0.47167 0.539907 0.64589 0.957085 0.708172 0.258201 0.604532 0.739961 0.947618 0.707762 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 681000 episodes
GETTING ACTION FROM:
action 3, numVisits=680979, meanQ=9.897333, numObservations: 9
action 2, numVisits=13, meanQ=4.467700, numObservations: 8
action 4, numVisits=4, meanQ=1.745000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.47167 0.539907 0.64589 0.957085 0.708172 0.258201 0.604532 0.739961 0.947618 0.707762 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 11
Initial state: 0 0.959531 0.471508 0.478476 0.5087 0.588192 0.691767 0.238892 0.148408 0.954404 0.886041 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 654344 episodes
GETTING ACTION FROM:
action 5, numVisits=654295, meanQ=10.047601, numObservations: 9
action 4, numVisits=38, meanQ=6.335274, numObservations: 9
action 1, numVisits=7, meanQ=4.585714, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.959531 0.471508 0.478476 0.5087 0.588192 0.691767 0.238892 0.148408 0.954404 0.886041 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 12
Initial state: 0 0.018688 0.0707483 0.391523 0.873937 0.349239 0.818588 0.958357 0.739504 0.461246 0.496456 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 683851 episodes
GETTING ACTION FROM:
action 3, numVisits=683654, meanQ=9.779227, numObservations: 9
action 1, numVisits=175, meanQ=9.184651, numObservations: 9
action 2, numVisits=18, meanQ=8.040000, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.018688 0.0707483 0.391523 0.873937 0.349239 0.818588 0.958357 0.739504 0.461246 0.496456 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=61581, meanQ=11.264770, numObservations: 9
action 4, numVisits=10, meanQ=8.098000, numObservations: 6
action 3, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 814424 episodes
GETTING ACTION FROM:
action 5, numVisits=876005, meanQ=13.156551, numObservations: 9
action 4, numVisits=10, meanQ=8.098000, numObservations: 6
action 3, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.018688 0.0707483 0.391523 0.873937 0.349239 0.818588 0.958357 0.739504 0.461246 0.496456 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=11894, meanQ=20.208063, numObservations: 9
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1027852 episodes
GETTING ACTION FROM:
action 5, numVisits=1039746, meanQ=22.691180, numObservations: 9
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.018688 0.0707483 0.391523 0.873937 0.349239 0.818588 0.958357 0.739504 0.461246 0.496456 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 13
Initial state: 0 0.0158607 0.255856 0.005884 0.376724 0.213058 0.743511 0.465915 0.468674 0.00889866 0.246412 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 682980 episodes
GETTING ACTION FROM:
action 5, numVisits=682960, meanQ=9.950829, numObservations: 9
action 1, numVisits=8, meanQ=4.625013, numObservations: 5
action 3, numVisits=6, meanQ=4.000017, numObservations: 5
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.0158607 0.255856 0.005884 0.376724 0.213058 0.743511 0.465915 0.468674 0.00889866 0.246412 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=78611, meanQ=11.265580, numObservations: 9
action 1, numVisits=4, meanQ=-0.252500, numObservations: 3
action 3, numVisits=4, meanQ=-0.252500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 827349 episodes
GETTING ACTION FROM:
action 2, numVisits=905960, meanQ=12.370960, numObservations: 9
action 1, numVisits=4, meanQ=-0.252500, numObservations: 3
action 3, numVisits=4, meanQ=-0.252500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.0158607 0.255856 0.005884 0.376724 0.213058 0.743511 0.465915 0.468674 0.00889866 0.246412 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=68284, meanQ=12.921839, numObservations: 9
action 4, numVisits=8, meanQ=6.120000, numObservations: 7
action 3, numVisits=5, meanQ=4.598000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 915555 episodes
GETTING ACTION FROM:
action 1, numVisits=983839, meanQ=11.512522, numObservations: 9
action 4, numVisits=8, meanQ=6.120000, numObservations: 7
action 3, numVisits=5, meanQ=4.598000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.0158607 0.255856 0.005884 0.376724 0.213058 0.743511 0.465915 0.468674 0.00889866 0.246412 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=61547, meanQ=13.325201, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 954679 episodes
GETTING ACTION FROM:
action 3, numVisits=1016226, meanQ=15.178563, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.0158607 0.255856 0.005884 0.376724 0.213058 0.743511 0.465915 0.468674 0.00889866 0.246412 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 4, numVisits=6854, meanQ=22.483636, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1042863 episodes
GETTING ACTION FROM:
action 4, numVisits=1049717, meanQ=21.403560, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 1 0.0158607 0.255856 0.005884 0.376724 0.213058 0.743511 0.465915 0.468674 0.00889866 0.246412 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.29271
Run # 14
Initial state: 0 0.307785 0.57181 0.303992 0.531771 0.615926 0.397911 0.462604 0.534458 0.115548 0.876648 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 685871 episodes
GETTING ACTION FROM:
action 3, numVisits=685852, meanQ=9.840571, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.307785 0.57181 0.303992 0.531771 0.615926 0.397911 0.462604 0.534458 0.115548 0.876648 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=16295, meanQ=10.780408, numObservations: 9
action 2, numVisits=7, meanQ=5.141429, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 983211 episodes
GETTING ACTION FROM:
action 4, numVisits=999503, meanQ=7.033171, numObservations: 9
action 2, numVisits=10, meanQ=3.799000, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.307785 0.57181 0.303992 0.531771 0.615926 0.397911 0.462604 0.534458 0.115548 0.876648 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 15
Initial state: 0 0.114971 0.496942 0.514583 0.440825 0.817393 0.363403 0.618898 0.815703 0.809534 0.383737 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 665741 episodes
GETTING ACTION FROM:
action 4, numVisits=665722, meanQ=9.940153, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
action 3, numVisits=2, meanQ=-4.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.114971 0.496942 0.514583 0.440825 0.817393 0.363403 0.618898 0.815703 0.809534 0.383737 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 16
Initial state: 0 0.507645 0.468365 0.365819 0.605552 0.24933 0.597367 0.716376 0.61049 0.842272 0.16748 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 674975 episodes
GETTING ACTION FROM:
action 4, numVisits=674954, meanQ=9.934555, numObservations: 9
action 2, numVisits=12, meanQ=4.915000, numObservations: 6
action 1, numVisits=5, meanQ=4.598000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.507645 0.468365 0.365819 0.605552 0.24933 0.597367 0.716376 0.61049 0.842272 0.16748 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 17
Initial state: 0 0.915369 0.690543 0.499529 0.568459 0.739264 0.411871 0.164917 0.293493 0.900352 0.040415 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 687149 episodes
GETTING ACTION FROM:
action 3, numVisits=687143, meanQ=9.978580, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.915369 0.690543 0.499529 0.568459 0.739264 0.411871 0.164917 0.293493 0.900352 0.040415 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 18
Initial state: 0 0.300761 0.582728 0.607168 0.0157495 0.0765435 0.605172 0.0172281 0.215996 0.515868 0.502737 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 688166 episodes
GETTING ACTION FROM:
action 1, numVisits=686770, meanQ=9.975330, numObservations: 9
action 3, numVisits=1357, meanQ=9.779073, numObservations: 9
action 5, numVisits=33, meanQ=7.910312, numObservations: 7
action 4, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.300761 0.582728 0.607168 0.0157495 0.0765435 0.605172 0.0172281 0.215996 0.515868 0.502737 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=62493, meanQ=11.173207, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 816301 episodes
GETTING ACTION FROM:
action 5, numVisits=878794, meanQ=11.729044, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.300761 0.582728 0.607168 0.0157495 0.0765435 0.605172 0.0172281 0.215996 0.515868 0.502737 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 19
Initial state: 0 0.422933 0.562556 0.070635 0.7471 0.0266748 0.641339 0.445483 0.00831945 0.708795 0.45822 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 677728 episodes
GETTING ACTION FROM:
action 5, numVisits=677711, meanQ=9.980678, numObservations: 9
action 1, numVisits=12, meanQ=7.831667, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.422933 0.562556 0.070635 0.7471 0.0266748 0.641339 0.445483 0.00831945 0.708795 0.45822 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 20
Initial state: 0 0.325509 0.982168 0.705609 0.420053 0.491698 0.540701 0.727054 0.17663 0.957509 0.372498 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 641605 episodes
GETTING ACTION FROM:
action 5, numVisits=641547, meanQ=10.066961, numObservations: 9
action 2, numVisits=41, meanQ=3.054400, numObservations: 9
action 4, numVisits=8, meanQ=2.151250, numObservations: 3
action 3, numVisits=6, meanQ=1.998333, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 2 0.325509 0.982168 0.705609 0.420053 0.491698 0.540701 0.727054 0.17663 0.957509 0.372498 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 21
Initial state: 0 0.26949 0.926094 0.255211 0.818521 0.552081 0.208805 0.258921 0.164422 0.421951 0.506235 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 689348 episodes
GETTING ACTION FROM:
action 1, numVisits=689318, meanQ=9.989541, numObservations: 9
action 2, numVisits=13, meanQ=7.313077, numObservations: 6
action 4, numVisits=13, meanQ=6.671538, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.26949 0.926094 0.255211 0.818521 0.552081 0.208805 0.258921 0.164422 0.421951 0.506235 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=62749, meanQ=11.276455, numObservations: 9
action 3, numVisits=6, meanQ=5.661683, numObservations: 5
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 836106 episodes
GETTING ACTION FROM:
action 5, numVisits=898855, meanQ=13.465152, numObservations: 9
action 3, numVisits=6, meanQ=5.661683, numObservations: 5
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.26949 0.926094 0.255211 0.818521 0.552081 0.208805 0.258921 0.164422 0.421951 0.506235 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 22
Initial state: 0 0.651259 0.755765 0.182389 0.220265 0.44868 0.453978 0.837709 0.0193477 0.0313327 0.0163781 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 667248 episodes
GETTING ACTION FROM:
action 5, numVisits=667227, meanQ=10.002507, numObservations: 9
action 2, numVisits=11, meanQ=4.451827, numObservations: 7
action 4, numVisits=6, meanQ=2.668350, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.651259 0.755765 0.182389 0.220265 0.44868 0.453978 0.837709 0.0193477 0.0313327 0.0163781 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=77619, meanQ=11.178279, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 821716 episodes
GETTING ACTION FROM:
action 4, numVisits=899335, meanQ=10.401200, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.651259 0.755765 0.182389 0.220265 0.44868 0.453978 0.837709 0.0193477 0.0313327 0.0163781 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 23
Initial state: 0 0.53199 0.49089 0.170918 0.266215 0.719688 0.479074 0.708069 0.885265 0.842013 0.352272 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 688648 episodes
GETTING ACTION FROM:
action 5, numVisits=688631, meanQ=9.985391, numObservations: 9
action 1, numVisits=8, meanQ=7.012500, numObservations: 5
action 2, numVisits=5, meanQ=6.196000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.53199 0.49089 0.170918 0.266215 0.719688 0.479074 0.708069 0.885265 0.842013 0.352272 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 24
Initial state: 0 0.27327 0.99041 0.448336 0.434746 0.0664501 0.873432 0.990376 0.636057 0.793092 0.40576 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 670296 episodes
GETTING ACTION FROM:
action 1, numVisits=670264, meanQ=9.912723, numObservations: 9
action 3, numVisits=24, meanQ=4.186675, numObservations: 9
action 4, numVisits=4, meanQ=1.745000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.27327 0.99041 0.448336 0.434746 0.0664501 0.873432 0.990376 0.636057 0.793092 0.40576 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=60890, meanQ=11.185436, numObservations: 9
action 1, numVisits=4, meanQ=3.742500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 827770 episodes
GETTING ACTION FROM:
action 3, numVisits=888660, meanQ=12.417034, numObservations: 9
action 1, numVisits=4, meanQ=3.742500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.27327 0.99041 0.448336 0.434746 0.0664501 0.873432 0.990376 0.636057 0.793092 0.40576 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=54415, meanQ=13.734651, numObservations: 9
action 4, numVisits=24, meanQ=11.375421, numObservations: 9
action 1, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 784002 episodes
GETTING ACTION FROM:
action 3, numVisits=838417, meanQ=18.468219, numObservations: 9
action 4, numVisits=24, meanQ=11.375421, numObservations: 9
action 1, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.27327 0.99041 0.448336 0.434746 0.0664501 0.873432 0.990376 0.636057 0.793092 0.40576 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=14893, meanQ=11.900732, numObservations: 9
action 5, numVisits=2, meanQ=6.500000, numObservations: 1
action 4, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 873426 episodes
GETTING ACTION FROM:
action 1, numVisits=888319, meanQ=19.237718, numObservations: 9
action 5, numVisits=2, meanQ=6.500000, numObservations: 1
action 4, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.27327 0.99041 0.448336 0.434746 0.0664501 0.873432 0.990376 0.636057 0.793092 0.40576 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 11.4068
Run # 25
Initial state: 0 0.123739 0.121082 0.447995 0.54956 0.121654 0.747259 0.295415 0.213082 0.826641 0.674822 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 691098 episodes
GETTING ACTION FROM:
action 1, numVisits=570402, meanQ=9.953507, numObservations: 9
action 3, numVisits=120640, meanQ=9.883150, numObservations: 9
action 2, numVisits=39, meanQ=8.284874, numObservations: 9
action 4, numVisits=14, meanQ=7.641429, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.123739 0.121082 0.447995 0.54956 0.121654 0.747259 0.295415 0.213082 0.826641 0.674822 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=65661, meanQ=11.086683, numObservations: 9
action 4, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 807707 episodes
GETTING ACTION FROM:
action 2, numVisits=873368, meanQ=10.339499, numObservations: 9
action 4, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.123739 0.121082 0.447995 0.54956 0.121654 0.747259 0.295415 0.213082 0.826641 0.674822 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 26
Initial state: 0 0.180824 0.636738 0.234282 0.940203 0.509496 0.517923 0.364412 0.19545 0.861603 0.872682 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 683605 episodes
GETTING ACTION FROM:
action 4, numVisits=683572, meanQ=9.997960, numObservations: 9
action -1, numVisits=23, meanQ=-0.106517, numObservations: 21
action 0, numVisits=5, meanQ=-1.010000, numObservations: 5
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.180824 0.636738 0.234282 0.940203 0.509496 0.517923 0.364412 0.19545 0.861603 0.872682 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=12777, meanQ=10.476076, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 848609 episodes
GETTING ACTION FROM:
action 2, numVisits=861386, meanQ=6.844383, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.180824 0.636738 0.234282 0.940203 0.509496 0.517923 0.364412 0.19545 0.861603 0.872682 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 0, numVisits=23850, meanQ=16.360404, numObservations: 242
action -1, numVisits=16, meanQ=-1.258119, numObservations: 15
action 4, numVisits=9, meanQ=-1.446667, numObservations: 5
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
action 5, numVisits=2, meanQ=-3.010000, numObservations: 2
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 251120 episodes
GETTING ACTION FROM:
action 0, numVisits=274970, meanQ=4.788390, numObservations: 243
action -1, numVisits=16, meanQ=-1.258119, numObservations: 15
action 4, numVisits=9, meanQ=-1.446667, numObservations: 5
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
action 5, numVisits=2, meanQ=-3.010000, numObservations: 2
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.180824 0.636738 0.234282 0.940203 0.509496 0.517923 0.364412 0.19545 0.861603 0.872682 w: 1
Observation: 0 0 3 0 3 0 2 0 1 0 3 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=587, meanQ=21.294192, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1015954 episodes
GETTING ACTION FROM:
action 3, numVisits=1016541, meanQ=19.987106, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.180824 0.636738 0.234282 0.940203 0.509496 0.517923 0.364412 0.19545 0.861603 0.872682 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 13.367
Run # 27
Initial state: 0 0.552847 0.341472 0.893725 0.368623 0.423482 0.530756 0.00896711 0.518497 0.730009 0.320832 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 685838 episodes
GETTING ACTION FROM:
action 2, numVisits=685794, meanQ=9.941792, numObservations: 9
action 1, numVisits=21, meanQ=7.760010, numObservations: 8
action 5, numVisits=9, meanQ=7.218889, numObservations: 5
action 4, numVisits=11, meanQ=6.734545, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.552847 0.341472 0.893725 0.368623 0.423482 0.530756 0.00896711 0.518497 0.730009 0.320832 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 28
Initial state: 0 0.0712014 0.113453 0.504977 0.549404 0.151428 0.898077 0.0138661 0.0516337 0.608893 0.562779 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 687537 episodes
GETTING ACTION FROM:
action 3, numVisits=687529, meanQ=9.992519, numObservations: 9
action 1, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.0712014 0.113453 0.504977 0.549404 0.151428 0.898077 0.0138661 0.0516337 0.608893 0.562779 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=62831, meanQ=11.090103, numObservations: 9
action 1, numVisits=5, meanQ=6.196000, numObservations: 4
action 5, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 828089 episodes
GETTING ACTION FROM:
action 4, numVisits=890920, meanQ=12.264709, numObservations: 9
action 1, numVisits=5, meanQ=6.196000, numObservations: 4
action 5, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.0712014 0.113453 0.504977 0.549404 0.151428 0.898077 0.0138661 0.0516337 0.608893 0.562779 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=13888, meanQ=14.050187, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 978318 episodes
GETTING ACTION FROM:
action 2, numVisits=992206, meanQ=14.034460, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.0712014 0.113453 0.504977 0.549404 0.151428 0.898077 0.0138661 0.0516337 0.608893 0.562779 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 29
Initial state: 0 0.0704179 0.709979 0.862211 0.947299 0.675905 0.000400906 0.587924 0.269076 0.420699 0.544003 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 684455 episodes
GETTING ACTION FROM:
action 1, numVisits=684447, meanQ=9.806773, numObservations: 9
action 3, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.0704179 0.709979 0.862211 0.947299 0.675905 0.000400906 0.587924 0.269076 0.420699 0.544003 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=61631, meanQ=11.197196, numObservations: 9
action 1, numVisits=3, meanQ=5.993333, numObservations: 3
action 5, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 833328 episodes
GETTING ACTION FROM:
action 4, numVisits=894959, meanQ=12.367924, numObservations: 9
action 1, numVisits=3, meanQ=5.993333, numObservations: 3
action 5, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.0704179 0.709979 0.862211 0.947299 0.675905 0.000400906 0.587924 0.269076 0.420699 0.544003 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 30
Initial state: 0 0.500813 0.43792 0.978951 0.529037 0.954439 0.237938 0.163452 0.692792 0.663288 0.599576 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 680839 episodes
GETTING ACTION FROM:
action 2, numVisits=680833, meanQ=9.965031, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.500813 0.43792 0.978951 0.529037 0.954439 0.237938 0.163452 0.692792 0.663288 0.599576 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 31
Initial state: 0 0.529802 0.523282 0.751488 0.606069 0.933398 0.243822 0.922827 0.0206201 0.974912 0.66636 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 680005 episodes
GETTING ACTION FROM:
action 4, numVisits=679999, meanQ=9.980970, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.529802 0.523282 0.751488 0.606069 0.933398 0.243822 0.922827 0.0206201 0.974912 0.66636 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 32
Initial state: 0 0.428819 0.561764 0.990353 0.0876127 0.945534 0.454602 0.951654 0.294818 0.163781 0.374558 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 687981 episodes
GETTING ACTION FROM:
action 3, numVisits=687972, meanQ=10.021816, numObservations: 9
action 5, numVisits=4, meanQ=1.745000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.428819 0.561764 0.990353 0.0876127 0.945534 0.454602 0.951654 0.294818 0.163781 0.374558 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 33
Initial state: 0 0.525652 0.477731 0.0755223 0.886645 0.581156 0.290711 0.0269447 0.120919 0.452054 0.998205 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 679293 episodes
GETTING ACTION FROM:
action 3, numVisits=679285, meanQ=9.775060, numObservations: 9
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.525652 0.477731 0.0755223 0.886645 0.581156 0.290711 0.0269447 0.120919 0.452054 0.998205 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=15783, meanQ=10.878747, numObservations: 9
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 5, numVisits=6, meanQ=-1.171667, numObservations: 6
action 1, numVisits=5, meanQ=-1.597980, numObservations: 4
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 994682 episodes
GETTING ACTION FROM:
action 4, numVisits=1010465, meanQ=7.821438, numObservations: 9
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 5, numVisits=6, meanQ=-1.171667, numObservations: 6
action 1, numVisits=5, meanQ=-1.597980, numObservations: 4
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.525652 0.477731 0.0755223 0.886645 0.581156 0.290711 0.0269447 0.120919 0.452054 0.998205 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=3039, meanQ=14.043909, numObservations: 9
action 2, numVisits=6, meanQ=4.330017, numObservations: 4
action 1, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1016337 episodes
GETTING ACTION FROM:
action 5, numVisits=1019376, meanQ=13.292560, numObservations: 9
action 2, numVisits=6, meanQ=4.330017, numObservations: 4
action 1, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.525652 0.477731 0.0755223 0.886645 0.581156 0.290711 0.0269447 0.120919 0.452054 0.998205 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -18.7411
Run # 34
Initial state: 0 0.810164 0.16403 0.78981 0.0778086 0.121738 0.145516 0.704776 0.174388 0.485385 0.503388 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 685832 episodes
GETTING ACTION FROM:
action 5, numVisits=685754, meanQ=9.957357, numObservations: 9
action 2, numVisits=65, meanQ=8.362783, numObservations: 9
action 3, numVisits=5, meanQ=6.196000, numObservations: 5
action 4, numVisits=5, meanQ=4.598000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 0 0.810164 0.16403 0.78981 0.0778086 0.121738 0.145516 0.704776 0.174388 0.485385 0.503388 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=11203, meanQ=19.980318, numObservations: 9
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1012291 episodes
GETTING ACTION FROM:
action 5, numVisits=1023494, meanQ=22.582758, numObservations: 9
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.810164 0.16403 0.78981 0.0778086 0.121738 0.145516 0.704776 0.174388 0.485385 0.503388 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 35
Initial state: 0 0.440248 0.95026 0.635767 0.738988 0.660789 0.22676 0.464553 0.562067 0.0290358 0.412282 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 683711 episodes
GETTING ACTION FROM:
action 1, numVisits=683697, meanQ=10.030457, numObservations: 9
action 3, numVisits=7, meanQ=4.707143, numObservations: 6
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.440248 0.95026 0.635767 0.738988 0.660789 0.22676 0.464553 0.562067 0.0290358 0.412282 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 36
Initial state: 0 0.469977 0.470881 0.588509 0.0335853 0.307869 0.325539 0.0697618 0.0480066 0.0761125 0.257899 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 680812 episodes
GETTING ACTION FROM:
action 2, numVisits=680797, meanQ=9.964920, numObservations: 9
action 3, numVisits=6, meanQ=4.661667, numObservations: 6
action 1, numVisits=5, meanQ=4.598000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.469977 0.470881 0.588509 0.0335853 0.307869 0.325539 0.0697618 0.0480066 0.0761125 0.257899 w: 1
Observation: 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 37
Initial state: 0 0.910144 0.300053 0.377845 0.44645 0.583508 0.742786 0.0418492 0.383765 0.388794 0.945135 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 688902 episodes
GETTING ACTION FROM:
action 3, numVisits=688886, meanQ=9.952459, numObservations: 9
action 4, numVisits=7, meanQ=5.141429, numObservations: 4
action 2, numVisits=5, meanQ=4.598000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.910144 0.300053 0.377845 0.44645 0.583508 0.742786 0.0418492 0.383765 0.388794 0.945135 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 38
Initial state: 0 0.879593 0.433492 0.366983 0.799874 0.462207 0.440355 0.757514 0.99226 0.240958 0.835937 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 637802 episodes
GETTING ACTION FROM:
action 5, numVisits=637778, meanQ=10.014956, numObservations: 9
action 3, numVisits=15, meanQ=4.588667, numObservations: 8
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action 4, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 0 0.879593 0.433492 0.366983 0.799874 0.462207 0.440355 0.757514 0.99226 0.240958 0.835937 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=74106, meanQ=11.087657, numObservations: 9
action -1, numVisits=17, meanQ=-1.244106, numObservations: 15
action 0, numVisits=16, meanQ=-1.258119, numObservations: 15
action 1, numVisits=4, meanQ=-2.250000, numObservations: 2
action 2, numVisits=6, meanQ=-3.164983, numObservations: 4
action 5, numVisits=2, meanQ=-4.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 794134 episodes
GETTING ACTION FROM:
action 4, numVisits=868240, meanQ=11.280826, numObservations: 9
action -1, numVisits=17, meanQ=-1.244106, numObservations: 15
action 0, numVisits=16, meanQ=-1.258119, numObservations: 15
action 1, numVisits=4, meanQ=-2.250000, numObservations: 2
action 2, numVisits=6, meanQ=-3.164983, numObservations: 4
action 5, numVisits=2, meanQ=-4.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.879593 0.433492 0.366983 0.799874 0.462207 0.440355 0.757514 0.99226 0.240958 0.835937 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 39
Initial state: 0 0.662342 0.437547 0.872449 0.925308 0.488656 0.542994 0.0847234 0.752792 0.714232 0.0472791 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 689470 episodes
GETTING ACTION FROM:
action 1, numVisits=689459, meanQ=9.935677, numObservations: 9
action 4, numVisits=4, meanQ=1.745000, numObservations: 4
action 5, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.662342 0.437547 0.872449 0.925308 0.488656 0.542994 0.0847234 0.752792 0.714232 0.0472791 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 40
Initial state: 0 0.476314 0.444706 0.993551 0.622563 0.409279 0.651957 0.71542 0.438976 0.470395 0.726833 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 683648 episodes
GETTING ACTION FROM:
action 4, numVisits=683640, meanQ=9.946365, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.476314 0.444706 0.993551 0.622563 0.409279 0.651957 0.71542 0.438976 0.470395 0.726833 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 41
Initial state: 0 0.421786 0.531981 0.907101 0.362052 0.686428 0.0550317 0.551355 0.483977 0.267293 0.207993 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 688343 episodes
GETTING ACTION FROM:
action 4, numVisits=684482, meanQ=9.790885, numObservations: 9
action 3, numVisits=3836, meanQ=9.217188, numObservations: 9
action 1, numVisits=21, meanQ=7.474290, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.421786 0.531981 0.907101 0.362052 0.686428 0.0550317 0.551355 0.483977 0.267293 0.207993 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 42
Initial state: 0 0.656913 0.62133 0.585362 0.517317 0.887559 0.574223 0.0791327 0.0117889 0.377184 0.508658 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 655076 episodes
GETTING ACTION FROM:
action 4, numVisits=655061, meanQ=9.971090, numObservations: 9
action 2, numVisits=10, meanQ=0.709000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.656913 0.62133 0.585362 0.517317 0.887559 0.574223 0.0791327 0.0117889 0.377184 0.508658 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=75611, meanQ=10.991867, numObservations: 9
action 2, numVisits=3, meanQ=5.330033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 752458 episodes
GETTING ACTION FROM:
action 5, numVisits=828069, meanQ=10.579122, numObservations: 9
action 2, numVisits=3, meanQ=5.330033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 0 0.656913 0.62133 0.585362 0.517317 0.887559 0.574223 0.0791327 0.0117889 0.377184 0.508658 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=6250, meanQ=12.646212, numObservations: 9
action 3, numVisits=8, meanQ=9.000013, numObservations: 5
action 5, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 979653 episodes
GETTING ACTION FROM:
action 2, numVisits=985903, meanQ=13.960808, numObservations: 9
action 3, numVisits=8, meanQ=9.000013, numObservations: 5
action 5, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.656913 0.62133 0.585362 0.517317 0.887559 0.574223 0.0791327 0.0117889 0.377184 0.508658 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -18.7411
Run # 43
Initial state: 0 0.442488 0.525371 0.0266256 0.185149 0.2531 0.27446 0.967667 0.6125 0.922296 0.345374 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 680819 episodes
GETTING ACTION FROM:
action 1, numVisits=680802, meanQ=9.946966, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.442488 0.525371 0.0266256 0.185149 0.2531 0.27446 0.967667 0.6125 0.922296 0.345374 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 44
Initial state: 0 0.886778 0.118165 0.512202 0.797243 0.52025 0.44184 0.987081 0.951611 0.841553 0.96048 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 682971 episodes
GETTING ACTION FROM:
action 2, numVisits=682954, meanQ=10.051232, numObservations: 9
action 5, numVisits=7, meanQ=5.141429, numObservations: 4
action 4, numVisits=6, meanQ=4.330017, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.886778 0.118165 0.512202 0.797243 0.52025 0.44184 0.987081 0.951611 0.841553 0.96048 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 45
Initial state: 0 0.702226 0.205368 0.803502 0.0421417 0.442792 0.496301 0.112024 0.123494 0.831681 0.27162 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 689151 episodes
GETTING ACTION FROM:
action 2, numVisits=689143, meanQ=10.021808, numObservations: 9
action 1, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.702226 0.205368 0.803502 0.0421417 0.442792 0.496301 0.112024 0.123494 0.831681 0.27162 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 46
Initial state: 0 0.348568 0.801734 0.212228 0.584939 0.249592 0.310575 0.840556 0.960449 0.538157 0.505192 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 685438 episodes
GETTING ACTION FROM:
action 4, numVisits=685418, meanQ=9.753939, numObservations: 9
action 5, numVisits=8, meanQ=4.872513, numObservations: 4
action 3, numVisits=8, meanQ=4.625013, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.348568 0.801734 0.212228 0.584939 0.249592 0.310575 0.840556 0.960449 0.538157 0.505192 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 47
Initial state: 0 0.535141 0.463999 0.875271 0.0797903 0.664283 0.97636 0.983545 0.516724 0.347363 0.936637 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 679185 episodes
GETTING ACTION FROM:
action 5, numVisits=679173, meanQ=9.826775, numObservations: 9
action 2, numVisits=5, meanQ=-0.804000, numObservations: 5
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 1 0.535141 0.463999 0.875271 0.0797903 0.664283 0.97636 0.983545 0.516724 0.347363 0.936637 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 48
Initial state: 0 0.524133 0.461153 0.646439 0.636708 0.0055544 0.604088 0.641807 0.622897 0.850112 0.276101 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 659964 episodes
GETTING ACTION FROM:
action 3, numVisits=659945, meanQ=10.074122, numObservations: 9
action 4, numVisits=12, meanQ=7.831667, numObservations: 7
action 1, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.524133 0.461153 0.646439 0.636708 0.0055544 0.604088 0.641807 0.622897 0.850112 0.276101 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=4665, meanQ=11.012554, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1023859 episodes
GETTING ACTION FROM:
action 2, numVisits=1028524, meanQ=13.793232, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.524133 0.461153 0.646439 0.636708 0.0055544 0.604088 0.641807 0.622897 0.850112 0.276101 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 49
Initial state: 0 0.472824 0.552059 0.933225 0.075357 0.288031 0.566966 0.643915 0.91299 0.617629 0.0106603 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 670313 episodes
GETTING ACTION FROM:
action 4, numVisits=670268, meanQ=9.984200, numObservations: 9
action 3, numVisits=34, meanQ=7.433532, numObservations: 8
action 1, numVisits=7, meanQ=4.585714, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.472824 0.552059 0.933225 0.075357 0.288031 0.566966 0.643915 0.91299 0.617629 0.0106603 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 50
Initial state: 0 0.309019 0.612618 0.681268 0.252007 0.946995 0.327186 0.30375 0.620278 0.52405 0.503892 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 636809 episodes
GETTING ACTION FROM:
action 5, numVisits=636800, meanQ=9.336710, numObservations: 9
action 4, numVisits=4, meanQ=1.745000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.309019 0.612618 0.681268 0.252007 0.946995 0.327186 0.30375 0.620278 0.52405 0.503892 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
[32m ProblemEnvironment.hpp 351: Done.[39m
