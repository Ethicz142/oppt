Run # 1
Initial state: 0 0.520987 0.556862 0.304013 0.0836293 0.278011 0.0631992 0.431589 0.487897 0.41301 0.257485 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 663338 episodes
GETTING ACTION FROM:
action 5, numVisits=663331, meanQ=14.067197, numObservations: 9
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.520987 0.556862 0.304013 0.0836293 0.278011 0.0631992 0.431589 0.487897 0.41301 0.257485 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 2
Initial state: 0 0.348459 0.07439 0.601543 0.0851719 0.456697 0.315478 0.821391 0.0521595 0.669466 0.232225 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 670805 episodes
GETTING ACTION FROM:
action 2, numVisits=670775, meanQ=14.091650, numObservations: 9
action 1, numVisits=12, meanQ=11.414167, numObservations: 6
action 5, numVisits=9, meanQ=9.998900, numObservations: 5
action 3, numVisits=6, meanQ=8.501683, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.348459 0.07439 0.601543 0.0851719 0.456697 0.315478 0.821391 0.0521595 0.669466 0.232225 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 3
Initial state: 0 0.385445 0.554879 0.974526 0.0641842 0.884215 0.654184 0.819302 0.424229 0.57235 0.285327 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 705736 episodes
GETTING ACTION FROM:
action 4, numVisits=705722, meanQ=13.978457, numObservations: 9
action 2, numVisits=5, meanQ=6.196000, numObservations: 4
action 5, numVisits=5, meanQ=6.196000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 2 0.385445 0.554879 0.974526 0.0641842 0.884215 0.654184 0.819302 0.424229 0.57235 0.285327 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 4
Initial state: 0 0.430774 0.282767 0.304017 0.440034 0.105206 0.541376 0.215064 0.63716 0.512169 0.251279 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 706578 episodes
GETTING ACTION FROM:
action 1, numVisits=706559, meanQ=14.173932, numObservations: 9
action 4, numVisits=12, meanQ=11.248342, numObservations: 7
action 3, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.430774 0.282767 0.304017 0.440034 0.105206 0.541376 0.215064 0.63716 0.512169 0.251279 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 5
Initial state: 0 0.571777 0.350464 0.978083 0.542226 0.380723 0.235569 0.0075529 0.0147069 0.70513 0.131588 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 706416 episodes
GETTING ACTION FROM:
action 5, numVisits=706409, meanQ=14.148837, numObservations: 9
action 4, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 2 0.571777 0.350464 0.978083 0.542226 0.380723 0.235569 0.0075529 0.0147069 0.70513 0.131588 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 6
Initial state: 0 0.0402821 0.0919135 0.487971 0.295194 0.295345 0.879903 0.556212 0.990781 0.271189 0.525255 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 703416 episodes
GETTING ACTION FROM:
action 3, numVisits=703404, meanQ=14.188821, numObservations: 9
action 4, numVisits=5, meanQ=6.196000, numObservations: 5
action 2, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.0402821 0.0919135 0.487971 0.295194 0.295345 0.879903 0.556212 0.990781 0.271189 0.525255 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=7136, meanQ=15.056092, numObservations: 9
action 1, numVisits=7, meanQ=6.857157, numObservations: 5
action 2, numVisits=8, meanQ=6.500000, numObservations: 4
action 4, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1022804 episodes
GETTING ACTION FROM:
action 5, numVisits=1029940, meanQ=17.393059, numObservations: 9
action 1, numVisits=7, meanQ=6.857157, numObservations: 5
action 2, numVisits=8, meanQ=6.500000, numObservations: 4
action 4, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.0402821 0.0919135 0.487971 0.295194 0.295345 0.879903 0.556212 0.990781 0.271189 0.525255 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=6135, meanQ=16.472990, numObservations: 9
action 4, numVisits=9, meanQ=10.220000, numObservations: 6
action 1, numVisits=4, meanQ=8.497500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1033647 episodes
GETTING ACTION FROM:
action 2, numVisits=1039782, meanQ=17.804953, numObservations: 9
action 4, numVisits=9, meanQ=10.220000, numObservations: 6
action 1, numVisits=4, meanQ=8.497500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.0402821 0.0919135 0.487971 0.295194 0.295345 0.879903 0.556212 0.990781 0.271189 0.525255 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 4, numVisits=114, meanQ=6.263357, numObservations: 9
action 5, numVisits=4, meanQ=1.757550, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1045421 episodes
GETTING ACTION FROM:
action 4, numVisits=1045535, meanQ=20.002935, numObservations: 9
action 5, numVisits=4, meanQ=1.757550, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.0402821 0.0919135 0.487971 0.295194 0.295345 0.879903 0.556212 0.990781 0.271189 0.525255 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -22.5537
Run # 7
Initial state: 0 0.567861 0.34337 0.80574 0.289241 0.45383 0.902017 0.249094 0.986192 0.999048 0.137614 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 697620 episodes
GETTING ACTION FROM:
action 5, numVisits=697569, meanQ=14.105618, numObservations: 9
action 4, numVisits=44, meanQ=8.233191, numObservations: 9
action 3, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 2 0.567861 0.34337 0.80574 0.289241 0.45383 0.902017 0.249094 0.986192 0.999048 0.137614 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 8
Initial state: 0 0.205702 0.679672 0.285348 0.750595 0.196616 0.545827 0.546757 0.308893 0.309999 0.190822 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 693916 episodes
GETTING ACTION FROM:
action 2, numVisits=693887, meanQ=14.029102, numObservations: 9
action 5, numVisits=17, meanQ=10.764129, numObservations: 6
action 4, numVisits=8, meanQ=9.496250, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.205702 0.679672 0.285348 0.750595 0.196616 0.545827 0.546757 0.308893 0.309999 0.190822 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=96442, meanQ=14.769213, numObservations: 9
action 3, numVisits=15, meanQ=11.338667, numObservations: 7
action 4, numVisits=6, meanQ=10.495000, numObservations: 5
action 1, numVisits=4, meanQ=8.497500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 784414 episodes
GETTING ACTION FROM:
action 5, numVisits=880856, meanQ=16.391437, numObservations: 9
action 3, numVisits=15, meanQ=11.338667, numObservations: 7
action 4, numVisits=6, meanQ=10.495000, numObservations: 5
action 1, numVisits=4, meanQ=8.497500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 0 0.205702 0.679672 0.285348 0.750595 0.196616 0.545827 0.546757 0.308893 0.309999 0.190822 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=42413, meanQ=15.680356, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 890411 episodes
GETTING ACTION FROM:
action 3, numVisits=932824, meanQ=14.990020, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.205702 0.679672 0.285348 0.750595 0.196616 0.545827 0.546757 0.308893 0.309999 0.190822 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 9
Initial state: 0 0.561375 0.296799 0.0303465 0.673151 0.250813 0.00122434 0.754408 0.651689 0.923086 0.612758 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 678297 episodes
GETTING ACTION FROM:
action 5, numVisits=678289, meanQ=14.144059, numObservations: 9
action 3, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.561375 0.296799 0.0303465 0.673151 0.250813 0.00122434 0.754408 0.651689 0.923086 0.612758 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 10
Initial state: 0 0.902179 0.586442 0.957373 0.106385 0.117131 0.477249 0.503506 0.356475 0.71112 0.0731611 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 706236 episodes
GETTING ACTION FROM:
action 1, numVisits=706228, meanQ=14.150813, numObservations: 9
action 2, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.902179 0.586442 0.957373 0.106385 0.117131 0.477249 0.503506 0.356475 0.71112 0.0731611 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 11
Initial state: 0 0.461846 0.270539 0.603869 0.383354 0.313 0.866548 0.0571219 0.744721 0.113495 0.777853 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 697321 episodes
GETTING ACTION FROM:
action 2, numVisits=697313, meanQ=14.033821, numObservations: 9
action 3, numVisits=3, meanQ=5.330033, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.461846 0.270539 0.603869 0.383354 0.313 0.866548 0.0571219 0.744721 0.113495 0.777853 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 12
Initial state: 0 0.969714 0.047627 0.710594 0.220511 0.449017 0.30475 0.895411 0.987988 0.742761 0.664504 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 704135 episodes
GETTING ACTION FROM:
action 4, numVisits=704109, meanQ=14.042598, numObservations: 9
action 2, numVisits=17, meanQ=11.468235, numObservations: 8
action 3, numVisits=5, meanQ=10.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 1 0.969714 0.047627 0.710594 0.220511 0.449017 0.30475 0.895411 0.987988 0.742761 0.664504 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 13
Initial state: 0 0.78705 0.970787 0.0821199 0.41634 0.552054 0.335687 0.357327 0.124025 0.877179 0.0636327 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 700495 episodes
GETTING ACTION FROM:
action 3, numVisits=700485, meanQ=14.058070, numObservations: 9
action 1, numVisits=3, meanQ=5.993333, numObservations: 3
action 5, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.78705 0.970787 0.0821199 0.41634 0.552054 0.335687 0.357327 0.124025 0.877179 0.0636327 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 14
Initial state: 0 0.440792 0.672966 0.825686 0.907397 0.961267 0.587259 0.177503 0.965328 0.496058 0.297662 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 705055 episodes
GETTING ACTION FROM:
action 3, numVisits=705047, meanQ=14.161538, numObservations: 9
action 1, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.440792 0.672966 0.825686 0.907397 0.961267 0.587259 0.177503 0.965328 0.496058 0.297662 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 15
Initial state: 0 0.802425 0.734029 0.555504 0.261485 0.812016 0.619618 0.70779 0.705578 0.601504 0.976592 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 702066 episodes
GETTING ACTION FROM:
action 2, numVisits=702059, meanQ=14.165832, numObservations: 9
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.802425 0.734029 0.555504 0.261485 0.812016 0.619618 0.70779 0.705578 0.601504 0.976592 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=10906, meanQ=20.027210, numObservations: 9
action 4, numVisits=7, meanQ=10.677143, numObservations: 5
action 1, numVisits=9, meanQ=10.220000, numObservations: 5
action 5, numVisits=9, meanQ=10.220000, numObservations: 5
action 3, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1003975 episodes
GETTING ACTION FROM:
action 2, numVisits=1014881, meanQ=22.536069, numObservations: 9
action 4, numVisits=7, meanQ=10.677143, numObservations: 5
action 1, numVisits=9, meanQ=10.220000, numObservations: 5
action 5, numVisits=9, meanQ=10.220000, numObservations: 5
action 3, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.802425 0.734029 0.555504 0.261485 0.812016 0.619618 0.70779 0.705578 0.601504 0.976592 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 16
Initial state: 0 0.458226 0.348458 0.240991 0.930198 0.59933 0.91889 0.739242 0.68563 0.627503 0.634726 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 699245 episodes
GETTING ACTION FROM:
action 3, numVisits=699236, meanQ=14.067413, numObservations: 9
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action 1, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.458226 0.348458 0.240991 0.930198 0.59933 0.91889 0.739242 0.68563 0.627503 0.634726 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 17
Initial state: 0 0.0555598 0.335854 0.899458 0.299806 0.431348 0.924614 0.136991 0.416396 0.40239 0.27172 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 701677 episodes
GETTING ACTION FROM:
action 4, numVisits=701656, meanQ=13.992934, numObservations: 9
action 1, numVisits=14, meanQ=11.427871, numObservations: 5
action 5, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.0555598 0.335854 0.899458 0.299806 0.431348 0.924614 0.136991 0.416396 0.40239 0.27172 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=9828, meanQ=14.046710, numObservations: 9
action 4, numVisits=4, meanQ=10.495000, numObservations: 2
action 3, numVisits=4, meanQ=8.497500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 982759 episodes
GETTING ACTION FROM:
action 2, numVisits=992587, meanQ=15.880616, numObservations: 9
action 4, numVisits=4, meanQ=10.495000, numObservations: 2
action 3, numVisits=4, meanQ=8.497500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.0555598 0.335854 0.899458 0.299806 0.431348 0.924614 0.136991 0.416396 0.40239 0.27172 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 18
Initial state: 0 0.836286 0.615827 0.566405 0.266928 0.0397426 0.110306 0.0939906 0.915665 0.150385 0.388819 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 675677 episodes
GETTING ACTION FROM:
action 1, numVisits=675669, meanQ=14.078352, numObservations: 9
action 4, numVisits=3, meanQ=0.666667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.836286 0.615827 0.566405 0.266928 0.0397426 0.110306 0.0939906 0.915665 0.150385 0.388819 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 19
Initial state: 0 0.12884 0.838287 0.328383 0.573708 0.589628 0.969784 0.997654 0.755186 0.497439 0.272548 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 705405 episodes
GETTING ACTION FROM:
action 4, numVisits=705388, meanQ=14.016515, numObservations: 9
action 5, numVisits=12, meanQ=7.831667, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 1 0.12884 0.838287 0.328383 0.573708 0.589628 0.969784 0.997654 0.755186 0.497439 0.272548 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 20
Initial state: 0 0.0574183 0.523209 0.101537 0.303267 0.890634 0.267604 0.392004 0.284825 0.530153 0.243894 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 706368 episodes
GETTING ACTION FROM:
action 5, numVisits=706359, meanQ=14.181229, numObservations: 9
action 2, numVisits=4, meanQ=1.745000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.0574183 0.523209 0.101537 0.303267 0.890634 0.267604 0.392004 0.284825 0.530153 0.243894 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=8907, meanQ=14.131344, numObservations: 9
action 2, numVisits=5, meanQ=3.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 966611 episodes
GETTING ACTION FROM:
action 4, numVisits=975518, meanQ=13.168306, numObservations: 9
action 2, numVisits=5, meanQ=3.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 1 0.0574183 0.523209 0.101537 0.303267 0.890634 0.267604 0.392004 0.284825 0.530153 0.243894 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 21
Initial state: 0 0.592666 0.282715 0.850875 0.889116 0.511262 0.759998 0.236396 0.798342 0.446811 0.313233 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 708619 episodes
GETTING ACTION FROM:
action 1, numVisits=708601, meanQ=14.147595, numObservations: 9
action 5, numVisits=7, meanQ=10.715729, numObservations: 4
action 2, numVisits=5, meanQ=7.794000, numObservations: 4
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action 4, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.592666 0.282715 0.850875 0.889116 0.511262 0.759998 0.236396 0.798342 0.446811 0.313233 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 22
Initial state: 0 0.750685 0.106079 0.622646 0.086664 0.207365 0.0403295 0.925287 0.0767045 0.557138 0.324622 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 704203 episodes
GETTING ACTION FROM:
action 4, numVisits=704153, meanQ=13.977540, numObservations: 9
action 5, numVisits=45, meanQ=9.859111, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.750685 0.106079 0.622646 0.086664 0.207365 0.0403295 0.925287 0.0767045 0.557138 0.324622 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 23
Initial state: 0 0.133059 0.697811 0.754684 0.725905 0.702478 0.593798 0.565479 0.340475 0.415207 0.492168 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 706193 episodes
GETTING ACTION FROM:
action 2, numVisits=706140, meanQ=14.183560, numObservations: 9
action 4, numVisits=19, meanQ=11.697368, numObservations: 7
action 1, numVisits=21, meanQ=11.664781, numObservations: 7
action 5, numVisits=4, meanQ=10.495000, numObservations: 4
action 3, numVisits=7, meanQ=10.141429, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 2 0.133059 0.697811 0.754684 0.725905 0.702478 0.593798 0.565479 0.340475 0.415207 0.492168 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 24
Initial state: 0 0.0275501 0.651976 0.301252 0.793546 0.0435468 0.559441 0.43788 0.339731 0.372353 0.459958 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 706131 episodes
GETTING ACTION FROM:
action 2, numVisits=706105, meanQ=14.078765, numObservations: 9
action 4, numVisits=18, meanQ=11.500006, numObservations: 8
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action 3, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.0275501 0.651976 0.301252 0.793546 0.0435468 0.559441 0.43788 0.339731 0.372353 0.459958 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=97716, meanQ=15.035019, numObservations: 9
action 5, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 857237 episodes
GETTING ACTION FROM:
action 3, numVisits=954953, meanQ=16.520454, numObservations: 9
action 5, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.0275501 0.651976 0.301252 0.793546 0.0435468 0.559441 0.43788 0.339731 0.372353 0.459958 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=77881, meanQ=15.514317, numObservations: 9
action 1, numVisits=4, meanQ=8.497500, numObservations: 3
action 4, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 936097 episodes
GETTING ACTION FROM:
action 5, numVisits=1013978, meanQ=17.559030, numObservations: 9
action 1, numVisits=4, meanQ=8.497500, numObservations: 3
action 4, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 0 0.0275501 0.651976 0.301252 0.793546 0.0435468 0.559441 0.43788 0.339731 0.372353 0.459958 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=48740, meanQ=17.950514, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1018813 episodes
GETTING ACTION FROM:
action 1, numVisits=1067553, meanQ=18.797229, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.0275501 0.651976 0.301252 0.793546 0.0435468 0.559441 0.43788 0.339731 0.372353 0.459958 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 4, numVisits=4832, meanQ=23.089430, numObservations: 9
action 3, numVisits=7, meanQ=20.141429, numObservations: 1
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action 2, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1037722 episodes
GETTING ACTION FROM:
action 4, numVisits=1042554, meanQ=23.837235, numObservations: 9
action 3, numVisits=7, meanQ=20.141429, numObservations: 1
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action 2, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 1 0.0275501 0.651976 0.301252 0.793546 0.0435468 0.559441 0.43788 0.339731 0.372353 0.459958 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.29271
Run # 25
Initial state: 0 0.178861 0.473161 0.865294 0.740411 0.533495 0.343491 0.221541 0.271343 0.653499 0.0253897 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 709039 episodes
GETTING ACTION FROM:
action 1, numVisits=709008, meanQ=14.131783, numObservations: 9
action 5, numVisits=24, meanQ=12.456671, numObservations: 7
action 4, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.178861 0.473161 0.865294 0.740411 0.533495 0.343491 0.221541 0.271343 0.653499 0.0253897 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 26
Initial state: 0 0.884033 0.760025 0.0764259 0.0602048 0.723409 0.433356 0.0947751 0.362415 0.490054 0.356777 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 710718 episodes
GETTING ACTION FROM:
action 1, numVisits=710712, meanQ=14.185515, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.884033 0.760025 0.0764259 0.0602048 0.723409 0.433356 0.0947751 0.362415 0.490054 0.356777 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 27
Initial state: 0 0.285896 0.335881 0.293839 0.780163 0.150194 0.231888 0.458017 0.283644 0.876893 0.923857 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 706001 episodes
GETTING ACTION FROM:
action 4, numVisits=705993, meanQ=14.106190, numObservations: 9
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.285896 0.335881 0.293839 0.780163 0.150194 0.231888 0.458017 0.283644 0.876893 0.923857 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=9102, meanQ=14.047237, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 954316 episodes
GETTING ACTION FROM:
action 5, numVisits=963418, meanQ=13.336291, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.285896 0.335881 0.293839 0.780163 0.150194 0.231888 0.458017 0.283644 0.876893 0.923857 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 28
Initial state: 0 0.737228 0.736605 0.697673 0.97217 0.541556 0.287253 0.0235234 0.416362 0.631624 0.0493349 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 709031 episodes
GETTING ACTION FROM:
action 4, numVisits=709023, meanQ=14.111570, numObservations: 9
action 5, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.737228 0.736605 0.697673 0.97217 0.541556 0.287253 0.0235234 0.416362 0.631624 0.0493349 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=96983, meanQ=15.049122, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 854705 episodes
GETTING ACTION FROM:
action 5, numVisits=951688, meanQ=15.948328, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.737228 0.736605 0.697673 0.97217 0.541556 0.287253 0.0235234 0.416362 0.631624 0.0493349 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 29
Initial state: 0 0.636279 0.901889 0.779574 0.808675 0.490204 0.659289 0.424488 0.274553 0.634567 0.166323 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 680612 episodes
GETTING ACTION FROM:
action 5, numVisits=680584, meanQ=14.143606, numObservations: 9
action 4, numVisits=21, meanQ=4.036200, numObservations: 7
action 2, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.636279 0.901889 0.779574 0.808675 0.490204 0.659289 0.424488 0.274553 0.634567 0.166323 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 30
Initial state: 0 0.487592 0.266673 0.329446 0.425031 0.292897 0.658682 0.898485 0.991142 0.181033 0.488125 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 703431 episodes
GETTING ACTION FROM:
action 2, numVisits=703421, meanQ=14.127906, numObservations: 9
action 4, numVisits=5, meanQ=0.794000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.487592 0.266673 0.329446 0.425031 0.292897 0.658682 0.898485 0.991142 0.181033 0.488125 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=97538, meanQ=14.826386, numObservations: 9
action 0, numVisits=55, meanQ=0.500020, numObservations: 36
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 863312 episodes
GETTING ACTION FROM:
action 1, numVisits=960850, meanQ=15.602905, numObservations: 9
action 0, numVisits=55, meanQ=0.500020, numObservations: 36
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.487592 0.266673 0.329446 0.425031 0.292897 0.658682 0.898485 0.991142 0.181033 0.488125 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 31
Initial state: 0 0.057106 0.638522 0.109936 0.223933 0.5383 0.320899 0.0221719 0.995166 0.57185 0.692528 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 701615 episodes
GETTING ACTION FROM:
action 5, numVisits=701581, meanQ=14.206978, numObservations: 9
action 3, numVisits=29, meanQ=11.813797, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.057106 0.638522 0.109936 0.223933 0.5383 0.320899 0.0221719 0.995166 0.57185 0.692528 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 32
Initial state: 0 0.511114 0.270368 0.264547 0.526489 0.11979 0.304773 0.988574 0.842373 0.196884 0.74796 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 697009 episodes
GETTING ACTION FROM:
action 3, numVisits=696953, meanQ=14.128011, numObservations: 9
action 1, numVisits=47, meanQ=9.782353, numObservations: 9
action 5, numVisits=5, meanQ=7.396020, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.511114 0.270368 0.264547 0.526489 0.11979 0.304773 0.988574 0.842373 0.196884 0.74796 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 33
Initial state: 0 0.0915492 0.748976 0.148423 0.162246 0.541287 0.265459 0.890026 0.806211 0.695354 0.604493 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 702571 episodes
GETTING ACTION FROM:
action 3, numVisits=702555, meanQ=13.990613, numObservations: 9
action 2, numVisits=8, meanQ=11.343750, numObservations: 5
action 4, numVisits=4, meanQ=8.497500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.0915492 0.748976 0.148423 0.162246 0.541287 0.265459 0.890026 0.806211 0.695354 0.604493 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 34
Initial state: 0 0.74944 0.412942 0.238073 0.283579 0.398471 0.258193 0.928376 0.342729 0.0121619 0.563508 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 703242 episodes
GETTING ACTION FROM:
action 1, numVisits=703234, meanQ=14.223293, numObservations: 9
action 4, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.74944 0.412942 0.238073 0.283579 0.398471 0.258193 0.928376 0.342729 0.0121619 0.563508 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 35
Initial state: 0 0.191647 0.216581 0.876022 0.94288 0.458767 0.347738 0.692998 0.536584 0.873647 0.948569 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 679341 episodes
GETTING ACTION FROM:
action 1, numVisits=679330, meanQ=14.121333, numObservations: 9
action 5, numVisits=6, meanQ=6.500000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.191647 0.216581 0.876022 0.94288 0.458767 0.347738 0.692998 0.536584 0.873647 0.948569 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=46826, meanQ=14.799986, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 843529 episodes
GETTING ACTION FROM:
action 4, numVisits=890355, meanQ=14.380167, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.191647 0.216581 0.876022 0.94288 0.458767 0.347738 0.692998 0.536584 0.873647 0.948569 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 36
Initial state: 0 0.338621 0.381135 0.512828 0.339482 0.84925 0.843913 0.548472 0.462942 0.74737 0.668826 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 702280 episodes
GETTING ACTION FROM:
action 5, numVisits=702274, meanQ=14.171003, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.338621 0.381135 0.512828 0.339482 0.84925 0.843913 0.548472 0.462942 0.74737 0.668826 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 37
Initial state: 0 0.223798 0.368069 0.722825 0.29476 0.755697 0.439109 0.386898 0.333862 0.833811 0.678774 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 702604 episodes
GETTING ACTION FROM:
action 2, numVisits=702595, meanQ=14.159107, numObservations: 9
action 5, numVisits=2, meanQ=6.500000, numObservations: 1
action 4, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.223798 0.368069 0.722825 0.29476 0.755697 0.439109 0.386898 0.333862 0.833811 0.678774 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 38
Initial state: 0 0.845887 0.369077 0.0545639 0.691958 0.234362 0.704154 0.0878597 0.32529 0.492552 0.281388 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 705115 episodes
GETTING ACTION FROM:
action 5, numVisits=705100, meanQ=14.181729, numObservations: 9
action 2, numVisits=10, meanQ=7.299000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.845887 0.369077 0.0545639 0.691958 0.234362 0.704154 0.0878597 0.32529 0.492552 0.281388 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 39
Initial state: 0 0.710084 0.486242 0.438295 0.22261 0.414977 0.345918 0.633024 0.806768 0.2509 0.401398 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 699504 episodes
GETTING ACTION FROM:
action 1, numVisits=699480, meanQ=14.140683, numObservations: 9
action 4, numVisits=9, meanQ=-0.779989, numObservations: 7
action -1, numVisits=6, meanQ=-1.010000, numObservations: 6
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.710084 0.486242 0.438295 0.22261 0.414977 0.345918 0.633024 0.806768 0.2509 0.401398 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 40
Initial state: 0 0.639315 0.12082 0.759892 0.523558 0.535423 0.270078 0.574572 0.667444 0.875084 0.669493 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 703702 episodes
GETTING ACTION FROM:
action 2, numVisits=703696, meanQ=14.148148, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.639315 0.12082 0.759892 0.523558 0.535423 0.270078 0.574572 0.667444 0.875084 0.669493 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 41
Initial state: 0 0.0365735 0.0848066 0.29317 0.370154 0.40388 0.336519 0.85491 0.0969442 0.0541245 0.59933 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 705063 episodes
GETTING ACTION FROM:
action 5, numVisits=705057, meanQ=14.128365, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 0 0.0365735 0.0848066 0.29317 0.370154 0.40388 0.336519 0.85491 0.0969442 0.0541245 0.59933 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=8586, meanQ=14.180540, numObservations: 9
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 980954 episodes
GETTING ACTION FROM:
action 4, numVisits=989540, meanQ=16.783940, numObservations: 9
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.0365735 0.0848066 0.29317 0.370154 0.40388 0.336519 0.85491 0.0969442 0.0541245 0.59933 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 42
Initial state: 0 0.266437 0.963522 0.532156 0.293862 0.925154 0.344347 0.98049 0.171325 0.819027 0.0886403 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 693320 episodes
GETTING ACTION FROM:
action 3, numVisits=693310, meanQ=14.163092, numObservations: 9
action 1, numVisits=3, meanQ=5.330033, numObservations: 2
action 2, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.266437 0.963522 0.532156 0.293862 0.925154 0.344347 0.98049 0.171325 0.819027 0.0886403 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 43
Initial state: 0 0.42533 0.25953 0.0584753 0.500833 0.901207 0.0313188 0.144796 0.572354 0.949263 0.770709 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 704431 episodes
GETTING ACTION FROM:
action 1, numVisits=704423, meanQ=14.138153, numObservations: 9
action 3, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.42533 0.25953 0.0584753 0.500833 0.901207 0.0313188 0.144796 0.572354 0.949263 0.770709 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 44
Initial state: 0 0.148147 0.449957 0.532268 0.283572 0.297947 0.236246 0.654108 0.685059 0.176747 0.38845 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 708011 episodes
GETTING ACTION FROM:
action 4, numVisits=707981, meanQ=14.059692, numObservations: 9
action 3, numVisits=12, meanQ=8.666683, numObservations: 6
action 5, numVisits=14, meanQ=8.502879, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 1 0.148147 0.449957 0.532268 0.283572 0.297947 0.236246 0.654108 0.685059 0.176747 0.38845 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 45
Initial state: 0 0.300848 0.20998 0.73622 0.698428 0.432174 0.31485 0.578084 0.412711 0.968496 0.160084 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 672419 episodes
GETTING ACTION FROM:
action 3, numVisits=672412, meanQ=14.003025, numObservations: 9
action 4, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.300848 0.20998 0.73622 0.698428 0.432174 0.31485 0.578084 0.412711 0.968496 0.160084 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 46
Initial state: 0 0.767267 0.591491 0.915259 0.960845 0.654787 0.801027 0.11197 0.645798 0.449362 0.308116 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 706910 episodes
GETTING ACTION FROM:
action 4, numVisits=706898, meanQ=14.102201, numObservations: 9
action 5, numVisits=5, meanQ=6.196000, numObservations: 4
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 0 0.767267 0.591491 0.915259 0.960845 0.654787 0.801027 0.11197 0.645798 0.449362 0.308116 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=97161, meanQ=15.111379, numObservations: 9
action 4, numVisits=50, meanQ=13.994909, numObservations: 5
action 5, numVisits=14, meanQ=11.282857, numObservations: 5
action 3, numVisits=7, meanQ=10.677143, numObservations: 4
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 875769 episodes
GETTING ACTION FROM:
action 1, numVisits=972930, meanQ=16.436092, numObservations: 9
action 4, numVisits=50, meanQ=13.994909, numObservations: 5
action 5, numVisits=14, meanQ=11.282857, numObservations: 5
action 3, numVisits=7, meanQ=10.677143, numObservations: 4
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.767267 0.591491 0.915259 0.960845 0.654787 0.801027 0.11197 0.645798 0.449362 0.308116 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 47
Initial state: 0 0.00888327 0.587348 0.470815 0.312069 0.76137 0.817748 0.773345 0.862546 0.815979 0.826752 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 601865 episodes
GETTING ACTION FROM:
action 4, numVisits=601853, meanQ=14.013584, numObservations: 9
action 1, numVisits=5, meanQ=6.196000, numObservations: 3
action 2, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.00888327 0.587348 0.470815 0.312069 0.76137 0.817748 0.773345 0.862546 0.815979 0.826752 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 48
Initial state: 0 0.550073 0.286186 0.830544 0.19796 0.195001 0.780684 0.845777 0.608679 0.307545 0.312566 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 709479 episodes
GETTING ACTION FROM:
action 4, numVisits=709459, meanQ=14.149525, numObservations: 9
action 3, numVisits=11, meanQ=10.430009, numObservations: 5
action 5, numVisits=5, meanQ=7.794000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.550073 0.286186 0.830544 0.19796 0.195001 0.780684 0.845777 0.608679 0.307545 0.312566 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 49
Initial state: 0 0.98583 0.448856 0.301323 0.499444 0.700671 0.0552107 0.545869 0.303929 0.118781 0.752456 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 698449 episodes
GETTING ACTION FROM:
action 3, numVisits=698437, meanQ=14.044412, numObservations: 9
action 2, numVisits=3, meanQ=5.993333, numObservations: 3
action 4, numVisits=5, meanQ=4.598000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.98583 0.448856 0.301323 0.499444 0.700671 0.0552107 0.545869 0.303929 0.118781 0.752456 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 50
Initial state: 0 0.555491 0.343949 0.0438428 0.124668 0.878427 0.671545 0.647212 0.904023 0.503453 0.467452 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 702846 episodes
GETTING ACTION FROM:
action 2, numVisits=702829, meanQ=14.182813, numObservations: 9
action 4, numVisits=9, meanQ=8.900000, numObservations: 6
action 5, numVisits=4, meanQ=8.497500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.555491 0.343949 0.0438428 0.124668 0.878427 0.671545 0.647212 0.904023 0.503453 0.467452 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=48394, meanQ=15.033843, numObservations: 9
action 3, numVisits=44, meanQ=12.263643, numObservations: 9
action 5, numVisits=9, meanQ=11.554456, numObservations: 4
action 1, numVisits=6, meanQ=10.495000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 850491 episodes
GETTING ACTION FROM:
action 4, numVisits=898885, meanQ=14.069744, numObservations: 9
action 3, numVisits=44, meanQ=12.263643, numObservations: 9
action 5, numVisits=9, meanQ=11.554456, numObservations: 4
action 1, numVisits=6, meanQ=10.495000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 1 0.555491 0.343949 0.0438428 0.124668 0.878427 0.671545 0.647212 0.904023 0.503453 0.467452 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
[32m ProblemEnvironment.hpp 351: Done.[39m
