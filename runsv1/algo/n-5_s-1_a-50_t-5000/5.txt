Run # 1
Initial state: 0 0.859498 0.13212 0.788079 0.412091 0.294946 0.0652019 0.402715 0.140416 0.567354 0.413932 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 136888 episodes
GETTING ACTION FROM:
action 2, numVisits=136876, meanQ=12.628034, numObservations: 9
action 1, numVisits=5, meanQ=4.400000, numObservations: 4
action 5, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.859498 0.13212 0.788079 0.412091 0.294946 0.0652019 0.402715 0.140416 0.567354 0.413932 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 2
Initial state: 0 0.293255 0.28698 0.617473 0.365118 0.226283 0.70525 0.0503709 0.870072 0.70009 0.100821 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 136087 episodes
GETTING ACTION FROM:
action 2, numVisits=136075, meanQ=12.278417, numObservations: 9
action 5, numVisits=6, meanQ=8.666683, numObservations: 5
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.293255 0.28698 0.617473 0.365118 0.226283 0.70525 0.0503709 0.870072 0.70009 0.100821 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 3
Initial state: 0 0.971158 0.0164659 0.56824 0.322774 0.716992 0.975629 0.391146 0.966031 0.462739 0.654697 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 129706 episodes
GETTING ACTION FROM:
action 5, numVisits=129695, meanQ=12.671866, numObservations: 9
action 1, numVisits=4, meanQ=6.500000, numObservations: 4
action 4, numVisits=3, meanQ=5.663333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 0 0.971158 0.0164659 0.56824 0.322774 0.716992 0.975629 0.391146 0.966031 0.462739 0.654697 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=20214, meanQ=13.338653, numObservations: 9
action 2, numVisits=8, meanQ=6.120000, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 49567 episodes
GETTING ACTION FROM:
action 4, numVisits=49563, meanQ=16.102106, numObservations: 9
action 5, numVisits=20216, meanQ=13.339001, numObservations: 9
action 2, numVisits=8, meanQ=6.120000, numObservations: 7
action -1, numVisits=3, meanQ=-1.340000, numObservations: 3
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.971158 0.0164659 0.56824 0.322774 0.716992 0.975629 0.391146 0.966031 0.462739 0.654697 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=4725, meanQ=16.566547, numObservations: 9
action 2, numVisits=6, meanQ=6.873257, numObservations: 5
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-8.852942, numObservations: 1
action 4, numVisits=1, meanQ=-10.954626, numObservations: 1
action 5, numVisits=1, meanQ=-1071.263970, numObservations: 1
Sampled 50807 episodes
GETTING ACTION FROM:
action 3, numVisits=55532, meanQ=17.640369, numObservations: 9
action 2, numVisits=6, meanQ=6.873257, numObservations: 5
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-8.852942, numObservations: 1
action 4, numVisits=1, meanQ=-10.954626, numObservations: 1
action 5, numVisits=1, meanQ=-1071.263970, numObservations: 1
action: 3
Next state: 1 0.971158 0.0164659 0.56824 0.322774 0.716992 0.975629 0.391146 0.966031 0.462739 0.654697 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 4
Initial state: 0 0.204891 0.0321375 0.0105825 0.992004 0.760464 0.292234 0.0819544 0.623152 0.606949 0.446196 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 138872 episodes
GETTING ACTION FROM:
action 5, numVisits=138866, meanQ=12.608618, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.204891 0.0321375 0.0105825 0.992004 0.760464 0.292234 0.0819544 0.623152 0.606949 0.446196 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 5
Initial state: 0 0.560331 0.400348 0.270318 0.78063 0.663018 0.0527206 0.502896 0.359804 0.463947 0.97993 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 138754 episodes
GETTING ACTION FROM:
action 5, numVisits=138748, meanQ=12.462218, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 1 0.560331 0.400348 0.270318 0.78063 0.663018 0.0527206 0.502896 0.359804 0.463947 0.97993 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 6
Initial state: 0 0.897136 0.48139 0.987371 0.318618 0.892711 0.356311 0.0146685 0.752476 0.546428 0.415293 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 132360 episodes
GETTING ACTION FROM:
action 4, numVisits=132352, meanQ=12.655211, numObservations: 9
action 2, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.897136 0.48139 0.987371 0.318618 0.892711 0.356311 0.0146685 0.752476 0.546428 0.415293 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=20868, meanQ=13.140066, numObservations: 9
action 1, numVisits=7, meanQ=8.565714, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 52259 episodes
GETTING ACTION FROM:
action 1, numVisits=52129, meanQ=16.015755, numObservations: 9
action 4, numVisits=20868, meanQ=13.140066, numObservations: 9
action 5, numVisits=58, meanQ=-3.716096, numObservations: 9
action 3, numVisits=2, meanQ=-7.240855, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=50, meanQ=-19.147824, numObservations: 35
action -1, numVisits=31, meanQ=-35.294673, numObservations: 26
action: 1
Next state: 2 0.897136 0.48139 0.987371 0.318618 0.892711 0.356311 0.0146685 0.752476 0.546428 0.415293 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 7
Initial state: 0 0.672743 0.477469 0.448508 0.0357973 0.617567 0.411964 0.0438923 0.171761 0.916358 0.55925 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 139498 episodes
GETTING ACTION FROM:
action 4, numVisits=139487, meanQ=12.726093, numObservations: 9
action 1, numVisits=4, meanQ=8.250000, numObservations: 4
action 5, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.672743 0.477469 0.448508 0.0357973 0.617567 0.411964 0.0438923 0.171761 0.916358 0.55925 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=16129, meanQ=13.443549, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 33522 episodes
GETTING ACTION FROM:
action 1, numVisits=49303, meanQ=12.159440, numObservations: 9
action 2, numVisits=344, meanQ=10.369741, numObservations: 9
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=3, meanQ=-1.340000, numObservations: 3
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.672743 0.477469 0.448508 0.0357973 0.617567 0.411964 0.0438923 0.171761 0.916358 0.55925 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 8
Initial state: 0 0.589953 0.34392 0.866102 0.467244 0.00959186 0.603069 0.172298 0.948631 0.169841 0.905234 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 129499 episodes
GETTING ACTION FROM:
action 2, numVisits=129490, meanQ=12.453331, numObservations: 9
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action 3, numVisits=3, meanQ=5.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.589953 0.34392 0.866102 0.467244 0.00959186 0.603069 0.172298 0.948631 0.169841 0.905234 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 9
Initial state: 0 0.6385 0.190854 0.780502 0.701041 0.549716 0.348889 0.958926 0.0657615 0.176411 0.419788 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 128850 episodes
GETTING ACTION FROM:
action 4, numVisits=128843, meanQ=12.703564, numObservations: 9
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.6385 0.190854 0.780502 0.701041 0.549716 0.348889 0.958926 0.0657615 0.176411 0.419788 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 10
Initial state: 0 0.0235464 0.614608 0.767833 0.829485 0.634642 0.35371 0.155659 0.513716 0.437915 0.154438 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 138803 episodes
GETTING ACTION FROM:
action 1, numVisits=138792, meanQ=12.533473, numObservations: 9
action 2, numVisits=4, meanQ=-0.500000, numObservations: 3
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.0235464 0.614608 0.767833 0.829485 0.634642 0.35371 0.155659 0.513716 0.437915 0.154438 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=21807, meanQ=13.541445, numObservations: 9
action 3, numVisits=6, meanQ=8.831683, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 51969 episodes
GETTING ACTION FROM:
action 5, numVisits=73762, meanQ=14.503105, numObservations: 9
action 3, numVisits=17, meanQ=9.665205, numObservations: 5
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.0235464 0.614608 0.767833 0.829485 0.634642 0.35371 0.155659 0.513716 0.437915 0.154438 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=6086, meanQ=14.691262, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 31347 episodes
GETTING ACTION FROM:
action 4, numVisits=37432, meanQ=13.959274, numObservations: 9
action -1, numVisits=3, meanQ=-1.340000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.0235464 0.614608 0.767833 0.829485 0.634642 0.35371 0.155659 0.513716 0.437915 0.154438 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=2996, meanQ=19.575193, numObservations: 9
action 2, numVisits=5, meanQ=11.688423, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 43532 episodes
GETTING ACTION FROM:
action 3, numVisits=46528, meanQ=19.376645, numObservations: 9
action 2, numVisits=5, meanQ=11.688423, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.0235464 0.614608 0.767833 0.829485 0.634642 0.35371 0.155659 0.513716 0.437915 0.154438 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 11.4068
Run # 11
Initial state: 0 0.731328 0.852051 0.81217 0.548951 0.371717 0.361719 0.525671 0.400795 0.741561 0.829666 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 138936 episodes
GETTING ACTION FROM:
action 3, numVisits=138929, meanQ=12.595018, numObservations: 9
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.731328 0.852051 0.81217 0.548951 0.371717 0.361719 0.525671 0.400795 0.741561 0.829666 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=4733, meanQ=13.642325, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 31214 episodes
GETTING ACTION FROM:
action 4, numVisits=35823, meanQ=14.121298, numObservations: 9
action 0, numVisits=102, meanQ=-0.724199, numObservations: 80
action -1, numVisits=21, meanQ=-2.127572, numObservations: 20
action 2, numVisits=2, meanQ=-4.004950, numObservations: 1
action 1, numVisits=2, meanQ=-8.125681, numObservations: 2
action 5, numVisits=2, meanQ=-8.315032, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.731328 0.852051 0.81217 0.548951 0.371717 0.361719 0.525671 0.400795 0.741561 0.829666 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 12
Initial state: 0 0.735662 5.83219e-05 0.110179 0.191178 0.752003 0.986868 0.375181 0.865599 0.517046 0.374474 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 138817 episodes
GETTING ACTION FROM:
action 3, numVisits=138809, meanQ=12.577442, numObservations: 9
action 2, numVisits=3, meanQ=4.340033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.735662 5.83219e-05 0.110179 0.191178 0.752003 0.986868 0.375181 0.865599 0.517046 0.374474 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 13
Initial state: 0 0.398352 0.690565 0.199808 0.913437 0.411606 0.925259 0.554104 0.329804 0.0955011 0.493733 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 139328 episodes
GETTING ACTION FROM:
action 3, numVisits=139312, meanQ=12.498185, numObservations: 9
action 2, numVisits=8, meanQ=8.250000, numObservations: 5
action 4, numVisits=4, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.398352 0.690565 0.199808 0.913437 0.411606 0.925259 0.554104 0.329804 0.0955011 0.493733 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 14
Initial state: 0 0.848298 0.0785858 0.0934063 0.630515 0.00179262 0.995645 0.414546 0.476058 0.608765 0.417117 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 136438 episodes
GETTING ACTION FROM:
action 2, numVisits=136409, meanQ=12.655661, numObservations: 9
action 4, numVisits=24, meanQ=8.375017, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.848298 0.0785858 0.0934063 0.630515 0.00179262 0.995645 0.414546 0.476058 0.608765 0.417117 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=1604, meanQ=12.943511, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 60454 episodes
GETTING ACTION FROM:
action 3, numVisits=62046, meanQ=15.055320, numObservations: 9
action -1, numVisits=6, meanQ=-1.835000, numObservations: 6
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=8, meanQ=-131.467399, numObservations: 7
action: 3
Next state: 0 0.848298 0.0785858 0.0934063 0.630515 0.00179262 0.995645 0.414546 0.476058 0.608765 0.417117 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=2577, meanQ=13.210141, numObservations: 9
action 4, numVisits=6, meanQ=2.681667, numObservations: 5
action 0, numVisits=6, meanQ=-1.341650, numObservations: 5
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=65, meanQ=-11.617175, numObservations: 35
Sampled 72238 episodes
GETTING ACTION FROM:
action 1, numVisits=74815, meanQ=14.865190, numObservations: 9
action 4, numVisits=6, meanQ=2.681667, numObservations: 5
action 0, numVisits=6, meanQ=-1.341650, numObservations: 5
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=65, meanQ=-11.617175, numObservations: 35
action: 1
Next state: 2 0.848298 0.0785858 0.0934063 0.630515 0.00179262 0.995645 0.414546 0.476058 0.608765 0.417117 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -18.7411
Run # 15
Initial state: 0 0.0651062 0.640828 0.52147 0.920193 0.555487 0.343024 0.330132 0.240678 0.118671 0.77243 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 139707 episodes
GETTING ACTION FROM:
action 4, numVisits=139697, meanQ=12.656275, numObservations: 9
action 5, numVisits=5, meanQ=4.400000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 0 0.0651062 0.640828 0.52147 0.920193 0.555487 0.343024 0.330132 0.240678 0.118671 0.77243 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=16209, meanQ=13.437099, numObservations: 9
action 3, numVisits=4, meanQ=6.500000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 34617 episodes
GETTING ACTION FROM:
action 5, numVisits=50821, meanQ=12.965144, numObservations: 9
action 3, numVisits=5, meanQ=3.124950, numObservations: 5
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.0651062 0.640828 0.52147 0.920193 0.555487 0.343024 0.330132 0.240678 0.118671 0.77243 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=481, meanQ=12.087688, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 56437 episodes
GETTING ACTION FROM:
action 3, numVisits=56916, meanQ=15.171665, numObservations: 9
action -1, numVisits=3, meanQ=-1.340000, numObservations: 3
action 0, numVisits=3, meanQ=-1.340000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.0651062 0.640828 0.52147 0.920193 0.555487 0.343024 0.330132 0.240678 0.118671 0.77243 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 16
Initial state: 0 0.928327 0.0966413 0.504988 0.705024 0.6099 0.435006 0.687821 0.142395 0.31208 0.964811 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 138291 episodes
GETTING ACTION FROM:
action 1, numVisits=138275, meanQ=12.617760, numObservations: 9
action 5, numVisits=6, meanQ=8.336683, numObservations: 4
action 3, numVisits=6, meanQ=7.666667, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.928327 0.0966413 0.504988 0.705024 0.6099 0.435006 0.687821 0.142395 0.31208 0.964811 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 17
Initial state: 0 0.494926 0.18632 0.432346 0.958884 0.63298 0.410299 0.110604 0.0855863 0.154527 0.978625 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 140635 episodes
GETTING ACTION FROM:
action 4, numVisits=140628, meanQ=12.658238, numObservations: 9
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.494926 0.18632 0.432346 0.958884 0.63298 0.410299 0.110604 0.0855863 0.154527 0.978625 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=16527, meanQ=13.109302, numObservations: 9
action 1, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 42312 episodes
GETTING ACTION FROM:
action 3, numVisits=58836, meanQ=12.931570, numObservations: 9
action 1, numVisits=3, meanQ=3.330000, numObservations: 3
action 0, numVisits=3, meanQ=-1.340000, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.494926 0.18632 0.432346 0.958884 0.63298 0.410299 0.110604 0.0855863 0.154527 0.978625 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 18
Initial state: 0 0.203998 0.611756 0.424431 0.689004 0.56227 0.963827 0.556914 0.435715 0.213391 0.777153 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 138815 episodes
GETTING ACTION FROM:
action 4, numVisits=138800, meanQ=12.735185, numObservations: 9
action 2, numVisits=10, meanQ=4.810000, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 1 0.203998 0.611756 0.424431 0.689004 0.56227 0.963827 0.556914 0.435715 0.213391 0.777153 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 19
Initial state: 0 0.311989 0.702153 0.0607375 0.747221 0.517622 0.415053 0.837 0.590153 0.305765 0.677578 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 132362 episodes
GETTING ACTION FROM:
action 2, numVisits=132344, meanQ=12.706564, numObservations: 9
action 5, numVisits=7, meanQ=6.715729, numObservations: 5
action 4, numVisits=3, meanQ=5.663333, numObservations: 3
action 1, numVisits=3, meanQ=5.333333, numObservations: 3
action 3, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.311989 0.702153 0.0607375 0.747221 0.517622 0.415053 0.837 0.590153 0.305765 0.677578 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=20885, meanQ=13.318772, numObservations: 9
action 4, numVisits=8, meanQ=5.121250, numObservations: 7
action 5, numVisits=8, meanQ=4.872513, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 47397 episodes
GETTING ACTION FROM:
action 5, numVisits=47390, meanQ=14.585419, numObservations: 9
action 2, numVisits=20887, meanQ=13.319090, numObservations: 9
action 4, numVisits=8, meanQ=5.121250, numObservations: 7
action -1, numVisits=7, meanQ=-1.434286, numObservations: 7
action 0, numVisits=7, meanQ=-1.434286, numObservations: 7
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=2, meanQ=-532.325016, numObservations: 1
action: 5
Next state: 0 0.311989 0.702153 0.0607375 0.747221 0.517622 0.415053 0.837 0.590153 0.305765 0.677578 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=4839, meanQ=16.555418, numObservations: 9
action 3, numVisits=253, meanQ=12.763503, numObservations: 9
action 4, numVisits=4, meanQ=6.644762, numObservations: 3
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 5, numVisits=1, meanQ=-9.663115, numObservations: 1
action 2, numVisits=1, meanQ=-1065.365376, numObservations: 1
Sampled 45105 episodes
GETTING ACTION FROM:
action 1, numVisits=49929, meanQ=17.497520, numObservations: 9
action 3, numVisits=268, meanQ=13.083755, numObservations: 9
action 4, numVisits=4, meanQ=6.644762, numObservations: 3
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 5, numVisits=1, meanQ=-9.663115, numObservations: 1
action 2, numVisits=1, meanQ=-1065.365376, numObservations: 1
action: 1
Next state: 0 0.311989 0.702153 0.0607375 0.747221 0.517622 0.415053 0.837 0.590153 0.305765 0.677578 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=3268, meanQ=18.332761, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.396558, numObservations: 1
action 1, numVisits=1, meanQ=-10.502096, numObservations: 1
action 5, numVisits=1, meanQ=-10.722628, numObservations: 1
action 2, numVisits=1, meanQ=-1066.652897, numObservations: 1
Sampled 102065 episodes
GETTING ACTION FROM:
action 3, numVisits=105333, meanQ=20.811302, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.396558, numObservations: 1
action 1, numVisits=1, meanQ=-10.502096, numObservations: 1
action 5, numVisits=1, meanQ=-10.722628, numObservations: 1
action 2, numVisits=1, meanQ=-1066.652897, numObservations: 1
action: 3
Next state: 1 0.311989 0.702153 0.0607375 0.747221 0.517622 0.415053 0.837 0.590153 0.305765 0.677578 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 11.4068
Run # 20
Initial state: 0 0.632554 0.325673 0.822232 0.383652 0.661227 0.560025 0.117717 0.927445 0.890155 0.518321 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 139265 episodes
GETTING ACTION FROM:
action 5, numVisits=139259, meanQ=12.747019, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 1 0.632554 0.325673 0.822232 0.383652 0.661227 0.560025 0.117717 0.927445 0.890155 0.518321 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 21
Initial state: 0 0.541602 0.405668 0.758967 0.765348 0.366554 0.623633 0.0836901 0.799744 0.826407 0.325117 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 139826 episodes
GETTING ACTION FROM:
action 4, numVisits=139813, meanQ=12.479491, numObservations: 9
action 1, numVisits=6, meanQ=4.496667, numObservations: 6
action 2, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.541602 0.405668 0.758967 0.765348 0.366554 0.623633 0.0836901 0.799744 0.826407 0.325117 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1680, meanQ=13.304161, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 73994 episodes
GETTING ACTION FROM:
action 2, numVisits=75670, meanQ=14.534119, numObservations: 9
action -1, numVisits=3, meanQ=-1.670000, numObservations: 3
action 0, numVisits=3, meanQ=-1.670000, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.541602 0.405668 0.758967 0.765348 0.366554 0.623633 0.0836901 0.799744 0.826407 0.325117 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 22
Initial state: 0 0.512187 0.872773 0.0587486 0.655832 0.876469 0.938728 0.617014 0.359616 0.512591 0.570993 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 139440 episodes
GETTING ACTION FROM:
action 5, numVisits=139434, meanQ=12.691097, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.512187 0.872773 0.0587486 0.655832 0.876469 0.938728 0.617014 0.359616 0.512591 0.570993 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=22104, meanQ=13.595543, numObservations: 9
action 5, numVisits=6, meanQ=9.501700, numObservations: 1
action 2, numVisits=4, meanQ=6.500000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 42189 episodes
GETTING ACTION FROM:
action 4, numVisits=63653, meanQ=14.152502, numObservations: 9
action 5, numVisits=8, meanQ=12.596275, numObservations: 1
action 2, numVisits=638, meanQ=12.198821, numObservations: 9
action -1, numVisits=3, meanQ=-1.340000, numObservations: 3
action 0, numVisits=3, meanQ=-1.340000, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.512187 0.872773 0.0587486 0.655832 0.876469 0.938728 0.617014 0.359616 0.512591 0.570993 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 23
Initial state: 0 0.232107 0.949544 0.380978 0.721499 0.995397 0.730743 0.487601 0.0898056 0.608124 0.374611 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 138694 episodes
GETTING ACTION FROM:
action 2, numVisits=137636, meanQ=12.706555, numObservations: 9
action 5, numVisits=1041, meanQ=12.219262, numObservations: 9
action 3, numVisits=13, meanQ=9.808477, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.232107 0.949544 0.380978 0.721499 0.995397 0.730743 0.487601 0.0898056 0.608124 0.374611 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=21708, meanQ=13.730124, numObservations: 9
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action 1, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 43006 episodes
GETTING ACTION FROM:
action 1, numVisits=42410, meanQ=15.547544, numObservations: 9
action 5, numVisits=22291, meanQ=13.744913, numObservations: 9
action 3, numVisits=16, meanQ=11.687506, numObservations: 6
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.232107 0.949544 0.380978 0.721499 0.995397 0.730743 0.487601 0.0898056 0.608124 0.374611 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 24
Initial state: 0 0.182171 0.250044 0.446274 0.340636 0.6258 0.983261 0.0103719 0.933451 0.559547 0.371338 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 138187 episodes
GETTING ACTION FROM:
action 2, numVisits=138179, meanQ=12.629851, numObservations: 9
action 1, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.182171 0.250044 0.446274 0.340636 0.6258 0.983261 0.0103719 0.933451 0.559547 0.371338 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=4857, meanQ=13.429971, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 31727 episodes
GETTING ACTION FROM:
action 4, numVisits=19615, meanQ=13.515115, numObservations: 9
action 3, numVisits=16928, meanQ=12.886300, numObservations: 9
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=26, meanQ=-40.541174, numObservations: 21
action 0, numVisits=18, meanQ=-58.970754, numObservations: 17
action: 4
Next state: 0 0.182171 0.250044 0.446274 0.340636 0.6258 0.983261 0.0103719 0.933451 0.559547 0.371338 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=2367, meanQ=12.801258, numObservations: 9
action 1, numVisits=5, meanQ=7.000020, numObservations: 2
action 3, numVisits=7, meanQ=5.677143, numObservations: 4
action 0, numVisits=9, meanQ=-1.010000, numObservations: 9
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=9, meanQ=-116.124778, numObservations: 8
Sampled 36669 episodes
GETTING ACTION FROM:
action 5, numVisits=39036, meanQ=15.201340, numObservations: 9
action 1, numVisits=5, meanQ=7.000020, numObservations: 2
action 3, numVisits=7, meanQ=5.677143, numObservations: 4
action 0, numVisits=9, meanQ=-1.010000, numObservations: 9
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=9, meanQ=-116.124778, numObservations: 8
action: 5
Next state: 1 0.182171 0.250044 0.446274 0.340636 0.6258 0.983261 0.0103719 0.933451 0.559547 0.371338 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 25
Initial state: 0 0.962099 0.0252583 0.564536 0.423649 0.105359 0.256318 0.237653 0.0739386 0.700888 0.212383 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 137761 episodes
GETTING ACTION FROM:
action 1, numVisits=137755, meanQ=12.436462, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.962099 0.0252583 0.564536 0.423649 0.105359 0.256318 0.237653 0.0739386 0.700888 0.212383 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 26
Initial state: 0 0.156092 0.932854 0.508766 0.0311679 0.588477 0.451187 0.372654 0.915533 0.884717 0.996572 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 139053 episodes
GETTING ACTION FROM:
action 4, numVisits=139027, meanQ=12.732181, numObservations: 9
action 2, numVisits=13, meanQ=6.768469, numObservations: 8
action 1, numVisits=9, meanQ=5.788889, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.156092 0.932854 0.508766 0.0311679 0.588477 0.451187 0.372654 0.915533 0.884717 0.996572 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 27
Initial state: 0 0.910755 0.149299 0.444133 0.312096 0.419653 0.0399085 0.0483423 0.15291 0.532521 0.407215 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 139134 episodes
GETTING ACTION FROM:
action 1, numVisits=139118, meanQ=12.707513, numObservations: 9
action 3, numVisits=6, meanQ=9.833350, numObservations: 4
action 4, numVisits=6, meanQ=8.833333, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.910755 0.149299 0.444133 0.312096 0.419653 0.0399085 0.0483423 0.15291 0.532521 0.407215 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 28
Initial state: 0 0.610222 0.421101 0.308057 0.278639 0.508409 0.788316 0.794831 0.154277 0.658301 0.401332 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 139614 episodes
GETTING ACTION FROM:
action 5, numVisits=139603, meanQ=12.712350, numObservations: 9
action 2, numVisits=4, meanQ=-0.500000, numObservations: 3
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.610222 0.421101 0.308057 0.278639 0.508409 0.788316 0.794831 0.154277 0.658301 0.401332 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 29
Initial state: 0 0.719483 0.595214 0.766771 0.971127 0.338521 0.491933 0.0238781 0.26887 0.619899 0.363298 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 137728 episodes
GETTING ACTION FROM:
action 3, numVisits=137713, meanQ=12.687884, numObservations: 9
action 5, numVisits=8, meanQ=5.747512, numObservations: 5
action 4, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.719483 0.595214 0.766771 0.971127 0.338521 0.491933 0.0238781 0.26887 0.619899 0.363298 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=1109, meanQ=13.893795, numObservations: 9
action 1, numVisits=13, meanQ=11.228469, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 150443 episodes
GETTING ACTION FROM:
action 4, numVisits=151550, meanQ=17.592508, numObservations: 9
action 1, numVisits=13, meanQ=11.228469, numObservations: 7
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 0 0.719483 0.595214 0.766771 0.971127 0.338521 0.491933 0.0238781 0.26887 0.619899 0.363298 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=880, meanQ=17.625110, numObservations: 9
action 2, numVisits=219, meanQ=11.975925, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 170844 episodes
GETTING ACTION FROM:
action 1, numVisits=171722, meanQ=14.081746, numObservations: 9
action 2, numVisits=219, meanQ=11.975925, numObservations: 9
action -1, numVisits=3, meanQ=-1.340000, numObservations: 3
action 0, numVisits=3, meanQ=-1.340000, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.719483 0.595214 0.766771 0.971127 0.338521 0.491933 0.0238781 0.26887 0.619899 0.363298 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 30
Initial state: 0 0.561249 0.341363 0.840491 0.729848 0.279134 0.185424 0.0569672 0.660446 0.587409 0.256404 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 139557 episodes
GETTING ACTION FROM:
action 4, numVisits=139546, meanQ=12.537442, numObservations: 9
action 1, numVisits=6, meanQ=9.668350, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 0 0.561249 0.341363 0.840491 0.729848 0.279134 0.185424 0.0569672 0.660446 0.587409 0.256404 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=21793, meanQ=13.737247, numObservations: 9
action 1, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 46058 episodes
GETTING ACTION FROM:
action 2, numVisits=67817, meanQ=15.089524, numObservations: 9
action 5, numVisits=32, meanQ=9.086143, numObservations: 9
action 1, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.561249 0.341363 0.840491 0.729848 0.279134 0.185424 0.0569672 0.660446 0.587409 0.256404 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 31
Initial state: 0 0.54041 0.310645 0.568807 0.37071 0.10386 0.75605 0.202565 0.628528 0.116629 0.544406 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 138534 episodes
GETTING ACTION FROM:
action 4, numVisits=138524, meanQ=12.590923, numObservations: 9
action 1, numVisits=5, meanQ=6.196000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 1 0.54041 0.310645 0.568807 0.37071 0.10386 0.75605 0.202565 0.628528 0.116629 0.544406 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 32
Initial state: 0 0.00172409 0.136792 0.753176 0.94231 0.590698 0.345152 0.195727 0.707094 0.779574 0.182524 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 139411 episodes
GETTING ACTION FROM:
action 4, numVisits=139380, meanQ=12.693995, numObservations: 9
action 3, numVisits=13, meanQ=10.384631, numObservations: 7
action 5, numVisits=14, meanQ=9.362864, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 0 0.00172409 0.136792 0.753176 0.94231 0.590698 0.345152 0.195727 0.707094 0.779574 0.182524 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=21721, meanQ=13.676025, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 50388 episodes
GETTING ACTION FROM:
action 3, numVisits=72107, meanQ=14.777648, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.00172409 0.136792 0.753176 0.94231 0.590698 0.345152 0.195727 0.707094 0.779574 0.182524 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 33
Initial state: 0 0.13401 0.832497 0.186281 0.331658 0.979327 0.808148 0.563595 0.379211 0.202828 0.507763 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 137642 episodes
GETTING ACTION FROM:
action 5, numVisits=137619, meanQ=12.674848, numObservations: 9
action 3, numVisits=10, meanQ=9.199020, numObservations: 4
action 2, numVisits=6, meanQ=8.350000, numObservations: 4
action 1, numVisits=4, meanQ=8.250000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 0 0.13401 0.832497 0.186281 0.331658 0.979327 0.808148 0.563595 0.379211 0.202828 0.507763 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=21666, meanQ=13.576222, numObservations: 9
action 4, numVisits=5, meanQ=4.598000, numObservations: 4
action 1, numVisits=5, meanQ=3.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 48346 episodes
GETTING ACTION FROM:
action 2, numVisits=69988, meanQ=14.979376, numObservations: 9
action 1, numVisits=5, meanQ=3.000000, numObservations: 4
action -1, numVisits=6, meanQ=-1.505000, numObservations: 5
action 0, numVisits=6, meanQ=-1.505000, numObservations: 6
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=19, meanQ=-44.365532, numObservations: 7
action: 2
Next state: 2 0.13401 0.832497 0.186281 0.331658 0.979327 0.808148 0.563595 0.379211 0.202828 0.507763 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 34
Initial state: 0 0.92145 0.74047 0.341078 0.166229 0.836747 0.193975 0.950072 0.125905 0.559638 0.33553 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 139916 episodes
GETTING ACTION FROM:
action 2, numVisits=139904, meanQ=12.750231, numObservations: 9
action 5, numVisits=6, meanQ=8.998333, numObservations: 5
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.92145 0.74047 0.341078 0.166229 0.836747 0.193975 0.950072 0.125905 0.559638 0.33553 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=4708, meanQ=13.129921, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 34127 episodes
GETTING ACTION FROM:
action 3, numVisits=38821, meanQ=12.553768, numObservations: 9
action 0, numVisits=9, meanQ=-1.340000, numObservations: 8
action -1, numVisits=7, meanQ=-1.434286, numObservations: 7
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.92145 0.74047 0.341078 0.166229 0.836747 0.193975 0.950072 0.125905 0.559638 0.33553 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=243, meanQ=7.494198, numObservations: 9
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=119, meanQ=-6.128268, numObservations: 55
action 3, numVisits=2, meanQ=-7.005000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=25, meanQ=-43.377017, numObservations: 20
Sampled 134453 episodes
GETTING ACTION FROM:
action 4, numVisits=133790, meanQ=9.889237, numObservations: 9
action 5, numVisits=907, meanQ=7.654136, numObservations: 9
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=119, meanQ=-6.128268, numObservations: 55
action 3, numVisits=2, meanQ=-7.005000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=25, meanQ=-43.377017, numObservations: 20
action: 4
Next state: 2 0.92145 0.74047 0.341078 0.166229 0.836747 0.193975 0.950072 0.125905 0.559638 0.33553 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -18.7411
Run # 35
Initial state: 0 0.318542 0.949867 0.422046 0.716928 0.85701 0.756736 0.207891 0.248361 0.561434 0.415244 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 137991 episodes
GETTING ACTION FROM:
action 1, numVisits=137977, meanQ=12.728185, numObservations: 9
action 3, numVisits=6, meanQ=9.623333, numObservations: 4
action 4, numVisits=4, meanQ=8.497500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.318542 0.949867 0.422046 0.716928 0.85701 0.756736 0.207891 0.248361 0.561434 0.415244 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=21812, meanQ=13.517580, numObservations: 9
action 1, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 54856 episodes
GETTING ACTION FROM:
action 4, numVisits=76666, meanQ=14.299367, numObservations: 9
action 1, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.318542 0.949867 0.422046 0.716928 0.85701 0.756736 0.207891 0.248361 0.561434 0.415244 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=690, meanQ=13.302498, numObservations: 8
action 5, numVisits=841, meanQ=11.479973, numObservations: 9
action 3, numVisits=4, meanQ=1.841523, numObservations: 4
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=25, meanQ=-28.100993, numObservations: 7
Sampled 39059 episodes
GETTING ACTION FROM:
action 5, numVisits=39894, meanQ=14.745533, numObservations: 9
action 1, numVisits=694, meanQ=13.345076, numObservations: 8
action 3, numVisits=4, meanQ=1.841523, numObservations: 4
action -1, numVisits=5, meanQ=-1.208000, numObservations: 4
action 0, numVisits=5, meanQ=-1.208000, numObservations: 5
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=25, meanQ=-28.100993, numObservations: 7
action: 5
Next state: 1 0.318542 0.949867 0.422046 0.716928 0.85701 0.756736 0.207891 0.248361 0.561434 0.415244 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 36
Initial state: 0 0.416227 0.384898 0.164134 0.465292 0.120024 0.629349 0.547932 0.395008 0.934937 0.251601 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 138649 episodes
GETTING ACTION FROM:
action 1, numVisits=138628, meanQ=12.597671, numObservations: 9
action 5, numVisits=16, meanQ=9.969375, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.416227 0.384898 0.164134 0.465292 0.120024 0.629349 0.547932 0.395008 0.934937 0.251601 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 37
Initial state: 0 0.966692 0.585291 0.898233 0.765461 0.529352 0.319006 0.47478 0.419567 0.880505 0.0612631 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 139818 episodes
GETTING ACTION FROM:
action 4, numVisits=139807, meanQ=12.777461, numObservations: 9
action 2, numVisits=6, meanQ=2.833350, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.966692 0.585291 0.898233 0.765461 0.529352 0.319006 0.47478 0.419567 0.880505 0.0612631 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=16426, meanQ=13.731683, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 35578 episodes
GETTING ACTION FROM:
action 2, numVisits=52002, meanQ=12.916051, numObservations: 9
action -1, numVisits=3, meanQ=-1.340000, numObservations: 3
action 0, numVisits=3, meanQ=-1.340000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.966692 0.585291 0.898233 0.765461 0.529352 0.319006 0.47478 0.419567 0.880505 0.0612631 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 38
Initial state: 0 0.0899795 0.472089 0.934359 0.958897 0.543033 0.41785 0.526221 0.522184 0.979716 0.806193 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 140194 episodes
GETTING ACTION FROM:
action 3, numVisits=140177, meanQ=12.665378, numObservations: 9
action 1, numVisits=10, meanQ=7.151000, numObservations: 5
action 2, numVisits=3, meanQ=5.663333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.0899795 0.472089 0.934359 0.958897 0.543033 0.41785 0.526221 0.522184 0.979716 0.806193 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 39
Initial state: 0 0.552388 0.433151 0.695661 0.892467 0.731772 0.323345 0.677629 0.646166 0.118961 0.968592 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 137315 episodes
GETTING ACTION FROM:
action 1, numVisits=137305, meanQ=12.831604, numObservations: 9
action 2, numVisits=5, meanQ=5.998000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.552388 0.433151 0.695661 0.892467 0.731772 0.323345 0.677629 0.646166 0.118961 0.968592 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 40
Initial state: 0 0.329848 0.353061 0.00163242 0.127851 0.841399 0.76151 0.550784 0.430953 0.0502974 0.776978 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 139013 episodes
GETTING ACTION FROM:
action 1, numVisits=139001, meanQ=12.791072, numObservations: 9
action 3, numVisits=7, meanQ=7.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.329848 0.353061 0.00163242 0.127851 0.841399 0.76151 0.550784 0.430953 0.0502974 0.776978 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 41
Initial state: 0 0.80205 0.892997 0.565856 0.379897 0.210822 0.634722 0.571007 0.0371442 0.343844 0.562866 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 138006 episodes
GETTING ACTION FROM:
action 4, numVisits=137992, meanQ=12.660547, numObservations: 9
action 3, numVisits=4, meanQ=8.250000, numObservations: 4
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action 5, numVisits=5, meanQ=5.998000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 2 0.80205 0.892997 0.565856 0.379897 0.210822 0.634722 0.571007 0.0371442 0.343844 0.562866 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 42
Initial state: 0 0.152589 0.96567 0.603798 0.39417 0.193897 0.305355 0.20169 0.638283 0.96809 0.858838 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 138650 episodes
GETTING ACTION FROM:
action 2, numVisits=138636, meanQ=12.661449, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 1, numVisits=5, meanQ=-1.200000, numObservations: 5
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.152589 0.96567 0.603798 0.39417 0.193897 0.305355 0.20169 0.638283 0.96809 0.858838 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 43
Initial state: 0 0.894877 0.400012 0.168083 0.58426 0.896346 0.275983 0.539109 0.381362 0.12962 0.820713 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 139231 episodes
GETTING ACTION FROM:
action 4, numVisits=139222, meanQ=12.565414, numObservations: 9
action 5, numVisits=4, meanQ=1.497500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.894877 0.400012 0.168083 0.58426 0.896346 0.275983 0.539109 0.381362 0.12962 0.820713 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 44
Initial state: 0 0.4784 0.590156 0.4107 0.850792 0.869175 0.952495 0.222461 0.429444 0.547581 0.402566 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 138166 episodes
GETTING ACTION FROM:
action 5, numVisits=138155, meanQ=12.475166, numObservations: 9
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action 4, numVisits=3, meanQ=5.663333, numObservations: 3
action 1, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 1 0.4784 0.590156 0.4107 0.850792 0.869175 0.952495 0.222461 0.429444 0.547581 0.402566 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 45
Initial state: 0 0.640553 0.0947551 0.815963 0.782748 0.534791 0.36679 0.341031 0.511263 0.408306 0.0302746 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 137735 episodes
GETTING ACTION FROM:
action 3, numVisits=137706, meanQ=12.596555, numObservations: 9
action 2, numVisits=20, meanQ=6.305005, numObservations: 7
action 5, numVisits=5, meanQ=5.204020, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.640553 0.0947551 0.815963 0.782748 0.534791 0.36679 0.341031 0.511263 0.408306 0.0302746 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 46
Initial state: 0 0.503204 0.434177 0.614146 0.380183 0.251517 0.543951 0.178128 0.793806 0.317464 0.549153 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 140045 episodes
GETTING ACTION FROM:
action 1, numVisits=140014, meanQ=12.707756, numObservations: 9
action 5, numVisits=15, meanQ=7.265340, numObservations: 6
action 3, numVisits=10, meanQ=7.199010, numObservations: 6
action 4, numVisits=3, meanQ=5.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.503204 0.434177 0.614146 0.380183 0.251517 0.543951 0.178128 0.793806 0.317464 0.549153 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 47
Initial state: 0 0.114611 0.891728 0.535043 0.547676 0.621529 0.375993 0.0557224 0.222843 0.839719 0.26925 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 138046 episodes
GETTING ACTION FROM:
action 4, numVisits=138031, meanQ=12.826635, numObservations: 9
action 2, numVisits=10, meanQ=9.173000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 0 0.114611 0.891728 0.535043 0.547676 0.621529 0.375993 0.0557224 0.222843 0.839719 0.26925 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=1786, meanQ=12.936699, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 61486 episodes
GETTING ACTION FROM:
action 3, numVisits=63253, meanQ=10.496275, numObservations: 9
action 0, numVisits=12, meanQ=-1.422500, numObservations: 12
action -1, numVisits=11, meanQ=-1.460000, numObservations: 11
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.114611 0.891728 0.535043 0.547676 0.621529 0.375993 0.0557224 0.222843 0.839719 0.26925 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 48
Initial state: 0 0.121264 0.875908 0.59847 0.397035 0.874421 0.744679 0.456348 0.602224 0.770608 0.268111 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 137382 episodes
GETTING ACTION FROM:
action 1, numVisits=137357, meanQ=12.781837, numObservations: 9
action 3, numVisits=18, meanQ=8.959444, numObservations: 9
action 2, numVisits=3, meanQ=5.663333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.121264 0.875908 0.59847 0.397035 0.874421 0.744679 0.456348 0.602224 0.770608 0.268111 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=21575, meanQ=13.605409, numObservations: 9
action 1, numVisits=10, meanQ=6.602040, numObservations: 2
action 2, numVisits=3, meanQ=5.993333, numObservations: 3
action 3, numVisits=3, meanQ=4.670033, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 44106 episodes
GETTING ACTION FROM:
action 4, numVisits=65677, meanQ=15.189773, numObservations: 9
action 1, numVisits=10, meanQ=6.602040, numObservations: 2
action 3, numVisits=3, meanQ=4.670033, numObservations: 1
action 2, numVisits=4, meanQ=1.745000, numObservations: 4
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 0 0.121264 0.875908 0.59847 0.397035 0.874421 0.744679 0.456348 0.602224 0.770608 0.268111 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=4169, meanQ=19.745712, numObservations: 9
action 1, numVisits=3179, meanQ=14.083248, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=3, meanQ=-1.673300, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 32459 episodes
GETTING ACTION FROM:
action 4, numVisits=4172, meanQ=19.747755, numObservations: 9
action 5, numVisits=32337, meanQ=17.794962, numObservations: 9
action 1, numVisits=3179, meanQ=14.083248, numObservations: 9
action 0, numVisits=100, meanQ=-4.442531, numObservations: 47
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=25, meanQ=-21.777956, numObservations: 21
action 3, numVisits=6, meanQ=-86.932185, numObservations: 4
action: 4
Next state: 0 0.121264 0.875908 0.59847 0.397035 0.874421 0.744679 0.456348 0.602224 0.770608 0.268111 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=1, meanQ=24.000000, numObservations: 1
action 2, numVisits=2189, meanQ=15.382328, numObservations: 9
action 4, numVisits=1, meanQ=-9.954295, numObservations: 1
action 3, numVisits=1, meanQ=-10.411843, numObservations: 1
action 5, numVisits=1, meanQ=-11.157150, numObservations: 1
action 0, numVisits=26, meanQ=-39.534680, numObservations: 20
action -1, numVisits=26, meanQ=-40.892114, numObservations: 17
Sampled 54385 episodes
GETTING ACTION FROM:
action 1, numVisits=24, meanQ=21.625004, numObservations: 5
action 2, numVisits=56551, meanQ=18.523978, numObservations: 9
action 4, numVisits=1, meanQ=-9.954295, numObservations: 1
action 3, numVisits=1, meanQ=-10.411843, numObservations: 1
action 5, numVisits=1, meanQ=-11.157150, numObservations: 1
action 0, numVisits=26, meanQ=-39.534680, numObservations: 20
action -1, numVisits=26, meanQ=-40.892114, numObservations: 17
action: 1
Next state: 1 0.121264 0.875908 0.59847 0.397035 0.874421 0.744679 0.456348 0.602224 0.770608 0.268111 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 11.4068
Run # 49
Initial state: 0 0.917976 0.160831 0.585695 0.34004 0.662546 0.81752 0.301642 0.877644 0.296277 0.00034246 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 139526 episodes
GETTING ACTION FROM:
action 1, numVisits=139511, meanQ=12.714443, numObservations: 9
action 5, numVisits=6, meanQ=8.185000, numObservations: 5
action 4, numVisits=4, meanQ=7.277500, numObservations: 3
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.917976 0.160831 0.585695 0.34004 0.662546 0.81752 0.301642 0.877644 0.296277 0.00034246 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 50
Initial state: 0 0.955806 0.212174 0.5779 0.363157 0.556258 0.923789 0.308609 0.930175 0.949234 0.378271 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 139517 episodes
GETTING ACTION FROM:
action 5, numVisits=139501, meanQ=12.559964, numObservations: 9
action 4, numVisits=9, meanQ=8.774444, numObservations: 6
action 2, numVisits=3, meanQ=4.340033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.955806 0.212174 0.5779 0.363157 0.556258 0.923789 0.308609 0.930175 0.949234 0.378271 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
[32m ProblemEnvironment.hpp 351: Done.[39m
