Run # 1
Initial state: 0 0.267061 0.0335873 0.762081 0.888601 0.206213 0.201882 0.520735 0.145273 0.641845 0.311083 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 130239 episodes
GETTING ACTION FROM:
action 4, numVisits=130224, meanQ=12.352867, numObservations: 9
action 5, numVisits=4, meanQ=8.250000, numObservations: 4
action 1, numVisits=5, meanQ=6.802020, numObservations: 4
action 2, numVisits=3, meanQ=5.663333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 2 0.267061 0.0335873 0.762081 0.888601 0.206213 0.201882 0.520735 0.145273 0.641845 0.311083 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 2
Initial state: 0 0.679925 0.482876 0.361604 0.076311 0.658442 0.456305 0.430856 0.427159 0.736413 0.23977 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 137729 episodes
GETTING ACTION FROM:
action 5, numVisits=137686, meanQ=12.398748, numObservations: 9
action 0, numVisits=20, meanQ=-1.010000, numObservations: 20
action -1, numVisits=15, meanQ=-1.142660, numObservations: 14
action 1, numVisits=2, meanQ=-4.000000, numObservations: 2
action 3, numVisits=2, meanQ=-4.000000, numObservations: 2
action 2, numVisits=2, meanQ=-7.500000, numObservations: 2
action 4, numVisits=2, meanQ=-9.445000, numObservations: 1
action: 5
Next state: 0 0.679925 0.482876 0.361604 0.076311 0.658442 0.456305 0.430856 0.427159 0.736413 0.23977 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=1580, meanQ=12.708245, numObservations: 9
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action 4, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 130353 episodes
GETTING ACTION FROM:
action 3, numVisits=131884, meanQ=9.705943, numObservations: 9
action 1, numVisits=44, meanQ=8.409091, numObservations: 9
action 4, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=4, meanQ=-1.752500, numObservations: 4
action 0, numVisits=4, meanQ=-1.752500, numObservations: 4
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.679925 0.482876 0.361604 0.076311 0.658442 0.456305 0.430856 0.427159 0.736413 0.23977 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 3
Initial state: 0 0.141675 0.589528 0.49641 0.0745657 0.797139 0.099827 0.628361 0.487222 0.725735 0.512728 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 139869 episodes
GETTING ACTION FROM:
action 4, numVisits=139861, meanQ=12.470144, numObservations: 9
action 1, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.141675 0.589528 0.49641 0.0745657 0.797139 0.099827 0.628361 0.487222 0.725735 0.512728 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 4
Initial state: 0 0.80788 0.707371 0.062812 0.72413 0.371589 0.701239 0.490797 0.421612 0.90163 0.24859 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 137777 episodes
GETTING ACTION FROM:
action 4, numVisits=137228, meanQ=12.375345, numObservations: 9
action 3, numVisits=539, meanQ=11.172999, numObservations: 9
action 1, numVisits=6, meanQ=7.831667, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.80788 0.707371 0.062812 0.72413 0.371589 0.701239 0.490797 0.421612 0.90163 0.24859 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 5
Initial state: 0 0.851121 0.0269129 0.472765 0.86684 0.593406 0.404075 0.197473 0.596476 0.599181 0.231168 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 138062 episodes
GETTING ACTION FROM:
action 2, numVisits=138054, meanQ=12.452083, numObservations: 9
action 3, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.851121 0.0269129 0.472765 0.86684 0.593406 0.404075 0.197473 0.596476 0.599181 0.231168 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 6
Initial state: 0 0.841868 0.120899 0.737034 0.125713 0.552252 0.306705 0.864884 0.752686 0.948746 0.247182 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 138784 episodes
GETTING ACTION FROM:
action 3, numVisits=138757, meanQ=12.351597, numObservations: 9
action 5, numVisits=16, meanQ=10.031250, numObservations: 8
action 2, numVisits=5, meanQ=5.800000, numObservations: 4
action 4, numVisits=3, meanQ=5.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.841868 0.120899 0.737034 0.125713 0.552252 0.306705 0.864884 0.752686 0.948746 0.247182 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=2356, meanQ=18.796682, numObservations: 9
action 2, numVisits=3, meanQ=12.333333, numObservations: 3
action 4, numVisits=3, meanQ=12.333333, numObservations: 3
action 5, numVisits=5, meanQ=11.598000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 128447 episodes
GETTING ACTION FROM:
action 3, numVisits=2428, meanQ=18.872608, numObservations: 9
action 2, numVisits=128335, meanQ=16.674429, numObservations: 9
action 4, numVisits=43, meanQ=13.401214, numObservations: 9
action 5, numVisits=6, meanQ=7.831667, numObservations: 6
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.841868 0.120899 0.737034 0.125713 0.552252 0.306705 0.864884 0.752686 0.948746 0.247182 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 7
Initial state: 0 0.505032 0.399951 0.279742 0.298256 0.0247479 0.646128 0.775686 0.5296 0.0507266 0.175813 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 125854 episodes
GETTING ACTION FROM:
action 1, numVisits=125845, meanQ=12.631906, numObservations: 9
action 2, numVisits=4, meanQ=1.250000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.505032 0.399951 0.279742 0.298256 0.0247479 0.646128 0.775686 0.5296 0.0507266 0.175813 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 8
Initial state: 0 0.0439849 0.252751 0.0417878 0.926497 0.0478957 0.27885 0.99107 0.104593 0.64829 0.401005 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 139538 episodes
GETTING ACTION FROM:
action 5, numVisits=139523, meanQ=12.336306, numObservations: 9
action 4, numVisits=8, meanQ=0.373762, numObservations: 5
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 1 0.0439849 0.252751 0.0417878 0.926497 0.0478957 0.27885 0.99107 0.104593 0.64829 0.401005 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 9
Initial state: 0 0.583457 0.936853 0.00943151 0.141425 0.781966 0.206359 0.585029 0.38573 0.163597 0.678744 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 133386 episodes
GETTING ACTION FROM:
action 5, numVisits=133377, meanQ=12.192905, numObservations: 9
action 3, numVisits=4, meanQ=6.500000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 1 0.583457 0.936853 0.00943151 0.141425 0.781966 0.206359 0.585029 0.38573 0.163597 0.678744 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 10
Initial state: 0 0.602578 0.342562 0.413905 0.91541 0.108896 0.610283 0.176287 0.187299 0.319398 0.568053 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 139300 episodes
GETTING ACTION FROM:
action 3, numVisits=139275, meanQ=12.445436, numObservations: 9
action 5, numVisits=16, meanQ=10.312513, numObservations: 7
action 2, numVisits=4, meanQ=8.250000, numObservations: 4
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.602578 0.342562 0.413905 0.91541 0.108896 0.610283 0.176287 0.187299 0.319398 0.568053 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 11
Initial state: 0 0.867155 0.0876297 0.827028 0.52022 0.414212 0.15512 0.0867925 0.743038 0.603889 0.31366 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 139255 episodes
GETTING ACTION FROM:
action 5, numVisits=139248, meanQ=12.343498, numObservations: 9
action 4, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 1 0.867155 0.0876297 0.827028 0.52022 0.414212 0.15512 0.0867925 0.743038 0.603889 0.31366 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 12
Initial state: 0 0.759218 0.249214 0.73189 0.932239 0.461199 0.0870806 0.499703 0.336902 0.17868 0.601373 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 127678 episodes
GETTING ACTION FROM:
action 3, numVisits=127670, meanQ=12.444199, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.759218 0.249214 0.73189 0.932239 0.461199 0.0870806 0.499703 0.336902 0.17868 0.601373 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=19020, meanQ=13.234619, numObservations: 9
action 4, numVisits=11, meanQ=9.543636, numObservations: 6
action 1, numVisits=4, meanQ=8.497500, numObservations: 3
action 5, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 46353 episodes
GETTING ACTION FROM:
action 4, numVisits=46360, meanQ=15.965674, numObservations: 9
action 3, numVisits=19020, meanQ=13.234619, numObservations: 9
action 1, numVisits=5, meanQ=4.598000, numObservations: 4
action 5, numVisits=4, meanQ=2.577499, numObservations: 4
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.759218 0.249214 0.73189 0.932239 0.461199 0.0870806 0.499703 0.336902 0.17868 0.601373 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 13
Initial state: 0 0.0954515 0.576122 0.503509 0.338084 0.397955 0.55007 0.974399 0.733585 0.236354 0.851076 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 138863 episodes
GETTING ACTION FROM:
action 4, numVisits=138857, meanQ=12.465803, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.0954515 0.576122 0.503509 0.338084 0.397955 0.55007 0.974399 0.733585 0.236354 0.851076 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 14
Initial state: 0 0.186442 0.985278 0.845725 0.654738 0.630697 0.369739 0.90183 0.583545 0.817565 0.0581485 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 140068 episodes
GETTING ACTION FROM:
action 3, numVisits=140054, meanQ=12.466119, numObservations: 9
action 2, numVisits=7, meanQ=6.998586, numObservations: 5
action 1, numVisits=3, meanQ=5.663333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.186442 0.985278 0.845725 0.654738 0.630697 0.369739 0.90183 0.583545 0.817565 0.0581485 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 15
Initial state: 0 0.70057 0.972756 0.559643 0.482724 0.701444 0.744036 0.481027 0.90227 0.316865 0.274807 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 139867 episodes
GETTING ACTION FROM:
action 3, numVisits=139857, meanQ=12.402137, numObservations: 9
action 2, numVisits=3, meanQ=5.333333, numObservations: 2
action 4, numVisits=3, meanQ=5.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.70057 0.972756 0.559643 0.482724 0.701444 0.744036 0.481027 0.90227 0.316865 0.274807 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 16
Initial state: 0 0.729784 0.258461 0.568819 0.317445 0.476876 0.393579 0.346251 0.958551 0.622379 0.531592 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 138520 episodes
GETTING ACTION FROM:
action 4, numVisits=138513, meanQ=12.305329, numObservations: 9
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 0 0.729784 0.258461 0.568819 0.317445 0.476876 0.393579 0.346251 0.958551 0.622379 0.531592 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=20573, meanQ=13.353508, numObservations: 9
action 3, numVisits=6, meanQ=1.998333, numObservations: 4
action 5, numVisits=6, meanQ=1.491667, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 42533 episodes
GETTING ACTION FROM:
action 2, numVisits=63070, meanQ=14.327230, numObservations: 9
action 3, numVisits=6, meanQ=1.998333, numObservations: 4
action 5, numVisits=6, meanQ=1.491667, numObservations: 5
action 0, numVisits=27, meanQ=-0.497033, numObservations: 24
action -1, numVisits=10, meanQ=-1.307000, numObservations: 9
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=2, meanQ=-10.493384, numObservations: 1
action: 2
Next state: 1 0.729784 0.258461 0.568819 0.317445 0.476876 0.393579 0.346251 0.958551 0.622379 0.531592 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 17
Initial state: 0 0.893157 0.905512 0.814799 0.399447 0.48719 0.450859 0.924117 0.780534 0.505796 0.803792 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 133075 episodes
GETTING ACTION FROM:
action 3, numVisits=133063, meanQ=12.458408, numObservations: 9
action 4, numVisits=5, meanQ=7.200000, numObservations: 5
action 2, numVisits=3, meanQ=5.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.893157 0.905512 0.814799 0.399447 0.48719 0.450859 0.924117 0.780534 0.505796 0.803792 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1627, meanQ=13.232425, numObservations: 9
action 4, numVisits=2, meanQ=6.500000, numObservations: 2
action 3, numVisits=3, meanQ=5.993333, numObservations: 2
action 5, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 83338 episodes
GETTING ACTION FROM:
action 5, numVisits=83334, meanQ=15.661520, numObservations: 9
action 2, numVisits=1629, meanQ=13.237497, numObservations: 9
action 3, numVisits=3, meanQ=5.993333, numObservations: 2
action 4, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=3, meanQ=-1.670000, numObservations: 3
action 0, numVisits=3, meanQ=-1.670000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 1 0.893157 0.905512 0.814799 0.399447 0.48719 0.450859 0.924117 0.780534 0.505796 0.803792 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 18
Initial state: 0 0.887042 0.993598 0.654226 0.375987 0.810709 0.547798 0.123533 0.221096 0.208231 0.616585 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 140060 episodes
GETTING ACTION FROM:
action 2, numVisits=140043, meanQ=12.435795, numObservations: 9
action 1, numVisits=10, meanQ=4.400000, numObservations: 6
action 3, numVisits=3, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.887042 0.993598 0.654226 0.375987 0.810709 0.547798 0.123533 0.221096 0.208231 0.616585 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 19
Initial state: 0 0.653443 0.452131 0.932173 0.852265 0.370367 0.565093 0.152614 0.774496 0.556602 0.20523 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 138914 episodes
GETTING ACTION FROM:
action 3, numVisits=138902, meanQ=12.359236, numObservations: 9
action 1, numVisits=7, meanQ=2.431457, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.653443 0.452131 0.932173 0.852265 0.370367 0.565093 0.152614 0.774496 0.556602 0.20523 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=459, meanQ=11.602648, numObservations: 9
action 4, numVisits=5, meanQ=6.196000, numObservations: 4
action 5, numVisits=3, meanQ=0.666667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 120784 episodes
GETTING ACTION FROM:
action 1, numVisits=121239, meanQ=14.911656, numObservations: 9
action 4, numVisits=5, meanQ=6.196000, numObservations: 4
action 5, numVisits=3, meanQ=0.666667, numObservations: 1
action -1, numVisits=3, meanQ=-1.670000, numObservations: 3
action 0, numVisits=3, meanQ=-1.670000, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.653443 0.452131 0.932173 0.852265 0.370367 0.565093 0.152614 0.774496 0.556602 0.20523 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=101, meanQ=9.912215, numObservations: 9
action 2, numVisits=3, meanQ=-0.012501, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=3, meanQ=-4.970000, numObservations: 2
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=47, meanQ=-22.273637, numObservations: 37
action 3, numVisits=1, meanQ=-1056.068548, numObservations: 1
Sampled 145974 episodes
GETTING ACTION FROM:
action 5, numVisits=146075, meanQ=11.354298, numObservations: 9
action 2, numVisits=3, meanQ=-0.012501, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=3, meanQ=-4.970000, numObservations: 2
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=47, meanQ=-22.273637, numObservations: 37
action 3, numVisits=1, meanQ=-1056.068548, numObservations: 1
action: 5
Next state: 0 0.653443 0.452131 0.932173 0.852265 0.370367 0.565093 0.152614 0.774496 0.556602 0.20523 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 0, numVisits=10, meanQ=1.068010, numObservations: 8
action -1, numVisits=2, meanQ=-6.815227, numObservations: 1
action 5, numVisits=1, meanQ=-10.731362, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.695972, numObservations: 1
action 4, numVisits=16, meanQ=-20.018186, numObservations: 6
action 3, numVisits=1, meanQ=-536.521538, numObservations: 1
Sampled 217837 episodes
GETTING ACTION FROM:
action 2, numVisits=217507, meanQ=11.727804, numObservations: 9
action 0, numVisits=86, meanQ=-1.643255, numObservations: 48
action 1, numVisits=255, meanQ=-2.627451, numObservations: 9
action -1, numVisits=2, meanQ=-6.815227, numObservations: 1
action 5, numVisits=2, meanQ=-10.865681, numObservations: 2
action 4, numVisits=16, meanQ=-20.018186, numObservations: 6
action 3, numVisits=1, meanQ=-536.521538, numObservations: 1
action: 2
Next state: 1 0.653443 0.452131 0.932173 0.852265 0.370367 0.565093 0.152614 0.774496 0.556602 0.20523 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 11.4068
Run # 20
Initial state: 0 0.58622 0.325377 0.940289 0.937488 0.0335827 0.584363 0.19485 0.486242 0.401153 0.904374 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 138390 episodes
GETTING ACTION FROM:
action 4, numVisits=138382, meanQ=12.477974, numObservations: 9
action 1, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 0 0.58622 0.325377 0.940289 0.937488 0.0335827 0.584363 0.19485 0.486242 0.401153 0.904374 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=5720, meanQ=12.709226, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 32358 episodes
GETTING ACTION FROM:
action 3, numVisits=38060, meanQ=12.360278, numObservations: 9
action -1, numVisits=10, meanQ=-1.307000, numObservations: 10
action 0, numVisits=10, meanQ=-1.406000, numObservations: 10
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.58622 0.325377 0.940289 0.937488 0.0335827 0.584363 0.19485 0.486242 0.401153 0.904374 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 21
Initial state: 0 0.89101 0.489966 0.258012 0.223114 0.74935 0.119171 0.661515 0.481871 0.168856 0.0983722 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 138178 episodes
GETTING ACTION FROM:
action 4, numVisits=138132, meanQ=12.463077, numObservations: 9
action -1, numVisits=18, meanQ=-1.010000, numObservations: 18
action 0, numVisits=18, meanQ=-1.230550, numObservations: 17
action 3, numVisits=5, meanQ=-2.600000, numObservations: 4
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=2, meanQ=-4.499950, numObservations: 1
action 2, numVisits=2, meanQ=-7.500000, numObservations: 2
action: 4
Next state: 1 0.89101 0.489966 0.258012 0.223114 0.74935 0.119171 0.661515 0.481871 0.168856 0.0983722 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 22
Initial state: 0 0.204739 0.76439 0.866597 0.908453 0.534652 0.391089 0.157133 0.785431 0.783591 0.215265 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 139316 episodes
GETTING ACTION FROM:
action 2, numVisits=139306, meanQ=12.351782, numObservations: 9
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action 3, numVisits=3, meanQ=5.000033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.204739 0.76439 0.866597 0.908453 0.534652 0.391089 0.157133 0.785431 0.783591 0.215265 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 23
Initial state: 0 0.797061 0.635497 0.582229 0.474075 0.280153 0.470192 0.281642 0.213224 0.73763 0.16527 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 139269 episodes
GETTING ACTION FROM:
action 1, numVisits=139250, meanQ=12.416869, numObservations: 9
action 5, numVisits=7, meanQ=5.000000, numObservations: 5
action 2, numVisits=8, meanQ=4.377512, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.797061 0.635497 0.582229 0.474075 0.280153 0.470192 0.281642 0.213224 0.73763 0.16527 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 24
Initial state: 0 0.636687 0.304882 0.0767448 0.906931 0.224384 0.950258 0.69691 0.374822 0.63536 0.738294 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 139215 episodes
GETTING ACTION FROM:
action 1, numVisits=139195, meanQ=12.565363, numObservations: 9
action 2, numVisits=15, meanQ=5.732680, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.636687 0.304882 0.0767448 0.906931 0.224384 0.950258 0.69691 0.374822 0.63536 0.738294 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 25
Initial state: 0 0.246774 0.0216945 0.110715 0.638503 0.488529 0.312771 0.108478 0.415714 0.768251 0.0687502 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 130047 episodes
GETTING ACTION FROM:
action 1, numVisits=130032, meanQ=12.429765, numObservations: 9
action 3, numVisits=6, meanQ=5.333333, numObservations: 6
action 2, numVisits=5, meanQ=4.400000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.246774 0.0216945 0.110715 0.638503 0.488529 0.312771 0.108478 0.415714 0.768251 0.0687502 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=18970, meanQ=13.590522, numObservations: 9
action 4, numVisits=12, meanQ=7.507500, numObservations: 4
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 49238 episodes
GETTING ACTION FROM:
action 4, numVisits=49240, meanQ=16.152304, numObservations: 9
action 1, numVisits=18971, meanQ=13.590314, numObservations: 9
action 2, numVisits=8, meanQ=4.128195, numObservations: 6
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.340000, numObservations: 3
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.246774 0.0216945 0.110715 0.638503 0.488529 0.312771 0.108478 0.415714 0.768251 0.0687502 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=1152, meanQ=11.494100, numObservations: 9
action 2, numVisits=11, meanQ=1.628203, numObservations: 7
action 0, numVisits=11, meanQ=-2.050811, numObservations: 10
action 4, numVisits=1, meanQ=-9.220479, numObservations: 1
action 5, numVisits=1, meanQ=-9.232964, numObservations: 1
action -1, numVisits=51, meanQ=-17.650429, numObservations: 27
action 1, numVisits=1, meanQ=-1067.214848, numObservations: 1
Sampled 26907 episodes
GETTING ACTION FROM:
action 3, numVisits=28059, meanQ=15.693146, numObservations: 9
action 2, numVisits=11, meanQ=1.628203, numObservations: 7
action 0, numVisits=11, meanQ=-2.050811, numObservations: 10
action 4, numVisits=1, meanQ=-9.220479, numObservations: 1
action 5, numVisits=1, meanQ=-9.232964, numObservations: 1
action -1, numVisits=51, meanQ=-17.650429, numObservations: 27
action 1, numVisits=1, meanQ=-1067.214848, numObservations: 1
action: 3
Next state: 1 0.246774 0.0216945 0.110715 0.638503 0.488529 0.312771 0.108478 0.415714 0.768251 0.0687502 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 26
Initial state: 0 0.287543 0.0816347 0.57611 0.305562 0.824057 0.954235 0.105523 0.735258 0.0908129 0.724118 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 138942 episodes
GETTING ACTION FROM:
action 4, numVisits=138936, meanQ=12.474170, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 0 0.287543 0.0816347 0.57611 0.305562 0.824057 0.954235 0.105523 0.735258 0.0908129 0.724118 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=1340, meanQ=14.162631, numObservations: 9
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action 4, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 160063 episodes
GETTING ACTION FROM:
action 1, numVisits=159987, meanQ=17.433764, numObservations: 9
action 3, numVisits=1416, meanQ=14.236846, numObservations: 9
action 4, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.287543 0.0816347 0.57611 0.305562 0.824057 0.954235 0.105523 0.735258 0.0908129 0.724118 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 27
Initial state: 0 0.296323 0.415184 0.67221 0.147501 0.123556 0.325 0.354685 0.535507 0.564359 0.361452 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 138891 episodes
GETTING ACTION FROM:
action 4, numVisits=138881, meanQ=12.429350, numObservations: 9
action 3, numVisits=3, meanQ=3.000000, numObservations: 2
action 5, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.296323 0.415184 0.67221 0.147501 0.123556 0.325 0.354685 0.535507 0.564359 0.361452 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=20630, meanQ=13.557199, numObservations: 9
action 1, numVisits=6, meanQ=7.831667, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 48208 episodes
GETTING ACTION FROM:
action 3, numVisits=68834, meanQ=14.209101, numObservations: 9
action 1, numVisits=7, meanQ=5.141429, numObservations: 5
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.296323 0.415184 0.67221 0.147501 0.123556 0.325 0.354685 0.535507 0.564359 0.361452 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 28
Initial state: 0 0.630492 0.760403 0.688292 0.857709 0.543818 0.35916 0.282799 0.0117931 0.585822 0.870585 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 138326 episodes
GETTING ACTION FROM:
action 1, numVisits=138314, meanQ=12.412202, numObservations: 9
action 5, numVisits=7, meanQ=4.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.630492 0.760403 0.688292 0.857709 0.543818 0.35916 0.282799 0.0117931 0.585822 0.870585 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 29
Initial state: 0 0.435871 0.522419 0.965903 0.182362 0.756009 0.0680527 0.640604 0.436815 0.146295 0.655509 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 139519 episodes
GETTING ACTION FROM:
action 4, numVisits=139513, meanQ=12.396401, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.435871 0.522419 0.965903 0.182362 0.756009 0.0680527 0.640604 0.436815 0.146295 0.655509 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 30
Initial state: 0 0.223993 0.920667 0.374616 0.132951 0.488444 0.334127 0.656694 0.110486 0.0386858 0.0882006 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 138238 episodes
GETTING ACTION FROM:
action 4, numVisits=138231, meanQ=12.406608, numObservations: 9
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.223993 0.920667 0.374616 0.132951 0.488444 0.334127 0.656694 0.110486 0.0386858 0.0882006 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 31
Initial state: 0 0.588689 0.395805 0.556994 0.583781 0.916259 0.0694921 0.639178 0.989621 0.462468 0.631982 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 138496 episodes
GETTING ACTION FROM:
action 5, numVisits=138445, meanQ=12.204066, numObservations: 9
action 3, numVisits=33, meanQ=5.682127, numObservations: 9
action 2, numVisits=14, meanQ=5.070714, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.588689 0.395805 0.556994 0.583781 0.916259 0.0694921 0.639178 0.989621 0.462468 0.631982 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1290, meanQ=12.505103, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 160032 episodes
GETTING ACTION FROM:
action 2, numVisits=161322, meanQ=15.738044, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.588689 0.395805 0.556994 0.583781 0.916259 0.0694921 0.639178 0.989621 0.462468 0.631982 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 32
Initial state: 0 0.445735 0.980967 0.090621 0.909928 0.424412 0.590118 0.58384 0.301732 0.690485 0.986342 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 133017 episodes
GETTING ACTION FROM:
action 1, numVisits=133009, meanQ=12.404095, numObservations: 9
action 2, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.445735 0.980967 0.090621 0.909928 0.424412 0.590118 0.58384 0.301732 0.690485 0.986342 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=19620, meanQ=13.067963, numObservations: 9
action 4, numVisits=31, meanQ=7.127110, numObservations: 9
action 3, numVisits=18, meanQ=6.997789, numObservations: 8
action 2, numVisits=8, meanQ=6.120000, numObservations: 6
action 5, numVisits=3, meanQ=4.670033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 50130 episodes
GETTING ACTION FROM:
action 2, numVisits=50128, meanQ=16.447959, numObservations: 9
action 1, numVisits=19624, meanQ=13.069460, numObservations: 9
action 4, numVisits=31, meanQ=7.127110, numObservations: 9
action 3, numVisits=18, meanQ=6.997789, numObservations: 8
action 5, numVisits=4, meanQ=2.252550, numObservations: 2
action -1, numVisits=4, meanQ=-1.257500, numObservations: 4
action 0, numVisits=3, meanQ=-1.340000, numObservations: 3
action: 2
Next state: 0 0.445735 0.980967 0.090621 0.909928 0.424412 0.590118 0.58384 0.301732 0.690485 0.986342 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=1, meanQ=24.000000, numObservations: 1
action 3, numVisits=4032, meanQ=12.791989, numObservations: 9
action -1, numVisits=19, meanQ=-3.399976, numObservations: 15
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.013901, numObservations: 1
action 0, numVisits=6, meanQ=-177.138487, numObservations: 5
Sampled 42986 episodes
GETTING ACTION FROM:
action 3, numVisits=47003, meanQ=14.934043, numObservations: 9
action 1, numVisits=16, meanQ=14.705971, numObservations: 4
action -1, numVisits=19, meanQ=-3.399976, numObservations: 15
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.013901, numObservations: 1
action 0, numVisits=6, meanQ=-177.138487, numObservations: 5
action: 3
Next state: 0 0.445735 0.980967 0.090621 0.909928 0.424412 0.590118 0.58384 0.301732 0.690485 0.986342 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=2233, meanQ=12.816953, numObservations: 9
action 4, numVisits=3, meanQ=0.666667, numObservations: 3
action 5, numVisits=1, meanQ=-9.970985, numObservations: 1
action 2, numVisits=1, meanQ=-11.152757, numObservations: 1
action 0, numVisits=49, meanQ=-15.910947, numObservations: 23
action -1, numVisits=7, meanQ=-148.870858, numObservations: 5
action 1, numVisits=1, meanQ=-1066.875713, numObservations: 1
Sampled 59034 episodes
GETTING ACTION FROM:
action 5, numVisits=58998, meanQ=19.608653, numObservations: 9
action 3, numVisits=2257, meanQ=12.928811, numObservations: 9
action 4, numVisits=16, meanQ=-6.815825, numObservations: 8
action 2, numVisits=1, meanQ=-11.152757, numObservations: 1
action 0, numVisits=49, meanQ=-15.910947, numObservations: 23
action -1, numVisits=7, meanQ=-148.870858, numObservations: 5
action 1, numVisits=1, meanQ=-1066.875713, numObservations: 1
action: 5
Next state: 1 0.445735 0.980967 0.090621 0.909928 0.424412 0.590118 0.58384 0.301732 0.690485 0.986342 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 11.4068
Run # 33
Initial state: 0 0.590086 0.368803 0.14615 0.101388 0.171198 0.331718 0.162616 0.799716 0.687171 0.550454 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 138232 episodes
GETTING ACTION FROM:
action 4, numVisits=138210, meanQ=12.437887, numObservations: 9
action 5, numVisits=17, meanQ=7.807653, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.590086 0.368803 0.14615 0.101388 0.171198 0.331718 0.162616 0.799716 0.687171 0.550454 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1024, meanQ=14.196477, numObservations: 9
action 3, numVisits=8, meanQ=4.122500, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 166910 episodes
GETTING ACTION FROM:
action 1, numVisits=167932, meanQ=16.188622, numObservations: 9
action 3, numVisits=8, meanQ=4.122500, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.590086 0.368803 0.14615 0.101388 0.171198 0.331718 0.162616 0.799716 0.687171 0.550454 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 34
Initial state: 0 0.763351 0.225618 0.509559 0.304677 0.572961 0.772769 0.980627 0.0284129 0.80786 0.694424 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 131648 episodes
GETTING ACTION FROM:
action 4, numVisits=131642, meanQ=12.186507, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.763351 0.225618 0.509559 0.304677 0.572961 0.772769 0.980627 0.0284129 0.80786 0.694424 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 35
Initial state: 0 0.854573 0.882397 0.770017 0.179736 0.302173 0.973424 0.486338 0.849948 0.658829 0.430566 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 139673 episodes
GETTING ACTION FROM:
action 2, numVisits=139666, meanQ=12.356931, numObservations: 9
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.854573 0.882397 0.770017 0.179736 0.302173 0.973424 0.486338 0.849948 0.658829 0.430566 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 36
Initial state: 0 0.220654 0.323198 0.302515 0.673879 0.407768 0.649756 0.200871 0.183498 0.505604 0.381483 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 140041 episodes
GETTING ACTION FROM:
action 1, numVisits=140028, meanQ=12.537066, numObservations: 9
action 3, numVisits=8, meanQ=4.873750, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.220654 0.323198 0.302515 0.673879 0.407768 0.649756 0.200871 0.183498 0.505604 0.381483 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 37
Initial state: 0 0.476554 0.103053 0.496585 0.340277 0.348815 0.737658 0.0268208 0.607983 0.888084 0.662985 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 138232 episodes
GETTING ACTION FROM:
action 1, numVisits=138202, meanQ=12.459893, numObservations: 9
action 3, numVisits=11, meanQ=10.180000, numObservations: 7
action 2, numVisits=9, meanQ=9.222222, numObservations: 7
action 5, numVisits=7, meanQ=6.857157, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.476554 0.103053 0.496585 0.340277 0.348815 0.737658 0.0268208 0.607983 0.888084 0.662985 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=15617, meanQ=13.324756, numObservations: 9
action 5, numVisits=33, meanQ=11.342436, numObservations: 9
action 2, numVisits=18, meanQ=10.337228, numObservations: 8
action 1, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 35746 episodes
GETTING ACTION FROM:
action 4, numVisits=51066, meanQ=13.222308, numObservations: 9
action 5, numVisits=196, meanQ=11.952774, numObservations: 9
action 2, numVisits=149, meanQ=11.830262, numObservations: 9
action 1, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 1 0.476554 0.103053 0.496585 0.340277 0.348815 0.737658 0.0268208 0.607983 0.888084 0.662985 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 38
Initial state: 0 0.194724 0.146818 0.247583 0.174245 0.553145 0.587948 0.660209 0.47034 0.189713 0.0719641 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 137401 episodes
GETTING ACTION FROM:
action 5, numVisits=137393, meanQ=12.416560, numObservations: 9
action 3, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 0 0.194724 0.146818 0.247583 0.174245 0.553145 0.587948 0.660209 0.47034 0.189713 0.0719641 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=15338, meanQ=13.152712, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 36248 episodes
GETTING ACTION FROM:
action 3, numVisits=51582, meanQ=12.927989, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.194724 0.146818 0.247583 0.174245 0.553145 0.587948 0.660209 0.47034 0.189713 0.0719641 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 39
Initial state: 0 0.566898 0.921857 0.173453 0.406011 0.404632 0.522596 0.847093 0.539751 0.507277 0.319552 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 138173 episodes
GETTING ACTION FROM:
action 1, numVisits=138153, meanQ=12.196713, numObservations: 9
action 5, numVisits=8, meanQ=9.372500, numObservations: 5
action 3, numVisits=8, meanQ=7.375000, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.566898 0.921857 0.173453 0.406011 0.404632 0.522596 0.847093 0.539751 0.507277 0.319552 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 40
Initial state: 0 0.708491 0.857667 0.989623 0.465954 0.278558 0.00502666 0.956833 0.130513 0.636554 0.406785 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 138949 episodes
GETTING ACTION FROM:
action 5, numVisits=138941, meanQ=12.299801, numObservations: 9
action 1, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.708491 0.857667 0.989623 0.465954 0.278558 0.00502666 0.956833 0.130513 0.636554 0.406785 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 41
Initial state: 0 0.662862 0.470048 0.375552 0.127504 0.557034 0.262217 0.746086 0.759487 0.910566 0.758519 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 137632 episodes
GETTING ACTION FROM:
action 4, numVisits=137626, meanQ=12.446900, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.662862 0.470048 0.375552 0.127504 0.557034 0.262217 0.746086 0.759487 0.910566 0.758519 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 42
Initial state: 0 0.389593 0.269996 0.579946 0.41035 0.449648 0.583727 0.0980047 0.776599 0.8361 0.298476 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 139680 episodes
GETTING ACTION FROM:
action 4, numVisits=139674, meanQ=12.367668, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.389593 0.269996 0.579946 0.41035 0.449648 0.583727 0.0980047 0.776599 0.8361 0.298476 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 43
Initial state: 0 0.217628 0.387045 0.583875 0.390823 0.0613248 0.6958 0.870219 0.521369 0.222551 0.355336 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 138787 episodes
GETTING ACTION FROM:
action 5, numVisits=138775, meanQ=12.305747, numObservations: 9
action 2, numVisits=7, meanQ=7.000000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.217628 0.387045 0.583875 0.390823 0.0613248 0.6958 0.870219 0.521369 0.222551 0.355336 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=5700, meanQ=13.083887, numObservations: 9
action 1, numVisits=30, meanQ=3.974017, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 36267 episodes
GETTING ACTION FROM:
action 2, numVisits=40361, meanQ=13.297714, numObservations: 9
action 4, numVisits=1489, meanQ=10.750377, numObservations: 9
action 1, numVisits=30, meanQ=3.974017, numObservations: 9
action 0, numVisits=38, meanQ=-1.891456, numObservations: 33
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=82, meanQ=-12.994631, numObservations: 58
action: 2
Next state: 1 0.217628 0.387045 0.583875 0.390823 0.0613248 0.6958 0.870219 0.521369 0.222551 0.355336 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 44
Initial state: 0 0.650932 0.168895 0.0363362 0.786842 0.634861 0.477266 0.252038 0.683847 0.807802 0.0764388 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 138742 episodes
GETTING ACTION FROM:
action 5, numVisits=138734, meanQ=12.532694, numObservations: 9
action 2, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.650932 0.168895 0.0363362 0.786842 0.634861 0.477266 0.252038 0.683847 0.807802 0.0764388 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 45
Initial state: 0 0.47563 0.807524 0.38995 0.0172932 0.510829 0.176906 0.631324 0.466827 0.00168614 0.112858 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 132270 episodes
GETTING ACTION FROM:
action 3, numVisits=132261, meanQ=12.317955, numObservations: 9
action 5, numVisits=4, meanQ=1.497500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.47563 0.807524 0.38995 0.0172932 0.510829 0.176906 0.631324 0.466827 0.00168614 0.112858 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=2070, meanQ=12.532592, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.671650, numObservations: 5
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 58491 episodes
GETTING ACTION FROM:
action 1, numVisits=60560, meanQ=12.061819, numObservations: 9
action -1, numVisits=8, meanQ=-1.010000, numObservations: 8
action 0, numVisits=6, meanQ=-1.671650, numObservations: 5
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.47563 0.807524 0.38995 0.0172932 0.510829 0.176906 0.631324 0.466827 0.00168614 0.112858 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 46
Initial state: 0 0.975764 0.90762 0.536775 0.803505 0.321779 0.990593 0.745975 0.744912 0.647016 0.382249 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 137641 episodes
GETTING ACTION FROM:
action 4, numVisits=137600, meanQ=12.459024, numObservations: 9
action 1, numVisits=35, meanQ=9.182871, numObservations: 9
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.975764 0.90762 0.536775 0.803505 0.321779 0.990593 0.745975 0.744912 0.647016 0.382249 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 47
Initial state: 0 0.817291 0.586301 0.899134 0.172386 0.741457 0.235875 0.590663 0.818877 0.516264 0.362368 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 138324 episodes
GETTING ACTION FROM:
action 1, numVisits=138316, meanQ=12.472892, numObservations: 9
action 5, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.817291 0.586301 0.899134 0.172386 0.741457 0.235875 0.590663 0.818877 0.516264 0.362368 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 48
Initial state: 0 0.609446 0.539284 0.301403 0.286396 0.0912867 0.884236 0.551674 0.30469 0.198512 0.0740745 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 138704 episodes
GETTING ACTION FROM:
action 5, numVisits=138695, meanQ=12.328427, numObservations: 9
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action 4, numVisits=3, meanQ=5.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 0 0.609446 0.539284 0.301403 0.286396 0.0912867 0.884236 0.551674 0.30469 0.198512 0.0740745 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=15290, meanQ=13.145399, numObservations: 9
action 3, numVisits=6, meanQ=9.163333, numObservations: 4
action 1, numVisits=4, meanQ=8.497500, numObservations: 3
action 2, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 31357 episodes
GETTING ACTION FROM:
action 4, numVisits=46622, meanQ=11.936577, numObservations: 9
action 3, numVisits=16, meanQ=7.303193, numObservations: 8
action 1, numVisits=5, meanQ=4.598000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action -1, numVisits=3, meanQ=-1.340000, numObservations: 3
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=12, meanQ=-76.984862, numObservations: 8
action: 4
Next state: 0 0.609446 0.539284 0.301403 0.286396 0.0912867 0.884236 0.551674 0.30469 0.198512 0.0740745 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=764, meanQ=18.628195, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 78832 episodes
GETTING ACTION FROM:
action 4, numVisits=872, meanQ=19.082914, numObservations: 9
action 1, numVisits=78717, meanQ=15.897552, numObservations: 9
action -1, numVisits=5, meanQ=-1.604000, numObservations: 4
action 0, numVisits=5, meanQ=-1.604000, numObservations: 5
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.609446 0.539284 0.301403 0.286396 0.0912867 0.884236 0.551674 0.30469 0.198512 0.0740745 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 49
Initial state: 0 0.82217 0.843282 0.581547 0.388931 0.0897074 0.0368106 0.222746 0.264515 0.868841 0.250577 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 138747 episodes
GETTING ACTION FROM:
action 2, numVisits=138741, meanQ=12.275816, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.82217 0.843282 0.581547 0.388931 0.0897074 0.0368106 0.222746 0.264515 0.868841 0.250577 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 50
Initial state: 0 0.92174 0.331313 0.160124 0.946343 0.824807 0.0117898 0.655527 0.422959 0.0164251 0.277311 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 129796 episodes
GETTING ACTION FROM:
action 4, numVisits=129790, meanQ=12.348436, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.92174 0.331313 0.160124 0.946343 0.824807 0.0117898 0.655527 0.422959 0.0164251 0.277311 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
[32m ProblemEnvironment.hpp 351: Done.[39m
