Run # 1
Initial state: 0 0.454446 0.33544 0.989943 0.415812 0.743482 0.151028 0.570306 0.9467 0.628329 0.505426 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 128883 episodes
GETTING ACTION FROM:
action 3, numVisits=128868, meanQ=8.982658, numObservations: 9
action 1, numVisits=8, meanQ=6.120000, numObservations: 7
action 2, numVisits=3, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 2 0.454446 0.33544 0.989943 0.415812 0.743482 0.151028 0.570306 0.9467 0.628329 0.505426 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 2
Initial state: 0 0.0641626 0.538365 0.0628715 0.874638 0.840417 0.500875 0.317589 0.435213 0.521055 0.602921 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 133207 episodes
GETTING ACTION FROM:
action 5, numVisits=133188, meanQ=8.833203, numObservations: 9
action 4, numVisits=12, meanQ=3.505842, numObservations: 7
action 2, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.0641626 0.538365 0.0628715 0.874638 0.840417 0.500875 0.317589 0.435213 0.521055 0.602921 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 3
Initial state: 0 0.939642 0.822473 0.625668 0.594861 0.771931 0.168001 0.304839 0.688261 0.540567 0.387318 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 125693 episodes
GETTING ACTION FROM:
action 4, numVisits=125657, meanQ=8.881388, numObservations: 9
action 3, numVisits=19, meanQ=6.210016, numObservations: 7
action 2, numVisits=13, meanQ=5.385408, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.939642 0.822473 0.625668 0.594861 0.771931 0.168001 0.304839 0.688261 0.540567 0.387318 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 4
Initial state: 0 0.865332 0.471135 0.452901 0.0466421 0.13376 0.968304 0.774205 0.771227 0.529647 0.550913 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 133963 episodes
GETTING ACTION FROM:
action 3, numVisits=133946, meanQ=8.917031, numObservations: 9
action 4, numVisits=10, meanQ=5.700010, numObservations: 6
action 1, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.865332 0.471135 0.452901 0.0466421 0.13376 0.968304 0.774205 0.771227 0.529647 0.550913 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 5
Initial state: 0 0.951486 0.392292 0.63035 0.618062 0.980054 0.19054 0.647302 0.479905 0.23356 0.427579 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 133156 episodes
GETTING ACTION FROM:
action 5, numVisits=133143, meanQ=9.021124, numObservations: 9
action 4, numVisits=8, meanQ=4.625013, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 2 0.951486 0.392292 0.63035 0.618062 0.980054 0.19054 0.647302 0.479905 0.23356 0.427579 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 6
Initial state: 0 0.363188 0.144084 0.601178 0.538954 0.713354 0.0116129 0.724386 0.909871 0.00536496 0.0118353 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 131476 episodes
GETTING ACTION FROM:
action 4, numVisits=131461, meanQ=8.816383, numObservations: 9
action -1, numVisits=5, meanQ=-1.010000, numObservations: 5
action 0, numVisits=5, meanQ=-1.010000, numObservations: 5
action 1, numVisits=2, meanQ=-4.000000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.363188 0.144084 0.601178 0.538954 0.713354 0.0116129 0.724386 0.909871 0.00536496 0.0118353 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 7
Initial state: 0 0.849389 0.140737 0.854792 0.991504 0.534309 0.261659 0.556855 0.497375 0.181189 0.402646 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 132805 episodes
GETTING ACTION FROM:
action 4, numVisits=132778, meanQ=8.893288, numObservations: 9
action 3, numVisits=8, meanQ=0.375000, numObservations: 5
action 1, numVisits=9, meanQ=-0.111111, numObservations: 6
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=5, meanQ=-1.200000, numObservations: 5
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 0 0.849389 0.140737 0.854792 0.991504 0.534309 0.261659 0.556855 0.497375 0.181189 0.402646 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=2062, meanQ=19.674906, numObservations: 9
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 130149 episodes
GETTING ACTION FROM:
action 4, numVisits=2068, meanQ=19.678313, numObservations: 9
action 3, numVisits=130139, meanQ=13.725656, numObservations: 9
action -1, numVisits=4, meanQ=-1.752500, numObservations: 4
action 0, numVisits=4, meanQ=-1.752500, numObservations: 4
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.849389 0.140737 0.854792 0.991504 0.534309 0.261659 0.556855 0.497375 0.181189 0.402646 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 8
Initial state: 0 0.323828 0.457359 0.0846351 0.150287 0.726647 0.942885 0.621471 0.622588 0.0504001 0.0327797 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 130462 episodes
GETTING ACTION FROM:
action 1, numVisits=130402, meanQ=8.718550, numObservations: 9
action 0, numVisits=29, meanQ=-1.421362, numObservations: 24
action -1, numVisits=25, meanQ=-1.723592, numObservations: 22
action 5, numVisits=2, meanQ=-5.489950, numObservations: 1
action 2, numVisits=2, meanQ=-9.445000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.323828 0.457359 0.0846351 0.150287 0.726647 0.942885 0.621471 0.622588 0.0504001 0.0327797 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=947, meanQ=10.147677, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 152170 episodes
GETTING ACTION FROM:
action 3, numVisits=153110, meanQ=14.646017, numObservations: 9
action 0, numVisits=4, meanQ=-1.505000, numObservations: 4
action -1, numVisits=4, meanQ=-1.752500, numObservations: 4
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=2, meanQ=-7.005000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.323828 0.457359 0.0846351 0.150287 0.726647 0.942885 0.621471 0.622588 0.0504001 0.0327797 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 9
Initial state: 0 0.593346 0.608084 0.287968 0.67066 0.0764909 0.9659 0.314236 0.0570429 0.910631 0.970874 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 131230 episodes
GETTING ACTION FROM:
action 1, numVisits=131210, meanQ=8.670976, numObservations: 9
action -1, numVisits=6, meanQ=-1.010000, numObservations: 6
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 3, numVisits=5, meanQ=-1.200000, numObservations: 4
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.593346 0.608084 0.287968 0.67066 0.0764909 0.9659 0.314236 0.0570429 0.910631 0.970874 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 10
Initial state: 0 0.372741 0.189814 0.556532 0.917914 0.64175 0.502334 0.00123168 0.353282 0.23743 0.158179 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 133058 episodes
GETTING ACTION FROM:
action 2, numVisits=133036, meanQ=8.859679, numObservations: 9
action 3, numVisits=10, meanQ=5.397000, numObservations: 6
action 5, numVisits=6, meanQ=3.165000, numObservations: 3
action 1, numVisits=3, meanQ=1.703333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 2 0.372741 0.189814 0.556532 0.917914 0.64175 0.502334 0.00123168 0.353282 0.23743 0.158179 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 11
Initial state: 0 0.372711 0.822514 0.451862 0.0731748 0.750303 0.221519 0.285762 0.996071 0.534812 0.620558 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 133340 episodes
GETTING ACTION FROM:
action 3, numVisits=133334, meanQ=8.860499, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 2 0.372711 0.822514 0.451862 0.0731748 0.750303 0.221519 0.285762 0.996071 0.534812 0.620558 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 12
Initial state: 0 0.403791 0.764143 0.0927158 0.668764 0.629049 0.750133 0.999 0.051218 0.561093 0.552223 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 132350 episodes
GETTING ACTION FROM:
action 2, numVisits=132323, meanQ=8.885225, numObservations: 9
action 4, numVisits=12, meanQ=6.332525, numObservations: 5
action 3, numVisits=5, meanQ=5.204020, numObservations: 4
action 5, numVisits=7, meanQ=5.141429, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.403791 0.764143 0.0927158 0.668764 0.629049 0.750133 0.999 0.051218 0.561093 0.552223 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=13642, meanQ=10.381383, numObservations: 9
action 5, numVisits=18, meanQ=6.542233, numObservations: 7
action 1, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 39750 episodes
GETTING ACTION FROM:
action 4, numVisits=53384, meanQ=11.871911, numObservations: 9
action 5, numVisits=18, meanQ=6.542233, numObservations: 7
action 1, numVisits=4, meanQ=-0.252500, numObservations: 4
action 0, numVisits=5, meanQ=-1.010000, numObservations: 5
action -1, numVisits=4, meanQ=-1.505000, numObservations: 4
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 2 0.403791 0.764143 0.0927158 0.668764 0.629049 0.750133 0.999 0.051218 0.561093 0.552223 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 13
Initial state: 0 0.0917418 0.7968 0.940608 0.954945 0.121913 0.422362 0.0256796 0.0844687 0.526895 0.594553 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 132421 episodes
GETTING ACTION FROM:
action 5, numVisits=132412, meanQ=8.930580, numObservations: 9
action 3, numVisits=4, meanQ=1.497500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.0917418 0.7968 0.940608 0.954945 0.121913 0.422362 0.0256796 0.0844687 0.526895 0.594553 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 14
Initial state: 0 0.130754 0.568617 0.645038 0.541013 0.82585 0.067296 0.337792 0.0694764 0.0778027 0.112729 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 132320 episodes
GETTING ACTION FROM:
action 2, numVisits=132314, meanQ=8.618158, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.130754 0.568617 0.645038 0.541013 0.82585 0.067296 0.337792 0.0694764 0.0778027 0.112729 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 15
Initial state: 0 0.00935795 0.118784 0.747213 0.860953 0.0665837 0.84043 0.635394 0.546277 0.063442 0.807551 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 132074 episodes
GETTING ACTION FROM:
action 1, numVisits=132066, meanQ=8.670490, numObservations: 9
action 4, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.00935795 0.118784 0.747213 0.860953 0.0665837 0.84043 0.635394 0.546277 0.063442 0.807551 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=13743, meanQ=10.115130, numObservations: 9
action 5, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 42215 episodes
GETTING ACTION FROM:
action 3, numVisits=55920, meanQ=11.459920, numObservations: 9
action 5, numVisits=6, meanQ=2.433318, numObservations: 4
action -1, numVisits=20, meanQ=-1.356995, numObservations: 19
action 0, numVisits=17, meanQ=-1.359412, numObservations: 16
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.00935795 0.118784 0.747213 0.860953 0.0665837 0.84043 0.635394 0.546277 0.063442 0.807551 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 16
Initial state: 0 0.935807 0.72875 0.615797 0.611243 0.669594 0.677414 0.0979682 0.861725 0.368298 0.468569 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 131637 episodes
GETTING ACTION FROM:
action 1, numVisits=131619, meanQ=8.812874, numObservations: 9
action 2, numVisits=13, meanQ=5.922346, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.935807 0.72875 0.615797 0.611243 0.669594 0.677414 0.0979682 0.861725 0.368298 0.468569 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 17
Initial state: 0 0.613866 0.563369 0.233127 0.166341 0.576448 0.809691 0.416006 0.773659 0.17281 0.114277 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79577 episodes
GETTING ACTION FROM:
action -1, numVisits=79556, meanQ=13.003344, numObservations: 243
action 0, numVisits=13, meanQ=-1.468446, numObservations: 11
action 4, numVisits=2, meanQ=-3.505000, numObservations: 2
action 3, numVisits=2, meanQ=-4.499950, numObservations: 1
action 2, numVisits=2, meanQ=-7.500000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.613866 0.563369 0.233127 0.166341 0.576448 0.809691 0.416006 0.773659 0.17281 0.114277 w: 1
Observation: 0 2 0 1 0 2 0 1 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=417, meanQ=13.015828, numObservations: 9
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 165995 episodes
GETTING ACTION FROM:
action 1, numVisits=166412, meanQ=14.073081, numObservations: 9
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.613866 0.563369 0.233127 0.166341 0.576448 0.809691 0.416006 0.773659 0.17281 0.114277 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 18
Initial state: 0 0.0241984 0.101798 0.512983 0.562526 0.86291 0.598968 0.738913 0.727571 0.982967 0.919316 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 132518 episodes
GETTING ACTION FROM:
action 5, numVisits=132498, meanQ=8.998133, numObservations: 9
action 1, numVisits=4, meanQ=2.750025, numObservations: 3
action 2, numVisits=9, meanQ=2.332222, numObservations: 5
action 3, numVisits=4, meanQ=1.000025, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 1 0.0241984 0.101798 0.512983 0.562526 0.86291 0.598968 0.738913 0.727571 0.982967 0.919316 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 19
Initial state: 0 0.582582 0.77564 0.331014 0.350607 0.909298 0.756153 0.545565 0.550928 0.215642 0.779019 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 126040 episodes
GETTING ACTION FROM:
action 2, numVisits=126030, meanQ=9.144153, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.582582 0.77564 0.331014 0.350607 0.909298 0.756153 0.545565 0.550928 0.215642 0.779019 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=22466, meanQ=10.050358, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 34464 episodes
GETTING ACTION FROM:
action 3, numVisits=56901, meanQ=9.714964, numObservations: 9
action -1, numVisits=22, meanQ=-0.245900, numObservations: 19
action 0, numVisits=7, meanQ=-2.688118, numObservations: 6
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=2, meanQ=-6.539542, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=2, meanQ=-532.152611, numObservations: 1
action: 3
Next state: 2 0.582582 0.77564 0.331014 0.350607 0.909298 0.756153 0.545565 0.550928 0.215642 0.779019 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 20
Initial state: 0 0.907376 0.903362 0.862038 0.872179 0.0121808 0.491808 0.517591 0.626266 0.118581 0.445963 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 130675 episodes
GETTING ACTION FROM:
action 4, numVisits=130667, meanQ=8.764754, numObservations: 9
action 3, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.907376 0.903362 0.862038 0.872179 0.0121808 0.491808 0.517591 0.626266 0.118581 0.445963 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 21
Initial state: 0 0.474157 0.296904 0.567304 0.529567 0.911889 0.620776 0.142811 0.20745 0.407212 0.800557 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 81242 episodes
GETTING ACTION FROM:
action -1, numVisits=81185, meanQ=13.195889, numObservations: 243
action 0, numVisits=51, meanQ=-1.147435, numObservations: 41
action 2, numVisits=2, meanQ=-7.500000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.474157 0.296904 0.567304 0.529567 0.911889 0.620776 0.142811 0.20745 0.407212 0.800557 w: 1
Observation: 0 2 0 2 0 3 0 1 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=274, meanQ=13.809360, numObservations: 9
action 3, numVisits=11, meanQ=9.543636, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 164826 episodes
GETTING ACTION FROM:
action 2, numVisits=165100, meanQ=14.751409, numObservations: 9
action 3, numVisits=11, meanQ=9.543636, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.474157 0.296904 0.567304 0.529567 0.911889 0.620776 0.142811 0.20745 0.407212 0.800557 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 22
Initial state: 0 0.84151 0.737247 0.329029 0.197346 0.468297 0.151446 0.509531 0.541593 0.810917 0.837714 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 131382 episodes
GETTING ACTION FROM:
action 1, numVisits=131341, meanQ=8.726509, numObservations: 9
action 4, numVisits=36, meanQ=4.174742, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.84151 0.737247 0.329029 0.197346 0.468297 0.151446 0.509531 0.541593 0.810917 0.837714 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 23
Initial state: 0 0.529596 0.57892 0.15079 0.743875 0.469086 0.725074 0.614061 0.903756 0.544241 0.375971 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 129990 episodes
GETTING ACTION FROM:
action 3, numVisits=129976, meanQ=8.753258, numObservations: 9
action 5, numVisits=6, meanQ=3.165000, numObservations: 4
action 2, numVisits=4, meanQ=1.497500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.529596 0.57892 0.15079 0.743875 0.469086 0.725074 0.614061 0.903756 0.544241 0.375971 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=13569, meanQ=10.221945, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 42911 episodes
GETTING ACTION FROM:
action 5, numVisits=56476, meanQ=11.797057, numObservations: 9
action -1, numVisits=3, meanQ=-1.340000, numObservations: 3
action 0, numVisits=3, meanQ=-1.340000, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.529596 0.57892 0.15079 0.743875 0.469086 0.725074 0.614061 0.903756 0.544241 0.375971 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 24
Initial state: 0 0.554602 0.52165 0.831527 0.202796 0.0915158 0.982329 0.0391376 0.206114 0.486101 0.92442 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 132915 episodes
GETTING ACTION FROM:
action 5, numVisits=132863, meanQ=8.970595, numObservations: 9
action 2, numVisits=47, meanQ=5.477466, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.554602 0.52165 0.831527 0.202796 0.0915158 0.982329 0.0391376 0.206114 0.486101 0.92442 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=23676, meanQ=10.467531, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 36242 episodes
GETTING ACTION FROM:
action 2, numVisits=59904, meanQ=10.573746, numObservations: 9
action 4, numVisits=4, meanQ=2.247543, numObservations: 3
action -1, numVisits=6, meanQ=-1.175000, numObservations: 6
action 0, numVisits=6, meanQ=-1.340000, numObservations: 6
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.554602 0.52165 0.831527 0.202796 0.0915158 0.982329 0.0391376 0.206114 0.486101 0.92442 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 25
Initial state: 0 0.090086 0.302823 0.900456 0.607646 0.807852 0.315734 0.528076 0.626918 0.142637 0.214773 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 132665 episodes
GETTING ACTION FROM:
action 2, numVisits=132624, meanQ=8.973617, numObservations: 9
action 5, numVisits=22, meanQ=5.647286, numObservations: 7
action 1, numVisits=15, meanQ=5.474007, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.090086 0.302823 0.900456 0.607646 0.807852 0.315734 0.528076 0.626918 0.142637 0.214773 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 26
Initial state: 0 0.656168 0.155845 0.193612 0.791353 0.670939 0.458913 0.508825 0.573172 0.837907 0.216279 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 132342 episodes
GETTING ACTION FROM:
action 3, numVisits=132334, meanQ=8.718202, numObservations: 9
action 2, numVisits=3, meanQ=1.703333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 2 0.656168 0.155845 0.193612 0.791353 0.670939 0.458913 0.508825 0.573172 0.837907 0.216279 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 27
Initial state: 0 0.443388 0.726105 0.571915 0.565531 0.11414 0.139897 0.767684 0.657721 0.546606 0.476406 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80943 episodes
GETTING ACTION FROM:
action -1, numVisits=80936, meanQ=13.604496, numObservations: 243
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.443388 0.726105 0.571915 0.565531 0.11414 0.139897 0.767684 0.657721 0.546606 0.476406 w: 1
Observation: 0 2 0 2 0 1 0 3 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=9, meanQ=12.333333, numObservations: 5
action 1, numVisits=75, meanQ=9.895739, numObservations: 9
action 4, numVisits=6, meanQ=6.500000, numObservations: 3
action 3, numVisits=3, meanQ=2.033333, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 157106 episodes
GETTING ACTION FROM:
action 2, numVisits=156797, meanQ=11.999869, numObservations: 9
action 1, numVisits=384, meanQ=7.917213, numObservations: 9
action 4, numVisits=15, meanQ=5.866000, numObservations: 6
action 3, numVisits=3, meanQ=2.033333, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.443388 0.726105 0.571915 0.565531 0.11414 0.139897 0.767684 0.657721 0.546606 0.476406 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 28
Initial state: 0 0.477526 0.675734 0.0547686 0.253164 0.581582 0.501025 0.456197 0.198309 0.0380623 0.702419 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 131803 episodes
GETTING ACTION FROM:
action 2, numVisits=131742, meanQ=8.756281, numObservations: 9
action 4, numVisits=46, meanQ=7.011243, numObservations: 8
action 3, numVisits=7, meanQ=5.000000, numObservations: 5
action 1, numVisits=5, meanQ=4.400000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.477526 0.675734 0.0547686 0.253164 0.581582 0.501025 0.456197 0.198309 0.0380623 0.702419 w: 1
Observation: 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=2375, meanQ=8.951790, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 47124 episodes
GETTING ACTION FROM:
action 4, numVisits=49257, meanQ=6.859445, numObservations: 9
action -1, numVisits=167, meanQ=-1.697773, numObservations: 106
action 0, numVisits=55, meanQ=-2.158318, numObservations: 41
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=23, meanQ=-39.214983, numObservations: 8
action: 4
Next state: 2 0.477526 0.675734 0.0547686 0.253164 0.581582 0.501025 0.456197 0.198309 0.0380623 0.702419 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 29
Initial state: 0 0.00480263 0.236895 0.705746 0.705374 0.918305 0.225072 0.581941 0.560563 0.489574 0.614565 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 130966 episodes
GETTING ACTION FROM:
action 3, numVisits=130951, meanQ=8.842404, numObservations: 9
action 1, numVisits=10, meanQ=4.802010, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 2 0.00480263 0.236895 0.705746 0.705374 0.918305 0.225072 0.581941 0.560563 0.489574 0.614565 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 30
Initial state: 0 0.548102 0.527736 0.821872 0.707449 0.500335 0.215608 0.310433 0.916469 0.437402 0.993598 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 132713 episodes
GETTING ACTION FROM:
action 2, numVisits=132699, meanQ=8.761697, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 1, numVisits=5, meanQ=-2.600000, numObservations: 3
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.548102 0.527736 0.821872 0.707449 0.500335 0.215608 0.310433 0.916469 0.437402 0.993598 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 31
Initial state: 0 0.965941 0.609346 0.49789 0.574507 0.20204 0.952968 0.570037 0.506334 0.232086 0.0542914 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 131238 episodes
GETTING ACTION FROM:
action 1, numVisits=131228, meanQ=8.906697, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.965941 0.609346 0.49789 0.574507 0.20204 0.952968 0.570037 0.506334 0.232086 0.0542914 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 32
Initial state: 0 0.205185 0.458661 0.359251 0.590035 0.520348 0.579093 0.687046 0.903342 0.395241 0.851059 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 132511 episodes
GETTING ACTION FROM:
action 3, numVisits=132505, meanQ=8.978513, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.205185 0.458661 0.359251 0.590035 0.520348 0.579093 0.687046 0.903342 0.395241 0.851059 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 33
Initial state: 0 0.388868 0.280728 0.635076 0.0580424 0.721696 0.145558 0.292966 0.446186 0.574496 0.530066 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 130497 episodes
GETTING ACTION FROM:
action 5, numVisits=130480, meanQ=8.774829, numObservations: 9
action 1, numVisits=12, meanQ=1.803342, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 1 0.388868 0.280728 0.635076 0.0580424 0.721696 0.145558 0.292966 0.446186 0.574496 0.530066 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 34
Initial state: 0 0.39719 0.66919 0.508457 0.632356 0.32627 0.748971 0.883916 0.177804 0.941022 0.238088 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 130966 episodes
GETTING ACTION FROM:
action 3, numVisits=130960, meanQ=8.819847, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.39719 0.66919 0.508457 0.632356 0.32627 0.748971 0.883916 0.177804 0.941022 0.238088 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=13476, meanQ=10.032353, numObservations: 9
action 0, numVisits=7, meanQ=-1.010000, numObservations: 7
action 3, numVisits=2, meanQ=-3.010000, numObservations: 2
action -1, numVisits=3, meanQ=-4.970000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 40238 episodes
GETTING ACTION FROM:
action 4, numVisits=53714, meanQ=11.582149, numObservations: 9
action 0, numVisits=7, meanQ=-1.010000, numObservations: 7
action 3, numVisits=2, meanQ=-3.010000, numObservations: 2
action -1, numVisits=3, meanQ=-4.970000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.39719 0.66919 0.508457 0.632356 0.32627 0.748971 0.883916 0.177804 0.941022 0.238088 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 35
Initial state: 0 0.622413 0.397684 0.524499 0.540052 0.00556543 0.633432 0.230796 0.259535 0.458473 0.639852 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 128716 episodes
GETTING ACTION FROM:
action 4, numVisits=128639, meanQ=8.850555, numObservations: 9
action 5, numVisits=57, meanQ=7.505281, numObservations: 9
action 2, numVisits=14, meanQ=5.928579, numObservations: 7
action 3, numVisits=3, meanQ=4.340033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 0 0.622413 0.397684 0.524499 0.540052 0.00556543 0.633432 0.230796 0.259535 0.458473 0.639852 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=23082, meanQ=10.679298, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 36983 episodes
GETTING ACTION FROM:
action 3, numVisits=60045, meanQ=10.300051, numObservations: 9
action 2, numVisits=4, meanQ=-0.568568, numObservations: 3
action 0, numVisits=9, meanQ=-1.230000, numObservations: 9
action -1, numVisits=8, meanQ=-1.257500, numObservations: 8
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=2, meanQ=-5.881910, numObservations: 2
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 3
Next state: 0 0.622413 0.397684 0.524499 0.540052 0.00556543 0.633432 0.230796 0.259535 0.458473 0.639852 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=1807, meanQ=11.377532, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 34149 episodes
GETTING ACTION FROM:
action 5, numVisits=35945, meanQ=11.212731, numObservations: 9
action -1, numVisits=9, meanQ=-1.010000, numObservations: 9
action 0, numVisits=8, meanQ=-1.133750, numObservations: 8
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.622413 0.397684 0.524499 0.540052 0.00556543 0.633432 0.230796 0.259535 0.458473 0.639852 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=1023, meanQ=15.290588, numObservations: 9
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=51, meanQ=-11.952331, numObservations: 20
action 1, numVisits=26, meanQ=-30.809999, numObservations: 8
action -1, numVisits=14, meanQ=-39.719904, numObservations: 8
action 5, numVisits=2, meanQ=-269.026916, numObservations: 1
Sampled 54861 episodes
GETTING ACTION FROM:
action 2, numVisits=55884, meanQ=17.019008, numObservations: 9
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=51, meanQ=-11.952331, numObservations: 20
action 1, numVisits=26, meanQ=-30.809999, numObservations: 8
action -1, numVisits=14, meanQ=-39.719904, numObservations: 8
action 5, numVisits=2, meanQ=-269.026916, numObservations: 1
action: 2
Next state: 1 0.622413 0.397684 0.524499 0.540052 0.00556543 0.633432 0.230796 0.259535 0.458473 0.639852 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 11.4068
Run # 36
Initial state: 0 0.590685 0.537689 0.855369 0.462196 0.173796 0.99964 0.0158235 0.751371 0.798831 0.465614 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 132049 episodes
GETTING ACTION FROM:
action 1, numVisits=132040, meanQ=8.787853, numObservations: 9
action 3, numVisits=4, meanQ=1.250000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.590685 0.537689 0.855369 0.462196 0.173796 0.99964 0.0158235 0.751371 0.798831 0.465614 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 37
Initial state: 0 0.542049 0.570629 0.132729 0.976403 0.770863 0.128064 0.0522004 0.648102 0.43204 0.42824 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 125920 episodes
GETTING ACTION FROM:
action 2, numVisits=125905, meanQ=8.952725, numObservations: 9
action 3, numVisits=7, meanQ=4.000000, numObservations: 5
action 1, numVisits=4, meanQ=1.250000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.542049 0.570629 0.132729 0.976403 0.770863 0.128064 0.0522004 0.648102 0.43204 0.42824 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=13005, meanQ=10.881621, numObservations: 9
action 5, numVisits=23, meanQ=8.259139, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 39520 episodes
GETTING ACTION FROM:
action 5, numVisits=39428, meanQ=13.635301, numObservations: 9
action 2, numVisits=13006, meanQ=10.881153, numObservations: 9
action 4, numVisits=3, meanQ=-7.748509, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=46, meanQ=-11.660605, numObservations: 9
action 0, numVisits=49, meanQ=-23.048707, numObservations: 39
action -1, numVisits=20, meanQ=-54.209590, numObservations: 17
action: 5
Next state: 0 0.542049 0.570629 0.132729 0.976403 0.770863 0.128064 0.0522004 0.648102 0.43204 0.42824 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=1, meanQ=24.000000, numObservations: 1
action 4, numVisits=4234, meanQ=10.165621, numObservations: 9
action 1, numVisits=1, meanQ=-10.035821, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=48, meanQ=-21.157471, numObservations: 33
action -1, numVisits=26, meanQ=-40.981493, numObservations: 15
action 3, numVisits=16, meanQ=-63.305650, numObservations: 8
Sampled 23342 episodes
GETTING ACTION FROM:
action 2, numVisits=10, meanQ=18.300010, numObservations: 4
action 4, numVisits=27567, meanQ=11.559090, numObservations: 9
action 1, numVisits=1, meanQ=-10.035821, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=48, meanQ=-21.157471, numObservations: 33
action -1, numVisits=26, meanQ=-40.981493, numObservations: 15
action 3, numVisits=16, meanQ=-63.305650, numObservations: 8
action: 2
Next state: 0 0.542049 0.570629 0.132729 0.976403 0.770863 0.128064 0.0522004 0.648102 0.43204 0.42824 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34350 episodes
GETTING ACTION FROM:
action 4, numVisits=34290, meanQ=12.654323, numObservations: 9
action 5, numVisits=7, meanQ=9.000000, numObservations: 1
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action 3, numVisits=43, meanQ=0.400766, numObservations: 9
action -1, numVisits=4, meanQ=-1.257500, numObservations: 4
action 0, numVisits=4, meanQ=-1.505000, numObservations: 4
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.542049 0.570629 0.132729 0.976403 0.770863 0.128064 0.0522004 0.648102 0.43204 0.42824 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 4, numVisits=665, meanQ=15.380667, numObservations: 9
action 1, numVisits=34, meanQ=-7.740690, numObservations: 9
action 3, numVisits=2, meanQ=-11.000000, numObservations: 2
action -1, numVisits=26, meanQ=-18.511711, numObservations: 12
action 0, numVisits=7, meanQ=-78.005658, numObservations: 4
action 5, numVisits=1, meanQ=-539.401677, numObservations: 1
action 2, numVisits=1, meanQ=-539.412298, numObservations: 1
Sampled 105528 episodes
GETTING ACTION FROM:
action 3, numVisits=105529, meanQ=20.384121, numObservations: 9
action 4, numVisits=666, meanQ=15.380455, numObservations: 9
action 1, numVisits=34, meanQ=-7.740690, numObservations: 9
action -1, numVisits=26, meanQ=-18.511711, numObservations: 12
action 0, numVisits=7, meanQ=-78.005658, numObservations: 4
action 5, numVisits=1, meanQ=-539.401677, numObservations: 1
action 2, numVisits=1, meanQ=-539.412298, numObservations: 1
action: 3
Next state: 2 0.542049 0.570629 0.132729 0.976403 0.770863 0.128064 0.0522004 0.648102 0.43204 0.42824 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -26.3282
Run # 38
Initial state: 0 0.453002 0.0190748 0.709779 0.033398 0.338803 0.785442 0.791165 0.044262 0.569834 0.536383 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 130838 episodes
GETTING ACTION FROM:
action 5, numVisits=130824, meanQ=8.900567, numObservations: 9
action 2, numVisits=7, meanQ=6.141429, numObservations: 6
action 4, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 1 0.453002 0.0190748 0.709779 0.033398 0.338803 0.785442 0.791165 0.044262 0.569834 0.536383 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 39
Initial state: 0 0.769061 0.0590682 0.532689 0.616559 0.993257 0.769398 0.692933 0.139602 0.96141 0.726075 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 132805 episodes
GETTING ACTION FROM:
action 1, numVisits=132793, meanQ=8.733189, numObservations: 9
action 4, numVisits=7, meanQ=2.140014, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.769061 0.0590682 0.532689 0.616559 0.993257 0.769398 0.692933 0.139602 0.96141 0.726075 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 40
Initial state: 0 0.271513 0.765012 0.186331 0.866497 0.515555 0.582759 0.708187 0.039105 0.643826 0.463153 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 125110 episodes
GETTING ACTION FROM:
action 5, numVisits=125098, meanQ=9.096138, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=5, meanQ=-1.200000, numObservations: 4
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 2 0.271513 0.765012 0.186331 0.866497 0.515555 0.582759 0.708187 0.039105 0.643826 0.463153 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 41
Initial state: 0 0.98462 0.457804 0.807773 0.369748 0.585012 0.578845 0.398127 0.361854 0.0627572 0.908945 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 125554 episodes
GETTING ACTION FROM:
action 3, numVisits=125548, meanQ=8.802256, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.98462 0.457804 0.807773 0.369748 0.585012 0.578845 0.398127 0.361854 0.0627572 0.908945 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 42
Initial state: 0 0.719994 0.370796 0.987369 0.825331 0.552029 0.569062 0.681613 0.523814 0.0947543 0.123951 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 133037 episodes
GETTING ACTION FROM:
action 4, numVisits=133029, meanQ=8.859185, numObservations: 9
action 1, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 1 0.719994 0.370796 0.987369 0.825331 0.552029 0.569062 0.681613 0.523814 0.0947543 0.123951 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 43
Initial state: 0 0.0821107 0.143871 0.69309 0.691889 0.573426 0.555788 0.367774 0.234464 0.97002 0.947157 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 131726 episodes
GETTING ACTION FROM:
action 2, numVisits=131705, meanQ=9.061650, numObservations: 9
action 3, numVisits=11, meanQ=6.907282, numObservations: 5
action 5, numVisits=6, meanQ=4.496667, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.0821107 0.143871 0.69309 0.691889 0.573426 0.555788 0.367774 0.234464 0.97002 0.947157 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 44
Initial state: 0 0.575377 0.173126 0.180491 0.692612 0.795487 0.663473 0.619468 0.583783 0.488793 0.268614 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 131479 episodes
GETTING ACTION FROM:
action 1, numVisits=131471, meanQ=9.141714, numObservations: 9
action 5, numVisits=3, meanQ=1.703333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.575377 0.173126 0.180491 0.692612 0.795487 0.663473 0.619468 0.583783 0.488793 0.268614 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 45
Initial state: 0 0.37297 0.510777 0.627315 0.631007 0.274528 0.0128984 0.0423514 0.0322246 0.885868 0.102737 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 125663 episodes
GETTING ACTION FROM:
action 5, numVisits=125596, meanQ=8.897896, numObservations: 9
action 1, numVisits=62, meanQ=7.612430, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 2 0.37297 0.510777 0.627315 0.631007 0.274528 0.0128984 0.0423514 0.0322246 0.885868 0.102737 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 46
Initial state: 0 0.593645 0.619883 0.576964 0.0950437 0.302273 0.134156 0.334686 0.66845 0.370573 0.575382 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 127331 episodes
GETTING ACTION FROM:
action 5, numVisits=127325, meanQ=9.066718, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.593645 0.619883 0.576964 0.0950437 0.302273 0.134156 0.334686 0.66845 0.370573 0.575382 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=4542, meanQ=9.686785, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.341650, numObservations: 5
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 33785 episodes
GETTING ACTION FROM:
action 1, numVisits=38258, meanQ=10.387188, numObservations: 9
action 0, numVisits=25, meanQ=-1.367192, numObservations: 22
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action 4, numVisits=2, meanQ=-8.128576, numObservations: 1
action -1, numVisits=55, meanQ=-17.987826, numObservations: 43
action: 1
Next state: 1 0.593645 0.619883 0.576964 0.0950437 0.302273 0.134156 0.334686 0.66845 0.370573 0.575382 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 47
Initial state: 0 0.441035 0.0725486 0.442352 0.214014 0.231823 0.425466 0.57869 0.619797 0.0355505 0.694388 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 132265 episodes
GETTING ACTION FROM:
action 5, numVisits=132245, meanQ=8.946008, numObservations: 9
action 1, numVisits=7, meanQ=0.000000, numObservations: 5
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 3, numVisits=4, meanQ=-2.250000, numObservations: 3
action 2, numVisits=2, meanQ=-7.500000, numObservations: 2
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.441035 0.0725486 0.442352 0.214014 0.231823 0.425466 0.57869 0.619797 0.0355505 0.694388 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=13795, meanQ=10.556651, numObservations: 9
action 1, numVisits=16, meanQ=6.031256, numObservations: 8
action 5, numVisits=3, meanQ=4.670033, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 47147 episodes
GETTING ACTION FROM:
action 3, numVisits=60926, meanQ=10.919118, numObservations: 9
action 1, numVisits=16, meanQ=6.031256, numObservations: 8
action 5, numVisits=4, meanQ=2.502525, numObservations: 2
action 0, numVisits=13, meanQ=0.436923, numObservations: 12
action -1, numVisits=4, meanQ=-1.257500, numObservations: 4
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.441035 0.0725486 0.442352 0.214014 0.231823 0.425466 0.57869 0.619797 0.0355505 0.694388 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=7972, meanQ=11.654471, numObservations: 9
action 1, numVisits=11, meanQ=6.727282, numObservations: 6
action 4, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 32138 episodes
GETTING ACTION FROM:
action 2, numVisits=40109, meanQ=11.737160, numObservations: 9
action 1, numVisits=11, meanQ=6.727282, numObservations: 6
action 4, numVisits=4, meanQ=0.432592, numObservations: 3
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.441035 0.0725486 0.442352 0.214014 0.231823 0.425466 0.57869 0.619797 0.0355505 0.694388 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=2513, meanQ=17.040556, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 77528 episodes
GETTING ACTION FROM:
action 1, numVisits=80039, meanQ=16.043950, numObservations: 9
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.441035 0.0725486 0.442352 0.214014 0.231823 0.425466 0.57869 0.619797 0.0355505 0.694388 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 4, numVisits=848, meanQ=21.571105, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 162596 episodes
GETTING ACTION FROM:
action 4, numVisits=163444, meanQ=22.616313, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 0 0.441035 0.0725486 0.442352 0.214014 0.231823 0.425466 0.57869 0.619797 0.0355505 0.694388 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: -4
Updated belief

t = 5
Improving policy...
PLANNING FROM:
action 4, numVisits=137, meanQ=22.788178, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-9.166344, numObservations: 1
action 5, numVisits=1, meanQ=-273.233008, numObservations: 1
action 3, numVisits=1, meanQ=-275.153738, numObservations: 1
action 2, numVisits=1, meanQ=-275.825846, numObservations: 1
Sampled 122431 episodes
GETTING ACTION FROM:
action 4, numVisits=2520, meanQ=22.518548, numObservations: 9
action 0, numVisits=117867, meanQ=-1.840100, numObservations: 220
action -1, numVisits=2183, meanQ=-2.202726, numObservations: 93
action 1, numVisits=1, meanQ=-9.166344, numObservations: 1
action 5, numVisits=1, meanQ=-273.233008, numObservations: 1
action 3, numVisits=1, meanQ=-275.153738, numObservations: 1
action 2, numVisits=1, meanQ=-275.825846, numObservations: 1
action: 4
Next state: 1 0.441035 0.0725486 0.442352 0.214014 0.231823 0.425466 0.57869 0.619797 0.0355505 0.694388 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 3.21978
Run # 48
Initial state: 0 0.598845 0.593744 0.809514 0.735207 0.404914 0.718291 0.718393 0.148577 0.905638 0.0256743 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80102 episodes
GETTING ACTION FROM:
action 0, numVisits=80075, meanQ=14.915442, numObservations: 243
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 2, numVisits=16, meanQ=-1.063725, numObservations: 7
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.598845 0.593744 0.809514 0.735207 0.404914 0.718291 0.718393 0.148577 0.905638 0.0256743 w: 1
Observation: 0 0 2 0 3 0 3 0 2 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=202, meanQ=15.786597, numObservations: 9
action 2, numVisits=2, meanQ=10.495000, numObservations: 1
action 5, numVisits=2, meanQ=10.495000, numObservations: 2
action 4, numVisits=9, meanQ=10.220000, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 159382 episodes
GETTING ACTION FROM:
action 1, numVisits=159583, meanQ=16.107395, numObservations: 9
action 5, numVisits=2, meanQ=10.495000, numObservations: 2
action 4, numVisits=9, meanQ=10.220000, numObservations: 7
action 2, numVisits=3, meanQ=4.670033, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.598845 0.593744 0.809514 0.735207 0.404914 0.718291 0.718393 0.148577 0.905638 0.0256743 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 49
Initial state: 0 0.458426 0.533422 0.595405 0.538429 0.191957 0.818627 0.0632596 0.365307 0.641036 0.247947 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 132640 episodes
GETTING ACTION FROM:
action 2, numVisits=132622, meanQ=8.967096, numObservations: 9
action 5, numVisits=13, meanQ=6.997692, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.458426 0.533422 0.595405 0.538429 0.191957 0.818627 0.0632596 0.365307 0.641036 0.247947 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 50
Initial state: 0 0.307602 0.696807 0.974679 0.109143 0.502455 0.518231 0.0429022 0.554616 0.0258161 0.436033 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 133383 episodes
GETTING ACTION FROM:
action 1, numVisits=133377, meanQ=8.939372, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.307602 0.696807 0.974679 0.109143 0.502455 0.518231 0.0429022 0.554616 0.0258161 0.436033 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=13702, meanQ=10.258076, numObservations: 9
action 5, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 48210 episodes
GETTING ACTION FROM:
action 2, numVisits=48203, meanQ=11.507991, numObservations: 9
action 3, numVisits=13703, meanQ=10.257948, numObservations: 9
action 5, numVisits=5, meanQ=4.598000, numObservations: 3
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=3, meanQ=-1.670000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.307602 0.696807 0.974679 0.109143 0.502455 0.518231 0.0429022 0.554616 0.0258161 0.436033 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=76, meanQ=10.061982, numObservations: 9
action 0, numVisits=15, meanQ=-1.142660, numObservations: 14
action -1, numVisits=14, meanQ=-1.294271, numObservations: 12
action 5, numVisits=1, meanQ=-9.803838, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=36, meanQ=-18.467535, numObservations: 8
action 1, numVisits=1, meanQ=-1069.047324, numObservations: 1
Sampled 112834 episodes
GETTING ACTION FROM:
action 3, numVisits=112910, meanQ=12.864433, numObservations: 9
action 0, numVisits=15, meanQ=-1.142660, numObservations: 14
action -1, numVisits=14, meanQ=-1.294271, numObservations: 12
action 5, numVisits=1, meanQ=-9.803838, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=36, meanQ=-18.467535, numObservations: 8
action 1, numVisits=1, meanQ=-1069.047324, numObservations: 1
action: 3
Next state: 1 0.307602 0.696807 0.974679 0.109143 0.502455 0.518231 0.0429022 0.554616 0.0258161 0.436033 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
[32m ProblemEnvironment.hpp 351: Done.[39m
