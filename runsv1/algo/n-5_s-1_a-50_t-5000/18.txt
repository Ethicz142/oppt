Run # 1
Initial state: 0 0.73638 0.0108414 0.95364 0.277228 0.00610794 0.517388 0.0315247 0.625568 0.529778 0.589788 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 139992 episodes
GETTING ACTION FROM:
action 2, numVisits=139986, meanQ=8.926892, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.73638 0.0108414 0.95364 0.277228 0.00610794 0.517388 0.0315247 0.625568 0.529778 0.589788 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 2
Initial state: 0 0.736767 0.264102 0.814964 0.687397 0.644014 0.38603 0.465817 0.618007 0.306087 0.478275 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 139753 episodes
GETTING ACTION FROM:
action 3, numVisits=139742, meanQ=8.886461, numObservations: 9
action 2, numVisits=6, meanQ=3.165000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.736767 0.264102 0.814964 0.687397 0.644014 0.38603 0.465817 0.618007 0.306087 0.478275 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 3
Initial state: 0 0.193971 0.444393 0.445602 0.588212 0.527895 0.564935 0.128565 0.126327 0.277181 0.949851 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 137097 episodes
GETTING ACTION FROM:
action 4, numVisits=137081, meanQ=8.987126, numObservations: 9
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 2, numVisits=5, meanQ=-2.600000, numObservations: 4
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.193971 0.444393 0.445602 0.588212 0.527895 0.564935 0.128565 0.126327 0.277181 0.949851 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=4070, meanQ=9.669165, numObservations: 9
action 5, numVisits=7, meanQ=6.282857, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 41447 episodes
GETTING ACTION FROM:
action 3, numVisits=44832, meanQ=10.935419, numObservations: 9
action 2, numVisits=584, meanQ=8.099161, numObservations: 9
action 5, numVisits=8, meanQ=4.122500, numObservations: 5
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=56, meanQ=-19.181012, numObservations: 47
action -1, numVisits=47, meanQ=-23.242862, numObservations: 40
action: 3
Next state: 1 0.193971 0.444393 0.445602 0.588212 0.527895 0.564935 0.128565 0.126327 0.277181 0.949851 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 4
Initial state: 0 0.509124 0.511481 0.490537 0.627822 0.198208 0.712183 0.93026 0.642634 0.0913755 0.190735 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 141986 episodes
GETTING ACTION FROM:
action 1, numVisits=141974, meanQ=9.023825, numObservations: 9
action 2, numVisits=4, meanQ=-0.500000, numObservations: 4
action 5, numVisits=4, meanQ=-0.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.509124 0.511481 0.490537 0.627822 0.198208 0.712183 0.93026 0.642634 0.0913755 0.190735 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 5
Initial state: 0 0.508007 0.427122 0.260725 0.483799 0.536813 0.515525 0.852712 0.452268 0.451307 0.230757 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 137955 episodes
GETTING ACTION FROM:
action 5, numVisits=137936, meanQ=8.682294, numObservations: 9
action 1, numVisits=14, meanQ=1.857157, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.508007 0.427122 0.260725 0.483799 0.536813 0.515525 0.852712 0.452268 0.451307 0.230757 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=21817, meanQ=10.229343, numObservations: 9
action 3, numVisits=28, meanQ=8.361075, numObservations: 9
action 2, numVisits=10, meanQ=7.674000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 34753 episodes
GETTING ACTION FROM:
action 4, numVisits=56499, meanQ=10.493943, numObservations: 9
action 2, numVisits=12, meanQ=4.561667, numObservations: 5
action -1, numVisits=6, meanQ=-1.010000, numObservations: 6
action 0, numVisits=5, meanQ=-1.208000, numObservations: 5
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=87, meanQ=-3.643040, numObservations: 9
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 4
Next state: 2 0.508007 0.427122 0.260725 0.483799 0.536813 0.515525 0.852712 0.452268 0.451307 0.230757 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 6
Initial state: 0 0.0180021 0.979276 0.623687 0.749414 0.597782 0.508018 0.556024 0.569178 0.0241233 0.836124 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 141570 episodes
GETTING ACTION FROM:
action 1, numVisits=141559, meanQ=8.878469, numObservations: 9
action 3, numVisits=4, meanQ=-0.500000, numObservations: 4
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.0180021 0.979276 0.623687 0.749414 0.597782 0.508018 0.556024 0.569178 0.0241233 0.836124 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 7
Initial state: 0 0.0992833 0.50577 0.030773 0.544473 0.542221 0.550028 0.164167 0.779217 0.822549 0.233306 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 142358 episodes
GETTING ACTION FROM:
action 1, numVisits=142348, meanQ=8.888404, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.0992833 0.50577 0.030773 0.544473 0.542221 0.550028 0.164167 0.779217 0.822549 0.233306 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=4162, meanQ=9.934987, numObservations: 9
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 36534 episodes
GETTING ACTION FROM:
action 2, numVisits=31677, meanQ=9.952917, numObservations: 9
action 3, numVisits=8960, meanQ=9.509396, numObservations: 9
action 4, numVisits=24, meanQ=6.215565, numObservations: 7
action 0, numVisits=24, meanQ=-1.340413, numObservations: 21
action -1, numVisits=21, meanQ=-1.434286, numObservations: 20
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.0992833 0.50577 0.030773 0.544473 0.542221 0.550028 0.164167 0.779217 0.822549 0.233306 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=684, meanQ=11.392428, numObservations: 9
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=67, meanQ=-15.214742, numObservations: 42
action 3, numVisits=22, meanQ=-28.188683, numObservations: 5
action 0, numVisits=8, meanQ=-132.031339, numObservations: 6
Sampled 32064 episodes
GETTING ACTION FROM:
action 4, numVisits=32748, meanQ=11.564222, numObservations: 9
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=67, meanQ=-15.214742, numObservations: 42
action 3, numVisits=22, meanQ=-28.188683, numObservations: 5
action 0, numVisits=8, meanQ=-132.031339, numObservations: 6
action: 4
Next state: 0 0.0992833 0.50577 0.030773 0.544473 0.542221 0.550028 0.164167 0.779217 0.822549 0.233306 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 5, numVisits=915, meanQ=15.320767, numObservations: 9
action 3, numVisits=69, meanQ=4.786315, numObservations: 9
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action -1, numVisits=5, meanQ=-3.590959, numObservations: 4
action 4, numVisits=1, meanQ=-13.159634, numObservations: 1
action 2, numVisits=1, meanQ=-13.757471, numObservations: 1
action 1, numVisits=1, meanQ=-1055.482900, numObservations: 1
Sampled 58942 episodes
GETTING ACTION FROM:
action 5, numVisits=59857, meanQ=16.474684, numObservations: 9
action 3, numVisits=69, meanQ=4.786315, numObservations: 9
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action -1, numVisits=5, meanQ=-3.590959, numObservations: 4
action 4, numVisits=1, meanQ=-13.159634, numObservations: 1
action 2, numVisits=1, meanQ=-13.757471, numObservations: 1
action 1, numVisits=1, meanQ=-1055.482900, numObservations: 1
action: 5
Next state: 2 0.0992833 0.50577 0.030773 0.544473 0.542221 0.550028 0.164167 0.779217 0.822549 0.233306 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -22.5537
Run # 8
Initial state: 0 0.781719 0.709412 0.666893 0.229492 0.474557 0.507735 0.714907 0.484616 0.589328 0.156573 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 141120 episodes
GETTING ACTION FROM:
action 3, numVisits=141106, meanQ=8.755430, numObservations: 9
action 5, numVisits=9, meanQ=6.456667, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.781719 0.709412 0.666893 0.229492 0.474557 0.507735 0.714907 0.484616 0.589328 0.156573 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 9
Initial state: 0 0.617224 0.154839 0.0893463 0.117523 0.555238 0.581927 0.107389 0.508912 0.37847 0.414431 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 140989 episodes
GETTING ACTION FROM:
action 2, numVisits=140978, meanQ=8.938091, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=2, meanQ=-7.500000, numObservations: 2
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.617224 0.154839 0.0893463 0.117523 0.555238 0.581927 0.107389 0.508912 0.37847 0.414431 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=22264, meanQ=10.292123, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 39266 episodes
GETTING ACTION FROM:
action 3, numVisits=61520, meanQ=9.716743, numObservations: 9
action 0, numVisits=6, meanQ=-1.175000, numObservations: 6
action -1, numVisits=5, meanQ=-1.406000, numObservations: 5
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.617224 0.154839 0.0893463 0.117523 0.555238 0.581927 0.107389 0.508912 0.37847 0.414431 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 10
Initial state: 0 0.622746 0.281355 0.371632 0.829839 0.485993 0.512538 0.282557 0.143754 0.691313 0.610222 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 141929 episodes
GETTING ACTION FROM:
action 1, numVisits=141911, meanQ=8.895471, numObservations: 9
action 3, numVisits=7, meanQ=5.141429, numObservations: 6
action 2, numVisits=5, meanQ=4.598000, numObservations: 4
action 4, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.622746 0.281355 0.371632 0.829839 0.485993 0.512538 0.282557 0.143754 0.691313 0.610222 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 11
Initial state: 0 0.852799 0.377669 0.703177 0.341208 0.0779411 0.686917 0.492073 0.528622 0.899006 0.0360698 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 142540 episodes
GETTING ACTION FROM:
action 4, numVisits=142529, meanQ=8.936937, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=4, meanQ=-2.250000, numObservations: 3
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.852799 0.377669 0.703177 0.341208 0.0779411 0.686917 0.492073 0.528622 0.899006 0.0360698 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 12
Initial state: 0 0.219562 0.87102 0.879057 0.399361 0.808461 0.00616583 0.540848 0.516965 0.934965 0.812462 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 140109 episodes
GETTING ACTION FROM:
action 4, numVisits=140103, meanQ=8.861601, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.219562 0.87102 0.879057 0.399361 0.808461 0.00616583 0.540848 0.516965 0.934965 0.812462 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 13
Initial state: 0 0.5035 0.568377 0.0011782 0.0928175 0.447109 0.868764 0.454437 0.232493 0.183671 0.446951 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 140715 episodes
GETTING ACTION FROM:
action 3, numVisits=140679, meanQ=8.749564, numObservations: 9
action -1, numVisits=15, meanQ=-1.274660, numObservations: 14
action 0, numVisits=10, meanQ=-1.406990, numObservations: 9
action 5, numVisits=7, meanQ=-2.000000, numObservations: 6
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=2, meanQ=-4.499950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.5035 0.568377 0.0011782 0.0928175 0.447109 0.868764 0.454437 0.232493 0.183671 0.446951 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=4097, meanQ=9.303930, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 41046 episodes
GETTING ACTION FROM:
action 2, numVisits=45100, meanQ=10.342477, numObservations: 9
action 0, numVisits=18, meanQ=-1.395000, numObservations: 18
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 1
action 5, numVisits=2, meanQ=-7.005000, numObservations: 2
action 4, numVisits=2, meanQ=-9.454447, numObservations: 1
action -1, numVisits=24, meanQ=-44.700326, numObservations: 23
action: 2
Next state: 0 0.5035 0.568377 0.0011782 0.0928175 0.447109 0.868764 0.454437 0.232493 0.183671 0.446951 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=532, meanQ=2.752819, numObservations: 9
action 1, numVisits=82, meanQ=-1.827855, numObservations: 9
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=2, meanQ=-8.091419, numObservations: 2
action -1, numVisits=29, meanQ=-36.450779, numObservations: 22
action 0, numVisits=19, meanQ=-56.203769, numObservations: 17
action 2, numVisits=2, meanQ=-525.793733, numObservations: 1
Sampled 28716 episodes
GETTING ACTION FROM:
action 5, numVisits=29247, meanQ=9.261543, numObservations: 9
action 1, numVisits=82, meanQ=-1.827855, numObservations: 9
action 3, numVisits=2, meanQ=-4.004950, numObservations: 1
action 4, numVisits=2, meanQ=-8.091419, numObservations: 2
action -1, numVisits=29, meanQ=-36.450779, numObservations: 22
action 0, numVisits=19, meanQ=-56.203769, numObservations: 17
action 2, numVisits=2, meanQ=-525.793733, numObservations: 1
action: 5
Next state: 0 0.5035 0.568377 0.0011782 0.0928175 0.447109 0.868764 0.454437 0.232493 0.183671 0.446951 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=1957, meanQ=19.798938, numObservations: 9
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=2, meanQ=-7.005000, numObservations: 2
action 0, numVisits=70, meanQ=-7.474101, numObservations: 42
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=45, meanQ=-19.132674, numObservations: 22
Sampled 57856 episodes
GETTING ACTION FROM:
action 1, numVisits=59813, meanQ=16.625906, numObservations: 9
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=2, meanQ=-7.005000, numObservations: 2
action 0, numVisits=70, meanQ=-7.474101, numObservations: 42
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=45, meanQ=-19.132674, numObservations: 22
action: 1
Next state: 1 0.5035 0.568377 0.0011782 0.0928175 0.447109 0.868764 0.454437 0.232493 0.183671 0.446951 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 11.4068
Run # 14
Initial state: 0 0.395714 0.279342 0.550546 0.520944 0.433439 0.026967 0.0289109 0.96992 0.966141 0.42168 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 137846 episodes
GETTING ACTION FROM:
action 4, numVisits=137840, meanQ=8.952353, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.395714 0.279342 0.550546 0.520944 0.433439 0.026967 0.0289109 0.96992 0.966141 0.42168 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 15
Initial state: 0 0.926277 0.407647 0.386441 0.209825 0.616842 0.463527 0.56549 0.507356 0.0939522 0.286624 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 141668 episodes
GETTING ACTION FROM:
action 4, numVisits=141660, meanQ=8.948659, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 1 0.926277 0.407647 0.386441 0.209825 0.616842 0.463527 0.56549 0.507356 0.0939522 0.286624 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 16
Initial state: 0 0.420774 0.0779087 0.23161 0.909848 0.013366 0.827677 0.0814085 0.24334 0.509727 0.52508 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 142927 episodes
GETTING ACTION FROM:
action 3, numVisits=142913, meanQ=9.016220, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 2, numVisits=4, meanQ=-2.250000, numObservations: 3
action 1, numVisits=2, meanQ=-4.000000, numObservations: 2
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.420774 0.0779087 0.23161 0.909848 0.013366 0.827677 0.0814085 0.24334 0.509727 0.52508 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 17
Initial state: 0 0.36661 0.936715 0.554985 0.60907 0.929181 0.333842 0.552602 0.243454 0.365523 0.0719837 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 140933 episodes
GETTING ACTION FROM:
action 1, numVisits=140923, meanQ=8.969465, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.36661 0.936715 0.554985 0.60907 0.929181 0.333842 0.552602 0.243454 0.365523 0.0719837 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=13547, meanQ=10.684035, numObservations: 9
action 4, numVisits=3, meanQ=4.670033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 50283 episodes
GETTING ACTION FROM:
action 3, numVisits=63712, meanQ=11.477541, numObservations: 9
action 4, numVisits=113, meanQ=1.224251, numObservations: 9
action -1, numVisits=5, meanQ=-1.208000, numObservations: 5
action 0, numVisits=5, meanQ=-1.406000, numObservations: 5
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.36661 0.936715 0.554985 0.60907 0.929181 0.333842 0.552602 0.243454 0.365523 0.0719837 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 18
Initial state: 0 0.0584682 0.283554 0.505491 0.587927 0.832638 0.349397 0.246722 0.150604 0.274873 0.381681 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 142843 episodes
GETTING ACTION FROM:
action 1, numVisits=142835, meanQ=8.896089, numObservations: 9
action 3, numVisits=3, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.0584682 0.283554 0.505491 0.587927 0.832638 0.349397 0.246722 0.150604 0.274873 0.381681 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=22780, meanQ=10.338715, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 44911 episodes
GETTING ACTION FROM:
action 4, numVisits=67638, meanQ=9.536776, numObservations: 9
action 2, numVisits=13, meanQ=3.387772, numObservations: 7
action 5, numVisits=8, meanQ=3.323486, numObservations: 6
action 3, numVisits=4, meanQ=-0.046112, numObservations: 3
action 0, numVisits=11, meanQ=-1.100000, numObservations: 11
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=24, meanQ=-44.326510, numObservations: 22
action: 4
Next state: 0 0.0584682 0.283554 0.505491 0.587927 0.832638 0.349397 0.246722 0.150604 0.274873 0.381681 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=9282, meanQ=12.258423, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 43547 episodes
GETTING ACTION FROM:
action 2, numVisits=52827, meanQ=11.304244, numObservations: 9
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.0584682 0.283554 0.505491 0.587927 0.832638 0.349397 0.246722 0.150604 0.274873 0.381681 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 19
Initial state: 0 0.654804 0.193511 0.762014 0.918977 0.485645 0.559566 0.389661 0.985717 0.0175088 0.376544 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 140099 episodes
GETTING ACTION FROM:
action 2, numVisits=140091, meanQ=8.602418, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.654804 0.193511 0.762014 0.918977 0.485645 0.559566 0.389661 0.985717 0.0175088 0.376544 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 20
Initial state: 0 0.311703 0.296635 0.531817 0.152528 0.122693 0.705799 0.534967 0.507446 0.685591 0.230096 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 140292 episodes
GETTING ACTION FROM:
action 4, numVisits=140283, meanQ=8.979566, numObservations: 9
action 2, numVisits=4, meanQ=2.500050, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 1 0.311703 0.296635 0.531817 0.152528 0.122693 0.705799 0.534967 0.507446 0.685591 0.230096 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 21
Initial state: 0 0.422975 0.745518 0.666509 0.663193 0.414209 0.0372572 0.539269 0.510447 0.676438 0.144682 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 127989 episodes
GETTING ACTION FROM:
action 2, numVisits=127967, meanQ=9.508599, numObservations: 9
action 4, numVisits=17, meanQ=1.535300, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.422975 0.745518 0.666509 0.663193 0.414209 0.0372572 0.539269 0.510447 0.676438 0.144682 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 22
Initial state: 0 0.311909 0.882133 0.375638 0.889156 0.160348 0.494991 0.467163 0.52311 0.313805 0.267652 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 141641 episodes
GETTING ACTION FROM:
action 1, numVisits=141631, meanQ=9.002040, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.311909 0.882133 0.375638 0.889156 0.160348 0.494991 0.467163 0.52311 0.313805 0.267652 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=13514, meanQ=10.118696, numObservations: 9
action 1, numVisits=7, meanQ=7.430043, numObservations: 2
action 4, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 51326 episodes
GETTING ACTION FROM:
action 2, numVisits=64814, meanQ=11.858533, numObservations: 9
action 1, numVisits=11, meanQ=10.819127, numObservations: 3
action 4, numVisits=15, meanQ=4.141795, numObservations: 8
action -1, numVisits=6, meanQ=-1.340000, numObservations: 6
action 0, numVisits=5, meanQ=-1.406000, numObservations: 5
action 3, numVisits=2, meanQ=-6.731853, numObservations: 2
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.311909 0.882133 0.375638 0.889156 0.160348 0.494991 0.467163 0.52311 0.313805 0.267652 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=4374, meanQ=10.000337, numObservations: 9
action 4, numVisits=13, meanQ=4.461554, numObservations: 7
action 5, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 30032 episodes
GETTING ACTION FROM:
action 3, numVisits=34406, meanQ=13.710412, numObservations: 9
action 4, numVisits=13, meanQ=4.461554, numObservations: 7
action 5, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.311909 0.882133 0.375638 0.889156 0.160348 0.494991 0.467163 0.52311 0.313805 0.267652 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=730, meanQ=13.348938, numObservations: 9
action 3, numVisits=2350, meanQ=12.372605, numObservations: 9
action 0, numVisits=7, meanQ=-1.294271, numObservations: 6
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=23, meanQ=-16.618899, numObservations: 11
Sampled 67431 episodes
GETTING ACTION FROM:
action 5, numVisits=67428, meanQ=19.980102, numObservations: 9
action 2, numVisits=734, meanQ=13.393408, numObservations: 9
action 3, numVisits=2350, meanQ=12.372605, numObservations: 9
action 0, numVisits=7, meanQ=-1.294271, numObservations: 6
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=23, meanQ=-16.618899, numObservations: 11
action: 5
Next state: 0 0.311909 0.882133 0.375638 0.889156 0.160348 0.494991 0.467163 0.52311 0.313805 0.267652 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 1, numVisits=1, meanQ=24.000000, numObservations: 1
action 4, numVisits=1643, meanQ=22.263395, numObservations: 9
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 5, numVisits=1, meanQ=-10.263751, numObservations: 1
action -1, numVisits=2, meanQ=-179.323016, numObservations: 1
action 3, numVisits=1, meanQ=-359.455428, numObservations: 1
action 2, numVisits=1, meanQ=-364.468185, numObservations: 1
Sampled 93788 episodes
GETTING ACTION FROM:
action 4, numVisits=95429, meanQ=22.131886, numObservations: 9
action 1, numVisits=3, meanQ=14.666667, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 5, numVisits=1, meanQ=-10.263751, numObservations: 1
action -1, numVisits=2, meanQ=-179.323016, numObservations: 1
action 3, numVisits=1, meanQ=-359.455428, numObservations: 1
action 2, numVisits=1, meanQ=-364.468185, numObservations: 1
action: 4
Next state: 1 0.311909 0.882133 0.375638 0.889156 0.160348 0.494991 0.467163 0.52311 0.313805 0.267652 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.29271
Run # 23
Initial state: 0 0.0585195 0.353854 0.412064 0.614606 0.337267 0.860804 0.517131 0.585772 0.663933 0.918123 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 81900 episodes
GETTING ACTION FROM:
action 0, numVisits=81878, meanQ=15.495470, numObservations: 243
action -1, numVisits=11, meanQ=-1.010000, numObservations: 11
action 1, numVisits=6, meanQ=-3.481667, numObservations: 4
action 4, numVisits=2, meanQ=-7.500000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.0585195 0.353854 0.412064 0.614606 0.337267 0.860804 0.517131 0.585772 0.663933 0.918123 w: 1
Observation: 0 0 1 0 3 0 3 0 2 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=431, meanQ=21.626449, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 189537 episodes
GETTING ACTION FROM:
action 4, numVisits=189968, meanQ=22.128662, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 0 0.0585195 0.353854 0.412064 0.614606 0.337267 0.860804 0.517131 0.585772 0.663933 0.918123 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=11597, meanQ=23.069362, numObservations: 9
action 5, numVisits=3, meanQ=12.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 189972 episodes
GETTING ACTION FROM:
action 4, numVisits=11651, meanQ=23.072785, numObservations: 9
action 5, numVisits=189921, meanQ=19.859601, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.0585195 0.353854 0.412064 0.614606 0.337267 0.860804 0.517131 0.585772 0.663933 0.918123 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 17.5624
Run # 24
Initial state: 0 0.223143 0.134927 0.65402 0.189107 0.102284 0.371635 0.502008 0.558854 0.318155 0.230327 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 140328 episodes
GETTING ACTION FROM:
action 5, numVisits=140322, meanQ=8.831605, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.223143 0.134927 0.65402 0.189107 0.102284 0.371635 0.502008 0.558854 0.318155 0.230327 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=22460, meanQ=9.840105, numObservations: 9
action 4, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 44869 episodes
GETTING ACTION FROM:
action 3, numVisits=67265, meanQ=9.764773, numObservations: 9
action 4, numVisits=52, meanQ=6.983405, numObservations: 9
action 0, numVisits=8, meanQ=-1.133750, numObservations: 8
action -1, numVisits=7, meanQ=-1.294271, numObservations: 6
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action 1, numVisits=2, meanQ=-530.667566, numObservations: 1
action: 3
Next state: 0 0.223143 0.134927 0.65402 0.189107 0.102284 0.371635 0.502008 0.558854 0.318155 0.230327 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action -1, numVisits=7938, meanQ=13.763722, numObservations: 203
action 0, numVisits=40, meanQ=-1.704980, numObservations: 32
action 5, numVisits=2, meanQ=-4.994950, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action 3, numVisits=2, meanQ=-7.005000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 11495 episodes
GETTING ACTION FROM:
action -1, numVisits=19433, meanQ=10.510630, numObservations: 231
action 0, numVisits=40, meanQ=-1.704980, numObservations: 32
action 5, numVisits=2, meanQ=-4.994950, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action 3, numVisits=2, meanQ=-7.005000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.223143 0.134927 0.65402 0.189107 0.102284 0.371635 0.502008 0.558854 0.318155 0.230327 w: 1
Observation: 0 1 0 3 0 1 0 2 0 1 0 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 4, numVisits=451, meanQ=22.254315, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 86708 episodes
GETTING ACTION FROM:
action 4, numVisits=87159, meanQ=21.643150, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.223143 0.134927 0.65402 0.189107 0.102284 0.371635 0.502008 0.558854 0.318155 0.230327 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 13.367
Run # 25
Initial state: 0 0.491462 0.561911 0.313704 0.77844 0.702309 0.766575 0.68668 0.783753 0.853664 0.176272 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 141806 episodes
GETTING ACTION FROM:
action 1, numVisits=141774, meanQ=8.957332, numObservations: 9
action 5, numVisits=27, meanQ=5.040759, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.491462 0.561911 0.313704 0.77844 0.702309 0.766575 0.68668 0.783753 0.853664 0.176272 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 26
Initial state: 0 0.994445 0.88802 0.142194 0.752183 0.164212 0.766543 0.523369 0.518479 0.461709 0.807428 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 141353 episodes
GETTING ACTION FROM:
action 4, numVisits=141342, meanQ=8.715920, numObservations: 9
action 3, numVisits=6, meanQ=4.331667, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.994445 0.88802 0.142194 0.752183 0.164212 0.766543 0.523369 0.518479 0.461709 0.807428 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 27
Initial state: 0 0.907633 0.00574033 0.227806 0.412546 0.669623 0.380319 0.548773 0.531017 0.304221 0.8188 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 141841 episodes
GETTING ACTION FROM:
action 5, numVisits=141821, meanQ=8.705043, numObservations: 9
action 2, numVisits=8, meanQ=4.501263, numObservations: 5
action 4, numVisits=3, meanQ=3.330000, numObservations: 3
action 1, numVisits=4, meanQ=2.502525, numObservations: 3
action 3, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 5
Next state: 1 0.907633 0.00574033 0.227806 0.412546 0.669623 0.380319 0.548773 0.531017 0.304221 0.8188 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 28
Initial state: 0 0.845045 0.33282 0.827959 0.211303 0.54123 0.522706 0.018684 0.0596675 0.200007 0.973753 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 142666 episodes
GETTING ACTION FROM:
action 5, numVisits=142656, meanQ=8.961232, numObservations: 9
action 3, numVisits=3, meanQ=3.330000, numObservations: 3
action 4, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.845045 0.33282 0.827959 0.211303 0.54123 0.522706 0.018684 0.0596675 0.200007 0.973753 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=13605, meanQ=10.143437, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 47927 episodes
GETTING ACTION FROM:
action 3, numVisits=61375, meanQ=10.462081, numObservations: 9
action 1, numVisits=79, meanQ=8.130881, numObservations: 9
action -1, numVisits=5, meanQ=-1.406000, numObservations: 5
action 0, numVisits=4, meanQ=-1.505000, numObservations: 4
action 4, numVisits=73, meanQ=-2.525788, numObservations: 9
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.845045 0.33282 0.827959 0.211303 0.54123 0.522706 0.018684 0.0596675 0.200007 0.973753 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 29
Initial state: 0 0.480234 0.515166 0.135942 0.0921538 0.478326 0.767679 0.917705 0.198595 0.297906 0.998119 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 140434 episodes
GETTING ACTION FROM:
action 5, numVisits=140377, meanQ=8.899569, numObservations: 9
action 4, numVisits=30, meanQ=5.202347, numObservations: 9
action 2, numVisits=16, meanQ=4.505637, numObservations: 7
action 1, numVisits=8, meanQ=4.122500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.480234 0.515166 0.135942 0.0921538 0.478326 0.767679 0.917705 0.198595 0.297906 0.998119 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=1177, meanQ=9.823400, numObservations: 9
action 1, numVisits=3, meanQ=3.330000, numObservations: 3
action 2, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 177014 episodes
GETTING ACTION FROM:
action 4, numVisits=178187, meanQ=13.823025, numObservations: 9
action 1, numVisits=3, meanQ=3.330000, numObservations: 3
action 2, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=3, meanQ=-1.340000, numObservations: 3
action 0, numVisits=3, meanQ=-1.670000, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 2 0.480234 0.515166 0.135942 0.0921538 0.478326 0.767679 0.917705 0.198595 0.297906 0.998119 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 30
Initial state: 0 0.852331 0.975871 0.941883 0.572548 0.241367 0.0236897 0.522294 0.53243 0.457644 0.147274 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 141620 episodes
GETTING ACTION FROM:
action 1, numVisits=141614, meanQ=8.947182, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.852331 0.975871 0.941883 0.572548 0.241367 0.0236897 0.522294 0.53243 0.457644 0.147274 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 31
Initial state: 0 0.501116 0.559838 0.246307 0.319012 0.340508 0.225653 0.246664 0.790981 0.886337 0.0242791 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 135768 episodes
GETTING ACTION FROM:
action 1, numVisits=135757, meanQ=8.916362, numObservations: 9
action 3, numVisits=4, meanQ=-0.252500, numObservations: 4
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.501116 0.559838 0.246307 0.319012 0.340508 0.225653 0.246664 0.790981 0.886337 0.0242791 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 32
Initial state: 0 0.813485 0.6699 0.846323 0.954105 0.425757 0.285029 0.278982 0.509411 0.548729 0.587575 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 141268 episodes
GETTING ACTION FROM:
action 4, numVisits=141260, meanQ=8.809230, numObservations: 9
action 3, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 0 0.813485 0.6699 0.846323 0.954105 0.425757 0.285029 0.278982 0.509411 0.548729 0.587575 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=4061, meanQ=9.869936, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 33021 episodes
GETTING ACTION FROM:
action 5, numVisits=36840, meanQ=9.002146, numObservations: 9
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=2, meanQ=-8.179783, numObservations: 2
action -1, numVisits=101, meanQ=-8.847421, numObservations: 66
action 0, numVisits=132, meanQ=-9.234798, numObservations: 91
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=11, meanQ=-89.012704, numObservations: 7
action: 5
Next state: 1 0.813485 0.6699 0.846323 0.954105 0.425757 0.285029 0.278982 0.509411 0.548729 0.587575 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 33
Initial state: 0 0.764559 0.174718 0.550809 0.113314 0.917555 0.749862 0.560334 0.610062 0.481997 0.727755 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 140510 episodes
GETTING ACTION FROM:
action 4, numVisits=140499, meanQ=8.862376, numObservations: 9
action 3, numVisits=6, meanQ=4.165017, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.764559 0.174718 0.550809 0.113314 0.917555 0.749862 0.560334 0.610062 0.481997 0.727755 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 34
Initial state: 0 0.568339 0.283969 0.0151435 0.774364 0.857572 0.140166 0.541553 0.551158 0.264221 0.84279 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 140960 episodes
GETTING ACTION FROM:
action 2, numVisits=140952, meanQ=8.858582, numObservations: 9
action 3, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.568339 0.283969 0.0151435 0.774364 0.857572 0.140166 0.541553 0.551158 0.264221 0.84279 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 35
Initial state: 0 0.531984 0.541716 0.301626 0.786884 0.826185 0.553845 0.15152 0.288576 0.40825 0.168733 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 139715 episodes
GETTING ACTION FROM:
action 5, numVisits=139703, meanQ=8.981176, numObservations: 9
action 1, numVisits=5, meanQ=3.622000, numObservations: 4
action 2, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.531984 0.541716 0.301626 0.786884 0.826185 0.553845 0.15152 0.288576 0.40825 0.168733 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=22211, meanQ=10.330320, numObservations: 9
action 1, numVisits=4, meanQ=6.500000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 54566 episodes
GETTING ACTION FROM:
action 2, numVisits=76666, meanQ=9.493427, numObservations: 9
action 1, numVisits=74, meanQ=7.169978, numObservations: 9
action 3, numVisits=27, meanQ=5.905290, numObservations: 9
action 0, numVisits=9, meanQ=-1.010000, numObservations: 9
action -1, numVisits=8, meanQ=-1.257500, numObservations: 8
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.531984 0.541716 0.301626 0.786884 0.826185 0.553845 0.15152 0.288576 0.40825 0.168733 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=5480, meanQ=13.674223, numObservations: 9
action 4, numVisits=9, meanQ=-0.621382, numObservations: 6
action 0, numVisits=15, meanQ=-2.417384, numObservations: 13
action -1, numVisits=13, meanQ=-2.769119, numObservations: 11
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=5, meanQ=-208.794192, numObservations: 3
Sampled 33822 episodes
GETTING ACTION FROM:
action 3, numVisits=39302, meanQ=14.664581, numObservations: 9
action 4, numVisits=9, meanQ=-0.621382, numObservations: 6
action 0, numVisits=15, meanQ=-2.417384, numObservations: 13
action -1, numVisits=13, meanQ=-2.769119, numObservations: 11
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=5, meanQ=-208.794192, numObservations: 3
action: 3
Next state: 2 0.531984 0.541716 0.301626 0.786884 0.826185 0.553845 0.15152 0.288576 0.40825 0.168733 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -18.7411
Run # 36
Initial state: 0 0.716445 0.797594 0.50577 0.999585 0.287944 0.992108 0.538303 0.612307 0.137195 0.942623 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 141857 episodes
GETTING ACTION FROM:
action 3, numVisits=141840, meanQ=9.014191, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=5, meanQ=-1.200000, numObservations: 5
action 4, numVisits=5, meanQ=-1.200000, numObservations: 4
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.716445 0.797594 0.50577 0.999585 0.287944 0.992108 0.538303 0.612307 0.137195 0.942623 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=13734, meanQ=10.412292, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 50326 episodes
GETTING ACTION FROM:
action 2, numVisits=49947, meanQ=11.174480, numObservations: 9
action 4, numVisits=14103, meanQ=10.402888, numObservations: 9
action 5, numVisits=4, meanQ=0.561689, numObservations: 3
action 0, numVisits=5, meanQ=-1.010000, numObservations: 5
action -1, numVisits=5, meanQ=-1.208000, numObservations: 4
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.716445 0.797594 0.50577 0.999585 0.287944 0.992108 0.538303 0.612307 0.137195 0.942623 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 37
Initial state: 0 0.38153 0.52942 0.525166 0.612591 0.692438 0.734619 0.969296 0.961028 0.301689 0.0498366 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 141525 episodes
GETTING ACTION FROM:
action 4, numVisits=141516, meanQ=8.764680, numObservations: 9
action 1, numVisits=4, meanQ=-0.500000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 1 0.38153 0.52942 0.525166 0.612591 0.692438 0.734619 0.969296 0.961028 0.301689 0.0498366 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 38
Initial state: 0 0.200581 0.676424 0.699352 0.205493 0.724993 0.585202 0.542889 0.585984 0.361239 0.830297 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 142275 episodes
GETTING ACTION FROM:
action 2, numVisits=142252, meanQ=9.045922, numObservations: 9
action 1, numVisits=14, meanQ=4.787150, numObservations: 7
action 3, numVisits=3, meanQ=3.000000, numObservations: 2
action 4, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 2 0.200581 0.676424 0.699352 0.205493 0.724993 0.585202 0.542889 0.585984 0.361239 0.830297 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 39
Initial state: 0 0.61641 0.429582 0.98325 0.0335579 0.210513 0.652344 0.503107 0.568745 0.594573 0.728036 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 141474 episodes
GETTING ACTION FROM:
action 3, numVisits=141429, meanQ=8.955256, numObservations: 9
action 1, numVisits=17, meanQ=6.631176, numObservations: 7
action 4, numVisits=13, meanQ=6.616162, numObservations: 6
action 2, numVisits=9, meanQ=6.221111, numObservations: 6
action 5, numVisits=4, meanQ=0.525000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.61641 0.429582 0.98325 0.0335579 0.210513 0.652344 0.503107 0.568745 0.594573 0.728036 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=13462, meanQ=10.309577, numObservations: 9
action 2, numVisits=3, meanQ=5.330033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 48095 episodes
GETTING ACTION FROM:
action 1, numVisits=61539, meanQ=11.878684, numObservations: 9
action 2, numVisits=14, meanQ=6.418753, numObservations: 8
action -1, numVisits=5, meanQ=-1.208000, numObservations: 5
action 0, numVisits=4, meanQ=-1.505000, numObservations: 4
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.61641 0.429582 0.98325 0.0335579 0.210513 0.652344 0.503107 0.568745 0.594573 0.728036 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 40
Initial state: 0 0.555318 0.50383 0.575818 0.949238 0.00206792 0.419937 0.753532 0.742381 0.167682 0.326987 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 141593 episodes
GETTING ACTION FROM:
action 3, numVisits=141571, meanQ=8.872970, numObservations: 9
action 1, numVisits=15, meanQ=1.133333, numObservations: 6
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.555318 0.50383 0.575818 0.949238 0.00206792 0.419937 0.753532 0.742381 0.167682 0.326987 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=2390, meanQ=9.752497, numObservations: 9
action -1, numVisits=6, meanQ=-1.010000, numObservations: 6
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 5, numVisits=6, meanQ=-1.171667, numObservations: 4
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 51583 episodes
GETTING ACTION FROM:
action 4, numVisits=53934, meanQ=8.088126, numObservations: 9
action 5, numVisits=6, meanQ=-1.171667, numObservations: 4
action 0, numVisits=28, meanQ=-2.011955, numObservations: 22
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=23, meanQ=-46.911731, numObservations: 20
action: 4
Next state: 1 0.555318 0.50383 0.575818 0.949238 0.00206792 0.419937 0.753532 0.742381 0.167682 0.326987 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 41
Initial state: 0 0.275403 0.389848 0.162779 0.0417967 0.536703 0.552847 0.705897 0.183403 0.830064 0.00551732 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 128709 episodes
GETTING ACTION FROM:
action 5, numVisits=128698, meanQ=9.572412, numObservations: 9
action 1, numVisits=6, meanQ=3.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.275403 0.389848 0.162779 0.0417967 0.536703 0.552847 0.705897 0.183403 0.830064 0.00551732 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 42
Initial state: 0 0.461108 0.499664 0.265069 0.26323 0.587542 0.925502 0.2087 0.960664 0.344461 0.903724 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 141456 episodes
GETTING ACTION FROM:
action 4, numVisits=141444, meanQ=8.848192, numObservations: 9
action 2, numVisits=7, meanQ=2.148600, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.461108 0.499664 0.265069 0.26323 0.587542 0.925502 0.2087 0.960664 0.344461 0.903724 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 43
Initial state: 0 0.55327 0.579174 0.503978 0.334457 0.41793 0.589869 0.0895994 0.109937 0.886988 0.821711 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 139896 episodes
GETTING ACTION FROM:
action 2, numVisits=139890, meanQ=8.857990, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.55327 0.579174 0.503978 0.334457 0.41793 0.589869 0.0895994 0.109937 0.886988 0.821711 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 44
Initial state: 0 0.679818 0.945448 0.460927 0.575881 0.574922 0.374617 0.650169 0.426281 0.590188 0.197857 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 141953 episodes
GETTING ACTION FROM:
action 2, numVisits=141947, meanQ=9.114075, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.679818 0.945448 0.460927 0.575881 0.574922 0.374617 0.650169 0.426281 0.590188 0.197857 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 45
Initial state: 0 0.58711 0.941181 0.0503175 0.21811 0.56132 0.521577 0.121499 0.415658 0.0369974 0.455574 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 141693 episodes
GETTING ACTION FROM:
action 1, numVisits=141685, meanQ=8.775560, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.58711 0.941181 0.0503175 0.21811 0.56132 0.521577 0.121499 0.415658 0.0369974 0.455574 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 46
Initial state: 0 0.171942 0.649572 0.481815 0.568849 0.469692 0.84784 0.523678 0.765444 0.843351 0.807035 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 140897 episodes
GETTING ACTION FROM:
action 2, numVisits=140886, meanQ=9.002314, numObservations: 9
action 4, numVisits=4, meanQ=-0.500000, numObservations: 3
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.171942 0.649572 0.481815 0.568849 0.469692 0.84784 0.523678 0.765444 0.843351 0.807035 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=2253, meanQ=20.045893, numObservations: 9
action 4, numVisits=2, meanQ=10.495000, numObservations: 2
action 5, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 150925 episodes
GETTING ACTION FROM:
action 2, numVisits=2277, meanQ=20.068604, numObservations: 9
action 4, numVisits=150898, meanQ=13.012418, numObservations: 9
action 5, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=3, meanQ=-1.670000, numObservations: 3
action 0, numVisits=3, meanQ=-1.670000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.171942 0.649572 0.481815 0.568849 0.469692 0.84784 0.523678 0.765444 0.843351 0.807035 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 47
Initial state: 0 0.709096 0.0206476 0.637233 0.618935 0.530836 0.601531 0.722984 0.178299 0.874021 0.889866 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 142085 episodes
GETTING ACTION FROM:
action 2, numVisits=142027, meanQ=9.055314, numObservations: 9
action 0, numVisits=33, meanQ=-0.800300, numObservations: 30
action -1, numVisits=12, meanQ=-1.340825, numObservations: 11
action 3, numVisits=10, meanQ=-1.497990, numObservations: 7
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.709096 0.0206476 0.637233 0.618935 0.530836 0.601531 0.722984 0.178299 0.874021 0.889866 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 48
Initial state: 0 0.386922 0.991916 0.822331 0.08346 0.950254 0.92558 0.138819 0.840495 0.505437 0.589738 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 143328 episodes
GETTING ACTION FROM:
action 4, numVisits=143276, meanQ=9.056583, numObservations: 9
action 1, numVisits=40, meanQ=7.899258, numObservations: 9
action 2, numVisits=6, meanQ=3.165000, numObservations: 5
action 5, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 0 0.386922 0.991916 0.822331 0.08346 0.950254 0.92558 0.138819 0.840495 0.505437 0.589738 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=4271, meanQ=10.216461, numObservations: 9
action 3, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 40943 episodes
GETTING ACTION FROM:
action 1, numVisits=45122, meanQ=9.865861, numObservations: 9
action 3, numVisits=4, meanQ=0.772500, numObservations: 3
action 0, numVisits=66, meanQ=-1.990246, numObservations: 56
action -1, numVisits=27, meanQ=-2.293333, numObservations: 23
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.386922 0.991916 0.822331 0.08346 0.950254 0.92558 0.138819 0.840495 0.505437 0.589738 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=2884, meanQ=13.316847, numObservations: 9
action 2, numVisits=3, meanQ=4.670033, numObservations: 2
action -1, numVisits=14, meanQ=-0.856298, numObservations: 10
action 0, numVisits=7, meanQ=-1.010000, numObservations: 7
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 43538 episodes
GETTING ACTION FROM:
action 5, numVisits=46422, meanQ=15.022385, numObservations: 9
action 2, numVisits=3, meanQ=4.670033, numObservations: 2
action -1, numVisits=14, meanQ=-0.856298, numObservations: 10
action 0, numVisits=7, meanQ=-1.010000, numObservations: 7
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.386922 0.991916 0.822331 0.08346 0.950254 0.92558 0.138819 0.840495 0.505437 0.589738 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 49
Initial state: 0 0.730424 0.160383 0.966736 0.104549 0.531245 0.619752 0.163474 0.893774 0.641522 0.174714 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 140090 episodes
GETTING ACTION FROM:
action 3, numVisits=140040, meanQ=8.931365, numObservations: 9
action 1, numVisits=43, meanQ=7.460705, numObservations: 8
action 2, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.730424 0.160383 0.966736 0.104549 0.531245 0.619752 0.163474 0.893774 0.641522 0.174714 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 50
Initial state: 0 0.176633 0.928324 0.402943 0.0447281 0.977102 0.0441195 0.879449 0.420249 0.507176 0.537144 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 138285 episodes
GETTING ACTION FROM:
action 2, numVisits=138274, meanQ=9.048218, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 1, numVisits=2, meanQ=-4.000000, numObservations: 2
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.176633 0.928324 0.402943 0.0447281 0.977102 0.0441195 0.879449 0.420249 0.507176 0.537144 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=21878, meanQ=10.236339, numObservations: 9
action 3, numVisits=10, meanQ=0.299000, numObservations: 5
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 41316 episodes
GETTING ACTION FROM:
action 4, numVisits=63168, meanQ=9.308681, numObservations: 9
action 3, numVisits=10, meanQ=0.299000, numObservations: 5
action -1, numVisits=15, meanQ=-1.142000, numObservations: 15
action 0, numVisits=14, meanQ=-1.222850, numObservations: 13
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=2, meanQ=-7.005000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.176633 0.928324 0.402943 0.0447281 0.977102 0.0441195 0.879449 0.420249 0.507176 0.537144 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
[32m ProblemEnvironment.hpp 351: Done.[39m
