Run # 1
Initial state: 0 0.177239 0.0197115 0.271105 0.521595 0.00649483 0.679914 0.669577 0.811221 0.490665 0.511845 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 135731 episodes
GETTING ACTION FROM:
action 3, numVisits=135714, meanQ=10.479627, numObservations: 9
action 1, numVisits=5, meanQ=4.598000, numObservations: 2
action 2, numVisits=8, meanQ=4.501263, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.177239 0.0197115 0.271105 0.521595 0.00649483 0.679914 0.669577 0.811221 0.490665 0.511845 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 2
Initial state: 0 0.9893 0.686441 0.432853 0.224024 0.561335 0.578139 0.572217 0.358443 0.358098 0.642313 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 137161 episodes
GETTING ACTION FROM:
action 2, numVisits=137151, meanQ=10.405754, numObservations: 9
action 4, numVisits=3, meanQ=5.663333, numObservations: 3
action 1, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.9893 0.686441 0.432853 0.224024 0.561335 0.578139 0.572217 0.358443 0.358098 0.642313 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=18250, meanQ=11.780878, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 45193 episodes
GETTING ACTION FROM:
action 4, numVisits=63438, meanQ=11.685708, numObservations: 9
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action -1, numVisits=3, meanQ=-1.340000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.9893 0.686441 0.432853 0.224024 0.561335 0.578139 0.572217 0.358443 0.358098 0.642313 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 3
Initial state: 0 0.808226 0.0196153 0.851838 0.736312 0.081413 0.140707 0.487523 0.497504 0.606711 0.909149 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 131988 episodes
GETTING ACTION FROM:
action 5, numVisits=131980, meanQ=10.284402, numObservations: 9
action 2, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.808226 0.0196153 0.851838 0.736312 0.081413 0.140707 0.487523 0.497504 0.606711 0.909149 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 4
Initial state: 0 0.161963 0.275064 0.545239 0.442355 0.494626 0.654831 0.0716165 0.952753 0.255023 0.111683 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 137409 episodes
GETTING ACTION FROM:
action 3, numVisits=137403, meanQ=10.466259, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.161963 0.275064 0.545239 0.442355 0.494626 0.654831 0.0716165 0.952753 0.255023 0.111683 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 5
Initial state: 0 0.315404 0.130484 0.204962 0.777179 0.264646 0.477723 0.534438 0.549576 0.81527 0.558355 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 136490 episodes
GETTING ACTION FROM:
action 1, numVisits=136463, meanQ=10.312263, numObservations: 9
action 3, numVisits=7, meanQ=-1.000000, numObservations: 4
action 0, numVisits=5, meanQ=-1.010000, numObservations: 5
action -1, numVisits=5, meanQ=-1.803980, numObservations: 4
action 4, numVisits=4, meanQ=-2.250000, numObservations: 3
action 2, numVisits=5, meanQ=-2.628000, numObservations: 3
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.315404 0.130484 0.204962 0.777179 0.264646 0.477723 0.534438 0.549576 0.81527 0.558355 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=2989, meanQ=11.258298, numObservations: 9
action 5, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 136176 episodes
GETTING ACTION FROM:
action 4, numVisits=139139, meanQ=6.795858, numObservations: 9
action 2, numVisits=9, meanQ=1.554444, numObservations: 5
action 5, numVisits=6, meanQ=0.666667, numObservations: 3
action -1, numVisits=9, meanQ=-1.670000, numObservations: 9
action 0, numVisits=8, meanQ=-1.752500, numObservations: 8
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.315404 0.130484 0.204962 0.777179 0.264646 0.477723 0.534438 0.549576 0.81527 0.558355 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 6
Initial state: 0 0.652911 0.205929 0.579079 0.536613 0.423378 0.938432 0.242978 0.0576292 0.241795 0.295608 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 137364 episodes
GETTING ACTION FROM:
action 2, numVisits=137356, meanQ=10.485307, numObservations: 9
action 1, numVisits=3, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.652911 0.205929 0.579079 0.536613 0.423378 0.938432 0.242978 0.0576292 0.241795 0.295608 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 7
Initial state: 0 0.444024 0.823353 0.0523521 0.796595 0.151957 0.944975 0.565725 0.5062 0.0328115 0.740458 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 137130 episodes
GETTING ACTION FROM:
action 3, numVisits=137120, meanQ=10.478051, numObservations: 9
action 1, numVisits=3, meanQ=5.000033, numObservations: 2
action 4, numVisits=3, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.444024 0.823353 0.0523521 0.796595 0.151957 0.944975 0.565725 0.5062 0.0328115 0.740458 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=15265, meanQ=11.711371, numObservations: 9
action 4, numVisits=23, meanQ=10.085657, numObservations: 9
action 5, numVisits=3, meanQ=4.670033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 56822 episodes
GETTING ACTION FROM:
action 1, numVisits=71701, meanQ=12.563949, numObservations: 9
action 4, numVisits=392, meanQ=8.716679, numObservations: 9
action 5, numVisits=15, meanQ=6.934020, numObservations: 8
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action -1, numVisits=3, meanQ=-1.340000, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.444024 0.823353 0.0523521 0.796595 0.151957 0.944975 0.565725 0.5062 0.0328115 0.740458 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=5284, meanQ=15.414568, numObservations: 9
action 4, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 56940 episodes
GETTING ACTION FROM:
action 2, numVisits=62224, meanQ=17.731376, numObservations: 9
action 4, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.444024 0.823353 0.0523521 0.796595 0.151957 0.944975 0.565725 0.5062 0.0328115 0.740458 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 4, numVisits=1701, meanQ=20.347428, numObservations: 9
action 5, numVisits=13, meanQ=11.767692, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 82303 episodes
GETTING ACTION FROM:
action 4, numVisits=84004, meanQ=21.795578, numObservations: 9
action 5, numVisits=13, meanQ=11.767692, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 0 0.444024 0.823353 0.0523521 0.796595 0.151957 0.944975 0.565725 0.5062 0.0328115 0.740458 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: -4
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 4, numVisits=154, meanQ=15.934918, numObservations: 8
action 5, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-10.085564, numObservations: 1
action 1, numVisits=1, meanQ=-539.279600, numObservations: 1
action 3, numVisits=1, meanQ=-539.447090, numObservations: 1
Sampled 193972 episodes
GETTING ACTION FROM:
action 4, numVisits=282, meanQ=18.339494, numObservations: 9
action 5, numVisits=193841, meanQ=16.633520, numObservations: 9
action -1, numVisits=5, meanQ=-1.604000, numObservations: 4
action 0, numVisits=5, meanQ=-1.604000, numObservations: 5
action 2, numVisits=1, meanQ=-10.085564, numObservations: 1
action 1, numVisits=1, meanQ=-539.279600, numObservations: 1
action 3, numVisits=1, meanQ=-539.447090, numObservations: 1
action: 4
Next state: 1 0.444024 0.823353 0.0523521 0.796595 0.151957 0.944975 0.565725 0.5062 0.0328115 0.740458 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.29271
Run # 8
Initial state: 0 0.387353 0.870626 0.862447 0.647293 0.548243 0.404777 0.879566 0.425248 0.754399 0.775562 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 139350 episodes
GETTING ACTION FROM:
action 5, numVisits=139305, meanQ=10.307775, numObservations: 9
action 3, numVisits=40, meanQ=6.510008, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.387353 0.870626 0.862447 0.647293 0.548243 0.404777 0.879566 0.425248 0.754399 0.775562 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 9
Initial state: 0 0.12115 0.0149739 0.33776 0.775873 0.5931 0.204264 0.509847 0.463244 0.924665 0.257831 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 139694 episodes
GETTING ACTION FROM:
action 1, numVisits=139688, meanQ=10.397830, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.12115 0.0149739 0.33776 0.775873 0.5931 0.204264 0.509847 0.463244 0.924665 0.257831 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=18763, meanQ=11.547322, numObservations: 9
action 3, numVisits=10, meanQ=5.997010, numObservations: 8
action 2, numVisits=10, meanQ=5.000010, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 39383 episodes
GETTING ACTION FROM:
action 5, numVisits=58074, meanQ=10.496747, numObservations: 9
action 3, numVisits=73, meanQ=7.398752, numObservations: 9
action 2, numVisits=10, meanQ=5.000010, numObservations: 5
action 0, numVisits=6, meanQ=-1.175000, numObservations: 6
action -1, numVisits=5, meanQ=-1.407980, numObservations: 4
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.12115 0.0149739 0.33776 0.775873 0.5931 0.204264 0.509847 0.463244 0.924665 0.257831 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 10
Initial state: 0 0.556284 0.588369 0.090458 0.281405 0.841153 0.389384 0.22862 0.563722 0.479967 0.425001 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 130847 episodes
GETTING ACTION FROM:
action 4, numVisits=130834, meanQ=10.522484, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 5, numVisits=4, meanQ=-2.250000, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.556284 0.588369 0.090458 0.281405 0.841153 0.389384 0.22862 0.563722 0.479967 0.425001 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=4940, meanQ=10.799664, numObservations: 9
action 5, numVisits=25, meanQ=5.880020, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 50659 episodes
GETTING ACTION FROM:
action 2, numVisits=50601, meanQ=11.956431, numObservations: 9
action 3, numVisits=4973, meanQ=10.805941, numObservations: 9
action 5, numVisits=25, meanQ=5.880020, numObservations: 6
action 0, numVisits=15, meanQ=-1.538000, numObservations: 15
action -1, numVisits=13, meanQ=-2.228462, numObservations: 12
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.556284 0.588369 0.090458 0.281405 0.841153 0.389384 0.22862 0.563722 0.479967 0.425001 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=3842, meanQ=14.180151, numObservations: 9
action -1, numVisits=10, meanQ=-3.624826, numObservations: 8
action 5, numVisits=51, meanQ=-9.160632, numObservations: 9
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-16.458084, numObservations: 1
action 0, numVisits=32, meanQ=-33.924003, numObservations: 25
action 4, numVisits=1, meanQ=-1056.796384, numObservations: 1
Sampled 40818 episodes
GETTING ACTION FROM:
action 3, numVisits=44660, meanQ=14.368868, numObservations: 9
action -1, numVisits=10, meanQ=-3.624826, numObservations: 8
action 5, numVisits=51, meanQ=-9.160632, numObservations: 9
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-16.458084, numObservations: 1
action 0, numVisits=32, meanQ=-33.924003, numObservations: 25
action 4, numVisits=1, meanQ=-1056.796384, numObservations: 1
action: 3
Next state: 2 0.556284 0.588369 0.090458 0.281405 0.841153 0.389384 0.22862 0.563722 0.479967 0.425001 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -18.7411
Run # 11
Initial state: 0 0.49336 0.583113 0.102362 0.34133 0.923038 0.47592 0.18328 0.608858 0.801788 0.618235 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 137937 episodes
GETTING ACTION FROM:
action 5, numVisits=137931, meanQ=10.498704, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.49336 0.583113 0.102362 0.34133 0.923038 0.47592 0.18328 0.608858 0.801788 0.618235 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 12
Initial state: 0 0.633338 0.882064 0.910054 0.163239 0.536405 0.414785 0.8995 0.802773 0.144326 0.961848 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 137462 episodes
GETTING ACTION FROM:
action 1, numVisits=137392, meanQ=10.549597, numObservations: 9
action 3, numVisits=49, meanQ=9.396537, numObservations: 9
action 5, numVisits=17, meanQ=8.706476, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.633338 0.882064 0.910054 0.163239 0.536405 0.414785 0.8995 0.802773 0.144326 0.961848 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 13
Initial state: 0 0.861986 0.614451 0.531285 0.552342 0.354066 0.349861 0.881893 0.0729008 0.825985 0.797045 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80783 episodes
GETTING ACTION FROM:
action -1, numVisits=80763, meanQ=13.910705, numObservations: 243
action 1, numVisits=10, meanQ=-0.691000, numObservations: 6
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.861986 0.614451 0.531285 0.552342 0.354066 0.349861 0.881893 0.0729008 0.825985 0.797045 w: 1
Observation: 0 3 0 2 0 1 0 2 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=221, meanQ=11.419533, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 171021 episodes
GETTING ACTION FROM:
action 4, numVisits=171242, meanQ=18.758832, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.861986 0.614451 0.531285 0.552342 0.354066 0.349861 0.881893 0.0729008 0.825985 0.797045 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 14
Initial state: 0 0.566159 0.522505 0.939668 0.200167 0.841695 0.305846 0.647741 0.901236 0.0138491 0.920765 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 137703 episodes
GETTING ACTION FROM:
action 1, numVisits=137692, meanQ=10.540650, numObservations: 9
action 2, numVisits=3, meanQ=1.703333, numObservations: 2
action 3, numVisits=4, meanQ=-0.252500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.566159 0.522505 0.939668 0.200167 0.841695 0.305846 0.647741 0.901236 0.0138491 0.920765 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 15
Initial state: 0 0.583673 0.488333 0.347419 0.695478 0.0649115 0.350005 0.349066 0.935187 0.170842 0.357682 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 137754 episodes
GETTING ACTION FROM:
action 3, numVisits=137742, meanQ=10.624721, numObservations: 9
action 4, numVisits=5, meanQ=4.400000, numObservations: 5
action 5, numVisits=3, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.583673 0.488333 0.347419 0.695478 0.0649115 0.350005 0.349066 0.935187 0.170842 0.357682 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=18707, meanQ=11.835348, numObservations: 9
action 2, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 52123 episodes
GETTING ACTION FROM:
action 4, numVisits=70824, meanQ=11.008260, numObservations: 9
action 2, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.583673 0.488333 0.347419 0.695478 0.0649115 0.350005 0.349066 0.935187 0.170842 0.357682 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=5108, meanQ=14.792462, numObservations: 9
action 2, numVisits=15, meanQ=8.967340, numObservations: 5
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 29263 episodes
GETTING ACTION FROM:
action 5, numVisits=34371, meanQ=16.230545, numObservations: 9
action 2, numVisits=15, meanQ=8.967340, numObservations: 5
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 0 0.583673 0.488333 0.347419 0.695478 0.0649115 0.350005 0.349066 0.935187 0.170842 0.357682 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=2233, meanQ=15.246269, numObservations: 9
action 4, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 19989 episodes
GETTING ACTION FROM:
action 1, numVisits=22222, meanQ=16.471588, numObservations: 9
action 4, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.583673 0.488333 0.347419 0.695478 0.0649115 0.350005 0.349066 0.935187 0.170842 0.357682 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 1, numVisits=167, meanQ=17.649993, numObservations: 9
action 2, numVisits=3, meanQ=1.517557, numObservations: 3
action 0, numVisits=5, meanQ=-1.010000, numObservations: 5
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=3, meanQ=-119.287957, numObservations: 2
Sampled 112261 episodes
GETTING ACTION FROM:
action 1, numVisits=339, meanQ=20.851693, numObservations: 9
action 2, numVisits=112087, meanQ=19.554714, numObservations: 9
action 0, numVisits=10, meanQ=-1.505000, numObservations: 9
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=3, meanQ=-119.287957, numObservations: 2
action: 1
Next state: 1 0.583673 0.488333 0.347419 0.695478 0.0649115 0.350005 0.349066 0.935187 0.170842 0.357682 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.29271
Run # 16
Initial state: 0 0.564155 0.553737 0.0978882 0.988726 0.669359 0.715711 0.46254 0.26984 0.456871 0.167288 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 136168 episodes
GETTING ACTION FROM:
action 4, numVisits=136154, meanQ=10.486961, numObservations: 9
action 1, numVisits=7, meanQ=6.141429, numObservations: 5
action 3, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.564155 0.553737 0.0978882 0.988726 0.669359 0.715711 0.46254 0.26984 0.456871 0.167288 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=18120, meanQ=11.521494, numObservations: 9
action -1, numVisits=16, meanQ=-1.258119, numObservations: 15
action 0, numVisits=14, meanQ=-1.577129, numObservations: 12
action 4, numVisits=2, meanQ=-4.004950, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
Sampled 40710 episodes
GETTING ACTION FROM:
action 5, numVisits=58830, meanQ=10.929595, numObservations: 9
action -1, numVisits=16, meanQ=-1.258119, numObservations: 15
action 0, numVisits=14, meanQ=-1.577129, numObservations: 12
action 4, numVisits=2, meanQ=-4.004950, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 5
Next state: 0 0.564155 0.553737 0.0978882 0.988726 0.669359 0.715711 0.46254 0.26984 0.456871 0.167288 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=7461, meanQ=13.953093, numObservations: 9
action 1, numVisits=5, meanQ=4.614490, numObservations: 5
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 31020 episodes
GETTING ACTION FROM:
action 3, numVisits=38479, meanQ=13.123508, numObservations: 9
action 1, numVisits=5, meanQ=4.614490, numObservations: 5
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.564155 0.553737 0.0978882 0.988726 0.669359 0.715711 0.46254 0.26984 0.456871 0.167288 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 17
Initial state: 0 0.996788 0.172368 0.77636 0.287752 0.465332 0.488142 0.667536 0.795136 0.17814 0.144539 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 128596 episodes
GETTING ACTION FROM:
action 5, numVisits=128588, meanQ=10.702459, numObservations: 9
action 1, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 2 0.996788 0.172368 0.77636 0.287752 0.465332 0.488142 0.667536 0.795136 0.17814 0.144539 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 18
Initial state: 0 0.583951 0.819133 0.144475 0.334111 0.870261 0.0588181 0.509185 0.817598 0.552431 0.501591 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 136305 episodes
GETTING ACTION FROM:
action 4, numVisits=136253, meanQ=10.385416, numObservations: 9
action 1, numVisits=35, meanQ=7.604586, numObservations: 9
action 2, numVisits=7, meanQ=6.000000, numObservations: 4
action 5, numVisits=7, meanQ=5.000000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 2 0.583951 0.819133 0.144475 0.334111 0.870261 0.0588181 0.509185 0.817598 0.552431 0.501591 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 19
Initial state: 0 0.493525 0.755572 0.721405 0.107233 0.960546 0.586005 0.350548 0.974364 0.491725 0.514348 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 136856 episodes
GETTING ACTION FROM:
action 1, numVisits=136707, meanQ=10.273275, numObservations: 9
action 3, numVisits=144, meanQ=9.630740, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.493525 0.755572 0.721405 0.107233 0.960546 0.586005 0.350548 0.974364 0.491725 0.514348 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 20
Initial state: 0 0.750807 0.00353515 0.105031 0.923404 0.208754 0.96104 0.579823 0.514018 0.422548 0.754367 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 137400 episodes
GETTING ACTION FROM:
action 5, numVisits=137389, meanQ=10.582384, numObservations: 9
action 4, numVisits=4, meanQ=3.247500, numObservations: 3
action 3, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.750807 0.00353515 0.105031 0.923404 0.208754 0.96104 0.579823 0.514018 0.422548 0.754367 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 21
Initial state: 0 0.5382 0.811326 0.488028 0.516105 0.94086 0.538172 0.0308199 0.392965 0.0923339 0.590196 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 137411 episodes
GETTING ACTION FROM:
action 5, numVisits=137403, meanQ=10.461331, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.5382 0.811326 0.488028 0.516105 0.94086 0.538172 0.0308199 0.392965 0.0923339 0.590196 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=15449, meanQ=11.788809, numObservations: 9
action 3, numVisits=7, meanQ=7.424286, numObservations: 4
action 2, numVisits=3, meanQ=5.993333, numObservations: 3
action 4, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 53073 episodes
GETTING ACTION FROM:
action 1, numVisits=68510, meanQ=13.417567, numObservations: 9
action 3, numVisits=11, meanQ=4.451827, numObservations: 5
action 2, numVisits=4, meanQ=1.745000, numObservations: 3
action 4, numVisits=4, meanQ=1.745000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action -1, numVisits=4, meanQ=-1.257500, numObservations: 4
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.5382 0.811326 0.488028 0.516105 0.94086 0.538172 0.0308199 0.392965 0.0923339 0.590196 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 22
Initial state: 0 0.247489 0.165802 0.2588 0.30873 0.476842 0.569292 0.868553 0.762874 0.311954 0.648489 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 135883 episodes
GETTING ACTION FROM:
action 2, numVisits=135869, meanQ=10.459863, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 4, numVisits=5, meanQ=-1.200000, numObservations: 5
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.247489 0.165802 0.2588 0.30873 0.476842 0.569292 0.868553 0.762874 0.311954 0.648489 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=18185, meanQ=11.495323, numObservations: 9
action 3, numVisits=9, meanQ=5.898889, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 42503 episodes
GETTING ACTION FROM:
action 4, numVisits=60624, meanQ=10.668258, numObservations: 9
action 3, numVisits=61, meanQ=9.147171, numObservations: 9
action 1, numVisits=6, meanQ=1.998333, numObservations: 5
action 0, numVisits=5, meanQ=-1.010000, numObservations: 5
action -1, numVisits=4, meanQ=-1.257500, numObservations: 4
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.247489 0.165802 0.2588 0.30873 0.476842 0.569292 0.868553 0.762874 0.311954 0.648489 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 23
Initial state: 0 0.620117 0.841051 0.413382 0.0878517 0.873698 0.349183 0.521853 0.439706 0.951908 0.802897 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 137255 episodes
GETTING ACTION FROM:
action 3, numVisits=137237, meanQ=10.450715, numObservations: 9
action 2, numVisits=13, meanQ=6.366162, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.620117 0.841051 0.413382 0.0878517 0.873698 0.349183 0.521853 0.439706 0.951908 0.802897 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=2872, meanQ=11.018360, numObservations: 9
action 2, numVisits=8, meanQ=5.623762, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 133345 episodes
GETTING ACTION FROM:
action 5, numVisits=136177, meanQ=7.015466, numObservations: 9
action 2, numVisits=32, meanQ=4.136611, numObservations: 9
action 0, numVisits=9, meanQ=-1.670000, numObservations: 9
action -1, numVisits=8, meanQ=-1.876250, numObservations: 8
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.620117 0.841051 0.413382 0.0878517 0.873698 0.349183 0.521853 0.439706 0.951908 0.802897 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 24
Initial state: 0 0.420848 0.87275 0.856813 0.605151 0.514428 0.485821 0.095412 0.225926 0.817798 0.0822749 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 137056 episodes
GETTING ACTION FROM:
action 1, numVisits=137048, meanQ=10.384143, numObservations: 9
action 5, numVisits=3, meanQ=5.663333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.420848 0.87275 0.856813 0.605151 0.514428 0.485821 0.095412 0.225926 0.817798 0.0822749 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=15348, meanQ=11.720517, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 53670 episodes
GETTING ACTION FROM:
action 5, numVisits=69014, meanQ=12.338706, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.420848 0.87275 0.856813 0.605151 0.514428 0.485821 0.095412 0.225926 0.817798 0.0822749 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 25
Initial state: 0 0.973872 0.166818 0.553019 0.437895 0.827539 0.456468 0.0582133 0.728311 0.972778 0.807941 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 138277 episodes
GETTING ACTION FROM:
action 3, numVisits=138254, meanQ=10.292785, numObservations: 9
action 2, numVisits=18, meanQ=4.056117, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.973872 0.166818 0.553019 0.437895 0.827539 0.456468 0.0582133 0.728311 0.972778 0.807941 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 26
Initial state: 0 0.560139 0.556093 0.299257 0.523745 0.032897 0.374479 0.645936 0.101056 0.251117 0.322501 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 137067 episodes
GETTING ACTION FROM:
action 4, numVisits=137022, meanQ=10.451892, numObservations: 9
action 5, numVisits=36, meanQ=7.035014, numObservations: 9
action 2, numVisits=5, meanQ=5.998000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 2 0.560139 0.556093 0.299257 0.523745 0.032897 0.374479 0.645936 0.101056 0.251117 0.322501 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 27
Initial state: 0 0.975033 0.965813 0.319276 0.545688 0.70628 0.762221 0.096641 0.0932723 0.57022 0.47757 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 137428 episodes
GETTING ACTION FROM:
action 2, numVisits=137213, meanQ=10.537045, numObservations: 9
action 3, numVisits=198, meanQ=7.961958, numObservations: 9
action 1, numVisits=11, meanQ=6.727282, numObservations: 6
action 5, numVisits=3, meanQ=5.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.975033 0.965813 0.319276 0.545688 0.70628 0.762221 0.096641 0.0932723 0.57022 0.47757 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=5200, meanQ=11.162399, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 40473 episodes
GETTING ACTION FROM:
action 1, numVisits=45654, meanQ=11.236089, numObservations: 9
action 0, numVisits=8, meanQ=-1.752500, numObservations: 7
action 4, numVisits=2, meanQ=-6.109931, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=12, meanQ=-88.525216, numObservations: 11
action: 1
Next state: 1 0.975033 0.965813 0.319276 0.545688 0.70628 0.762221 0.096641 0.0932723 0.57022 0.47757 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 28
Initial state: 0 0.961534 0.377603 0.501625 0.402274 0.00845686 0.738908 0.746843 0.59149 0.78655 0.150419 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 136209 episodes
GETTING ACTION FROM:
action 1, numVisits=136193, meanQ=10.346787, numObservations: 9
action 4, numVisits=9, meanQ=7.444467, numObservations: 3
action 3, numVisits=3, meanQ=5.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.961534 0.377603 0.501625 0.402274 0.00845686 0.738908 0.746843 0.59149 0.78655 0.150419 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 29
Initial state: 0 0.671453 0.730023 0.516253 0.538171 0.307369 0.724252 0.803667 0.154952 0.308527 0.797302 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 135747 episodes
GETTING ACTION FROM:
action 2, numVisits=135738, meanQ=10.535791, numObservations: 9
action 1, numVisits=4, meanQ=1.250000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.671453 0.730023 0.516253 0.538171 0.307369 0.724252 0.803667 0.154952 0.308527 0.797302 w: 1
Observation: 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 30
Initial state: 0 0.0384481 0.81458 0.513571 0.406127 0.0138735 0.0850135 0.344802 0.77058 0.73314 0.612152 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 130218 episodes
GETTING ACTION FROM:
action 5, numVisits=130210, meanQ=10.434636, numObservations: 9
action 1, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.0384481 0.81458 0.513571 0.406127 0.0138735 0.0850135 0.344802 0.77058 0.73314 0.612152 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 31
Initial state: 0 0.383629 0.337715 0.285111 0.388444 0.405466 0.210749 0.474783 0.47863 0.645818 0.757752 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 131641 episodes
GETTING ACTION FROM:
action 3, numVisits=131633, meanQ=10.526046, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.383629 0.337715 0.285111 0.388444 0.405466 0.210749 0.474783 0.47863 0.645818 0.757752 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 32
Initial state: 0 0.0372907 0.322702 0.484361 0.524559 0.191286 0.947247 0.402431 0.33369 0.519161 0.248774 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 136508 episodes
GETTING ACTION FROM:
action 4, numVisits=136494, meanQ=10.518926, numObservations: 9
action 2, numVisits=7, meanQ=0.000000, numObservations: 7
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.0372907 0.322702 0.484361 0.524559 0.191286 0.947247 0.402431 0.33369 0.519161 0.248774 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=18201, meanQ=11.735708, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 33544 episodes
GETTING ACTION FROM:
action 3, numVisits=51409, meanQ=11.076364, numObservations: 9
action 5, numVisits=316, meanQ=9.220491, numObservations: 9
action -1, numVisits=16, meanQ=0.103750, numObservations: 15
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 3
Next state: 0 0.0372907 0.322702 0.484361 0.524559 0.191286 0.947247 0.402431 0.33369 0.519161 0.248774 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=362, meanQ=13.831594, numObservations: 9
action 5, numVisits=3, meanQ=1.050126, numObservations: 3
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=12, meanQ=-76.704366, numObservations: 6
Sampled 44202 episodes
GETTING ACTION FROM:
action 5, numVisits=44183, meanQ=15.366374, numObservations: 9
action 3, numVisits=375, meanQ=14.059372, numObservations: 9
action 0, numVisits=7, meanQ=-1.575714, numObservations: 6
action -1, numVisits=6, meanQ=-1.836650, numObservations: 5
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=12, meanQ=-76.704366, numObservations: 6
action: 5
Next state: 0 0.0372907 0.322702 0.484361 0.524559 0.191286 0.947247 0.402431 0.33369 0.519161 0.248774 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=74, meanQ=6.523305, numObservations: 9
action 5, numVisits=3, meanQ=-12.166777, numObservations: 3
action 2, numVisits=2, meanQ=-12.637192, numObservations: 2
action 0, numVisits=42, meanQ=-13.517611, numObservations: 21
action -1, numVisits=21, meanQ=-27.217935, numObservations: 16
action 4, numVisits=1, meanQ=-536.381805, numObservations: 1
action 3, numVisits=1, meanQ=-536.384119, numObservations: 1
Sampled 106994 episodes
GETTING ACTION FROM:
action 1, numVisits=107068, meanQ=11.869697, numObservations: 9
action 5, numVisits=3, meanQ=-12.166777, numObservations: 3
action 2, numVisits=2, meanQ=-12.637192, numObservations: 2
action 0, numVisits=42, meanQ=-13.517611, numObservations: 21
action -1, numVisits=21, meanQ=-27.217935, numObservations: 16
action 4, numVisits=1, meanQ=-536.381805, numObservations: 1
action 3, numVisits=1, meanQ=-536.384119, numObservations: 1
action: 1
Next state: 0 0.0372907 0.322702 0.484361 0.524559 0.191286 0.947247 0.402431 0.33369 0.519161 0.248774 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 5, numVisits=1, meanQ=24.000000, numObservations: 1
action 1, numVisits=510, meanQ=13.713558, numObservations: 9
action 2, numVisits=18, meanQ=-17.226071, numObservations: 7
action 0, numVisits=11, meanQ=-33.855092, numObservations: 8
action -1, numVisits=4, meanQ=-90.608415, numObservations: 3
action 3, numVisits=1, meanQ=-359.656223, numObservations: 1
action 4, numVisits=1, meanQ=-536.349091, numObservations: 1
Sampled 189961 episodes
GETTING ACTION FROM:
action 1, numVisits=755, meanQ=11.992946, numObservations: 9
action 2, numVisits=189729, meanQ=8.006043, numObservations: 9
action 5, numVisits=6, meanQ=6.500000, numObservations: 3
action 0, numVisits=11, meanQ=-33.855092, numObservations: 8
action -1, numVisits=4, meanQ=-90.608415, numObservations: 3
action 3, numVisits=1, meanQ=-359.656223, numObservations: 1
action 4, numVisits=1, meanQ=-536.349091, numObservations: 1
action: 1
Next state: 0 0.0372907 0.322702 0.484361 0.524559 0.191286 0.947247 0.402431 0.33369 0.519161 0.248774 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 5
Improving policy...
PLANNING FROM:
action -1, numVisits=5, meanQ=-1.407980, numObservations: 4
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-14.061542, numObservations: 1
action 0, numVisits=13, meanQ=-25.064861, numObservations: 10
action 3, numVisits=1, meanQ=-359.913642, numObservations: 1
action 4, numVisits=1, meanQ=-360.875694, numObservations: 1
Sampled 221655 episodes
GETTING ACTION FROM:
action 2, numVisits=221582, meanQ=5.880225, numObservations: 9
action -1, numVisits=79, meanQ=-1.949999, numObservations: 44
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-14.061542, numObservations: 1
action 0, numVisits=13, meanQ=-25.064861, numObservations: 10
action 3, numVisits=1, meanQ=-359.913642, numObservations: 1
action 4, numVisits=1, meanQ=-360.875694, numObservations: 1
action: 2
Next state: 1 0.0372907 0.322702 0.484361 0.524559 0.191286 0.947247 0.402431 0.33369 0.519161 0.248774 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 3.21978
Run # 33
Initial state: 0 0.544119 0.180905 0.472724 0.371138 0.354417 0.789619 0.561108 0.456919 0.620913 0.0917471 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 137664 episodes
GETTING ACTION FROM:
action 5, numVisits=137658, meanQ=10.334446, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.544119 0.180905 0.472724 0.371138 0.354417 0.789619 0.561108 0.456919 0.620913 0.0917471 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 34
Initial state: 0 0.26101 0.468945 0.830525 0.0669725 0.0615999 0.806202 0.507323 0.522942 0.24523 0.695845 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 137557 episodes
GETTING ACTION FROM:
action 1, numVisits=137547, meanQ=10.311322, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.26101 0.468945 0.830525 0.0669725 0.0615999 0.806202 0.507323 0.522942 0.24523 0.695845 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 35
Initial state: 0 0.138364 0.636878 0.725709 0.742972 0.49078 0.917235 0.999063 0.612357 0.567795 0.532639 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 137185 episodes
GETTING ACTION FROM:
action 3, numVisits=137173, meanQ=10.440411, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=2, meanQ=-7.500000, numObservations: 2
action 2, numVisits=2, meanQ=-7.500000, numObservations: 2
action: 3
Next state: 1 0.138364 0.636878 0.725709 0.742972 0.49078 0.917235 0.999063 0.612357 0.567795 0.532639 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 36
Initial state: 0 0.138242 0.644018 0.126105 0.655734 0.667683 0.212588 0.420647 0.687421 0.54877 0.519773 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 137370 episodes
GETTING ACTION FROM:
action 3, numVisits=137355, meanQ=10.410958, numObservations: 9
action 4, numVisits=7, meanQ=1.998586, numObservations: 4
action 2, numVisits=4, meanQ=-0.252500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.138242 0.644018 0.126105 0.655734 0.667683 0.212588 0.420647 0.687421 0.54877 0.519773 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 37
Initial state: 0 0.777921 0.707697 0.93931 0.314385 0.963633 0.0508702 0.584837 0.512778 0.455035 0.628716 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 139765 episodes
GETTING ACTION FROM:
action 3, numVisits=139749, meanQ=10.325478, numObservations: 9
action 4, numVisits=5, meanQ=-1.002000, numObservations: 4
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=5, meanQ=-1.399980, numObservations: 4
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.777921 0.707697 0.93931 0.314385 0.963633 0.0508702 0.584837 0.512778 0.455035 0.628716 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 38
Initial state: 0 0.309096 0.682809 0.188591 0.845896 0.634986 0.1147 0.557335 0.568316 0.0485188 0.110434 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 130307 episodes
GETTING ACTION FROM:
action 3, numVisits=130285, meanQ=10.526625, numObservations: 9
action 5, numVisits=10, meanQ=5.502010, numObservations: 7
action 2, numVisits=6, meanQ=3.670017, numObservations: 5
action 4, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.309096 0.682809 0.188591 0.845896 0.634986 0.1147 0.557335 0.568316 0.0485188 0.110434 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 39
Initial state: 0 0.630874 0.0454903 0.519139 0.53835 0.498432 0.884138 0.0918444 0.680788 0.968045 0.651807 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 136205 episodes
GETTING ACTION FROM:
action 2, numVisits=136199, meanQ=10.264523, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.630874 0.0454903 0.519139 0.53835 0.498432 0.884138 0.0918444 0.680788 0.968045 0.651807 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 40
Initial state: 0 0.531969 0.488119 0.646553 0.714512 0.30985 0.357899 0.49699 0.643933 0.608175 0.852961 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 133129 episodes
GETTING ACTION FROM:
action 5, numVisits=133123, meanQ=10.487585, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.531969 0.488119 0.646553 0.714512 0.30985 0.357899 0.49699 0.643933 0.608175 0.852961 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 41
Initial state: 0 0.078702 0.778792 0.485375 0.955117 0.0943319 0.667592 0.135668 0.271253 0.561961 0.522285 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 137386 episodes
GETTING ACTION FROM:
action 1, numVisits=137267, meanQ=10.395667, numObservations: 9
action 4, numVisits=114, meanQ=7.625533, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.078702 0.778792 0.485375 0.955117 0.0943319 0.667592 0.135668 0.271253 0.561961 0.522285 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 42
Initial state: 0 0.75171 0.832215 0.853989 0.835028 0.0637938 0.529992 0.924499 0.982573 0.478757 0.567434 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 136454 episodes
GETTING ACTION FROM:
action 4, numVisits=136448, meanQ=10.383584, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.75171 0.832215 0.853989 0.835028 0.0637938 0.529992 0.924499 0.982573 0.478757 0.567434 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 43
Initial state: 0 0.731001 0.266051 0.0751025 0.826728 0.683318 0.843049 0.529094 0.460565 0.896308 0.419677 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 136869 episodes
GETTING ACTION FROM:
action 3, numVisits=136857, meanQ=10.299147, numObservations: 9
action 4, numVisits=4, meanQ=2.255025, numObservations: 3
action 5, numVisits=4, meanQ=1.497500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.731001 0.266051 0.0751025 0.826728 0.683318 0.843049 0.529094 0.460565 0.896308 0.419677 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 44
Initial state: 0 0.320456 0.150449 0.807759 0.00530708 0.957039 0.640247 0.549697 0.425626 0.366277 0.206558 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80903 episodes
GETTING ACTION FROM:
action -1, numVisits=80881, meanQ=13.767070, numObservations: 243
action 0, numVisits=11, meanQ=-1.010000, numObservations: 11
action 1, numVisits=4, meanQ=-2.250000, numObservations: 3
action 3, numVisits=2, meanQ=-4.499950, numObservations: 1
action 4, numVisits=2, meanQ=-7.500000, numObservations: 2
action 5, numVisits=2, meanQ=-7.500000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.320456 0.150449 0.807759 0.00530708 0.957039 0.640247 0.549697 0.425626 0.366277 0.206558 w: 1
Observation: 0 1 0 3 0 3 0 2 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=616, meanQ=14.546349, numObservations: 83
action 2, numVisits=28, meanQ=0.143221, numObservations: 6
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 82732 episodes
GETTING ACTION FROM:
action -1, numVisits=83348, meanQ=19.194961, numObservations: 227
action 2, numVisits=28, meanQ=0.143221, numObservations: 6
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.320456 0.150449 0.807759 0.00530708 0.957039 0.640247 0.549697 0.425626 0.366277 0.206558 w: 1
Observation: 0 1 0 3 0 3 0 2 0 1 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=28573, meanQ=23.326596, numObservations: 9
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 191372 episodes
GETTING ACTION FROM:
action 4, numVisits=219945, meanQ=23.397897, numObservations: 9
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.320456 0.150449 0.807759 0.00530708 0.957039 0.640247 0.549697 0.425626 0.366277 0.206558 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.5424
Run # 45
Initial state: 0 0.0249861 0.679594 0.429478 0.259424 0.509875 0.539416 0.264929 0.704072 0.11136 0.852699 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 136113 episodes
GETTING ACTION FROM:
action 1, numVisits=136105, meanQ=10.379910, numObservations: 9
action 5, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.0249861 0.679594 0.429478 0.259424 0.509875 0.539416 0.264929 0.704072 0.11136 0.852699 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 46
Initial state: 0 0.768978 0.400958 0.55256 0.876462 0.862253 0.88396 0.825682 0.450309 0.54845 0.436385 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 132602 episodes
GETTING ACTION FROM:
action 4, numVisits=132594, meanQ=10.512961, numObservations: 9
action 2, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.768978 0.400958 0.55256 0.876462 0.862253 0.88396 0.825682 0.450309 0.54845 0.436385 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 47
Initial state: 0 0.0420733 0.641041 0.888245 0.781089 0.718146 0.137248 0.504847 0.398252 0.475371 0.336578 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 137424 episodes
GETTING ACTION FROM:
action 2, numVisits=137405, meanQ=10.525131, numObservations: 9
action 1, numVisits=14, meanQ=7.490000, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.0420733 0.641041 0.888245 0.781089 0.718146 0.137248 0.504847 0.398252 0.475371 0.336578 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 48
Initial state: 0 0.453208 0.376833 0.505756 0.581893 0.762851 0.811314 0.879598 0.916768 0.189897 0.879595 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 137609 episodes
GETTING ACTION FROM:
action 4, numVisits=137601, meanQ=10.352156, numObservations: 9
action 1, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.453208 0.376833 0.505756 0.581893 0.762851 0.811314 0.879598 0.916768 0.189897 0.879595 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 49
Initial state: 0 0.0905341 0.813257 0.0425322 0.792562 0.889346 0.260812 0.552223 0.511254 0.331882 0.217123 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 137854 episodes
GETTING ACTION FROM:
action 3, numVisits=137842, meanQ=10.432213, numObservations: 9
action 1, numVisits=5, meanQ=7.198020, numObservations: 4
action 5, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.0905341 0.813257 0.0425322 0.792562 0.889346 0.260812 0.552223 0.511254 0.331882 0.217123 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 50
Initial state: 0 0.188986 0.785675 0.964848 0.381933 0.542479 0.502803 0.962555 0.345957 0.399165 0.827113 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 138655 episodes
GETTING ACTION FROM:
action 5, numVisits=138631, meanQ=10.452447, numObservations: 9
action 1, numVisits=16, meanQ=4.545637, numObservations: 7
action 3, numVisits=4, meanQ=1.250000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.188986 0.785675 0.964848 0.381933 0.542479 0.502803 0.962555 0.345957 0.399165 0.827113 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=15404, meanQ=11.656485, numObservations: 9
action 1, numVisits=3, meanQ=3.330000, numObservations: 3
action 5, numVisits=3, meanQ=2.033333, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 56870 episodes
GETTING ACTION FROM:
action 2, numVisits=72270, meanQ=13.190686, numObservations: 9
action 1, numVisits=3, meanQ=3.330000, numObservations: 3
action 5, numVisits=3, meanQ=2.033333, numObservations: 1
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.340000, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.188986 0.785675 0.964848 0.381933 0.542479 0.502803 0.962555 0.345957 0.399165 0.827113 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
[32m ProblemEnvironment.hpp 351: Done.[39m
