Run # 1
Initial state: 0 0.749696 0.903472 0.799634 0.33806 0.538455 0.795854 0.0648421 0.915761 0.484416 0.4981 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 143158 episodes
GETTING ACTION FROM:
action 4, numVisits=143140, meanQ=8.663458, numObservations: 9
action -1, numVisits=5, meanQ=-1.010000, numObservations: 5
action 0, numVisits=5, meanQ=-1.010000, numObservations: 5
action 1, numVisits=5, meanQ=-2.600000, numObservations: 5
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.749696 0.903472 0.799634 0.33806 0.538455 0.795854 0.0648421 0.915761 0.484416 0.4981 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1178, meanQ=9.895786, numObservations: 9
action 4, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 191190 episodes
GETTING ACTION FROM:
action 1, numVisits=192364, meanQ=12.435072, numObservations: 9
action 4, numVisits=3, meanQ=3.330000, numObservations: 3
action 0, numVisits=3, meanQ=-1.340000, numObservations: 3
action -1, numVisits=3, meanQ=-1.670000, numObservations: 3
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.749696 0.903472 0.799634 0.33806 0.538455 0.795854 0.0648421 0.915761 0.484416 0.4981 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 2
Initial state: 0 0.569035 0.59184 0.914598 0.97847 0.193958 0.344557 0.267872 0.256118 0.831611 0.417166 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 146596 episodes
GETTING ACTION FROM:
action 5, numVisits=146586, meanQ=8.522576, numObservations: 9
action 2, numVisits=3, meanQ=0.666667, numObservations: 2
action 3, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.569035 0.59184 0.914598 0.97847 0.193958 0.344557 0.267872 0.256118 0.831611 0.417166 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 3
Initial state: 0 0.520518 0.707392 0.278213 0.181486 0.835117 0.657941 0.00242978 0.200826 0.508502 0.568148 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 146002 episodes
GETTING ACTION FROM:
action 5, numVisits=145994, meanQ=8.476356, numObservations: 9
action 2, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.520518 0.707392 0.278213 0.181486 0.835117 0.657941 0.00242978 0.200826 0.508502 0.568148 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 4
Initial state: 0 0.118486 0.0697316 0.918069 0.931173 0.400945 0.472712 0.0766478 0.26378 0.023869 0.686317 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 145346 episodes
GETTING ACTION FROM:
action 5, numVisits=145329, meanQ=8.730058, numObservations: 9
action 2, numVisits=4, meanQ=1.745000, numObservations: 3
action 3, numVisits=4, meanQ=1.745000, numObservations: 4
action 4, numVisits=6, meanQ=1.185000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.118486 0.0697316 0.918069 0.931173 0.400945 0.472712 0.0766478 0.26378 0.023869 0.686317 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=11502, meanQ=9.952410, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 60833 episodes
GETTING ACTION FROM:
action 3, numVisits=72329, meanQ=11.164879, numObservations: 9
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.257500, numObservations: 4
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.118486 0.0697316 0.918069 0.931173 0.400945 0.472712 0.0766478 0.26378 0.023869 0.686317 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 5
Initial state: 0 0.794909 0.850081 0.539174 0.178886 0.522967 0.564347 0.627598 0.830849 0.428088 0.820793 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 133528 episodes
GETTING ACTION FROM:
action 4, numVisits=133510, meanQ=8.942360, numObservations: 9
action 1, numVisits=11, meanQ=0.885455, numObservations: 7
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.794909 0.850081 0.539174 0.178886 0.522967 0.564347 0.627598 0.830849 0.428088 0.820793 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 6
Initial state: 0 0.158871 0.764103 0.895672 0.781415 0.448935 0.541931 0.137056 0.235801 0.989405 0.883196 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 82919 episodes
GETTING ACTION FROM:
action -1, numVisits=82871, meanQ=12.922799, numObservations: 243
action 0, numVisits=34, meanQ=-1.476465, numObservations: 31
action 3, numVisits=7, meanQ=-2.142843, numObservations: 5
action 4, numVisits=2, meanQ=-5.489950, numObservations: 1
action 2, numVisits=2, meanQ=-7.500000, numObservations: 1
action 5, numVisits=2, meanQ=-7.500000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.158871 0.764103 0.895672 0.781415 0.448935 0.541931 0.137056 0.235801 0.989405 0.883196 w: 1
Observation: 0 3 0 3 0 2 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=610, meanQ=21.042064, numObservations: 9
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 192419 episodes
GETTING ACTION FROM:
action 3, numVisits=193029, meanQ=21.755378, numObservations: 9
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.158871 0.764103 0.895672 0.781415 0.448935 0.541931 0.137056 0.235801 0.989405 0.883196 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 7
Initial state: 0 0.121042 0.988918 0.733331 0.0491735 0.527122 0.732576 0.506856 0.53543 0.703662 0.206036 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 146757 episodes
GETTING ACTION FROM:
action 2, numVisits=146715, meanQ=8.446455, numObservations: 9
action 5, numVisits=35, meanQ=6.958583, numObservations: 8
action 1, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 2 0.121042 0.988918 0.733331 0.0491735 0.527122 0.732576 0.506856 0.53543 0.703662 0.206036 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 8
Initial state: 0 0.128682 0.41212 0.775295 0.468518 0.573698 0.501509 0.547277 0.94888 0.697077 0.019035 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 141301 episodes
GETTING ACTION FROM:
action 4, numVisits=141281, meanQ=8.682600, numObservations: 9
action 1, numVisits=7, meanQ=0.000000, numObservations: 4
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 5, numVisits=5, meanQ=-1.200000, numObservations: 5
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.128682 0.41212 0.775295 0.468518 0.573698 0.501509 0.547277 0.94888 0.697077 0.019035 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 9
Initial state: 0 0.500781 0.529012 0.709572 0.108183 0.387606 0.707729 0.341522 0.363745 0.787082 0.397462 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 83074 episodes
GETTING ACTION FROM:
action -1, numVisits=83016, meanQ=12.796647, numObservations: 243
action 0, numVisits=39, meanQ=-1.518454, numObservations: 35
action 2, numVisits=11, meanQ=-2.727273, numObservations: 5
action 5, numVisits=3, meanQ=-6.333333, numObservations: 3
action 1, numVisits=2, meanQ=-7.500000, numObservations: 2
action 3, numVisits=2, meanQ=-7.500000, numObservations: 2
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.500781 0.529012 0.709572 0.108183 0.387606 0.707729 0.341522 0.363745 0.787082 0.397462 w: 1
Observation: 0 2 0 3 0 2 0 1 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=299, meanQ=11.772149, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 179022 episodes
GETTING ACTION FROM:
action 1, numVisits=179321, meanQ=15.995834, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.500781 0.529012 0.709572 0.108183 0.387606 0.707729 0.341522 0.363745 0.787082 0.397462 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 10
Initial state: 0 0.581656 0.584358 0.779012 0.85532 0.875101 0.00911176 0.390164 0.645477 0.151282 0.700397 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 147365 episodes
GETTING ACTION FROM:
action 1, numVisits=147347, meanQ=8.682881, numObservations: 9
action 4, numVisits=10, meanQ=4.011000, numObservations: 7
action 3, numVisits=4, meanQ=2.502525, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.581656 0.584358 0.779012 0.85532 0.875101 0.00911176 0.390164 0.645477 0.151282 0.700397 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 11
Initial state: 0 0.555045 0.473202 0.181704 0.136285 0.732743 0.19426 0.17804 0.751635 0.51717 0.695187 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 146870 episodes
GETTING ACTION FROM:
action 1, numVisits=146860, meanQ=8.628679, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.555045 0.473202 0.181704 0.136285 0.732743 0.19426 0.17804 0.751635 0.51717 0.695187 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 12
Initial state: 0 0.469604 0.446646 0.631545 0.780093 0.417139 0.573724 0.0733 0.848191 0.287669 0.823294 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 145679 episodes
GETTING ACTION FROM:
action 1, numVisits=145669, meanQ=8.427667, numObservations: 9
action 3, numVisits=3, meanQ=3.000000, numObservations: 2
action 4, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.469604 0.446646 0.631545 0.780093 0.417139 0.573724 0.0733 0.848191 0.287669 0.823294 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 13
Initial state: 0 0.390625 0.480557 0.712214 0.676315 0.31359 0.00927783 0.0445185 0.449217 0.650588 0.408754 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 133793 episodes
GETTING ACTION FROM:
action 2, numVisits=133744, meanQ=8.781328, numObservations: 9
action 3, numVisits=42, meanQ=4.018102, numObservations: 9
action 1, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.390625 0.480557 0.712214 0.676315 0.31359 0.00927783 0.0445185 0.449217 0.650588 0.408754 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 14
Initial state: 0 0.862363 0.254584 0.636656 0.67814 0.863256 0.982684 0.194357 0.726821 0.471674 0.647905 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 147107 episodes
GETTING ACTION FROM:
action 5, numVisits=147094, meanQ=8.602138, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 1, numVisits=2, meanQ=-4.000000, numObservations: 2
action 2, numVisits=2, meanQ=-7.500000, numObservations: 2
action 4, numVisits=2, meanQ=-7.500000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.862363 0.254584 0.636656 0.67814 0.863256 0.982684 0.194357 0.726821 0.471674 0.647905 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 15
Initial state: 0 0.832935 0.0962366 0.586972 0.896642 0.95388 0.802671 0.748367 0.817664 0.579951 0.587319 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 144229 episodes
GETTING ACTION FROM:
action 4, numVisits=144221, meanQ=8.672221, numObservations: 9
action 5, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.832935 0.0962366 0.586972 0.896642 0.95388 0.802671 0.748367 0.817664 0.579951 0.587319 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 16
Initial state: 0 0.344218 0.417328 0.223634 0.843693 0.161943 0.802314 0.480229 0.564564 0.584851 0.573787 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 82243 episodes
GETTING ACTION FROM:
action -1, numVisits=82215, meanQ=12.674595, numObservations: 243
action 0, numVisits=18, meanQ=-1.230550, numObservations: 17
action 3, numVisits=6, meanQ=-4.000000, numObservations: 6
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.344218 0.417328 0.223634 0.843693 0.161943 0.802314 0.480229 0.564564 0.584851 0.573787 w: 1
Observation: 0 1 0 1 0 1 0 2 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=576, meanQ=20.868811, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 187846 episodes
GETTING ACTION FROM:
action 4, numVisits=188422, meanQ=21.020777, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.344218 0.417328 0.223634 0.843693 0.161943 0.802314 0.480229 0.564564 0.584851 0.573787 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 17
Initial state: 0 0.961612 0.254119 0.469949 0.644234 0.719408 0.820422 0.288619 0.329707 0.931447 0.336879 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 147983 episodes
GETTING ACTION FROM:
action 4, numVisits=147974, meanQ=8.623531, numObservations: 9
action 5, numVisits=4, meanQ=1.497500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.961612 0.254119 0.469949 0.644234 0.719408 0.820422 0.288619 0.329707 0.931447 0.336879 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 18
Initial state: 0 0.691511 0.906825 0.0863022 0.686571 0.809618 0.289375 0.755944 0.0965975 0.487446 0.545365 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 147927 episodes
GETTING ACTION FROM:
action 4, numVisits=147918, meanQ=8.605113, numObservations: 9
action 2, numVisits=4, meanQ=1.497500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.691511 0.906825 0.0863022 0.686571 0.809618 0.289375 0.755944 0.0965975 0.487446 0.545365 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 19
Initial state: 0 0.527381 0.519323 0.226427 0.752452 0.918974 0.00817302 0.01705 0.77318 0.11183 0.784678 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 146768 episodes
GETTING ACTION FROM:
action 5, numVisits=146748, meanQ=8.420292, numObservations: 9
action 1, numVisits=8, meanQ=3.468750, numObservations: 6
action 2, numVisits=8, meanQ=3.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 0 0.527381 0.519323 0.226427 0.752452 0.918974 0.00817302 0.01705 0.77318 0.11183 0.784678 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=11568, meanQ=10.124154, numObservations: 9
action 4, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 54377 episodes
GETTING ACTION FROM:
action 3, numVisits=65941, meanQ=11.031695, numObservations: 9
action 4, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=3, meanQ=-1.670000, numObservations: 3
action 0, numVisits=3, meanQ=-1.670000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.527381 0.519323 0.226427 0.752452 0.918974 0.00817302 0.01705 0.77318 0.11183 0.784678 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 20
Initial state: 0 0.881891 0.225463 0.380715 0.264263 0.435204 0.552427 0.189471 0.282519 0.0485986 0.49057 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 146921 episodes
GETTING ACTION FROM:
action 1, numVisits=146906, meanQ=8.503451, numObservations: 9
action 2, numVisits=10, meanQ=5.898010, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.881891 0.225463 0.380715 0.264263 0.435204 0.552427 0.189471 0.282519 0.0485986 0.49057 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 21
Initial state: 0 0.598174 0.793813 0.520911 0.525203 0.823592 0.975986 0.00264551 0.87961 0.709663 0.892013 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 147531 episodes
GETTING ACTION FROM:
action 1, numVisits=147423, meanQ=8.600075, numObservations: 9
action -1, numVisits=62, meanQ=-1.058063, numObservations: 58
action 0, numVisits=41, meanQ=-1.082680, numObservations: 37
action 4, numVisits=2, meanQ=-3.505000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.598174 0.793813 0.520911 0.525203 0.823592 0.975986 0.00264551 0.87961 0.709663 0.892013 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 22
Initial state: 0 0.234906 0.847691 0.277723 0.323293 0.21377 0.229193 0.216387 0.914853 0.543108 0.490098 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 83188 episodes
GETTING ACTION FROM:
action -1, numVisits=83140, meanQ=12.825976, numObservations: 243
action 0, numVisits=40, meanQ=-1.455995, numObservations: 37
action 1, numVisits=2, meanQ=-4.000000, numObservations: 2
action 5, numVisits=2, meanQ=-4.499950, numObservations: 1
action 4, numVisits=2, meanQ=-7.500000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.234906 0.847691 0.277723 0.323293 0.21377 0.229193 0.216387 0.914853 0.543108 0.490098 w: 1
Observation: 0 1 0 1 0 2 0 1 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=294, meanQ=13.681572, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 179103 episodes
GETTING ACTION FROM:
action 5, numVisits=179397, meanQ=14.623843, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 1 0.234906 0.847691 0.277723 0.323293 0.21377 0.229193 0.216387 0.914853 0.543108 0.490098 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 23
Initial state: 0 0.372079 0.576596 0.959238 0.373843 0.478468 0.539958 0.772763 0.749594 0.816578 0.151428 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 145825 episodes
GETTING ACTION FROM:
action 5, numVisits=145812, meanQ=8.396510, numObservations: 9
action 4, numVisits=8, meanQ=4.750000, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.372079 0.576596 0.959238 0.373843 0.478468 0.539958 0.772763 0.749594 0.816578 0.151428 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 24
Initial state: 0 0.887486 0.000306442 0.480974 0.548415 0.193775 0.353782 0.446399 0.143486 0.240206 0.147711 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 147441 episodes
GETTING ACTION FROM:
action 5, numVisits=147435, meanQ=8.549667, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.887486 0.000306442 0.480974 0.548415 0.193775 0.353782 0.446399 0.143486 0.240206 0.147711 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=19912, meanQ=10.128264, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 46112 episodes
GETTING ACTION FROM:
action 4, numVisits=66002, meanQ=9.247002, numObservations: 9
action 3, numVisits=8, meanQ=3.123750, numObservations: 5
action 1, numVisits=4, meanQ=0.022047, numObservations: 4
action 0, numVisits=7, meanQ=-1.010000, numObservations: 7
action -1, numVisits=6, meanQ=-1.340000, numObservations: 6
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 4
Next state: 0 0.887486 0.000306442 0.480974 0.548415 0.193775 0.353782 0.446399 0.143486 0.240206 0.147711 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=982, meanQ=10.652901, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-5.946790, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 37654 episodes
GETTING ACTION FROM:
action 2, numVisits=38623, meanQ=7.622995, numObservations: 9
action -1, numVisits=16, meanQ=-1.628750, numObservations: 15
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-5.946790, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.887486 0.000306442 0.480974 0.548415 0.193775 0.353782 0.446399 0.143486 0.240206 0.147711 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 25
Initial state: 0 0.334699 0.469154 0.638635 0.999057 0.567175 0.47124 0.900955 0.759346 0.771185 0.813785 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 147785 episodes
GETTING ACTION FROM:
action 5, numVisits=147779, meanQ=8.553984, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 1 0.334699 0.469154 0.638635 0.999057 0.567175 0.47124 0.900955 0.759346 0.771185 0.813785 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 26
Initial state: 0 0.559652 0.573349 0.477546 0.22361 0.237374 0.429649 0.0985789 0.275216 0.823831 0.331372 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 147053 episodes
GETTING ACTION FROM:
action 2, numVisits=147038, meanQ=8.461912, numObservations: 9
action 4, numVisits=6, meanQ=4.496667, numObservations: 5
action 5, numVisits=5, meanQ=4.400000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.559652 0.573349 0.477546 0.22361 0.237374 0.429649 0.0985789 0.275216 0.823831 0.331372 w: 1
Observation: 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 27
Initial state: 0 0.464829 0.512374 0.518816 0.818929 0.729888 0.397854 0.945285 0.746485 0.161036 0.422227 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 147297 episodes
GETTING ACTION FROM:
action 4, numVisits=147255, meanQ=8.533049, numObservations: 9
action 5, numVisits=31, meanQ=6.866129, numObservations: 9
action 1, numVisits=5, meanQ=4.400000, numObservations: 4
action 2, numVisits=3, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.464829 0.512374 0.518816 0.818929 0.729888 0.397854 0.945285 0.746485 0.161036 0.422227 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 28
Initial state: 0 0.802881 0.691757 0.165714 0.0497612 0.719901 0.78836 0.0505639 0.716693 0.463634 0.534669 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 147683 episodes
GETTING ACTION FROM:
action 5, numVisits=147669, meanQ=8.426406, numObservations: 9
action 1, numVisits=7, meanQ=0.000000, numObservations: 7
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 1 0.802881 0.691757 0.165714 0.0497612 0.719901 0.78836 0.0505639 0.716693 0.463634 0.534669 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 29
Initial state: 0 0.618989 0.24293 0.352559 0.149323 0.0972386 0.658729 0.248007 0.351357 0.519615 0.502564 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 140741 episodes
GETTING ACTION FROM:
action 1, numVisits=140733, meanQ=8.780436, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.618989 0.24293 0.352559 0.149323 0.0972386 0.658729 0.248007 0.351357 0.519615 0.502564 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 30
Initial state: 0 0.22936 0.314173 0.714147 0.801572 0.936734 0.792975 0.461806 0.521248 0.735917 0.265876 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 147636 episodes
GETTING ACTION FROM:
action 4, numVisits=147515, meanQ=8.664405, numObservations: 9
action 5, numVisits=89, meanQ=7.580129, numObservations: 9
action 2, numVisits=22, meanQ=6.316818, numObservations: 9
action 1, numVisits=7, meanQ=5.141429, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 1 0.22936 0.314173 0.714147 0.801572 0.936734 0.792975 0.461806 0.521248 0.735917 0.265876 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 31
Initial state: 0 0.953664 0.904755 0.417449 0.524998 0.328063 0.278507 0.236282 0.815966 0.199089 0.109588 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 147061 episodes
GETTING ACTION FROM:
action 5, numVisits=147055, meanQ=8.396056, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.953664 0.904755 0.417449 0.524998 0.328063 0.278507 0.236282 0.815966 0.199089 0.109588 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=20051, meanQ=10.035367, numObservations: 9
action 1, numVisits=3, meanQ=0.666667, numObservations: 3
action 3, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 44511 episodes
GETTING ACTION FROM:
action 2, numVisits=64416, meanQ=9.862610, numObservations: 9
action 1, numVisits=77, meanQ=6.528884, numObservations: 9
action 4, numVisits=18, meanQ=4.464307, numObservations: 5
action 3, numVisits=3, meanQ=0.666667, numObservations: 3
action 0, numVisits=8, meanQ=-1.133750, numObservations: 8
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=49, meanQ=-20.763859, numObservations: 39
action: 2
Next state: 1 0.953664 0.904755 0.417449 0.524998 0.328063 0.278507 0.236282 0.815966 0.199089 0.109588 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 32
Initial state: 0 0.608152 0.709185 0.445556 0.63569 0.810213 0.0851114 0.115709 0.851199 0.855895 0.329059 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 146923 episodes
GETTING ACTION FROM:
action 4, numVisits=146915, meanQ=8.512129, numObservations: 9
action 3, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.608152 0.709185 0.445556 0.63569 0.810213 0.0851114 0.115709 0.851199 0.855895 0.329059 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=11626, meanQ=9.884273, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 49030 episodes
GETTING ACTION FROM:
action 3, numVisits=60647, meanQ=10.713483, numObservations: 9
action -1, numVisits=6, meanQ=-1.175000, numObservations: 6
action 0, numVisits=5, meanQ=-1.406000, numObservations: 5
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.608152 0.709185 0.445556 0.63569 0.810213 0.0851114 0.115709 0.851199 0.855895 0.329059 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 33
Initial state: 0 0.669063 0.00970905 0.0382679 0.757247 0.574181 0.557461 0.028861 0.313372 0.732496 0.777383 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 146019 episodes
GETTING ACTION FROM:
action 3, numVisits=146013, meanQ=8.489057, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.669063 0.00970905 0.0382679 0.757247 0.574181 0.557461 0.028861 0.313372 0.732496 0.777383 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 34
Initial state: 0 0.248245 0.0941116 0.365889 0.770694 0.393843 0.423715 0.311571 0.896407 0.511083 0.572114 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 146970 episodes
GETTING ACTION FROM:
action 3, numVisits=146944, meanQ=8.531435, numObservations: 9
action 2, numVisits=15, meanQ=-0.333327, numObservations: 7
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.248245 0.0941116 0.365889 0.770694 0.393843 0.423715 0.311571 0.896407 0.511083 0.572114 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 35
Initial state: 0 0.527153 0.421758 0.169618 0.731556 0.150005 0.779076 0.401914 0.550293 0.914655 0.459742 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 142773 episodes
GETTING ACTION FROM:
action 2, numVisits=141650, meanQ=8.474961, numObservations: 9
action 3, numVisits=662, meanQ=8.096417, numObservations: 9
action 1, numVisits=441, meanQ=8.065148, numObservations: 9
action 4, numVisits=13, meanQ=6.306923, numObservations: 6
action 5, numVisits=5, meanQ=4.400000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.527153 0.421758 0.169618 0.731556 0.150005 0.779076 0.401914 0.550293 0.914655 0.459742 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=11270, meanQ=10.398886, numObservations: 9
action 1, numVisits=17, meanQ=8.939412, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 48152 episodes
GETTING ACTION FROM:
action 1, numVisits=48165, meanQ=13.821608, numObservations: 9
action 2, numVisits=11270, meanQ=10.398886, numObservations: 9
action 0, numVisits=3, meanQ=-1.340000, numObservations: 3
action -1, numVisits=3, meanQ=-1.670000, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.527153 0.421758 0.169618 0.731556 0.150005 0.779076 0.401914 0.550293 0.914655 0.459742 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=629, meanQ=12.266959, numObservations: 9
action 3, numVisits=13, meanQ=5.030494, numObservations: 5
action 1, numVisits=12, meanQ=4.314960, numObservations: 6
action -1, numVisits=6, meanQ=-1.010000, numObservations: 6
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 5, numVisits=1, meanQ=-8.512914, numObservations: 1
action 2, numVisits=1, meanQ=-1019.552706, numObservations: 1
Sampled 74475 episodes
GETTING ACTION FROM:
action 4, numVisits=75104, meanQ=11.899517, numObservations: 9
action 3, numVisits=13, meanQ=5.030494, numObservations: 5
action 1, numVisits=12, meanQ=4.314960, numObservations: 6
action -1, numVisits=6, meanQ=-1.010000, numObservations: 6
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 5, numVisits=1, meanQ=-8.512914, numObservations: 1
action 2, numVisits=1, meanQ=-1019.552706, numObservations: 1
action: 4
Next state: 1 0.527153 0.421758 0.169618 0.731556 0.150005 0.779076 0.401914 0.550293 0.914655 0.459742 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 36
Initial state: 0 0.649916 0.586263 0.00405734 0.920728 0.865746 0.688252 0.883721 0.0352322 0.520119 0.633407 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 147864 episodes
GETTING ACTION FROM:
action 2, numVisits=147847, meanQ=8.358040, numObservations: 9
action -1, numVisits=6, meanQ=-1.010000, numObservations: 6
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 1, numVisits=2, meanQ=-7.500000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.649916 0.586263 0.00405734 0.920728 0.865746 0.688252 0.883721 0.0352322 0.520119 0.633407 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 37
Initial state: 0 0.313279 0.18935 0.160092 0.701219 0.300419 0.751646 0.554438 0.523216 0.0709059 0.776555 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 146384 episodes
GETTING ACTION FROM:
action 3, numVisits=146378, meanQ=8.584769, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.313279 0.18935 0.160092 0.701219 0.300419 0.751646 0.554438 0.523216 0.0709059 0.776555 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=11394, meanQ=10.027321, numObservations: 9
action 1, numVisits=4, meanQ=3.742500, numObservations: 4
action 5, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 56821 episodes
GETTING ACTION FROM:
action 2, numVisits=68210, meanQ=10.344559, numObservations: 9
action 1, numVisits=4, meanQ=3.742500, numObservations: 4
action 5, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=4, meanQ=-1.257500, numObservations: 4
action 0, numVisits=3, meanQ=-1.670000, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.313279 0.18935 0.160092 0.701219 0.300419 0.751646 0.554438 0.523216 0.0709059 0.776555 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=1020, meanQ=13.214598, numObservations: 9
action 4, numVisits=1893, meanQ=8.805573, numObservations: 9
action -1, numVisits=5, meanQ=-1.010000, numObservations: 5
action 0, numVisits=5, meanQ=-1.010000, numObservations: 5
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=13, meanQ=-68.626834, numObservations: 6
Sampled 55566 episodes
GETTING ACTION FROM:
action 5, numVisits=56586, meanQ=14.197231, numObservations: 9
action 4, numVisits=1893, meanQ=8.805573, numObservations: 9
action -1, numVisits=5, meanQ=-1.010000, numObservations: 5
action 0, numVisits=5, meanQ=-1.010000, numObservations: 5
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=13, meanQ=-68.626834, numObservations: 6
action: 5
Next state: 0 0.313279 0.18935 0.160092 0.701219 0.300419 0.751646 0.554438 0.523216 0.0709059 0.776555 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 5, numVisits=938, meanQ=17.085182, numObservations: 9
action 2, numVisits=8, meanQ=3.720593, numObservations: 4
action -1, numVisits=6, meanQ=-1.010000, numObservations: 6
action 0, numVisits=65, meanQ=-2.158394, numObservations: 29
action 1, numVisits=1, meanQ=-9.788585, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=13, meanQ=-64.902596, numObservations: 6
Sampled 65959 episodes
GETTING ACTION FROM:
action 1, numVisits=65954, meanQ=19.749115, numObservations: 9
action 5, numVisits=939, meanQ=17.086282, numObservations: 9
action 2, numVisits=8, meanQ=3.720593, numObservations: 4
action 0, numVisits=65, meanQ=-2.158394, numObservations: 29
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=11, meanQ=-34.316595, numObservations: 8
action 4, numVisits=13, meanQ=-64.902596, numObservations: 6
action: 1
Next state: 0 0.313279 0.18935 0.160092 0.701219 0.300419 0.751646 0.554438 0.523216 0.0709059 0.776555 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 5, numVisits=1, meanQ=24.000000, numObservations: 1
action 4, numVisits=3585, meanQ=22.927718, numObservations: 9
action 1, numVisits=1, meanQ=-8.060547, numObservations: 1
action -1, numVisits=8, meanQ=-46.264781, numObservations: 7
action 0, numVisits=3, meanQ=-121.677710, numObservations: 2
action 3, numVisits=1, meanQ=-361.326378, numObservations: 1
action 2, numVisits=1, meanQ=-363.714456, numObservations: 1
Sampled 140623 episodes
GETTING ACTION FROM:
action 4, numVisits=144207, meanQ=22.565823, numObservations: 9
action 5, numVisits=2, meanQ=6.500000, numObservations: 1
action 1, numVisits=1, meanQ=-8.060547, numObservations: 1
action -1, numVisits=8, meanQ=-46.264781, numObservations: 7
action 0, numVisits=3, meanQ=-121.677710, numObservations: 2
action 3, numVisits=1, meanQ=-361.326378, numObservations: 1
action 2, numVisits=1, meanQ=-363.714456, numObservations: 1
action: 4
Next state: 1 0.313279 0.18935 0.160092 0.701219 0.300419 0.751646 0.554438 0.523216 0.0709059 0.776555 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.29271
Run # 38
Initial state: 0 0.626935 0.438719 0.267983 0.977196 0.430272 0.63585 0.942994 0.237203 0.0387364 0.755151 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 143523 episodes
GETTING ACTION FROM:
action 3, numVisits=143513, meanQ=8.698632, numObservations: 9
action 4, numVisits=3, meanQ=0.666667, numObservations: 3
action 5, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.626935 0.438719 0.267983 0.977196 0.430272 0.63585 0.942994 0.237203 0.0387364 0.755151 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 39
Initial state: 0 0.830427 0.742771 0.167777 0.680253 0.517122 0.519218 0.625361 0.774068 0.541235 0.0980442 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 147747 episodes
GETTING ACTION FROM:
action 5, numVisits=147707, meanQ=8.686398, numObservations: 9
action 1, numVisits=28, meanQ=6.187875, numObservations: 9
action 3, numVisits=6, meanQ=4.496667, numObservations: 5
action 2, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 2 0.830427 0.742771 0.167777 0.680253 0.517122 0.519218 0.625361 0.774068 0.541235 0.0980442 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 40
Initial state: 0 0.819385 0.697776 0.912666 0.888286 0.160715 0.760069 0.322223 0.693377 0.396365 0.616822 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 134259 episodes
GETTING ACTION FROM:
action 4, numVisits=134246, meanQ=8.990536, numObservations: 9
action 5, numVisits=6, meanQ=5.331683, numObservations: 4
action 2, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.819385 0.697776 0.912666 0.888286 0.160715 0.760069 0.322223 0.693377 0.396365 0.616822 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=10502, meanQ=9.622454, numObservations: 9
action 2, numVisits=7, meanQ=5.715729, numObservations: 5
action 1, numVisits=3, meanQ=3.330000, numObservations: 3
action 3, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 49434 episodes
GETTING ACTION FROM:
action 5, numVisits=59848, meanQ=11.437898, numObservations: 9
action 1, numVisits=75, meanQ=7.366978, numObservations: 9
action 2, numVisits=11, meanQ=2.998058, numObservations: 6
action 3, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=9, meanQ=-1.010000, numObservations: 9
action 0, numVisits=5, meanQ=-1.802000, numObservations: 5
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 1 0.819385 0.697776 0.912666 0.888286 0.160715 0.760069 0.322223 0.693377 0.396365 0.616822 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 41
Initial state: 0 0.40683 0.621457 0.401367 0.758422 0.957064 0.828501 0.659233 0.0737526 0.843426 0.168384 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 142888 episodes
GETTING ACTION FROM:
action 4, numVisits=142882, meanQ=8.637864, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.40683 0.621457 0.401367 0.758422 0.957064 0.828501 0.659233 0.0737526 0.843426 0.168384 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 42
Initial state: 0 0.65378 0.976509 0.110635 0.191006 0.389763 0.562455 0.196788 0.358989 0.211439 0.577797 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 146852 episodes
GETTING ACTION FROM:
action 4, numVisits=146836, meanQ=8.580213, numObservations: 9
action 2, numVisits=7, meanQ=5.141429, numObservations: 4
action 1, numVisits=3, meanQ=3.330000, numObservations: 3
action 5, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.65378 0.976509 0.110635 0.191006 0.389763 0.562455 0.196788 0.358989 0.211439 0.577797 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=19697, meanQ=9.812510, numObservations: 9
action 2, numVisits=13, meanQ=7.612308, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 38698 episodes
GETTING ACTION FROM:
action 1, numVisits=58333, meanQ=9.202901, numObservations: 9
action 5, numVisits=26, meanQ=4.817724, numObservations: 9
action 3, numVisits=15, meanQ=4.040040, numObservations: 9
action -1, numVisits=6, meanQ=-1.341650, numObservations: 5
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=5, meanQ=-3.584000, numObservations: 4
action 2, numVisits=27, meanQ=-31.613462, numObservations: 9
action: 1
Next state: 1 0.65378 0.976509 0.110635 0.191006 0.389763 0.562455 0.196788 0.358989 0.211439 0.577797 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 43
Initial state: 0 0.458906 0.061535 0.750848 0.858802 0.553683 0.610837 0.261685 0.0649277 0.592021 0.766912 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 148127 episodes
GETTING ACTION FROM:
action 4, numVisits=87172, meanQ=8.639595, numObservations: 9
action 2, numVisits=60934, meanQ=8.632093, numObservations: 9
action 5, numVisits=10, meanQ=4.901010, numObservations: 3
action 3, numVisits=6, meanQ=4.165017, numObservations: 4
action 1, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 4
Next state: 2 0.458906 0.061535 0.750848 0.858802 0.553683 0.610837 0.261685 0.0649277 0.592021 0.766912 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 44
Initial state: 0 0.930288 0.362125 0.0526412 0.454935 0.765329 0.636861 0.500685 0.505853 0.0430268 0.294678 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 146747 episodes
GETTING ACTION FROM:
action 3, numVisits=146741, meanQ=8.629177, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.930288 0.362125 0.0526412 0.454935 0.765329 0.636861 0.500685 0.505853 0.0430268 0.294678 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 45
Initial state: 0 0.69228 0.737041 0.711794 0.435611 0.328231 0.320665 0.643758 0.00367639 0.417456 0.542162 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 142879 episodes
GETTING ACTION FROM:
action 5, numVisits=142871, meanQ=8.657994, numObservations: 9
action 3, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.69228 0.737041 0.711794 0.435611 0.328231 0.320665 0.643758 0.00367639 0.417456 0.542162 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 46
Initial state: 0 0.80408 0.694585 0.57329 0.480163 0.999497 0.88034 0.173037 0.545929 0.657179 0.615125 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 148069 episodes
GETTING ACTION FROM:
action 3, numVisits=148012, meanQ=8.510888, numObservations: 9
action -1, numVisits=36, meanQ=-0.762775, numObservations: 33
action 0, numVisits=16, meanQ=-1.010000, numObservations: 16
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=2, meanQ=-9.445000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.80408 0.694585 0.57329 0.480163 0.999497 0.88034 0.173037 0.545929 0.657179 0.615125 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 47
Initial state: 0 0.67569 0.250575 0.765906 0.526329 0.538694 0.52886 0.191736 0.330574 0.887071 0.731981 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 146740 episodes
GETTING ACTION FROM:
action 3, numVisits=146732, meanQ=8.546344, numObservations: 9
action 1, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.67569 0.250575 0.765906 0.526329 0.538694 0.52886 0.191736 0.330574 0.887071 0.731981 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 48
Initial state: 0 0.547118 0.497019 0.0303558 0.301404 0.877104 0.0401072 0.3591 0.421743 0.990867 0.178072 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 147198 episodes
GETTING ACTION FROM:
action 1, numVisits=147147, meanQ=8.563248, numObservations: 9
action 4, numVisits=44, meanQ=7.476145, numObservations: 9
action 5, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.547118 0.497019 0.0303558 0.301404 0.877104 0.0401072 0.3591 0.421743 0.990867 0.178072 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 49
Initial state: 0 0.197688 0.671743 0.313832 0.115113 0.213784 0.921484 0.393996 0.346495 0.546691 0.566129 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 147466 episodes
GETTING ACTION FROM:
action 1, numVisits=147448, meanQ=8.447367, numObservations: 9
action 2, numVisits=8, meanQ=0.375000, numObservations: 4
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 5, numVisits=4, meanQ=-2.250000, numObservations: 2
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.197688 0.671743 0.313832 0.115113 0.213784 0.921484 0.393996 0.346495 0.546691 0.566129 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=11795, meanQ=10.180282, numObservations: 9
action 4, numVisits=8, meanQ=5.623762, numObservations: 6
action 3, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 57761 episodes
GETTING ACTION FROM:
action 2, numVisits=69535, meanQ=11.449961, numObservations: 9
action 3, numVisits=3, meanQ=0.666667, numObservations: 2
action 0, numVisits=4, meanQ=-1.257500, numObservations: 4
action -1, numVisits=4, meanQ=-1.257500, numObservations: 4
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=23, meanQ=-28.938498, numObservations: 8
action: 2
Next state: 0 0.197688 0.671743 0.313832 0.115113 0.213784 0.921484 0.393996 0.346495 0.546691 0.566129 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=6302, meanQ=13.226439, numObservations: 9
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=2, meanQ=-6.179641, numObservations: 2
action 5, numVisits=2, meanQ=-7.005000, numObservations: 2
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=55, meanQ=-16.968782, numObservations: 33
action -1, numVisits=5, meanQ=-209.081966, numObservations: 3
Sampled 32741 episodes
GETTING ACTION FROM:
action 3, numVisits=37868, meanQ=14.445805, numObservations: 9
action 5, numVisits=1167, meanQ=11.502668, numObservations: 9
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=2, meanQ=-6.179641, numObservations: 2
action 0, numVisits=55, meanQ=-16.968782, numObservations: 33
action 4, numVisits=11, meanQ=-51.090691, numObservations: 6
action -1, numVisits=5, meanQ=-209.081966, numObservations: 3
action: 3
Next state: 1 0.197688 0.671743 0.313832 0.115113 0.213784 0.921484 0.393996 0.346495 0.546691 0.566129 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 50
Initial state: 0 0.92044 0.460047 0.791672 0.394348 0.000683867 0.224593 0.516701 0.484904 0.345218 0.814148 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 147101 episodes
GETTING ACTION FROM:
action 2, numVisits=147095, meanQ=8.599791, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.92044 0.460047 0.791672 0.394348 0.000683867 0.224593 0.516701 0.484904 0.345218 0.814148 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
[32m ProblemEnvironment.hpp 351: Done.[39m
