Run # 1
Initial state: 0 0.427128 0.453386 0.798581 0.695378 0.850647 0.862929 0.817883 0.259625 0.28418 0.38358 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 164714 episodes
GETTING ACTION FROM:
action 4, numVisits=164704, meanQ=12.312916, numObservations: 9
action 1, numVisits=3, meanQ=3.000000, numObservations: 3
action 5, numVisits=3, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.427128 0.453386 0.798581 0.695378 0.850647 0.862929 0.817883 0.259625 0.28418 0.38358 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 2
Initial state: 0 0.352624 0.177697 0.449937 0.474018 0.325969 0.40633 0.0495438 0.485128 0.752354 0.764929 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168448 episodes
GETTING ACTION FROM:
action 4, numVisits=168421, meanQ=12.312043, numObservations: 9
action 5, numVisits=22, meanQ=10.771364, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.352624 0.177697 0.449937 0.474018 0.325969 0.40633 0.0495438 0.485128 0.752354 0.764929 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=12174, meanQ=13.081510, numObservations: 9
action 4, numVisits=5, meanQ=6.946000, numObservations: 3
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action 5, numVisits=4, meanQ=6.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 79595 episodes
GETTING ACTION FROM:
action 3, numVisits=91764, meanQ=13.379887, numObservations: 9
action 4, numVisits=5, meanQ=6.946000, numObservations: 3
action 5, numVisits=4, meanQ=6.500000, numObservations: 3
action 2, numVisits=3, meanQ=3.000000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action -1, numVisits=3, meanQ=-1.340000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.352624 0.177697 0.449937 0.474018 0.325969 0.40633 0.0495438 0.485128 0.752354 0.764929 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 3
Initial state: 0 0.270896 0.417438 0.0867806 0.419988 0.87417 0.981672 0.307 0.945645 0.821253 0.975239 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 160796 episodes
GETTING ACTION FROM:
action 4, numVisits=160761, meanQ=12.337660, numObservations: 9
action 5, numVisits=24, meanQ=8.420833, numObservations: 7
action 3, numVisits=7, meanQ=5.857157, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.270896 0.417438 0.0867806 0.419988 0.87417 0.981672 0.307 0.945645 0.821253 0.975239 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 4
Initial state: 0 0.307669 0.618964 0.272628 0.38556 0.573302 0.931035 0.22208 0.364237 0.997806 0.248934 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168881 episodes
GETTING ACTION FROM:
action 2, numVisits=168875, meanQ=12.154442, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.307669 0.618964 0.272628 0.38556 0.573302 0.931035 0.22208 0.364237 0.997806 0.248934 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 5
Initial state: 0 0.752955 0.214762 0.114999 0.649374 0.312379 0.404501 0.282069 0.961051 0.816598 0.490213 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168621 episodes
GETTING ACTION FROM:
action 3, numVisits=168611, meanQ=12.302851, numObservations: 9
action 1, numVisits=5, meanQ=4.400000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.752955 0.214762 0.114999 0.649374 0.312379 0.404501 0.282069 0.961051 0.816598 0.490213 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 6
Initial state: 0 0.446525 0.680724 0.252388 0.386725 0.903615 0.984693 0.117167 0.0208446 0.202818 0.818951 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168010 episodes
GETTING ACTION FROM:
action 4, numVisits=167979, meanQ=12.261913, numObservations: 9
action 3, numVisits=22, meanQ=10.578636, numObservations: 9
action 5, numVisits=4, meanQ=8.250000, numObservations: 2
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.446525 0.680724 0.252388 0.386725 0.903615 0.984693 0.117167 0.0208446 0.202818 0.818951 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=3081, meanQ=12.910191, numObservations: 9
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 155058 episodes
GETTING ACTION FROM:
action 3, numVisits=158102, meanQ=9.453928, numObservations: 9
action 1, numVisits=19, meanQ=6.032515, numObservations: 8
action 2, numVisits=13, meanQ=5.768462, numObservations: 6
action 0, numVisits=5, meanQ=-1.604000, numObservations: 5
action -1, numVisits=5, meanQ=-1.802000, numObservations: 5
action 5, numVisits=2, meanQ=-7.005000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.446525 0.680724 0.252388 0.386725 0.903615 0.984693 0.117167 0.0208446 0.202818 0.818951 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 7
Initial state: 0 0.101081 0.564206 0.712657 0.235708 0.708667 0.282997 0.266497 0.400866 0.232078 0.692891 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168421 episodes
GETTING ACTION FROM:
action 5, numVisits=168409, meanQ=12.306024, numObservations: 9
action 2, numVisits=6, meanQ=8.833333, numObservations: 4
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.101081 0.564206 0.712657 0.235708 0.708667 0.282997 0.266497 0.400866 0.232078 0.692891 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=11735, meanQ=13.098682, numObservations: 9
action 2, numVisits=35, meanQ=9.836006, numObservations: 7
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 67549 episodes
GETTING ACTION FROM:
action 4, numVisits=78907, meanQ=13.625785, numObservations: 9
action 1, numVisits=375, meanQ=11.321994, numObservations: 9
action 2, numVisits=35, meanQ=9.836006, numObservations: 7
action -1, numVisits=3, meanQ=-1.340000, numObservations: 3
action 0, numVisits=3, meanQ=-1.340000, numObservations: 3
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.101081 0.564206 0.712657 0.235708 0.708667 0.282997 0.266497 0.400866 0.232078 0.692891 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 8
Initial state: 0 0.87247 0.551928 0.174283 0.594064 0.32303 0.451056 0.960325 0.811582 0.23869 0.0408487 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168320 episodes
GETTING ACTION FROM:
action 1, numVisits=168309, meanQ=12.297411, numObservations: 9
action 4, numVisits=3, meanQ=3.000000, numObservations: 3
action 3, numVisits=4, meanQ=1.250000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.87247 0.551928 0.174283 0.594064 0.32303 0.451056 0.960325 0.811582 0.23869 0.0408487 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 9
Initial state: 0 0.744351 0.103601 0.684441 0.677597 0.272037 0.404197 0.262642 0.323938 0.52083 0.7325 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168900 episodes
GETTING ACTION FROM:
action 3, numVisits=168893, meanQ=12.160968, numObservations: 9
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.744351 0.103601 0.684441 0.677597 0.272037 0.404197 0.262642 0.323938 0.52083 0.7325 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 10
Initial state: 0 0.649911 0.706217 0.218239 0.184333 0.323776 0.448273 0.796205 0.896326 0.334186 0.998841 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168595 episodes
GETTING ACTION FROM:
action 2, numVisits=168562, meanQ=12.232018, numObservations: 9
action 4, numVisits=11, meanQ=9.010000, numObservations: 6
action 5, numVisits=15, meanQ=8.340667, numObservations: 5
action 3, numVisits=4, meanQ=6.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.649911 0.706217 0.218239 0.184333 0.323776 0.448273 0.796205 0.896326 0.334186 0.998841 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=9353, meanQ=12.665304, numObservations: 9
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action 4, numVisits=4, meanQ=6.500000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 67707 episodes
GETTING ACTION FROM:
action 3, numVisits=77051, meanQ=12.954334, numObservations: 9
action 4, numVisits=8, meanQ=6.500000, numObservations: 5
action 1, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=3, meanQ=-1.340000, numObservations: 2
action 0, numVisits=3, meanQ=-1.340000, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.649911 0.706217 0.218239 0.184333 0.323776 0.448273 0.796205 0.896326 0.334186 0.998841 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 11
Initial state: 0 0.749574 0.612017 0.298247 0.463869 0.765203 0.155646 0.0120796 0.419255 0.81371 0.70893 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163261 episodes
GETTING ACTION FROM:
action 5, numVisits=163245, meanQ=12.283663, numObservations: 9
action 1, numVisits=9, meanQ=-0.111111, numObservations: 7
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.749574 0.612017 0.298247 0.463869 0.765203 0.155646 0.0120796 0.419255 0.81371 0.70893 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 12
Initial state: 0 0.963902 0.133937 0.350946 0.347534 0.789904 0.59016 0.699092 0.533336 0.390112 0.684538 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168710 episodes
GETTING ACTION FROM:
action 4, numVisits=168704, meanQ=12.277904, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.963902 0.133937 0.350946 0.347534 0.789904 0.59016 0.699092 0.533336 0.390112 0.684538 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 13
Initial state: 0 0.0197712 0.447928 0.717427 0.954163 0.272785 0.390794 0.263358 0.0958675 0.597219 0.500266 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168245 episodes
GETTING ACTION FROM:
action 2, numVisits=168233, meanQ=12.113147, numObservations: 9
action 1, numVisits=3, meanQ=3.000000, numObservations: 3
action 3, numVisits=5, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.0197712 0.447928 0.717427 0.954163 0.272785 0.390794 0.263358 0.0958675 0.597219 0.500266 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 14
Initial state: 0 0.281188 0.433948 0.932602 0.281062 0.381871 0.780926 0.379093 0.0881053 0.618424 0.976867 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 169066 episodes
GETTING ACTION FROM:
action 1, numVisits=169058, meanQ=12.226259, numObservations: 9
action 2, numVisits=3, meanQ=3.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.281188 0.433948 0.932602 0.281062 0.381871 0.780926 0.379093 0.0881053 0.618424 0.976867 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 15
Initial state: 0 0.960502 0.016408 0.316423 0.346359 0.411734 0.454559 0.841041 0.306383 0.765768 0.139714 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168923 episodes
GETTING ACTION FROM:
action 2, numVisits=168904, meanQ=12.259103, numObservations: 9
action 5, numVisits=11, meanQ=5.269091, numObservations: 6
action 3, numVisits=4, meanQ=1.250000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.960502 0.016408 0.316423 0.346359 0.411734 0.454559 0.841041 0.306383 0.765768 0.139714 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 16
Initial state: 0 0.287649 0.441777 0.299297 0.533274 0.536483 0.935521 0.740929 0.925339 0.0580762 0.922273 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168934 episodes
GETTING ACTION FROM:
action 4, numVisits=168926, meanQ=12.338808, numObservations: 9
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action 5, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.287649 0.441777 0.299297 0.533274 0.536483 0.935521 0.740929 0.925339 0.0580762 0.922273 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 17
Initial state: 0 0.275122 0.387438 0.0826286 0.258837 0.360459 0.358995 0.862482 0.0513085 0.503001 0.123911 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168148 episodes
GETTING ACTION FROM:
action 1, numVisits=168138, meanQ=12.300297, numObservations: 9
action 3, numVisits=5, meanQ=7.000020, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.275122 0.387438 0.0826286 0.258837 0.360459 0.358995 0.862482 0.0513085 0.503001 0.123911 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 18
Initial state: 0 0.349577 0.400255 0.267987 0.999363 0.678914 0.824223 0.0102011 0.154339 0.0175417 0.223349 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168107 episodes
GETTING ACTION FROM:
action 5, numVisits=168093, meanQ=12.193143, numObservations: 9
action 2, numVisits=7, meanQ=7.290029, numObservations: 4
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action 4, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 0 0.349577 0.400255 0.267987 0.999363 0.678914 0.824223 0.0102011 0.154339 0.0175417 0.223349 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=9293, meanQ=13.046802, numObservations: 9
action 3, numVisits=15, meanQ=9.532673, numObservations: 7
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action 4, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 73859 episodes
GETTING ACTION FROM:
action 1, numVisits=83145, meanQ=12.864150, numObservations: 9
action 3, numVisits=16, meanQ=8.318622, numObservations: 7
action 4, numVisits=3, meanQ=3.000000, numObservations: 2
action 2, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.349577 0.400255 0.267987 0.999363 0.678914 0.824223 0.0102011 0.154339 0.0175417 0.223349 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 19
Initial state: 0 0.3415 0.416162 0.91801 0.823493 0.807981 0.564354 0.673961 0.0476746 0.460926 0.305124 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 169102 episodes
GETTING ACTION FROM:
action 4, numVisits=163669, meanQ=12.174216, numObservations: 9
action 5, numVisits=5410, meanQ=12.080595, numObservations: 9
action 2, numVisits=19, meanQ=10.420526, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 2 0.3415 0.416162 0.91801 0.823493 0.807981 0.564354 0.673961 0.0476746 0.460926 0.305124 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 20
Initial state: 0 0.310043 0.341867 0.654557 0.710555 0.490105 0.622693 0.141304 0.863086 0.637021 0.218282 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168228 episodes
GETTING ACTION FROM:
action 4, numVisits=168218, meanQ=12.277148, numObservations: 9
action 2, numVisits=3, meanQ=0.666667, numObservations: 2
action 3, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.310043 0.341867 0.654557 0.710555 0.490105 0.622693 0.141304 0.863086 0.637021 0.218282 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 21
Initial state: 0 0.573267 0.93697 0.634874 0.793833 0.278917 0.997961 0.6881 0.136032 0.316223 0.416832 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 169131 episodes
GETTING ACTION FROM:
action 4, numVisits=169120, meanQ=12.276011, numObservations: 9
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action 3, numVisits=3, meanQ=3.000000, numObservations: 2
action 5, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.573267 0.93697 0.634874 0.793833 0.278917 0.997961 0.6881 0.136032 0.316223 0.416832 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 22
Initial state: 0 0.951238 0.0312059 0.291102 0.441482 0.653241 0.333151 0.801233 0.534297 0.601687 0.435266 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167383 episodes
GETTING ACTION FROM:
action 5, numVisits=167373, meanQ=12.315376, numObservations: 9
action 4, numVisits=5, meanQ=4.400000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.951238 0.0312059 0.291102 0.441482 0.653241 0.333151 0.801233 0.534297 0.601687 0.435266 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 23
Initial state: 0 0.239599 0.548693 0.642514 0.533945 0.320377 0.332456 0.678691 0.993902 0.142008 0.700338 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168204 episodes
GETTING ACTION FROM:
action 5, numVisits=168195, meanQ=12.147984, numObservations: 9
action 2, numVisits=4, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.239599 0.548693 0.642514 0.533945 0.320377 0.332456 0.678691 0.993902 0.142008 0.700338 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 24
Initial state: 0 0.133982 0.795559 0.539276 0.741574 0.292843 0.395496 0.687702 0.153428 0.948471 0.0760948 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168739 episodes
GETTING ACTION FROM:
action 2, numVisits=168719, meanQ=12.363095, numObservations: 9
action 1, numVisits=15, meanQ=8.065353, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.133982 0.795559 0.539276 0.741574 0.292843 0.395496 0.687702 0.153428 0.948471 0.0760948 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 25
Initial state: 0 0.368292 0.125995 0.673465 0.0398197 0.269354 0.444921 0.413783 0.0605741 0.44553 0.192277 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168759 episodes
GETTING ACTION FROM:
action 2, numVisits=168752, meanQ=12.229827, numObservations: 9
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.368292 0.125995 0.673465 0.0398197 0.269354 0.444921 0.413783 0.0605741 0.44553 0.192277 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 26
Initial state: 0 0.97159 0.0528056 0.344581 0.335228 0.797231 0.14144 0.450326 0.252858 0.509526 0.225395 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166977 episodes
GETTING ACTION FROM:
action 2, numVisits=166920, meanQ=12.248240, numObservations: 9
action 3, numVisits=48, meanQ=10.681671, numObservations: 9
action 4, numVisits=2, meanQ=6.500000, numObservations: 2
action 5, numVisits=2, meanQ=6.500000, numObservations: 1
action 1, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.97159 0.0528056 0.344581 0.335228 0.797231 0.14144 0.450326 0.252858 0.509526 0.225395 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 27
Initial state: 0 0.172185 0.753963 0.765588 0.769111 0.323226 0.418608 0.214481 0.786907 0.584617 0.945003 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166587 episodes
GETTING ACTION FROM:
action 2, numVisits=166537, meanQ=12.283104, numObservations: 9
action 1, numVisits=27, meanQ=6.370370, numObservations: 7
action 5, numVisits=11, meanQ=5.545455, numObservations: 5
action 3, numVisits=5, meanQ=4.400000, numObservations: 4
action 4, numVisits=5, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.172185 0.753963 0.765588 0.769111 0.323226 0.418608 0.214481 0.786907 0.584617 0.945003 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 28
Initial state: 0 0.683623 0.285038 0.352459 0.390589 0.87586 0.642482 0.381226 0.318099 0.648266 0.560528 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168630 episodes
GETTING ACTION FROM:
action 5, numVisits=168624, meanQ=12.115793, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.683623 0.285038 0.352459 0.390589 0.87586 0.642482 0.381226 0.318099 0.648266 0.560528 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 29
Initial state: 0 0.336922 0.402499 0.418278 0.368353 0.549635 0.704401 0.0226977 0.113276 0.782006 0.22432 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167802 episodes
GETTING ACTION FROM:
action 3, numVisits=166927, meanQ=12.166588, numObservations: 9
action 4, numVisits=869, meanQ=11.869226, numObservations: 9
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.336922 0.402499 0.418278 0.368353 0.549635 0.704401 0.0226977 0.113276 0.782006 0.22432 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 30
Initial state: 0 0.679035 0.787959 0.348144 0.37254 0.725353 0.679045 0.668976 0.961337 0.177226 0.174648 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168089 episodes
GETTING ACTION FROM:
action 5, numVisits=168059, meanQ=11.998470, numObservations: 9
action 3, numVisits=20, meanQ=4.749505, numObservations: 8
action 4, numVisits=6, meanQ=3.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.679035 0.787959 0.348144 0.37254 0.725353 0.679045 0.668976 0.961337 0.177226 0.174648 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=3153, meanQ=12.515660, numObservations: 9
action 1, numVisits=16, meanQ=8.497500, numObservations: 8
action 2, numVisits=14, meanQ=7.909286, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 143826 episodes
GETTING ACTION FROM:
action 4, numVisits=146959, meanQ=9.787466, numObservations: 9
action 1, numVisits=23, meanQ=7.128696, numObservations: 8
action 2, numVisits=19, meanQ=6.617368, numObservations: 6
action -1, numVisits=5, meanQ=-1.802000, numObservations: 5
action 0, numVisits=5, meanQ=-1.802000, numObservations: 5
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.679035 0.787959 0.348144 0.37254 0.725353 0.679045 0.668976 0.961337 0.177226 0.174648 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 31
Initial state: 0 0.910055 0.0255308 0.0408122 0.383524 0.419687 0.16448 0.754864 0.256841 0.266064 0.389749 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168212 episodes
GETTING ACTION FROM:
action 2, numVisits=168206, meanQ=12.308009, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.910055 0.0255308 0.0408122 0.383524 0.419687 0.16448 0.754864 0.256841 0.266064 0.389749 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 32
Initial state: 0 0.502136 0.896575 0.372336 0.215136 0.108499 0.00619019 0.283828 0.441869 0.501871 0.64422 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166805 episodes
GETTING ACTION FROM:
action 5, numVisits=166796, meanQ=12.143706, numObservations: 9
action 2, numVisits=4, meanQ=-0.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.502136 0.896575 0.372336 0.215136 0.108499 0.00619019 0.283828 0.441869 0.501871 0.64422 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 33
Initial state: 0 0.849024 0.920328 0.10848 0.675886 0.272073 0.372958 0.983572 0.51305 0.0535442 0.873158 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167211 episodes
GETTING ACTION FROM:
action 3, numVisits=167191, meanQ=12.127632, numObservations: 9
action 5, numVisits=10, meanQ=8.600000, numObservations: 5
action 4, numVisits=6, meanQ=7.666667, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.849024 0.920328 0.10848 0.675886 0.272073 0.372958 0.983572 0.51305 0.0535442 0.873158 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=2658, meanQ=10.936410, numObservations: 9
action 2, numVisits=9, meanQ=2.442222, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 139870 episodes
GETTING ACTION FROM:
action 1, numVisits=142524, meanQ=11.880558, numObservations: 9
action 2, numVisits=9, meanQ=2.442222, numObservations: 6
action -1, numVisits=3, meanQ=-1.340000, numObservations: 2
action 0, numVisits=3, meanQ=-1.670000, numObservations: 3
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.849024 0.920328 0.10848 0.675886 0.272073 0.372958 0.983572 0.51305 0.0535442 0.873158 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 34
Initial state: 0 0.394118 0.155561 0.0801761 0.890777 0.34524 0.375816 0.546324 0.0877641 0.646735 0.847036 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167802 episodes
GETTING ACTION FROM:
action 4, numVisits=167794, meanQ=12.271111, numObservations: 9
action 2, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.394118 0.155561 0.0801761 0.890777 0.34524 0.375816 0.546324 0.0877641 0.646735 0.847036 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 35
Initial state: 0 0.305219 0.337269 0.872701 0.802095 0.631116 0.212256 0.915732 0.223962 0.506854 0.488446 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168916 episodes
GETTING ACTION FROM:
action 2, numVisits=168894, meanQ=12.287718, numObservations: 9
action 4, numVisits=17, meanQ=9.412365, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.305219 0.337269 0.872701 0.802095 0.631116 0.212256 0.915732 0.223962 0.506854 0.488446 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 36
Initial state: 0 0.357874 0.357424 0.729404 0.650022 0.683637 0.700153 0.841917 0.226114 0.257553 0.0227171 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163073 episodes
GETTING ACTION FROM:
action 5, numVisits=163065, meanQ=12.296504, numObservations: 9
action 1, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 2 0.357874 0.357424 0.729404 0.650022 0.683637 0.700153 0.841917 0.226114 0.257553 0.0227171 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 37
Initial state: 0 0.720158 0.365412 0.388757 0.972404 0.306596 0.409375 0.169311 0.999406 0.379693 0.695828 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161146 episodes
GETTING ACTION FROM:
action 4, numVisits=161132, meanQ=12.324855, numObservations: 9
action 3, numVisits=9, meanQ=1.444444, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.720158 0.365412 0.388757 0.972404 0.306596 0.409375 0.169311 0.999406 0.379693 0.695828 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=11224, meanQ=13.220839, numObservations: 9
action 3, numVisits=52, meanQ=12.405398, numObservations: 9
action 2, numVisits=8, meanQ=10.875000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 62636 episodes
GETTING ACTION FROM:
action 3, numVisits=62678, meanQ=13.315713, numObservations: 9
action 4, numVisits=11224, meanQ=13.220839, numObservations: 9
action 2, numVisits=14, meanQ=10.000000, numObservations: 6
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.340000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.720158 0.365412 0.388757 0.972404 0.306596 0.409375 0.169311 0.999406 0.379693 0.695828 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 38
Initial state: 0 0.211194 0.0831685 0.306846 0.378063 0.953238 0.853528 0.849367 0.742453 0.724666 0.301769 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165709 episodes
GETTING ACTION FROM:
action 5, numVisits=165694, meanQ=12.229292, numObservations: 9
action 4, numVisits=8, meanQ=7.375000, numObservations: 7
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 2 0.211194 0.0831685 0.306846 0.378063 0.953238 0.853528 0.849367 0.742453 0.724666 0.301769 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 39
Initial state: 0 0.523054 0.49425 0.656069 0.0131466 0.0171314 0.853515 0.300357 0.341492 0.721168 0.503696 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166987 episodes
GETTING ACTION FROM:
action 4, numVisits=166955, meanQ=12.168644, numObservations: 9
action 5, numVisits=19, meanQ=8.630526, numObservations: 7
action 2, numVisits=8, meanQ=7.375000, numObservations: 5
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.523054 0.49425 0.656069 0.0131466 0.0171314 0.853515 0.300357 0.341492 0.721168 0.503696 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=2593, meanQ=11.627000, numObservations: 9
action 1, numVisits=9, meanQ=5.898889, numObservations: 5
action 5, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 168899 episodes
GETTING ACTION FROM:
action 2, numVisits=171489, meanQ=13.475984, numObservations: 9
action 1, numVisits=9, meanQ=5.898889, numObservations: 5
action 5, numVisits=3, meanQ=3.330000, numObservations: 2
action 0, numVisits=3, meanQ=-1.340000, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.523054 0.49425 0.656069 0.0131466 0.0171314 0.853515 0.300357 0.341492 0.721168 0.503696 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 40
Initial state: 0 0.983729 0.804224 0.950669 0.867833 0.356979 0.385704 0.0652031 0.0300104 0.503942 0.425992 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167240 episodes
GETTING ACTION FROM:
action 4, numVisits=167223, meanQ=12.209145, numObservations: 9
action 2, numVisits=12, meanQ=10.000000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.983729 0.804224 0.950669 0.867833 0.356979 0.385704 0.0652031 0.0300104 0.503942 0.425992 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=9289, meanQ=12.898531, numObservations: 9
action 3, numVisits=4, meanQ=8.497500, numObservations: 3
action 4, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 70922 episodes
GETTING ACTION FROM:
action 1, numVisits=80204, meanQ=13.065255, numObservations: 9
action 3, numVisits=7, meanQ=6.141429, numObservations: 4
action 4, numVisits=3, meanQ=5.993333, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=3, meanQ=-354.354991, numObservations: 2
action: 1
Next state: 1 0.983729 0.804224 0.950669 0.867833 0.356979 0.385704 0.0652031 0.0300104 0.503942 0.425992 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 41
Initial state: 0 0.297259 0.461745 0.56784 0.661341 0.932296 0.0314109 0.752411 0.734535 0.543508 0.772813 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167867 episodes
GETTING ACTION FROM:
action 3, numVisits=167798, meanQ=12.226616, numObservations: 9
action 2, numVisits=36, meanQ=9.659728, numObservations: 9
action 1, numVisits=15, meanQ=8.406667, numObservations: 5
action 5, numVisits=8, meanQ=7.877512, numObservations: 5
action 4, numVisits=8, meanQ=7.843750, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 2 0.297259 0.461745 0.56784 0.661341 0.932296 0.0314109 0.752411 0.734535 0.543508 0.772813 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 42
Initial state: 0 0.777441 0.317956 0.258712 0.418195 0.114956 0.078662 0.92164 0.450494 0.374583 0.895623 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168571 episodes
GETTING ACTION FROM:
action 5, numVisits=168555, meanQ=12.154845, numObservations: 9
action 3, numVisits=5, meanQ=5.800000, numObservations: 4
action 1, numVisits=7, meanQ=5.000000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.777441 0.317956 0.258712 0.418195 0.114956 0.078662 0.92164 0.450494 0.374583 0.895623 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 43
Initial state: 0 0.845836 0.74824 0.793962 0.113187 0.965108 0.936862 0.628363 0.838964 0.267411 0.374054 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168786 episodes
GETTING ACTION FROM:
action 4, numVisits=168750, meanQ=12.299636, numObservations: 9
action 2, numVisits=31, meanQ=9.137745, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.845836 0.74824 0.793962 0.113187 0.965108 0.936862 0.628363 0.838964 0.267411 0.374054 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 44
Initial state: 0 0.904838 0.753335 0.808753 0.98387 0.0194531 0.645216 0.3263 0.334965 0.685673 0.845898 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167327 episodes
GETTING ACTION FROM:
action 2, numVisits=167318, meanQ=12.106533, numObservations: 9
action 3, numVisits=4, meanQ=1.250000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.904838 0.753335 0.808753 0.98387 0.0194531 0.645216 0.3263 0.334965 0.685673 0.845898 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 45
Initial state: 0 0.93506 0.525802 0.98501 0.109345 0.179778 0.49723 0.810364 0.565361 0.285478 0.376542 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168701 episodes
GETTING ACTION FROM:
action 2, numVisits=168654, meanQ=12.106934, numObservations: 9
action 4, numVisits=40, meanQ=8.624750, numObservations: 7
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 2 0.93506 0.525802 0.98501 0.109345 0.179778 0.49723 0.810364 0.565361 0.285478 0.376542 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 46
Initial state: 0 0.951464 0.185248 0.740889 0.532255 0.0232094 0.247013 0.481499 0.539528 0.273748 0.434713 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168361 episodes
GETTING ACTION FROM:
action 4, numVisits=168346, meanQ=12.127046, numObservations: 9
action 5, numVisits=8, meanQ=9.125000, numObservations: 5
action 3, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.951464 0.185248 0.740889 0.532255 0.0232094 0.247013 0.481499 0.539528 0.273748 0.434713 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 47
Initial state: 0 0.293838 0.460738 0.959211 0.95937 0.58152 0.00928005 0.753493 0.238963 0.514928 0.982903 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168235 episodes
GETTING ACTION FROM:
action 3, numVisits=167887, meanQ=12.243022, numObservations: 9
action 1, numVisits=336, meanQ=11.286742, numObservations: 9
action 2, numVisits=8, meanQ=9.372500, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.293838 0.460738 0.959211 0.95937 0.58152 0.00928005 0.753493 0.238963 0.514928 0.982903 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 48
Initial state: 0 0.357011 0.392712 0.952402 0.790893 0.998935 0.06725 0.562967 0.552575 0.629844 0.504584 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162886 episodes
GETTING ACTION FROM:
action 4, numVisits=162867, meanQ=12.212238, numObservations: 9
action 3, numVisits=14, meanQ=7.363571, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.357011 0.392712 0.952402 0.790893 0.998935 0.06725 0.562967 0.552575 0.629844 0.504584 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 49
Initial state: 0 0.0066623 0.126215 0.805205 0.780849 0.254235 0.360265 0.381986 0.164404 0.9425 0.991259 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162843 episodes
GETTING ACTION FROM:
action 4, numVisits=162799, meanQ=11.967752, numObservations: 9
action 1, numVisits=14, meanQ=10.070714, numObservations: 5
action 5, numVisits=19, meanQ=10.052105, numObservations: 5
action 2, numVisits=4, meanQ=8.250000, numObservations: 4
action 3, numVisits=5, meanQ=7.596000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 4
Next state: 2 0.0066623 0.126215 0.805205 0.780849 0.254235 0.360265 0.381986 0.164404 0.9425 0.991259 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 50
Initial state: 0 0.617627 0.34106 0.254839 0.457556 0.660974 0.147359 0.0505002 0.0520372 0.644134 0.646165 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 158192 episodes
GETTING ACTION FROM:
action 4, numVisits=158176, meanQ=12.352285, numObservations: 9
action 3, numVisits=11, meanQ=9.100000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.617627 0.34106 0.254839 0.457556 0.660974 0.147359 0.0505002 0.0520372 0.644134 0.646165 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=8826, meanQ=12.581806, numObservations: 9
action 1, numVisits=27, meanQ=9.044074, numObservations: 6
action 2, numVisits=15, meanQ=8.732000, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 55650 episodes
GETTING ACTION FROM:
action 3, numVisits=64455, meanQ=11.821533, numObservations: 9
action 1, numVisits=32, meanQ=8.006392, numObservations: 7
action 2, numVisits=25, meanQ=7.717577, numObservations: 6
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=4, meanQ=-3.980717, numObservations: 3
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.617627 0.34106 0.254839 0.457556 0.660974 0.147359 0.0505002 0.0520372 0.644134 0.646165 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
[32m ProblemEnvironment.hpp 351: Done.[39m
