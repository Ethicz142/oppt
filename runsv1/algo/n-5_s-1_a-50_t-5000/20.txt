Run # 1
Initial state: 0 0.775065 0.192911 0.783271 0.723617 0.161362 0.0105209 0.755487 0.937467 0.559327 0.482103 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 140032 episodes
GETTING ACTION FROM:
action 2, numVisits=140019, meanQ=11.553151, numObservations: 9
action 1, numVisits=8, meanQ=1.717512, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.775065 0.192911 0.783271 0.723617 0.161362 0.0105209 0.755487 0.937467 0.559327 0.482103 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 2
Initial state: 0 0.955724 0.401927 0.405945 0.779533 0.526126 0.492318 0.972442 0.52208 0.622315 0.628209 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 142885 episodes
GETTING ACTION FROM:
action 4, numVisits=142877, meanQ=11.720595, numObservations: 9
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 1 0.955724 0.401927 0.405945 0.779533 0.526126 0.492318 0.972442 0.52208 0.622315 0.628209 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 3
Initial state: 0 0.715299 0.919918 0.398012 0.955176 0.815886 0.640519 0.540397 0.420389 0.386981 0.618911 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 143587 episodes
GETTING ACTION FROM:
action 4, numVisits=143574, meanQ=11.580472, numObservations: 9
action 1, numVisits=6, meanQ=1.185000, numObservations: 4
action 3, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.715299 0.919918 0.398012 0.955176 0.815886 0.640519 0.540397 0.420389 0.386981 0.618911 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 4
Initial state: 0 0.448519 0.416571 0.466111 0.162067 0.813976 0.279756 0.963419 0.73029 0.189876 0.457346 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 142924 episodes
GETTING ACTION FROM:
action 2, numVisits=142916, meanQ=11.408492, numObservations: 9
action 4, numVisits=3, meanQ=5.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.448519 0.416571 0.466111 0.162067 0.813976 0.279756 0.963419 0.73029 0.189876 0.457346 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=2234, meanQ=12.341513, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 138056 episodes
GETTING ACTION FROM:
action 1, numVisits=140275, meanQ=7.660923, numObservations: 9
action -1, numVisits=8, meanQ=-1.752500, numObservations: 8
action 0, numVisits=8, meanQ=-1.752500, numObservations: 8
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.448519 0.416571 0.466111 0.162067 0.813976 0.279756 0.963419 0.73029 0.189876 0.457346 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=469, meanQ=20.519887, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 155028 episodes
GETTING ACTION FROM:
action 1, numVisits=622, meanQ=20.975783, numObservations: 9
action 4, numVisits=154868, meanQ=14.414817, numObservations: 9
action -1, numVisits=5, meanQ=-1.802000, numObservations: 5
action 0, numVisits=5, meanQ=-1.802000, numObservations: 5
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.448519 0.416571 0.466111 0.162067 0.813976 0.279756 0.963419 0.73029 0.189876 0.457346 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 5
Initial state: 0 0.567809 0.480701 0.0964635 0.318188 0.975408 0.140628 0.670045 0.432177 0.90194 0.947836 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 142556 episodes
GETTING ACTION FROM:
action 3, numVisits=142548, meanQ=11.736613, numObservations: 9
action 2, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.567809 0.480701 0.0964635 0.318188 0.975408 0.140628 0.670045 0.432177 0.90194 0.947836 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 6
Initial state: 0 0.48887 0.400484 0.731803 0.331189 0.945088 0.16605 0.62844 0.0323682 0.966952 0.356673 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 142180 episodes
GETTING ACTION FROM:
action 4, numVisits=142170, meanQ=11.496483, numObservations: 9
action 5, numVisits=5, meanQ=5.800000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.48887 0.400484 0.731803 0.331189 0.945088 0.16605 0.62844 0.0323682 0.966952 0.356673 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 7
Initial state: 0 0.647086 0.284773 0.873003 0.993399 0.450122 0.444102 0.3547 0.0565178 0.619956 0.920751 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 143689 episodes
GETTING ACTION FROM:
action 1, numVisits=143639, meanQ=11.562514, numObservations: 9
action 4, numVisits=37, meanQ=7.351908, numObservations: 8
action 5, numVisits=9, meanQ=5.678889, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.647086 0.284773 0.873003 0.993399 0.450122 0.444102 0.3547 0.0565178 0.619956 0.920751 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 8
Initial state: 0 0.231896 0.0338356 0.662358 0.608562 0.355096 0.253023 0.568564 0.491143 0.0311898 0.962014 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 144579 episodes
GETTING ACTION FROM:
action 5, numVisits=144573, meanQ=11.687679, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.231896 0.0338356 0.662358 0.608562 0.355096 0.253023 0.568564 0.491143 0.0311898 0.962014 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=18364, meanQ=12.647627, numObservations: 9
action 1, numVisits=26, meanQ=9.182327, numObservations: 8
action 3, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 60370 episodes
GETTING ACTION FROM:
action 4, numVisits=78725, meanQ=13.683245, numObservations: 9
action 1, numVisits=26, meanQ=9.182327, numObservations: 8
action 3, numVisits=8, meanQ=7.967500, numObservations: 4
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action -1, numVisits=3, meanQ=-1.340000, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 1 0.231896 0.0338356 0.662358 0.608562 0.355096 0.253023 0.568564 0.491143 0.0311898 0.962014 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 9
Initial state: 0 0.95073 0.932603 0.0005551 0.0466687 0.239328 0.127424 0.529737 0.464936 0.708157 0.76144 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 143188 episodes
GETTING ACTION FROM:
action 3, numVisits=143143, meanQ=11.590113, numObservations: 9
action 2, numVisits=34, meanQ=9.495003, numObservations: 8
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action 4, numVisits=6, meanQ=6.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 2 0.95073 0.932603 0.0005551 0.0466687 0.239328 0.127424 0.529737 0.464936 0.708157 0.76144 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 10
Initial state: 0 0.432008 0.102025 0.195111 0.917968 0.865579 0.550414 0.268717 0.247513 0.456461 0.449496 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 142788 episodes
GETTING ACTION FROM:
action 4, numVisits=142773, meanQ=11.689504, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 3, numVisits=5, meanQ=-2.600000, numObservations: 5
action 2, numVisits=2, meanQ=-4.000000, numObservations: 2
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.432008 0.102025 0.195111 0.917968 0.865579 0.550414 0.268717 0.247513 0.456461 0.449496 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 11
Initial state: 0 0.821437 0.965481 0.238978 0.549888 0.523628 0.448102 0.0644523 0.0981739 0.963856 0.699033 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 143222 episodes
GETTING ACTION FROM:
action 2, numVisits=143207, meanQ=11.483211, numObservations: 9
action 1, numVisits=6, meanQ=7.666667, numObservations: 5
action 5, numVisits=5, meanQ=5.998000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.821437 0.965481 0.238978 0.549888 0.523628 0.448102 0.0644523 0.0981739 0.963856 0.699033 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=4137, meanQ=12.290720, numObservations: 9
action 4, numVisits=12, meanQ=8.331675, numObservations: 5
action 2, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 42625 episodes
GETTING ACTION FROM:
action 1, numVisits=46163, meanQ=12.429046, numObservations: 9
action 4, numVisits=279, meanQ=8.807214, numObservations: 9
action 2, numVisits=4, meanQ=3.495000, numObservations: 3
action -1, numVisits=278, meanQ=-1.257578, numObservations: 117
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action 5, numVisits=2, meanQ=-7.005000, numObservations: 2
action 0, numVisits=53, meanQ=-20.675549, numObservations: 41
action: 1
Next state: 1 0.821437 0.965481 0.238978 0.549888 0.523628 0.448102 0.0644523 0.0981739 0.963856 0.699033 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 12
Initial state: 0 0.769556 0.480099 0.839001 0.167521 0.494015 0.563227 0.0836685 0.562361 0.470312 0.487532 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 143923 episodes
GETTING ACTION FROM:
action 2, numVisits=143910, meanQ=11.686170, numObservations: 9
action 3, numVisits=6, meanQ=4.661667, numObservations: 4
action 1, numVisits=3, meanQ=4.340033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 2 0.769556 0.480099 0.839001 0.167521 0.494015 0.563227 0.0836685 0.562361 0.470312 0.487532 w: 1
Observation: 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 13
Initial state: 0 0.53763 0.402277 0.0257855 0.0272555 0.00472305 0.995907 0.82879 0.567117 0.719589 0.127747 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 143671 episodes
GETTING ACTION FROM:
action 3, numVisits=143663, meanQ=11.702513, numObservations: 9
action 2, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.53763 0.402277 0.0257855 0.0272555 0.00472305 0.995907 0.82879 0.567117 0.719589 0.127747 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=18788, meanQ=12.996676, numObservations: 9
action 4, numVisits=2, meanQ=6.500000, numObservations: 2
action 1, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 46977 episodes
GETTING ACTION FROM:
action 5, numVisits=65717, meanQ=14.216119, numObservations: 9
action 1, numVisits=47, meanQ=9.213066, numObservations: 8
action 4, numVisits=3, meanQ=3.000000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 2 0.53763 0.402277 0.0257855 0.0272555 0.00472305 0.995907 0.82879 0.567117 0.719589 0.127747 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 14
Initial state: 0 0.350008 0.0478221 0.826744 0.964394 0.870903 0.638571 0.454889 0.395793 0.730855 0.577475 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 136175 episodes
GETTING ACTION FROM:
action 3, numVisits=136169, meanQ=10.888206, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.350008 0.0478221 0.826744 0.964394 0.870903 0.638571 0.454889 0.395793 0.730855 0.577475 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 15
Initial state: 0 0.991199 0.858697 0.676538 0.705542 0.612114 0.416973 0.819482 0.496282 0.841937 0.380199 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 136457 episodes
GETTING ACTION FROM:
action 3, numVisits=136443, meanQ=10.962850, numObservations: 9
action 1, numVisits=9, meanQ=5.788889, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.991199 0.858697 0.676538 0.705542 0.612114 0.416973 0.819482 0.496282 0.841937 0.380199 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 16
Initial state: 0 0.666704 0.18345 0.477224 0.925599 0.593802 0.658952 0.200506 0.488752 0.508704 0.376749 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 144237 episodes
GETTING ACTION FROM:
action 5, numVisits=144223, meanQ=11.673026, numObservations: 9
action 2, numVisits=8, meanQ=8.373750, numObservations: 4
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.666704 0.18345 0.477224 0.925599 0.593802 0.658952 0.200506 0.488752 0.508704 0.376749 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=2400, meanQ=20.219887, numObservations: 9
action 1, numVisits=3, meanQ=14.996667, numObservations: 3
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action 4, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 142335 episodes
GETTING ACTION FROM:
action 5, numVisits=2418, meanQ=20.242339, numObservations: 9
action 1, numVisits=142302, meanQ=14.060427, numObservations: 9
action 4, numVisits=9, meanQ=8.843346, numObservations: 6
action 2, numVisits=11, meanQ=8.801593, numObservations: 7
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.666704 0.18345 0.477224 0.925599 0.593802 0.658952 0.200506 0.488752 0.508704 0.376749 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 17
Initial state: 0 0.584933 0.748375 0.744108 0.314668 0.481142 0.516961 0.739038 0.4482 0.556414 0.372707 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 143926 episodes
GETTING ACTION FROM:
action 2, numVisits=143914, meanQ=11.684012, numObservations: 9
action 1, numVisits=5, meanQ=5.800000, numObservations: 5
action 5, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.584933 0.748375 0.744108 0.314668 0.481142 0.516961 0.739038 0.4482 0.556414 0.372707 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 18
Initial state: 0 0.147656 0.748635 0.589596 0.472296 0.630129 0.325644 0.871101 0.788455 0.282095 0.834725 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 142385 episodes
GETTING ACTION FROM:
action 1, numVisits=142344, meanQ=11.598379, numObservations: 9
action 3, numVisits=30, meanQ=8.598680, numObservations: 8
action 2, numVisits=7, meanQ=6.141429, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.147656 0.748635 0.589596 0.472296 0.630129 0.325644 0.871101 0.788455 0.282095 0.834725 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=18499, meanQ=12.764118, numObservations: 9
action 4, numVisits=9, meanQ=6.331111, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 56380 episodes
GETTING ACTION FROM:
action 2, numVisits=74876, meanQ=14.790978, numObservations: 9
action 4, numVisits=9, meanQ=6.331111, numObservations: 6
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.147656 0.748635 0.589596 0.472296 0.630129 0.325644 0.871101 0.788455 0.282095 0.834725 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 19
Initial state: 0 0.948579 0.126144 0.537151 0.415168 0.0499806 0.342908 0.30112 0.0506347 0.341945 0.538692 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 143177 episodes
GETTING ACTION FROM:
action 4, numVisits=143167, meanQ=11.642661, numObservations: 9
action 5, numVisits=5, meanQ=5.998000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.948579 0.126144 0.537151 0.415168 0.0499806 0.342908 0.30112 0.0506347 0.341945 0.538692 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=16808, meanQ=12.642083, numObservations: 9
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 44361 episodes
GETTING ACTION FROM:
action 1, numVisits=61150, meanQ=10.544613, numObservations: 9
action 5, numVisits=10, meanQ=4.743104, numObservations: 7
action 2, numVisits=4, meanQ=0.403546, numObservations: 4
action -1, numVisits=5, meanQ=-1.010000, numObservations: 5
action 0, numVisits=5, meanQ=-1.010000, numObservations: 5
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=2, meanQ=-5.397728, numObservations: 2
action: 1
Next state: 2 0.948579 0.126144 0.537151 0.415168 0.0499806 0.342908 0.30112 0.0506347 0.341945 0.538692 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 20
Initial state: 0 0.790204 0.922605 0.511054 0.075775 0.613556 0.151637 0.136786 0.260241 0.542748 0.414197 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 144161 episodes
GETTING ACTION FROM:
action 1, numVisits=144129, meanQ=11.645060, numObservations: 9
action 2, numVisits=7, meanQ=6.715729, numObservations: 4
action 4, numVisits=19, meanQ=6.605795, numObservations: 7
action 5, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.790204 0.922605 0.511054 0.075775 0.613556 0.151637 0.136786 0.260241 0.542748 0.414197 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 21
Initial state: 0 0.019246 0.810569 0.609524 0.38585 0.181242 0.993679 0.0734312 0.208524 0.623681 0.503018 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 142357 episodes
GETTING ACTION FROM:
action 1, numVisits=142349, meanQ=11.450261, numObservations: 9
action 5, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.019246 0.810569 0.609524 0.38585 0.181242 0.993679 0.0734312 0.208524 0.623681 0.503018 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=16707, meanQ=12.727039, numObservations: 9
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action -1, numVisits=7, meanQ=-1.577129, numObservations: 6
action 2, numVisits=5, meanQ=-1.597980, numObservations: 3
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=2, meanQ=-8.950000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 48083 episodes
GETTING ACTION FROM:
action 3, numVisits=64790, meanQ=11.826546, numObservations: 9
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action -1, numVisits=7, meanQ=-1.577129, numObservations: 6
action 2, numVisits=5, meanQ=-1.597980, numObservations: 3
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=2, meanQ=-8.950000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.019246 0.810569 0.609524 0.38585 0.181242 0.993679 0.0734312 0.208524 0.623681 0.503018 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=644, meanQ=13.821184, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=5, meanQ=-1.803980, numObservations: 4
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=2, meanQ=-4.994950, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 75614 episodes
GETTING ACTION FROM:
action 2, numVisits=76258, meanQ=14.101804, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=5, meanQ=-1.803980, numObservations: 4
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=2, meanQ=-4.994950, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.019246 0.810569 0.609524 0.38585 0.181242 0.993679 0.0734312 0.208524 0.623681 0.503018 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 22
Initial state: 0 0.887458 0.544257 0.62352 0.958923 0.0848852 0.428808 0.452496 0.382222 0.47095 0.794306 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 144135 episodes
GETTING ACTION FROM:
action 3, numVisits=144129, meanQ=11.492922, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.887458 0.544257 0.62352 0.958923 0.0848852 0.428808 0.452496 0.382222 0.47095 0.794306 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=16726, meanQ=12.517718, numObservations: 9
action 2, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 41772 episodes
GETTING ACTION FROM:
action 5, numVisits=58489, meanQ=11.707475, numObservations: 9
action 2, numVisits=8, meanQ=6.497525, numObservations: 3
action -1, numVisits=3, meanQ=-1.340000, numObservations: 3
action 0, numVisits=3, meanQ=-1.340000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.887458 0.544257 0.62352 0.958923 0.0848852 0.428808 0.452496 0.382222 0.47095 0.794306 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 23
Initial state: 0 0.324707 0.646585 0.996687 0.0791401 0.417034 0.400072 0.915427 0.92874 0.599947 0.392916 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 144117 episodes
GETTING ACTION FROM:
action 1, numVisits=144099, meanQ=11.652820, numObservations: 9
action 3, numVisits=13, meanQ=7.692323, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.324707 0.646585 0.996687 0.0791401 0.417034 0.400072 0.915427 0.92874 0.599947 0.392916 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=18641, meanQ=12.659956, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 50980 episodes
GETTING ACTION FROM:
action 4, numVisits=48894, meanQ=13.798105, numObservations: 9
action 2, numVisits=20723, meanQ=12.837924, numObservations: 9
action -1, numVisits=4, meanQ=-1.257500, numObservations: 4
action 0, numVisits=3, meanQ=-1.670000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.324707 0.646585 0.996687 0.0791401 0.417034 0.400072 0.915427 0.92874 0.599947 0.392916 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 24
Initial state: 0 0.49315 0.440568 0.311972 0.228008 0.0286903 0.482741 0.573256 0.816048 0.174743 0.965114 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 143544 episodes
GETTING ACTION FROM:
action 3, numVisits=143536, meanQ=11.581353, numObservations: 9
action 4, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.49315 0.440568 0.311972 0.228008 0.0286903 0.482741 0.573256 0.816048 0.174743 0.965114 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 25
Initial state: 0 0.111349 0.0160877 0.763692 0.695721 0.548357 0.431793 0.70848 0.422208 0.637356 0.941581 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 141687 episodes
GETTING ACTION FROM:
action 1, numVisits=141674, meanQ=11.495567, numObservations: 9
action 5, numVisits=6, meanQ=8.185000, numObservations: 3
action 3, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.111349 0.0160877 0.763692 0.695721 0.548357 0.431793 0.70848 0.422208 0.637356 0.941581 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=16773, meanQ=12.187845, numObservations: 9
action 4, numVisits=3, meanQ=3.330000, numObservations: 3
action 3, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 39109 episodes
GETTING ACTION FROM:
action 2, numVisits=55874, meanQ=10.822932, numObservations: 9
action 3, numVisits=3, meanQ=0.666667, numObservations: 3
action 4, numVisits=4, meanQ=-0.252500, numObservations: 4
action -1, numVisits=5, meanQ=-1.010000, numObservations: 5
action 0, numVisits=4, meanQ=-1.257500, numObservations: 4
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.111349 0.0160877 0.763692 0.695721 0.548357 0.431793 0.70848 0.422208 0.637356 0.941581 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 26
Initial state: 0 0.0232724 0.39323 0.246506 0.0773164 0.857351 0.778488 0.415735 0.341138 0.55268 0.475657 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 137498 episodes
GETTING ACTION FROM:
action 2, numVisits=137478, meanQ=11.764017, numObservations: 9
action 3, numVisits=15, meanQ=8.466020, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.0232724 0.39323 0.246506 0.0773164 0.857351 0.778488 0.415735 0.341138 0.55268 0.475657 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=16149, meanQ=12.748491, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.671650, numObservations: 5
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 48588 episodes
GETTING ACTION FROM:
action 1, numVisits=64737, meanQ=12.756142, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.671650, numObservations: 5
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.0232724 0.39323 0.246506 0.0773164 0.857351 0.778488 0.415735 0.341138 0.55268 0.475657 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=1035, meanQ=13.570997, numObservations: 9
action 4, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 35537 episodes
GETTING ACTION FROM:
action 5, numVisits=36566, meanQ=12.972526, numObservations: 9
action 4, numVisits=3, meanQ=3.330000, numObservations: 3
action 0, numVisits=5, meanQ=-1.406000, numObservations: 5
action -1, numVisits=5, meanQ=-1.604000, numObservations: 5
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.0232724 0.39323 0.246506 0.0773164 0.857351 0.778488 0.415735 0.341138 0.55268 0.475657 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 27
Initial state: 0 0.180933 0.428548 0.277431 0.505965 0.471832 0.556651 0.29038 0.898696 0.525708 0.380391 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 144004 episodes
GETTING ACTION FROM:
action 5, numVisits=143980, meanQ=11.729346, numObservations: 9
action 3, numVisits=15, meanQ=9.475347, numObservations: 6
action 1, numVisits=4, meanQ=6.500000, numObservations: 4
action 4, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 1 0.180933 0.428548 0.277431 0.505965 0.471832 0.556651 0.29038 0.898696 0.525708 0.380391 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 28
Initial state: 0 0.847544 0.236837 0.116148 0.126642 0.976031 0.956258 0.955665 0.822218 0.498694 0.376732 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 143041 episodes
GETTING ACTION FROM:
action 3, numVisits=143027, meanQ=11.645167, numObservations: 9
action 2, numVisits=7, meanQ=7.000000, numObservations: 6
action 1, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.847544 0.236837 0.116148 0.126642 0.976031 0.956258 0.955665 0.822218 0.498694 0.376732 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 29
Initial state: 0 0.575605 0.43557 0.515614 0.354865 0.841698 0.297316 0.640374 0.981382 0.338455 0.336393 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 143000 episodes
GETTING ACTION FROM:
action 3, numVisits=142992, meanQ=11.464692, numObservations: 9
action 4, numVisits=3, meanQ=5.663333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.575605 0.43557 0.515614 0.354865 0.841698 0.297316 0.640374 0.981382 0.338455 0.336393 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 30
Initial state: 0 0.956073 0.545233 0.00501066 0.382588 0.489011 0.373672 0.0350881 0.167775 0.332601 0.0242608 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 144014 episodes
GETTING ACTION FROM:
action 4, numVisits=144000, meanQ=11.431806, numObservations: 9
action 2, numVisits=9, meanQ=6.456667, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.956073 0.545233 0.00501066 0.382588 0.489011 0.373672 0.0350881 0.167775 0.332601 0.0242608 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=17012, meanQ=12.347911, numObservations: 9
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action 1, numVisits=3, meanQ=5.330033, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 43782 episodes
GETTING ACTION FROM:
action 3, numVisits=60787, meanQ=11.898796, numObservations: 9
action 2, numVisits=3, meanQ=3.000000, numObservations: 2
action 1, numVisits=4, meanQ=1.247525, numObservations: 2
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=3, meanQ=-1.340000, numObservations: 3
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.956073 0.545233 0.00501066 0.382588 0.489011 0.373672 0.0350881 0.167775 0.332601 0.0242608 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 31
Initial state: 0 0.84927 0.449878 0.739486 0.440602 0.996634 0.36948 0.5377 0.446633 0.992901 0.574179 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 137173 episodes
GETTING ACTION FROM:
action 3, numVisits=137161, meanQ=11.654730, numObservations: 9
action 1, numVisits=7, meanQ=5.444286, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 2 0.84927 0.449878 0.739486 0.440602 0.996634 0.36948 0.5377 0.446633 0.992901 0.574179 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 32
Initial state: 0 0.739479 0.574136 0.772626 0.0157854 0.581876 0.469986 0.247237 0.697803 0.266267 0.675804 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 142653 episodes
GETTING ACTION FROM:
action 1, numVisits=142647, meanQ=11.617793, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.739479 0.574136 0.772626 0.0157854 0.581876 0.469986 0.247237 0.697803 0.266267 0.675804 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 33
Initial state: 0 0.183705 0.841277 0.596931 0.472246 0.860063 0.237282 0.312442 0.274051 0.833358 0.936381 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 138265 episodes
GETTING ACTION FROM:
action 1, numVisits=138250, meanQ=11.667008, numObservations: 9
action 2, numVisits=5, meanQ=4.952000, numObservations: 4
action 3, numVisits=4, meanQ=3.247500, numObservations: 3
action 4, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.183705 0.841277 0.596931 0.472246 0.860063 0.237282 0.312442 0.274051 0.833358 0.936381 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=17654, meanQ=12.594942, numObservations: 9
action 4, numVisits=8, meanQ=9.247513, numObservations: 5
action 5, numVisits=7, meanQ=8.281443, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 45997 episodes
GETTING ACTION FROM:
action 5, numVisits=45986, meanQ=13.851027, numObservations: 9
action 1, numVisits=17654, meanQ=12.594942, numObservations: 9
action 4, numVisits=20, meanQ=6.294971, numObservations: 8
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action -1, numVisits=4, meanQ=-1.257500, numObservations: 4
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.183705 0.841277 0.596931 0.472246 0.860063 0.237282 0.312442 0.274051 0.833358 0.936381 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 34
Initial state: 0 0.519634 0.457982 0.383051 0.476051 0.242283 0.914993 0.763833 0.520908 0.0949372 0.00843625 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 144499 episodes
GETTING ACTION FROM:
action 3, numVisits=144480, meanQ=11.561404, numObservations: 9
action 1, numVisits=12, meanQ=5.333333, numObservations: 7
action 4, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.519634 0.457982 0.383051 0.476051 0.242283 0.914993 0.763833 0.520908 0.0949372 0.00843625 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=18606, meanQ=12.406031, numObservations: 9
action 3, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 43074 episodes
GETTING ACTION FROM:
action 5, numVisits=61668, meanQ=13.915965, numObservations: 9
action 3, numVisits=8, meanQ=12.386250, numObservations: 3
action -1, numVisits=5, meanQ=-1.010000, numObservations: 5
action 0, numVisits=4, meanQ=-1.505000, numObservations: 4
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.519634 0.457982 0.383051 0.476051 0.242283 0.914993 0.763833 0.520908 0.0949372 0.00843625 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action -1, numVisits=625, meanQ=4.029636, numObservations: 122
action 0, numVisits=8, meanQ=-1.754975, numObservations: 6
action 5, numVisits=4, meanQ=-2.250000, numObservations: 2
action 3, numVisits=2, meanQ=-4.004950, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action 2, numVisits=2, meanQ=-8.950000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 58847 episodes
GETTING ACTION FROM:
action -1, numVisits=59451, meanQ=-0.485703, numObservations: 242
action 0, numVisits=29, meanQ=-1.898610, numObservations: 20
action 5, numVisits=4, meanQ=-2.250000, numObservations: 2
action 3, numVisits=2, meanQ=-4.004950, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action 2, numVisits=2, meanQ=-8.950000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.519634 0.457982 0.383051 0.476051 0.242283 0.914993 0.763833 0.520908 0.0949372 0.00843625 w: 1
Observation: 0 2 0 1 0 1 0 3 0 1 0 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=143, meanQ=16.727166, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.017004, numObservations: 1
action 5, numVisits=1, meanQ=-12.425856, numObservations: 1
action 3, numVisits=1, meanQ=-1065.979538, numObservations: 1
Sampled 85768 episodes
GETTING ACTION FROM:
action 1, numVisits=85911, meanQ=21.135289, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.017004, numObservations: 1
action 5, numVisits=1, meanQ=-12.425856, numObservations: 1
action 3, numVisits=1, meanQ=-1065.979538, numObservations: 1
action: 1
Next state: 0 0.519634 0.457982 0.383051 0.476051 0.242283 0.914993 0.763833 0.520908 0.0949372 0.00843625 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 0, numVisits=3027, meanQ=13.627412, numObservations: 112
action 1, numVisits=19, meanQ=-7.322555, numObservations: 6
action 2, numVisits=1, meanQ=-9.876475, numObservations: 1
action 4, numVisits=1, meanQ=-10.006460, numObservations: 1
action -1, numVisits=3, meanQ=-179.200215, numObservations: 2
action 5, numVisits=1, meanQ=-539.569828, numObservations: 1
action 3, numVisits=1, meanQ=-539.596075, numObservations: 1
Sampled 97177 episodes
GETTING ACTION FROM:
action 4, numVisits=18165, meanQ=5.043042, numObservations: 9
action 0, numVisits=82040, meanQ=-0.573092, numObservations: 219
action 1, numVisits=19, meanQ=-7.322555, numObservations: 6
action 2, numVisits=1, meanQ=-9.876475, numObservations: 1
action -1, numVisits=3, meanQ=-179.200215, numObservations: 2
action 5, numVisits=1, meanQ=-539.569828, numObservations: 1
action 3, numVisits=1, meanQ=-539.596075, numObservations: 1
action: 4
Next state: 1 0.519634 0.457982 0.383051 0.476051 0.242283 0.914993 0.763833 0.520908 0.0949372 0.00843625 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9.25291
Run # 35
Initial state: 0 0.286958 0.2253 0.0183964 0.312442 0.481242 0.481932 0.8153 0.924987 0.346711 0.284858 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 133795 episodes
GETTING ACTION FROM:
action 1, numVisits=133789, meanQ=11.894631, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.286958 0.2253 0.0183964 0.312442 0.481242 0.481932 0.8153 0.924987 0.346711 0.284858 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=15682, meanQ=15.019914, numObservations: 241
action 0, numVisits=9, meanQ=-1.451100, numObservations: 8
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 5, numVisits=2, meanQ=-3.010000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 21147 episodes
GETTING ACTION FROM:
action -1, numVisits=36829, meanQ=13.430870, numObservations: 243
action 0, numVisits=9, meanQ=-1.451100, numObservations: 8
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 5, numVisits=2, meanQ=-3.010000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.286958 0.2253 0.0183964 0.312442 0.481242 0.481932 0.8153 0.924987 0.346711 0.284858 w: 1
Observation: 0 1 0 3 0 2 0 3 0 1 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=486, meanQ=18.828121, numObservations: 9
action 4, numVisits=2, meanQ=10.495000, numObservations: 1
action 2, numVisits=4, meanQ=6.500000, numObservations: 3
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 106108 episodes
GETTING ACTION FROM:
action 3, numVisits=106594, meanQ=21.481566, numObservations: 9
action 4, numVisits=2, meanQ=10.495000, numObservations: 1
action 2, numVisits=4, meanQ=6.500000, numObservations: 3
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.286958 0.2253 0.0183964 0.312442 0.481242 0.481932 0.8153 0.924987 0.346711 0.284858 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 17.5424
Run # 36
Initial state: 0 0.823746 0.210033 0.968343 0.131631 0.780919 0.363777 0.456824 0.441884 0.307738 0.994315 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 137788 episodes
GETTING ACTION FROM:
action 5, numVisits=137775, meanQ=11.559138, numObservations: 9
action 2, numVisits=8, meanQ=8.125013, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 1 0.823746 0.210033 0.968343 0.131631 0.780919 0.363777 0.456824 0.441884 0.307738 0.994315 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 37
Initial state: 0 0.0582421 0.952476 0.776323 0.235705 0.809679 0.378708 0.543309 0.385817 0.738301 0.310139 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 144124 episodes
GETTING ACTION FROM:
action 3, numVisits=144110, meanQ=11.580035, numObservations: 9
action 5, numVisits=7, meanQ=7.141429, numObservations: 6
action 2, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.0582421 0.952476 0.776323 0.235705 0.809679 0.378708 0.543309 0.385817 0.738301 0.310139 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 38
Initial state: 0 0.506282 0.480109 0.064852 0.975135 0.578557 0.351639 0.920751 0.665313 0.974942 0.834646 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 142859 episodes
GETTING ACTION FROM:
action 5, numVisits=142847, meanQ=11.597864, numObservations: 9
action 3, numVisits=5, meanQ=0.200000, numObservations: 5
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.506282 0.480109 0.064852 0.975135 0.578557 0.351639 0.920751 0.665313 0.974942 0.834646 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 39
Initial state: 0 0.430921 0.763161 0.0679159 0.546351 0.507661 0.395312 0.0737679 0.313647 0.569104 0.365025 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 144079 episodes
GETTING ACTION FROM:
action 5, numVisits=144058, meanQ=11.627035, numObservations: 9
action 1, numVisits=11, meanQ=9.010000, numObservations: 6
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action 2, numVisits=5, meanQ=4.400000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 0 0.430921 0.763161 0.0679159 0.546351 0.507661 0.395312 0.0737679 0.313647 0.569104 0.365025 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=2508, meanQ=11.281738, numObservations: 9
action 1, numVisits=12, meanQ=5.915842, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 61923 episodes
GETTING ACTION FROM:
action 3, numVisits=64407, meanQ=9.986748, numObservations: 9
action 1, numVisits=12, meanQ=5.915842, numObservations: 6
action 0, numVisits=14, meanQ=-1.505000, numObservations: 14
action -1, numVisits=12, meanQ=-1.670000, numObservations: 12
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.430921 0.763161 0.0679159 0.546351 0.507661 0.395312 0.0737679 0.313647 0.569104 0.365025 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 40
Initial state: 0 0.491085 0.635625 0.0370025 0.000642529 0.466232 0.486676 0.955006 0.81046 0.748077 0.681478 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 144486 episodes
GETTING ACTION FROM:
action 1, numVisits=144480, meanQ=11.689088, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.491085 0.635625 0.0370025 0.000642529 0.466232 0.486676 0.955006 0.81046 0.748077 0.681478 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 41
Initial state: 0 0.396019 0.15504 0.511945 0.3832 0.00957371 0.519772 0.220424 0.00700917 0.627264 0.34604 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 133912 episodes
GETTING ACTION FROM:
action 5, numVisits=133904, meanQ=11.783788, numObservations: 9
action 4, numVisits=3, meanQ=5.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.396019 0.15504 0.511945 0.3832 0.00957371 0.519772 0.220424 0.00700917 0.627264 0.34604 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 42
Initial state: 0 0.607002 0.452875 0.319054 0.999727 0.890466 0.863716 0.563535 0.356766 0.691858 0.643454 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 143643 episodes
GETTING ACTION FROM:
action 4, numVisits=143637, meanQ=11.619275, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.607002 0.452875 0.319054 0.999727 0.890466 0.863716 0.563535 0.356766 0.691858 0.643454 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=2568, meanQ=11.518468, numObservations: 9
action 5, numVisits=26, meanQ=8.917312, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 69677 episodes
GETTING ACTION FROM:
action 2, numVisits=72227, meanQ=11.503814, numObservations: 9
action 5, numVisits=31, meanQ=6.868484, numObservations: 8
action -1, numVisits=8, meanQ=-1.381250, numObservations: 8
action 0, numVisits=7, meanQ=-1.575714, numObservations: 7
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.607002 0.452875 0.319054 0.999727 0.890466 0.863716 0.563535 0.356766 0.691858 0.643454 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=3070, meanQ=14.557186, numObservations: 9
action 5, numVisits=282, meanQ=6.847173, numObservations: 9
action 2, numVisits=10, meanQ=3.305060, numObservations: 1
action -1, numVisits=54, meanQ=-1.535120, numObservations: 35
action 0, numVisits=7, meanQ=-2.707143, numObservations: 6
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 61302 episodes
GETTING ACTION FROM:
action 1, numVisits=64372, meanQ=13.770211, numObservations: 9
action 5, numVisits=282, meanQ=6.847173, numObservations: 9
action 2, numVisits=10, meanQ=3.305060, numObservations: 1
action -1, numVisits=54, meanQ=-1.535120, numObservations: 35
action 0, numVisits=7, meanQ=-2.707143, numObservations: 6
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.607002 0.452875 0.319054 0.999727 0.890466 0.863716 0.563535 0.356766 0.691858 0.643454 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 43
Initial state: 0 0.808376 0.0901036 0.674985 0.737991 0.76176 0.161935 0.575277 0.438866 0.809847 0.981085 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 143575 episodes
GETTING ACTION FROM:
action 1, numVisits=143560, meanQ=11.684461, numObservations: 9
action -1, numVisits=5, meanQ=-1.010000, numObservations: 5
action 0, numVisits=5, meanQ=-1.010000, numObservations: 5
action 3, numVisits=2, meanQ=-4.000000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.808376 0.0901036 0.674985 0.737991 0.76176 0.161935 0.575277 0.438866 0.809847 0.981085 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=2202, meanQ=12.591248, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 138078 episodes
GETTING ACTION FROM:
action 5, numVisits=140262, meanQ=7.373654, numObservations: 9
action -1, numVisits=9, meanQ=-1.670000, numObservations: 9
action 0, numVisits=9, meanQ=-1.670000, numObservations: 9
action 2, numVisits=2, meanQ=-7.005000, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.808376 0.0901036 0.674985 0.737991 0.76176 0.161935 0.575277 0.438866 0.809847 0.981085 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 44
Initial state: 0 0.297305 0.576497 0.901353 0.882459 0.88928 0.185064 0.472357 0.410728 0.411021 0.865407 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 138830 episodes
GETTING ACTION FROM:
action 1, numVisits=138822, meanQ=11.668539, numObservations: 9
action 5, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.297305 0.576497 0.901353 0.882459 0.88928 0.185064 0.472357 0.410728 0.411021 0.865407 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=17895, meanQ=12.840097, numObservations: 9
action 5, numVisits=4, meanQ=1.745000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 55055 episodes
GETTING ACTION FROM:
action 2, numVisits=55035, meanQ=14.043679, numObservations: 9
action 1, numVisits=17901, meanQ=12.842978, numObservations: 9
action 5, numVisits=4, meanQ=1.745000, numObservations: 4
action 0, numVisits=9, meanQ=-1.450000, numObservations: 9
action -1, numVisits=8, meanQ=-1.505000, numObservations: 8
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.297305 0.576497 0.901353 0.882459 0.88928 0.185064 0.472357 0.410728 0.411021 0.865407 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 45
Initial state: 0 0.999487 0.940159 0.815536 0.709737 0.599868 0.457985 0.657867 0.847428 0.23172 0.709288 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 143844 episodes
GETTING ACTION FROM:
action 4, numVisits=143810, meanQ=11.487980, numObservations: 9
action 2, numVisits=27, meanQ=7.510389, numObservations: 8
action 1, numVisits=3, meanQ=5.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 1 0.999487 0.940159 0.815536 0.709737 0.599868 0.457985 0.657867 0.847428 0.23172 0.709288 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 46
Initial state: 0 0.928863 0.889333 0.51797 0.484042 0.878677 0.849222 0.655123 0.616596 0.0558314 0.837877 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 143416 episodes
GETTING ACTION FROM:
action 1, numVisits=143399, meanQ=11.416488, numObservations: 9
action 5, numVisits=12, meanQ=4.750000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.928863 0.889333 0.51797 0.484042 0.878677 0.849222 0.655123 0.616596 0.0558314 0.837877 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 47
Initial state: 0 0.60225 0.465507 0.465324 0.937326 0.462374 0.0305985 0.147911 0.322536 0.15925 0.318447 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 144333 episodes
GETTING ACTION FROM:
action 4, numVisits=144324, meanQ=11.589643, numObservations: 9
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action 5, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.60225 0.465507 0.465324 0.937326 0.462374 0.0305985 0.147911 0.322536 0.15925 0.318447 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=4183, meanQ=12.260767, numObservations: 9
action 3, numVisits=30, meanQ=6.782670, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 39563 episodes
GETTING ACTION FROM:
action 2, numVisits=43729, meanQ=12.129142, numObservations: 9
action 3, numVisits=30, meanQ=6.782670, numObservations: 9
action -1, numVisits=13, meanQ=-1.086154, numObservations: 13
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=6, meanQ=-3.485000, numObservations: 5
action: 2
Next state: 1 0.60225 0.465507 0.465324 0.937326 0.462374 0.0305985 0.147911 0.322536 0.15925 0.318447 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 48
Initial state: 0 0.57926 0.0542108 0.827426 0.576206 0.208798 0.541196 0.82086 0.788839 0.452243 0.441188 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 138412 episodes
GETTING ACTION FROM:
action 2, numVisits=138406, meanQ=11.666123, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.57926 0.0542108 0.827426 0.576206 0.208798 0.541196 0.82086 0.788839 0.452243 0.441188 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 49
Initial state: 0 0.675377 0.887538 0.564843 0.412457 0.231181 0.472558 0.0716031 0.269101 0.260931 0.270709 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 142951 episodes
GETTING ACTION FROM:
action 4, numVisits=142943, meanQ=11.665343, numObservations: 9
action 2, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 0 0.675377 0.887538 0.564843 0.412457 0.231181 0.472558 0.0716031 0.269101 0.260931 0.270709 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=16839, meanQ=12.816175, numObservations: 9
action 0, numVisits=7, meanQ=-1.010000, numObservations: 7
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=3, meanQ=-4.970000, numObservations: 2
Sampled 45129 episodes
GETTING ACTION FROM:
action 1, numVisits=61853, meanQ=12.035268, numObservations: 9
action 3, numVisits=109, meanQ=10.508468, numObservations: 9
action 0, numVisits=13, meanQ=-1.238462, numObservations: 13
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=3, meanQ=-4.970000, numObservations: 2
action 5, numVisits=2, meanQ=-5.165844, numObservations: 2
action: 1
Next state: 1 0.675377 0.887538 0.564843 0.412457 0.231181 0.472558 0.0716031 0.269101 0.260931 0.270709 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 50
Initial state: 0 0.517162 0.403036 0.962949 0.14687 0.320372 0.633818 0.545281 0.142315 0.7729 0.38284 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 143285 episodes
GETTING ACTION FROM:
action 1, numVisits=143258, meanQ=11.657259, numObservations: 9
action 5, numVisits=18, meanQ=9.061111, numObservations: 7
action 4, numVisits=5, meanQ=5.998000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.517162 0.403036 0.962949 0.14687 0.320372 0.633818 0.545281 0.142315 0.7729 0.38284 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
[32m ProblemEnvironment.hpp 351: Done.[39m
