Run # 1
Initial state: 0 0.771161 0.86042 0.890896 0.762873 0.334537 0.923168 0.0052545 0.775072 0.427149 0.356416 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31670 episodes
GETTING ACTION FROM:
action 1, numVisits=31653, meanQ=12.256348, numObservations: 9
action 5, numVisits=12, meanQ=8.919192, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.771161 0.86042 0.890896 0.762873 0.334537 0.923168 0.0052545 0.775072 0.427149 0.356416 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 2
Initial state: 0 0.949528 0.0792137 0.497435 0.605327 0.167019 0.329021 0.419014 0.350492 0.170569 0.257915 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32333 episodes
GETTING ACTION FROM:
action 2, numVisits=32318, meanQ=12.210325, numObservations: 9
action 5, numVisits=10, meanQ=10.000000, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.949528 0.0792137 0.497435 0.605327 0.167019 0.329021 0.419014 0.350492 0.170569 0.257915 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 3
Initial state: 0 0.982513 0.00758077 0.588734 0.14937 0.922279 0.967422 0.349146 0.445748 0.0962779 0.677464 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32290 episodes
GETTING ACTION FROM:
action 3, numVisits=32284, meanQ=12.290995, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.982513 0.00758077 0.588734 0.14937 0.922279 0.967422 0.349146 0.445748 0.0962779 0.677464 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 4
Initial state: 0 0.437191 0.416954 0.772642 0.680145 0.605256 0.106861 0.766965 0.214571 0.77475 0.00645661 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32443 episodes
GETTING ACTION FROM:
action 1, numVisits=32432, meanQ=12.208470, numObservations: 9
action 2, numVisits=4, meanQ=8.250000, numObservations: 3
action 5, numVisits=3, meanQ=5.663333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.437191 0.416954 0.772642 0.680145 0.605256 0.106861 0.766965 0.214571 0.77475 0.00645661 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 5
Initial state: 0 0.448303 0.90944 0.70846 0.779576 0.2247 0.699715 0.637393 0.922369 0.340503 0.471151 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32366 episodes
GETTING ACTION FROM:
action 3, numVisits=32355, meanQ=12.126684, numObservations: 9
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action 4, numVisits=5, meanQ=5.800000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.448303 0.90944 0.70846 0.779576 0.2247 0.699715 0.637393 0.922369 0.340503 0.471151 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=3052, meanQ=11.750845, numObservations: 9
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action 2, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 11025 episodes
GETTING ACTION FROM:
action 5, numVisits=13962, meanQ=12.647316, numObservations: 9
action 1, numVisits=113, meanQ=5.465531, numObservations: 9
action 2, numVisits=4, meanQ=2.304400, numObservations: 4
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 1 0.448303 0.90944 0.70846 0.779576 0.2247 0.699715 0.637393 0.922369 0.340503 0.471151 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 6
Initial state: 0 0.852735 0.202285 0.337201 0.422075 0.120043 0.0868163 0.534773 0.733131 0.472566 0.517808 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32442 episodes
GETTING ACTION FROM:
action 1, numVisits=32436, meanQ=12.082232, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.852735 0.202285 0.337201 0.422075 0.120043 0.0868163 0.534773 0.733131 0.472566 0.517808 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 7
Initial state: 0 0.655851 0.933657 0.369655 0.437971 0.585458 0.961972 0.134458 0.963954 0.607241 0.153734 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32253 episodes
GETTING ACTION FROM:
action 3, numVisits=32230, meanQ=12.351998, numObservations: 9
action 5, numVisits=7, meanQ=9.444286, numObservations: 5
action 4, numVisits=10, meanQ=8.897000, numObservations: 6
action 1, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.655851 0.933657 0.369655 0.437971 0.585458 0.961972 0.134458 0.963954 0.607241 0.153734 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 8
Initial state: 0 0.258986 0.640232 0.08558 0.835044 0.856812 0.0334015 0.412328 0.381183 0.0490305 0.731969 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32397 episodes
GETTING ACTION FROM:
action 5, numVisits=32352, meanQ=12.432486, numObservations: 9
action 1, numVisits=31, meanQ=10.500977, numObservations: 9
action 4, numVisits=8, meanQ=9.372500, numObservations: 6
action 3, numVisits=3, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 1 0.258986 0.640232 0.08558 0.835044 0.856812 0.0334015 0.412328 0.381183 0.0490305 0.731969 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 9
Initial state: 0 0.427078 0.324102 0.083789 0.140337 0.669599 0.903885 0.29302 0.378298 0.619735 0.485378 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32189 episodes
GETTING ACTION FROM:
action 2, numVisits=32178, meanQ=12.414292, numObservations: 9
action 1, numVisits=6, meanQ=3.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.427078 0.324102 0.083789 0.140337 0.669599 0.903885 0.29302 0.378298 0.619735 0.485378 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=2427, meanQ=12.667037, numObservations: 9
action 3, numVisits=22, meanQ=8.225459, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 13593 episodes
GETTING ACTION FROM:
action 4, numVisits=16018, meanQ=12.945701, numObservations: 9
action 3, numVisits=22, meanQ=8.225459, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 0 0.427078 0.324102 0.083789 0.140337 0.669599 0.903885 0.29302 0.378298 0.619735 0.485378 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=221, meanQ=9.454504, numObservations: 9
action 5, numVisits=66, meanQ=-0.073321, numObservations: 9
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=2, meanQ=-6.673550, numObservations: 2
action 4, numVisits=2, meanQ=-6.685663, numObservations: 2
action 0, numVisits=18, meanQ=-57.868588, numObservations: 14
action -1, numVisits=6, meanQ=-177.277694, numObservations: 5
Sampled 10494 episodes
GETTING ACTION FROM:
action 1, numVisits=10715, meanQ=11.055028, numObservations: 9
action 5, numVisits=66, meanQ=-0.073321, numObservations: 9
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=2, meanQ=-6.673550, numObservations: 2
action 4, numVisits=2, meanQ=-6.685663, numObservations: 2
action 0, numVisits=18, meanQ=-57.868588, numObservations: 14
action -1, numVisits=6, meanQ=-177.277694, numObservations: 5
action: 1
Next state: 1 0.427078 0.324102 0.083789 0.140337 0.669599 0.903885 0.29302 0.378298 0.619735 0.485378 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 10
Initial state: 0 0.923502 0.626204 0.81324 0.265396 0.859047 0.0976496 0.26935 0.0488049 0.44559 0.362029 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31133 episodes
GETTING ACTION FROM:
action 1, numVisits=31123, meanQ=12.227065, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.923502 0.626204 0.81324 0.265396 0.859047 0.0976496 0.26935 0.0488049 0.44559 0.362029 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 11
Initial state: 0 0.698846 0.136678 0.55976 0.202565 0.220605 0.523514 0.570296 0.511495 0.396868 0.398864 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32311 episodes
GETTING ACTION FROM:
action 5, numVisits=32293, meanQ=12.197875, numObservations: 9
action 4, numVisits=10, meanQ=7.299000, numObservations: 6
action 1, numVisits=4, meanQ=7.190000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.698846 0.136678 0.55976 0.202565 0.220605 0.523514 0.570296 0.511495 0.396868 0.398864 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 12
Initial state: 0 0.543486 0.823322 0.108887 0.0827497 0.0767117 0.291083 0.752814 0.448411 0.339904 0.419348 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30982 episodes
GETTING ACTION FROM:
action 2, numVisits=30976, meanQ=12.177589, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.543486 0.823322 0.108887 0.0827497 0.0767117 0.291083 0.752814 0.448411 0.339904 0.419348 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=2303, meanQ=13.010084, numObservations: 9
action 4, numVisits=3, meanQ=3.330000, numObservations: 3
action 1, numVisits=4, meanQ=-0.252500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 9340 episodes
GETTING ACTION FROM:
action 3, numVisits=11484, meanQ=12.038458, numObservations: 9
action 4, numVisits=3, meanQ=3.330000, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=106, meanQ=-12.082355, numObservations: 71
action -1, numVisits=45, meanQ=-19.507424, numObservations: 32
action 1, numVisits=8, meanQ=-23.130469, numObservations: 4
action 5, numVisits=7, meanQ=-144.022450, numObservations: 4
action: 3
Next state: 0 0.543486 0.823322 0.108887 0.0827497 0.0767117 0.291083 0.752814 0.448411 0.339904 0.419348 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=146, meanQ=14.293379, numObservations: 9
action 1, numVisits=11, meanQ=8.817273, numObservations: 7
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=47, meanQ=-9.726140, numObservations: 9
Sampled 7731 episodes
GETTING ACTION FROM:
action 5, numVisits=7868, meanQ=13.705276, numObservations: 9
action 1, numVisits=12, meanQ=7.165833, numObservations: 7
action -1, numVisits=7, meanQ=-1.151429, numObservations: 7
action 0, numVisits=5, meanQ=-1.406000, numObservations: 5
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=47, meanQ=-9.726140, numObservations: 9
action: 5
Next state: 0 0.543486 0.823322 0.108887 0.0827497 0.0767117 0.291083 0.752814 0.448411 0.339904 0.419348 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 0, numVisits=18, meanQ=0.255000, numObservations: 17
action -1, numVisits=10, meanQ=-1.208990, numObservations: 9
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-13.078848, numObservations: 1
action 5, numVisits=1, meanQ=-14.359690, numObservations: 1
action 2, numVisits=1, meanQ=-534.239416, numObservations: 1
action 3, numVisits=1, meanQ=-534.569958, numObservations: 1
Sampled 8753 episodes
GETTING ACTION FROM:
action -1, numVisits=8665, meanQ=-1.405444, numObservations: 235
action 0, numVisits=116, meanQ=-4.302990, numObservations: 64
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-13.078848, numObservations: 1
action 5, numVisits=1, meanQ=-14.359690, numObservations: 1
action 2, numVisits=1, meanQ=-534.239416, numObservations: 1
action 3, numVisits=1, meanQ=-534.569958, numObservations: 1
action: -1
Next state: 0 0.543486 0.823322 0.108887 0.0827497 0.0767117 0.291083 0.752814 0.448411 0.339904 0.419348 w: 1
Observation: 0 3 0 1 0 1 0 3 0 2 0 
Immediate reward: -2
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 5, numVisits=1, meanQ=24.000000, numObservations: 1
action 0, numVisits=14, meanQ=5.211443, numObservations: 8
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 1, numVisits=1, meanQ=-12.455465, numObservations: 1
action 4, numVisits=1, meanQ=-15.775192, numObservations: 1
action 2, numVisits=1, meanQ=-360.417292, numObservations: 1
action 3, numVisits=1, meanQ=-360.576804, numObservations: 1
Sampled 16864 episodes
GETTING ACTION FROM:
action 5, numVisits=305, meanQ=20.020077, numObservations: 9
action 0, numVisits=16507, meanQ=-1.109409, numObservations: 227
action -1, numVisits=70, meanQ=-7.086313, numObservations: 21
action 1, numVisits=1, meanQ=-12.455465, numObservations: 1
action 4, numVisits=1, meanQ=-15.775192, numObservations: 1
action 2, numVisits=1, meanQ=-360.417292, numObservations: 1
action 3, numVisits=1, meanQ=-360.576804, numObservations: 1
action: 5
Next state: 1 0.543486 0.823322 0.108887 0.0827497 0.0767117 0.291083 0.752814 0.448411 0.339904 0.419348 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9.23331
Run # 13
Initial state: 0 0.242898 0.585755 0.986532 0.0861277 0.37392 0.39373 0.0126145 0.147877 0.670788 0.421744 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32295 episodes
GETTING ACTION FROM:
action 4, numVisits=32279, meanQ=12.194934, numObservations: 9
action 1, numVisits=9, meanQ=9.222222, numObservations: 5
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 0 0.242898 0.585755 0.986532 0.0861277 0.37392 0.39373 0.0126145 0.147877 0.670788 0.421744 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=2421, meanQ=13.081061, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 12300 episodes
GETTING ACTION FROM:
action 5, numVisits=14719, meanQ=12.799468, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.242898 0.585755 0.986532 0.0861277 0.37392 0.39373 0.0126145 0.147877 0.670788 0.421744 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 14
Initial state: 0 0.159317 0.816628 0.508369 0.0036151 0.083568 0.319248 0.416786 0.358809 0.829395 0.950978 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32021 episodes
GETTING ACTION FROM:
action 3, numVisits=32011, meanQ=12.370336, numObservations: 9
action 5, numVisits=5, meanQ=5.800000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.159317 0.816628 0.508369 0.0036151 0.083568 0.319248 0.416786 0.358809 0.829395 0.950978 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=2425, meanQ=12.164867, numObservations: 9
action 5, numVisits=29, meanQ=5.612086, numObservations: 9
action 1, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 9979 episodes
GETTING ACTION FROM:
action 2, numVisits=12387, meanQ=12.136584, numObservations: 9
action 5, numVisits=42, meanQ=6.935012, numObservations: 9
action 1, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.340000, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.159317 0.816628 0.508369 0.0036151 0.083568 0.319248 0.416786 0.358809 0.829395 0.950978 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 15
Initial state: 0 0.868178 0.626455 0.364884 0.428431 0.0635225 0.29771 0.424759 0.902727 0.0138534 0.922495 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32329 episodes
GETTING ACTION FROM:
action 5, numVisits=32312, meanQ=12.542250, numObservations: 9
action 2, numVisits=8, meanQ=7.763750, numObservations: 6
action 4, numVisits=5, meanQ=5.800000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 1 0.868178 0.626455 0.364884 0.428431 0.0635225 0.29771 0.424759 0.902727 0.0138534 0.922495 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 16
Initial state: 0 0.283698 0.130892 0.870498 0.297654 0.322761 0.910526 0.34669 0.401702 0.682644 0.00837278 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32306 episodes
GETTING ACTION FROM:
action 1, numVisits=32280, meanQ=12.129521, numObservations: 9
action 2, numVisits=11, meanQ=5.796364, numObservations: 6
action 4, numVisits=11, meanQ=5.269091, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.283698 0.130892 0.870498 0.297654 0.322761 0.910526 0.34669 0.401702 0.682644 0.00837278 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=2366, meanQ=12.787984, numObservations: 9
action 5, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 13302 episodes
GETTING ACTION FROM:
action 3, numVisits=15439, meanQ=12.346406, numObservations: 9
action 5, numVisits=229, meanQ=11.783738, numObservations: 9
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.283698 0.130892 0.870498 0.297654 0.322761 0.910526 0.34669 0.401702 0.682644 0.00837278 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 17
Initial state: 0 0.401451 0.283195 0.428991 0.40261 0.285114 0.308065 0.986527 0.287233 0.686092 0.288011 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30831 episodes
GETTING ACTION FROM:
action 3, numVisits=30821, meanQ=12.029317, numObservations: 9
action 4, numVisits=2, meanQ=6.500000, numObservations: 2
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action 1, numVisits=3, meanQ=5.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.401451 0.283195 0.428991 0.40261 0.285114 0.308065 0.986527 0.287233 0.686092 0.288011 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=2289, meanQ=13.245460, numObservations: 9
action 1, numVisits=14, meanQ=7.909286, numObservations: 5
action 2, numVisits=11, meanQ=7.068191, numObservations: 7
action 4, numVisits=12, meanQ=6.091683, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 9769 episodes
GETTING ACTION FROM:
action 5, numVisits=12054, meanQ=13.087592, numObservations: 9
action 1, numVisits=14, meanQ=7.909286, numObservations: 5
action 2, numVisits=11, meanQ=7.068191, numObservations: 7
action 4, numVisits=12, meanQ=6.091683, numObservations: 6
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 2 0.401451 0.283195 0.428991 0.40261 0.285114 0.308065 0.986527 0.287233 0.686092 0.288011 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 18
Initial state: 0 0.735649 0.223771 0.551192 0.926222 0.390775 0.345356 0.186187 0.263929 0.283098 0.0353058 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32154 episodes
GETTING ACTION FROM:
action 2, numVisits=32142, meanQ=12.280775, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 4, numVisits=2, meanQ=-4.000000, numObservations: 2
action 5, numVisits=2, meanQ=-7.500000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.735649 0.223771 0.551192 0.926222 0.390775 0.345356 0.186187 0.263929 0.283098 0.0353058 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 19
Initial state: 0 0.845118 0.608794 0.755455 0.327608 0.693611 0.580877 0.425766 0.37147 0.617871 0.686674 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30404 episodes
GETTING ACTION FROM:
action 3, numVisits=30382, meanQ=12.245647, numObservations: 9
action 1, numVisits=17, meanQ=4.015294, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.845118 0.608794 0.755455 0.327608 0.693611 0.580877 0.425766 0.37147 0.617871 0.686674 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 20
Initial state: 0 0.368521 0.984111 0.253111 0.164074 0.404819 0.432271 0.124417 0.821115 0.210227 0.853219 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32581 episodes
GETTING ACTION FROM:
action 2, numVisits=29546, meanQ=12.335893, numObservations: 9
action 1, numVisits=3006, meanQ=12.115964, numObservations: 9
action 4, numVisits=18, meanQ=10.486122, numObservations: 7
action 5, numVisits=6, meanQ=7.831667, numObservations: 5
action 3, numVisits=3, meanQ=5.663333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.368521 0.984111 0.253111 0.164074 0.404819 0.432271 0.124417 0.821115 0.210227 0.853219 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=2206, meanQ=13.388503, numObservations: 9
action 1, numVisits=14, meanQ=6.427871, numObservations: 7
action 4, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 10599 episodes
GETTING ACTION FROM:
action 3, numVisits=12803, meanQ=13.411799, numObservations: 9
action 1, numVisits=14, meanQ=6.427871, numObservations: 7
action 4, numVisits=3, meanQ=3.330000, numObservations: 3
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.368521 0.984111 0.253111 0.164074 0.404819 0.432271 0.124417 0.821115 0.210227 0.853219 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 21
Initial state: 0 0.736715 0.218411 0.658176 0.144729 0.457488 0.972313 0.693332 0.824943 0.429207 0.371448 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32277 episodes
GETTING ACTION FROM:
action 1, numVisits=32262, meanQ=12.064385, numObservations: 9
action 5, numVisits=8, meanQ=6.888750, numObservations: 5
action 4, numVisits=3, meanQ=5.663333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.736715 0.218411 0.658176 0.144729 0.457488 0.972313 0.693332 0.824943 0.429207 0.371448 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 22
Initial state: 0 0.615094 0.983516 0.598414 0.188215 0.390926 0.471837 0.583329 0.693111 0.219474 0.704134 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30906 episodes
GETTING ACTION FROM:
action 3, numVisits=30891, meanQ=12.277324, numObservations: 9
action 4, numVisits=8, meanQ=4.873750, numObservations: 6
action 5, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.615094 0.983516 0.598414 0.188215 0.390926 0.471837 0.583329 0.693111 0.219474 0.704134 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 23
Initial state: 0 0.438879 0.328826 0.739113 0.816329 0.887053 0.813571 0.787458 0.655705 0.174858 0.153281 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32403 episodes
GETTING ACTION FROM:
action 4, numVisits=32397, meanQ=12.221004, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.438879 0.328826 0.739113 0.816329 0.887053 0.813571 0.787458 0.655705 0.174858 0.153281 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 24
Initial state: 0 0.326652 0.509878 0.629203 0.562054 0.343766 0.370128 0.994671 0.45209 0.469499 0.72595 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32288 episodes
GETTING ACTION FROM:
action 2, numVisits=32269, meanQ=12.437932, numObservations: 9
action 5, numVisits=13, meanQ=9.373854, numObservations: 6
action 4, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.326652 0.509878 0.629203 0.562054 0.343766 0.370128 0.994671 0.45209 0.469499 0.72595 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 25
Initial state: 0 0.250227 0.706748 0.4539 0.481657 0.905691 0.60516 0.686753 0.782859 0.163407 0.481298 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31000 episodes
GETTING ACTION FROM:
action 4, numVisits=30994, meanQ=12.342629, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.250227 0.706748 0.4539 0.481657 0.905691 0.60516 0.686753 0.782859 0.163407 0.481298 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 26
Initial state: 0 0.164073 0.0282727 0.348201 0.337572 0.572739 0.979495 0.412104 0.19247 0.325471 0.847694 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32169 episodes
GETTING ACTION FROM:
action 3, numVisits=32150, meanQ=12.177783, numObservations: 9
action 1, numVisits=9, meanQ=8.751111, numObservations: 6
action 2, numVisits=6, meanQ=7.666667, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.164073 0.0282727 0.348201 0.337572 0.572739 0.979495 0.412104 0.19247 0.325471 0.847694 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 27
Initial state: 0 0.0278198 0.288984 0.310778 0.587279 0.690647 0.706966 0.4036 0.413947 0.0960005 0.0343307 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32341 episodes
GETTING ACTION FROM:
action 1, numVisits=32331, meanQ=12.421613, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.0278198 0.288984 0.310778 0.587279 0.690647 0.706966 0.4036 0.413947 0.0960005 0.0343307 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=2353, meanQ=13.801544, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 10791 episodes
GETTING ACTION FROM:
action 5, numVisits=13140, meanQ=12.436781, numObservations: 9
action -1, numVisits=3, meanQ=-1.340000, numObservations: 3
action 0, numVisits=3, meanQ=-1.340000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.0278198 0.288984 0.310778 0.587279 0.690647 0.706966 0.4036 0.413947 0.0960005 0.0343307 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 28
Initial state: 0 0.962942 0.476094 0.504769 0.0616319 0.713851 0.210299 0.660619 0.938544 0.444042 0.47235 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32167 episodes
GETTING ACTION FROM:
action 1, numVisits=32160, meanQ=12.193903, numObservations: 9
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.962942 0.476094 0.504769 0.0616319 0.713851 0.210299 0.660619 0.938544 0.444042 0.47235 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 29
Initial state: 0 0.155156 0.502886 0.83659 0.491532 0.508009 0.0522513 0.439951 0.344045 0.957496 0.763389 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32186 episodes
GETTING ACTION FROM:
action 5, numVisits=32157, meanQ=12.293948, numObservations: 9
action 3, numVisits=21, meanQ=9.481429, numObservations: 9
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action 4, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 1 0.155156 0.502886 0.83659 0.491532 0.508009 0.0522513 0.439951 0.344045 0.957496 0.763389 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 30
Initial state: 0 0.88732 0.0160039 0.451003 0.417151 0.855701 0.821192 0.0489197 0.229307 0.355328 0.689659 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32152 episodes
GETTING ACTION FROM:
action 1, numVisits=32142, meanQ=12.141422, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.88732 0.0160039 0.451003 0.417151 0.855701 0.821192 0.0489197 0.229307 0.355328 0.689659 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 31
Initial state: 0 0.260938 0.164047 0.0872448 0.394708 0.40537 0.435051 0.248154 0.850819 0.873219 0.0385738 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31360 episodes
GETTING ACTION FROM:
action 1, numVisits=31350, meanQ=12.129832, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.260938 0.164047 0.0872448 0.394708 0.40537 0.435051 0.248154 0.850819 0.873219 0.0385738 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=585, meanQ=13.364629, numObservations: 9
action 3, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 34245 episodes
GETTING ACTION FROM:
action 2, numVisits=26050, meanQ=9.402241, numObservations: 9
action 5, numVisits=8771, meanQ=9.130608, numObservations: 9
action 3, numVisits=6, meanQ=3.425564, numObservations: 4
action -1, numVisits=5, meanQ=-1.604000, numObservations: 5
action 0, numVisits=4, meanQ=-1.752500, numObservations: 4
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.260938 0.164047 0.0872448 0.394708 0.40537 0.435051 0.248154 0.850819 0.873219 0.0385738 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 32
Initial state: 0 0.841787 0.476624 0.362773 0.482572 0.255122 0.863049 0.765764 0.583785 0.271498 0.82465 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32176 episodes
GETTING ACTION FROM:
action 5, numVisits=32158, meanQ=12.174958, numObservations: 9
action 1, numVisits=11, meanQ=9.453636, numObservations: 6
action 4, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.841787 0.476624 0.362773 0.482572 0.255122 0.863049 0.765764 0.583785 0.271498 0.82465 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=3115, meanQ=13.147274, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 11606 episodes
GETTING ACTION FROM:
action 2, numVisits=14719, meanQ=13.262509, numObservations: 9
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.841787 0.476624 0.362773 0.482572 0.255122 0.863049 0.765764 0.583785 0.271498 0.82465 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 33
Initial state: 0 0.236618 0.111472 0.799718 0.0745976 0.2192 0.00865881 0.422846 0.408393 0.888215 0.154982 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32131 episodes
GETTING ACTION FROM:
action 2, numVisits=32117, meanQ=12.371210, numObservations: 9
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action 4, numVisits=2, meanQ=6.500000, numObservations: 2
action 5, numVisits=6, meanQ=6.500000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 2 0.236618 0.111472 0.799718 0.0745976 0.2192 0.00865881 0.422846 0.408393 0.888215 0.154982 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 34
Initial state: 0 0.227084 0.786271 0.626241 0.143479 0.803268 0.893488 0.34449 0.431566 0.0315374 0.249971 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31919 episodes
GETTING ACTION FROM:
action 2, numVisits=31893, meanQ=12.258269, numObservations: 9
action 5, numVisits=19, meanQ=9.057900, numObservations: 8
action 1, numVisits=3, meanQ=5.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.227084 0.786271 0.626241 0.143479 0.803268 0.893488 0.34449 0.431566 0.0315374 0.249971 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 35
Initial state: 0 0.996862 0.311315 0.0704019 0.141711 0.0254232 0.0294053 0.0584285 0.574204 0.417427 0.465776 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32315 episodes
GETTING ACTION FROM:
action 5, numVisits=32293, meanQ=12.315146, numObservations: 9
action 4, numVisits=15, meanQ=6.398667, numObservations: 5
action 1, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.996862 0.311315 0.0704019 0.141711 0.0254232 0.0294053 0.0584285 0.574204 0.417427 0.465776 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 36
Initial state: 0 0.855719 0.858406 0.368022 0.41433 0.0434145 0.609165 0.561965 0.887948 0.166746 0.195537 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32421 episodes
GETTING ACTION FROM:
action 1, numVisits=32322, meanQ=12.311783, numObservations: 9
action 2, numVisits=73, meanQ=10.233851, numObservations: 9
action 4, numVisits=19, meanQ=9.157905, numObservations: 8
action 5, numVisits=4, meanQ=8.497500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.855719 0.858406 0.368022 0.41433 0.0434145 0.609165 0.561965 0.887948 0.166746 0.195537 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 37
Initial state: 0 0.446701 0.453736 0.429531 0.309943 0.00712278 0.0108652 0.0901338 0.975789 0.914468 0.898818 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32129 episodes
GETTING ACTION FROM:
action 1, numVisits=32121, meanQ=12.183664, numObservations: 9
action 5, numVisits=3, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.446701 0.453736 0.429531 0.309943 0.00712278 0.0108652 0.0901338 0.975789 0.914468 0.898818 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 38
Initial state: 0 0.111643 0.0130023 0.12447 0.106767 0.397565 0.398425 0.241902 0.909158 0.336778 0.583271 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32150 episodes
GETTING ACTION FROM:
action 4, numVisits=32133, meanQ=12.313319, numObservations: 9
action 1, numVisits=6, meanQ=8.833333, numObservations: 5
action 2, numVisits=4, meanQ=8.250000, numObservations: 4
action 3, numVisits=4, meanQ=8.250000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.111643 0.0130023 0.12447 0.106767 0.397565 0.398425 0.241902 0.909158 0.336778 0.583271 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=278, meanQ=13.345523, numObservations: 9
action 5, numVisits=4, meanQ=10.495000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 25749 episodes
GETTING ACTION FROM:
action 5, numVisits=25732, meanQ=14.133098, numObservations: 9
action 4, numVisits=292, meanQ=13.463929, numObservations: 9
action -1, numVisits=5, meanQ=-1.604000, numObservations: 5
action 0, numVisits=4, meanQ=-1.752500, numObservations: 4
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.111643 0.0130023 0.12447 0.106767 0.397565 0.398425 0.241902 0.909158 0.336778 0.583271 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 39
Initial state: 0 0.381813 0.365193 0.489465 0.674635 0.769075 0.168442 0.170612 0.849463 0.547822 0.100823 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32113 episodes
GETTING ACTION FROM:
action 1, numVisits=32107, meanQ=12.337567, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.381813 0.365193 0.489465 0.674635 0.769075 0.168442 0.170612 0.849463 0.547822 0.100823 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 40
Initial state: 0 0.942772 0.899326 0.151859 0.964033 0.471101 0.553382 0.416145 0.392818 0.667043 0.943181 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30384 episodes
GETTING ACTION FROM:
action 3, numVisits=30370, meanQ=12.384963, numObservations: 9
action 1, numVisits=8, meanQ=8.390013, numObservations: 4
action 4, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.942772 0.899326 0.151859 0.964033 0.471101 0.553382 0.416145 0.392818 0.667043 0.943181 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 41
Initial state: 0 0.438693 0.320825 0.927932 0.620316 0.535819 0.265233 0.435288 0.883776 0.510835 0.699205 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18226 episodes
GETTING ACTION FROM:
action 0, numVisits=18209, meanQ=16.096046, numObservations: 243
action -1, numVisits=10, meanQ=-1.208990, numObservations: 9
action 2, numVisits=2, meanQ=-7.500000, numObservations: 2
action 4, numVisits=2, meanQ=-7.500000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.438693 0.320825 0.927932 0.620316 0.535819 0.265233 0.435288 0.883776 0.510835 0.699205 w: 1
Observation: 0 0 2 0 3 0 1 0 3 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=182, meanQ=21.721539, numObservations: 8
action 5, numVisits=12, meanQ=11.083342, numObservations: 5
action 4, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 39010 episodes
GETTING ACTION FROM:
action 1, numVisits=39192, meanQ=22.382403, numObservations: 9
action 5, numVisits=12, meanQ=11.083342, numObservations: 5
action 4, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.438693 0.320825 0.927932 0.620316 0.535819 0.265233 0.435288 0.883776 0.510835 0.699205 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 42
Initial state: 0 0.439564 0.0643949 0.923808 0.680332 0.120489 0.658115 0.374908 0.379498 0.695528 0.90617 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30994 episodes
GETTING ACTION FROM:
action 3, numVisits=30979, meanQ=12.257011, numObservations: 9
action 1, numVisits=6, meanQ=8.833333, numObservations: 5
action 4, numVisits=4, meanQ=8.250000, numObservations: 3
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.439564 0.0643949 0.923808 0.680332 0.120489 0.658115 0.374908 0.379498 0.695528 0.90617 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 43
Initial state: 0 0.964899 0.686872 0.3832 0.320275 0.0957259 0.874406 0.344608 0.857364 0.865428 0.159547 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32285 episodes
GETTING ACTION FROM:
action 2, numVisits=32263, meanQ=12.130462, numObservations: 9
action 4, numVisits=17, meanQ=8.822941, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.964899 0.686872 0.3832 0.320275 0.0957259 0.874406 0.344608 0.857364 0.865428 0.159547 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 44
Initial state: 0 0.266946 0.395876 0.617894 0.704469 0.876692 0.970543 0.837536 0.59303 0.395291 0.334489 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31984 episodes
GETTING ACTION FROM:
action 2, numVisits=31976, meanQ=12.284935, numObservations: 9
action 1, numVisits=3, meanQ=5.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.266946 0.395876 0.617894 0.704469 0.876692 0.970543 0.837536 0.59303 0.395291 0.334489 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 45
Initial state: 0 0.184694 0.592675 0.363563 0.385234 0.285082 0.728028 0.743203 0.703819 0.0989528 0.781918 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32301 episodes
GETTING ACTION FROM:
action 2, numVisits=32291, meanQ=12.158474, numObservations: 9
action 4, numVisits=5, meanQ=4.598000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.184694 0.592675 0.363563 0.385234 0.285082 0.728028 0.743203 0.703819 0.0989528 0.781918 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 46
Initial state: 0 0.685007 0.288502 0.415829 0.321638 0.289599 0.940556 0.908633 0.138951 0.581111 0.111892 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32353 episodes
GETTING ACTION FROM:
action 2, numVisits=32290, meanQ=12.326404, numObservations: 9
action 4, numVisits=49, meanQ=10.456541, numObservations: 9
action 1, numVisits=8, meanQ=9.372500, numObservations: 5
action 3, numVisits=3, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.685007 0.288502 0.415829 0.321638 0.289599 0.940556 0.908633 0.138951 0.581111 0.111892 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 47
Initial state: 0 0.761618 0.669873 0.504653 0.817476 0.0770624 0.953987 0.346121 0.373176 0.000111813 0.624158 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32238 episodes
GETTING ACTION FROM:
action 1, numVisits=32218, meanQ=12.254745, numObservations: 9
action 4, numVisits=11, meanQ=7.363645, numObservations: 7
action 2, numVisits=5, meanQ=5.800000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.761618 0.669873 0.504653 0.817476 0.0770624 0.953987 0.346121 0.373176 0.000111813 0.624158 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 48
Initial state: 0 0.229765 0.858194 0.399722 0.303151 0.107203 0.0834491 0.423819 0.422683 0.693578 0.64479 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31260 episodes
GETTING ACTION FROM:
action 5, numVisits=31244, meanQ=12.267587, numObservations: 9
action 1, numVisits=7, meanQ=9.000000, numObservations: 6
action 2, numVisits=4, meanQ=8.250000, numObservations: 4
action 4, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 1 0.229765 0.858194 0.399722 0.303151 0.107203 0.0834491 0.423819 0.422683 0.693578 0.64479 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 49
Initial state: 0 0.153908 0.959556 0.814943 0.11857 0.495748 0.702762 0.213329 0.937831 0.35331 0.364915 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31822 episodes
GETTING ACTION FROM:
action 5, numVisits=31809, meanQ=12.249165, numObservations: 9
action 2, numVisits=8, meanQ=3.502512, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.153908 0.959556 0.814943 0.11857 0.495748 0.702762 0.213329 0.937831 0.35331 0.364915 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 50
Initial state: 0 0.357219 0.368695 0.304665 0.114846 0.96327 0.774251 0.547802 0.0708379 0.162919 0.669095 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32304 episodes
GETTING ACTION FROM:
action 1, numVisits=32296, meanQ=12.474007, numObservations: 9
action 4, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.357219 0.368695 0.304665 0.114846 0.96327 0.774251 0.547802 0.0708379 0.162919 0.669095 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
[32m ProblemEnvironment.hpp 351: Done.[39m
