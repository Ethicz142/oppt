Run # 1
Initial state: 0 0.868938 0.848328 0.109755 0.521891 0.564786 0.950808 0.453258 0.692743 0.543758 0.548667 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27571 episodes
GETTING ACTION FROM:
action 4, numVisits=27560, meanQ=10.510403, numObservations: 9
action 1, numVisits=6, meanQ=2.516667, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.868938 0.848328 0.109755 0.521891 0.564786 0.950808 0.453258 0.692743 0.543758 0.548667 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=3442, meanQ=11.352813, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 8756 episodes
GETTING ACTION FROM:
action 2, numVisits=12198, meanQ=11.758949, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.868938 0.848328 0.109755 0.521891 0.564786 0.950808 0.453258 0.692743 0.543758 0.548667 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=260, meanQ=12.285948, numObservations: 9
action 1, numVisits=5, meanQ=-0.804000, numObservations: 4
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 9076 episodes
GETTING ACTION FROM:
action 3, numVisits=9334, meanQ=12.634806, numObservations: 9
action 1, numVisits=5, meanQ=-0.804000, numObservations: 4
action 0, numVisits=3, meanQ=-1.340000, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=3, meanQ=-4.970000, numObservations: 2
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.868938 0.848328 0.109755 0.521891 0.564786 0.950808 0.453258 0.692743 0.543758 0.548667 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 2
Initial state: 0 0.816008 0.977724 0.685396 0.270174 0.550768 0.542285 0.70532 0.651669 0.672566 0.819283 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27888 episodes
GETTING ACTION FROM:
action 2, numVisits=27868, meanQ=10.458534, numObservations: 9
action 5, numVisits=7, meanQ=6.000000, numObservations: 6
action 3, numVisits=9, meanQ=5.780011, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.816008 0.977724 0.685396 0.270174 0.550768 0.542285 0.70532 0.651669 0.672566 0.819283 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 3
Initial state: 0 0.987971 0.80053 0.514202 0.500596 0.796612 0.960425 0.913634 0.289839 0.0587916 0.0260189 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17688 episodes
GETTING ACTION FROM:
action 0, numVisits=17672, meanQ=14.784430, numObservations: 243
action -1, numVisits=7, meanQ=-2.707143, numObservations: 6
action 2, numVisits=3, meanQ=-4.000000, numObservations: 3
action 4, numVisits=2, meanQ=-7.500000, numObservations: 2
action 5, numVisits=2, meanQ=-7.500000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.987971 0.80053 0.514202 0.500596 0.796612 0.960425 0.913634 0.289839 0.0587916 0.0260189 w: 1
Observation: 0 0 3 0 2 0 3 0 1 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=116, meanQ=16.526118, numObservations: 9
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 31659 episodes
GETTING ACTION FROM:
action 3, numVisits=31775, meanQ=18.765888, numObservations: 9
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.987971 0.80053 0.514202 0.500596 0.796612 0.960425 0.913634 0.289839 0.0587916 0.0260189 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 4
Initial state: 0 0.50962 0.411265 0.754266 0.105234 0.125429 0.339279 0.902123 0.793434 0.86409 0.975463 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28171 episodes
GETTING ACTION FROM:
action 2, numVisits=28154, meanQ=10.701054, numObservations: 9
action 4, numVisits=8, meanQ=8.373750, numObservations: 5
action 1, numVisits=3, meanQ=5.333333, numObservations: 3
action 5, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 2 0.50962 0.411265 0.754266 0.105234 0.125429 0.339279 0.902123 0.793434 0.86409 0.975463 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 5
Initial state: 0 0.625947 0.242545 0.52968 0.502158 0.796818 0.181409 0.368719 0.528129 0.674548 0.598179 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28341 episodes
GETTING ACTION FROM:
action 2, numVisits=28335, meanQ=10.517888, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.625947 0.242545 0.52968 0.502158 0.796818 0.181409 0.368719 0.528129 0.674548 0.598179 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 6
Initial state: 0 0.929584 0.3186 0.79725 0.670271 0.525769 0.541207 0.030819 0.788232 0.620589 0.348215 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28337 episodes
GETTING ACTION FROM:
action 4, numVisits=28331, meanQ=10.575151, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 1 0.929584 0.3186 0.79725 0.670271 0.525769 0.541207 0.030819 0.788232 0.620589 0.348215 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 7
Initial state: 0 0.0661748 0.467538 0.833444 0.970786 0.00764626 0.685788 0.578818 0.444461 0.620374 0.930951 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27100 episodes
GETTING ACTION FROM:
action 3, numVisits=27090, meanQ=10.834656, numObservations: 9
action 2, numVisits=5, meanQ=5.600020, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.0661748 0.467538 0.833444 0.970786 0.00764626 0.685788 0.578818 0.444461 0.620374 0.930951 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=3230, meanQ=12.991451, numObservations: 9
action 2, numVisits=13, meanQ=5.228477, numObservations: 7
action 4, numVisits=4, meanQ=3.742500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 10915 episodes
GETTING ACTION FROM:
action 1, numVisits=10868, meanQ=13.969511, numObservations: 9
action 3, numVisits=3231, meanQ=12.989515, numObservations: 9
action 4, numVisits=11, meanQ=0.846038, numObservations: 5
action 5, numVisits=2, meanQ=-7.005000, numObservations: 2
action -1, numVisits=19, meanQ=-56.845403, numObservations: 18
action 0, numVisits=19, meanQ=-57.588364, numObservations: 16
action 2, numVisits=16, meanQ=-59.301535, numObservations: 7
action: 1
Next state: 0 0.0661748 0.467538 0.833444 0.970786 0.00764626 0.685788 0.578818 0.444461 0.620374 0.930951 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=276, meanQ=12.576576, numObservations: 9
action 2, numVisits=6, meanQ=6.500000, numObservations: 3
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 4, numVisits=1, meanQ=-10.596000, numObservations: 1
action 1, numVisits=1, meanQ=-12.901044, numObservations: 1
action 3, numVisits=1, meanQ=-1063.820956, numObservations: 1
Sampled 6928 episodes
GETTING ACTION FROM:
action 5, numVisits=7202, meanQ=14.933883, numObservations: 9
action 2, numVisits=6, meanQ=6.500000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action -1, numVisits=3, meanQ=-1.340000, numObservations: 3
action 4, numVisits=1, meanQ=-10.596000, numObservations: 1
action 1, numVisits=1, meanQ=-12.901044, numObservations: 1
action 3, numVisits=1, meanQ=-1063.820956, numObservations: 1
action: 5
Next state: 1 0.0661748 0.467538 0.833444 0.970786 0.00764626 0.685788 0.578818 0.444461 0.620374 0.930951 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 8
Initial state: 0 0.903591 0.903728 0.208567 0.286986 0.546935 0.49487 0.13336 0.217895 0.996559 0.629462 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28327 episodes
GETTING ACTION FROM:
action 5, numVisits=28321, meanQ=10.475218, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.903591 0.903728 0.208567 0.286986 0.546935 0.49487 0.13336 0.217895 0.996559 0.629462 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 9
Initial state: 0 0.511642 0.86058 0.808061 0.453927 0.792842 0.944909 0.484024 0.47852 0.750795 0.603403 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27156 episodes
GETTING ACTION FROM:
action 3, numVisits=27146, meanQ=10.734809, numObservations: 9
action 5, numVisits=5, meanQ=7.596000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.511642 0.86058 0.808061 0.453927 0.792842 0.944909 0.484024 0.47852 0.750795 0.603403 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 10
Initial state: 0 0.276177 0.680629 0.142469 0.23393 0.171784 0.369691 0.116929 0.833391 0.514026 0.506078 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28042 episodes
GETTING ACTION FROM:
action 5, numVisits=28034, meanQ=10.451241, numObservations: 9
action 3, numVisits=3, meanQ=5.000033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.276177 0.680629 0.142469 0.23393 0.171784 0.369691 0.116929 0.833391 0.514026 0.506078 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 11
Initial state: 0 0.56396 0.451334 0.924431 0.573094 0.0737015 0.491743 0.000407796 0.999793 0.977154 0.223039 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28085 episodes
GETTING ACTION FROM:
action 5, numVisits=28045, meanQ=10.764509, numObservations: 9
action 2, numVisits=29, meanQ=6.327252, numObservations: 7
action 4, numVisits=5, meanQ=4.400000, numObservations: 5
action 3, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 2 0.56396 0.451334 0.924431 0.573094 0.0737015 0.491743 0.000407796 0.999793 0.977154 0.223039 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 12
Initial state: 0 0.564069 0.475524 0.302616 0.702334 0.756342 0.186944 0.670971 0.787516 0.234884 0.585744 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28358 episodes
GETTING ACTION FROM:
action 5, numVisits=28352, meanQ=10.543771, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.564069 0.475524 0.302616 0.702334 0.756342 0.186944 0.670971 0.787516 0.234884 0.585744 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 13
Initial state: 0 0.408918 0.486965 0.564923 0.727796 0.217352 0.587057 0.489885 0.433044 0.810928 0.248568 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28243 episodes
GETTING ACTION FROM:
action 5, numVisits=28230, meanQ=10.315429, numObservations: 9
action 2, numVisits=8, meanQ=4.997500, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.408918 0.486965 0.564923 0.727796 0.217352 0.587057 0.489885 0.433044 0.810928 0.248568 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 14
Initial state: 0 0.500651 0.791134 0.859532 0.467211 0.601608 0.43168 0.352466 0.899194 0.680651 0.193617 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28267 episodes
GETTING ACTION FROM:
action 3, numVisits=28256, meanQ=10.758774, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=2, meanQ=-7.500000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.500651 0.791134 0.859532 0.467211 0.601608 0.43168 0.352466 0.899194 0.680651 0.193617 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 15
Initial state: 0 0.921265 0.249291 0.557425 0.446617 0.396041 0.626116 0.397018 0.233782 0.00520798 0.448405 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28306 episodes
GETTING ACTION FROM:
action 4, numVisits=28300, meanQ=10.717503, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.921265 0.249291 0.557425 0.446617 0.396041 0.626116 0.397018 0.233782 0.00520798 0.448405 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=4055, meanQ=11.542046, numObservations: 9
action 3, numVisits=23, meanQ=5.867830, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 7056 episodes
GETTING ACTION FROM:
action 1, numVisits=11105, meanQ=10.630640, numObservations: 9
action 3, numVisits=23, meanQ=5.867830, numObservations: 9
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.921265 0.249291 0.557425 0.446617 0.396041 0.626116 0.397018 0.233782 0.00520798 0.448405 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 16
Initial state: 0 0.537252 0.90612 0.265394 0.839742 0.38645 0.895919 0.573084 0.463965 0.809778 0.908624 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28217 episodes
GETTING ACTION FROM:
action 2, numVisits=28211, meanQ=10.248518, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.537252 0.90612 0.265394 0.839742 0.38645 0.895919 0.573084 0.463965 0.809778 0.908624 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 17
Initial state: 0 0.650549 0.310986 0.381853 0.214589 0.188014 0.269828 0.575362 0.453039 0.981727 0.28676 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27160 episodes
GETTING ACTION FROM:
action 2, numVisits=27154, meanQ=10.581418, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.650549 0.310986 0.381853 0.214589 0.188014 0.269828 0.575362 0.453039 0.981727 0.28676 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=3703, meanQ=11.160923, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 8727 episodes
GETTING ACTION FROM:
action 4, numVisits=12406, meanQ=11.370400, numObservations: 9
action -1, numVisits=17, meanQ=-1.126471, numObservations: 17
action 0, numVisits=9, meanQ=-2.175374, numObservations: 8
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=2, meanQ=-6.128461, numObservations: 2
action 5, numVisits=2, meanQ=-7.005000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.650549 0.310986 0.381853 0.214589 0.188014 0.269828 0.575362 0.453039 0.981727 0.28676 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 18
Initial state: 0 0.621207 0.43678 0.33812 0.704833 0.000125272 0.575813 0.709974 0.164507 0.907145 0.207492 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28277 episodes
GETTING ACTION FROM:
action 2, numVisits=28250, meanQ=10.539111, numObservations: 9
action 4, numVisits=18, meanQ=7.334467, numObservations: 8
action 1, numVisits=5, meanQ=5.800000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.621207 0.43678 0.33812 0.704833 0.000125272 0.575813 0.709974 0.164507 0.907145 0.207492 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 19
Initial state: 0 0.261958 0.219809 0.0212238 0.126239 0.748805 0.600984 0.00991118 0.447473 0.613651 0.442402 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27093 episodes
GETTING ACTION FROM:
action 1, numVisits=27059, meanQ=10.597849, numObservations: 9
action 4, numVisits=24, meanQ=8.938346, numObservations: 7
action 2, numVisits=6, meanQ=7.666667, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.261958 0.219809 0.0212238 0.126239 0.748805 0.600984 0.00991118 0.447473 0.613651 0.442402 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=3697, meanQ=11.334557, numObservations: 9
action 3, numVisits=15, meanQ=7.731347, numObservations: 8
action 2, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 9832 episodes
GETTING ACTION FROM:
action 4, numVisits=13479, meanQ=9.992672, numObservations: 9
action 3, numVisits=17, meanQ=5.496646, numObservations: 8
action -1, numVisits=15, meanQ=-1.010000, numObservations: 15
action 0, numVisits=14, meanQ=-1.080714, numObservations: 14
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=24, meanQ=-35.775985, numObservations: 9
action: 4
Next state: 0 0.261958 0.219809 0.0212238 0.126239 0.748805 0.600984 0.00991118 0.447473 0.613651 0.442402 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=1466, meanQ=12.566241, numObservations: 9
action 2, numVisits=36, meanQ=9.028072, numObservations: 8
action 3, numVisits=7, meanQ=7.424286, numObservations: 6
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 6960 episodes
GETTING ACTION FROM:
action 5, numVisits=7070, meanQ=11.383092, numObservations: 9
action 2, numVisits=1275, meanQ=9.633520, numObservations: 9
action 0, numVisits=16, meanQ=-1.566875, numObservations: 15
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=96, meanQ=-4.165812, numObservations: 46
action 3, numVisits=16, meanQ=-8.378804, numObservations: 9
action: 5
Next state: 1 0.261958 0.219809 0.0212238 0.126239 0.748805 0.600984 0.00991118 0.447473 0.613651 0.442402 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 20
Initial state: 0 0.519295 0.659555 0.577056 0.49723 0.762907 0.6167 0.427636 0.885005 0.863747 0.973277 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27783 episodes
GETTING ACTION FROM:
action 2, numVisits=27770, meanQ=10.302239, numObservations: 9
action 5, numVisits=6, meanQ=4.166667, numObservations: 4
action 1, numVisits=3, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.519295 0.659555 0.577056 0.49723 0.762907 0.6167 0.427636 0.885005 0.863747 0.973277 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 21
Initial state: 0 0.745368 0.747004 0.961934 0.259481 0.581426 0.559731 0.0476459 0.429415 0.996115 0.0526591 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28225 episodes
GETTING ACTION FROM:
action 3, numVisits=28217, meanQ=10.797397, numObservations: 9
action 2, numVisits=3, meanQ=5.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.745368 0.747004 0.961934 0.259481 0.581426 0.559731 0.0476459 0.429415 0.996115 0.0526591 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 22
Initial state: 0 0.512134 0.853176 0.575665 0.410812 0.662085 0.922182 0.839379 0.355974 0.847074 0.0661461 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17638 episodes
GETTING ACTION FROM:
action 0, numVisits=17615, meanQ=14.601557, numObservations: 243
action -1, numVisits=14, meanQ=-1.294271, numObservations: 12
action 1, numVisits=2, meanQ=-4.000000, numObservations: 2
action 2, numVisits=2, meanQ=-9.445000, numObservations: 1
action 3, numVisits=2, meanQ=-9.445000, numObservations: 1
action 4, numVisits=2, meanQ=-9.445000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.512134 0.853176 0.575665 0.410812 0.662085 0.922182 0.839379 0.355974 0.847074 0.0661461 w: 1
Observation: 0 0 3 0 2 0 1 0 1 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=107, meanQ=21.521407, numObservations: 8
action 1, numVisits=3, meanQ=14.996667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 36321 episodes
GETTING ACTION FROM:
action 2, numVisits=36428, meanQ=21.326566, numObservations: 9
action 1, numVisits=3, meanQ=14.996667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.512134 0.853176 0.575665 0.410812 0.662085 0.922182 0.839379 0.355974 0.847074 0.0661461 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 23
Initial state: 0 0.981903 0.0772632 0.00612182 0.237109 0.351613 0.00379717 0.508566 0.410685 0.289705 0.35437 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28251 episodes
GETTING ACTION FROM:
action 5, numVisits=28230, meanQ=10.730643, numObservations: 9
action 1, numVisits=8, meanQ=8.222513, numObservations: 5
action 3, numVisits=9, meanQ=7.665567, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.981903 0.0772632 0.00612182 0.237109 0.351613 0.00379717 0.508566 0.410685 0.289705 0.35437 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=3928, meanQ=11.322890, numObservations: 9
action 3, numVisits=12, meanQ=5.915017, numObservations: 6
action 2, numVisits=3, meanQ=4.670033, numObservations: 2
action 1, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 6442 episodes
GETTING ACTION FROM:
action 4, numVisits=9684, meanQ=11.158342, numObservations: 9
action 2, numVisits=516, meanQ=6.531579, numObservations: 9
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=136, meanQ=-5.413826, numObservations: 9
action 0, numVisits=25, meanQ=-41.788485, numObservations: 21
action -1, numVisits=19, meanQ=-54.926739, numObservations: 16
action 1, numVisits=10, meanQ=-102.816562, numObservations: 5
action: 4
Next state: 1 0.981903 0.0772632 0.00612182 0.237109 0.351613 0.00379717 0.508566 0.410685 0.289705 0.35437 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 24
Initial state: 0 0.450735 0.131791 0.0220742 0.497838 0.620151 0.497713 0.758234 0.96216 0.691952 0.422672 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 25873 episodes
GETTING ACTION FROM:
action 3, numVisits=25864, meanQ=9.912679, numObservations: 9
action 1, numVisits=4, meanQ=0.505025, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.450735 0.131791 0.0220742 0.497838 0.620151 0.497713 0.758234 0.96216 0.691952 0.422672 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 25
Initial state: 0 0.282563 0.151864 0.0546508 0.351678 0.869502 0.808716 0.780932 0.971941 0.487402 0.552543 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27845 episodes
GETTING ACTION FROM:
action 4, numVisits=27835, meanQ=10.610592, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 1 0.282563 0.151864 0.0546508 0.351678 0.869502 0.808716 0.780932 0.971941 0.487402 0.552543 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 26
Initial state: 0 0.131274 0.0379392 0.565084 0.510552 0.721437 0.0588077 0.129613 0.207974 0.0177599 0.0840769 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28465 episodes
GETTING ACTION FROM:
action 3, numVisits=28455, meanQ=10.713367, numObservations: 9
action 2, numVisits=3, meanQ=4.340033, numObservations: 2
action 4, numVisits=3, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 2 0.131274 0.0379392 0.565084 0.510552 0.721437 0.0588077 0.129613 0.207974 0.0177599 0.0840769 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 27
Initial state: 0 0.0660999 0.629571 0.556355 0.487322 0.9267 0.892531 0.942508 0.745213 0.0174583 0.0043781 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27354 episodes
GETTING ACTION FROM:
action 2, numVisits=27330, meanQ=10.657287, numObservations: 9
action 4, numVisits=19, meanQ=5.949489, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.0660999 0.629571 0.556355 0.487322 0.9267 0.892531 0.942508 0.745213 0.0174583 0.0043781 w: 1
Observation: 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 28
Initial state: 0 0.278254 0.74377 0.461163 0.956396 0.930219 0.741364 0.334009 0.127402 0.616349 0.532494 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26636 episodes
GETTING ACTION FROM:
action 4, numVisits=26627, meanQ=10.465364, numObservations: 9
action 3, numVisits=4, meanQ=1.250000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.278254 0.74377 0.461163 0.956396 0.930219 0.741364 0.334009 0.127402 0.616349 0.532494 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=3763, meanQ=13.318988, numObservations: 227
action -1, numVisits=7, meanQ=-1.294271, numObservations: 6
action 1, numVisits=6, meanQ=-1.834967, numObservations: 3
action 3, numVisits=2, meanQ=-3.010000, numObservations: 2
action 4, numVisits=2, meanQ=-7.005000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 4374 episodes
GETTING ACTION FROM:
action 0, numVisits=8137, meanQ=12.441904, numObservations: 240
action -1, numVisits=7, meanQ=-1.294271, numObservations: 6
action 1, numVisits=6, meanQ=-1.834967, numObservations: 3
action 3, numVisits=2, meanQ=-3.010000, numObservations: 2
action 4, numVisits=2, meanQ=-7.005000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.278254 0.74377 0.461163 0.956396 0.930219 0.741364 0.334009 0.127402 0.616349 0.532494 w: 1
Observation: 0 0 3 0 3 0 3 0 1 0 2 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=110, meanQ=15.698289, numObservations: 9
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 14682 episodes
GETTING ACTION FROM:
action 2, numVisits=14792, meanQ=16.665512, numObservations: 9
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.278254 0.74377 0.461163 0.956396 0.930219 0.741364 0.334009 0.127402 0.616349 0.532494 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 5, numVisits=2404, meanQ=20.291487, numObservations: 9
action 3, numVisits=79, meanQ=5.778348, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=18, meanQ=-42.656814, numObservations: 5
Sampled 23085 episodes
GETTING ACTION FROM:
action 5, numVisits=25489, meanQ=21.982214, numObservations: 9
action 3, numVisits=79, meanQ=5.778348, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=18, meanQ=-42.656814, numObservations: 5
action: 5
Next state: 1 0.278254 0.74377 0.461163 0.956396 0.930219 0.741364 0.334009 0.127402 0.616349 0.532494 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 13.3868
Run # 29
Initial state: 0 0.188006 0.316149 0.603303 0.461957 0.980139 0.0520294 0.909496 0.94177 0.815116 0.408922 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27924 episodes
GETTING ACTION FROM:
action 1, numVisits=27914, meanQ=10.454282, numObservations: 9
action 5, numVisits=3, meanQ=5.663333, numObservations: 3
action 4, numVisits=3, meanQ=1.703333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.188006 0.316149 0.603303 0.461957 0.980139 0.0520294 0.909496 0.94177 0.815116 0.408922 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=955, meanQ=12.075411, numObservations: 9
action 5, numVisits=3, meanQ=3.330000, numObservations: 3
action 3, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 8723 episodes
GETTING ACTION FROM:
action 4, numVisits=9658, meanQ=10.651174, numObservations: 9
action 5, numVisits=5, meanQ=4.243481, numObservations: 4
action 3, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=12, meanQ=-1.340000, numObservations: 12
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=8, meanQ=-132.045049, numObservations: 7
action: 4
Next state: 1 0.188006 0.316149 0.603303 0.461957 0.980139 0.0520294 0.909496 0.94177 0.815116 0.408922 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 30
Initial state: 0 0.470641 0.227118 0.79448 0.639458 0.620185 0.411821 0.16896 0.0635093 0.296023 0.543446 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28202 episodes
GETTING ACTION FROM:
action 1, numVisits=28190, meanQ=10.526602, numObservations: 9
action 5, numVisits=7, meanQ=2.574300, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.470641 0.227118 0.79448 0.639458 0.620185 0.411821 0.16896 0.0635093 0.296023 0.543446 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=3957, meanQ=11.115701, numObservations: 9
action 3, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 9090 episodes
GETTING ACTION FROM:
action 5, numVisits=13043, meanQ=11.055992, numObservations: 9
action 3, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=3, meanQ=-1.340000, numObservations: 3
action 0, numVisits=3, meanQ=-1.340000, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.470641 0.227118 0.79448 0.639458 0.620185 0.411821 0.16896 0.0635093 0.296023 0.543446 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=389, meanQ=12.132977, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 7962 episodes
GETTING ACTION FROM:
action 4, numVisits=8345, meanQ=12.715058, numObservations: 9
action -1, numVisits=5, meanQ=-1.208000, numObservations: 5
action 0, numVisits=5, meanQ=-1.406000, numObservations: 5
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 0 0.470641 0.227118 0.79448 0.639458 0.620185 0.411821 0.16896 0.0635093 0.296023 0.543446 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=538, meanQ=16.174735, numObservations: 9
action 3, numVisits=45, meanQ=-1.620763, numObservations: 9
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=28, meanQ=-21.204939, numObservations: 16
action 0, numVisits=20, meanQ=-25.297605, numObservations: 17
Sampled 9706 episodes
GETTING ACTION FROM:
action 2, numVisits=10244, meanQ=16.992877, numObservations: 9
action 3, numVisits=45, meanQ=-1.620763, numObservations: 9
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=28, meanQ=-21.204939, numObservations: 16
action 0, numVisits=20, meanQ=-25.297605, numObservations: 17
action: 2
Next state: 1 0.470641 0.227118 0.79448 0.639458 0.620185 0.411821 0.16896 0.0635093 0.296023 0.543446 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 11.4068
Run # 31
Initial state: 0 0.484639 0.540775 0.362548 0.794679 0.665502 0.254857 0.723572 0.703796 0.926374 0.401102 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28230 episodes
GETTING ACTION FROM:
action 3, numVisits=28202, meanQ=10.779592, numObservations: 9
action 2, numVisits=17, meanQ=9.043529, numObservations: 8
action 1, numVisits=7, meanQ=7.714314, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 2 0.484639 0.540775 0.362548 0.794679 0.665502 0.254857 0.723572 0.703796 0.926374 0.401102 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 32
Initial state: 0 0.171781 0.303829 0.714214 0.903161 0.511399 0.469828 0.648591 0.942305 0.947382 0.770601 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27369 episodes
GETTING ACTION FROM:
action 4, numVisits=27363, meanQ=10.501818, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.171781 0.303829 0.714214 0.903161 0.511399 0.469828 0.648591 0.942305 0.947382 0.770601 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 33
Initial state: 0 0.490831 0.538591 0.213761 0.495076 0.975309 0.131897 0.770552 0.799951 0.461037 0.36295 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28629 episodes
GETTING ACTION FROM:
action 1, numVisits=22399, meanQ=10.769420, numObservations: 9
action 2, numVisits=6210, meanQ=10.299004, numObservations: 9
action 3, numVisits=10, meanQ=7.999000, numObservations: 6
action 4, numVisits=7, meanQ=7.282857, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.490831 0.538591 0.213761 0.495076 0.975309 0.131897 0.770552 0.799951 0.461037 0.36295 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 34
Initial state: 0 0.650767 0.890318 0.590743 0.649488 0.315638 0.823751 0.388288 0.739946 0.518677 0.555842 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28591 episodes
GETTING ACTION FROM:
action 3, numVisits=28577, meanQ=10.689245, numObservations: 9
action 1, numVisits=9, meanQ=7.776667, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.650767 0.890318 0.590743 0.649488 0.315638 0.823751 0.388288 0.739946 0.518677 0.555842 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=3433, meanQ=11.673041, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 10717 episodes
GETTING ACTION FROM:
action 2, numVisits=14146, meanQ=12.849450, numObservations: 9
action -1, numVisits=3, meanQ=-1.340000, numObservations: 3
action 0, numVisits=3, meanQ=-1.340000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.650767 0.890318 0.590743 0.649488 0.315638 0.823751 0.388288 0.739946 0.518677 0.555842 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 35
Initial state: 0 0.831002 0.400655 0.577479 0.473917 0.0852524 0.330244 0.869227 0.390968 0.698931 0.157599 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28508 episodes
GETTING ACTION FROM:
action 4, numVisits=28387, meanQ=10.567339, numObservations: 9
action 0, numVisits=93, meanQ=-0.564394, numObservations: 68
action -1, numVisits=18, meanQ=-1.120550, numObservations: 17
action 3, numVisits=5, meanQ=-2.402000, numObservations: 3
action 5, numVisits=2, meanQ=-3.505000, numObservations: 2
action 1, numVisits=2, meanQ=-4.499950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.831002 0.400655 0.577479 0.473917 0.0852524 0.330244 0.869227 0.390968 0.698931 0.157599 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 36
Initial state: 0 0.681218 0.404114 0.55799 0.456251 0.130462 0.976448 0.0728941 0.176964 0.633286 0.210731 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28440 episodes
GETTING ACTION FROM:
action 3, numVisits=28434, meanQ=10.670051, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.681218 0.404114 0.55799 0.456251 0.130462 0.976448 0.0728941 0.176964 0.633286 0.210731 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=3296, meanQ=12.092883, numObservations: 9
action 5, numVisits=17, meanQ=8.939412, numObservations: 6
action 2, numVisits=5, meanQ=7.000020, numObservations: 4
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 10161 episodes
GETTING ACTION FROM:
action 4, numVisits=13348, meanQ=13.598437, numObservations: 9
action 2, numVisits=33, meanQ=8.124933, numObservations: 9
action 5, numVisits=94, meanQ=1.449305, numObservations: 9
action 1, numVisits=3, meanQ=0.666667, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 0 0.681218 0.404114 0.55799 0.456251 0.130462 0.976448 0.0728941 0.176964 0.633286 0.210731 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=1177, meanQ=12.985812, numObservations: 9
action 2, numVisits=14, meanQ=8.362864, numObservations: 6
action 3, numVisits=9, meanQ=8.112244, numObservations: 4
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 5134 episodes
GETTING ACTION FROM:
action 5, numVisits=6311, meanQ=14.298195, numObservations: 9
action 2, numVisits=14, meanQ=8.362864, numObservations: 6
action 3, numVisits=9, meanQ=8.112244, numObservations: 4
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.681218 0.404114 0.55799 0.456251 0.130462 0.976448 0.0728941 0.176964 0.633286 0.210731 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=8, meanQ=11.234095, numObservations: 6
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 5, numVisits=1, meanQ=-10.410100, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-539.448364, numObservations: 1
action 3, numVisits=1, meanQ=-1068.104131, numObservations: 1
Sampled 27403 episodes
GETTING ACTION FROM:
action 2, numVisits=27409, meanQ=17.762075, numObservations: 9
action -1, numVisits=3, meanQ=-1.340000, numObservations: 3
action 0, numVisits=3, meanQ=-1.340000, numObservations: 3
action 5, numVisits=1, meanQ=-10.410100, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-539.448364, numObservations: 1
action 3, numVisits=1, meanQ=-1068.104131, numObservations: 1
action: 2
Next state: 1 0.681218 0.404114 0.55799 0.456251 0.130462 0.976448 0.0728941 0.176964 0.633286 0.210731 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 11.4068
Run # 37
Initial state: 0 0.313395 0.284322 0.66849 0.834977 0.159073 0.520773 0.271011 0.222634 0.523275 0.513555 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28321 episodes
GETTING ACTION FROM:
action 3, numVisits=28263, meanQ=10.559978, numObservations: 9
action 4, numVisits=31, meanQ=6.774861, numObservations: 9
action 2, numVisits=23, meanQ=6.209565, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.313395 0.284322 0.66849 0.834977 0.159073 0.520773 0.271011 0.222634 0.523275 0.513555 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=983, meanQ=11.956830, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 7084 episodes
GETTING ACTION FROM:
action 4, numVisits=7926, meanQ=11.555120, numObservations: 9
action -1, numVisits=47, meanQ=-1.508875, numObservations: 38
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=73, meanQ=-14.911429, numObservations: 59
action 5, numVisits=26, meanQ=-29.002511, numObservations: 9
action: 4
Next state: 0 0.313395 0.284322 0.66849 0.834977 0.159073 0.520773 0.271011 0.222634 0.523275 0.513555 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=833, meanQ=11.958514, numObservations: 9
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action 1, numVisits=3, meanQ=-0.717645, numObservations: 3
action 0, numVisits=13, meanQ=-1.010000, numObservations: 13
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=5, meanQ=-209.256824, numObservations: 4
Sampled 5759 episodes
GETTING ACTION FROM:
action 2, numVisits=6553, meanQ=11.869870, numObservations: 9
action 3, numVisits=4, meanQ=6.500000, numObservations: 3
action 1, numVisits=3, meanQ=-0.717645, numObservations: 3
action 0, numVisits=17, meanQ=-1.068235, numObservations: 17
action 5, numVisits=34, meanQ=-2.660990, numObservations: 8
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=5, meanQ=-209.256824, numObservations: 4
action: 2
Next state: 1 0.313395 0.284322 0.66849 0.834977 0.159073 0.520773 0.271011 0.222634 0.523275 0.513555 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 38
Initial state: 0 0.522191 0.9219 0.724963 0.739155 0.476069 0.214164 0.506052 0.484026 0.430633 0.989737 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27887 episodes
GETTING ACTION FROM:
action 1, numVisits=27867, meanQ=10.576750, numObservations: 9
action 4, numVisits=15, meanQ=1.674673, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.522191 0.9219 0.724963 0.739155 0.476069 0.214164 0.506052 0.484026 0.430633 0.989737 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 39
Initial state: 0 0.013811 0.372344 0.313404 0.6056 0.913584 0.861806 0.936522 0.0546076 0.51904 0.538186 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27912 episodes
GETTING ACTION FROM:
action 5, numVisits=27882, meanQ=10.530807, numObservations: 9
action 4, numVisits=16, meanQ=6.499381, numObservations: 8
action 2, numVisits=8, meanQ=4.387500, numObservations: 5
action 1, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 1 0.013811 0.372344 0.313404 0.6056 0.913584 0.861806 0.936522 0.0546076 0.51904 0.538186 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 40
Initial state: 0 0.297441 0.959939 0.15929 0.867438 0.790168 0.429071 0.727059 0.844744 0.490771 0.452002 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28379 episodes
GETTING ACTION FROM:
action 1, numVisits=28362, meanQ=10.600168, numObservations: 9
action 4, numVisits=10, meanQ=5.397000, numObservations: 7
action 5, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.297441 0.959939 0.15929 0.867438 0.790168 0.429071 0.727059 0.844744 0.490771 0.452002 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=3450, meanQ=12.003614, numObservations: 9
action 0, numVisits=7, meanQ=-1.010000, numObservations: 7
action 5, numVisits=6, meanQ=-1.171667, numObservations: 5
action -1, numVisits=6, meanQ=-1.671650, numObservations: 5
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
action 1, numVisits=2, meanQ=-4.994950, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 9312 episodes
GETTING ACTION FROM:
action 3, numVisits=12762, meanQ=13.587967, numObservations: 9
action 0, numVisits=7, meanQ=-1.010000, numObservations: 7
action 5, numVisits=6, meanQ=-1.171667, numObservations: 5
action -1, numVisits=6, meanQ=-1.671650, numObservations: 5
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
action 1, numVisits=2, meanQ=-4.994950, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.297441 0.959939 0.15929 0.867438 0.790168 0.429071 0.727059 0.844744 0.490771 0.452002 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 41
Initial state: 0 0.919105 0.0587054 0.741193 0.874471 0.946978 0.57298 0.51948 0.453895 0.866243 0.769936 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27925 episodes
GETTING ACTION FROM:
action 5, numVisits=27906, meanQ=10.364209, numObservations: 9
action 3, numVisits=6, meanQ=3.000000, numObservations: 4
action 4, numVisits=9, meanQ=2.236678, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 1 0.919105 0.0587054 0.741193 0.874471 0.946978 0.57298 0.51948 0.453895 0.866243 0.769936 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 42
Initial state: 0 0.122046 0.219016 0.489656 0.409513 0.218393 0.949441 0.560145 0.941631 0.969884 0.226497 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28306 episodes
GETTING ACTION FROM:
action 3, numVisits=28295, meanQ=10.618847, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 2, numVisits=2, meanQ=-4.000000, numObservations: 2
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.122046 0.219016 0.489656 0.409513 0.218393 0.949441 0.560145 0.941631 0.969884 0.226497 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=3357, meanQ=11.521120, numObservations: 9
action 2, numVisits=15, meanQ=8.382013, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 10270 episodes
GETTING ACTION FROM:
action 4, numVisits=13621, meanQ=12.717565, numObservations: 9
action 2, numVisits=17, meanQ=6.101776, numObservations: 8
action -1, numVisits=3, meanQ=-1.340000, numObservations: 3
action 0, numVisits=3, meanQ=-1.670000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 1 0.122046 0.219016 0.489656 0.409513 0.218393 0.949441 0.560145 0.941631 0.969884 0.226497 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 43
Initial state: 0 0.950712 0.955912 0.46111 0.827095 0.526247 0.68029 0.550489 0.453906 0.130734 0.891404 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28126 episodes
GETTING ACTION FROM:
action 3, numVisits=28118, meanQ=10.813067, numObservations: 9
action 2, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.950712 0.955912 0.46111 0.827095 0.526247 0.68029 0.550489 0.453906 0.130734 0.891404 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 44
Initial state: 0 0.881839 0.0909815 0.10859 0.757087 0.822536 0.304684 0.841626 0.837942 0.585519 0.424701 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28110 episodes
GETTING ACTION FROM:
action 4, numVisits=28098, meanQ=10.403617, numObservations: 9
action 1, numVisits=5, meanQ=6.008040, numObservations: 3
action 5, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.881839 0.0909815 0.10859 0.757087 0.822536 0.304684 0.841626 0.837942 0.585519 0.424701 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 45
Initial state: 0 0.852471 0.583375 0.138656 0.837923 0.553309 0.487296 0.412684 0.334827 0.251848 0.337073 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28094 episodes
GETTING ACTION FROM:
action 5, numVisits=28065, meanQ=10.600203, numObservations: 9
action 2, numVisits=9, meanQ=7.444467, numObservations: 5
action 1, numVisits=16, meanQ=6.879381, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 0 0.852471 0.583375 0.138656 0.837923 0.553309 0.487296 0.412684 0.334827 0.251848 0.337073 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=3893, meanQ=11.710365, numObservations: 9
action 4, numVisits=5, meanQ=6.196000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 8819 episodes
GETTING ACTION FROM:
action 3, numVisits=12705, meanQ=11.353193, numObservations: 9
action 4, numVisits=8, meanQ=4.122500, numObservations: 7
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action -1, numVisits=3, meanQ=-1.670000, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.852471 0.583375 0.138656 0.837923 0.553309 0.487296 0.412684 0.334827 0.251848 0.337073 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 46
Initial state: 0 0.906928 0.866397 0.0535233 0.399216 0.134704 0.107817 0.242333 0.669008 0.584755 0.475206 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28338 episodes
GETTING ACTION FROM:
action 4, numVisits=28330, meanQ=10.557069, numObservations: 9
action 2, numVisits=3, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 0 0.906928 0.866397 0.0535233 0.399216 0.134704 0.107817 0.242333 0.669008 0.584755 0.475206 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=3309, meanQ=10.901949, numObservations: 9
action 4, numVisits=71, meanQ=7.742615, numObservations: 6
action 3, numVisits=7, meanQ=5.715729, numObservations: 5
action 5, numVisits=4, meanQ=3.742500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 10945 episodes
GETTING ACTION FROM:
action 1, numVisits=14248, meanQ=12.742401, numObservations: 9
action 4, numVisits=71, meanQ=7.742615, numObservations: 6
action 3, numVisits=7, meanQ=5.715729, numObservations: 5
action 5, numVisits=5, meanQ=0.794000, numObservations: 4
action -1, numVisits=4, meanQ=-1.257500, numObservations: 4
action 0, numVisits=3, meanQ=-1.340000, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.906928 0.866397 0.0535233 0.399216 0.134704 0.107817 0.242333 0.669008 0.584755 0.475206 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 47
Initial state: 0 0.23298 0.0649874 0.981018 0.157102 0.292114 0.38277 0.528726 0.550633 0.477537 0.294539 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28266 episodes
GETTING ACTION FROM:
action 4, numVisits=28254, meanQ=10.554738, numObservations: 9
action 5, numVisits=7, meanQ=7.282857, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.23298 0.0649874 0.981018 0.157102 0.292114 0.38277 0.528726 0.550633 0.477537 0.294539 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 48
Initial state: 0 0.00544452 0.862937 0.576002 0.215826 0.521633 0.459979 0.825366 0.777525 0.174705 0.382824 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28249 episodes
GETTING ACTION FROM:
action 1, numVisits=28224, meanQ=10.472297, numObservations: 9
action 2, numVisits=9, meanQ=8.106667, numObservations: 5
action 5, numVisits=10, meanQ=7.999000, numObservations: 7
action 4, numVisits=3, meanQ=5.663333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.00544452 0.862937 0.576002 0.215826 0.521633 0.459979 0.825366 0.777525 0.174705 0.382824 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=3931, meanQ=11.728967, numObservations: 9
action 5, numVisits=33, meanQ=10.408794, numObservations: 9
action 4, numVisits=6, meanQ=9.163333, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 10974 episodes
GETTING ACTION FROM:
action 2, numVisits=13633, meanQ=10.743987, numObservations: 9
action 5, numVisits=1296, meanQ=9.664542, numObservations: 9
action 4, numVisits=8, meanQ=4.997500, numObservations: 7
action 0, numVisits=5, meanQ=-1.010000, numObservations: 5
action -1, numVisits=4, meanQ=-1.257500, numObservations: 4
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.00544452 0.862937 0.576002 0.215826 0.521633 0.459979 0.825366 0.777525 0.174705 0.382824 w: 1
Observation: 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 49
Initial state: 0 0.27647 0.384601 0.198864 0.724042 0.570513 0.460358 0.446821 0.591179 0.672881 0.952669 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28172 episodes
GETTING ACTION FROM:
action 1, numVisits=28166, meanQ=10.467638, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.27647 0.384601 0.198864 0.724042 0.570513 0.460358 0.446821 0.591179 0.672881 0.952669 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=4014, meanQ=11.801648, numObservations: 9
action 5, numVisits=3, meanQ=3.330000, numObservations: 3
action 1, numVisits=3, meanQ=2.033333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 9694 episodes
GETTING ACTION FROM:
action 4, numVisits=13701, meanQ=10.959594, numObservations: 9
action 1, numVisits=3, meanQ=2.033333, numObservations: 2
action 5, numVisits=4, meanQ=-0.006066, numObservations: 4
action -1, numVisits=4, meanQ=-1.257500, numObservations: 4
action 0, numVisits=4, meanQ=-1.257500, numObservations: 4
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 1 0.27647 0.384601 0.198864 0.724042 0.570513 0.460358 0.446821 0.591179 0.672881 0.952669 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 50
Initial state: 0 0.0996052 0.993063 0.837029 0.925328 0.136492 0.785778 0.0690702 0.717996 0.612062 0.448225 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28121 episodes
GETTING ACTION FROM:
action 4, numVisits=28111, meanQ=10.406934, numObservations: 9
action 2, numVisits=5, meanQ=5.998000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 0 0.0996052 0.993063 0.837029 0.925328 0.136492 0.785778 0.0690702 0.717996 0.612062 0.448225 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=3425, meanQ=12.083158, numObservations: 9
action 3, numVisits=6, meanQ=9.163333, numObservations: 3
action 5, numVisits=5, meanQ=7.396020, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 11672 episodes
GETTING ACTION FROM:
action 2, numVisits=15053, meanQ=12.241172, numObservations: 9
action 3, numVisits=28, meanQ=9.057775, numObservations: 8
action 5, numVisits=24, meanQ=8.503307, numObservations: 8
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.0996052 0.993063 0.837029 0.925328 0.136492 0.785778 0.0690702 0.717996 0.612062 0.448225 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
[32m ProblemEnvironment.hpp 351: Done.[39m
