Run # 1
Initial state: 0 0.666155 0.260176 0.974155 0.918629 0.682714 0.756634 0.301877 0.269466 0.538944 0.468294 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30065 episodes
GETTING ACTION FROM:
action 4, numVisits=30050, meanQ=12.409013, numObservations: 9
action 2, numVisits=10, meanQ=8.600000, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.666155 0.260176 0.974155 0.918629 0.682714 0.756634 0.301877 0.269466 0.538944 0.468294 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=2793, meanQ=12.866553, numObservations: 9
action 3, numVisits=12, meanQ=9.163333, numObservations: 7
action 2, numVisits=8, meanQ=7.498750, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 9325 episodes
GETTING ACTION FROM:
action 1, numVisits=12112, meanQ=11.571640, numObservations: 9
action 3, numVisits=13, meanQ=7.661579, numObservations: 7
action 2, numVisits=9, meanQ=5.443333, numObservations: 6
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action -1, numVisits=3, meanQ=-1.340000, numObservations: 3
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.666155 0.260176 0.974155 0.918629 0.682714 0.756634 0.301877 0.269466 0.538944 0.468294 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 2
Initial state: 0 0.428587 0.520113 0.407351 0.173267 0.646189 0.0588373 0.715843 0.0305588 0.448013 0.400176 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30332 episodes
GETTING ACTION FROM:
action 4, numVisits=30320, meanQ=12.185788, numObservations: 9
action 2, numVisits=3, meanQ=5.333333, numObservations: 3
action 1, numVisits=5, meanQ=4.400000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.428587 0.520113 0.407351 0.173267 0.646189 0.0588373 0.715843 0.0305588 0.448013 0.400176 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 3
Initial state: 0 0.970892 0.505437 0.358288 0.680132 0.264839 0.933793 0.436054 0.406818 0.973576 0.160615 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17875 episodes
GETTING ACTION FROM:
action 0, numVisits=17858, meanQ=15.511149, numObservations: 243
action -1, numVisits=10, meanQ=-1.010000, numObservations: 10
action 1, numVisits=2, meanQ=-7.500000, numObservations: 2
action 3, numVisits=2, meanQ=-7.500000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.970892 0.505437 0.358288 0.680132 0.264839 0.933793 0.436054 0.406818 0.973576 0.160615 w: 1
Observation: 0 0 3 0 3 0 3 0 2 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=164, meanQ=18.039732, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 30115 episodes
GETTING ACTION FROM:
action 3, numVisits=30279, meanQ=17.806628, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.970892 0.505437 0.358288 0.680132 0.264839 0.933793 0.436054 0.406818 0.973576 0.160615 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=7648, meanQ=18.522472, numObservations: 9
action 3, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 26394 episodes
GETTING ACTION FROM:
action 4, numVisits=26385, meanQ=22.828981, numObservations: 9
action 2, numVisits=7651, meanQ=18.523952, numObservations: 9
action 3, numVisits=3, meanQ=5.663333, numObservations: 2
action -1, numVisits=4, meanQ=-1.505000, numObservations: 4
action 0, numVisits=4, meanQ=-1.505000, numObservations: 4
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.970892 0.505437 0.358288 0.680132 0.264839 0.933793 0.436054 0.406818 0.973576 0.160615 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 17.5624
Run # 4
Initial state: 0 0.752594 0.048453 0.223479 0.804504 0.0649343 0.610631 0.163562 0.641368 0.474288 0.444936 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29203 episodes
GETTING ACTION FROM:
action 2, numVisits=29178, meanQ=12.322925, numObservations: 9
action 0, numVisits=19, meanQ=-1.218942, numObservations: 18
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.752594 0.048453 0.223479 0.804504 0.0649343 0.610631 0.163562 0.641368 0.474288 0.444936 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 5
Initial state: 0 0.457345 0.603953 0.86784 0.696028 0.904559 0.859732 0.22346 0.441406 0.492467 0.369637 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30374 episodes
GETTING ACTION FROM:
action 5, numVisits=30366, meanQ=12.380928, numObservations: 9
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 1 0.457345 0.603953 0.86784 0.696028 0.904559 0.859732 0.22346 0.441406 0.492467 0.369637 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 6
Initial state: 0 0.494838 0.751301 0.481064 0.415048 0.727419 0.303848 0.729431 0.775357 0.00279484 0.638536 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29412 episodes
GETTING ACTION FROM:
action 2, numVisits=29395, meanQ=12.414504, numObservations: 9
action 5, numVisits=12, meanQ=6.669183, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.494838 0.751301 0.481064 0.415048 0.727419 0.303848 0.729431 0.775357 0.00279484 0.638536 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 7
Initial state: 0 0.454175 0.45268 0.826108 0.739158 0.587735 0.969431 0.90449 0.11237 0.0410087 0.776152 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30523 episodes
GETTING ACTION FROM:
action 4, numVisits=30515, meanQ=12.260451, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.454175 0.45268 0.826108 0.739158 0.587735 0.969431 0.90449 0.11237 0.0410087 0.776152 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 8
Initial state: 0 0.479739 0.485206 0.136152 0.483106 0.503864 0.74482 0.363347 0.234721 0.790389 0.124881 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30690 episodes
GETTING ACTION FROM:
action 1, numVisits=30682, meanQ=12.403703, numObservations: 9
action 5, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.479739 0.485206 0.136152 0.483106 0.503864 0.74482 0.363347 0.234721 0.790389 0.124881 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 9
Initial state: 0 0.525841 0.160795 0.987267 0.847915 0.451289 0.47902 0.666614 0.60561 0.302135 0.454251 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30327 episodes
GETTING ACTION FROM:
action 1, numVisits=30321, meanQ=12.278008, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.525841 0.160795 0.987267 0.847915 0.451289 0.47902 0.666614 0.60561 0.302135 0.454251 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=307, meanQ=2.770091, numObservations: 149
action 0, numVisits=32, meanQ=-0.917806, numObservations: 28
action 5, numVisits=2, meanQ=-3.010000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 6814 episodes
GETTING ACTION FROM:
action -1, numVisits=7100, meanQ=1.529671, numObservations: 242
action 5, numVisits=8, meanQ=-4.607188, numObservations: 5
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=47, meanQ=-23.604147, numObservations: 37
action: -1
Next state: 0 0.525841 0.160795 0.987267 0.847915 0.451289 0.47902 0.666614 0.60561 0.302135 0.454251 w: 1
Observation: 0 2 0 3 0 2 0 3 0 1 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=42, meanQ=18.144330, numObservations: 5
action 2, numVisits=3, meanQ=12.333333, numObservations: 2
action 3, numVisits=3, meanQ=11.948080, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 48239 episodes
GETTING ACTION FROM:
action 4, numVisits=48278, meanQ=17.290832, numObservations: 9
action 3, numVisits=5, meanQ=9.768848, numObservations: 4
action 2, numVisits=4, meanQ=6.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.525841 0.160795 0.987267 0.847915 0.451289 0.47902 0.666614 0.60561 0.302135 0.454251 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 17.5424
Run # 10
Initial state: 0 0.930024 0.740316 0.528128 0.334408 0.576244 0.0287953 0.57015 0.111933 0.893103 0.330287 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29212 episodes
GETTING ACTION FROM:
action 2, numVisits=29202, meanQ=11.965623, numObservations: 9
action 3, numVisits=3, meanQ=5.333333, numObservations: 2
action 4, numVisits=3, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.930024 0.740316 0.528128 0.334408 0.576244 0.0287953 0.57015 0.111933 0.893103 0.330287 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 11
Initial state: 0 0.189582 0.773025 0.0517941 0.288115 0.931185 0.778165 0.349007 0.360435 0.460863 0.357782 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30707 episodes
GETTING ACTION FROM:
action 2, numVisits=30621, meanQ=12.174192, numObservations: 9
action 3, numVisits=81, meanQ=11.162849, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.189582 0.773025 0.0517941 0.288115 0.931185 0.778165 0.349007 0.360435 0.460863 0.357782 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=3674, meanQ=13.218694, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 12008 episodes
GETTING ACTION FROM:
action 3, numVisits=15680, meanQ=14.511591, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.189582 0.773025 0.0517941 0.288115 0.931185 0.778165 0.349007 0.360435 0.460863 0.357782 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 12
Initial state: 0 0.92594 0.93028 0.50207 0.393481 0.485794 0.960303 0.171183 0.993209 0.977615 0.883655 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30538 episodes
GETTING ACTION FROM:
action 1, numVisits=30501, meanQ=12.340070, numObservations: 9
action 4, numVisits=30, meanQ=7.869333, numObservations: 7
action 5, numVisits=3, meanQ=5.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.92594 0.93028 0.50207 0.393481 0.485794 0.960303 0.171183 0.993209 0.977615 0.883655 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 13
Initial state: 0 0.338788 0.586973 0.366937 0.223373 0.508044 0.50274 0.431398 0.48172 0.973822 0.262839 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30593 episodes
GETTING ACTION FROM:
action 2, numVisits=30562, meanQ=12.258219, numObservations: 9
action 4, numVisits=23, meanQ=10.076961, numObservations: 8
action 1, numVisits=4, meanQ=8.497500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.338788 0.586973 0.366937 0.223373 0.508044 0.50274 0.431398 0.48172 0.973822 0.262839 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=2957, meanQ=13.581348, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 7407 episodes
GETTING ACTION FROM:
action 3, numVisits=10358, meanQ=11.818036, numObservations: 9
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.338788 0.586973 0.366937 0.223373 0.508044 0.50274 0.431398 0.48172 0.973822 0.262839 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 14
Initial state: 0 0.477026 0.437186 0.119996 0.435824 0.882887 0.55265 0.420515 0.046321 0.487759 0.911618 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30261 episodes
GETTING ACTION FROM:
action 2, numVisits=30231, meanQ=12.470440, numObservations: 9
action 1, numVisits=15, meanQ=5.517333, numObservations: 6
action 5, numVisits=11, meanQ=4.632727, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.477026 0.437186 0.119996 0.435824 0.882887 0.55265 0.420515 0.046321 0.487759 0.911618 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 15
Initial state: 0 0.902746 0.384576 0.0266407 0.0711494 0.479085 0.47011 0.44645 0.23839 0.814136 0.920571 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30415 episodes
GETTING ACTION FROM:
action 2, numVisits=30407, meanQ=11.925931, numObservations: 9
action 4, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.902746 0.384576 0.0266407 0.0711494 0.479085 0.47011 0.44645 0.23839 0.814136 0.920571 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=2903, meanQ=12.638856, numObservations: 9
action 1, numVisits=4, meanQ=8.497500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 8598 episodes
GETTING ACTION FROM:
action 3, numVisits=11450, meanQ=11.864121, numObservations: 9
action 1, numVisits=51, meanQ=9.121828, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.902746 0.384576 0.0266407 0.0711494 0.479085 0.47011 0.44645 0.23839 0.814136 0.920571 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 16
Initial state: 0 0.927874 0.315921 0.581825 0.663089 0.655061 0.418271 0.520808 0.392552 0.362277 0.465317 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30592 episodes
GETTING ACTION FROM:
action 3, numVisits=30585, meanQ=12.277219, numObservations: 9
action 4, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.927874 0.315921 0.581825 0.663089 0.655061 0.418271 0.520808 0.392552 0.362277 0.465317 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 17
Initial state: 0 0.655484 0.654292 0.146588 0.759996 0.1279 0.0305635 0.0784318 0.233853 0.528844 0.382729 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29295 episodes
GETTING ACTION FROM:
action 4, numVisits=29288, meanQ=12.535737, numObservations: 9
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.655484 0.654292 0.146588 0.759996 0.1279 0.0305635 0.0784318 0.233853 0.528844 0.382729 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=2851, meanQ=13.375958, numObservations: 9
action 2, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 8342 episodes
GETTING ACTION FROM:
action 3, numVisits=11188, meanQ=12.416526, numObservations: 9
action 2, numVisits=4, meanQ=3.245025, numObservations: 3
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.655484 0.654292 0.146588 0.759996 0.1279 0.0305635 0.0784318 0.233853 0.528844 0.382729 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=907, meanQ=10.045450, numObservations: 9
action 2, numVisits=16, meanQ=7.458042, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=42, meanQ=-8.670701, numObservations: 8
Sampled 6659 episodes
GETTING ACTION FROM:
action 5, numVisits=7561, meanQ=9.792736, numObservations: 9
action 2, numVisits=19, meanQ=6.701514, numObservations: 9
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=42, meanQ=-8.670701, numObservations: 8
action: 5
Next state: 1 0.655484 0.654292 0.146588 0.759996 0.1279 0.0305635 0.0784318 0.233853 0.528844 0.382729 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 18
Initial state: 0 0.724726 0.296958 0.0674166 0.170281 0.0554431 0.705938 0.0575524 0.561073 0.491648 0.494423 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30280 episodes
GETTING ACTION FROM:
action 4, numVisits=30267, meanQ=12.351337, numObservations: 9
action 3, numVisits=8, meanQ=5.500013, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.724726 0.296958 0.0674166 0.170281 0.0554431 0.705938 0.0575524 0.561073 0.491648 0.494423 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=488, meanQ=20.406731, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 18844 episodes
GETTING ACTION FROM:
action 4, numVisits=595, meanQ=20.781831, numObservations: 9
action 0, numVisits=18109, meanQ=0.223622, numObservations: 241
action -1, numVisits=630, meanQ=-3.396591, numObservations: 148
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.724726 0.296958 0.0674166 0.170281 0.0554431 0.705938 0.0575524 0.561073 0.491648 0.494423 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=2, meanQ=6.772237, numObservations: 1
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 16817 episodes
GETTING ACTION FROM:
action 1, numVisits=16461, meanQ=14.341554, numObservations: 9
action 3, numVisits=4, meanQ=6.796668, numObservations: 2
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=45, meanQ=-3.529870, numObservations: 8
action 0, numVisits=295, meanQ=-3.661733, numObservations: 103
action -1, numVisits=11, meanQ=-79.010872, numObservations: 7
action 5, numVisits=9, meanQ=-113.116194, numObservations: 6
action: 1
Next state: 2 0.724726 0.296958 0.0674166 0.170281 0.0554431 0.705938 0.0575524 0.561073 0.491648 0.494423 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -18.7411
Run # 19
Initial state: 0 0.0533125 0.231259 0.430893 0.419571 0.920008 0.735158 0.546996 0.909287 0.967188 0.289985 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30318 episodes
GETTING ACTION FROM:
action 3, numVisits=30310, meanQ=12.168075, numObservations: 9
action 5, numVisits=3, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.0533125 0.231259 0.430893 0.419571 0.920008 0.735158 0.546996 0.909287 0.967188 0.289985 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 20
Initial state: 0 0.624418 0.411972 0.994595 0.730451 0.548068 0.40024 0.626431 0.79387 0.71159 0.179619 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30542 episodes
GETTING ACTION FROM:
action 4, numVisits=30536, meanQ=12.352711, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.624418 0.411972 0.994595 0.730451 0.548068 0.40024 0.626431 0.79387 0.71159 0.179619 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 21
Initial state: 0 0.531414 0.0345937 0.457421 0.328797 0.700665 0.660027 0.833553 0.0516903 0.292281 0.457837 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30569 episodes
GETTING ACTION FROM:
action 2, numVisits=30548, meanQ=12.140443, numObservations: 9
action 4, numVisits=9, meanQ=7.554467, numObservations: 6
action 1, numVisits=6, meanQ=6.500000, numObservations: 4
action 3, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.531414 0.0345937 0.457421 0.328797 0.700665 0.660027 0.833553 0.0516903 0.292281 0.457837 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=1052, meanQ=11.802948, numObservations: 9
action 3, numVisits=22, meanQ=7.322277, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 11095 episodes
GETTING ACTION FROM:
action 4, numVisits=12138, meanQ=12.814545, numObservations: 9
action 3, numVisits=22, meanQ=7.322277, numObservations: 8
action -1, numVisits=6, meanQ=-1.175000, numObservations: 6
action 0, numVisits=5, meanQ=-1.208000, numObservations: 5
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.531414 0.0345937 0.457421 0.328797 0.700665 0.660027 0.833553 0.0516903 0.292281 0.457837 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 22
Initial state: 0 0.481562 0.485428 0.814348 0.5928 0.1296 0.196209 0.0772205 0.799738 0.238392 0.704334 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30412 episodes
GETTING ACTION FROM:
action 5, numVisits=30402, meanQ=12.278754, numObservations: 9
action 2, numVisits=3, meanQ=5.663333, numObservations: 3
action 4, numVisits=3, meanQ=5.663333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.481562 0.485428 0.814348 0.5928 0.1296 0.196209 0.0772205 0.799738 0.238392 0.704334 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=3738, meanQ=13.636296, numObservations: 9
action 4, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 8962 episodes
GETTING ACTION FROM:
action 2, numVisits=12690, meanQ=14.600245, numObservations: 9
action 4, numVisits=11, meanQ=6.646995, numObservations: 6
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.481562 0.485428 0.814348 0.5928 0.1296 0.196209 0.0772205 0.799738 0.238392 0.704334 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 23
Initial state: 0 0.455416 0.392123 0.146312 0.37143 0.612693 0.144777 0.8115 0.531442 0.0924391 0.140568 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30498 episodes
GETTING ACTION FROM:
action 3, numVisits=30489, meanQ=12.343514, numObservations: 9
action 1, numVisits=4, meanQ=3.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.455416 0.392123 0.146312 0.37143 0.612693 0.144777 0.8115 0.531442 0.0924391 0.140568 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 24
Initial state: 0 0.691795 0.662439 0.361118 0.134006 0.42876 0.470148 0.331598 0.950245 0.205051 0.126014 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30063 episodes
GETTING ACTION FROM:
action 3, numVisits=30053, meanQ=12.209017, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.691795 0.662439 0.361118 0.134006 0.42876 0.470148 0.331598 0.950245 0.205051 0.126014 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 25
Initial state: 0 0.300954 0.0531941 0.376768 0.401002 0.524527 0.370921 0.831533 0.268875 0.568005 0.624856 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30153 episodes
GETTING ACTION FROM:
action 1, numVisits=30144, meanQ=12.109122, numObservations: 9
action 4, numVisits=4, meanQ=1.250000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.300954 0.0531941 0.376768 0.401002 0.524527 0.370921 0.831533 0.268875 0.568005 0.624856 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=2941, meanQ=12.258418, numObservations: 9
action 2, numVisits=7, meanQ=5.998586, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 7786 episodes
GETTING ACTION FROM:
action 4, numVisits=10720, meanQ=10.939822, numObservations: 9
action 2, numVisits=8, meanQ=4.042832, numObservations: 6
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.257500, numObservations: 4
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 2 0.300954 0.0531941 0.376768 0.401002 0.524527 0.370921 0.831533 0.268875 0.568005 0.624856 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 26
Initial state: 0 0.12901 0.221701 0.00317008 0.511905 0.363104 0.0977791 0.115643 0.902141 0.466042 0.3422 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28283 episodes
GETTING ACTION FROM:
action 3, numVisits=28274, meanQ=12.231323, numObservations: 9
action 4, numVisits=4, meanQ=3.247500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.12901 0.221701 0.00317008 0.511905 0.363104 0.0977791 0.115643 0.902141 0.466042 0.3422 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=2670, meanQ=13.106171, numObservations: 9
action 5, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 9652 episodes
GETTING ACTION FROM:
action 1, numVisits=12317, meanQ=12.026352, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=5, meanQ=-204.471364, numObservations: 3
action: 1
Next state: 0 0.12901 0.221701 0.00317008 0.511905 0.363104 0.0977791 0.115643 0.902141 0.466042 0.3422 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=964, meanQ=13.401951, numObservations: 9
action 5, numVisits=4, meanQ=-0.252500, numObservations: 3
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 5513 episodes
GETTING ACTION FROM:
action 2, numVisits=6477, meanQ=14.524339, numObservations: 9
action 5, numVisits=4, meanQ=-0.252500, numObservations: 3
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.12901 0.221701 0.00317008 0.511905 0.363104 0.0977791 0.115643 0.902141 0.466042 0.3422 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 5, numVisits=429, meanQ=14.840633, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.341650, numObservations: 5
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
action 3, numVisits=2, meanQ=-3.010000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 20785 episodes
GETTING ACTION FROM:
action 5, numVisits=21214, meanQ=16.541861, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.341650, numObservations: 5
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
action 3, numVisits=2, meanQ=-3.010000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.12901 0.221701 0.00317008 0.511905 0.363104 0.0977791 0.115643 0.902141 0.466042 0.3422 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 11.4068
Run # 27
Initial state: 0 0.207087 0.495536 0.492566 0.380852 0.0732394 0.879028 0.12504 0.788284 0.0751021 0.0211717 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29423 episodes
GETTING ACTION FROM:
action 3, numVisits=29417, meanQ=12.536671, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.207087 0.495536 0.492566 0.380852 0.0732394 0.879028 0.12504 0.788284 0.0751021 0.0211717 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=3561, meanQ=13.708268, numObservations: 9
action 2, numVisits=35, meanQ=11.712577, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 11808 episodes
GETTING ACTION FROM:
action 2, numVisits=11837, meanQ=14.628570, numObservations: 9
action 3, numVisits=3563, meanQ=13.710102, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.670000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.207087 0.495536 0.492566 0.380852 0.0732394 0.879028 0.12504 0.788284 0.0751021 0.0211717 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 28
Initial state: 0 0.538765 0.32589 0.57503 0.467553 0.052996 0.817594 0.30328 0.282663 0.952945 0.61305 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30493 episodes
GETTING ACTION FROM:
action 5, numVisits=30475, meanQ=12.316294, numObservations: 9
action 3, numVisits=8, meanQ=9.125000, numObservations: 6
action 1, numVisits=4, meanQ=6.500000, numObservations: 2
action 2, numVisits=3, meanQ=5.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 1 0.538765 0.32589 0.57503 0.467553 0.052996 0.817594 0.30328 0.282663 0.952945 0.61305 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 29
Initial state: 0 0.271742 0.431624 0.526356 0.338187 0.212125 0.152999 0.962253 0.634169 0.012152 0.145101 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30500 episodes
GETTING ACTION FROM:
action 5, numVisits=30491, meanQ=12.356556, numObservations: 9
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action 2, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 0 0.271742 0.431624 0.526356 0.338187 0.212125 0.152999 0.962253 0.634169 0.012152 0.145101 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=2893, meanQ=12.973910, numObservations: 9
action 1, numVisits=7, meanQ=8.281443, numObservations: 4
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action 4, numVisits=4, meanQ=6.500000, numObservations: 4
action 5, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 8515 episodes
GETTING ACTION FROM:
action 2, numVisits=11377, meanQ=11.712054, numObservations: 9
action 1, numVisits=20, meanQ=8.327148, numObservations: 6
action 3, numVisits=15, meanQ=6.497367, numObservations: 9
action 5, numVisits=3, meanQ=5.993333, numObservations: 2
action 4, numVisits=5, meanQ=3.245365, numObservations: 4
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.340000, numObservations: 3
action: 2
Next state: 1 0.271742 0.431624 0.526356 0.338187 0.212125 0.152999 0.962253 0.634169 0.012152 0.145101 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 30
Initial state: 0 0.576236 0.0668209 0.626683 0.773593 0.479465 0.381242 0.0178032 0.922875 0.857431 0.00773754 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28578 episodes
GETTING ACTION FROM:
action 3, numVisits=28570, meanQ=12.287808, numObservations: 9
action 4, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.576236 0.0668209 0.626683 0.773593 0.479465 0.381242 0.0178032 0.922875 0.857431 0.00773754 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 31
Initial state: 0 0.967388 0.209552 0.585691 0.119045 0.895951 0.657853 0.972848 0.145506 0.501439 0.465672 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29210 episodes
GETTING ACTION FROM:
action 3, numVisits=28940, meanQ=12.281953, numObservations: 9
action 4, numVisits=262, meanQ=11.804922, numObservations: 9
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action 5, numVisits=3, meanQ=4.340033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.967388 0.209552 0.585691 0.119045 0.895951 0.657853 0.972848 0.145506 0.501439 0.465672 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 32
Initial state: 0 0.407057 0.488353 0.857472 0.639211 0.310016 0.626939 0.441024 0.347314 0.79226 0.621573 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30518 episodes
GETTING ACTION FROM:
action 4, numVisits=30262, meanQ=12.319709, numObservations: 9
action 5, numVisits=236, meanQ=11.916350, numObservations: 9
action 1, numVisits=9, meanQ=9.197789, numObservations: 5
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action 2, numVisits=7, meanQ=6.442871, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 4
Next state: 1 0.407057 0.488353 0.857472 0.639211 0.310016 0.626939 0.441024 0.347314 0.79226 0.621573 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 33
Initial state: 0 0.438687 0.916468 0.100723 0.097354 0.520589 0.322133 0.651808 0.999934 0.801955 0.609716 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30345 episodes
GETTING ACTION FROM:
action 3, numVisits=30318, meanQ=12.450230, numObservations: 9
action 1, numVisits=20, meanQ=10.063505, numObservations: 6
action 5, numVisits=3, meanQ=5.663333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.438687 0.916468 0.100723 0.097354 0.520589 0.322133 0.651808 0.999934 0.801955 0.609716 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 34
Initial state: 0 0.60152 0.811062 0.0345111 0.0815019 0.553174 0.536388 0.371712 0.576247 0.534486 0.44456 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30343 episodes
GETTING ACTION FROM:
action 1, numVisits=30327, meanQ=12.477498, numObservations: 9
action 2, numVisits=7, meanQ=0.000000, numObservations: 5
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.60152 0.811062 0.0345111 0.0815019 0.553174 0.536388 0.371712 0.576247 0.534486 0.44456 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 35
Initial state: 0 0.853816 0.921338 0.961866 0.68667 0.924627 0.964484 0.166365 0.294083 0.54382 0.478587 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30450 episodes
GETTING ACTION FROM:
action 3, numVisits=30439, meanQ=12.389994, numObservations: 9
action 4, numVisits=6, meanQ=8.998333, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.853816 0.921338 0.961866 0.68667 0.924627 0.964484 0.166365 0.294083 0.54382 0.478587 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 36
Initial state: 0 0.979162 0.0308339 0.524373 0.47514 0.963869 0.538047 0.765925 0.0189043 0.158495 0.199813 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30501 episodes
GETTING ACTION FROM:
action 5, numVisits=30489, meanQ=12.189422, numObservations: 9
action 3, numVisits=7, meanQ=5.857157, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.979162 0.0308339 0.524373 0.47514 0.963869 0.538047 0.765925 0.0189043 0.158495 0.199813 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=2794, meanQ=12.386016, numObservations: 9
action 1, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 11170 episodes
GETTING ACTION FROM:
action 2, numVisits=2795, meanQ=12.384698, numObservations: 9
action 3, numVisits=11018, meanQ=12.290022, numObservations: 9
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=4, meanQ=-6.515818, numObservations: 3
action -1, numVisits=67, meanQ=-15.326062, numObservations: 50
action 0, numVisits=53, meanQ=-17.262451, numObservations: 43
action 1, numVisits=34, meanQ=-23.494361, numObservations: 9
action: 2
Next state: 0 0.979162 0.0308339 0.524373 0.47514 0.963869 0.538047 0.765925 0.0189043 0.158495 0.199813 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=43, meanQ=20.583023, numObservations: 7
action 4, numVisits=3, meanQ=12.333333, numObservations: 3
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 29085 episodes
GETTING ACTION FROM:
action 2, numVisits=217, meanQ=21.853364, numObservations: 9
action 1, numVisits=28900, meanQ=13.533657, numObservations: 9
action 4, numVisits=14, meanQ=6.500000, numObservations: 6
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.979162 0.0308339 0.524373 0.47514 0.963869 0.538047 0.765925 0.0189043 0.158495 0.199813 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 37
Initial state: 0 0.819493 0.844423 0.455252 0.383695 0.121481 0.203201 0.797458 0.683129 0.677499 0.800056 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30332 episodes
GETTING ACTION FROM:
action 1, numVisits=30323, meanQ=12.154605, numObservations: 9
action 5, numVisits=4, meanQ=7.277500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.819493 0.844423 0.455252 0.383695 0.121481 0.203201 0.797458 0.683129 0.677499 0.800056 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 38
Initial state: 0 0.783923 0.383962 0.688422 0.106758 0.0817055 0.422058 0.523329 0.32519 0.0844501 0.591062 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28495 episodes
GETTING ACTION FROM:
action 3, numVisits=28469, meanQ=12.086321, numObservations: 9
action 1, numVisits=15, meanQ=9.207340, numObservations: 7
action 5, numVisits=5, meanQ=3.820000, numObservations: 4
action 2, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.783923 0.383962 0.688422 0.106758 0.0817055 0.422058 0.523329 0.32519 0.0844501 0.591062 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=935, meanQ=12.557397, numObservations: 9
action 1, numVisits=11, meanQ=9.543636, numObservations: 6
action 5, numVisits=6, meanQ=9.163333, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 11053 episodes
GETTING ACTION FROM:
action 4, numVisits=11966, meanQ=11.218314, numObservations: 9
action 1, numVisits=16, meanQ=7.520227, numObservations: 8
action 5, numVisits=7, meanQ=6.282857, numObservations: 5
action -1, numVisits=10, meanQ=-1.307000, numObservations: 10
action 0, numVisits=8, meanQ=-1.505000, numObservations: 8
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.783923 0.383962 0.688422 0.106758 0.0817055 0.422058 0.523329 0.32519 0.0844501 0.591062 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 39
Initial state: 0 0.721811 0.254151 0.524275 0.394536 0.120251 0.67782 0.567867 0.391127 0.372091 0.848677 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30435 episodes
GETTING ACTION FROM:
action 1, numVisits=30424, meanQ=12.344111, numObservations: 9
action 2, numVisits=6, meanQ=6.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.721811 0.254151 0.524275 0.394536 0.120251 0.67782 0.567867 0.391127 0.372091 0.848677 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 40
Initial state: 0 0.563026 0.97393 0.646019 0.880258 0.407142 0.758448 0.307854 0.103896 0.449785 0.395237 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30097 episodes
GETTING ACTION FROM:
action 4, numVisits=30075, meanQ=12.276440, numObservations: 9
action 2, numVisits=17, meanQ=7.912353, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 0 0.563026 0.97393 0.646019 0.880258 0.407142 0.758448 0.307854 0.103896 0.449785 0.395237 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=2813, meanQ=12.956902, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 9369 episodes
GETTING ACTION FROM:
action 5, numVisits=10757, meanQ=12.768054, numObservations: 9
action 2, numVisits=1418, meanQ=11.008985, numObservations: 9
action 0, numVisits=5, meanQ=-1.208000, numObservations: 5
action -1, numVisits=5, meanQ=-1.208000, numObservations: 5
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.563026 0.97393 0.646019 0.880258 0.407142 0.758448 0.307854 0.103896 0.449785 0.395237 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 41
Initial state: 0 0.651775 0.616412 0.958137 0.950422 0.451883 0.456556 0.345414 0.183965 0.495839 0.690652 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30471 episodes
GETTING ACTION FROM:
action 3, numVisits=30455, meanQ=12.113103, numObservations: 9
action 1, numVisits=5, meanQ=7.200000, numObservations: 4
action 2, numVisits=7, meanQ=7.000000, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.651775 0.616412 0.958137 0.950422 0.451883 0.456556 0.345414 0.183965 0.495839 0.690652 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 42
Initial state: 0 0.335814 0.359006 0.943199 0.800815 0.466542 0.36911 0.773744 0.82253 0.706271 0.642009 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30598 episodes
GETTING ACTION FROM:
action 1, numVisits=30589, meanQ=11.978196, numObservations: 9
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action 4, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.335814 0.359006 0.943199 0.800815 0.466542 0.36911 0.773744 0.82253 0.706271 0.642009 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1020, meanQ=11.854844, numObservations: 9
action 3, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 11273 episodes
GETTING ACTION FROM:
action 2, numVisits=12279, meanQ=12.262696, numObservations: 9
action 3, numVisits=3, meanQ=0.666667, numObservations: 2
action 0, numVisits=8, meanQ=-1.133750, numObservations: 8
action -1, numVisits=8, meanQ=-1.133750, numObservations: 8
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.335814 0.359006 0.943199 0.800815 0.466542 0.36911 0.773744 0.82253 0.706271 0.642009 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 43
Initial state: 0 0.0918119 0.717546 0.623642 0.82026 0.697179 0.834251 0.250777 0.676753 0.516744 0.415414 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29198 episodes
GETTING ACTION FROM:
action 2, numVisits=29188, meanQ=12.291697, numObservations: 9
action 3, numVisits=3, meanQ=5.663333, numObservations: 3
action 5, numVisits=3, meanQ=5.663333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.0918119 0.717546 0.623642 0.82026 0.697179 0.834251 0.250777 0.676753 0.516744 0.415414 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 44
Initial state: 0 0.0114375 0.736997 0.916366 0.901495 0.159018 0.636783 0.151706 0.94903 0.550019 0.318302 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30471 episodes
GETTING ACTION FROM:
action 4, numVisits=30442, meanQ=12.414960, numObservations: 9
action 5, numVisits=24, meanQ=7.415838, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.0114375 0.736997 0.916366 0.901495 0.159018 0.636783 0.151706 0.94903 0.550019 0.318302 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=3750, meanQ=13.394227, numObservations: 9
action 5, numVisits=13, meanQ=10.151546, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 11788 episodes
GETTING ACTION FROM:
action 3, numVisits=15517, meanQ=14.891985, numObservations: 9
action 5, numVisits=32, meanQ=8.616002, numObservations: 8
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.0114375 0.736997 0.916366 0.901495 0.159018 0.636783 0.151706 0.94903 0.550019 0.318302 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=1269, meanQ=14.342729, numObservations: 9
action 1, numVisits=7, meanQ=7.424286, numObservations: 7
action 5, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 11978 episodes
GETTING ACTION FROM:
action 2, numVisits=13247, meanQ=16.542009, numObservations: 9
action 1, numVisits=7, meanQ=7.424286, numObservations: 7
action 5, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.0114375 0.736997 0.916366 0.901495 0.159018 0.636783 0.151706 0.94903 0.550019 0.318302 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 45
Initial state: 0 0.535972 0.67354 0.435461 0.437832 0.264022 0.946455 0.889042 0.105578 0.575251 0.661315 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30224 episodes
GETTING ACTION FROM:
action 1, numVisits=30205, meanQ=12.122466, numObservations: 9
action 3, numVisits=12, meanQ=8.750008, numObservations: 5
action 2, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.535972 0.67354 0.435461 0.437832 0.264022 0.946455 0.889042 0.105578 0.575251 0.661315 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 46
Initial state: 0 0.876068 0.677725 0.529161 0.441782 0.0549867 0.486445 0.674893 0.48547 0.795742 0.682832 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30201 episodes
GETTING ACTION FROM:
action 2, numVisits=30185, meanQ=12.298477, numObservations: 9
action 3, numVisits=9, meanQ=9.222222, numObservations: 5
action 5, numVisits=3, meanQ=5.663333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.876068 0.677725 0.529161 0.441782 0.0549867 0.486445 0.674893 0.48547 0.795742 0.682832 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 47
Initial state: 0 0.23602 0.642576 0.530512 0.388526 0.746031 0.842547 0.0809656 0.565274 0.925508 0.640366 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28935 episodes
GETTING ACTION FROM:
action 3, numVisits=28929, meanQ=11.946290, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.23602 0.642576 0.530512 0.388526 0.746031 0.842547 0.0809656 0.565274 0.925508 0.640366 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 48
Initial state: 0 0.850746 0.210771 0.998512 0.199371 0.202182 0.225639 0.480675 0.46072 0.149923 0.890164 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30237 episodes
GETTING ACTION FROM:
action 1, numVisits=30170, meanQ=12.166070, numObservations: 9
action 3, numVisits=60, meanQ=10.116008, numObservations: 9
action 4, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.850746 0.210771 0.998512 0.199371 0.202182 0.225639 0.480675 0.46072 0.149923 0.890164 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 49
Initial state: 0 0.894117 0.555431 0.433764 0.476914 0.500808 0.0927089 0.416309 0.607472 0.37007 0.364804 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30524 episodes
GETTING ACTION FROM:
action 1, numVisits=30516, meanQ=12.178988, numObservations: 9
action 2, numVisits=3, meanQ=5.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.894117 0.555431 0.433764 0.476914 0.500808 0.0927089 0.416309 0.607472 0.37007 0.364804 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 50
Initial state: 0 0.00502824 0.273915 0.135848 0.511931 0.116192 0.195889 0.219012 0.102112 0.535294 0.338342 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30369 episodes
GETTING ACTION FROM:
action 3, numVisits=30361, meanQ=11.896333, numObservations: 9
action 2, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.00502824 0.273915 0.135848 0.511931 0.116192 0.195889 0.219012 0.102112 0.535294 0.338342 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=2845, meanQ=13.289526, numObservations: 9
action 2, numVisits=7, meanQ=5.715729, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 11193 episodes
GETTING ACTION FROM:
action 4, numVisits=14034, meanQ=11.885037, numObservations: 9
action 2, numVisits=7, meanQ=5.715729, numObservations: 6
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.00502824 0.273915 0.135848 0.511931 0.116192 0.195889 0.219012 0.102112 0.535294 0.338342 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=686, meanQ=14.606072, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 8111 episodes
GETTING ACTION FROM:
action 2, numVisits=8797, meanQ=12.788635, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.00502824 0.273915 0.135848 0.511931 0.116192 0.195889 0.219012 0.102112 0.535294 0.338342 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 5, numVisits=740, meanQ=18.502879, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 22046 episodes
GETTING ACTION FROM:
action 5, numVisits=22786, meanQ=19.524814, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 1 0.00502824 0.273915 0.135848 0.511931 0.116192 0.195889 0.219012 0.102112 0.535294 0.338342 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 11.4068
[32m ProblemEnvironment.hpp 351: Done.[39m
