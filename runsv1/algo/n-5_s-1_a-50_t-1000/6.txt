Run # 1
Initial state: 0 0.525392 0.866722 0.306306 0.64101 0.704117 0.0656529 0.116834 0.129347 0.65728 0.63916 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26194 episodes
GETTING ACTION FROM:
action 4, numVisits=26188, meanQ=8.191889, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.525392 0.866722 0.306306 0.64101 0.704117 0.0656529 0.116834 0.129347 0.65728 0.63916 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=5056, meanQ=8.915210, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=2, meanQ=-4.994950, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 8035 episodes
GETTING ACTION FROM:
action 2, numVisits=13080, meanQ=8.844390, numObservations: 9
action -1, numVisits=11, meanQ=-1.280900, numObservations: 10
action 0, numVisits=12, meanQ=-1.959513, numObservations: 11
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=2, meanQ=-4.994950, numObservations: 1
action 3, numVisits=2, meanQ=-6.608698, numObservations: 2
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.525392 0.866722 0.306306 0.64101 0.704117 0.0656529 0.116834 0.129347 0.65728 0.63916 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=437, meanQ=12.229200, numObservations: 9
action -1, numVisits=9, meanQ=-1.892200, numObservations: 7
action 0, numVisits=7, meanQ=-2.707143, numObservations: 6
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
action 4, numVisits=2, meanQ=-3.010000, numObservations: 2
action 5, numVisits=2, meanQ=-3.010000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 5402 episodes
GETTING ACTION FROM:
action 1, numVisits=5839, meanQ=12.493315, numObservations: 9
action -1, numVisits=9, meanQ=-1.892200, numObservations: 7
action 0, numVisits=7, meanQ=-2.707143, numObservations: 6
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
action 4, numVisits=2, meanQ=-3.010000, numObservations: 2
action 5, numVisits=2, meanQ=-3.010000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.525392 0.866722 0.306306 0.64101 0.704117 0.0656529 0.116834 0.129347 0.65728 0.63916 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 2
Initial state: 0 0.681991 0.509858 0.0395681 0.278555 0.685791 0.760957 0.919975 0.413379 0.896193 0.1558 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26582 episodes
GETTING ACTION FROM:
action 3, numVisits=26538, meanQ=8.471009, numObservations: 9
action -1, numVisits=19, meanQ=-1.010000, numObservations: 19
action 0, numVisits=19, meanQ=-1.010000, numObservations: 19
action 2, numVisits=2, meanQ=-3.505000, numObservations: 2
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=2, meanQ=-5.489950, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.681991 0.509858 0.0395681 0.278555 0.685791 0.760957 0.919975 0.413379 0.896193 0.1558 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 3
Initial state: 0 0.715445 0.955687 0.509535 0.947299 0.622743 0.554272 0.898607 0.81571 0.763359 0.0843081 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26349 episodes
GETTING ACTION FROM:
action 1, numVisits=26336, meanQ=8.002650, numObservations: 9
action 4, numVisits=8, meanQ=4.873750, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.715445 0.955687 0.509535 0.947299 0.622743 0.554272 0.898607 0.81571 0.763359 0.0843081 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 4
Initial state: 0 0.401362 0.00307577 0.658934 0.58797 0.0742067 0.0147387 0.882504 0.429266 0.734937 0.260425 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26551 episodes
GETTING ACTION FROM:
action 4, numVisits=26532, meanQ=8.114187, numObservations: 9
action -1, numVisits=6, meanQ=-1.010000, numObservations: 6
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 1, numVisits=3, meanQ=-6.333333, numObservations: 3
action 2, numVisits=2, meanQ=-7.500000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.401362 0.00307577 0.658934 0.58797 0.0742067 0.0147387 0.882504 0.429266 0.734937 0.260425 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 5
Initial state: 0 0.578226 0.254699 0.908949 0.252179 0.232745 0.333735 0.609834 0.674137 0.824214 0.131703 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26833 episodes
GETTING ACTION FROM:
action 5, numVisits=26824, meanQ=8.303517, numObservations: 9
action 4, numVisits=4, meanQ=1.250000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 2 0.578226 0.254699 0.908949 0.252179 0.232745 0.333735 0.609834 0.674137 0.824214 0.131703 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 6
Initial state: 0 0.723612 0.261643 0.551765 0.509761 0.233865 0.87056 0.315533 0.0850056 0.523147 0.0699619 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17751 episodes
GETTING ACTION FROM:
action 0, numVisits=17737, meanQ=13.906546, numObservations: 243
action -1, numVisits=6, meanQ=-1.010000, numObservations: 6
action 2, numVisits=2, meanQ=-4.000000, numObservations: 2
action 4, numVisits=2, meanQ=-4.000000, numObservations: 2
action 5, numVisits=2, meanQ=-4.499950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.723612 0.261643 0.551765 0.509761 0.233865 0.87056 0.315533 0.0850056 0.523147 0.0699619 w: 1
Observation: 0 0 1 0 2 0 1 0 1 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=218, meanQ=20.456547, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 37230 episodes
GETTING ACTION FROM:
action 2, numVisits=37448, meanQ=21.675528, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.723612 0.261643 0.551765 0.509761 0.233865 0.87056 0.315533 0.0850056 0.523147 0.0699619 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 7
Initial state: 0 0.243517 0.492346 0.544888 0.24604 0.589718 0.589635 0.551022 0.109347 0.477069 0.945775 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26626 episodes
GETTING ACTION FROM:
action 1, numVisits=26616, meanQ=8.181663, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.243517 0.492346 0.544888 0.24604 0.589718 0.589635 0.551022 0.109347 0.477069 0.945775 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1155, meanQ=3.474952, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 5889 episodes
GETTING ACTION FROM:
action 3, numVisits=5721, meanQ=9.446219, numObservations: 9
action 1, numVisits=1155, meanQ=3.474952, numObservations: 9
action 2, numVisits=3, meanQ=-8.336667, numObservations: 2
action 4, numVisits=52, meanQ=-8.952572, numObservations: 8
action 0, numVisits=89, meanQ=-13.263689, numObservations: 68
action -1, numVisits=35, meanQ=-30.743205, numObservations: 31
action 5, numVisits=6, meanQ=-176.471047, numObservations: 3
action: 3
Next state: 1 0.243517 0.492346 0.544888 0.24604 0.589718 0.589635 0.551022 0.109347 0.477069 0.945775 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 8
Initial state: 0 0.561491 0.622815 0.962719 0.807715 0.188654 0.698888 0.73238 0.407798 0.687695 0.711323 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 25981 episodes
GETTING ACTION FROM:
action 2, numVisits=25970, meanQ=8.448980, numObservations: 9
action 1, numVisits=3, meanQ=3.000000, numObservations: 2
action 3, numVisits=4, meanQ=1.000025, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.561491 0.622815 0.962719 0.807715 0.188654 0.698888 0.73238 0.407798 0.687695 0.711323 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 9
Initial state: 0 0.949824 0.0459058 0.935513 0.207994 0.852679 0.719602 0.624216 0.68023 0.717219 0.0557617 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26995 episodes
GETTING ACTION FROM:
action 2, numVisits=26989, meanQ=8.500593, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.949824 0.0459058 0.935513 0.207994 0.852679 0.719602 0.624216 0.68023 0.717219 0.0557617 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 10
Initial state: 0 0.0121538 0.929917 0.930658 0.11688 0.171938 0.472887 0.235544 0.0238885 0.6723 0.591347 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26264 episodes
GETTING ACTION FROM:
action 4, numVisits=26246, meanQ=8.516802, numObservations: 9
action 2, numVisits=13, meanQ=6.698462, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.0121538 0.929917 0.930658 0.11688 0.171938 0.472887 0.235544 0.0238885 0.6723 0.591347 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=592, meanQ=9.620263, numObservations: 9
action 2, numVisits=23, meanQ=8.652187, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 19665 episodes
GETTING ACTION FROM:
action 2, numVisits=16312, meanQ=5.085749, numObservations: 9
action 1, numVisits=3383, meanQ=5.070803, numObservations: 9
action 5, numVisits=511, meanQ=3.935495, numObservations: 9
action 3, numVisits=12, meanQ=1.332500, numObservations: 6
action -1, numVisits=38, meanQ=-1.817632, numObservations: 29
action 0, numVisits=28, meanQ=-2.212143, numObservations: 22
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.0121538 0.929917 0.930658 0.11688 0.171938 0.472887 0.235544 0.0238885 0.6723 0.591347 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 11
Initial state: 0 0.204481 0.407592 0.893588 0.320948 0.612553 0.675849 0.669449 0.819801 0.333445 0.0487264 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26048 episodes
GETTING ACTION FROM:
action 2, numVisits=26033, meanQ=8.546041, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 4, numVisits=5, meanQ=-1.200000, numObservations: 5
action 1, numVisits=2, meanQ=-4.000000, numObservations: 2
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.204481 0.407592 0.893588 0.320948 0.612553 0.675849 0.669449 0.819801 0.333445 0.0487264 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 12
Initial state: 0 0.939085 0.947657 0.621669 0.520325 0.480275 0.432811 0.534381 0.363232 0.605888 0.242582 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26132 episodes
GETTING ACTION FROM:
action 1, numVisits=26115, meanQ=8.516047, numObservations: 9
action 5, numVisits=12, meanQ=3.416683, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.939085 0.947657 0.621669 0.520325 0.480275 0.432811 0.534381 0.363232 0.605888 0.242582 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 13
Initial state: 0 0.235535 0.891861 0.668013 0.381915 0.672323 0.616991 0.809155 0.252711 0.442641 0.933115 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26906 episodes
GETTING ACTION FROM:
action 5, numVisits=26900, meanQ=8.306007, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.235535 0.891861 0.668013 0.381915 0.672323 0.616991 0.809155 0.252711 0.442641 0.933115 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=2717, meanQ=10.040608, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 7542 episodes
GETTING ACTION FROM:
action 2, numVisits=10259, meanQ=11.236936, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.235535 0.891861 0.668013 0.381915 0.672323 0.616991 0.809155 0.252711 0.442641 0.933115 w: 1
Observation: 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 14
Initial state: 0 0.839336 0.120216 0.532131 0.536727 0.866455 0.569536 0.250998 0.89209 0.926846 0.497179 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26576 episodes
GETTING ACTION FROM:
action 3, numVisits=26565, meanQ=8.367093, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 1, numVisits=2, meanQ=-7.500000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.839336 0.120216 0.532131 0.536727 0.866455 0.569536 0.250998 0.89209 0.926846 0.497179 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 15
Initial state: 0 0.962614 0.49122 0.641365 0.635113 0.169384 0.84149 0.298681 0.841363 0.022759 0.697298 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17703 episodes
GETTING ACTION FROM:
action 0, numVisits=17685, meanQ=13.493535, numObservations: 243
action -1, numVisits=8, meanQ=-2.495000, numObservations: 7
action 3, numVisits=3, meanQ=-4.000000, numObservations: 3
action 2, numVisits=3, meanQ=-6.333333, numObservations: 3
action 1, numVisits=2, meanQ=-7.500000, numObservations: 2
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.962614 0.49122 0.641365 0.635113 0.169384 0.84149 0.298681 0.841363 0.022759 0.697298 w: 1
Observation: 0 0 1 0 2 0 3 0 3 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=98, meanQ=19.182761, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 38012 episodes
GETTING ACTION FROM:
action 2, numVisits=38110, meanQ=22.321656, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.962614 0.49122 0.641365 0.635113 0.169384 0.84149 0.298681 0.841363 0.022759 0.697298 w: 1
Observation: 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=277, meanQ=21.628527, numObservations: 9
action 4, numVisits=13, meanQ=14.622315, numObservations: 5
action 3, numVisits=5, meanQ=10.820000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 23166 episodes
GETTING ACTION FROM:
action 2, numVisits=282, meanQ=21.634721, numObservations: 9
action 4, numVisits=23174, meanQ=21.284573, numObservations: 9
action 3, numVisits=5, meanQ=10.820000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.962614 0.49122 0.641365 0.635113 0.169384 0.84149 0.298681 0.841363 0.022759 0.697298 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 17.5624
Run # 16
Initial state: 0 0.789426 0.543555 0.632088 0.680923 0.00251887 0.899558 0.972425 0.474797 0.137507 0.357702 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26789 episodes
GETTING ACTION FROM:
action 3, numVisits=26769, meanQ=8.359211, numObservations: 9
action 5, numVisits=10, meanQ=6.102020, numObservations: 5
action 2, numVisits=6, meanQ=3.000000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.789426 0.543555 0.632088 0.680923 0.00251887 0.899558 0.972425 0.474797 0.137507 0.357702 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=2759, meanQ=9.052398, numObservations: 9
action 1, numVisits=12, meanQ=1.079167, numObservations: 7
action 5, numVisits=6, meanQ=0.666667, numObservations: 4
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 7078 episodes
GETTING ACTION FROM:
action 2, numVisits=9806, meanQ=10.227948, numObservations: 9
action 1, numVisits=12, meanQ=1.079167, numObservations: 7
action 5, numVisits=7, meanQ=-0.483354, numObservations: 5
action -1, numVisits=18, meanQ=-1.340000, numObservations: 17
action 0, numVisits=16, meanQ=-2.242239, numObservations: 12
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.789426 0.543555 0.632088 0.680923 0.00251887 0.899558 0.972425 0.474797 0.137507 0.357702 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 17
Initial state: 0 0.216586 0.351166 0.0881144 0.979828 0.743578 0.690313 0.293977 0.189618 0.619127 0.667343 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17695 episodes
GETTING ACTION FROM:
action -1, numVisits=17656, meanQ=12.280079, numObservations: 243
action 0, numVisits=33, meanQ=-1.790300, numObservations: 30
action 3, numVisits=2, meanQ=-7.500000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.216586 0.351166 0.0881144 0.979828 0.743578 0.690313 0.293977 0.189618 0.619127 0.667343 w: 1
Observation: 0 1 0 1 0 3 0 1 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=161, meanQ=20.438763, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 37352 episodes
GETTING ACTION FROM:
action 5, numVisits=37513, meanQ=21.399843, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.216586 0.351166 0.0881144 0.979828 0.743578 0.690313 0.293977 0.189618 0.619127 0.667343 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 18
Initial state: 0 0.626211 0.665528 0.511637 0.0287046 0.0066927 0.626475 0.323482 0.225579 0.861584 0.967148 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27305 episodes
GETTING ACTION FROM:
action 4, numVisits=9288, meanQ=8.543891, numObservations: 9
action 1, numVisits=17569, meanQ=8.410244, numObservations: 9
action 5, numVisits=438, meanQ=8.133501, numObservations: 9
action 2, numVisits=7, meanQ=5.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.626211 0.665528 0.511637 0.0287046 0.0066927 0.626475 0.323482 0.225579 0.861584 0.967148 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=898, meanQ=10.008407, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 8382 episodes
GETTING ACTION FROM:
action 5, numVisits=9274, meanQ=10.057795, numObservations: 9
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.257500, numObservations: 4
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.626211 0.665528 0.511637 0.0287046 0.0066927 0.626475 0.323482 0.225579 0.861584 0.967148 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 19
Initial state: 0 0.945518 0.221599 0.373226 0.704866 0.793479 0.579608 0.645444 0.626516 0.343074 0.72339 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26380 episodes
GETTING ACTION FROM:
action 1, numVisits=26374, meanQ=8.037723, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.945518 0.221599 0.373226 0.704866 0.793479 0.579608 0.645444 0.626516 0.343074 0.72339 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=518, meanQ=7.946491, numObservations: 9
action 3, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 7756 episodes
GETTING ACTION FROM:
action 5, numVisits=8219, meanQ=5.638681, numObservations: 9
action 3, numVisits=13, meanQ=0.208960, numObservations: 8
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=26, meanQ=-40.878222, numObservations: 23
action -1, numVisits=20, meanQ=-52.012856, numObservations: 17
action: 5
Next state: 1 0.945518 0.221599 0.373226 0.704866 0.793479 0.579608 0.645444 0.626516 0.343074 0.72339 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 20
Initial state: 0 0.550775 0.645572 0.968527 0.452367 0.159027 0.778009 0.390167 0.45882 0.110475 0.292628 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26587 episodes
GETTING ACTION FROM:
action 3, numVisits=26572, meanQ=8.391285, numObservations: 9
action 2, numVisits=10, meanQ=4.499000, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.550775 0.645572 0.968527 0.452367 0.159027 0.778009 0.390167 0.45882 0.110475 0.292628 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 21
Initial state: 0 0.480043 0.664096 0.0723201 0.216684 0.857167 0.483061 0.623385 0.58753 0.260767 0.987582 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26583 episodes
GETTING ACTION FROM:
action 3, numVisits=26577, meanQ=8.399865, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 2 0.480043 0.664096 0.0723201 0.216684 0.857167 0.483061 0.623385 0.58753 0.260767 0.987582 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 22
Initial state: 0 0.92507 0.526818 0.634565 0.271113 0.136359 0.58736 0.262881 0.375658 0.556817 0.665879 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26787 episodes
GETTING ACTION FROM:
action 1, numVisits=26777, meanQ=8.480555, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.92507 0.526818 0.634565 0.271113 0.136359 0.58736 0.262881 0.375658 0.556817 0.665879 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 23
Initial state: 0 0.556879 0.633504 0.172486 0.112291 0.0706563 0.709198 0.193855 0.0859188 0.839101 0.446321 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17835 episodes
GETTING ACTION FROM:
action 0, numVisits=17755, meanQ=14.142825, numObservations: 243
action -1, numVisits=75, meanQ=-1.407056, numObservations: 61
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.556879 0.633504 0.172486 0.112291 0.0706563 0.709198 0.193855 0.0859188 0.839101 0.446321 w: 1
Observation: 0 0 2 0 1 0 2 0 1 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=113, meanQ=14.175759, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 31581 episodes
GETTING ACTION FROM:
action 1, numVisits=31694, meanQ=15.712708, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.556879 0.633504 0.172486 0.112291 0.0706563 0.709198 0.193855 0.0859188 0.839101 0.446321 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 24
Initial state: 0 0.105383 0.225323 0.489854 0.488346 0.303265 0.556918 0.618261 0.657222 0.532595 0.839312 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26590 episodes
GETTING ACTION FROM:
action 1, numVisits=26582, meanQ=8.135126, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.105383 0.225323 0.489854 0.488346 0.303265 0.556918 0.618261 0.657222 0.532595 0.839312 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=1183, meanQ=9.356262, numObservations: 9
action -1, numVisits=7, meanQ=-1.577129, numObservations: 6
action 0, numVisits=3, meanQ=-1.673300, numObservations: 2
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 6262 episodes
GETTING ACTION FROM:
action 3, numVisits=7337, meanQ=7.790717, numObservations: 9
action 0, numVisits=69, meanQ=-1.826721, numObservations: 61
action -1, numVisits=48, meanQ=-2.185926, numObservations: 37
action 5, numVisits=2, meanQ=-7.254056, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.105383 0.225323 0.489854 0.488346 0.303265 0.556918 0.618261 0.657222 0.532595 0.839312 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=191, meanQ=12.996013, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 3, numVisits=2, meanQ=-3.010000, numObservations: 2
action 4, numVisits=2, meanQ=-3.010000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 6416 episodes
GETTING ACTION FROM:
action 5, numVisits=6598, meanQ=10.891289, numObservations: 9
action -1, numVisits=11, meanQ=-1.190000, numObservations: 11
action 0, numVisits=11, meanQ=-1.280000, numObservations: 10
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 3, numVisits=2, meanQ=-3.010000, numObservations: 2
action 4, numVisits=2, meanQ=-3.010000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.105383 0.225323 0.489854 0.488346 0.303265 0.556918 0.618261 0.657222 0.532595 0.839312 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 25
Initial state: 0 0.658148 0.655648 0.126124 0.220558 0.584226 0.95688 0.889874 0.348796 0.509584 0.74303 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26948 episodes
GETTING ACTION FROM:
action 1, numVisits=26938, meanQ=8.341588, numObservations: 9
action 3, numVisits=5, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.658148 0.655648 0.126124 0.220558 0.584226 0.95688 0.889874 0.348796 0.509584 0.74303 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 26
Initial state: 0 0.607874 0.493356 0.808716 0.9578 0.257606 0.743119 0.0627085 0.215843 0.419098 0.175608 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 25974 episodes
GETTING ACTION FROM:
action 1, numVisits=25964, meanQ=8.442103, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.607874 0.493356 0.808716 0.9578 0.257606 0.743119 0.0627085 0.215843 0.419098 0.175608 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 27
Initial state: 0 0.293414 0.148424 0.258062 0.994377 0.659298 0.624517 0.738924 0.97337 0.225764 0.149753 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26719 episodes
GETTING ACTION FROM:
action 5, numVisits=26706, meanQ=8.302031, numObservations: 9
action 2, numVisits=6, meanQ=4.166667, numObservations: 4
action 3, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 0 0.293414 0.148424 0.258062 0.994377 0.659298 0.624517 0.738924 0.97337 0.225764 0.149753 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=5221, meanQ=9.881214, numObservations: 9
action 4, numVisits=27, meanQ=4.967426, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 6529 episodes
GETTING ACTION FROM:
action 1, numVisits=11702, meanQ=8.686368, numObservations: 9
action 2, numVisits=30, meanQ=5.427122, numObservations: 9
action 4, numVisits=27, meanQ=4.967426, numObservations: 8
action 0, numVisits=10, meanQ=-1.109000, numObservations: 10
action -1, numVisits=10, meanQ=-1.109000, numObservations: 10
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=2, meanQ=-4.004950, numObservations: 1
action: 1
Next state: 0 0.293414 0.148424 0.258062 0.994377 0.659298 0.624517 0.738924 0.97337 0.225764 0.149753 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=1943, meanQ=11.988311, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 5945 episodes
GETTING ACTION FROM:
action 2, numVisits=7886, meanQ=10.904249, numObservations: 9
action -1, numVisits=3, meanQ=-1.340000, numObservations: 3
action 0, numVisits=3, meanQ=-1.340000, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.293414 0.148424 0.258062 0.994377 0.659298 0.624517 0.738924 0.97337 0.225764 0.149753 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 28
Initial state: 0 0.859288 0.532188 0.755794 0.339871 0.596313 0.855656 0.602333 0.627271 0.836196 0.566226 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26225 episodes
GETTING ACTION FROM:
action 5, numVisits=26219, meanQ=8.752557, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 1 0.859288 0.532188 0.755794 0.339871 0.596313 0.855656 0.602333 0.627271 0.836196 0.566226 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 29
Initial state: 0 0.298939 0.792357 0.494361 0.307262 0.181229 0.0321814 0.819673 0.395402 0.588042 0.524416 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26926 episodes
GETTING ACTION FROM:
action 5, numVisits=26918, meanQ=8.204962, numObservations: 9
action 2, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.298939 0.792357 0.494361 0.307262 0.181229 0.0321814 0.819673 0.395402 0.588042 0.524416 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 30
Initial state: 0 0.963867 0.987575 0.224588 0.956494 0.585132 0.655779 0.997863 0.95494 0.680899 0.170771 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26873 episodes
GETTING ACTION FROM:
action 3, numVisits=26865, meanQ=8.141806, numObservations: 9
action 2, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.963867 0.987575 0.224588 0.956494 0.585132 0.655779 0.997863 0.95494 0.680899 0.170771 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 31
Initial state: 0 0.494961 0.405768 0.666942 0.506534 0.185752 0.477996 0.83404 0.797413 0.295628 0.0179253 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26926 episodes
GETTING ACTION FROM:
action 1, numVisits=26914, meanQ=8.378418, numObservations: 9
action 2, numVisits=7, meanQ=1.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.494961 0.405768 0.666942 0.506534 0.185752 0.477996 0.83404 0.797413 0.295628 0.0179253 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=5255, meanQ=9.653648, numObservations: 9
action 3, numVisits=17, meanQ=2.999418, numObservations: 8
action 2, numVisits=4, meanQ=-0.252500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 5852 episodes
GETTING ACTION FROM:
action 4, numVisits=11087, meanQ=9.578579, numObservations: 9
action 3, numVisits=17, meanQ=2.999418, numObservations: 8
action 2, numVisits=4, meanQ=-0.252500, numObservations: 3
action 0, numVisits=13, meanQ=-0.531520, numObservations: 10
action -1, numVisits=8, meanQ=-1.133750, numObservations: 7
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 4
Next state: 1 0.494961 0.405768 0.666942 0.506534 0.185752 0.477996 0.83404 0.797413 0.295628 0.0179253 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 32
Initial state: 0 0.906026 0.382722 0.605537 0.616294 0.579242 0.450566 0.972605 0.751627 0.291702 0.658256 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26896 episodes
GETTING ACTION FROM:
action 2, numVisits=26880, meanQ=8.645999, numObservations: 9
action -1, numVisits=6, meanQ=-1.010000, numObservations: 6
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.906026 0.382722 0.605537 0.616294 0.579242 0.450566 0.972605 0.751627 0.291702 0.658256 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 33
Initial state: 0 0.302943 0.266291 0.60063 0.587269 0.899314 0.463186 0.916332 0.451634 0.338988 0.705858 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26857 episodes
GETTING ACTION FROM:
action 2, numVisits=26844, meanQ=8.501813, numObservations: 9
action 5, numVisits=5, meanQ=3.552000, numObservations: 4
action 3, numVisits=4, meanQ=1.250000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.302943 0.266291 0.60063 0.587269 0.899314 0.463186 0.916332 0.451634 0.338988 0.705858 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 34
Initial state: 0 0.592928 0.620955 0.0306 0.939568 0.112668 0.071669 0.877716 0.276107 0.339378 0.195326 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26818 episodes
GETTING ACTION FROM:
action 2, numVisits=26812, meanQ=8.374102, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.592928 0.620955 0.0306 0.939568 0.112668 0.071669 0.877716 0.276107 0.339378 0.195326 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=2618, meanQ=10.312002, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 8184 episodes
GETTING ACTION FROM:
action 5, numVisits=10797, meanQ=10.432866, numObservations: 9
action 0, numVisits=4, meanQ=-1.257500, numObservations: 4
action -1, numVisits=3, meanQ=-1.340000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.592928 0.620955 0.0306 0.939568 0.112668 0.071669 0.877716 0.276107 0.339378 0.195326 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=1510, meanQ=9.846772, numObservations: 9
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=3, meanQ=-1.673300, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 4238 episodes
GETTING ACTION FROM:
action 3, numVisits=5739, meanQ=9.846846, numObservations: 9
action -1, numVisits=9, meanQ=-1.340000, numObservations: 9
action 0, numVisits=6, meanQ=-1.671650, numObservations: 5
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=2, meanQ=-7.005000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.592928 0.620955 0.0306 0.939568 0.112668 0.071669 0.877716 0.276107 0.339378 0.195326 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=897, meanQ=12.937036, numObservations: 9
action -1, numVisits=6, meanQ=-1.341650, numObservations: 5
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=58, meanQ=-12.403649, numObservations: 21
Sampled 6977 episodes
GETTING ACTION FROM:
action 1, numVisits=7874, meanQ=14.359147, numObservations: 9
action -1, numVisits=6, meanQ=-1.341650, numObservations: 5
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=58, meanQ=-12.403649, numObservations: 21
action: 1
Next state: 1 0.592928 0.620955 0.0306 0.939568 0.112668 0.071669 0.877716 0.276107 0.339378 0.195326 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 11.4068
Run # 35
Initial state: 0 0.854153 0.339256 0.441098 0.714215 0.243203 0.190259 0.790376 0.924109 0.585301 0.6092 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 24533 episodes
GETTING ACTION FROM:
action 2, numVisits=24524, meanQ=6.913348, numObservations: 9
action 3, numVisits=4, meanQ=3.247500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.854153 0.339256 0.441098 0.714215 0.243203 0.190259 0.790376 0.924109 0.585301 0.6092 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 36
Initial state: 0 0.545697 0.6844 0.352842 0.284883 0.761689 0.725936 0.976227 0.0675476 0.76584 0.581929 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 25915 episodes
GETTING ACTION FROM:
action 2, numVisits=25909, meanQ=8.303864, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.545697 0.6844 0.352842 0.284883 0.761689 0.725936 0.976227 0.0675476 0.76584 0.581929 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=557, meanQ=9.602015, numObservations: 9
action 1, numVisits=9, meanQ=-0.558889, numObservations: 5
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 21430 episodes
GETTING ACTION FROM:
action 4, numVisits=21926, meanQ=4.640239, numObservations: 9
action 1, numVisits=9, meanQ=-0.558889, numObservations: 5
action -1, numVisits=34, meanQ=-1.650588, numObservations: 30
action 0, numVisits=33, meanQ=-1.670000, numObservations: 26
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.545697 0.6844 0.352842 0.284883 0.761689 0.725936 0.976227 0.0675476 0.76584 0.581929 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 37
Initial state: 0 0.0201317 0.85828 0.556244 0.605604 0.356343 0.75683 0.474048 0.212585 0.948689 0.349709 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26481 episodes
GETTING ACTION FROM:
action 3, numVisits=26448, meanQ=8.371126, numObservations: 9
action -1, numVisits=15, meanQ=-1.274660, numObservations: 14
action 0, numVisits=12, meanQ=-1.340825, numObservations: 11
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=2, meanQ=-4.499950, numObservations: 1
action 1, numVisits=2, meanQ=-7.500000, numObservations: 2
action: 3
Next state: 0 0.0201317 0.85828 0.556244 0.605604 0.356343 0.75683 0.474048 0.212585 0.948689 0.349709 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=2601, meanQ=10.086201, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 7481 episodes
GETTING ACTION FROM:
action 1, numVisits=10082, meanQ=10.307861, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.0201317 0.85828 0.556244 0.605604 0.356343 0.75683 0.474048 0.212585 0.948689 0.349709 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 38
Initial state: 0 0.376862 0.486661 0.302404 0.45097 0.77645 0.485296 0.591794 0.542145 0.765679 0.233559 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 25621 episodes
GETTING ACTION FROM:
action 4, numVisits=25609, meanQ=8.426942, numObservations: 9
action 1, numVisits=3, meanQ=3.000000, numObservations: 3
action 5, numVisits=5, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 1 0.376862 0.486661 0.302404 0.45097 0.77645 0.485296 0.591794 0.542145 0.765679 0.233559 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 39
Initial state: 0 0.943364 0.968563 0.486244 0.699378 0.349537 0.707329 0.660317 0.589191 0.901336 0.831919 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 24683 episodes
GETTING ACTION FROM:
action 3, numVisits=24651, meanQ=8.704819, numObservations: 9
action 0, numVisits=15, meanQ=-1.274660, numObservations: 14
action -1, numVisits=13, meanQ=-1.315377, numObservations: 12
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.943364 0.968563 0.486244 0.699378 0.349537 0.707329 0.660317 0.589191 0.901336 0.831919 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 40
Initial state: 0 0.647496 0.663186 0.185065 0.669878 0.202054 0.822975 0.743554 0.711512 0.944114 0.772692 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26025 episodes
GETTING ACTION FROM:
action 4, numVisits=26012, meanQ=8.659236, numObservations: 9
action 1, numVisits=6, meanQ=-0.170000, numObservations: 6
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.647496 0.663186 0.185065 0.669878 0.202054 0.822975 0.743554 0.711512 0.944114 0.772692 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 41
Initial state: 0 0.710671 0.0833245 0.270234 0.393217 0.667511 0.622133 0.413763 0.694976 0.154559 0.45784 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26843 episodes
GETTING ACTION FROM:
action 1, numVisits=26832, meanQ=8.319495, numObservations: 9
action 2, numVisits=3, meanQ=3.000000, numObservations: 2
action 3, numVisits=4, meanQ=1.250000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.710671 0.0833245 0.270234 0.393217 0.667511 0.622133 0.413763 0.694976 0.154559 0.45784 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 42
Initial state: 0 0.245215 0.44911 0.336315 0.115501 0.13869 0.0290543 0.658862 0.771573 0.629113 0.645224 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 25976 episodes
GETTING ACTION FROM:
action 1, numVisits=25966, meanQ=8.159018, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.245215 0.44911 0.336315 0.115501 0.13869 0.0290543 0.658862 0.771573 0.629113 0.645224 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=5125, meanQ=8.919668, numObservations: 9
action 3, numVisits=11, meanQ=6.361818, numObservations: 7
action 2, numVisits=5, meanQ=6.196000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 6590 episodes
GETTING ACTION FROM:
action 4, numVisits=9443, meanQ=9.148426, numObservations: 9
action 5, numVisits=2182, meanQ=6.750712, numObservations: 9
action -1, numVisits=8, meanQ=-2.618750, numObservations: 6
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=3, meanQ=-4.970000, numObservations: 2
action 2, numVisits=53, meanQ=-5.702370, numObservations: 9
action 3, numVisits=45, meanQ=-16.941056, numObservations: 9
action: 4
Next state: 1 0.245215 0.44911 0.336315 0.115501 0.13869 0.0290543 0.658862 0.771573 0.629113 0.645224 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 43
Initial state: 0 0.460444 0.554125 0.0730638 0.156298 0.592401 0.522632 0.180137 0.51 0.697897 0.621407 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26819 episodes
GETTING ACTION FROM:
action 4, numVisits=26811, meanQ=8.161013, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.460444 0.554125 0.0730638 0.156298 0.592401 0.522632 0.180137 0.51 0.697897 0.621407 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1174, meanQ=8.844178, numObservations: 9
action 5, numVisits=27, meanQ=4.500007, numObservations: 8
action 2, numVisits=5, meanQ=1.598020, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 6078 episodes
GETTING ACTION FROM:
action 1, numVisits=7025, meanQ=9.090833, numObservations: 9
action 5, numVisits=30, meanQ=2.950007, numObservations: 9
action 2, numVisits=5, meanQ=1.598020, numObservations: 4
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=198, meanQ=-5.246989, numObservations: 117
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action -1, numVisits=27, meanQ=-40.109832, numObservations: 24
action: 1
Next state: 0 0.460444 0.554125 0.0730638 0.156298 0.592401 0.522632 0.180137 0.51 0.697897 0.621407 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=191, meanQ=9.839482, numObservations: 9
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action 4, numVisits=2, meanQ=-7.005000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=33, meanQ=-32.603837, numObservations: 32
action -1, numVisits=29, meanQ=-35.350904, numObservations: 21
Sampled 6750 episodes
GETTING ACTION FROM:
action 3, numVisits=6941, meanQ=10.880687, numObservations: 9
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action 4, numVisits=2, meanQ=-7.005000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=33, meanQ=-32.603837, numObservations: 32
action -1, numVisits=29, meanQ=-35.350904, numObservations: 21
action: 3
Next state: 1 0.460444 0.554125 0.0730638 0.156298 0.592401 0.522632 0.180137 0.51 0.697897 0.621407 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 44
Initial state: 0 0.579983 0.602616 0.36428 0.449581 0.48198 0.0345015 0.641118 0.473999 0.915757 0.435331 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27124 episodes
GETTING ACTION FROM:
action 3, numVisits=27105, meanQ=8.469306, numObservations: 9
action -1, numVisits=6, meanQ=-1.010000, numObservations: 6
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 4, numVisits=2, meanQ=-4.000000, numObservations: 2
action 2, numVisits=2, meanQ=-7.500000, numObservations: 2
action 5, numVisits=2, meanQ=-7.500000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.579983 0.602616 0.36428 0.449581 0.48198 0.0345015 0.641118 0.473999 0.915757 0.435331 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=5288, meanQ=9.754266, numObservations: 9
action 1, numVisits=19, meanQ=2.373174, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 7025 episodes
GETTING ACTION FROM:
action 5, numVisits=12298, meanQ=9.348805, numObservations: 9
action 1, numVisits=19, meanQ=2.373174, numObservations: 7
action 0, numVisits=8, meanQ=-1.257500, numObservations: 8
action -1, numVisits=7, meanQ=-1.292857, numObservations: 7
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action 4, numVisits=2, meanQ=-7.005000, numObservations: 1
action: 5
Next state: 2 0.579983 0.602616 0.36428 0.449581 0.48198 0.0345015 0.641118 0.473999 0.915757 0.435331 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 45
Initial state: 0 0.420851 0.0917071 0.0328193 0.466187 0.548741 0.404164 0.0648493 0.127323 0.547098 0.523408 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26039 episodes
GETTING ACTION FROM:
action 4, numVisits=26033, meanQ=8.053234, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.420851 0.0917071 0.0328193 0.466187 0.548741 0.404164 0.0648493 0.127323 0.547098 0.523408 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=5174, meanQ=8.999418, numObservations: 9
action 3, numVisits=6, meanQ=2.668350, numObservations: 4
action 5, numVisits=6, meanQ=1.998333, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 6668 episodes
GETTING ACTION FROM:
action 1, numVisits=11822, meanQ=8.450514, numObservations: 9
action 3, numVisits=6, meanQ=2.668350, numObservations: 4
action 5, numVisits=6, meanQ=1.998333, numObservations: 4
action 0, numVisits=10, meanQ=-1.208000, numObservations: 10
action -1, numVisits=9, meanQ=-1.230000, numObservations: 9
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=4, meanQ=-262.567372, numObservations: 3
action: 1
Next state: 2 0.420851 0.0917071 0.0328193 0.466187 0.548741 0.404164 0.0648493 0.127323 0.547098 0.523408 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 46
Initial state: 0 0.59746 0.644268 0.339356 0.790401 0.257577 0.0448008 0.92479 0.759296 0.165694 0.832542 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26551 episodes
GETTING ACTION FROM:
action 1, numVisits=26545, meanQ=7.886088, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.59746 0.644268 0.339356 0.790401 0.257577 0.0448008 0.92479 0.759296 0.165694 0.832542 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 47
Initial state: 0 0.209864 0.048269 0.636529 0.624169 0.146565 0.0199837 0.0210424 0.00279749 0.0557499 0.733805 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27123 episodes
GETTING ACTION FROM:
action 5, numVisits=27115, meanQ=8.659136, numObservations: 9
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.209864 0.048269 0.636529 0.624169 0.146565 0.0199837 0.0210424 0.00279749 0.0557499 0.733805 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=2673, meanQ=10.211857, numObservations: 9
action -1, numVisits=6, meanQ=-1.010000, numObservations: 6
action 0, numVisits=5, meanQ=-1.010000, numObservations: 5
action 4, numVisits=7, meanQ=-1.144257, numObservations: 5
action 1, numVisits=6, meanQ=-1.833317, numObservations: 5
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 8014 episodes
GETTING ACTION FROM:
action 3, numVisits=10687, meanQ=10.531244, numObservations: 9
action -1, numVisits=6, meanQ=-1.010000, numObservations: 6
action 0, numVisits=5, meanQ=-1.010000, numObservations: 5
action 4, numVisits=7, meanQ=-1.144257, numObservations: 5
action 1, numVisits=6, meanQ=-1.833317, numObservations: 5
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.209864 0.048269 0.636529 0.624169 0.146565 0.0199837 0.0210424 0.00279749 0.0557499 0.733805 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=1527, meanQ=12.099843, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=24, meanQ=-28.976096, numObservations: 7
Sampled 5301 episodes
GETTING ACTION FROM:
action 4, numVisits=6826, meanQ=12.641998, numObservations: 9
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action -1, numVisits=3, meanQ=-1.340000, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=24, meanQ=-28.976096, numObservations: 7
action: 4
Next state: 0 0.209864 0.048269 0.636529 0.624169 0.146565 0.0199837 0.0210424 0.00279749 0.0557499 0.733805 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=780, meanQ=15.992047, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=62, meanQ=-2.083229, numObservations: 9
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 4794 episodes
GETTING ACTION FROM:
action 2, numVisits=5574, meanQ=15.441660, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=62, meanQ=-2.083229, numObservations: 9
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.209864 0.048269 0.636529 0.624169 0.146565 0.0199837 0.0210424 0.00279749 0.0557499 0.733805 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 11.4068
Run # 48
Initial state: 0 0.171138 0.104061 0.958676 0.473428 0.133087 0.0110359 0.666631 0.533672 0.528458 0.260697 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 25654 episodes
GETTING ACTION FROM:
action 4, numVisits=25642, meanQ=8.489122, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 3, numVisits=2, meanQ=-4.000000, numObservations: 2
action 2, numVisits=2, meanQ=-7.500000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.171138 0.104061 0.958676 0.473428 0.133087 0.0110359 0.666631 0.533672 0.528458 0.260697 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 49
Initial state: 0 0.674174 0.722026 0.592467 0.524435 0.474531 0.314405 0.400816 0.425951 0.447503 0.829319 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26108 episodes
GETTING ACTION FROM:
action 5, numVisits=26092, meanQ=8.885709, numObservations: 9
action 2, numVisits=5, meanQ=-0.595960, numObservations: 2
action 4, numVisits=5, meanQ=-1.002000, numObservations: 5
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 0 0.674174 0.722026 0.592467 0.524435 0.474531 0.314405 0.400816 0.425951 0.447503 0.829319 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=2531, meanQ=11.831048, numObservations: 9
action 4, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 8296 episodes
GETTING ACTION FROM:
action 5, numVisits=2533, meanQ=11.834156, numObservations: 9
action 2, numVisits=8235, meanQ=10.376432, numObservations: 9
action 1, numVisits=2, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=27, meanQ=-40.843595, numObservations: 23
action 4, numVisits=18, meanQ=-49.411129, numObservations: 8
action 0, numVisits=19, meanQ=-57.925009, numObservations: 14
action: 5
Next state: 1 0.674174 0.722026 0.592467 0.524435 0.474531 0.314405 0.400816 0.425951 0.447503 0.829319 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 50
Initial state: 0 0.438781 0.0553956 0.601771 0.97454 0.23006 0.645549 0.396625 0.266608 0.586867 0.645891 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26687 episodes
GETTING ACTION FROM:
action 5, numVisits=26657, meanQ=8.285792, numObservations: 9
action 3, numVisits=25, meanQ=4.251220, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 1 0.438781 0.0553956 0.601771 0.97454 0.23006 0.645549 0.396625 0.266608 0.586867 0.645891 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
[32m ProblemEnvironment.hpp 351: Done.[39m
