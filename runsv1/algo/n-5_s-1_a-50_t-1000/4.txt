Run # 1
Initial state: 0 0.60971 0.614073 0.290258 0.624413 0.0482241 0.862223 0.628568 0.828307 0.486287 0.523983 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17947 episodes
GETTING ACTION FROM:
action -1, numVisits=17922, meanQ=14.558952, numObservations: 242
action 0, numVisits=19, meanQ=-1.635263, numObservations: 18
action 1, numVisits=2, meanQ=-4.499950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.60971 0.614073 0.290258 0.624413 0.0482241 0.862223 0.628568 0.828307 0.486287 0.523983 w: 1
Observation: 0 1 0 1 0 1 0 3 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=103, meanQ=21.291069, numObservations: 9
action 4, numVisits=2, meanQ=6.500000, numObservations: 2
action 3, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 38435 episodes
GETTING ACTION FROM:
action 5, numVisits=38538, meanQ=22.415410, numObservations: 9
action 4, numVisits=2, meanQ=6.500000, numObservations: 2
action 3, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.60971 0.614073 0.290258 0.624413 0.0482241 0.862223 0.628568 0.828307 0.486287 0.523983 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 2
Initial state: 0 0.854286 0.24844 0.241032 0.14432 0.783799 0.604163 0.488492 0.518184 0.740475 0.191979 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31020 episodes
GETTING ACTION FROM:
action 5, numVisits=31013, meanQ=11.279831, numObservations: 9
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.854286 0.24844 0.241032 0.14432 0.783799 0.604163 0.488492 0.518184 0.740475 0.191979 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 3
Initial state: 0 0.34984 0.997884 0.501866 0.386313 0.766933 0.264802 0.113891 0.990736 0.386165 0.310037 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30939 episodes
GETTING ACTION FROM:
action 2, numVisits=30916, meanQ=11.235342, numObservations: 9
action 1, numVisits=11, meanQ=9.010000, numObservations: 5
action 4, numVisits=8, meanQ=6.845000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.34984 0.997884 0.501866 0.386313 0.766933 0.264802 0.113891 0.990736 0.386165 0.310037 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 4
Initial state: 0 0.476037 0.414593 0.84621 0.562874 0.55732 0.675573 0.031125 0.882582 0.79413 0.631062 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31071 episodes
GETTING ACTION FROM:
action 4, numVisits=31063, meanQ=11.086552, numObservations: 9
action 1, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.476037 0.414593 0.84621 0.562874 0.55732 0.675573 0.031125 0.882582 0.79413 0.631062 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=3138, meanQ=12.310138, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 12252 episodes
GETTING ACTION FROM:
action 5, numVisits=15386, meanQ=13.062600, numObservations: 9
action -1, numVisits=3, meanQ=-1.340000, numObservations: 3
action 0, numVisits=3, meanQ=-1.340000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 2 0.476037 0.414593 0.84621 0.562874 0.55732 0.675573 0.031125 0.882582 0.79413 0.631062 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 5
Initial state: 0 0.375615 0.559465 0.949637 0.908616 0.460475 0.440744 0.0749653 0.28796 0.828118 0.589128 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31106 episodes
GETTING ACTION FROM:
action 1, numVisits=31082, meanQ=11.117526, numObservations: 9
action 3, numVisits=10, meanQ=5.609000, numObservations: 6
action 4, numVisits=10, meanQ=5.000010, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.375615 0.559465 0.949637 0.908616 0.460475 0.440744 0.0749653 0.28796 0.828118 0.589128 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=3104, meanQ=12.074826, numObservations: 9
action 2, numVisits=8, meanQ=8.436250, numObservations: 6
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 10897 episodes
GETTING ACTION FROM:
action 4, numVisits=13989, meanQ=11.410535, numObservations: 9
action 2, numVisits=9, meanQ=6.276667, numObservations: 6
action 3, numVisits=9, meanQ=4.981854, numObservations: 5
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action -1, numVisits=3, meanQ=-1.340000, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.375615 0.559465 0.949637 0.908616 0.460475 0.440744 0.0749653 0.28796 0.828118 0.589128 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=1150, meanQ=12.225662, numObservations: 9
action 2, numVisits=21, meanQ=9.194166, numObservations: 7
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 6181 episodes
GETTING ACTION FROM:
action 3, numVisits=7249, meanQ=8.941447, numObservations: 9
action 5, numVisits=9, meanQ=1.913099, numObservations: 7
action -1, numVisits=8, meanQ=-1.133750, numObservations: 8
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=32, meanQ=-6.680828, numObservations: 8
action 0, numVisits=59, meanQ=-7.629040, numObservations: 36
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.375615 0.559465 0.949637 0.908616 0.460475 0.440744 0.0749653 0.28796 0.828118 0.589128 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 6
Initial state: 0 0.230498 0.272885 0.575974 0.351817 0.823813 0.71539 0.797783 0.616764 0.459867 0.466554 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30884 episodes
GETTING ACTION FROM:
action 4, numVisits=30865, meanQ=10.891669, numObservations: 9
action 5, numVisits=12, meanQ=5.167508, numObservations: 5
action 1, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 1 0.230498 0.272885 0.575974 0.351817 0.823813 0.71539 0.797783 0.616764 0.459867 0.466554 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 7
Initial state: 0 0.694713 0.684477 0.207118 0.183962 0.450031 0.427975 0.576401 0.132986 0.459433 0.205149 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31112 episodes
GETTING ACTION FROM:
action 1, numVisits=31092, meanQ=11.100294, numObservations: 9
action 3, numVisits=15, meanQ=7.066680, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.694713 0.684477 0.207118 0.183962 0.450031 0.427975 0.576401 0.132986 0.459433 0.205149 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 8
Initial state: 0 0.677567 0.0732525 0.501298 0.514994 0.76837 0.797105 0.0871054 0.17267 0.678709 0.829952 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31027 episodes
GETTING ACTION FROM:
action 2, numVisits=31019, meanQ=11.356632, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.677567 0.0732525 0.501298 0.514994 0.76837 0.797105 0.0871054 0.17267 0.678709 0.829952 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 9
Initial state: 0 0.0400276 0.415826 0.849767 0.376338 0.775062 0.216571 0.308571 0.894845 0.485454 0.538534 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29211 episodes
GETTING ACTION FROM:
action 3, numVisits=29201, meanQ=11.500994, numObservations: 9
action 4, numVisits=3, meanQ=5.333333, numObservations: 3
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.0400276 0.415826 0.849767 0.376338 0.775062 0.216571 0.308571 0.894845 0.485454 0.538534 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 10
Initial state: 0 0.858773 0.278193 0.868972 0.259331 0.448298 0.44995 0.903637 0.146278 0.604434 0.410917 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18235 episodes
GETTING ACTION FROM:
action -1, numVisits=18203, meanQ=14.667140, numObservations: 243
action 2, numVisits=12, meanQ=-1.664133, numObservations: 6
action 0, numVisits=14, meanQ=-1.858571, numObservations: 13
action 5, numVisits=2, meanQ=-4.000000, numObservations: 2
action 3, numVisits=2, meanQ=-7.500000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.858773 0.278193 0.868972 0.259331 0.448298 0.44995 0.903637 0.146278 0.604434 0.410917 w: 1
Observation: 0 3 0 3 0 2 0 3 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=66, meanQ=14.055761, numObservations: 9
action 1, numVisits=5, meanQ=3.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 36150 episodes
GETTING ACTION FROM:
action 5, numVisits=36216, meanQ=16.032101, numObservations: 9
action 1, numVisits=5, meanQ=3.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.858773 0.278193 0.868972 0.259331 0.448298 0.44995 0.903637 0.146278 0.604434 0.410917 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 11
Initial state: 0 0.658442 0.251745 0.357467 0.524721 0.332986 0.353101 0.969585 0.392108 0.494035 0.500417 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30764 episodes
GETTING ACTION FROM:
action 3, numVisits=30723, meanQ=10.879095, numObservations: 9
action 5, numVisits=34, meanQ=7.684424, numObservations: 9
action 1, numVisits=3, meanQ=5.000033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.658442 0.251745 0.357467 0.524721 0.332986 0.353101 0.969585 0.392108 0.494035 0.500417 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=954, meanQ=8.977127, numObservations: 227
action -1, numVisits=7, meanQ=-2.991414, numObservations: 5
action 4, numVisits=2, meanQ=-3.010000, numObservations: 2
action 5, numVisits=2, meanQ=-4.004950, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 4851 episodes
GETTING ACTION FROM:
action 0, numVisits=5805, meanQ=7.963439, numObservations: 243
action -1, numVisits=7, meanQ=-2.991414, numObservations: 5
action 4, numVisits=2, meanQ=-3.010000, numObservations: 2
action 5, numVisits=2, meanQ=-4.004950, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.658442 0.251745 0.357467 0.524721 0.332986 0.353101 0.969585 0.392108 0.494035 0.500417 w: 1
Observation: 0 0 1 0 2 0 1 0 2 0 2 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 9885 episodes
GETTING ACTION FROM:
action 2, numVisits=9806, meanQ=14.189714, numObservations: 9
action -1, numVisits=23, meanQ=-1.897236, numObservations: 16
action 0, numVisits=15, meanQ=-1.946636, numObservations: 14
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=38, meanQ=-19.011068, numObservations: 8
action: 2
Next state: 0 0.658442 0.251745 0.357467 0.524721 0.332986 0.353101 0.969585 0.392108 0.494035 0.500417 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 4, numVisits=392, meanQ=16.518561, numObservations: 9
action 5, numVisits=4, meanQ=7.061712, numObservations: 3
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-10.548551, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-1067.663596, numObservations: 1
Sampled 19469 episodes
GETTING ACTION FROM:
action 4, numVisits=19861, meanQ=16.040614, numObservations: 9
action 5, numVisits=4, meanQ=7.061712, numObservations: 3
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-10.548551, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-1067.663596, numObservations: 1
action: 4
Next state: 2 0.658442 0.251745 0.357467 0.524721 0.332986 0.353101 0.969585 0.392108 0.494035 0.500417 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -20.5737
Run # 12
Initial state: 0 0.325676 0.864332 0.209398 0.094314 0.0181543 0.137008 0.419932 0.5064 0.637611 0.662382 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30915 episodes
GETTING ACTION FROM:
action 4, numVisits=30904, meanQ=11.063778, numObservations: 9
action 3, numVisits=6, meanQ=4.331667, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.325676 0.864332 0.209398 0.094314 0.0181543 0.137008 0.419932 0.5064 0.637611 0.662382 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 13
Initial state: 0 0.782054 0.881089 0.0659598 0.177052 0.0670878 0.0362393 0.163799 0.980982 0.40635 0.513624 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30943 episodes
GETTING ACTION FROM:
action 5, numVisits=30934, meanQ=11.122567, numObservations: 9
action 1, numVisits=4, meanQ=1.250000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 1 0.782054 0.881089 0.0659598 0.177052 0.0670878 0.0362393 0.163799 0.980982 0.40635 0.513624 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 14
Initial state: 0 0.41344 0.258724 0.492388 0.451805 0.0198093 0.608233 0.0763976 0.857468 0.624782 0.985481 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30892 episodes
GETTING ACTION FROM:
action 2, numVisits=30879, meanQ=11.412904, numObservations: 9
action 4, numVisits=7, meanQ=7.282857, numObservations: 6
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.41344 0.258724 0.492388 0.451805 0.0198093 0.608233 0.0763976 0.857468 0.624782 0.985481 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 15
Initial state: 0 0.160914 0.545432 0.171994 0.132865 0.194268 0.561799 0.464219 0.399543 0.877506 0.332617 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30590 episodes
GETTING ACTION FROM:
action 3, numVisits=30579, meanQ=10.980888, numObservations: 9
action 1, numVisits=6, meanQ=4.165017, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.160914 0.545432 0.171994 0.132865 0.194268 0.561799 0.464219 0.399543 0.877506 0.332617 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=3083, meanQ=11.725602, numObservations: 9
action 5, numVisits=6, meanQ=8.831683, numObservations: 4
action 1, numVisits=8, meanQ=8.497500, numObservations: 4
action 3, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 13721 episodes
GETTING ACTION FROM:
action 5, numVisits=13724, meanQ=13.111561, numObservations: 9
action 4, numVisits=3083, meanQ=11.725602, numObservations: 9
action 3, numVisits=3, meanQ=5.993333, numObservations: 3
action 1, numVisits=9, meanQ=5.898889, numObservations: 4
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.160914 0.545432 0.171994 0.132865 0.194268 0.561799 0.464219 0.399543 0.877506 0.332617 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 16
Initial state: 0 0.707069 0.209744 0.0643528 0.543644 0.188243 0.76365 0.481015 0.458717 0.749392 0.566629 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30502 episodes
GETTING ACTION FROM:
action 5, numVisits=30482, meanQ=11.067627, numObservations: 9
action 2, numVisits=15, meanQ=6.784013, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.707069 0.209744 0.0643528 0.543644 0.188243 0.76365 0.481015 0.458717 0.749392 0.566629 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 17
Initial state: 0 0.48807 0.128841 0.00191951 0.633587 0.412143 0.484127 0.732127 0.910252 0.893534 0.951078 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30948 episodes
GETTING ACTION FROM:
action 2, numVisits=30940, meanQ=11.199098, numObservations: 9
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action 4, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.48807 0.128841 0.00191951 0.633587 0.412143 0.484127 0.732127 0.910252 0.893534 0.951078 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 18
Initial state: 0 0.862857 0.712513 0.364149 0.405043 0.667829 0.616641 0.47714 0.452375 0.607604 0.276889 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30962 episodes
GETTING ACTION FROM:
action 3, numVisits=30944, meanQ=11.152045, numObservations: 9
action 2, numVisits=10, meanQ=0.200000, numObservations: 4
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=2, meanQ=-7.500000, numObservations: 2
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.862857 0.712513 0.364149 0.405043 0.667829 0.616641 0.47714 0.452375 0.607604 0.276889 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 19
Initial state: 0 0.798112 0.922225 0.49282 0.418147 0.560147 0.188625 0.457141 0.760085 0.285439 0.223031 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30959 episodes
GETTING ACTION FROM:
action 1, numVisits=30949, meanQ=10.901960, numObservations: 9
action 3, numVisits=5, meanQ=5.402020, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.798112 0.922225 0.49282 0.418147 0.560147 0.188625 0.457141 0.760085 0.285439 0.223031 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 20
Initial state: 0 0.700414 0.818397 0.426373 0.474712 0.226231 0.8466 0.571951 0.0556979 0.283348 0.106216 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31191 episodes
GETTING ACTION FROM:
action 3, numVisits=30338, meanQ=11.244226, numObservations: 9
action 5, numVisits=847, meanQ=10.787587, numObservations: 9
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.700414 0.818397 0.426373 0.474712 0.226231 0.8466 0.571951 0.0556979 0.283348 0.106216 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=249, meanQ=13.019614, numObservations: 9
action 1, numVisits=3, meanQ=3.330000, numObservations: 3
action 4, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 36032 episodes
GETTING ACTION FROM:
action 5, numVisits=36279, meanQ=14.712453, numObservations: 9
action 1, numVisits=3, meanQ=3.330000, numObservations: 3
action 4, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 0 0.700414 0.818397 0.426373 0.474712 0.226231 0.8466 0.571951 0.0556979 0.283348 0.106216 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 0, numVisits=84, meanQ=3.574023, numObservations: 48
action -1, numVisits=8, meanQ=-1.010000, numObservations: 8
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=58, meanQ=-6.430709, numObservations: 6
action 1, numVisits=34, meanQ=-15.969220, numObservations: 8
Sampled 27687 episodes
GETTING ACTION FROM:
action 2, numVisits=27496, meanQ=16.149957, numObservations: 9
action 4, numVisits=4, meanQ=-0.252500, numObservations: 2
action -1, numVisits=14, meanQ=-1.434286, numObservations: 13
action 0, numVisits=267, meanQ=-1.598780, numObservations: 92
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=58, meanQ=-6.430709, numObservations: 6
action 1, numVisits=34, meanQ=-15.969220, numObservations: 8
action: 2
Next state: 1 0.700414 0.818397 0.426373 0.474712 0.226231 0.8466 0.571951 0.0556979 0.283348 0.106216 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 21
Initial state: 0 0.988729 0.206518 0.967051 0.722378 0.607248 0.557499 0.417611 0.473174 0.445192 0.0714426 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30824 episodes
GETTING ACTION FROM:
action 3, numVisits=30788, meanQ=11.243878, numObservations: 9
action 4, numVisits=31, meanQ=5.971297, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.988729 0.206518 0.967051 0.722378 0.607248 0.557499 0.417611 0.473174 0.445192 0.0714426 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 22
Initial state: 0 0.48084 0.395992 0.192867 0.840517 0.80725 0.948629 0.984924 0.214571 0.0783222 0.10423 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30800 episodes
GETTING ACTION FROM:
action 5, numVisits=30729, meanQ=11.356009, numObservations: 9
action 2, numVisits=50, meanQ=10.362410, numObservations: 8
action 1, numVisits=17, meanQ=9.707076, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.48084 0.395992 0.192867 0.840517 0.80725 0.948629 0.984924 0.214571 0.0783222 0.10423 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=3140, meanQ=12.232278, numObservations: 9
action 2, numVisits=18, meanQ=9.787778, numObservations: 8
action 1, numVisits=5, meanQ=6.196000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 10407 episodes
GETTING ACTION FROM:
action 4, numVisits=13498, meanQ=12.444876, numObservations: 9
action 2, numVisits=65, meanQ=10.587433, numObservations: 9
action 1, numVisits=5, meanQ=6.196000, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.48084 0.395992 0.192867 0.840517 0.80725 0.948629 0.984924 0.214571 0.0783222 0.10423 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=197, meanQ=15.576075, numObservations: 9
action 2, numVisits=7, meanQ=6.282857, numObservations: 6
action 1, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 27559 episodes
GETTING ACTION FROM:
action 3, numVisits=27717, meanQ=8.884581, numObservations: 9
action 2, numVisits=38, meanQ=6.920526, numObservations: 9
action 1, numVisits=4, meanQ=-0.252500, numObservations: 4
action 0, numVisits=6, meanQ=-1.505000, numObservations: 6
action -1, numVisits=5, meanQ=-1.604000, numObservations: 5
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.48084 0.395992 0.192867 0.840517 0.80725 0.948629 0.984924 0.214571 0.0783222 0.10423 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 23
Initial state: 0 0.657633 0.936916 0.798431 0.669682 0.241314 0.407283 0.446028 0.435147 0.195268 0.692094 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30561 episodes
GETTING ACTION FROM:
action 1, numVisits=30550, meanQ=11.018454, numObservations: 9
action 4, numVisits=4, meanQ=6.500000, numObservations: 4
action 5, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.657633 0.936916 0.798431 0.669682 0.241314 0.407283 0.446028 0.435147 0.195268 0.692094 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 24
Initial state: 0 0.172152 0.998709 0.423362 0.442164 0.364086 0.0933962 0.142837 0.753142 0.798317 0.419115 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30939 episodes
GETTING ACTION FROM:
action 4, numVisits=30929, meanQ=10.949298, numObservations: 9
action 1, numVisits=3, meanQ=0.666667, numObservations: 3
action 5, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.172152 0.998709 0.423362 0.442164 0.364086 0.0933962 0.142837 0.753142 0.798317 0.419115 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=172, meanQ=11.429071, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=3, meanQ=-1.673300, numObservations: 2
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 38151 episodes
GETTING ACTION FROM:
action 3, numVisits=38323, meanQ=14.956070, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=3, meanQ=-1.673300, numObservations: 2
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.172152 0.998709 0.423362 0.442164 0.364086 0.0933962 0.142837 0.753142 0.798317 0.419115 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=151, meanQ=12.346522, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 33188 episodes
GETTING ACTION FROM:
action 5, numVisits=33339, meanQ=15.245445, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.172152 0.998709 0.423362 0.442164 0.364086 0.0933962 0.142837 0.753142 0.798317 0.419115 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 25
Initial state: 0 0.2503 0.849449 0.966965 0.753675 0.442023 0.531887 0.856109 0.106315 0.690445 0.340231 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30960 episodes
GETTING ACTION FROM:
action 3, numVisits=30954, meanQ=11.371877, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.2503 0.849449 0.966965 0.753675 0.442023 0.531887 0.856109 0.106315 0.690445 0.340231 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 26
Initial state: 0 0.439368 0.390406 0.858215 0.331051 0.730324 0.605507 0.332353 0.771418 0.562057 0.082114 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28180 episodes
GETTING ACTION FROM:
action 3, numVisits=28170, meanQ=11.076570, numObservations: 9
action 4, numVisits=5, meanQ=4.598000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.439368 0.390406 0.858215 0.331051 0.730324 0.605507 0.332353 0.771418 0.562057 0.082114 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 27
Initial state: 0 0.926221 0.992112 0.231583 0.0599855 0.561268 0.350992 0.461787 0.430246 0.588553 0.267819 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31118 episodes
GETTING ACTION FROM:
action 2, numVisits=31110, meanQ=11.327359, numObservations: 9
action 5, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.926221 0.992112 0.231583 0.0599855 0.561268 0.350992 0.461787 0.430246 0.588553 0.267819 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 28
Initial state: 0 0.679037 0.736343 0.27589 0.243166 0.459639 0.0195004 0.483607 0.504077 0.696427 0.604099 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30723 episodes
GETTING ACTION FROM:
action 4, numVisits=30681, meanQ=11.078057, numObservations: 9
action 1, numVisits=35, meanQ=6.970866, numObservations: 9
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 1 0.679037 0.736343 0.27589 0.243166 0.459639 0.0195004 0.483607 0.504077 0.696427 0.604099 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 29
Initial state: 0 0.238393 0.543494 0.771773 0.266738 0.496239 0.352379 0.00659275 0.992445 0.477783 0.363299 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29940 episodes
GETTING ACTION FROM:
action 5, numVisits=29932, meanQ=11.321424, numObservations: 9
action 2, numVisits=3, meanQ=5.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.238393 0.543494 0.771773 0.266738 0.496239 0.352379 0.00659275 0.992445 0.477783 0.363299 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 30
Initial state: 0 0.013081 0.863474 0.419182 0.470305 0.227313 0.841541 0.58509 0.149927 0.228719 0.912841 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30952 episodes
GETTING ACTION FROM:
action 1, numVisits=30938, meanQ=11.180574, numObservations: 9
action 2, numVisits=7, meanQ=6.282857, numObservations: 5
action 5, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.013081 0.863474 0.419182 0.470305 0.227313 0.841541 0.58509 0.149927 0.228719 0.912841 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=3015, meanQ=12.646211, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 13526 episodes
GETTING ACTION FROM:
action 4, numVisits=16539, meanQ=13.834613, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.013081 0.863474 0.419182 0.470305 0.227313 0.841541 0.58509 0.149927 0.228719 0.912841 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 31
Initial state: 0 0.967561 0.642176 0.912606 0.290371 0.41377 0.388495 0.0238724 0.424041 0.0412026 0.53113 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30792 episodes
GETTING ACTION FROM:
action 5, numVisits=30781, meanQ=11.108207, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 4, numVisits=2, meanQ=-4.000000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.967561 0.642176 0.912606 0.290371 0.41377 0.388495 0.0238724 0.424041 0.0412026 0.53113 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=3143, meanQ=11.389242, numObservations: 9
action 3, numVisits=3, meanQ=3.330000, numObservations: 3
action 2, numVisits=7, meanQ=3.281443, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 10866 episodes
GETTING ACTION FROM:
action 1, numVisits=14005, meanQ=11.771339, numObservations: 9
action 3, numVisits=3, meanQ=3.330000, numObservations: 3
action 2, numVisits=7, meanQ=3.281443, numObservations: 5
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.967561 0.642176 0.912606 0.290371 0.41377 0.388495 0.0238724 0.424041 0.0412026 0.53113 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 32
Initial state: 0 0.0605501 0.980644 0.408835 0.468839 0.264567 0.592652 0.624153 0.139199 0.0795735 0.19479 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30804 episodes
GETTING ACTION FROM:
action 2, numVisits=30794, meanQ=11.082747, numObservations: 9
action 3, numVisits=5, meanQ=5.998000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.0605501 0.980644 0.408835 0.468839 0.264567 0.592652 0.624153 0.139199 0.0795735 0.19479 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 33
Initial state: 0 0.950947 0.144569 0.271605 0.608781 0.475555 0.390044 0.166642 0.820525 0.10463 0.182366 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31050 episodes
GETTING ACTION FROM:
action 4, numVisits=31039, meanQ=11.188045, numObservations: 9
action 3, numVisits=3, meanQ=0.666667, numObservations: 3
action 2, numVisits=4, meanQ=-0.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.950947 0.144569 0.271605 0.608781 0.475555 0.390044 0.166642 0.820525 0.10463 0.182366 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=304, meanQ=10.993279, numObservations: 9
action 2, numVisits=4, meanQ=1.745000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 18790 episodes
GETTING ACTION FROM:
action 5, numVisits=19089, meanQ=13.963689, numObservations: 9
action 2, numVisits=4, meanQ=1.745000, numObservations: 4
action -1, numVisits=4, meanQ=-1.505000, numObservations: 4
action 0, numVisits=3, meanQ=-1.670000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.950947 0.144569 0.271605 0.608781 0.475555 0.390044 0.166642 0.820525 0.10463 0.182366 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=9, meanQ=6.823834, numObservations: 5
action 1, numVisits=4, meanQ=5.341465, numObservations: 3
action 0, numVisits=18, meanQ=0.595259, numObservations: 15
action -1, numVisits=10, meanQ=-2.641053, numObservations: 8
action 5, numVisits=1, meanQ=-12.940458, numObservations: 1
action 2, numVisits=1, meanQ=-13.638700, numObservations: 1
action 4, numVisits=1, meanQ=-1055.424646, numObservations: 1
Sampled 28080 episodes
GETTING ACTION FROM:
action 1, numVisits=28080, meanQ=13.068831, numObservations: 9
action 3, numVisits=11, meanQ=6.764955, numObservations: 5
action 0, numVisits=20, meanQ=0.335733, numObservations: 16
action -1, numVisits=10, meanQ=-2.641053, numObservations: 8
action 5, numVisits=1, meanQ=-12.940458, numObservations: 1
action 2, numVisits=1, meanQ=-13.638700, numObservations: 1
action 4, numVisits=1, meanQ=-1055.424646, numObservations: 1
action: 1
Next state: 2 0.950947 0.144569 0.271605 0.608781 0.475555 0.390044 0.166642 0.820525 0.10463 0.182366 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -18.7411
Run # 34
Initial state: 0 0.0589559 0.45061 0.311946 0.401571 0.576229 0.0473388 0.0846629 0.857289 0.443105 0.376937 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30594 episodes
GETTING ACTION FROM:
action 5, numVisits=30512, meanQ=11.065366, numObservations: 9
action 4, numVisits=71, meanQ=8.920427, numObservations: 9
action 3, numVisits=7, meanQ=7.424286, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.0589559 0.45061 0.311946 0.401571 0.576229 0.0473388 0.0846629 0.857289 0.443105 0.376937 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 35
Initial state: 0 0.0213708 0.852276 0.187639 0.271268 0.639577 0.722322 0.81861 0.302254 0.416505 0.476534 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30520 episodes
GETTING ACTION FROM:
action 4, numVisits=30504, meanQ=11.046751, numObservations: 9
action 3, numVisits=7, meanQ=6.998586, numObservations: 4
action 1, numVisits=3, meanQ=3.330000, numObservations: 3
action 2, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 2 0.0213708 0.852276 0.187639 0.271268 0.639577 0.722322 0.81861 0.302254 0.416505 0.476534 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 36
Initial state: 0 0.536898 0.772623 0.462632 0.518861 0.287853 0.591922 0.763007 0.780366 0.383575 0.18409 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18137 episodes
GETTING ACTION FROM:
action 0, numVisits=18095, meanQ=15.257763, numObservations: 243
action -1, numVisits=25, meanQ=-1.168796, numObservations: 24
action 5, numVisits=10, meanQ=-1.801000, numObservations: 7
action 3, numVisits=2, meanQ=-4.000000, numObservations: 2
action 1, numVisits=3, meanQ=-7.630000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.536898 0.772623 0.462632 0.518861 0.287853 0.591922 0.763007 0.780366 0.383575 0.18409 w: 1
Observation: 0 0 3 0 2 0 3 0 3 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=111, meanQ=20.532615, numObservations: 9
action 3, numVisits=5, meanQ=13.196000, numObservations: 3
action 4, numVisits=5, meanQ=11.598000, numObservations: 3
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 38937 episodes
GETTING ACTION FROM:
action 2, numVisits=39048, meanQ=22.492513, numObservations: 9
action 3, numVisits=5, meanQ=13.196000, numObservations: 3
action 4, numVisits=5, meanQ=11.598000, numObservations: 3
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.536898 0.772623 0.462632 0.518861 0.287853 0.591922 0.763007 0.780366 0.383575 0.18409 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 37
Initial state: 0 0.527428 0.961213 0.69011 0.0916949 0.436844 0.525821 0.678974 0.123001 0.0426666 0.743313 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30892 episodes
GETTING ACTION FROM:
action 4, numVisits=30881, meanQ=11.402994, numObservations: 9
action 1, numVisits=5, meanQ=7.200000, numObservations: 4
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 2 0.527428 0.961213 0.69011 0.0916949 0.436844 0.525821 0.678974 0.123001 0.0426666 0.743313 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 38
Initial state: 0 0.211101 0.24052 0.886735 0.0801893 0.429098 0.358038 0.934226 0.785343 0.823262 0.973263 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30944 episodes
GETTING ACTION FROM:
action 3, numVisits=30936, meanQ=11.270919, numObservations: 9
action 4, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.211101 0.24052 0.886735 0.0801893 0.429098 0.358038 0.934226 0.785343 0.823262 0.973263 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 39
Initial state: 0 0.903273 0.339529 0.295953 0.558504 0.446654 0.531629 0.390186 0.375255 0.430319 0.973947 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18058 episodes
GETTING ACTION FROM:
action 0, numVisits=18035, meanQ=15.248145, numObservations: 243
action -1, numVisits=15, meanQ=-1.274660, numObservations: 14
action 3, numVisits=3, meanQ=-4.993300, numObservations: 2
action 5, numVisits=2, meanQ=-7.500000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.903273 0.339529 0.295953 0.558504 0.446654 0.531629 0.390186 0.375255 0.430319 0.973947 w: 1
Observation: 0 0 1 0 3 0 2 0 2 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=61, meanQ=14.777109, numObservations: 8
action 3, numVisits=5, meanQ=10.000000, numObservations: 4
action 4, numVisits=4, meanQ=6.500000, numObservations: 3
action 5, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 29503 episodes
GETTING ACTION FROM:
action 2, numVisits=29564, meanQ=16.407960, numObservations: 9
action 3, numVisits=5, meanQ=10.000000, numObservations: 4
action 4, numVisits=4, meanQ=6.500000, numObservations: 3
action 5, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.903273 0.339529 0.295953 0.558504 0.446654 0.531629 0.390186 0.375255 0.430319 0.973947 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=6171, meanQ=15.839399, numObservations: 9
action 3, numVisits=4, meanQ=1.745000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 14297 episodes
GETTING ACTION FROM:
action 4, numVisits=14288, meanQ=18.581517, numObservations: 9
action 2, numVisits=6175, meanQ=15.842931, numObservations: 9
action 3, numVisits=4, meanQ=1.745000, numObservations: 3
action -1, numVisits=4, meanQ=-1.257500, numObservations: 3
action 0, numVisits=4, meanQ=-1.257500, numObservations: 4
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.903273 0.339529 0.295953 0.558504 0.446654 0.531629 0.390186 0.375255 0.430319 0.973947 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -16.7411
Run # 40
Initial state: 0 0.625016 0.604723 0.407036 0.463418 0.663512 0.623759 0.527456 0.107588 0.0224427 0.853284 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31014 episodes
GETTING ACTION FROM:
action 4, numVisits=30988, meanQ=11.286347, numObservations: 9
action 3, numVisits=10, meanQ=7.999000, numObservations: 7
action 5, numVisits=11, meanQ=7.814545, numObservations: 8
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 2 0.625016 0.604723 0.407036 0.463418 0.663512 0.623759 0.527456 0.107588 0.0224427 0.853284 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 41
Initial state: 0 0.169784 0.73981 0.426536 0.376888 0.611229 0.687951 0.860023 0.988111 0.992925 0.2404 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28094 episodes
GETTING ACTION FROM:
action 2, numVisits=28078, meanQ=10.772005, numObservations: 9
action 3, numVisits=11, meanQ=6.644545, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.169784 0.73981 0.426536 0.376888 0.611229 0.687951 0.860023 0.988111 0.992925 0.2404 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 42
Initial state: 0 0.744937 0.708183 0.474426 0.445492 0.43002 0.162035 0.697937 0.568662 0.714413 0.357049 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30364 episodes
GETTING ACTION FROM:
action 5, numVisits=30352, meanQ=11.387860, numObservations: 9
action 3, numVisits=4, meanQ=1.250000, numObservations: 3
action 4, numVisits=4, meanQ=1.250000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.744937 0.708183 0.474426 0.445492 0.43002 0.162035 0.697937 0.568662 0.714413 0.357049 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 43
Initial state: 0 0.818229 0.503599 0.94012 0.414874 0.43172 0.47968 0.203892 0.792009 0.591469 0.606662 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30741 episodes
GETTING ACTION FROM:
action 2, numVisits=30732, meanQ=11.105352, numObservations: 9
action 4, numVisits=2, meanQ=6.500000, numObservations: 2
action 5, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 2 0.818229 0.503599 0.94012 0.414874 0.43172 0.47968 0.203892 0.792009 0.591469 0.606662 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 44
Initial state: 0 0.614811 0.590083 0.46426 0.473125 0.211305 0.649491 0.828289 0.354685 0.894384 0.0771393 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30716 episodes
GETTING ACTION FROM:
action 3, numVisits=30710, meanQ=11.192374, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.614811 0.590083 0.46426 0.473125 0.211305 0.649491 0.828289 0.354685 0.894384 0.0771393 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=3091, meanQ=12.419150, numObservations: 9
action 2, numVisits=3, meanQ=5.993333, numObservations: 3
action 5, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 11353 episodes
GETTING ACTION FROM:
action 4, numVisits=14396, meanQ=13.237151, numObservations: 9
action 2, numVisits=49, meanQ=9.834723, numObservations: 9
action 5, numVisits=3, meanQ=3.330000, numObservations: 3
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.614811 0.590083 0.46426 0.473125 0.211305 0.649491 0.828289 0.354685 0.894384 0.0771393 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 45
Initial state: 0 0.820393 0.247155 0.204282 0.472052 0.295025 0.797239 0.468865 0.00898563 0.400278 0.545685 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30968 episodes
GETTING ACTION FROM:
action 5, numVisits=30958, meanQ=11.217157, numObservations: 9
action 1, numVisits=5, meanQ=4.598000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.820393 0.247155 0.204282 0.472052 0.295025 0.797239 0.468865 0.00898563 0.400278 0.545685 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 46
Initial state: 0 0.188295 0.565042 0.55469 0.00109823 0.910364 0.927008 0.411565 0.750561 0.495259 0.408085 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30767 episodes
GETTING ACTION FROM:
action 1, numVisits=30739, meanQ=10.984019, numObservations: 9
action 5, numVisits=13, meanQ=4.614623, numObservations: 7
action 3, numVisits=11, meanQ=4.452727, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.188295 0.565042 0.55469 0.00109823 0.910364 0.927008 0.411565 0.750561 0.495259 0.408085 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=3151, meanQ=12.328428, numObservations: 9
action 4, numVisits=6, meanQ=3.330000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 14261 episodes
GETTING ACTION FROM:
action 3, numVisits=17410, meanQ=12.926648, numObservations: 9
action 4, numVisits=6, meanQ=3.330000, numObservations: 4
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.188295 0.565042 0.55469 0.00109823 0.910364 0.927008 0.411565 0.750561 0.495259 0.408085 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 47
Initial state: 0 0.375783 0.44881 0.856842 0.304751 0.298137 0.653606 0.416769 0.489779 0.709306 0.180497 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30912 episodes
GETTING ACTION FROM:
action 1, numVisits=30902, meanQ=11.172133, numObservations: 9
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action 4, numVisits=3, meanQ=5.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.375783 0.44881 0.856842 0.304751 0.298137 0.653606 0.416769 0.489779 0.709306 0.180497 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 48
Initial state: 0 0.459805 0.458587 0.63009 0.0933522 0.0828465 0.213787 0.864126 0.812255 0.781521 0.674938 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30938 episodes
GETTING ACTION FROM:
action 2, numVisits=30927, meanQ=11.250881, numObservations: 9
action 5, numVisits=4, meanQ=-0.252500, numObservations: 4
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.459805 0.458587 0.63009 0.0933522 0.0828465 0.213787 0.864126 0.812255 0.781521 0.674938 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 49
Initial state: 0 0.661321 0.278374 0.429391 0.546417 0.730517 0.276999 0.332012 0.491473 0.32101 0.221458 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29912 episodes
GETTING ACTION FROM:
action 4, numVisits=29904, meanQ=11.167097, numObservations: 9
action 2, numVisits=3, meanQ=5.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.661321 0.278374 0.429391 0.546417 0.730517 0.276999 0.332012 0.491473 0.32101 0.221458 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=900, meanQ=14.026543, numObservations: 9
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 10726 episodes
GETTING ACTION FROM:
action 3, numVisits=11591, meanQ=11.829326, numObservations: 9
action 0, numVisits=10, meanQ=-1.307000, numObservations: 10
action -1, numVisits=8, meanQ=-1.505000, numObservations: 8
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=21, meanQ=-38.624701, numObservations: 8
action: 3
Next state: 2 0.661321 0.278374 0.429391 0.546417 0.730517 0.276999 0.332012 0.491473 0.32101 0.221458 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 50
Initial state: 0 0.219365 0.245456 0.187634 0.409996 0.494087 0.400602 0.213129 0.711952 0.0852665 0.738936 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30551 episodes
GETTING ACTION FROM:
action 1, numVisits=30543, meanQ=11.408419, numObservations: 9
action 3, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.219365 0.245456 0.187634 0.409996 0.494087 0.400602 0.213129 0.711952 0.0852665 0.738936 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=3176, meanQ=12.242917, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 13327 episodes
GETTING ACTION FROM:
action 4, numVisits=16501, meanQ=13.365762, numObservations: 9
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.219365 0.245456 0.187634 0.409996 0.494087 0.400602 0.213129 0.711952 0.0852665 0.738936 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=837, meanQ=14.593643, numObservations: 9
action 3, numVisits=4, meanQ=7.525000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 21316 episodes
GETTING ACTION FROM:
action 5, numVisits=22151, meanQ=14.637439, numObservations: 9
action 3, numVisits=4, meanQ=7.525000, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.219365 0.245456 0.187634 0.409996 0.494087 0.400602 0.213129 0.711952 0.0852665 0.738936 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=461, meanQ=18.499443, numObservations: 9
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 17988 episodes
GETTING ACTION FROM:
action 2, numVisits=18449, meanQ=20.308918, numObservations: 9
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.219365 0.245456 0.187634 0.409996 0.494087 0.400602 0.213129 0.711952 0.0852665 0.738936 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 2, numVisits=3, meanQ=-0.219798, numObservations: 2
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action -1, numVisits=22, meanQ=-7.066137, numObservations: 11
action 5, numVisits=1, meanQ=-9.146540, numObservations: 1
action 3, numVisits=1, meanQ=-10.308075, numObservations: 1
action 1, numVisits=1, meanQ=-361.775811, numObservations: 1
action 4, numVisits=1, meanQ=-363.354669, numObservations: 1
Sampled 30475 episodes
GETTING ACTION FROM:
action 3, numVisits=30003, meanQ=18.249443, numObservations: 9
action 2, numVisits=370, meanQ=16.491681, numObservations: 9
action 0, numVisits=112, meanQ=-4.369606, numObservations: 44
action -1, numVisits=22, meanQ=-7.066137, numObservations: 11
action 5, numVisits=1, meanQ=-9.146540, numObservations: 1
action 1, numVisits=1, meanQ=-361.775811, numObservations: 1
action 4, numVisits=1, meanQ=-363.354669, numObservations: 1
action: 3
Next state: 1 0.219365 0.245456 0.187634 0.409996 0.494087 0.400602 0.213129 0.711952 0.0852665 0.738936 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.29271
[32m ProblemEnvironment.hpp 351: Done.[39m
