Run # 1
Initial state: 0 0.882169 0.187509 0.256328 0.510111 0.276781 0.134487 0.344512 0.861885 0.479683 0.545942 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28457 episodes
GETTING ACTION FROM:
action 3, numVisits=28429, meanQ=8.429882, numObservations: 9
action 5, numVisits=13, meanQ=2.676946, numObservations: 6
action 1, numVisits=5, meanQ=1.798000, numObservations: 5
action 4, numVisits=7, meanQ=1.141429, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.882169 0.187509 0.256328 0.510111 0.276781 0.134487 0.344512 0.861885 0.479683 0.545942 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=4100, meanQ=9.591350, numObservations: 9
action 1, numVisits=5, meanQ=0.794000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 8170 episodes
GETTING ACTION FROM:
action 2, numVisits=12251, meanQ=9.105833, numObservations: 9
action 5, numVisits=4, meanQ=1.576452, numObservations: 4
action 1, numVisits=5, meanQ=0.794000, numObservations: 5
action -1, numVisits=9, meanQ=-1.120000, numObservations: 9
action 0, numVisits=9, meanQ=-1.120000, numObservations: 9
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.882169 0.187509 0.256328 0.510111 0.276781 0.134487 0.344512 0.861885 0.479683 0.545942 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=123, meanQ=1.211265, numObservations: 8
action -1, numVisits=17, meanQ=-2.551900, numObservations: 13
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=2, meanQ=-7.005000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=48, meanQ=-20.990516, numObservations: 27
Sampled 19877 episodes
GETTING ACTION FROM:
action 4, numVisits=19656, meanQ=12.097096, numObservations: 9
action 3, numVisits=25, meanQ=9.044000, numObservations: 4
action 2, numVisits=123, meanQ=1.211265, numObservations: 8
action -1, numVisits=216, meanQ=-4.224176, numObservations: 76
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=48, meanQ=-20.990516, numObservations: 27
action: 4
Next state: 0 0.882169 0.187509 0.256328 0.510111 0.276781 0.134487 0.344512 0.861885 0.479683 0.545942 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=1, meanQ=24.000000, numObservations: 1
action 0, numVisits=164, meanQ=5.696229, numObservations: 56
action 1, numVisits=1, meanQ=-9.948484, numObservations: 1
action 5, numVisits=1, meanQ=-10.507658, numObservations: 1
action 4, numVisits=1, meanQ=-11.479656, numObservations: 1
action -1, numVisits=18, meanQ=-22.544687, numObservations: 9
action 3, numVisits=1, meanQ=-538.905627, numObservations: 1
Sampled 12610 episodes
GETTING ACTION FROM:
action 2, numVisits=408, meanQ=22.779412, numObservations: 9
action 0, numVisits=12367, meanQ=-0.732041, numObservations: 206
action 1, numVisits=1, meanQ=-9.948484, numObservations: 1
action 5, numVisits=1, meanQ=-10.507658, numObservations: 1
action 4, numVisits=1, meanQ=-11.479656, numObservations: 1
action -1, numVisits=18, meanQ=-22.544687, numObservations: 9
action 3, numVisits=1, meanQ=-538.905627, numObservations: 1
action: 2
Next state: 0 0.882169 0.187509 0.256328 0.510111 0.276781 0.134487 0.344512 0.861885 0.479683 0.545942 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 37582 episodes
GETTING ACTION FROM:
action 2, numVisits=275, meanQ=22.764036, numObservations: 9
action 4, numVisits=13, meanQ=18.615385, numObservations: 5
action 1, numVisits=37274, meanQ=14.732920, numObservations: 9
action 3, numVisits=3, meanQ=12.333333, numObservations: 3
action 5, numVisits=13, meanQ=10.538462, numObservations: 5
action -1, numVisits=2, meanQ=-2.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.000000, numObservations: 2
action: 2
Next state: 0 0.882169 0.187509 0.256328 0.510111 0.276781 0.134487 0.344512 0.861885 0.479683 0.545942 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 5
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 44823 episodes
GETTING ACTION FROM:
action 4, numVisits=196, meanQ=21.873010, numObservations: 8
action 2, numVisits=61, meanQ=20.901639, numObservations: 6
action 1, numVisits=44159, meanQ=14.710302, numObservations: 9
action 5, numVisits=402, meanQ=14.250189, numObservations: 8
action -1, numVisits=2, meanQ=-2.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.000000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.882169 0.187509 0.256328 0.510111 0.276781 0.134487 0.344512 0.861885 0.479683 0.545942 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 3.21978
Run # 2
Initial state: 0 0.980389 0.414168 0.42784 0.498273 0.815966 0.293956 0.205545 0.134091 0.256244 0.303892 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28351 episodes
GETTING ACTION FROM:
action 5, numVisits=28345, meanQ=8.873563, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 0 0.980389 0.414168 0.42784 0.498273 0.815966 0.293956 0.205545 0.134091 0.256244 0.303892 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=3983, meanQ=9.969636, numObservations: 9
action 1, numVisits=18, meanQ=3.555578, numObservations: 8
action 4, numVisits=7, meanQ=2.424286, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 9914 episodes
GETTING ACTION FROM:
action 3, numVisits=13887, meanQ=9.147587, numObservations: 9
action 1, numVisits=18, meanQ=3.555578, numObservations: 8
action 4, numVisits=7, meanQ=2.424286, numObservations: 5
action 0, numVisits=6, meanQ=-1.340000, numObservations: 6
action -1, numVisits=6, meanQ=-1.505000, numObservations: 6
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.980389 0.414168 0.42784 0.498273 0.815966 0.293956 0.205545 0.134091 0.256244 0.303892 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 3
Initial state: 0 0.900929 0.0932839 0.939371 0.547917 0.473629 0.504538 0.103771 0.546499 0.446925 0.481405 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29459 episodes
GETTING ACTION FROM:
action 5, numVisits=29453, meanQ=9.202040, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.900929 0.0932839 0.939371 0.547917 0.473629 0.504538 0.103771 0.546499 0.446925 0.481405 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 4
Initial state: 0 0.276955 0.942332 0.755657 0.331199 0.48858 0.527767 0.862362 0.158334 0.310786 0.989092 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29446 episodes
GETTING ACTION FROM:
action 4, numVisits=29434, meanQ=8.874669, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 1, numVisits=2, meanQ=-4.000000, numObservations: 2
action 2, numVisits=2, meanQ=-4.000000, numObservations: 2
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.276955 0.942332 0.755657 0.331199 0.48858 0.527767 0.862362 0.158334 0.310786 0.989092 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 5
Initial state: 0 0.185801 0.56109 0.368699 0.300338 0.140371 0.456881 0.413333 0.570676 0.0216955 0.328292 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29526 episodes
GETTING ACTION FROM:
action 5, numVisits=29520, meanQ=8.796545, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.185801 0.56109 0.368699 0.300338 0.140371 0.456881 0.413333 0.570676 0.0216955 0.328292 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=4091, meanQ=9.558111, numObservations: 9
action 1, numVisits=25, meanQ=6.318816, numObservations: 8
action 3, numVisits=12, meanQ=6.062517, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 11176 episodes
GETTING ACTION FROM:
action 2, numVisits=15233, meanQ=9.754943, numObservations: 9
action 1, numVisits=25, meanQ=6.318816, numObservations: 8
action -1, numVisits=5, meanQ=-1.010000, numObservations: 5
action 0, numVisits=5, meanQ=-1.010000, numObservations: 5
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=2, meanQ=-4.004950, numObservations: 1
action 3, numVisits=37, meanQ=-20.977512, numObservations: 9
action: 2
Next state: 0 0.185801 0.56109 0.368699 0.300338 0.140371 0.456881 0.413333 0.570676 0.0216955 0.328292 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=1689, meanQ=11.501987, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 8138 episodes
GETTING ACTION FROM:
action 1, numVisits=9823, meanQ=9.790033, numObservations: 9
action 0, numVisits=4, meanQ=-1.257500, numObservations: 4
action -1, numVisits=4, meanQ=-1.754975, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.185801 0.56109 0.368699 0.300338 0.140371 0.456881 0.413333 0.570676 0.0216955 0.328292 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=330, meanQ=13.526325, numObservations: 9
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=44, meanQ=-6.174153, numObservations: 20
action 1, numVisits=4, meanQ=-8.666592, numObservations: 3
action 0, numVisits=21, meanQ=-26.964384, numObservations: 13
action 4, numVisits=15, meanQ=-65.705304, numObservations: 6
Sampled 22333 episodes
GETTING ACTION FROM:
action 3, numVisits=22663, meanQ=17.162383, numObservations: 9
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=44, meanQ=-6.174153, numObservations: 20
action 1, numVisits=4, meanQ=-8.666592, numObservations: 3
action 0, numVisits=21, meanQ=-26.964384, numObservations: 13
action 4, numVisits=15, meanQ=-65.705304, numObservations: 6
action: 3
Next state: 0 0.185801 0.56109 0.368699 0.300338 0.140371 0.456881 0.413333 0.570676 0.0216955 0.328292 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 1, numVisits=1, meanQ=24.000000, numObservations: 1
action 4, numVisits=229, meanQ=11.896044, numObservations: 9
action 0, numVisits=8, meanQ=-5.404105, numObservations: 5
action -1, numVisits=2, meanQ=-6.726984, numObservations: 1
action 3, numVisits=1, meanQ=-10.383263, numObservations: 1
action 2, numVisits=1, meanQ=-364.588846, numObservations: 1
action 5, numVisits=1, meanQ=-365.127807, numObservations: 1
Sampled 23847 episodes
GETTING ACTION FROM:
action 4, numVisits=24065, meanQ=6.674418, numObservations: 9
action 0, numVisits=8, meanQ=-5.404105, numObservations: 5
action 1, numVisits=12, meanQ=-6.238971, numObservations: 5
action -1, numVisits=2, meanQ=-6.726984, numObservations: 1
action 3, numVisits=1, meanQ=-10.383263, numObservations: 1
action 2, numVisits=1, meanQ=-364.588846, numObservations: 1
action 5, numVisits=1, meanQ=-365.127807, numObservations: 1
action: 4
Next state: 1 0.185801 0.56109 0.368699 0.300338 0.140371 0.456881 0.413333 0.570676 0.0216955 0.328292 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.29271
Run # 6
Initial state: 0 0.932019 0.401487 0.484314 0.545555 0.973776 0.631453 0.0112919 0.477466 0.297783 0.780658 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26362 episodes
GETTING ACTION FROM:
action 3, numVisits=26351, meanQ=9.359509, numObservations: 9
action 4, numVisits=3, meanQ=3.000000, numObservations: 3
action 1, numVisits=4, meanQ=2.750025, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.932019 0.401487 0.484314 0.545555 0.973776 0.631453 0.0112919 0.477466 0.297783 0.780658 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 7
Initial state: 0 0.0275628 0.130813 0.489973 0.511351 0.725901 0.0135361 0.983615 0.169337 0.889123 0.160636 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29215 episodes
GETTING ACTION FROM:
action 1, numVisits=29207, meanQ=8.748011, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.0275628 0.130813 0.489973 0.511351 0.725901 0.0135361 0.983615 0.169337 0.889123 0.160636 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=479, meanQ=10.718657, numObservations: 9
action 2, numVisits=7, meanQ=5.998586, numObservations: 5
action 3, numVisits=4, meanQ=1.745000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 13953 episodes
GETTING ACTION FROM:
action 2, numVisits=10196, meanQ=7.948979, numObservations: 9
action 5, numVisits=3861, meanQ=5.991234, numObservations: 9
action 4, numVisits=42, meanQ=4.486294, numObservations: 9
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=321, meanQ=-4.793537, numObservations: 148
action 0, numVisits=17, meanQ=-62.895912, numObservations: 16
action 3, numVisits=9, meanQ=-112.445027, numObservations: 5
action: 2
Next state: 1 0.0275628 0.130813 0.489973 0.511351 0.725901 0.0135361 0.983615 0.169337 0.889123 0.160636 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 8
Initial state: 0 0.995226 0.327214 0.439534 0.541701 0.300591 0.856527 0.62987 0.200369 0.998551 0.116254 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29596 episodes
GETTING ACTION FROM:
action 4, numVisits=29574, meanQ=8.793502, numObservations: 9
action 5, numVisits=12, meanQ=0.666667, numObservations: 6
action 1, numVisits=4, meanQ=-0.500000, numObservations: 4
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.995226 0.327214 0.439534 0.541701 0.300591 0.856527 0.62987 0.200369 0.998551 0.116254 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 9
Initial state: 0 0.332051 0.264034 0.433154 0.608934 0.340172 0.338754 0.806466 0.269523 0.980668 0.605547 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28143 episodes
GETTING ACTION FROM:
action 3, numVisits=28107, meanQ=9.466624, numObservations: 9
action 4, numVisits=26, meanQ=8.114623, numObservations: 8
action 1, numVisits=6, meanQ=6.500000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.332051 0.264034 0.433154 0.608934 0.340172 0.338754 0.806466 0.269523 0.980668 0.605547 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=3925, meanQ=10.078543, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 9545 episodes
GETTING ACTION FROM:
action 1, numVisits=13445, meanQ=9.171531, numObservations: 9
action 0, numVisits=16, meanQ=-1.821816, numObservations: 15
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=11, meanQ=-97.185206, numObservations: 10
action: 1
Next state: 0 0.332051 0.264034 0.433154 0.608934 0.340172 0.338754 0.806466 0.269523 0.980668 0.605547 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=1611, meanQ=10.616970, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=5, meanQ=-3.386000, numObservations: 4
Sampled 5010 episodes
GETTING ACTION FROM:
action 2, numVisits=6621, meanQ=10.911577, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=5, meanQ=-3.386000, numObservations: 4
action: 2
Next state: 1 0.332051 0.264034 0.433154 0.608934 0.340172 0.338754 0.806466 0.269523 0.980668 0.605547 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 10
Initial state: 0 0.217136 0.688198 0.300549 0.315799 0.311183 0.747332 0.0183545 0.620524 0.507085 0.551603 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29488 episodes
GETTING ACTION FROM:
action 4, numVisits=29482, meanQ=9.262571, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.217136 0.688198 0.300549 0.315799 0.311183 0.747332 0.0183545 0.620524 0.507085 0.551603 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 11
Initial state: 0 0.207863 0.927807 0.598874 0.272733 0.0327729 0.656521 0.485093 0.874384 0.436083 0.519473 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29442 episodes
GETTING ACTION FROM:
action 2, numVisits=29422, meanQ=8.850696, numObservations: 9
action -1, numVisits=6, meanQ=-1.010000, numObservations: 6
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 4, numVisits=2, meanQ=-4.000000, numObservations: 2
action 5, numVisits=2, meanQ=-4.000000, numObservations: 2
action 1, numVisits=3, meanQ=-6.333333, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.207863 0.927807 0.598874 0.272733 0.0327729 0.656521 0.485093 0.874384 0.436083 0.519473 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 12
Initial state: 0 0.248993 0.767945 0.397276 0.92239 0.923141 0.678332 0.943023 0.166561 0.54125 0.578296 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29570 episodes
GETTING ACTION FROM:
action 3, numVisits=29524, meanQ=9.081645, numObservations: 9
action 1, numVisits=39, meanQ=7.800772, numObservations: 9
action 4, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.248993 0.767945 0.397276 0.92239 0.923141 0.678332 0.943023 0.166561 0.54125 0.578296 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 13
Initial state: 0 0.438701 0.534116 0.929373 0.565904 0.671443 0.200939 0.094241 0.0432232 0.657364 0.77451 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29287 episodes
GETTING ACTION FROM:
action 3, numVisits=29269, meanQ=9.138950, numObservations: 9
action 4, numVisits=8, meanQ=-0.500000, numObservations: 5
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 1, numVisits=2, meanQ=-4.000000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.438701 0.534116 0.929373 0.565904 0.671443 0.200939 0.094241 0.0432232 0.657364 0.77451 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 14
Initial state: 0 0.189032 0.0545502 0.512154 0.504647 0.871683 0.50147 0.495656 0.715181 0.120652 0.848348 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29698 episodes
GETTING ACTION FROM:
action 4, numVisits=29687, meanQ=8.940797, numObservations: 9
action 1, numVisits=6, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.189032 0.0545502 0.512154 0.504647 0.871683 0.50147 0.495656 0.715181 0.120652 0.848348 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 15
Initial state: 0 0.177909 0.406507 0.714596 0.748381 0.746214 0.200139 0.546698 0.547644 0.623444 0.996547 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29089 episodes
GETTING ACTION FROM:
action 4, numVisits=29080, meanQ=8.811856, numObservations: 9
action 2, numVisits=4, meanQ=2.750025, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.177909 0.406507 0.714596 0.748381 0.746214 0.200139 0.546698 0.547644 0.623444 0.996547 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 16
Initial state: 0 0.378798 0.666147 0.50156 0.279714 0.612354 0.000525833 0.0388162 0.629696 0.506353 0.538367 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29245 episodes
GETTING ACTION FROM:
action 1, numVisits=29228, meanQ=9.219990, numObservations: 9
action 5, numVisits=10, meanQ=4.499000, numObservations: 7
action 4, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.378798 0.666147 0.50156 0.279714 0.612354 0.000525833 0.0388162 0.629696 0.506353 0.538367 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=1444, meanQ=10.316780, numObservations: 9
action 1, numVisits=1239, meanQ=10.240028, numObservations: 9
action 3, numVisits=7, meanQ=5.715729, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 10242 episodes
GETTING ACTION FROM:
action 4, numVisits=11570, meanQ=12.720307, numObservations: 9
action 1, numVisits=1239, meanQ=10.240028, numObservations: 9
action 3, numVisits=119, meanQ=4.457502, numObservations: 9
action -1, numVisits=3, meanQ=-1.340000, numObservations: 3
action 0, numVisits=3, meanQ=-1.340000, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.378798 0.666147 0.50156 0.279714 0.612354 0.000525833 0.0388162 0.629696 0.506353 0.538367 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 0, numVisits=34, meanQ=-0.647739, numObservations: 29
action -1, numVisits=11, meanQ=-2.090000, numObservations: 10
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action 4, numVisits=2, meanQ=-8.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=16, meanQ=-62.312455, numObservations: 8
Sampled 34219 episodes
GETTING ACTION FROM:
action 2, numVisits=33631, meanQ=17.238974, numObservations: 9
action 1, numVisits=5, meanQ=10.820000, numObservations: 1
action -1, numVisits=461, meanQ=-3.175576, numObservations: 112
action 0, numVisits=170, meanQ=-4.865832, numObservations: 69
action 4, numVisits=2, meanQ=-8.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=16, meanQ=-62.312455, numObservations: 8
action: 2
Next state: 2 0.378798 0.666147 0.50156 0.279714 0.612354 0.000525833 0.0388162 0.629696 0.506353 0.538367 w: 1
Observation: 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -18.7411
Run # 17
Initial state: 0 0.418823 0.527841 0.336641 0.935103 0.0237631 0.980326 0.87993 0.325597 0.250948 0.896477 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28297 episodes
GETTING ACTION FROM:
action 3, numVisits=28285, meanQ=9.143243, numObservations: 9
action 4, numVisits=7, meanQ=5.000000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.418823 0.527841 0.336641 0.935103 0.0237631 0.980326 0.87993 0.325597 0.250948 0.896477 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=2514, meanQ=12.254977, numObservations: 9
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 13447 episodes
GETTING ACTION FROM:
action 3, numVisits=2515, meanQ=12.253198, numObservations: 9
action 5, numVisits=13274, meanQ=9.569545, numObservations: 9
action 1, numVisits=3, meanQ=-7.908794, numObservations: 2
action 4, numVisits=3, meanQ=-8.054849, numObservations: 2
action -1, numVisits=107, meanQ=-10.512884, numObservations: 69
action 2, numVisits=44, meanQ=-15.498266, numObservations: 9
action 0, numVisits=23, meanQ=-48.006103, numObservations: 20
action: 3
Next state: 0 0.418823 0.527841 0.336641 0.935103 0.0237631 0.980326 0.87993 0.325597 0.250948 0.896477 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=1218, meanQ=11.901582, numObservations: 9
action 2, numVisits=31, meanQ=6.092265, numObservations: 8
action 1, numVisits=8, meanQ=3.592500, numObservations: 4
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 16096 episodes
GETTING ACTION FROM:
action 2, numVisits=16116, meanQ=13.611123, numObservations: 9
action 3, numVisits=1222, meanQ=11.926881, numObservations: 9
action 1, numVisits=9, meanQ=1.711461, numObservations: 4
action 0, numVisits=5, meanQ=-1.406000, numObservations: 5
action -1, numVisits=4, meanQ=-1.505000, numObservations: 4
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.418823 0.527841 0.336641 0.935103 0.0237631 0.980326 0.87993 0.325597 0.250948 0.896477 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 5, numVisits=635, meanQ=13.577493, numObservations: 9
action 1, numVisits=4, meanQ=6.500000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-9.234283, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 18556 episodes
GETTING ACTION FROM:
action 5, numVisits=19189, meanQ=15.663366, numObservations: 9
action 1, numVisits=4, meanQ=6.500000, numObservations: 4
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-9.234283, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.418823 0.527841 0.336641 0.935103 0.0237631 0.980326 0.87993 0.325597 0.250948 0.896477 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: -4
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 1, numVisits=52, meanQ=13.423499, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 5, numVisits=1, meanQ=-8.951495, numObservations: 1
action 2, numVisits=1, meanQ=-9.198821, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-540.725121, numObservations: 1
Sampled 26035 episodes
GETTING ACTION FROM:
action 1, numVisits=26087, meanQ=15.306821, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 5, numVisits=1, meanQ=-8.951495, numObservations: 1
action 2, numVisits=1, meanQ=-9.198821, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-540.725121, numObservations: 1
action: 1
Next state: 1 0.418823 0.527841 0.336641 0.935103 0.0237631 0.980326 0.87993 0.325597 0.250948 0.896477 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.29271
Run # 18
Initial state: 0 0.4458 0.547447 0.150423 0.893346 0.114192 0.506056 0.934276 0.511655 0.379831 0.149839 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29496 episodes
GETTING ACTION FROM:
action 1, numVisits=29490, meanQ=9.044741, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.4458 0.547447 0.150423 0.893346 0.114192 0.506056 0.934276 0.511655 0.379831 0.149839 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 19
Initial state: 0 0.841286 0.414275 0.591415 0.669885 0.0740756 0.25135 0.378964 0.861077 0.418048 0.575461 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29359 episodes
GETTING ACTION FROM:
action 4, numVisits=29349, meanQ=8.955120, numObservations: 9
action 5, numVisits=5, meanQ=4.598000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.841286 0.414275 0.591415 0.669885 0.0740756 0.25135 0.378964 0.861077 0.418048 0.575461 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 20
Initial state: 0 0.301223 0.776957 0.819238 0.424572 0.246618 0.0159698 0.452891 0.494898 0.184744 0.781081 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29036 episodes
GETTING ACTION FROM:
action 3, numVisits=29004, meanQ=8.890753, numObservations: 9
action 1, numVisits=27, meanQ=4.114822, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.301223 0.776957 0.819238 0.424572 0.246618 0.0159698 0.452891 0.494898 0.184744 0.781081 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=4099, meanQ=10.129150, numObservations: 9
action 5, numVisits=20, meanQ=8.301515, numObservations: 7
action 4, numVisits=5, meanQ=5.798020, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 11488 episodes
GETTING ACTION FROM:
action 1, numVisits=15288, meanQ=9.248097, numObservations: 9
action 5, numVisits=301, meanQ=5.733512, numObservations: 9
action 4, numVisits=6, meanQ=2.998350, numObservations: 3
action 2, numVisits=4, meanQ=0.084946, numObservations: 3
action -1, numVisits=9, meanQ=-1.230000, numObservations: 9
action 0, numVisits=7, meanQ=-1.292857, numObservations: 7
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.301223 0.776957 0.819238 0.424572 0.246618 0.0159698 0.452891 0.494898 0.184744 0.781081 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=1029, meanQ=10.752950, numObservations: 9
action 2, numVisits=6, meanQ=4.661667, numObservations: 5
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=6, meanQ=-166.571148, numObservations: 2
Sampled 7078 episodes
GETTING ACTION FROM:
action 5, numVisits=8105, meanQ=10.981806, numObservations: 9
action 2, numVisits=6, meanQ=4.661667, numObservations: 5
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.257500, numObservations: 4
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=6, meanQ=-166.571148, numObservations: 2
action: 5
Next state: 1 0.301223 0.776957 0.819238 0.424572 0.246618 0.0159698 0.452891 0.494898 0.184744 0.781081 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 21
Initial state: 0 0.0292917 0.755935 0.666178 0.331677 0.586738 0.117772 0.504443 0.5982 0.0366327 0.522881 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29314 episodes
GETTING ACTION FROM:
action 3, numVisits=29291, meanQ=9.095814, numObservations: 9
action 4, numVisits=14, meanQ=7.215021, numObservations: 7
action 2, numVisits=5, meanQ=4.400000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 2 0.0292917 0.755935 0.666178 0.331677 0.586738 0.117772 0.504443 0.5982 0.0366327 0.522881 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 22
Initial state: 0 0.785983 0.847792 0.993135 0.315564 0.0662123 0.582159 0.531521 0.592514 0.147363 0.0214171 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29524 episodes
GETTING ACTION FROM:
action 1, numVisits=29518, meanQ=9.054517, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.785983 0.847792 0.993135 0.315564 0.0662123 0.582159 0.531521 0.592514 0.147363 0.0214171 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 23
Initial state: 0 0.528593 0.0699051 0.182625 0.707613 0.763547 0.442794 0.947611 0.487341 0.542558 0.611776 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29246 episodes
GETTING ACTION FROM:
action 2, numVisits=29240, meanQ=8.932893, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.528593 0.0699051 0.182625 0.707613 0.763547 0.442794 0.947611 0.487341 0.542558 0.611776 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 24
Initial state: 0 0.425681 0.519405 0.380257 0.256452 0.828621 0.375094 0.65704 0.0824025 0.859602 0.283104 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29407 episodes
GETTING ACTION FROM:
action 1, numVisits=29399, meanQ=8.886297, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.425681 0.519405 0.380257 0.256452 0.828621 0.375094 0.65704 0.0824025 0.859602 0.283104 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 25
Initial state: 0 0.640333 0.359516 0.123851 0.937783 0.42923 0.768429 0.353694 0.810243 0.457531 0.598994 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28477 episodes
GETTING ACTION FROM:
action 5, numVisits=28465, meanQ=8.837137, numObservations: 9
action 2, numVisits=7, meanQ=5.141429, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.640333 0.359516 0.123851 0.937783 0.42923 0.768429 0.353694 0.810243 0.457531 0.598994 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 26
Initial state: 0 0.327732 0.887158 0.682225 0.772633 0.548706 0.522918 0.64706 0.864014 0.282163 0.701081 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29356 episodes
GETTING ACTION FROM:
action 4, numVisits=29350, meanQ=9.191743, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.327732 0.887158 0.682225 0.772633 0.548706 0.522918 0.64706 0.864014 0.282163 0.701081 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 27
Initial state: 0 0.667814 0.282955 0.406442 0.0632319 0.557462 0.591168 0.747699 0.760497 0.682919 0.445319 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29465 episodes
GETTING ACTION FROM:
action 3, numVisits=29444, meanQ=9.007404, numObservations: 9
action 5, numVisits=8, meanQ=2.513750, numObservations: 5
action 1, numVisits=9, meanQ=1.444444, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.667814 0.282955 0.406442 0.0632319 0.557462 0.591168 0.747699 0.760497 0.682919 0.445319 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 28
Initial state: 0 0.781477 0.3753 0.93602 0.864603 0.999204 0.467379 0.772718 0.355342 0.448249 0.558381 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29471 episodes
GETTING ACTION FROM:
action 4, numVisits=29438, meanQ=8.829418, numObservations: 9
action 5, numVisits=28, meanQ=6.250732, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.781477 0.3753 0.93602 0.864603 0.999204 0.467379 0.772718 0.355342 0.448249 0.558381 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 29
Initial state: 0 0.535332 0.895664 0.0227376 0.189104 0.43273 0.540282 0.925314 0.277235 0.916968 0.88685 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28203 episodes
GETTING ACTION FROM:
action 3, numVisits=28175, meanQ=8.996043, numObservations: 9
action 5, numVisits=21, meanQ=5.812876, numObservations: 8
action 4, numVisits=3, meanQ=5.000033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.535332 0.895664 0.0227376 0.189104 0.43273 0.540282 0.925314 0.277235 0.916968 0.88685 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 30
Initial state: 0 0.475089 0.510992 0.909637 0.43335 0.334844 0.617259 0.590372 0.0446627 0.573996 0.146785 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29505 episodes
GETTING ACTION FROM:
action 1, numVisits=29496, meanQ=9.039684, numObservations: 9
action 3, numVisits=4, meanQ=3.495000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.475089 0.510992 0.909637 0.43335 0.334844 0.617259 0.590372 0.0446627 0.573996 0.146785 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 31
Initial state: 0 0.0789556 0.357334 0.924352 0.156148 0.68336 0.90671 0.524872 0.599708 0.84893 0.586897 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28566 episodes
GETTING ACTION FROM:
action 4, numVisits=28560, meanQ=9.272937, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.0789556 0.357334 0.924352 0.156148 0.68336 0.90671 0.524872 0.599708 0.84893 0.586897 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 32
Initial state: 0 0.616918 0.343144 0.459591 0.719503 0.215973 0.919288 0.271313 0.453987 0.444373 0.615119 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29487 episodes
GETTING ACTION FROM:
action 3, numVisits=29479, meanQ=9.015176, numObservations: 9
action 2, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.616918 0.343144 0.459591 0.719503 0.215973 0.919288 0.271313 0.453987 0.444373 0.615119 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 33
Initial state: 0 0.81165 0.263636 0.194534 0.950799 0.59146 0.381495 0.533625 0.239516 0.533123 0.496425 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28516 episodes
GETTING ACTION FROM:
action 4, numVisits=28494, meanQ=8.934398, numObservations: 9
action -1, numVisits=9, meanQ=-1.010000, numObservations: 9
action 0, numVisits=9, meanQ=-1.010000, numObservations: 9
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.81165 0.263636 0.194534 0.950799 0.59146 0.381495 0.533625 0.239516 0.533123 0.496425 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 34
Initial state: 0 0.626087 0.751089 0.648263 0.506266 0.509775 0.497044 0.845643 0.209334 0.0442304 0.954087 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29433 episodes
GETTING ACTION FROM:
action 1, numVisits=29425, meanQ=8.923347, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.626087 0.751089 0.648263 0.506266 0.509775 0.497044 0.845643 0.209334 0.0442304 0.954087 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 35
Initial state: 0 0.641004 0.177019 0.468206 0.195199 0.729227 0.949909 0.161367 0.897104 0.527885 0.598312 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29213 episodes
GETTING ACTION FROM:
action 1, numVisits=29199, meanQ=8.649816, numObservations: 9
action 5, numVisits=6, meanQ=2.351667, numObservations: 4
action 2, numVisits=4, meanQ=1.250000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.641004 0.177019 0.468206 0.195199 0.729227 0.949909 0.161367 0.897104 0.527885 0.598312 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=710, meanQ=8.523090, numObservations: 9
action -1, numVisits=5, meanQ=-1.010000, numObservations: 5
action 0, numVisits=5, meanQ=-1.010000, numObservations: 5
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 25148 episodes
GETTING ACTION FROM:
action 5, numVisits=25817, meanQ=5.322568, numObservations: 9
action 4, numVisits=4, meanQ=-0.252500, numObservations: 4
action -1, numVisits=24, meanQ=-1.711250, numObservations: 22
action 0, numVisits=22, meanQ=-1.775000, numObservations: 20
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.641004 0.177019 0.468206 0.195199 0.729227 0.949909 0.161367 0.897104 0.527885 0.598312 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=12, meanQ=11.825001, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.063877, numObservations: 1
action 3, numVisits=1, meanQ=-10.916607, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-1066.227846, numObservations: 1
Sampled 39129 episodes
GETTING ACTION FROM:
action 2, numVisits=39137, meanQ=12.858498, numObservations: 9
action -1, numVisits=3, meanQ=-1.670000, numObservations: 3
action 0, numVisits=3, meanQ=-1.670000, numObservations: 3
action 5, numVisits=1, meanQ=-10.063877, numObservations: 1
action 3, numVisits=1, meanQ=-10.916607, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-1066.227846, numObservations: 1
action: 2
Next state: 0 0.641004 0.177019 0.468206 0.195199 0.729227 0.949909 0.161367 0.897104 0.527885 0.598312 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=23, meanQ=8.693094, numObservations: 7
action 4, numVisits=3, meanQ=-0.403395, numObservations: 3
action -1, numVisits=4, meanQ=-4.659629, numObservations: 3
action 0, numVisits=3, meanQ=-5.887630, numObservations: 2
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.411170, numObservations: 1
action 1, numVisits=1, meanQ=-533.207615, numObservations: 1
Sampled 61939 episodes
GETTING ACTION FROM:
action 3, numVisits=61962, meanQ=8.730888, numObservations: 9
action 4, numVisits=3, meanQ=-0.403395, numObservations: 3
action -1, numVisits=4, meanQ=-4.659629, numObservations: 3
action 0, numVisits=3, meanQ=-5.887630, numObservations: 2
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.411170, numObservations: 1
action 1, numVisits=1, meanQ=-533.207615, numObservations: 1
action: 3
Next state: 1 0.641004 0.177019 0.468206 0.195199 0.729227 0.949909 0.161367 0.897104 0.527885 0.598312 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 11.4068
Run # 36
Initial state: 0 0.0719025 0.763108 0.951997 0.781694 0.578049 0.176677 0.238148 0.637275 0.488123 0.49755 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29702 episodes
GETTING ACTION FROM:
action 1, numVisits=29691, meanQ=9.002242, numObservations: 9
action 3, numVisits=6, meanQ=1.833333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.0719025 0.763108 0.951997 0.781694 0.578049 0.176677 0.238148 0.637275 0.488123 0.49755 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=2535, meanQ=10.193821, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 12241 episodes
GETTING ACTION FROM:
action 2, numVisits=14772, meanQ=12.098619, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.0719025 0.763108 0.951997 0.781694 0.578049 0.176677 0.238148 0.637275 0.488123 0.49755 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 37
Initial state: 0 0.916378 0.449101 0.554574 0.572271 0.637299 0.156769 0.186879 0.122353 0.0453545 0.38835 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28241 episodes
GETTING ACTION FROM:
action 3, numVisits=28205, meanQ=8.969551, numObservations: 9
action -1, numVisits=11, meanQ=-1.370900, numObservations: 10
action 0, numVisits=20, meanQ=-1.604000, numObservations: 19
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=2, meanQ=-5.489950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.916378 0.449101 0.554574 0.572271 0.637299 0.156769 0.186879 0.122353 0.0453545 0.38835 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 38
Initial state: 0 0.859 0.77737 0.535759 0.498126 0.2846 0.128063 0.883516 0.0567732 0.996906 0.84579 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29551 episodes
GETTING ACTION FROM:
action 2, numVisits=29543, meanQ=8.961180, numObservations: 9
action 5, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.859 0.77737 0.535759 0.498126 0.2846 0.128063 0.883516 0.0567732 0.996906 0.84579 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=424, meanQ=20.207026, numObservations: 9
action 1, numVisits=12, meanQ=-0.918333, numObservations: 4
action -1, numVisits=5, meanQ=-1.010000, numObservations: 5
action 0, numVisits=5, meanQ=-1.010000, numObservations: 5
action 3, numVisits=6, meanQ=-1.171667, numObservations: 4
action 5, numVisits=4, meanQ=-2.250000, numObservations: 3
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 28231 episodes
GETTING ACTION FROM:
action 2, numVisits=469, meanQ=20.371142, numObservations: 9
action 4, numVisits=28179, meanQ=11.781481, numObservations: 9
action 1, numVisits=12, meanQ=-0.918333, numObservations: 4
action 3, numVisits=6, meanQ=-1.171667, numObservations: 4
action -1, numVisits=9, meanQ=-1.450000, numObservations: 9
action 0, numVisits=9, meanQ=-1.450000, numObservations: 9
action 5, numVisits=4, meanQ=-2.250000, numObservations: 3
action: 2
Next state: 1 0.859 0.77737 0.535759 0.498126 0.2846 0.128063 0.883516 0.0567732 0.996906 0.84579 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 39
Initial state: 0 0.861925 0.826356 0.858246 0.399034 0.0776134 0.473045 0.613241 0.15472 0.49884 0.584155 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29577 episodes
GETTING ACTION FROM:
action 5, numVisits=29559, meanQ=9.034818, numObservations: 9
action 4, numVisits=8, meanQ=5.003775, numObservations: 5
action 3, numVisits=6, meanQ=4.165017, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.861925 0.826356 0.858246 0.399034 0.0776134 0.473045 0.613241 0.15472 0.49884 0.584155 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 40
Initial state: 0 0.349205 0.981325 0.681713 0.199619 0.253157 0.485304 0.258927 0.459665 0.474537 0.531347 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28388 episodes
GETTING ACTION FROM:
action 2, numVisits=28374, meanQ=9.038728, numObservations: 9
action 4, numVisits=7, meanQ=4.000000, numObservations: 5
action 5, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.349205 0.981325 0.681713 0.199619 0.253157 0.485304 0.258927 0.459665 0.474537 0.531347 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=739, meanQ=9.070513, numObservations: 9
action 3, numVisits=4, meanQ=1.745000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 28603 episodes
GETTING ACTION FROM:
action 4, numVisits=29232, meanQ=5.788834, numObservations: 9
action 3, numVisits=78, meanQ=4.118018, numObservations: 9
action -1, numVisits=19, meanQ=-1.791579, numObservations: 18
action 0, numVisits=19, meanQ=-1.791579, numObservations: 18
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.349205 0.981325 0.681713 0.199619 0.253157 0.485304 0.258927 0.459665 0.474537 0.531347 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=512, meanQ=11.649449, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 29666 episodes
GETTING ACTION FROM:
action 1, numVisits=28807, meanQ=8.437607, numObservations: 9
action 3, numVisits=1359, meanQ=7.240622, numObservations: 9
action -1, numVisits=8, meanQ=-1.752500, numObservations: 8
action 0, numVisits=8, meanQ=-1.752500, numObservations: 7
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=2, meanQ=-7.005000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.349205 0.981325 0.681713 0.199619 0.253157 0.485304 0.258927 0.459665 0.474537 0.531347 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 41
Initial state: 0 0.525183 0.557432 0.230772 0.626649 0.92069 0.827472 0.678358 0.168321 0.935835 0.9026 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29626 episodes
GETTING ACTION FROM:
action 4, numVisits=29620, meanQ=8.803553, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.525183 0.557432 0.230772 0.626649 0.92069 0.827472 0.678358 0.168321 0.935835 0.9026 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 42
Initial state: 0 0.616295 0.920038 0.0250369 0.232439 0.3631 0.189343 0.457401 0.527836 0.372059 0.635027 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27500 episodes
GETTING ACTION FROM:
action 2, numVisits=27494, meanQ=8.099020, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.616295 0.920038 0.0250369 0.232439 0.3631 0.189343 0.457401 0.527836 0.372059 0.635027 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=3849, meanQ=3.137037, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 7894 episodes
GETTING ACTION FROM:
action 5, numVisits=7808, meanQ=7.466651, numObservations: 9
action 2, numVisits=3849, meanQ=3.137037, numObservations: 9
action 1, numVisits=2, meanQ=-11.000000, numObservations: 2
action 3, numVisits=27, meanQ=-31.350806, numObservations: 7
action 4, numVisits=30, meanQ=-31.444827, numObservations: 9
action -1, numVisits=31, meanQ=-35.677479, numObservations: 27
action 0, numVisits=13, meanQ=-81.926233, numObservations: 12
action: 5
Next state: 0 0.616295 0.920038 0.0250369 0.232439 0.3631 0.189343 0.457401 0.527836 0.372059 0.635027 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=448, meanQ=4.367715, numObservations: 9
action 0, numVisits=105, meanQ=-6.187099, numObservations: 54
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-12.362999, numObservations: 1
action -1, numVisits=22, meanQ=-49.693089, numObservations: 16
action 1, numVisits=10, meanQ=-104.815423, numObservations: 6
action 2, numVisits=1, meanQ=-1061.682296, numObservations: 1
Sampled 5501 episodes
GETTING ACTION FROM:
action 4, numVisits=5469, meanQ=13.514429, numObservations: 9
action 5, numVisits=450, meanQ=4.331783, numObservations: 9
action 0, numVisits=105, meanQ=-6.187099, numObservations: 54
action 3, numVisits=32, meanQ=-7.479299, numObservations: 9
action -1, numVisits=22, meanQ=-49.693089, numObservations: 16
action 1, numVisits=10, meanQ=-104.815423, numObservations: 6
action 2, numVisits=1, meanQ=-1061.682296, numObservations: 1
action: 4
Next state: 1 0.616295 0.920038 0.0250369 0.232439 0.3631 0.189343 0.457401 0.527836 0.372059 0.635027 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 43
Initial state: 0 0.471171 0.614907 0.94754 0.335344 0.398467 0.972446 0.260501 0.131788 0.824606 0.455292 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29515 episodes
GETTING ACTION FROM:
action 2, numVisits=29495, meanQ=8.898471, numObservations: 9
action 1, numVisits=15, meanQ=6.813333, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.471171 0.614907 0.94754 0.335344 0.398467 0.972446 0.260501 0.131788 0.824606 0.455292 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 44
Initial state: 0 0.115952 0.456021 0.0236507 0.478379 0.473185 0.554166 0.614244 0.359587 0.118371 0.289789 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29234 episodes
GETTING ACTION FROM:
action 1, numVisits=29222, meanQ=8.791869, numObservations: 9
action 3, numVisits=7, meanQ=5.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.115952 0.456021 0.0236507 0.478379 0.473185 0.554166 0.614244 0.359587 0.118371 0.289789 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=4063, meanQ=9.471993, numObservations: 9
action 3, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 10930 episodes
GETTING ACTION FROM:
action 2, numVisits=14967, meanQ=8.857930, numObservations: 9
action 3, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=21, meanQ=-0.114286, numObservations: 20
action 0, numVisits=7, meanQ=-1.151429, numObservations: 7
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.115952 0.456021 0.0236507 0.478379 0.473185 0.554166 0.614244 0.359587 0.118371 0.289789 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=1478, meanQ=10.214869, numObservations: 9
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 7471 episodes
GETTING ACTION FROM:
action 4, numVisits=8949, meanQ=11.748955, numObservations: 9
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.115952 0.456021 0.0236507 0.478379 0.473185 0.554166 0.614244 0.359587 0.118371 0.289789 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -18.7411
Run # 45
Initial state: 0 0.683773 0.749231 0.123637 0.840717 0.641438 0.643542 0.413195 0.58943 0.845142 0.214618 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29222 episodes
GETTING ACTION FROM:
action 3, numVisits=29207, meanQ=8.930048, numObservations: 9
action 1, numVisits=10, meanQ=5.502010, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.683773 0.749231 0.123637 0.840717 0.641438 0.643542 0.413195 0.58943 0.845142 0.214618 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 46
Initial state: 0 0.440395 0.160282 0.453145 0.615332 0.544004 0.920234 0.992634 0.108439 0.974489 0.994675 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29152 episodes
GETTING ACTION FROM:
action 1, numVisits=29138, meanQ=8.857874, numObservations: 9
action 2, numVisits=9, meanQ=6.221111, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.440395 0.160282 0.453145 0.615332 0.544004 0.920234 0.992634 0.108439 0.974489 0.994675 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 47
Initial state: 0 0.185663 0.681023 0.416127 0.56381 0.402329 0.916347 0.0607145 0.940993 0.760368 0.299477 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29333 episodes
GETTING ACTION FROM:
action 5, numVisits=29314, meanQ=8.852240, numObservations: 9
action 4, numVisits=11, meanQ=6.637282, numObservations: 6
action 3, numVisits=4, meanQ=3.495000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.185663 0.681023 0.416127 0.56381 0.402329 0.916347 0.0607145 0.940993 0.760368 0.299477 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 48
Initial state: 0 0.158449 0.108863 0.373542 0.815868 0.67364 0.175697 0.604968 0.00546353 0.462891 0.571412 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29274 episodes
GETTING ACTION FROM:
action 2, numVisits=29262, meanQ=8.889859, numObservations: 9
action 3, numVisits=7, meanQ=4.444286, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.158449 0.108863 0.373542 0.815868 0.67364 0.175697 0.604968 0.00546353 0.462891 0.571412 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 49
Initial state: 0 0.279676 0.961973 0.911589 0.784422 0.48471 0.609977 0.583942 0.954741 0.897579 0.428764 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29358 episodes
GETTING ACTION FROM:
action 2, numVisits=29349, meanQ=8.837913, numObservations: 9
action 1, numVisits=4, meanQ=-0.500000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.279676 0.961973 0.911589 0.784422 0.48471 0.609977 0.583942 0.954741 0.897579 0.428764 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 50
Initial state: 0 0.50116 0.526142 0.162155 0.752726 0.852465 0.0259755 0.569521 0.20759 0.881121 0.14436 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29309 episodes
GETTING ACTION FROM:
action 5, numVisits=29293, meanQ=8.988986, numObservations: 9
action 2, numVisits=9, meanQ=-0.663311, numObservations: 5
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.50116 0.526142 0.162155 0.752726 0.852465 0.0259755 0.569521 0.20759 0.881121 0.14436 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=837, meanQ=9.796304, numObservations: 9
action 3, numVisits=4, meanQ=-0.252500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 25323 episodes
GETTING ACTION FROM:
action 4, numVisits=26021, meanQ=4.624863, numObservations: 9
action 1, numVisits=42, meanQ=2.666431, numObservations: 9
action -1, numVisits=54, meanQ=-1.816667, numObservations: 42
action 0, numVisits=44, meanQ=-1.910225, numObservations: 33
action 3, numVisits=5, meanQ=-2.402000, numObservations: 4
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 4
Next state: 2 0.50116 0.526142 0.162155 0.752726 0.852465 0.0259755 0.569521 0.20759 0.881121 0.14436 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
[32m ProblemEnvironment.hpp 351: Done.[39m
