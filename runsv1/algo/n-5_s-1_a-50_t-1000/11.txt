Run # 1
Initial state: 0 0.193514 0.997024 0.779602 0.373322 0.644891 0.266866 0.711753 0.418853 0.500819 0.578465 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 25866 episodes
GETTING ACTION FROM:
action 2, numVisits=25835, meanQ=7.854009, numObservations: 9
action 0, numVisits=16, meanQ=-1.010000, numObservations: 16
action -1, numVisits=11, meanQ=-1.190900, numObservations: 10
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.193514 0.997024 0.779602 0.373322 0.644891 0.266866 0.711753 0.418853 0.500819 0.578465 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 2
Initial state: 0 0.499944 0.68049 0.242084 0.230714 0.0331628 0.211465 0.588113 0.448522 0.86462 0.401221 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29012 episodes
GETTING ACTION FROM:
action 3, numVisits=28994, meanQ=7.427193, numObservations: 9
action 1, numVisits=13, meanQ=4.920000, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.499944 0.68049 0.242084 0.230714 0.0331628 0.211465 0.588113 0.448522 0.86462 0.401221 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=466, meanQ=9.187426, numObservations: 9
action 5, numVisits=81, meanQ=8.683543, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 11836 episodes
GETTING ACTION FROM:
action 1, numVisits=11041, meanQ=6.868367, numObservations: 9
action 5, numVisits=970, meanQ=6.582087, numObservations: 9
action 2, numVisits=76, meanQ=6.347208, numObservations: 9
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=226, meanQ=-6.169038, numObservations: 126
action 0, numVisits=73, meanQ=-15.421150, numObservations: 51
action: 1
Next state: 1 0.499944 0.68049 0.242084 0.230714 0.0331628 0.211465 0.588113 0.448522 0.86462 0.401221 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 3
Initial state: 0 0.570048 0.733637 0.652418 0.382316 0.123293 0.908261 0.889763 0.952845 0.449012 0.556333 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28749 episodes
GETTING ACTION FROM:
action 4, numVisits=28722, meanQ=7.326742, numObservations: 9
action 3, numVisits=18, meanQ=0.450556, numObservations: 6
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.570048 0.733637 0.652418 0.382316 0.123293 0.908261 0.889763 0.952845 0.449012 0.556333 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 4
Initial state: 0 0.515952 0.143746 0.531513 0.552823 0.969888 0.37455 0.705172 0.0887693 0.768096 0.738093 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28338 episodes
GETTING ACTION FROM:
action 4, numVisits=28328, meanQ=7.081568, numObservations: 9
action 3, numVisits=3, meanQ=3.000000, numObservations: 3
action 1, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.515952 0.143746 0.531513 0.552823 0.969888 0.37455 0.705172 0.0887693 0.768096 0.738093 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=947, meanQ=8.399313, numObservations: 9
action 5, numVisits=5, meanQ=5.402020, numObservations: 3
action 2, numVisits=8, meanQ=5.121250, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 25484 episodes
GETTING ACTION FROM:
action 3, numVisits=26318, meanQ=4.427117, numObservations: 9
action 2, numVisits=14, meanQ=0.748210, numObservations: 6
action 5, numVisits=16, meanQ=0.688131, numObservations: 7
action -1, numVisits=48, meanQ=-1.855625, numObservations: 39
action 0, numVisits=46, meanQ=-1.870870, numObservations: 30
action 1, numVisits=5, meanQ=-2.402000, numObservations: 3
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.515952 0.143746 0.531513 0.552823 0.969888 0.37455 0.705172 0.0887693 0.768096 0.738093 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 5
Initial state: 0 0.512633 0.644647 0.259976 0.21427 0.83463 0.567294 0.96725 0.157776 0.989788 0.95187 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29152 episodes
GETTING ACTION FROM:
action 3, numVisits=29144, meanQ=7.428733, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.512633 0.644647 0.259976 0.21427 0.83463 0.567294 0.96725 0.157776 0.989788 0.95187 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 6
Initial state: 0 0.779477 0.846845 0.00752346 0.739182 0.492459 0.708158 0.916474 0.576483 0.0992565 0.730124 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28397 episodes
GETTING ACTION FROM:
action 2, numVisits=28365, meanQ=7.308122, numObservations: 9
action 5, numVisits=23, meanQ=5.162196, numObservations: 7
action 1, numVisits=3, meanQ=0.666667, numObservations: 3
action 4, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.779477 0.846845 0.00752346 0.739182 0.492459 0.708158 0.916474 0.576483 0.0992565 0.730124 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1970, meanQ=10.269525, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 10545 episodes
GETTING ACTION FROM:
action 5, numVisits=10479, meanQ=10.428356, numObservations: 9
action 2, numVisits=1974, meanQ=10.287807, numObservations: 9
action 3, numVisits=3, meanQ=-7.377573, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=40, meanQ=-28.301519, numObservations: 33
action 0, numVisits=19, meanQ=-56.461789, numObservations: 15
action 4, numVisits=5, meanQ=-206.475341, numObservations: 4
action: 5
Next state: 0 0.779477 0.846845 0.00752346 0.739182 0.492459 0.708158 0.916474 0.576483 0.0992565 0.730124 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=436, meanQ=14.794496, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-8.456750, numObservations: 1
action 5, numVisits=1, meanQ=-8.830382, numObservations: 1
action 4, numVisits=1, meanQ=-9.129179, numObservations: 1
action 2, numVisits=1, meanQ=-1071.377550, numObservations: 1
Sampled 10199 episodes
GETTING ACTION FROM:
action 1, numVisits=10633, meanQ=15.423193, numObservations: 9
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 3, numVisits=1, meanQ=-8.456750, numObservations: 1
action 5, numVisits=1, meanQ=-8.830382, numObservations: 1
action 4, numVisits=1, meanQ=-9.129179, numObservations: 1
action 2, numVisits=1, meanQ=-1071.377550, numObservations: 1
action: 1
Next state: 2 0.779477 0.846845 0.00752346 0.739182 0.492459 0.708158 0.916474 0.576483 0.0992565 0.730124 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -18.7411
Run # 7
Initial state: 0 0.421767 0.52562 0.361595 0.0259129 0.673689 0.370842 0.483755 0.709467 0.824644 0.89121 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29076 episodes
GETTING ACTION FROM:
action 1, numVisits=29060, meanQ=7.245558, numObservations: 9
action 4, numVisits=11, meanQ=1.281836, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.421767 0.52562 0.361595 0.0259129 0.673689 0.370842 0.483755 0.709467 0.824644 0.89121 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=4768, meanQ=8.865004, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 7661 episodes
GETTING ACTION FROM:
action 4, numVisits=12396, meanQ=7.618737, numObservations: 9
action 3, numVisits=12, meanQ=2.386681, numObservations: 7
action 0, numVisits=15, meanQ=-1.955865, numObservations: 14
action -1, numVisits=8, meanQ=-2.279247, numObservations: 7
action 5, numVisits=2, meanQ=-7.005000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.421767 0.52562 0.361595 0.0259129 0.673689 0.370842 0.483755 0.709467 0.824644 0.89121 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 8
Initial state: 0 0.00263009 0.353254 0.340443 0.125715 0.634296 0.0892433 0.572057 0.392754 0.52431 0.638922 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28895 episodes
GETTING ACTION FROM:
action 1, numVisits=28887, meanQ=7.083815, numObservations: 9
action 2, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.00263009 0.353254 0.340443 0.125715 0.634296 0.0892433 0.572057 0.392754 0.52431 0.638922 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=4761, meanQ=8.708866, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 8588 episodes
GETTING ACTION FROM:
action 2, numVisits=13291, meanQ=8.601357, numObservations: 9
action 3, numVisits=8, meanQ=0.191078, numObservations: 7
action 0, numVisits=17, meanQ=-1.068235, numObservations: 17
action -1, numVisits=13, meanQ=-1.238462, numObservations: 13
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=26, meanQ=-34.928327, numObservations: 9
action: 2
Next state: 0 0.00263009 0.353254 0.340443 0.125715 0.634296 0.0892433 0.572057 0.392754 0.52431 0.638922 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=1124, meanQ=11.697074, numObservations: 9
action 4, numVisits=694, meanQ=11.092880, numObservations: 9
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 6461 episodes
GETTING ACTION FROM:
action 4, numVisits=3608, meanQ=9.999854, numObservations: 9
action 3, numVisits=4671, meanQ=9.796836, numObservations: 9
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.00263009 0.353254 0.340443 0.125715 0.634296 0.0892433 0.572057 0.392754 0.52431 0.638922 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -18.7411
Run # 9
Initial state: 0 0.336719 0.928681 0.765292 0.52933 0.381598 0.541112 0.453158 0.0204115 0.442548 0.572775 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28934 episodes
GETTING ACTION FROM:
action 1, numVisits=28926, meanQ=7.454991, numObservations: 9
action 2, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.336719 0.928681 0.765292 0.52933 0.381598 0.541112 0.453158 0.0204115 0.442548 0.572775 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 10
Initial state: 0 0.340278 0.185663 0.430641 0.679361 0.788835 0.503803 0.0849078 0.337017 0.105899 0.770273 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28551 episodes
GETTING ACTION FROM:
action 5, numVisits=28545, meanQ=7.071757, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.340278 0.185663 0.430641 0.679361 0.788835 0.503803 0.0849078 0.337017 0.105899 0.770273 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=2168, meanQ=9.053906, numObservations: 9
action 4, numVisits=9, meanQ=5.443333, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 9336 episodes
GETTING ACTION FROM:
action 4, numVisits=9231, meanQ=10.268691, numObservations: 9
action 1, numVisits=2275, meanQ=9.172603, numObservations: 9
action 0, numVisits=5, meanQ=-1.208000, numObservations: 5
action -1, numVisits=4, meanQ=-1.505000, numObservations: 4
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.340278 0.185663 0.430641 0.679361 0.788835 0.503803 0.0849078 0.337017 0.105899 0.770273 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 11
Initial state: 0 0.441937 0.694363 0.970552 0.982208 0.0475136 0.984545 0.934578 0.00522513 0.639049 0.1069 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29016 episodes
GETTING ACTION FROM:
action 3, numVisits=28995, meanQ=7.540651, numObservations: 9
action 5, numVisits=16, meanQ=3.874381, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.441937 0.694363 0.970552 0.982208 0.0475136 0.984545 0.934578 0.00522513 0.639049 0.1069 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=126, meanQ=10.472035, numObservations: 9
action 4, numVisits=20, meanQ=8.504005, numObservations: 9
action 1, numVisits=4, meanQ=6.500000, numObservations: 3
action 2, numVisits=4, meanQ=6.500000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 15011 episodes
GETTING ACTION FROM:
action 1, numVisits=14976, meanQ=12.177546, numObservations: 9
action 3, numVisits=132, meanQ=10.602095, numObservations: 9
action 2, numVisits=6, meanQ=0.666667, numObservations: 5
action 0, numVisits=7, meanQ=-1.717143, numObservations: 7
action -1, numVisits=6, meanQ=-1.835000, numObservations: 6
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=40, meanQ=-20.479001, numObservations: 9
action: 1
Next state: 1 0.441937 0.694363 0.970552 0.982208 0.0475136 0.984545 0.934578 0.00522513 0.639049 0.1069 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 12
Initial state: 0 0.517802 0.536994 0.678368 0.376102 0.904613 0.924863 0.045935 0.0639895 0.54738 0.765715 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29017 episodes
GETTING ACTION FROM:
action 5, numVisits=29005, meanQ=7.239039, numObservations: 9
action 1, numVisits=4, meanQ=1.497500, numObservations: 4
action 2, numVisits=4, meanQ=1.497500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.517802 0.536994 0.678368 0.376102 0.904613 0.924863 0.045935 0.0639895 0.54738 0.765715 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 13
Initial state: 0 0.820972 0.338092 0.672259 0.700224 0.734883 0.564436 0.643303 0.794977 0.463051 0.714529 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28410 episodes
GETTING ACTION FROM:
action 5, numVisits=28404, meanQ=7.210429, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.820972 0.338092 0.672259 0.700224 0.734883 0.564436 0.643303 0.794977 0.463051 0.714529 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 14
Initial state: 0 0.0918211 0.236326 0.436436 0.556177 0.284341 0.90655 0.0198784 0.504225 0.492629 0.866776 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29083 episodes
GETTING ACTION FROM:
action 1, numVisits=29075, meanQ=7.404731, numObservations: 9
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.0918211 0.236326 0.436436 0.556177 0.284341 0.90655 0.0198784 0.504225 0.492629 0.866776 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=4915, meanQ=8.787480, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 8398 episodes
GETTING ACTION FROM:
action 3, numVisits=13298, meanQ=7.537362, numObservations: 9
action -1, numVisits=8, meanQ=-2.409257, numObservations: 7
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=7, meanQ=-3.539524, numObservations: 6
action 4, numVisits=2, meanQ=-6.597315, numObservations: 2
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.0918211 0.236326 0.436436 0.556177 0.284341 0.90655 0.0198784 0.504225 0.492629 0.866776 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 15
Initial state: 0 0.0551168 0.787644 0.825439 0.152347 0.954299 0.760353 0.0244211 0.181407 0.517867 0.591884 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29071 episodes
GETTING ACTION FROM:
action 2, numVisits=29061, meanQ=7.347981, numObservations: 9
action 1, numVisits=5, meanQ=3.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.0551168 0.787644 0.825439 0.152347 0.954299 0.760353 0.0244211 0.181407 0.517867 0.591884 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 16
Initial state: 0 0.505825 0.58128 0.389303 0.931135 0.154829 0.481168 0.147409 0.0159686 0.125352 0.0265022 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29007 episodes
GETTING ACTION FROM:
action 5, numVisits=28980, meanQ=7.064564, numObservations: 9
action 2, numVisits=8, meanQ=-0.501237, numObservations: 5
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 1, numVisits=9, meanQ=-1.446667, numObservations: 6
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 0 0.505825 0.58128 0.389303 0.931135 0.154829 0.481168 0.147409 0.0159686 0.125352 0.0265022 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=4739, meanQ=8.678830, numObservations: 9
action 3, numVisits=6, meanQ=5.330033, numObservations: 3
action 1, numVisits=5, meanQ=4.598000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 6987 episodes
GETTING ACTION FROM:
action 4, numVisits=11673, meanQ=8.358439, numObservations: 9
action 3, numVisits=26, meanQ=5.216139, numObservations: 7
action 1, numVisits=6, meanQ=1.998333, numObservations: 3
action -1, numVisits=14, meanQ=-1.151429, numObservations: 14
action 0, numVisits=19, meanQ=-1.192606, numObservations: 16
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 4
Next state: 0 0.505825 0.58128 0.389303 0.931135 0.154829 0.481168 0.147409 0.0159686 0.125352 0.0265022 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=1590, meanQ=9.790587, numObservations: 9
action 0, numVisits=7, meanQ=-1.010000, numObservations: 7
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=5, meanQ=-3.386000, numObservations: 4
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 6297 episodes
GETTING ACTION FROM:
action 2, numVisits=7887, meanQ=9.805287, numObservations: 9
action 0, numVisits=7, meanQ=-1.010000, numObservations: 7
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=5, meanQ=-3.386000, numObservations: 4
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.505825 0.58128 0.389303 0.931135 0.154829 0.481168 0.147409 0.0159686 0.125352 0.0265022 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action -1, numVisits=101, meanQ=3.085578, numObservations: 31
action 1, numVisits=128, meanQ=-2.792989, numObservations: 9
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=2, meanQ=-6.721733, numObservations: 2
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action 0, numVisits=9, meanQ=-60.441644, numObservations: 8
Sampled 10891 episodes
GETTING ACTION FROM:
action 3, numVisits=10860, meanQ=12.654259, numObservations: 9
action 1, numVisits=128, meanQ=-2.792989, numObservations: 9
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=134, meanQ=-5.333322, numObservations: 41
action 2, numVisits=2, meanQ=-6.721733, numObservations: 2
action 0, numVisits=9, meanQ=-60.441644, numObservations: 8
action: 3
Next state: 0 0.505825 0.58128 0.389303 0.931135 0.154829 0.481168 0.147409 0.0159686 0.125352 0.0265022 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 3, numVisits=320, meanQ=9.033410, numObservations: 9
action -1, numVisits=45, meanQ=-14.973403, numObservations: 13
action 1, numVisits=5, meanQ=-59.740068, numObservations: 3
action 0, numVisits=6, meanQ=-60.673121, numObservations: 5
action 2, numVisits=1, meanQ=-360.307135, numObservations: 1
action 4, numVisits=1, meanQ=-364.230640, numObservations: 1
action 5, numVisits=1, meanQ=-364.335180, numObservations: 1
Sampled 10048 episodes
GETTING ACTION FROM:
action 3, numVisits=323, meanQ=9.041325, numObservations: 9
action -1, numVisits=10090, meanQ=0.294468, numObservations: 162
action 1, numVisits=5, meanQ=-59.740068, numObservations: 3
action 0, numVisits=6, meanQ=-60.673121, numObservations: 5
action 2, numVisits=1, meanQ=-360.307135, numObservations: 1
action 4, numVisits=1, meanQ=-364.230640, numObservations: 1
action 5, numVisits=1, meanQ=-364.335180, numObservations: 1
action: 3
Next state: 0 0.505825 0.58128 0.389303 0.931135 0.154829 0.481168 0.147409 0.0159686 0.125352 0.0265022 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 5
Improving policy...
PLANNING FROM:
action 1, numVisits=233, meanQ=20.865310, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-360.764711, numObservations: 1
action 4, numVisits=1, meanQ=-363.736620, numObservations: 1
action 5, numVisits=1, meanQ=-364.059515, numObservations: 1
Sampled 37269 episodes
GETTING ACTION FROM:
action 1, numVisits=37502, meanQ=21.468091, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-360.764711, numObservations: 1
action 4, numVisits=1, meanQ=-363.736620, numObservations: 1
action 5, numVisits=1, meanQ=-364.059515, numObservations: 1
action: 1
Next state: 1 0.505825 0.58128 0.389303 0.931135 0.154829 0.481168 0.147409 0.0159686 0.125352 0.0265022 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 3.21978
Run # 17
Initial state: 0 0.247888 0.715634 0.264045 0.357451 0.539619 0.666066 0.321624 0.0902504 0.239813 0.737072 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28414 episodes
GETTING ACTION FROM:
action 1, numVisits=28402, meanQ=7.547341, numObservations: 9
action 5, numVisits=7, meanQ=1.714314, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.247888 0.715634 0.264045 0.357451 0.539619 0.666066 0.321624 0.0902504 0.239813 0.737072 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=950, meanQ=8.055591, numObservations: 9
action 0, numVisits=7, meanQ=-1.010000, numObservations: 7
action -1, numVisits=6, meanQ=-2.990000, numObservations: 5
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 9165 episodes
GETTING ACTION FROM:
action 2, numVisits=10077, meanQ=9.232797, numObservations: 9
action 0, numVisits=44, meanQ=-1.696210, numObservations: 39
action -1, numVisits=6, meanQ=-2.990000, numObservations: 5
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=2, meanQ=-7.005000, numObservations: 1
action: 2
Next state: 0 0.247888 0.715634 0.264045 0.357451 0.539619 0.666066 0.321624 0.0902504 0.239813 0.737072 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=807, meanQ=13.205843, numObservations: 9
action 4, numVisits=6, meanQ=3.330000, numObservations: 5
action 0, numVisits=16, meanQ=-1.917368, numObservations: 15
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=5, meanQ=-3.351089, numObservations: 4
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 9269 episodes
GETTING ACTION FROM:
action 3, numVisits=10076, meanQ=9.832893, numObservations: 9
action 4, numVisits=6, meanQ=3.330000, numObservations: 5
action 0, numVisits=16, meanQ=-1.917368, numObservations: 15
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=5, meanQ=-3.351089, numObservations: 4
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.247888 0.715634 0.264045 0.357451 0.539619 0.666066 0.321624 0.0902504 0.239813 0.737072 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 18
Initial state: 0 0.667379 0.813962 0.806538 0.540465 0.512092 0.58541 0.126091 0.917135 0.203628 0.761634 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26028 episodes
GETTING ACTION FROM:
action 5, numVisits=26022, meanQ=7.719841, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.667379 0.813962 0.806538 0.540465 0.512092 0.58541 0.126091 0.917135 0.203628 0.761634 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 19
Initial state: 0 0.355851 0.869383 0.800182 0.00391522 0.163804 0.0014626 0.630943 0.565215 0.514583 0.702932 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28925 episodes
GETTING ACTION FROM:
action 1, numVisits=28915, meanQ=7.092865, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.355851 0.869383 0.800182 0.00391522 0.163804 0.0014626 0.630943 0.565215 0.514583 0.702932 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 20
Initial state: 0 0.732699 0.152632 0.526449 0.403937 0.96936 0.0747915 0.18051 0.143069 0.528875 0.62833 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28938 episodes
GETTING ACTION FROM:
action 1, numVisits=28924, meanQ=7.220596, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 2, numVisits=5, meanQ=-2.600000, numObservations: 3
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.732699 0.152632 0.526449 0.403937 0.96936 0.0747915 0.18051 0.143069 0.528875 0.62833 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 21
Initial state: 0 0.898053 0.465032 0.466382 0.553417 0.0651714 0.842372 0.563407 0.397608 0.236727 0.444762 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17846 episodes
GETTING ACTION FROM:
action -1, numVisits=17818, meanQ=12.501046, numObservations: 243
action 0, numVisits=11, meanQ=-1.190900, numObservations: 10
action 3, numVisits=6, meanQ=-1.668317, numObservations: 4
action 5, numVisits=6, meanQ=-2.503333, numObservations: 5
action 1, numVisits=2, meanQ=-5.489950, numObservations: 1
action 2, numVisits=2, meanQ=-7.500000, numObservations: 2
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.898053 0.465032 0.466382 0.553417 0.0651714 0.842372 0.563407 0.397608 0.236727 0.444762 w: 1
Observation: 0 3 0 2 0 1 0 2 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=48, meanQ=9.801677, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 34471 episodes
GETTING ACTION FROM:
action 2, numVisits=34519, meanQ=13.681955, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.898053 0.465032 0.466382 0.553417 0.0651714 0.842372 0.563407 0.397608 0.236727 0.444762 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 22
Initial state: 0 0.190217 0.0839376 0.55417 0.567034 0.878526 0.040717 0.416563 0.737954 0.919816 0.817407 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28004 episodes
GETTING ACTION FROM:
action 3, numVisits=27998, meanQ=7.303662, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.190217 0.0839376 0.55417 0.567034 0.878526 0.040717 0.416563 0.737954 0.919816 0.817407 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 23
Initial state: 0 0.441252 0.525979 0.689315 0.108345 0.51119 0.689263 0.594774 0.0202183 0.213262 0.701679 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28931 episodes
GETTING ACTION FROM:
action 5, numVisits=28925, meanQ=7.206844, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 0 0.441252 0.525979 0.689315 0.108345 0.51119 0.689263 0.594774 0.0202183 0.213262 0.701679 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=941, meanQ=7.451084, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 8969 episodes
GETTING ACTION FROM:
action 4, numVisits=9840, meanQ=6.671230, numObservations: 9
action 0, numVisits=29, meanQ=-2.731592, numObservations: 26
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=42, meanQ=-26.573510, numObservations: 37
action: 4
Next state: 2 0.441252 0.525979 0.689315 0.108345 0.51119 0.689263 0.594774 0.0202183 0.213262 0.701679 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 24
Initial state: 0 0.120673 0.908873 0.284692 0.394509 0.514286 0.668122 0.0655822 0.10752 0.956819 0.672069 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17809 episodes
GETTING ACTION FROM:
action 0, numVisits=17793, meanQ=14.171311, numObservations: 243
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 2, numVisits=4, meanQ=-1.472500, numObservations: 3
action 1, numVisits=2, meanQ=-7.500000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.120673 0.908873 0.284692 0.394509 0.514286 0.668122 0.0655822 0.10752 0.956819 0.672069 w: 1
Observation: 0 0 3 0 1 0 2 0 1 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=86, meanQ=19.639656, numObservations: 9
action 1, numVisits=7, meanQ=10.141429, numObservations: 3
action 5, numVisits=11, meanQ=9.909100, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 37649 episodes
GETTING ACTION FROM:
action 3, numVisits=37735, meanQ=21.543721, numObservations: 9
action 1, numVisits=7, meanQ=10.141429, numObservations: 3
action 5, numVisits=11, meanQ=9.909100, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.120673 0.908873 0.284692 0.394509 0.514286 0.668122 0.0655822 0.10752 0.956819 0.672069 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 25
Initial state: 0 0.609535 0.955261 0.174694 0.191238 0.890408 0.458718 0.171535 0.611262 0.521576 0.679478 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28951 episodes
GETTING ACTION FROM:
action 1, numVisits=28945, meanQ=7.151183, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.609535 0.955261 0.174694 0.191238 0.890408 0.458718 0.171535 0.611262 0.521576 0.679478 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 26
Initial state: 0 0.000840498 0.431325 0.281307 0.966834 0.967599 0.207256 0.525201 0.568593 0.890557 0.154469 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28777 episodes
GETTING ACTION FROM:
action 3, numVisits=28771, meanQ=6.917315, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.000840498 0.431325 0.281307 0.966834 0.967599 0.207256 0.525201 0.568593 0.890557 0.154469 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 27
Initial state: 0 0.728101 0.453823 0.198078 0.652152 0.395741 0.110903 0.516433 0.629207 0.276749 0.21655 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29322 episodes
GETTING ACTION FROM:
action 3, numVisits=29312, meanQ=7.189869, numObservations: 9
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action 1, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.728101 0.453823 0.198078 0.652152 0.395741 0.110903 0.516433 0.629207 0.276749 0.21655 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 28
Initial state: 0 0.515388 0.69673 0.136794 0.408066 0.0704431 0.443576 0.580967 0.500194 0.588811 0.58693 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27968 episodes
GETTING ACTION FROM:
action 1, numVisits=27958, meanQ=7.544689, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.515388 0.69673 0.136794 0.408066 0.0704431 0.443576 0.580967 0.500194 0.588811 0.58693 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 29
Initial state: 0 0.815644 0.0813583 0.444131 0.697341 0.0125589 0.111997 0.939684 0.406208 0.962303 0.247104 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 25957 episodes
GETTING ACTION FROM:
action 2, numVisits=25948, meanQ=6.657014, numObservations: 9
action 1, numVisits=4, meanQ=0.505025, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.815644 0.0813583 0.444131 0.697341 0.0125589 0.111997 0.939684 0.406208 0.962303 0.247104 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=396, meanQ=20.032431, numObservations: 9
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 23638 episodes
GETTING ACTION FROM:
action 2, numVisits=410, meanQ=20.150321, numObservations: 9
action 1, numVisits=23607, meanQ=12.214554, numObservations: 9
action 0, numVisits=11, meanQ=-1.730000, numObservations: 10
action -1, numVisits=10, meanQ=-1.802000, numObservations: 9
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.815644 0.0813583 0.444131 0.697341 0.0125589 0.111997 0.939684 0.406208 0.962303 0.247104 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 30
Initial state: 0 0.45307 0.673967 0.732694 0.884179 0.289633 0.320257 0.987542 0.228861 0.839314 0.34918 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29202 episodes
GETTING ACTION FROM:
action 2, numVisits=29148, meanQ=7.506742, numObservations: 9
action 5, numVisits=47, meanQ=5.391563, numObservations: 9
action 1, numVisits=3, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 2 0.45307 0.673967 0.732694 0.884179 0.289633 0.320257 0.987542 0.228861 0.839314 0.34918 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 31
Initial state: 0 0.547656 0.180438 0.864726 0.33669 0.193959 0.611592 0.510464 0.614195 0.746203 0.184269 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28539 episodes
GETTING ACTION FROM:
action 5, numVisits=28531, meanQ=7.567836, numObservations: 9
action 1, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.547656 0.180438 0.864726 0.33669 0.193959 0.611592 0.510464 0.614195 0.746203 0.184269 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=818, meanQ=7.909985, numObservations: 9
action -1, numVisits=15, meanQ=-0.416660, numObservations: 12
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 27189 episodes
GETTING ACTION FROM:
action 3, numVisits=27908, meanQ=4.702550, numObservations: 9
action -1, numVisits=79, meanQ=-1.423795, numObservations: 59
action 0, numVisits=40, meanQ=-1.703000, numObservations: 30
action 4, numVisits=2, meanQ=-7.005000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.547656 0.180438 0.864726 0.33669 0.193959 0.611592 0.510464 0.614195 0.746203 0.184269 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=393, meanQ=11.659267, numObservations: 9
action 2, numVisits=17, meanQ=3.663667, numObservations: 5
action 0, numVisits=30, meanQ=-1.191537, numObservations: 22
action -1, numVisits=10, meanQ=-1.407980, numObservations: 8
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 27791 episodes
GETTING ACTION FROM:
action 1, numVisits=28184, meanQ=8.322712, numObservations: 9
action 2, numVisits=17, meanQ=3.663667, numObservations: 5
action 0, numVisits=30, meanQ=-1.191537, numObservations: 22
action -1, numVisits=10, meanQ=-1.407980, numObservations: 8
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.547656 0.180438 0.864726 0.33669 0.193959 0.611592 0.510464 0.614195 0.746203 0.184269 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -18.7411
Run # 32
Initial state: 0 0.23611 0.998334 0.575909 0.0365643 0.157893 0.133884 0.430725 0.57985 0.569288 0.873462 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28754 episodes
GETTING ACTION FROM:
action 5, numVisits=28746, meanQ=6.819625, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.23611 0.998334 0.575909 0.0365643 0.157893 0.133884 0.430725 0.57985 0.569288 0.873462 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 33
Initial state: 0 0.93291 0.521661 0.184337 0.059066 0.712617 0.804517 0.793937 0.114985 0.496178 0.692245 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28994 episodes
GETTING ACTION FROM:
action 2, numVisits=28985, meanQ=7.142362, numObservations: 9
action 3, numVisits=4, meanQ=0.277500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.93291 0.521661 0.184337 0.059066 0.712617 0.804517 0.793937 0.114985 0.496178 0.692245 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=937, meanQ=8.755280, numObservations: 9
action 5, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 29905 episodes
GETTING ACTION FROM:
action 5, numVisits=28514, meanQ=5.267267, numObservations: 9
action 4, numVisits=2280, meanQ=4.965734, numObservations: 9
action 0, numVisits=26, meanQ=-1.771538, numObservations: 23
action -1, numVisits=23, meanQ=-1.827826, numObservations: 21
action 3, numVisits=5, meanQ=-2.402000, numObservations: 5
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.93291 0.521661 0.184337 0.059066 0.712617 0.804517 0.793937 0.114985 0.496178 0.692245 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 34
Initial state: 0 0.384636 0.447716 0.69074 0.0760322 0.54027 0.548777 0.601186 0.651038 0.755347 0.399938 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29215 episodes
GETTING ACTION FROM:
action 3, numVisits=29192, meanQ=7.298751, numObservations: 9
action -1, numVisits=5, meanQ=-1.010000, numObservations: 5
action 0, numVisits=5, meanQ=-1.010000, numObservations: 5
action 1, numVisits=5, meanQ=-1.200000, numObservations: 4
action 2, numVisits=5, meanQ=-1.200000, numObservations: 5
action 5, numVisits=2, meanQ=-4.000000, numObservations: 2
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.384636 0.447716 0.69074 0.0760322 0.54027 0.548777 0.601186 0.651038 0.755347 0.399938 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=477, meanQ=19.411663, numObservations: 9
action 5, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 30218 episodes
GETTING ACTION FROM:
action 3, numVisits=503, meanQ=19.617442, numObservations: 9
action 2, numVisits=30153, meanQ=10.016212, numObservations: 9
action 5, numVisits=25, meanQ=4.583993, numObservations: 8
action -1, numVisits=10, meanQ=-1.703000, numObservations: 10
action 0, numVisits=8, meanQ=-1.876250, numObservations: 8
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.384636 0.447716 0.69074 0.0760322 0.54027 0.548777 0.601186 0.651038 0.755347 0.399938 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 35
Initial state: 0 0.419416 0.928023 0.0592261 0.0755494 0.181766 0.43747 0.502826 0.642387 0.900367 0.348969 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28484 episodes
GETTING ACTION FROM:
action 4, numVisits=28469, meanQ=7.502212, numObservations: 9
action 1, numVisits=3, meanQ=3.000000, numObservations: 2
action 2, numVisits=6, meanQ=3.000000, numObservations: 4
action 3, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.419416 0.928023 0.0592261 0.0755494 0.181766 0.43747 0.502826 0.642387 0.900367 0.348969 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 36
Initial state: 0 0.344713 0.879059 0.780654 0.158718 0.429251 0.570325 0.490629 0.708225 0.0611262 0.971975 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28749 episodes
GETTING ACTION FROM:
action 2, numVisits=28717, meanQ=7.074966, numObservations: 9
action 4, numVisits=17, meanQ=5.411771, numObservations: 6
action 3, numVisits=11, meanQ=3.816364, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.344713 0.879059 0.780654 0.158718 0.429251 0.570325 0.490629 0.708225 0.0611262 0.971975 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 37
Initial state: 0 0.187998 0.337896 0.918364 0.127641 0.272577 0.800818 0.48645 0.588842 0.752571 0.395723 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28981 episodes
GETTING ACTION FROM:
action 5, numVisits=28957, meanQ=7.356342, numObservations: 9
action 3, numVisits=15, meanQ=5.266013, numObservations: 8
action 1, numVisits=5, meanQ=3.552000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.187998 0.337896 0.918364 0.127641 0.272577 0.800818 0.48645 0.588842 0.752571 0.395723 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 38
Initial state: 0 0.63181 0.137371 0.951963 0.318956 0.00999771 0.101248 0.51366 0.703572 0.465862 0.854252 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29128 episodes
GETTING ACTION FROM:
action 2, numVisits=29108, meanQ=7.494149, numObservations: 9
action 1, numVisits=11, meanQ=0.363645, numObservations: 7
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.63181 0.137371 0.951963 0.318956 0.00999771 0.101248 0.51366 0.703572 0.465862 0.854252 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 39
Initial state: 0 0.0804961 0.98858 0.215507 0.880304 0.560673 0.711247 0.289731 0.0586251 0.596941 0.357676 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29295 episodes
GETTING ACTION FROM:
action 5, numVisits=29283, meanQ=7.399549, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 2, numVisits=2, meanQ=-4.000000, numObservations: 2
action 1, numVisits=2, meanQ=-7.500000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.0804961 0.98858 0.215507 0.880304 0.560673 0.711247 0.289731 0.0586251 0.596941 0.357676 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=172, meanQ=8.705829, numObservations: 9
action 1, numVisits=9, meanQ=2.442222, numObservations: 6
action 3, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 35873 episodes
GETTING ACTION FROM:
action 2, numVisits=36041, meanQ=12.494896, numObservations: 9
action 1, numVisits=9, meanQ=2.442222, numObservations: 6
action 3, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=3, meanQ=-1.670000, numObservations: 3
action 0, numVisits=3, meanQ=-1.670000, numObservations: 3
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.0804961 0.98858 0.215507 0.880304 0.560673 0.711247 0.289731 0.0586251 0.596941 0.357676 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=54, meanQ=11.608543, numObservations: 6
action 3, numVisits=102, meanQ=1.314878, numObservations: 9
action -1, numVisits=7, meanQ=-2.707143, numObservations: 6
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=6, meanQ=-177.313820, numObservations: 5
Sampled 30843 episodes
GETTING ACTION FROM:
action 3, numVisits=30763, meanQ=15.008261, numObservations: 9
action 2, numVisits=93, meanQ=14.299164, numObservations: 7
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=150, meanQ=-5.224805, numObservations: 57
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=6, meanQ=-177.313820, numObservations: 5
action: 3
Next state: 1 0.0804961 0.98858 0.215507 0.880304 0.560673 0.711247 0.289731 0.0586251 0.596941 0.357676 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 40
Initial state: 0 0.995999 0.910936 0.322764 0.0910936 0.548195 0.604593 0.709596 0.316471 0.0794613 0.368208 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28813 episodes
GETTING ACTION FROM:
action 2, numVisits=28807, meanQ=7.165153, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.995999 0.910936 0.322764 0.0910936 0.548195 0.604593 0.709596 0.316471 0.0794613 0.368208 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=4775, meanQ=8.711313, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 7409 episodes
GETTING ACTION FROM:
action 5, numVisits=12134, meanQ=7.354809, numObservations: 9
action -1, numVisits=11, meanQ=-1.461800, numObservations: 9
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=2, meanQ=-6.245770, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=40, meanQ=-25.696948, numObservations: 30
action: 5
Next state: 0 0.995999 0.910936 0.322764 0.0910936 0.548195 0.604593 0.709596 0.316471 0.0794613 0.368208 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=1647, meanQ=11.389308, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 5565 episodes
GETTING ACTION FROM:
action 3, numVisits=7206, meanQ=10.800244, numObservations: 9
action -1, numVisits=5, meanQ=-1.208000, numObservations: 5
action 0, numVisits=5, meanQ=-1.208000, numObservations: 5
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.995999 0.910936 0.322764 0.0910936 0.548195 0.604593 0.709596 0.316471 0.0794613 0.368208 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 41
Initial state: 0 0.421571 0.227104 0.620976 0.886354 0.425479 0.727052 0.759145 0.420544 0.53998 0.711272 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28782 episodes
GETTING ACTION FROM:
action 3, numVisits=28761, meanQ=7.274716, numObservations: 9
action 2, numVisits=13, meanQ=5.229238, numObservations: 7
action 1, numVisits=4, meanQ=1.250000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.421571 0.227104 0.620976 0.886354 0.425479 0.727052 0.759145 0.420544 0.53998 0.711272 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=976, meanQ=8.686865, numObservations: 9
action 5, numVisits=5, meanQ=6.196000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 9194 episodes
GETTING ACTION FROM:
action 1, numVisits=10083, meanQ=8.192836, numObservations: 9
action 5, numVisits=9, meanQ=0.915568, numObservations: 6
action 0, numVisits=38, meanQ=-2.839183, numObservations: 31
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=2, meanQ=-4.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=46, meanQ=-23.226678, numObservations: 38
action: 1
Next state: 0 0.421571 0.227104 0.620976 0.886354 0.425479 0.727052 0.759145 0.420544 0.53998 0.711272 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=1071, meanQ=9.897950, numObservations: 9
action -1, numVisits=29, meanQ=-1.053318, numObservations: 17
action 0, numVisits=7, meanQ=-2.707143, numObservations: 6
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 6966 episodes
GETTING ACTION FROM:
action 2, numVisits=8037, meanQ=10.045687, numObservations: 9
action -1, numVisits=29, meanQ=-1.053318, numObservations: 17
action 0, numVisits=7, meanQ=-2.707143, numObservations: 6
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.421571 0.227104 0.620976 0.886354 0.425479 0.727052 0.759145 0.420544 0.53998 0.711272 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 42
Initial state: 0 0.518507 0.562191 0.930717 0.125913 0.821707 0.832787 0.649088 0.425342 0.545454 0.180292 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29020 episodes
GETTING ACTION FROM:
action 1, numVisits=29014, meanQ=7.277711, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.518507 0.562191 0.930717 0.125913 0.821707 0.832787 0.649088 0.425342 0.545454 0.180292 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 43
Initial state: 0 0.633312 0.14625 0.91653 0.338583 0.982712 0.699751 0.566097 0.899189 0.513363 0.554567 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28982 episodes
GETTING ACTION FROM:
action 2, numVisits=28970, meanQ=7.105494, numObservations: 9
action 5, numVisits=7, meanQ=1.141429, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.633312 0.14625 0.91653 0.338583 0.982712 0.699751 0.566097 0.899189 0.513363 0.554567 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 44
Initial state: 0 0.221736 0.0850041 0.638776 0.181391 0.916609 0.983822 0.212465 0.353619 0.435398 0.57031 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29010 episodes
GETTING ACTION FROM:
action 4, numVisits=28998, meanQ=7.534721, numObservations: 9
action 3, numVisits=5, meanQ=0.596000, numObservations: 5
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 0 0.221736 0.0850041 0.638776 0.181391 0.916609 0.983822 0.212465 0.353619 0.435398 0.57031 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=549, meanQ=9.886454, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 12586 episodes
GETTING ACTION FROM:
action 2, numVisits=12820, meanQ=5.299602, numObservations: 9
action -1, numVisits=233, meanQ=-5.961889, numObservations: 141
action 3, numVisits=2, meanQ=-7.005000, numObservations: 1
action 1, numVisits=2, meanQ=-9.032481, numObservations: 2
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=82, meanQ=-14.795046, numObservations: 51
action: 2
Next state: 2 0.221736 0.0850041 0.638776 0.181391 0.916609 0.983822 0.212465 0.353619 0.435398 0.57031 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 45
Initial state: 0 0.730011 0.775029 0.349038 0.679842 0.543463 0.642596 0.382444 0.394037 0.229222 0.468938 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28989 episodes
GETTING ACTION FROM:
action 5, numVisits=28869, meanQ=7.305770, numObservations: 9
action 3, numVisits=115, meanQ=6.111957, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.730011 0.775029 0.349038 0.679842 0.543463 0.642596 0.382444 0.394037 0.229222 0.468938 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=4719, meanQ=8.593893, numObservations: 9
action 1, numVisits=10, meanQ=6.500000, numObservations: 6
action 2, numVisits=12, meanQ=6.415850, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 9230 episodes
GETTING ACTION FROM:
action 2, numVisits=7288, meanQ=8.522782, numObservations: 9
action 4, numVisits=6624, meanQ=8.381905, numObservations: 9
action 1, numVisits=13, meanQ=2.461538, numObservations: 7
action -1, numVisits=31, meanQ=-1.169677, numObservations: 30
action 0, numVisits=16, meanQ=-1.568113, numObservations: 13
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=2, meanQ=-5.846211, numObservations: 2
action: 2
Next state: 0 0.730011 0.775029 0.349038 0.679842 0.543463 0.642596 0.382444 0.394037 0.229222 0.468938 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 0, numVisits=100, meanQ=0.558621, numObservations: 62
action 3, numVisits=4, meanQ=-1.664509, numObservations: 4
action 4, numVisits=66, meanQ=-5.988279, numObservations: 8
action 2, numVisits=1, meanQ=-10.577231, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=43, meanQ=-24.773515, numObservations: 32
action 5, numVisits=1, meanQ=-1068.432596, numObservations: 1
Sampled 10160 episodes
GETTING ACTION FROM:
action 3, numVisits=10069, meanQ=11.951739, numObservations: 9
action 0, numVisits=195, meanQ=-3.560107, numObservations: 81
action 4, numVisits=66, meanQ=-5.988279, numObservations: 8
action 2, numVisits=1, meanQ=-10.577231, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=43, meanQ=-24.773515, numObservations: 32
action 5, numVisits=1, meanQ=-1068.432596, numObservations: 1
action: 3
Next state: 1 0.730011 0.775029 0.349038 0.679842 0.543463 0.642596 0.382444 0.394037 0.229222 0.468938 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 46
Initial state: 0 0.722695 0.780353 0.718703 0.767699 0.484791 0.643004 0.926842 0.735295 0.237066 0.48561 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28399 episodes
GETTING ACTION FROM:
action 1, numVisits=28390, meanQ=7.309956, numObservations: 9
action 3, numVisits=4, meanQ=2.255025, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.722695 0.780353 0.718703 0.767699 0.484791 0.643004 0.926842 0.735295 0.237066 0.48561 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 47
Initial state: 0 0.91997 0.0215581 0.542891 0.603005 0.621057 0.555876 0.13416 0.170834 0.355257 0.924448 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28947 episodes
GETTING ACTION FROM:
action 4, numVisits=28934, meanQ=7.198851, numObservations: 9
action 1, numVisits=6, meanQ=4.331667, numObservations: 5
action 5, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.91997 0.0215581 0.542891 0.603005 0.621057 0.555876 0.13416 0.170834 0.355257 0.924448 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=4750, meanQ=8.274792, numObservations: 9
action 1, numVisits=8, meanQ=4.872513, numObservations: 6
action 3, numVisits=4, meanQ=0.772500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 8842 episodes
GETTING ACTION FROM:
action 2, numVisits=13498, meanQ=6.745417, numObservations: 9
action 1, numVisits=85, meanQ=4.861272, numObservations: 9
action 3, numVisits=5, meanQ=-1.582000, numObservations: 4
action 0, numVisits=15, meanQ=-1.969277, numObservations: 13
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=2, meanQ=-6.075697, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.91997 0.0215581 0.542891 0.603005 0.621057 0.555876 0.13416 0.170834 0.355257 0.924448 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 48
Initial state: 0 0.809872 0.270277 0.140852 0.141904 0.0475703 0.0551028 0.445085 0.686669 0.768483 0.391617 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28874 episodes
GETTING ACTION FROM:
action 5, numVisits=28862, meanQ=6.980253, numObservations: 9
action -1, numVisits=5, meanQ=-1.010000, numObservations: 5
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=3, meanQ=-4.970000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.809872 0.270277 0.140852 0.141904 0.0475703 0.0551028 0.445085 0.686669 0.768483 0.391617 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 49
Initial state: 0 0.700324 0.703067 0.194288 0.694525 0.961713 0.81585 0.343355 0.085511 0.484981 0.622029 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28319 episodes
GETTING ACTION FROM:
action 4, numVisits=28313, meanQ=7.335367, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.700324 0.703067 0.194288 0.694525 0.961713 0.81585 0.343355 0.085511 0.484981 0.622029 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=4666, meanQ=8.694204, numObservations: 9
action 2, numVisits=13, meanQ=6.383077, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 6967 episodes
GETTING ACTION FROM:
action 1, numVisits=11604, meanQ=8.401864, numObservations: 9
action 2, numVisits=21, meanQ=3.190237, numObservations: 7
action 0, numVisits=12, meanQ=-1.175000, numObservations: 12
action -1, numVisits=10, meanQ=-1.307000, numObservations: 10
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.700324 0.703067 0.194288 0.694525 0.961713 0.81585 0.343355 0.085511 0.484981 0.622029 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 50
Initial state: 0 0.290273 0.152583 0.211731 0.264243 0.44652 0.59126 0.218812 0.14737 0.407241 0.420688 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28079 episodes
GETTING ACTION FROM:
action 2, numVisits=28062, meanQ=7.209950, numObservations: 9
action -1, numVisits=6, meanQ=-1.010000, numObservations: 6
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 1, numVisits=2, meanQ=-7.500000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.290273 0.152583 0.211731 0.264243 0.44652 0.59126 0.218812 0.14737 0.407241 0.420688 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=4549, meanQ=8.473477, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 9275 episodes
GETTING ACTION FROM:
action 3, numVisits=13799, meanQ=8.394338, numObservations: 9
action 5, numVisits=6, meanQ=2.119392, numObservations: 5
action -1, numVisits=10, meanQ=-1.208000, numObservations: 10
action 0, numVisits=10, meanQ=-1.307000, numObservations: 10
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=2, meanQ=-4.004950, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 3
Next state: 0 0.290273 0.152583 0.211731 0.264243 0.44652 0.59126 0.218812 0.14737 0.407241 0.420688 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=170, meanQ=7.192656, numObservations: 7
action 5, numVisits=6, meanQ=-2.626378, numObservations: 4
action -1, numVisits=18, meanQ=-2.912914, numObservations: 15
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action 0, numVisits=75, meanQ=-9.689400, numObservations: 42
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 18927 episodes
GETTING ACTION FROM:
action 5, numVisits=17939, meanQ=12.140042, numObservations: 9
action 3, numVisits=203, meanQ=9.559170, numObservations: 8
action -1, numVisits=979, meanQ=-2.381953, numObservations: 125
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action 0, numVisits=75, meanQ=-9.689400, numObservations: 42
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.290273 0.152583 0.211731 0.264243 0.44652 0.59126 0.218812 0.14737 0.407241 0.420688 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=324, meanQ=8.154595, numObservations: 9
action -1, numVisits=98, meanQ=-6.621740, numObservations: 37
action 5, numVisits=2, meanQ=-12.195856, numObservations: 1
action 4, numVisits=24, meanQ=-23.652421, numObservations: 5
action 0, numVisits=6, meanQ=-90.204014, numObservations: 5
action 2, numVisits=1, meanQ=-539.656122, numObservations: 1
action 3, numVisits=1, meanQ=-539.661503, numObservations: 1
Sampled 15797 episodes
GETTING ACTION FROM:
action 1, numVisits=16121, meanQ=11.193396, numObservations: 9
action -1, numVisits=98, meanQ=-6.621740, numObservations: 37
action 5, numVisits=2, meanQ=-12.195856, numObservations: 1
action 4, numVisits=24, meanQ=-23.652421, numObservations: 5
action 0, numVisits=6, meanQ=-90.204014, numObservations: 5
action 2, numVisits=1, meanQ=-539.656122, numObservations: 1
action 3, numVisits=1, meanQ=-539.661503, numObservations: 1
action: 1
Next state: 0 0.290273 0.152583 0.211731 0.264243 0.44652 0.59126 0.218812 0.14737 0.407241 0.420688 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 3, numVisits=1, meanQ=24.000000, numObservations: 1
action 4, numVisits=432, meanQ=8.142194, numObservations: 9
action 1, numVisits=1, meanQ=-10.433544, numObservations: 1
action 5, numVisits=1, meanQ=-10.504549, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=8, meanQ=-68.356128, numObservations: 5
action 0, numVisits=2, meanQ=-268.408210, numObservations: 1
Sampled 17580 episodes
GETTING ACTION FROM:
action 3, numVisits=224, meanQ=22.606071, numObservations: 8
action 4, numVisits=17789, meanQ=8.898522, numObservations: 9
action 1, numVisits=1, meanQ=-10.433544, numObservations: 1
action 5, numVisits=1, meanQ=-10.504549, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=8, meanQ=-68.356128, numObservations: 5
action 0, numVisits=2, meanQ=-268.408210, numObservations: 1
action: 3
Next state: 1 0.290273 0.152583 0.211731 0.264243 0.44652 0.59126 0.218812 0.14737 0.407241 0.420688 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.29271
[32m ProblemEnvironment.hpp 351: Done.[39m
