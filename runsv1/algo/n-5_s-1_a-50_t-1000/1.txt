Run # 1
Initial state: 0 0.291785 0.0831552 0.0813944 0.554178 0.768867 0.554557 0.319673 0.291671 0.509184 0.339647 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27143 episodes
GETTING ACTION FROM:
action 3, numVisits=27134, meanQ=13.296998, numObservations: 9
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action 4, numVisits=3, meanQ=5.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.291785 0.0831552 0.0813944 0.554178 0.768867 0.554557 0.319673 0.291671 0.509184 0.339647 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 2
Initial state: 0 0.961971 0.643119 0.499895 0.489609 0.26313 0.341574 0.243437 0.222355 0.491158 0.313048 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30097 episodes
GETTING ACTION FROM:
action 2, numVisits=30091, meanQ=13.594569, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.961971 0.643119 0.499895 0.489609 0.26313 0.341574 0.243437 0.222355 0.491158 0.313048 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 3
Initial state: 0 0.465218 0.387896 0.754094 0.0861419 0.703 0.102114 0.782456 0.566507 0.728148 0.833712 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30177 episodes
GETTING ACTION FROM:
action 3, numVisits=30117, meanQ=13.563367, numObservations: 9
action 1, numVisits=23, meanQ=10.435230, numObservations: 8
action 5, numVisits=18, meanQ=9.721111, numObservations: 7
action 2, numVisits=15, meanQ=9.264667, numObservations: 7
action 4, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 2 0.465218 0.387896 0.754094 0.0861419 0.703 0.102114 0.782456 0.566507 0.728148 0.833712 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 4
Initial state: 0 0.633561 0.680373 0.539184 0.263966 0.700219 0.0836157 0.863509 0.83807 0.737499 0.187105 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29650 episodes
GETTING ACTION FROM:
action 4, numVisits=29644, meanQ=13.155729, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.633561 0.680373 0.539184 0.263966 0.700219 0.0836157 0.863509 0.83807 0.737499 0.187105 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 5
Initial state: 0 0.0703504 0.370262 0.380186 0.728098 0.46622 0.356009 0.584172 0.494525 0.858332 0.767485 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29985 episodes
GETTING ACTION FROM:
action 5, numVisits=29938, meanQ=13.429411, numObservations: 9
action 3, numVisits=17, meanQ=6.530594, numObservations: 7
action 1, numVisits=22, meanQ=6.489105, numObservations: 7
action 2, numVisits=3, meanQ=3.000000, numObservations: 2
action 4, numVisits=3, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 5
Next state: 1 0.0703504 0.370262 0.380186 0.728098 0.46622 0.356009 0.584172 0.494525 0.858332 0.767485 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 6
Initial state: 0 0.463325 0.387721 0.145374 0.800053 0.956912 0.842642 0.21979 0.640062 0.760558 0.773977 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29870 episodes
GETTING ACTION FROM:
action 3, numVisits=29818, meanQ=13.425410, numObservations: 9
action 5, numVisits=21, meanQ=7.463819, numObservations: 9
action 1, numVisits=16, meanQ=7.436875, numObservations: 6
action 4, numVisits=8, meanQ=7.357500, numObservations: 6
action 2, numVisits=5, meanQ=5.600020, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.463325 0.387721 0.145374 0.800053 0.956912 0.842642 0.21979 0.640062 0.760558 0.773977 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 7
Initial state: 0 0.580662 0.26605 0.865804 0.829639 0.298962 0.315203 0.625054 0.464753 0.102438 0.0317893 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28442 episodes
GETTING ACTION FROM:
action 1, numVisits=28433, meanQ=13.741042, numObservations: 9
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action 2, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.580662 0.26605 0.865804 0.829639 0.298962 0.315203 0.625054 0.464753 0.102438 0.0317893 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=439, meanQ=19.925285, numObservations: 9
action 3, numVisits=8, meanQ=4.635000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 28362 episodes
GETTING ACTION FROM:
action 1, numVisits=460, meanQ=19.985413, numObservations: 9
action 5, numVisits=28336, meanQ=15.697557, numObservations: 9
action 3, numVisits=8, meanQ=4.635000, numObservations: 5
action 0, numVisits=4, meanQ=-1.505000, numObservations: 4
action -1, numVisits=4, meanQ=-1.752500, numObservations: 4
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.580662 0.26605 0.865804 0.829639 0.298962 0.315203 0.625054 0.464753 0.102438 0.0317893 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 8
Initial state: 0 0.60136 0.131407 0.480392 0.981624 0.521653 0.350102 0.760162 0.456257 0.237717 0.0156034 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29432 episodes
GETTING ACTION FROM:
action 2, numVisits=29400, meanQ=13.533747, numObservations: 9
action 3, numVisits=15, meanQ=11.466000, numObservations: 6
action 1, numVisits=8, meanQ=9.372500, numObservations: 8
action 5, numVisits=6, meanQ=8.833333, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.60136 0.131407 0.480392 0.981624 0.521653 0.350102 0.760162 0.456257 0.237717 0.0156034 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 9
Initial state: 0 0.456171 0.450604 0.382645 0.894787 0.768613 0.849336 0.0340334 0.879756 0.448755 0.321804 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28293 episodes
GETTING ACTION FROM:
action 3, numVisits=28287, meanQ=13.383983, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.456171 0.450604 0.382645 0.894787 0.768613 0.849336 0.0340334 0.879756 0.448755 0.321804 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 10
Initial state: 0 0.754186 0.573474 0.714003 0.128541 0.0778218 0.848582 0.505297 0.335123 0.186938 0.492175 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29722 episodes
GETTING ACTION FROM:
action 5, numVisits=29709, meanQ=13.656008, numObservations: 9
action 1, numVisits=4, meanQ=10.000000, numObservations: 3
action 3, numVisits=3, meanQ=5.663333, numObservations: 3
action 4, numVisits=3, meanQ=4.340033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 0 0.754186 0.573474 0.714003 0.128541 0.0778218 0.848582 0.505297 0.335123 0.186938 0.492175 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=361, meanQ=14.649679, numObservations: 9
action 2, numVisits=13, meanQ=7.768477, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 17239 episodes
GETTING ACTION FROM:
action 1, numVisits=17594, meanQ=15.430646, numObservations: 9
action 2, numVisits=13, meanQ=7.768477, numObservations: 7
action 0, numVisits=4, meanQ=-1.505000, numObservations: 4
action -1, numVisits=4, meanQ=-1.752500, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.754186 0.573474 0.714003 0.128541 0.0778218 0.848582 0.505297 0.335123 0.186938 0.492175 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 11
Initial state: 0 0.197313 0.406119 0.348083 0.22223 0.277802 0.897497 0.248869 0.608985 0.602603 0.38897 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29775 episodes
GETTING ACTION FROM:
action 5, numVisits=29741, meanQ=13.543487, numObservations: 9
action -1, numVisits=15, meanQ=-1.275320, numObservations: 13
action 0, numVisits=13, meanQ=-1.315377, numObservations: 12
action 3, numVisits=2, meanQ=-3.505000, numObservations: 2
action 2, numVisits=2, meanQ=-7.500000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.197313 0.406119 0.348083 0.22223 0.277802 0.897497 0.248869 0.608985 0.602603 0.38897 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 12
Initial state: 0 0.500619 0.261825 0.21593 0.363388 0.6393 0.985341 0.202883 0.603857 0.146789 0.35728 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30018 episodes
GETTING ACTION FROM:
action 5, numVisits=29991, meanQ=13.572250, numObservations: 9
action 3, numVisits=18, meanQ=6.612239, numObservations: 7
action 2, numVisits=5, meanQ=5.998000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 2 0.500619 0.261825 0.21593 0.363388 0.6393 0.985341 0.202883 0.603857 0.146789 0.35728 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 13
Initial state: 0 0.856022 0.650924 0.469878 0.836378 0.46209 0.400213 0.835537 0.195696 0.638293 0.657609 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29940 episodes
GETTING ACTION FROM:
action 5, numVisits=29901, meanQ=13.658809, numObservations: 9
action 4, numVisits=22, meanQ=8.228191, numObservations: 7
action 2, numVisits=13, meanQ=7.545400, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 1 0.856022 0.650924 0.469878 0.836378 0.46209 0.400213 0.835537 0.195696 0.638293 0.657609 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 14
Initial state: 0 0.852587 0.629185 0.97081 0.965108 0.0409205 0.719859 0.463383 0.324209 0.920066 0.833247 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29930 episodes
GETTING ACTION FROM:
action 4, numVisits=29915, meanQ=13.682945, numObservations: 9
action 2, numVisits=4, meanQ=8.250000, numObservations: 3
action 3, numVisits=7, meanQ=7.857157, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.852587 0.629185 0.97081 0.965108 0.0409205 0.719859 0.463383 0.324209 0.920066 0.833247 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 15
Initial state: 0 0.172469 0.00372828 0.49831 0.271033 0.303998 0.784983 0.374053 0.97363 0.803611 0.227867 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29896 episodes
GETTING ACTION FROM:
action 2, numVisits=29888, meanQ=13.657417, numObservations: 9
action 5, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.172469 0.00372828 0.49831 0.271033 0.303998 0.784983 0.374053 0.97363 0.803611 0.227867 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 16
Initial state: 0 0.572251 0.412712 0.930045 0.133467 0.782776 0.51826 0.819819 0.0374328 0.283221 0.526171 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29876 episodes
GETTING ACTION FROM:
action 3, numVisits=29862, meanQ=13.460252, numObservations: 9
action 4, numVisits=7, meanQ=7.818571, numObservations: 5
action 1, numVisits=3, meanQ=4.340033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.572251 0.412712 0.930045 0.133467 0.782776 0.51826 0.819819 0.0374328 0.283221 0.526171 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 17
Initial state: 0 0.554596 0.37796 0.444583 0.513917 0.344666 0.0526226 0.905336 0.238825 0.119463 0.50981 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29485 episodes
GETTING ACTION FROM:
action 2, numVisits=29469, meanQ=13.250566, numObservations: 9
action 4, numVisits=10, meanQ=7.900000, numObservations: 6
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.554596 0.37796 0.444583 0.513917 0.344666 0.0526226 0.905336 0.238825 0.119463 0.50981 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 18
Initial state: 0 0.299747 0.0537222 0.636927 0.0129004 0.19821 0.803957 0.584918 0.263371 0.395173 0.850601 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29897 episodes
GETTING ACTION FROM:
action 4, numVisits=29891, meanQ=13.647954, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.299747 0.0537222 0.636927 0.0129004 0.19821 0.803957 0.584918 0.263371 0.395173 0.850601 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 19
Initial state: 0 0.258123 0.716573 0.866335 0.613038 0.592896 0.378978 0.459315 0.174959 0.267542 0.589397 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29961 episodes
GETTING ACTION FROM:
action 1, numVisits=29944, meanQ=13.350967, numObservations: 9
action 5, numVisits=7, meanQ=10.574300, numObservations: 5
action 4, numVisits=6, meanQ=9.006700, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.258123 0.716573 0.866335 0.613038 0.592896 0.378978 0.459315 0.174959 0.267542 0.589397 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=4328, meanQ=13.969946, numObservations: 9
action 3, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 10371 episodes
GETTING ACTION FROM:
action 3, numVisits=10279, meanQ=16.674564, numObservations: 9
action 2, numVisits=4421, meanQ=14.051066, numObservations: 9
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.258123 0.716573 0.866335 0.613038 0.592896 0.378978 0.459315 0.174959 0.267542 0.589397 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 20
Initial state: 0 0.941281 0.605599 0.325988 0.0829711 0.571037 0.30388 0.896755 0.744105 0.313371 0.992321 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27932 episodes
GETTING ACTION FROM:
action 2, numVisits=27909, meanQ=13.338292, numObservations: 9
action 5, numVisits=11, meanQ=8.727273, numObservations: 8
action 4, numVisits=6, meanQ=8.350000, numObservations: 5
action 3, numVisits=3, meanQ=1.703333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.941281 0.605599 0.325988 0.0829711 0.571037 0.30388 0.896755 0.744105 0.313371 0.992321 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=2369, meanQ=13.887645, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 7607 episodes
GETTING ACTION FROM:
action 5, numVisits=9974, meanQ=13.494896, numObservations: 9
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.941281 0.605599 0.325988 0.0829711 0.571037 0.30388 0.896755 0.744105 0.313371 0.992321 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 21
Initial state: 0 0.460051 0.298978 0.244939 0.651753 0.191871 0.915451 0.51381 0.609576 0.335207 0.615047 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29629 episodes
GETTING ACTION FROM:
action 5, numVisits=29609, meanQ=13.478496, numObservations: 9
action 2, numVisits=11, meanQ=6.727282, numObservations: 6
action 3, numVisits=5, meanQ=5.998000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 0 0.460051 0.298978 0.244939 0.651753 0.191871 0.915451 0.51381 0.609576 0.335207 0.615047 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=4448, meanQ=14.444862, numObservations: 9
action 4, numVisits=4, meanQ=8.497500, numObservations: 2
action 2, numVisits=8, meanQ=8.497500, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 10216 episodes
GETTING ACTION FROM:
action 1, numVisits=14661, meanQ=15.862869, numObservations: 9
action 2, numVisits=8, meanQ=8.497500, numObservations: 6
action 4, numVisits=5, meanQ=4.598000, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.460051 0.298978 0.244939 0.651753 0.191871 0.915451 0.51381 0.609576 0.335207 0.615047 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 22
Initial state: 0 0.991382 0.585357 0.275522 0.0759161 0.610902 0.645651 0.134596 0.576642 0.539899 0.388898 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29736 episodes
GETTING ACTION FROM:
action 2, numVisits=29712, meanQ=13.492876, numObservations: 9
action 4, numVisits=12, meanQ=10.500008, numObservations: 7
action 3, numVisits=6, meanQ=7.831667, numObservations: 5
action 5, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.991382 0.585357 0.275522 0.0759161 0.610902 0.645651 0.134596 0.576642 0.539899 0.388898 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=2445, meanQ=14.028575, numObservations: 9
action 3, numVisits=29, meanQ=6.553121, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 8745 episodes
GETTING ACTION FROM:
action 5, numVisits=11188, meanQ=13.362029, numObservations: 9
action 3, numVisits=29, meanQ=6.553121, numObservations: 9
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.991382 0.585357 0.275522 0.0759161 0.610902 0.645651 0.134596 0.576642 0.539899 0.388898 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 23
Initial state: 0 0.443089 0.747289 0.572142 0.412443 0.838226 0.993706 0.88238 0.104095 0.0395239 0.116239 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29708 episodes
GETTING ACTION FROM:
action 5, numVisits=29693, meanQ=13.320314, numObservations: 9
action 1, numVisits=4, meanQ=8.250000, numObservations: 2
action 4, numVisits=5, meanQ=7.398000, numObservations: 5
action 3, numVisits=3, meanQ=5.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 0 0.443089 0.747289 0.572142 0.412443 0.838226 0.993706 0.88238 0.104095 0.0395239 0.116239 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=2460, meanQ=13.903999, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 8008 episodes
GETTING ACTION FROM:
action 2, numVisits=10466, meanQ=13.605975, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.443089 0.747289 0.572142 0.412443 0.838226 0.993706 0.88238 0.104095 0.0395239 0.116239 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 24
Initial state: 0 0.636494 0.230753 0.299857 0.440824 0.450272 0.6656 0.464163 0.399981 0.158742 0.89635 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29823 episodes
GETTING ACTION FROM:
action 4, numVisits=29812, meanQ=13.555942, numObservations: 9
action 3, numVisits=6, meanQ=8.833333, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.636494 0.230753 0.299857 0.440824 0.450272 0.6656 0.464163 0.399981 0.158742 0.89635 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 25
Initial state: 0 0.957736 0.400315 0.228992 0.720385 0.83368 0.0798021 0.544952 0.330469 0.932092 0.62377 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29840 episodes
GETTING ACTION FROM:
action 3, numVisits=29831, meanQ=13.528527, numObservations: 9
action 2, numVisits=4, meanQ=8.250000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 2 0.957736 0.400315 0.228992 0.720385 0.83368 0.0798021 0.544952 0.330469 0.932092 0.62377 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 26
Initial state: 0 0.359924 0.478714 0.987891 0.498177 0.590494 0.370738 0.175675 0.117314 0.56439 0.185259 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29959 episodes
GETTING ACTION FROM:
action 4, numVisits=29947, meanQ=13.472716, numObservations: 9
action 5, numVisits=4, meanQ=10.000000, numObservations: 4
action 2, numVisits=4, meanQ=8.250000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.359924 0.478714 0.987891 0.498177 0.590494 0.370738 0.175675 0.117314 0.56439 0.185259 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=2534, meanQ=14.076976, numObservations: 9
action 1, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 7402 episodes
GETTING ACTION FROM:
action 3, numVisits=9934, meanQ=13.472823, numObservations: 9
action 1, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.359924 0.478714 0.987891 0.498177 0.590494 0.370738 0.175675 0.117314 0.56439 0.185259 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 27
Initial state: 0 0.787342 0.957497 0.561736 0.420337 0.217277 0.491152 0.336193 0.291457 0.746681 0.830505 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29857 episodes
GETTING ACTION FROM:
action 2, numVisits=29841, meanQ=13.538937, numObservations: 9
action 4, numVisits=8, meanQ=9.248750, numObservations: 7
action 3, numVisits=4, meanQ=8.250000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.787342 0.957497 0.561736 0.420337 0.217277 0.491152 0.336193 0.291457 0.746681 0.830505 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 28
Initial state: 0 0.365156 0.374886 0.982561 0.862345 0.680176 0.858094 0.594586 0.35135 0.386755 0.849873 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29894 episodes
GETTING ACTION FROM:
action 4, numVisits=29888, meanQ=13.494142, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.365156 0.374886 0.982561 0.862345 0.680176 0.858094 0.594586 0.35135 0.386755 0.849873 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 29
Initial state: 0 0.535267 0.241733 0.190356 0.282323 0.754601 0.513762 0.599883 0.323412 0.971763 0.0486408 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28720 episodes
GETTING ACTION FROM:
action 3, numVisits=28701, meanQ=13.437580, numObservations: 9
action 5, numVisits=4, meanQ=10.247500, numObservations: 4
action 4, numVisits=9, meanQ=10.110000, numObservations: 4
action 2, numVisits=3, meanQ=5.663333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.535267 0.241733 0.190356 0.282323 0.754601 0.513762 0.599883 0.323412 0.971763 0.0486408 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 30
Initial state: 0 0.152346 0.523151 0.0176586 0.134142 0.502794 0.750448 0.560909 0.280281 0.0608121 0.864819 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30112 episodes
GETTING ACTION FROM:
action 4, numVisits=30083, meanQ=13.632952, numObservations: 9
action 5, numVisits=22, meanQ=8.626377, numObservations: 7
action 2, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.152346 0.523151 0.0176586 0.134142 0.502794 0.750448 0.560909 0.280281 0.0608121 0.864819 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 31
Initial state: 0 0.445337 0.334499 0.91902 0.524584 0.213493 0.00768756 0.0347277 0.59556 0.736078 0.642399 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29888 episodes
GETTING ACTION FROM:
action 5, numVisits=29876, meanQ=13.680420, numObservations: 9
action 2, numVisits=4, meanQ=8.250000, numObservations: 3
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action 1, numVisits=3, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 1 0.445337 0.334499 0.91902 0.524584 0.213493 0.00768756 0.0347277 0.59556 0.736078 0.642399 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 32
Initial state: 0 0.842557 0.181687 0.137752 0.574661 0.560471 0.505688 0.632742 0.596345 0.490589 0.411896 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29686 episodes
GETTING ACTION FROM:
action 4, numVisits=29678, meanQ=13.541501, numObservations: 9
action 5, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.842557 0.181687 0.137752 0.574661 0.560471 0.505688 0.632742 0.596345 0.490589 0.411896 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 33
Initial state: 0 0.582316 0.364275 0.806275 0.882718 0.223873 0.514065 0.65861 0.54692 0.113448 0.463079 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29967 episodes
GETTING ACTION FROM:
action 1, numVisits=29934, meanQ=13.594075, numObservations: 9
action 4, numVisits=26, meanQ=8.059631, numObservations: 8
action 2, numVisits=3, meanQ=5.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.582316 0.364275 0.806275 0.882718 0.223873 0.514065 0.65861 0.54692 0.113448 0.463079 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 34
Initial state: 0 0.20759 0.603223 0.600654 0.361408 0.656779 0.427399 0.861618 0.42664 0.0985646 0.702998 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30053 episodes
GETTING ACTION FROM:
action 3, numVisits=30025, meanQ=13.498834, numObservations: 9
action 5, numVisits=23, meanQ=10.765652, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.20759 0.603223 0.600654 0.361408 0.656779 0.427399 0.861618 0.42664 0.0985646 0.702998 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 35
Initial state: 0 0.919448 0.605157 0.467752 0.294617 0.876449 0.649086 0.330605 0.22241 0.160413 0.71303 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29914 episodes
GETTING ACTION FROM:
action 2, numVisits=29873, meanQ=13.668217, numObservations: 9
action 0, numVisits=27, meanQ=-0.534800, numObservations: 22
action -1, numVisits=10, meanQ=-1.010000, numObservations: 10
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.919448 0.605157 0.467752 0.294617 0.876449 0.649086 0.330605 0.22241 0.160413 0.71303 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 36
Initial state: 0 0.545972 0.294059 0.96436 0.60266 0.404482 0.824888 0.328547 0.0217225 0.506963 0.700873 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29782 episodes
GETTING ACTION FROM:
action 4, numVisits=29767, meanQ=13.378126, numObservations: 9
action 3, numVisits=8, meanQ=8.876262, numObservations: 6
action 2, numVisits=3, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.545972 0.294059 0.96436 0.60266 0.404482 0.824888 0.328547 0.0217225 0.506963 0.700873 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=2439, meanQ=13.895835, numObservations: 9
action 3, numVisits=16, meanQ=6.922519, numObservations: 6
action 1, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 8704 episodes
GETTING ACTION FROM:
action 2, numVisits=11124, meanQ=13.193958, numObservations: 9
action 3, numVisits=32, meanQ=9.450694, numObservations: 8
action 1, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.545972 0.294059 0.96436 0.60266 0.404482 0.824888 0.328547 0.0217225 0.506963 0.700873 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 37
Initial state: 0 0.0674997 0.0239001 0.00210541 0.0430137 0.737921 0.668007 0.590359 0.267353 0.040262 0.48011 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29944 episodes
GETTING ACTION FROM:
action 5, numVisits=29938, meanQ=13.379715, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.0674997 0.0239001 0.00210541 0.0430137 0.737921 0.668007 0.590359 0.267353 0.040262 0.48011 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=4373, meanQ=13.804479, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 11078 episodes
GETTING ACTION FROM:
action 1, numVisits=15451, meanQ=14.712444, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.0674997 0.0239001 0.00210541 0.0430137 0.737921 0.668007 0.590359 0.267353 0.040262 0.48011 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=899, meanQ=16.231156, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 8631 episodes
GETTING ACTION FROM:
action 2, numVisits=9530, meanQ=16.726433, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.0674997 0.0239001 0.00210541 0.0430137 0.737921 0.668007 0.590359 0.267353 0.040262 0.48011 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 4, numVisits=280, meanQ=15.072313, numObservations: 9
action 5, numVisits=51, meanQ=11.232808, numObservations: 6
action 0, numVisits=11, meanQ=-2.172767, numObservations: 9
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=16, meanQ=-29.723113, numObservations: 5
action -1, numVisits=4, meanQ=-265.454421, numObservations: 3
Sampled 13108 episodes
GETTING ACTION FROM:
action 4, numVisits=13388, meanQ=18.627614, numObservations: 9
action 5, numVisits=51, meanQ=11.232808, numObservations: 6
action 0, numVisits=11, meanQ=-2.172767, numObservations: 9
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=16, meanQ=-29.723113, numObservations: 5
action -1, numVisits=4, meanQ=-265.454421, numObservations: 3
action: 4
Next state: 1 0.0674997 0.0239001 0.00210541 0.0430137 0.737921 0.668007 0.590359 0.267353 0.040262 0.48011 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 11.4068
Run # 38
Initial state: 0 0.652688 0.808041 0.508116 0.573528 0.364193 0.111806 0.631952 0.9819 0.490384 0.310454 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29868 episodes
GETTING ACTION FROM:
action 1, numVisits=29858, meanQ=13.443694, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.652688 0.808041 0.508116 0.573528 0.364193 0.111806 0.631952 0.9819 0.490384 0.310454 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 39
Initial state: 0 0.14613 0.243611 0.386114 0.891564 0.597139 0.374157 0.932921 0.222552 0.966489 0.703026 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29902 episodes
GETTING ACTION FROM:
action 5, numVisits=29890, meanQ=13.471749, numObservations: 9
action 3, numVisits=7, meanQ=6.998586, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.14613 0.243611 0.386114 0.891564 0.597139 0.374157 0.932921 0.222552 0.966489 0.703026 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 40
Initial state: 0 0.352403 0.231642 0.338152 0.792574 0.590784 0.326746 0.405231 0.152248 0.0797762 0.868885 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30057 episodes
GETTING ACTION FROM:
action 4, numVisits=30043, meanQ=13.704908, numObservations: 9
action 3, numVisits=9, meanQ=8.751111, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.352403 0.231642 0.338152 0.792574 0.590784 0.326746 0.405231 0.152248 0.0797762 0.868885 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 41
Initial state: 0 0.177778 0.463411 0.161561 0.21369 0.301331 0.697523 0.516824 0.325317 0.271376 0.249574 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30050 episodes
GETTING ACTION FROM:
action 1, numVisits=30044, meanQ=13.377069, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.177778 0.463411 0.161561 0.21369 0.301331 0.697523 0.516824 0.325317 0.271376 0.249574 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 42
Initial state: 0 0.457289 0.273148 0.378355 0.539521 0.15742 0.232519 0.784308 0.510245 0.394656 0.91121 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29944 episodes
GETTING ACTION FROM:
action 4, numVisits=29931, meanQ=13.455600, numObservations: 9
action 3, numVisits=8, meanQ=8.373750, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.457289 0.273148 0.378355 0.539521 0.15742 0.232519 0.784308 0.510245 0.394656 0.91121 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 43
Initial state: 0 0.310818 0.975593 0.892964 0.513673 0.0105437 0.259385 0.498422 0.301806 0.141646 0.166084 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30067 episodes
GETTING ACTION FROM:
action 5, numVisits=30045, meanQ=13.435500, numObservations: 9
action 4, numVisits=8, meanQ=10.875000, numObservations: 5
action 3, numVisits=9, meanQ=9.222222, numObservations: 4
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.310818 0.975593 0.892964 0.513673 0.0105437 0.259385 0.498422 0.301806 0.141646 0.166084 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=2496, meanQ=13.326812, numObservations: 9
action 3, numVisits=16, meanQ=10.171881, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 7507 episodes
GETTING ACTION FROM:
action 4, numVisits=9926, meanQ=13.529046, numObservations: 9
action 3, numVisits=90, meanQ=11.010061, numObservations: 9
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.310818 0.975593 0.892964 0.513673 0.0105437 0.259385 0.498422 0.301806 0.141646 0.166084 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 44
Initial state: 0 0.382612 0.0465279 0.557448 0.268063 0.178269 0.584968 0.868817 0.906707 0.316994 0.243617 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29861 episodes
GETTING ACTION FROM:
action 3, numVisits=29838, meanQ=13.507740, numObservations: 9
action 1, numVisits=14, meanQ=6.427164, numObservations: 7
action 4, numVisits=5, meanQ=5.220000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.382612 0.0465279 0.557448 0.268063 0.178269 0.584968 0.868817 0.906707 0.316994 0.243617 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=4371, meanQ=14.471116, numObservations: 9
action 4, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 11152 episodes
GETTING ACTION FROM:
action 2, numVisits=15521, meanQ=15.555719, numObservations: 9
action 4, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.382612 0.0465279 0.557448 0.268063 0.178269 0.584968 0.868817 0.906707 0.316994 0.243617 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 45
Initial state: 0 0.0434835 0.0871007 0.611042 0.26556 0.407288 0.333243 0.127934 0.821616 0.0953407 0.442555 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30006 episodes
GETTING ACTION FROM:
action 4, numVisits=29996, meanQ=13.463973, numObservations: 9
action 3, numVisits=3, meanQ=5.333333, numObservations: 3
action 2, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 0 0.0434835 0.0871007 0.611042 0.26556 0.407288 0.333243 0.127934 0.821616 0.0953407 0.442555 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=2491, meanQ=14.768378, numObservations: 9
action 5, numVisits=5, meanQ=6.196000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 7262 episodes
GETTING ACTION FROM:
action 3, numVisits=9751, meanQ=13.244523, numObservations: 9
action 5, numVisits=5, meanQ=6.196000, numObservations: 3
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.0434835 0.0871007 0.611042 0.26556 0.407288 0.333243 0.127934 0.821616 0.0953407 0.442555 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=282, meanQ=14.029891, numObservations: 9
action 3, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=8, meanQ=-121.847669, numObservations: 5
Sampled 5724 episodes
GETTING ACTION FROM:
action 2, numVisits=6004, meanQ=15.019663, numObservations: 9
action 3, numVisits=3, meanQ=3.330000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=8, meanQ=-121.847669, numObservations: 5
action: 2
Next state: 0 0.0434835 0.0871007 0.611042 0.26556 0.407288 0.333243 0.127934 0.821616 0.0953407 0.442555 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=65, meanQ=18.790491, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.569878, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-536.801899, numObservations: 1
action 4, numVisits=1, meanQ=-1068.226491, numObservations: 1
Sampled 16860 episodes
GETTING ACTION FROM:
action 2, numVisits=152, meanQ=20.890671, numObservations: 9
action -1, numVisits=15863, meanQ=-1.699511, numObservations: 211
action 0, numVisits=912, meanQ=-2.935758, numObservations: 127
action 5, numVisits=1, meanQ=-10.569878, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-536.801899, numObservations: 1
action 4, numVisits=1, meanQ=-1068.226491, numObservations: 1
action: 2
Next state: 1 0.0434835 0.0871007 0.611042 0.26556 0.407288 0.333243 0.127934 0.821616 0.0953407 0.442555 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 11.4068
Run # 46
Initial state: 0 0.865492 0.658397 0.0855626 0.648225 0.978606 0.368393 0.50913 0.343425 0.778731 0.3014 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27969 episodes
GETTING ACTION FROM:
action 1, numVisits=27928, meanQ=13.110180, numObservations: 9
action 4, numVisits=23, meanQ=6.260017, numObservations: 7
action 5, numVisits=14, meanQ=6.070007, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.865492 0.658397 0.0855626 0.648225 0.978606 0.368393 0.50913 0.343425 0.778731 0.3014 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 47
Initial state: 0 0.956924 0.835624 0.45821 0.341286 0.32916 0.172344 0.189103 0.846103 0.902328 0.0629876 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27680 episodes
GETTING ACTION FROM:
action 2, numVisits=27662, meanQ=13.575206, numObservations: 9
action 1, numVisits=11, meanQ=9.736364, numObservations: 7
action 4, numVisits=3, meanQ=5.663333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.956924 0.835624 0.45821 0.341286 0.32916 0.172344 0.189103 0.846103 0.902328 0.0629876 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 48
Initial state: 0 0.885266 0.24817 0.0933611 0.55309 0.517782 0.277497 0.736245 0.599305 0.340549 0.611357 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30015 episodes
GETTING ACTION FROM:
action 5, numVisits=29996, meanQ=13.574145, numObservations: 9
action 4, numVisits=11, meanQ=1.364573, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=4, meanQ=-2.250000, numObservations: 2
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.885266 0.24817 0.0933611 0.55309 0.517782 0.277497 0.736245 0.599305 0.340549 0.611357 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=4378, meanQ=14.454594, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 10692 episodes
GETTING ACTION FROM:
action 1, numVisits=15068, meanQ=15.465973, numObservations: 9
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.885266 0.24817 0.0933611 0.55309 0.517782 0.277497 0.736245 0.599305 0.340549 0.611357 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 49
Initial state: 0 0.0697103 0.00977038 0.185433 0.674216 0.820617 0.634558 0.287667 0.0221368 0.610367 0.267859 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30115 episodes
GETTING ACTION FROM:
action 2, numVisits=30092, meanQ=13.520462, numObservations: 9
action 5, numVisits=17, meanQ=9.654124, numObservations: 7
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.0697103 0.00977038 0.185433 0.674216 0.820617 0.634558 0.287667 0.0221368 0.610367 0.267859 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=4452, meanQ=14.578956, numObservations: 9
action 5, numVisits=4, meanQ=9.997525, numObservations: 3
action 3, numVisits=4, meanQ=8.497500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 11044 episodes
GETTING ACTION FROM:
action 4, numVisits=15427, meanQ=14.643619, numObservations: 9
action 5, numVisits=71, meanQ=13.111500, numObservations: 9
action 3, numVisits=4, meanQ=8.497500, numObservations: 4
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 0 0.0697103 0.00977038 0.185433 0.674216 0.820617 0.634558 0.287667 0.0221368 0.610367 0.267859 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=144, meanQ=16.399960, numObservations: 9
action 3, numVisits=5, meanQ=7.000020, numObservations: 3
action 5, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 14781 episodes
GETTING ACTION FROM:
action 1, numVisits=14906, meanQ=15.745972, numObservations: 9
action 3, numVisits=12, meanQ=10.730008, numObservations: 5
action 5, numVisits=13, meanQ=6.579024, numObservations: 7
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.0697103 0.00977038 0.185433 0.674216 0.820617 0.634558 0.287667 0.0221368 0.610367 0.267859 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=26, meanQ=10.683480, numObservations: 5
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=44, meanQ=-7.735404, numObservations: 8
action -1, numVisits=35, meanQ=-15.991456, numObservations: 21
action 0, numVisits=28, meanQ=-19.327152, numObservations: 15
action 5, numVisits=16, meanQ=-23.972783, numObservations: 5
Sampled 21989 episodes
GETTING ACTION FROM:
action 3, numVisits=22024, meanQ=11.523350, numObservations: 9
action 1, numVisits=35, meanQ=8.986585, numObservations: 5
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=35, meanQ=-15.991456, numObservations: 21
action 0, numVisits=28, meanQ=-19.327152, numObservations: 15
action 5, numVisits=16, meanQ=-23.972783, numObservations: 5
action: 3
Next state: 1 0.0697103 0.00977038 0.185433 0.674216 0.820617 0.634558 0.287667 0.0221368 0.610367 0.267859 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 11.4068
Run # 50
Initial state: 0 0.190027 0.947555 0.427113 0.481085 0.879142 0.168345 0.987349 0.791653 0.560443 0.3477 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29656 episodes
GETTING ACTION FROM:
action 5, numVisits=29649, meanQ=13.265646, numObservations: 9
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.190027 0.947555 0.427113 0.481085 0.879142 0.168345 0.987349 0.791653 0.560443 0.3477 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
[32m ProblemEnvironment.hpp 351: Done.[39m
