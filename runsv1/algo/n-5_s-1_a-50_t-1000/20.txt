Run # 1
Initial state: 0 0.0421056 0.252357 0.301971 0.0136794 0.990976 0.764812 0.328226 0.80466 0.492276 0.319778 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27695 episodes
GETTING ACTION FROM:
action 4, numVisits=27672, meanQ=12.874441, numObservations: 9
action 1, numVisits=13, meanQ=5.771562, numObservations: 8
action 2, numVisits=6, meanQ=4.331667, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 0 0.0421056 0.252357 0.301971 0.0136794 0.990976 0.764812 0.328226 0.80466 0.492276 0.319778 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=285, meanQ=15.166531, numObservations: 9
action 2, numVisits=33, meanQ=10.470315, numObservations: 9
action 3, numVisits=29, meanQ=10.371055, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 31746 episodes
GETTING ACTION FROM:
action 5, numVisits=32031, meanQ=16.729345, numObservations: 9
action 2, numVisits=33, meanQ=10.470315, numObservations: 9
action 3, numVisits=29, meanQ=10.371055, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.0421056 0.252357 0.301971 0.0136794 0.990976 0.764812 0.328226 0.80466 0.492276 0.319778 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 2
Initial state: 0 0.0618658 0.454874 0.766676 0.605779 0.305494 0.537399 0.582817 0.392529 0.317542 0.631423 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26650 episodes
GETTING ACTION FROM:
action 4, numVisits=26644, meanQ=12.501307, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 1 0.0618658 0.454874 0.766676 0.605779 0.305494 0.537399 0.582817 0.392529 0.317542 0.631423 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 3
Initial state: 0 0.784145 0.949925 0.962126 0.118072 0.412321 0.760092 0.493149 0.359614 0.868203 0.851987 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28059 episodes
GETTING ACTION FROM:
action 5, numVisits=28053, meanQ=13.023276, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.784145 0.949925 0.962126 0.118072 0.412321 0.760092 0.493149 0.359614 0.868203 0.851987 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 4
Initial state: 0 0.251444 0.103089 0.141562 0.626718 0.679581 0.908805 0.084036 0.242413 0.574535 0.350225 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28379 episodes
GETTING ACTION FROM:
action 2, numVisits=28357, meanQ=13.213188, numObservations: 9
action 4, numVisits=11, meanQ=10.160009, numObservations: 8
action 1, numVisits=6, meanQ=9.998350, numObservations: 3
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.251444 0.103089 0.141562 0.626718 0.679581 0.908805 0.084036 0.242413 0.574535 0.350225 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 5
Initial state: 0 0.149483 0.00290304 0.491768 0.337301 0.012739 0.90102 0.720663 0.217234 0.939495 0.525908 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27869 episodes
GETTING ACTION FROM:
action 5, numVisits=27822, meanQ=12.943501, numObservations: 9
action 1, numVisits=42, meanQ=10.819768, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.149483 0.00290304 0.491768 0.337301 0.012739 0.90102 0.720663 0.217234 0.939495 0.525908 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 6
Initial state: 0 0.977378 0.512112 0.845737 0.00220327 0.28374 0.0763562 0.860282 0.447941 0.604175 0.434409 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28135 episodes
GETTING ACTION FROM:
action 1, numVisits=28110, meanQ=12.638314, numObservations: 9
action 3, numVisits=16, meanQ=6.750638, numObservations: 7
action 4, numVisits=5, meanQ=5.022000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.977378 0.512112 0.845737 0.00220327 0.28374 0.0763562 0.860282 0.447941 0.604175 0.434409 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 7
Initial state: 0 0.25387 0.147911 0.272114 0.0950256 0.742783 0.970003 0.159301 0.294842 0.659054 0.341229 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27920 episodes
GETTING ACTION FROM:
action 2, numVisits=27903, meanQ=13.012785, numObservations: 9
action 3, numVisits=10, meanQ=5.402020, numObservations: 5
action 5, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.25387 0.147911 0.272114 0.0950256 0.742783 0.970003 0.159301 0.294842 0.659054 0.341229 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 8
Initial state: 0 0.144968 0.149899 0.245038 0.903661 0.578528 0.316727 0.303012 0.739254 0.541733 0.506817 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26762 episodes
GETTING ACTION FROM:
action 4, numVisits=26733, meanQ=12.931682, numObservations: 9
action 2, numVisits=12, meanQ=9.580842, numObservations: 6
action 5, numVisits=4, meanQ=8.250000, numObservations: 4
action 3, numVisits=10, meanQ=7.610000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.144968 0.149899 0.245038 0.903661 0.578528 0.316727 0.303012 0.739254 0.541733 0.506817 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=4246, meanQ=13.011028, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 10972 episodes
GETTING ACTION FROM:
action 5, numVisits=10793, meanQ=15.389194, numObservations: 9
action 4, numVisits=4248, meanQ=13.012633, numObservations: 9
action 3, numVisits=7, meanQ=0.001117, numObservations: 4
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action -1, numVisits=90, meanQ=-12.057609, numObservations: 55
action 0, numVisits=71, meanQ=-13.562698, numObservations: 43
action 2, numVisits=13, meanQ=-66.758281, numObservations: 4
action: 5
Next state: 1 0.144968 0.149899 0.245038 0.903661 0.578528 0.316727 0.303012 0.739254 0.541733 0.506817 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 9
Initial state: 0 0.593252 0.319455 0.960943 0.412403 0.621132 0.18155 0.207013 0.809146 0.60264 0.0154628 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26070 episodes
GETTING ACTION FROM:
action 4, numVisits=26051, meanQ=13.024981, numObservations: 9
action 5, numVisits=12, meanQ=6.673367, numObservations: 4
action 2, numVisits=3, meanQ=5.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.593252 0.319455 0.960943 0.412403 0.621132 0.18155 0.207013 0.809146 0.60264 0.0154628 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=4147, meanQ=13.381629, numObservations: 9
action 2, numVisits=24, meanQ=8.594175, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 8763 episodes
GETTING ACTION FROM:
action 5, numVisits=8660, meanQ=15.426855, numObservations: 9
action 4, numVisits=4150, meanQ=13.385779, numObservations: 9
action 2, numVisits=103, meanQ=3.722584, numObservations: 9
action -1, numVisits=5, meanQ=-1.208000, numObservations: 5
action 0, numVisits=5, meanQ=-1.208000, numObservations: 5
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=15, meanQ=-57.036332, numObservations: 8
action: 5
Next state: 0 0.593252 0.319455 0.960943 0.412403 0.621132 0.18155 0.207013 0.809146 0.60264 0.0154628 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=1, meanQ=24.000000, numObservations: 1
action -1, numVisits=41, meanQ=1.623219, numObservations: 30
action 3, numVisits=1, meanQ=-9.348605, numObservations: 1
action 2, numVisits=1, meanQ=-9.693203, numObservations: 1
action 5, numVisits=1, meanQ=-10.500725, numObservations: 1
action 0, numVisits=14, meanQ=-76.639169, numObservations: 13
action 1, numVisits=3, meanQ=-349.505493, numObservations: 2
Sampled 13787 episodes
GETTING ACTION FROM:
action 3, numVisits=13748, meanQ=14.636747, numObservations: 9
action -1, numVisits=66, meanQ=-7.397266, numObservations: 47
action 2, numVisits=1, meanQ=-9.693203, numObservations: 1
action 5, numVisits=1, meanQ=-10.500725, numObservations: 1
action 4, numVisits=16, meanQ=-23.362349, numObservations: 5
action 0, numVisits=14, meanQ=-76.639169, numObservations: 13
action 1, numVisits=3, meanQ=-349.505493, numObservations: 2
action: 3
Next state: 2 0.593252 0.319455 0.960943 0.412403 0.621132 0.18155 0.207013 0.809146 0.60264 0.0154628 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -18.7411
Run # 10
Initial state: 0 0.619895 0.416667 0.468962 0.870495 0.747949 0.774674 0.962726 0.516139 0.289332 0.704547 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26639 episodes
GETTING ACTION FROM:
action 4, numVisits=26620, meanQ=12.807348, numObservations: 9
action 1, numVisits=12, meanQ=6.081667, numObservations: 6
action 5, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.619895 0.416667 0.468962 0.870495 0.747949 0.774674 0.962726 0.516139 0.289332 0.704547 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 11
Initial state: 0 0.125274 0.130208 0.777582 0.623111 0.58612 0.326676 0.00974996 0.756592 0.799832 0.416562 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28106 episodes
GETTING ACTION FROM:
action 3, numVisits=28075, meanQ=12.926959, numObservations: 9
action 4, numVisits=15, meanQ=9.500007, numObservations: 5
action 1, numVisits=10, meanQ=8.798000, numObservations: 6
action 5, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.125274 0.130208 0.777582 0.623111 0.58612 0.326676 0.00974996 0.756592 0.799832 0.416562 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 12
Initial state: 0 0.104145 0.70683 0.545275 0.359656 0.353976 0.840663 0.965149 0.769596 0.851935 0.883963 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28026 episodes
GETTING ACTION FROM:
action 2, numVisits=28009, meanQ=12.898623, numObservations: 9
action 1, numVisits=9, meanQ=10.000000, numObservations: 6
action 4, numVisits=4, meanQ=9.187500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.104145 0.70683 0.545275 0.359656 0.353976 0.840663 0.965149 0.769596 0.851935 0.883963 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 13
Initial state: 0 0.179789 0.748179 0.0933684 0.707024 0.822614 0.338243 0.725281 0.237523 0.613133 0.35243 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28291 episodes
GETTING ACTION FROM:
action 4, numVisits=28281, meanQ=13.009640, numObservations: 9
action 5, numVisits=3, meanQ=3.000000, numObservations: 3
action 2, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.179789 0.748179 0.0933684 0.707024 0.822614 0.338243 0.725281 0.237523 0.613133 0.35243 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 14
Initial state: 0 0.971598 0.375778 0.698055 0.030681 0.561427 0.348658 0.860761 0.495952 0.362639 0.821267 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28199 episodes
GETTING ACTION FROM:
action 1, numVisits=28175, meanQ=12.932782, numObservations: 9
action 4, numVisits=13, meanQ=6.692315, numObservations: 6
action 3, numVisits=7, meanQ=5.585714, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.971598 0.375778 0.698055 0.030681 0.561427 0.348658 0.860761 0.495952 0.362639 0.821267 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 15
Initial state: 0 0.0135135 0.227025 0.727459 0.914831 0.629739 0.316147 0.976684 0.0316022 0.0618193 0.296328 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28365 episodes
GETTING ACTION FROM:
action 4, numVisits=28359, meanQ=13.076280, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.0135135 0.227025 0.727459 0.914831 0.629739 0.316147 0.976684 0.0316022 0.0618193 0.296328 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 16
Initial state: 0 0.376511 0.105175 0.832048 0.0513179 0.707763 0.54518 0.591462 0.311177 0.974471 0.163997 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28202 episodes
GETTING ACTION FROM:
action 5, numVisits=28192, meanQ=12.931024, numObservations: 9
action 3, numVisits=3, meanQ=5.663333, numObservations: 2
action 1, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.376511 0.105175 0.832048 0.0513179 0.707763 0.54518 0.591462 0.311177 0.974471 0.163997 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 17
Initial state: 0 0.826173 0.932137 0.775666 0.835095 0.30668 0.662109 0.634197 0.367371 0.078328 0.37719 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28223 episodes
GETTING ACTION FROM:
action 1, numVisits=28198, meanQ=12.959000, numObservations: 9
action 5, numVisits=20, meanQ=8.638505, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.826173 0.932137 0.775666 0.835095 0.30668 0.662109 0.634197 0.367371 0.078328 0.37719 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 18
Initial state: 0 0.490065 0.916376 0.585862 0.659752 0.661732 0.406314 0.43902 0.175265 0.394834 0.210286 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27849 episodes
GETTING ACTION FROM:
action 3, numVisits=27843, meanQ=12.901303, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.490065 0.916376 0.585862 0.659752 0.661732 0.406314 0.43902 0.175265 0.394834 0.210286 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=130, meanQ=13.058526, numObservations: 9
action 2, numVisits=8, meanQ=-0.782500, numObservations: 5
action -1, numVisits=6, meanQ=-1.010000, numObservations: 6
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 23560 episodes
GETTING ACTION FROM:
action 1, numVisits=23690, meanQ=15.069967, numObservations: 9
action 2, numVisits=8, meanQ=-0.782500, numObservations: 5
action -1, numVisits=6, meanQ=-1.010000, numObservations: 6
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.490065 0.916376 0.585862 0.659752 0.661732 0.406314 0.43902 0.175265 0.394834 0.210286 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 19
Initial state: 0 0.385055 0.580209 0.23233 0.871959 0.738294 0.162006 0.51681 0.322085 0.792268 0.948316 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28300 episodes
GETTING ACTION FROM:
action 1, numVisits=28289, meanQ=13.012334, numObservations: 9
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action 3, numVisits=3, meanQ=3.000000, numObservations: 3
action 4, numVisits=3, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.385055 0.580209 0.23233 0.871959 0.738294 0.162006 0.51681 0.322085 0.792268 0.948316 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=4425, meanQ=14.157952, numObservations: 9
action 2, numVisits=23, meanQ=11.693913, numObservations: 7
action 3, numVisits=3, meanQ=3.330000, numObservations: 3
action 5, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 9580 episodes
GETTING ACTION FROM:
action 4, numVisits=13991, meanQ=14.572913, numObservations: 9
action 2, numVisits=35, meanQ=10.851611, numObservations: 8
action 3, numVisits=3, meanQ=3.330000, numObservations: 3
action 5, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 0 0.385055 0.580209 0.23233 0.871959 0.738294 0.162006 0.51681 0.322085 0.792268 0.948316 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=83, meanQ=11.992985, numObservations: 9
action 2, numVisits=16, meanQ=9.787506, numObservations: 6
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 12389 episodes
GETTING ACTION FROM:
action 3, numVisits=12458, meanQ=12.668519, numObservations: 9
action 2, numVisits=22, meanQ=7.300005, numObservations: 6
action -1, numVisits=6, meanQ=-1.505000, numObservations: 6
action 0, numVisits=6, meanQ=-1.505000, numObservations: 6
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.385055 0.580209 0.23233 0.871959 0.738294 0.162006 0.51681 0.322085 0.792268 0.948316 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=1, meanQ=24.000000, numObservations: 1
action 5, numVisits=25, meanQ=12.073163, numObservations: 7
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-13.008548, numObservations: 1
action 4, numVisits=1, meanQ=-536.705456, numObservations: 1
Sampled 28228 episodes
GETTING ACTION FROM:
action 5, numVisits=28151, meanQ=4.847539, numObservations: 9
action 1, numVisits=15, meanQ=3.000000, numObservations: 4
action -1, numVisits=46, meanQ=-1.935435, numObservations: 26
action 0, numVisits=46, meanQ=-1.935435, numObservations: 27
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-13.008548, numObservations: 1
action 4, numVisits=1, meanQ=-536.705456, numObservations: 1
action: 5
Next state: 1 0.385055 0.580209 0.23233 0.871959 0.738294 0.162006 0.51681 0.322085 0.792268 0.948316 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 11.4068
Run # 20
Initial state: 0 0.0557397 0.16274 0.596343 0.310219 0.106014 0.033127 0.529605 0.90366 0.868086 0.7559 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28104 episodes
GETTING ACTION FROM:
action 2, numVisits=28095, meanQ=13.028647, numObservations: 9
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.0557397 0.16274 0.596343 0.310219 0.106014 0.033127 0.529605 0.90366 0.868086 0.7559 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 21
Initial state: 0 0.519829 0.676474 0.554669 0.318235 0.191432 0.221748 0.496675 0.257051 0.487138 0.214516 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26860 episodes
GETTING ACTION FROM:
action 4, numVisits=26842, meanQ=12.914874, numObservations: 9
action 3, numVisits=13, meanQ=6.769231, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.519829 0.676474 0.554669 0.318235 0.191432 0.221748 0.496675 0.257051 0.487138 0.214516 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 22
Initial state: 0 0.334868 0.157478 0.190868 0.00336702 0.52587 0.342975 0.733455 0.772905 0.0364638 0.589898 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28073 episodes
GETTING ACTION FROM:
action 3, numVisits=26644, meanQ=12.677011, numObservations: 9
action 4, numVisits=1411, meanQ=12.472591, numObservations: 9
action 1, numVisits=8, meanQ=9.248750, numObservations: 5
action 2, numVisits=6, meanQ=7.666667, numObservations: 5
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.334868 0.157478 0.190868 0.00336702 0.52587 0.342975 0.733455 0.772905 0.0364638 0.589898 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 23
Initial state: 0 0.920366 0.048236 0.58054 0.374965 0.433529 0.937511 0.363057 0.4901 0.247723 0.325495 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28151 episodes
GETTING ACTION FROM:
action 1, numVisits=28143, meanQ=13.136149, numObservations: 9
action 3, numVisits=3, meanQ=5.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.920366 0.048236 0.58054 0.374965 0.433529 0.937511 0.363057 0.4901 0.247723 0.325495 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 24
Initial state: 0 0.509181 0.919119 0.370981 0.700875 0.898088 0.140852 0.639323 0.406294 0.173329 0.926583 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27971 episodes
GETTING ACTION FROM:
action 3, numVisits=27939, meanQ=13.089970, numObservations: 9
action 4, numVisits=26, meanQ=8.576169, numObservations: 9
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 2 0.509181 0.919119 0.370981 0.700875 0.898088 0.140852 0.639323 0.406294 0.173329 0.926583 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 25
Initial state: 0 0.92965 0.89143 0.052028 0.952165 0.619003 0.301071 0.5093 0.59682 0.302295 0.81719 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26873 episodes
GETTING ACTION FROM:
action 3, numVisits=26859, meanQ=12.845655, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 2, numVisits=5, meanQ=-1.200000, numObservations: 4
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.92965 0.89143 0.052028 0.952165 0.619003 0.301071 0.5093 0.59682 0.302295 0.81719 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 26
Initial state: 0 0.475111 0.226433 0.954474 0.638071 0.4989 0.339166 0.516547 0.682028 0.921323 0.153887 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27071 episodes
GETTING ACTION FROM:
action 3, numVisits=27061, meanQ=13.056904, numObservations: 9
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action 5, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.475111 0.226433 0.954474 0.638071 0.4989 0.339166 0.516547 0.682028 0.921323 0.153887 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 27
Initial state: 0 0.552496 0.430018 0.737425 0.844105 0.577981 0.88636 0.336665 0.55211 0.339511 0.48189 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27907 episodes
GETTING ACTION FROM:
action 1, numVisits=27899, meanQ=12.599423, numObservations: 9
action 5, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.552496 0.430018 0.737425 0.844105 0.577981 0.88636 0.336665 0.55211 0.339511 0.48189 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 28
Initial state: 0 0.952219 0.201707 0.0774717 0.149006 0.0564489 0.170176 0.457638 0.25347 0.516577 0.35856 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28062 episodes
GETTING ACTION FROM:
action 2, numVisits=28046, meanQ=12.878398, numObservations: 9
action 1, numVisits=7, meanQ=8.424286, numObservations: 5
action 5, numVisits=5, meanQ=7.596000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.952219 0.201707 0.0774717 0.149006 0.0564489 0.170176 0.457638 0.25347 0.516577 0.35856 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=4422, meanQ=13.978972, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 10127 episodes
GETTING ACTION FROM:
action 4, numVisits=14547, meanQ=14.665417, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.952219 0.201707 0.0774717 0.149006 0.0564489 0.170176 0.457638 0.25347 0.516577 0.35856 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=1128, meanQ=16.014386, numObservations: 9
action 3, numVisits=3, meanQ=4.670033, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 7830 episodes
GETTING ACTION FROM:
action 5, numVisits=8958, meanQ=16.372210, numObservations: 9
action 3, numVisits=3, meanQ=4.670033, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 1 0.952219 0.201707 0.0774717 0.149006 0.0564489 0.170176 0.457638 0.25347 0.516577 0.35856 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 29
Initial state: 0 0.725139 0.216077 0.109972 0.650556 0.882189 0.790214 0.797878 0.556925 0.55814 0.307905 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28373 episodes
GETTING ACTION FROM:
action 3, numVisits=28348, meanQ=12.822902, numObservations: 9
action 5, numVisits=20, meanQ=9.801010, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.725139 0.216077 0.109972 0.650556 0.882189 0.790214 0.797878 0.556925 0.55814 0.307905 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 30
Initial state: 0 0.867074 0.210469 0.954728 0.546831 0.737188 0.989196 0.855281 0.50308 0.613437 0.393219 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28136 episodes
GETTING ACTION FROM:
action 2, numVisits=28123, meanQ=12.762900, numObservations: 9
action 4, numVisits=4, meanQ=6.500000, numObservations: 4
action 1, numVisits=3, meanQ=3.000000, numObservations: 3
action 3, numVisits=3, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.867074 0.210469 0.954728 0.546831 0.737188 0.989196 0.855281 0.50308 0.613437 0.393219 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 31
Initial state: 0 0.0166625 0.861482 0.748001 0.843152 0.110176 0.945768 0.656028 0.448112 0.497186 0.356806 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28037 episodes
GETTING ACTION FROM:
action 1, numVisits=28004, meanQ=12.997085, numObservations: 9
action 4, numVisits=17, meanQ=10.220588, numObservations: 6
action 5, numVisits=11, meanQ=10.094564, numObservations: 6
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.0166625 0.861482 0.748001 0.843152 0.110176 0.945768 0.656028 0.448112 0.497186 0.356806 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=4433, meanQ=13.958118, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 10081 episodes
GETTING ACTION FROM:
action 3, numVisits=14512, meanQ=14.829982, numObservations: 9
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.0166625 0.861482 0.748001 0.843152 0.110176 0.945768 0.656028 0.448112 0.497186 0.356806 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=1680, meanQ=13.538682, numObservations: 9
action 2, numVisits=21, meanQ=10.717143, numObservations: 8
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 7363 episodes
GETTING ACTION FROM:
action 5, numVisits=9043, meanQ=16.049888, numObservations: 9
action 2, numVisits=21, meanQ=10.717143, numObservations: 8
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 1 0.0166625 0.861482 0.748001 0.843152 0.110176 0.945768 0.656028 0.448112 0.497186 0.356806 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 32
Initial state: 0 0.91229 0.166505 0.723512 0.580756 0.524043 0.436471 0.186348 0.918627 0.213879 0.962644 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26501 episodes
GETTING ACTION FROM:
action 3, numVisits=26493, meanQ=12.742927, numObservations: 9
action 2, numVisits=3, meanQ=4.340033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.91229 0.166505 0.723512 0.580756 0.524043 0.436471 0.186348 0.918627 0.213879 0.962644 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=117, meanQ=13.797045, numObservations: 9
action 1, numVisits=104, meanQ=8.457583, numObservations: 9
action 4, numVisits=18, meanQ=6.916667, numObservations: 7
action 2, numVisits=9, meanQ=6.345567, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 15810 episodes
GETTING ACTION FROM:
action 5, numVisits=15923, meanQ=15.368484, numObservations: 9
action 1, numVisits=104, meanQ=8.457583, numObservations: 9
action 4, numVisits=18, meanQ=6.916667, numObservations: 7
action 2, numVisits=9, meanQ=6.345567, numObservations: 6
action 0, numVisits=3, meanQ=-1.340000, numObservations: 3
action -1, numVisits=3, meanQ=-1.670000, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 0 0.91229 0.166505 0.723512 0.580756 0.524043 0.436471 0.186348 0.918627 0.213879 0.962644 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=436, meanQ=14.535106, numObservations: 9
action 1, numVisits=9, meanQ=0.774467, numObservations: 5
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=35, meanQ=-16.273692, numObservations: 9
action 0, numVisits=38, meanQ=-25.231954, numObservations: 23
action -1, numVisits=32, meanQ=-33.556748, numObservations: 27
Sampled 19413 episodes
GETTING ACTION FROM:
action 2, numVisits=19849, meanQ=17.999335, numObservations: 9
action 1, numVisits=9, meanQ=0.774467, numObservations: 5
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=35, meanQ=-16.273692, numObservations: 9
action 0, numVisits=38, meanQ=-25.231954, numObservations: 23
action -1, numVisits=32, meanQ=-33.556748, numObservations: 27
action: 2
Next state: 1 0.91229 0.166505 0.723512 0.580756 0.524043 0.436471 0.186348 0.918627 0.213879 0.962644 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 33
Initial state: 0 0.0577732 0.984241 0.979405 0.470688 0.550183 0.182073 0.414925 0.453115 0.547843 0.392603 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26908 episodes
GETTING ACTION FROM:
action 3, numVisits=26894, meanQ=13.093606, numObservations: 9
action 2, numVisits=9, meanQ=6.888889, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.0577732 0.984241 0.979405 0.470688 0.550183 0.182073 0.414925 0.453115 0.547843 0.392603 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=293, meanQ=13.764227, numObservations: 9
action 2, numVisits=4, meanQ=10.495000, numObservations: 4
action 5, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 13463 episodes
GETTING ACTION FROM:
action 1, numVisits=13747, meanQ=11.163515, numObservations: 9
action 2, numVisits=7, meanQ=7.282857, numObservations: 5
action 5, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=4, meanQ=-1.752500, numObservations: 4
action 0, numVisits=4, meanQ=-1.752500, numObservations: 4
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.0577732 0.984241 0.979405 0.470688 0.550183 0.182073 0.414925 0.453115 0.547843 0.392603 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 34
Initial state: 0 0.426309 0.537875 0.985346 0.00957322 0.707203 0.501051 0.507869 0.321151 0.118426 0.626557 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28143 episodes
GETTING ACTION FROM:
action 5, numVisits=28104, meanQ=12.905243, numObservations: 9
action 4, numVisits=20, meanQ=8.450510, numObservations: 8
action 2, numVisits=9, meanQ=6.331111, numObservations: 5
action 3, numVisits=7, meanQ=6.141429, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 0 0.426309 0.537875 0.985346 0.00957322 0.707203 0.501051 0.507869 0.321151 0.118426 0.626557 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=4509, meanQ=13.878771, numObservations: 9
action 4, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 11046 episodes
GETTING ACTION FROM:
action 2, numVisits=15498, meanQ=14.218163, numObservations: 9
action 4, numVisits=57, meanQ=12.281367, numObservations: 9
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.426309 0.537875 0.985346 0.00957322 0.707203 0.501051 0.507869 0.321151 0.118426 0.626557 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=122, meanQ=3.793050, numObservations: 9
action 0, numVisits=33, meanQ=2.138060, numObservations: 20
action -1, numVisits=15, meanQ=-1.010000, numObservations: 15
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 25288 episodes
GETTING ACTION FROM:
action 1, numVisits=25097, meanQ=12.661137, numObservations: 9
action 4, numVisits=155, meanQ=3.951206, numObservations: 9
action 5, numVisits=4, meanQ=-0.252500, numObservations: 1
action 0, numVisits=177, meanQ=-0.809118, numObservations: 61
action -1, numVisits=26, meanQ=-1.428846, numObservations: 24
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.426309 0.537875 0.985346 0.00957322 0.707203 0.501051 0.507869 0.321151 0.118426 0.626557 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 4, numVisits=309, meanQ=17.705658, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 20250 episodes
GETTING ACTION FROM:
action 4, numVisits=20559, meanQ=13.039415, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.426309 0.537875 0.985346 0.00957322 0.707203 0.501051 0.507869 0.321151 0.118426 0.626557 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 11.4068
Run # 35
Initial state: 0 0.435167 0.976339 0.855355 0.235537 0.142415 0.553488 0.620392 0.372196 0.838739 0.861408 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28051 episodes
GETTING ACTION FROM:
action 2, numVisits=28045, meanQ=13.097574, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.435167 0.976339 0.855355 0.235537 0.142415 0.553488 0.620392 0.372196 0.838739 0.861408 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=129, meanQ=13.010668, numObservations: 9
action 5, numVisits=7, meanQ=7.140014, numObservations: 6
action 2, numVisits=5, meanQ=6.196000, numObservations: 4
action 3, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 22049 episodes
GETTING ACTION FROM:
action 4, numVisits=22176, meanQ=14.348810, numObservations: 9
action 5, numVisits=7, meanQ=7.140014, numObservations: 6
action 2, numVisits=5, meanQ=6.196000, numObservations: 4
action 3, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.435167 0.976339 0.855355 0.235537 0.142415 0.553488 0.620392 0.372196 0.838739 0.861408 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 36
Initial state: 0 0.395659 0.679369 0.119914 0.109717 0.661428 0.296141 0.894566 0.957475 0.0758014 0.459785 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26853 episodes
GETTING ACTION FROM:
action 1, numVisits=26842, meanQ=12.914040, numObservations: 9
action 4, numVisits=4, meanQ=9.255025, numObservations: 3
action 5, numVisits=3, meanQ=5.663333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.395659 0.679369 0.119914 0.109717 0.661428 0.296141 0.894566 0.957475 0.0758014 0.459785 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 37
Initial state: 0 0.00348931 0.291548 0.222736 0.642946 0.106246 0.228375 0.474053 0.0464212 0.58532 0.340781 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26879 episodes
GETTING ACTION FROM:
action 4, numVisits=26873, meanQ=12.745593, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.00348931 0.291548 0.222736 0.642946 0.106246 0.228375 0.474053 0.0464212 0.58532 0.340781 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=2836, meanQ=13.436232, numObservations: 9
action 5, numVisits=9, meanQ=6.777789, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 7014 episodes
GETTING ACTION FROM:
action 2, numVisits=9846, meanQ=12.261046, numObservations: 9
action 5, numVisits=9, meanQ=6.777789, numObservations: 5
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action -1, numVisits=3, meanQ=-1.340000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.00348931 0.291548 0.222736 0.642946 0.106246 0.228375 0.474053 0.0464212 0.58532 0.340781 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=1244, meanQ=13.574582, numObservations: 9
action 5, numVisits=7, meanQ=10.046223, numObservations: 5
action 3, numVisits=7, meanQ=6.857157, numObservations: 4
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 6324 episodes
GETTING ACTION FROM:
action 1, numVisits=7567, meanQ=14.735844, numObservations: 9
action 5, numVisits=8, meanQ=7.135541, numObservations: 5
action 3, numVisits=7, meanQ=6.857157, numObservations: 4
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.00348931 0.291548 0.222736 0.642946 0.106246 0.228375 0.474053 0.0464212 0.58532 0.340781 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=582, meanQ=9.790293, numObservations: 9
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=35, meanQ=-5.044817, numObservations: 6
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=29, meanQ=-13.418209, numObservations: 16
action 0, numVisits=15, meanQ=-35.985023, numObservations: 11
Sampled 7489 episodes
GETTING ACTION FROM:
action 3, numVisits=8071, meanQ=15.306707, numObservations: 9
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=35, meanQ=-5.044817, numObservations: 6
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=29, meanQ=-13.418209, numObservations: 16
action 0, numVisits=15, meanQ=-35.985023, numObservations: 11
action: 3
Next state: 0 0.00348931 0.291548 0.222736 0.642946 0.106246 0.228375 0.474053 0.0464212 0.58532 0.340781 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 5, numVisits=580, meanQ=21.972271, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.074282, numObservations: 1
action 4, numVisits=1, meanQ=-1068.353855, numObservations: 1
Sampled 16799 episodes
GETTING ACTION FROM:
action 5, numVisits=17379, meanQ=22.777487, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.074282, numObservations: 1
action 4, numVisits=1, meanQ=-1068.353855, numObservations: 1
action: 5
Next state: 1 0.00348931 0.291548 0.222736 0.642946 0.106246 0.228375 0.474053 0.0464212 0.58532 0.340781 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.29271
Run # 38
Initial state: 0 0.435095 0.74779 0.803939 0.996183 0.439925 0.683774 0.595361 0.362569 0.941357 0.906963 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27922 episodes
GETTING ACTION FROM:
action 5, numVisits=27914, meanQ=13.014955, numObservations: 9
action 1, numVisits=3, meanQ=4.340033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.435095 0.74779 0.803939 0.996183 0.439925 0.683774 0.595361 0.362569 0.941357 0.906963 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 39
Initial state: 0 0.924609 0.26682 0.35602 0.379484 0.835287 0.495164 0.639966 0.334243 0.175324 0.473832 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27905 episodes
GETTING ACTION FROM:
action 5, numVisits=27861, meanQ=12.958309, numObservations: 9
action 1, numVisits=39, meanQ=7.358479, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.924609 0.26682 0.35602 0.379484 0.835287 0.495164 0.639966 0.334243 0.175324 0.473832 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=4410, meanQ=13.690129, numObservations: 9
action 4, numVisits=8, meanQ=9.496250, numObservations: 6
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 9781 episodes
GETTING ACTION FROM:
action 3, numVisits=14149, meanQ=14.453052, numObservations: 9
action 4, numVisits=45, meanQ=9.197515, numObservations: 9
action 2, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.670000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.924609 0.26682 0.35602 0.379484 0.835287 0.495164 0.639966 0.334243 0.175324 0.473832 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 40
Initial state: 0 0.744908 0.920585 0.484413 0.0294169 0.790559 0.794943 0.522527 0.359116 0.474441 0.570566 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27807 episodes
GETTING ACTION FROM:
action 4, numVisits=27799, meanQ=12.966253, numObservations: 9
action 2, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.744908 0.920585 0.484413 0.0294169 0.790559 0.794943 0.522527 0.359116 0.474441 0.570566 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 41
Initial state: 0 0.918286 0.498432 0.352469 0.79493 0.703639 0.250771 0.323887 0.442968 0.50948 0.340711 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28187 episodes
GETTING ACTION FROM:
action 5, numVisits=28181, meanQ=13.100816, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.918286 0.498432 0.352469 0.79493 0.703639 0.250771 0.323887 0.442968 0.50948 0.340711 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 42
Initial state: 0 0.98923 0.215227 0.328796 0.186449 0.508123 0.362393 0.712854 0.690763 0.802519 0.33724 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28117 episodes
GETTING ACTION FROM:
action 5, numVisits=28108, meanQ=12.626639, numObservations: 9
action 3, numVisits=4, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.98923 0.215227 0.328796 0.186449 0.508123 0.362393 0.712854 0.690763 0.802519 0.33724 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 43
Initial state: 0 0.575511 0.918714 0.547644 0.828055 0.660035 0.328493 0.551558 0.233111 0.653111 0.7535 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27999 episodes
GETTING ACTION FROM:
action 4, numVisits=27983, meanQ=12.784414, numObservations: 9
action 1, numVisits=8, meanQ=8.876262, numObservations: 4
action 3, numVisits=4, meanQ=8.497500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 2 0.575511 0.918714 0.547644 0.828055 0.660035 0.328493 0.551558 0.233111 0.653111 0.7535 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 44
Initial state: 0 0.473897 0.194413 0.278099 0.144875 0.391151 0.462069 0.623246 0.38564 0.385436 0.746207 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27924 episodes
GETTING ACTION FROM:
action 2, numVisits=27918, meanQ=12.834529, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.473897 0.194413 0.278099 0.144875 0.391151 0.462069 0.623246 0.38564 0.385436 0.746207 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=2855, meanQ=13.702379, numObservations: 9
action 3, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 6840 episodes
GETTING ACTION FROM:
action 4, numVisits=9692, meanQ=13.362481, numObservations: 9
action 3, numVisits=4, meanQ=0.772500, numObservations: 3
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.473897 0.194413 0.278099 0.144875 0.391151 0.462069 0.623246 0.38564 0.385436 0.746207 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 45
Initial state: 0 0.218597 0.73266 0.641738 0.409256 0.425751 0.635393 0.281121 0.540285 0.798833 0.693844 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28181 episodes
GETTING ACTION FROM:
action 2, numVisits=28169, meanQ=13.060533, numObservations: 9
action 4, numVisits=7, meanQ=8.141429, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.218597 0.73266 0.641738 0.409256 0.425751 0.635393 0.281121 0.540285 0.798833 0.693844 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 46
Initial state: 0 0.0784952 0.134865 0.256988 0.554339 0.221354 0.917951 0.801702 0.986926 0.57995 0.388524 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27906 episodes
GETTING ACTION FROM:
action 2, numVisits=27898, meanQ=12.955207, numObservations: 9
action 3, numVisits=3, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.0784952 0.134865 0.256988 0.554339 0.221354 0.917951 0.801702 0.986926 0.57995 0.388524 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=4373, meanQ=13.814079, numObservations: 9
action 4, numVisits=8, meanQ=8.497500, numObservations: 6
action 5, numVisits=6, meanQ=7.183333, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 8500 episodes
GETTING ACTION FROM:
action 3, numVisits=12871, meanQ=14.924430, numObservations: 9
action 4, numVisits=8, meanQ=8.497500, numObservations: 6
action 5, numVisits=6, meanQ=7.183333, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.0784952 0.134865 0.256988 0.554339 0.221354 0.917951 0.801702 0.986926 0.57995 0.388524 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=672, meanQ=14.332211, numObservations: 8
action 3, numVisits=733, meanQ=9.984504, numObservations: 9
action 4, numVisits=68, meanQ=-2.154139, numObservations: 9
action -1, numVisits=38, meanQ=-2.514769, numObservations: 25
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=53, meanQ=-16.042402, numObservations: 28
Sampled 11927 episodes
GETTING ACTION FROM:
action 5, numVisits=11894, meanQ=18.651778, numObservations: 9
action 2, numVisits=685, meanQ=14.496488, numObservations: 8
action 3, numVisits=733, meanQ=9.984504, numObservations: 9
action 4, numVisits=68, meanQ=-2.154139, numObservations: 9
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action -1, numVisits=59, meanQ=-11.344308, numObservations: 34
action 0, numVisits=53, meanQ=-16.042402, numObservations: 28
action: 5
Next state: 1 0.0784952 0.134865 0.256988 0.554339 0.221354 0.917951 0.801702 0.986926 0.57995 0.388524 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 47
Initial state: 0 0.00786161 0.817873 0.473493 0.857195 0.548083 0.415107 0.238747 0.163281 0.855492 0.303734 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28030 episodes
GETTING ACTION FROM:
action 1, numVisits=28018, meanQ=12.935008, numObservations: 9
action 3, numVisits=7, meanQ=7.141429, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.00786161 0.817873 0.473493 0.857195 0.548083 0.415107 0.238747 0.163281 0.855492 0.303734 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=4453, meanQ=13.890549, numObservations: 9
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 9567 episodes
GETTING ACTION FROM:
action 3, numVisits=14017, meanQ=14.828149, numObservations: 9
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action 5, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.00786161 0.817873 0.473493 0.857195 0.548083 0.415107 0.238747 0.163281 0.855492 0.303734 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 48
Initial state: 0 0.858563 0.453343 0.493883 0.31833 0.768899 0.977314 0.084558 0.347693 0.15321 0.0704178 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26862 episodes
GETTING ACTION FROM:
action 5, numVisits=26840, meanQ=12.890505, numObservations: 9
action 2, numVisits=14, meanQ=10.338571, numObservations: 7
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action 4, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.858563 0.453343 0.493883 0.31833 0.768899 0.977314 0.084558 0.347693 0.15321 0.0704178 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 49
Initial state: 0 0.719186 0.0800173 0.418812 0.948493 0.541211 0.380135 0.957304 0.00835277 0.212352 0.42074 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28110 episodes
GETTING ACTION FROM:
action 2, numVisits=28101, meanQ=12.796043, numObservations: 9
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action 3, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.719186 0.0800173 0.418812 0.948493 0.541211 0.380135 0.957304 0.00835277 0.212352 0.42074 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=4370, meanQ=13.303724, numObservations: 9
action 1, numVisits=21, meanQ=7.570967, numObservations: 9
action 5, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 11431 episodes
GETTING ACTION FROM:
action 4, numVisits=15799, meanQ=14.650183, numObservations: 9
action 1, numVisits=21, meanQ=7.570967, numObservations: 9
action 5, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.719186 0.0800173 0.418812 0.948493 0.541211 0.380135 0.957304 0.00835277 0.212352 0.42074 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 50
Initial state: 0 0.298897 0.877958 0.609697 0.328417 0.711045 0.609514 0.384776 0.120779 0.473865 0.257676 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26303 episodes
GETTING ACTION FROM:
action 5, numVisits=26252, meanQ=13.162946, numObservations: 9
action 4, numVisits=33, meanQ=10.030324, numObservations: 8
action 3, numVisits=6, meanQ=8.998333, numObservations: 5
action 2, numVisits=9, meanQ=8.444444, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 0 0.298897 0.877958 0.609697 0.328417 0.711045 0.609514 0.384776 0.120779 0.473865 0.257676 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=2734, meanQ=14.166713, numObservations: 9
action 4, numVisits=15, meanQ=10.800673, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 6651 episodes
GETTING ACTION FROM:
action 1, numVisits=9381, meanQ=12.963531, numObservations: 9
action 4, numVisits=16, meanQ=9.505678, numObservations: 7
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.298897 0.877958 0.609697 0.328417 0.711045 0.609514 0.384776 0.120779 0.473865 0.257676 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=56, meanQ=13.111224, numObservations: 7
action 4, numVisits=12, meanQ=11.474742, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=14, meanQ=-61.684263, numObservations: 8
Sampled 10823 episodes
GETTING ACTION FROM:
action 4, numVisits=10830, meanQ=17.739853, numObservations: 9
action 1, numVisits=59, meanQ=12.768523, numObservations: 7
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=14, meanQ=-61.684263, numObservations: 8
action: 4
Next state: 0 0.298897 0.877958 0.609697 0.328417 0.711045 0.609514 0.384776 0.120779 0.473865 0.257676 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=234, meanQ=12.178723, numObservations: 9
action 2, numVisits=3, meanQ=-0.408322, numObservations: 3
action -1, numVisits=4, meanQ=-1.507475, numObservations: 3
action 0, numVisits=2, meanQ=-7.760082, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-535.861586, numObservations: 1
action 1, numVisits=1, meanQ=-536.050366, numObservations: 1
Sampled 13705 episodes
GETTING ACTION FROM:
action 3, numVisits=13939, meanQ=15.959802, numObservations: 9
action 2, numVisits=3, meanQ=-0.408322, numObservations: 3
action -1, numVisits=4, meanQ=-1.507475, numObservations: 3
action 0, numVisits=2, meanQ=-7.760082, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-535.861586, numObservations: 1
action 1, numVisits=1, meanQ=-536.050366, numObservations: 1
action: 3
Next state: 1 0.298897 0.877958 0.609697 0.328417 0.711045 0.609514 0.384776 0.120779 0.473865 0.257676 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 11.4068
[32m ProblemEnvironment.hpp 351: Done.[39m
