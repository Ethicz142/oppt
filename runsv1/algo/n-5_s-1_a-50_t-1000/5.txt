Run # 1
Initial state: 0 0.119746 0.902717 0.694886 0.614824 0.43974 0.301897 0.0495719 0.355245 0.575042 0.53335 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26192 episodes
GETTING ACTION FROM:
action 1, numVisits=26186, meanQ=11.517621, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.119746 0.902717 0.694886 0.614824 0.43974 0.301897 0.0495719 0.355245 0.575042 0.53335 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=3217, meanQ=14.590129, numObservations: 9
action 4, numVisits=9, meanQ=6.777789, numObservations: 6
action 3, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 9878 episodes
GETTING ACTION FROM:
action 5, numVisits=9763, meanQ=15.030622, numObservations: 9
action 1, numVisits=3218, meanQ=14.588568, numObservations: 9
action 4, numVisits=13, meanQ=4.258646, numObservations: 7
action 3, numVisits=108, meanQ=2.648009, numObservations: 9
action -1, numVisits=4, meanQ=-1.505000, numObservations: 4
action 0, numVisits=4, meanQ=-1.505000, numObservations: 4
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 1 0.119746 0.902717 0.694886 0.614824 0.43974 0.301897 0.0495719 0.355245 0.575042 0.53335 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 2
Initial state: 0 0.581373 0.665741 0.461599 0.0539814 0.975021 0.349859 0.542267 0.458131 0.372787 0.024091 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28272 episodes
GETTING ACTION FROM:
action 1, numVisits=28263, meanQ=11.074334, numObservations: 9
action 4, numVisits=4, meanQ=2.750025, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.581373 0.665741 0.461599 0.0539814 0.975021 0.349859 0.542267 0.458131 0.372787 0.024091 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 3
Initial state: 0 0.664021 0.29845 0.57542 0.688705 0.53868 0.511506 0.162693 0.307273 0.8891 0.828647 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27059 episodes
GETTING ACTION FROM:
action 4, numVisits=27050, meanQ=11.026720, numObservations: 9
action 3, numVisits=4, meanQ=2.750025, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 0 0.664021 0.29845 0.57542 0.688705 0.53868 0.511506 0.162693 0.307273 0.8891 0.828647 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=3604, meanQ=11.218767, numObservations: 9
action 5, numVisits=24, meanQ=4.751679, numObservations: 8
action 2, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 6912 episodes
GETTING ACTION FROM:
action 1, numVisits=10506, meanQ=10.292753, numObservations: 9
action 5, numVisits=24, meanQ=4.751679, numObservations: 8
action 2, numVisits=3, meanQ=0.666667, numObservations: 2
action 0, numVisits=6, meanQ=-1.175000, numObservations: 6
action -1, numVisits=6, meanQ=-1.175000, numObservations: 6
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.664021 0.29845 0.57542 0.688705 0.53868 0.511506 0.162693 0.307273 0.8891 0.828647 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 4
Initial state: 0 0.940231 0.497247 0.00134193 0.0485805 0.520787 0.443567 0.80895 0.248076 0.418705 0.712162 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28701 episodes
GETTING ACTION FROM:
action 5, numVisits=28695, meanQ=10.740269, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.940231 0.497247 0.00134193 0.0485805 0.520787 0.443567 0.80895 0.248076 0.418705 0.712162 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=3578, meanQ=11.838088, numObservations: 9
action 1, numVisits=11, meanQ=9.555464, numObservations: 6
action 4, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 11109 episodes
GETTING ACTION FROM:
action 3, numVisits=14683, meanQ=13.248054, numObservations: 9
action 1, numVisits=13, meanQ=8.759238, numObservations: 6
action 4, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.940231 0.497247 0.00134193 0.0485805 0.520787 0.443567 0.80895 0.248076 0.418705 0.712162 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 5
Initial state: 0 0.0274405 0.954922 0.371958 0.58654 0.0341749 0.598871 0.076818 0.867516 0.540395 0.47039 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27597 episodes
GETTING ACTION FROM:
action 4, numVisits=26765, meanQ=10.840124, numObservations: 9
action 2, numVisits=574, meanQ=10.322858, numObservations: 9
action 3, numVisits=254, meanQ=10.216814, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.0274405 0.954922 0.371958 0.58654 0.0341749 0.598871 0.076818 0.867516 0.540395 0.47039 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=214, meanQ=12.034488, numObservations: 9
action 2, numVisits=11, meanQ=7.453645, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 34602 episodes
GETTING ACTION FROM:
action 5, numVisits=34814, meanQ=15.544163, numObservations: 9
action 2, numVisits=11, meanQ=7.453645, numObservations: 6
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.0274405 0.954922 0.371958 0.58654 0.0341749 0.598871 0.076818 0.867516 0.540395 0.47039 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=36, meanQ=15.583015, numObservations: 6
action 3, numVisits=2, meanQ=6.810919, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-10.782692, numObservations: 1
action 1, numVisits=1, meanQ=-11.158221, numObservations: 1
action 4, numVisits=1, meanQ=-1066.406288, numObservations: 1
Sampled 41386 episodes
GETTING ACTION FROM:
action 5, numVisits=925, meanQ=22.270230, numObservations: 9
action 3, numVisits=40495, meanQ=14.593258, numObservations: 9
action -1, numVisits=3, meanQ=-1.670000, numObservations: 3
action 0, numVisits=3, meanQ=-1.670000, numObservations: 3
action 2, numVisits=1, meanQ=-10.782692, numObservations: 1
action 1, numVisits=1, meanQ=-11.158221, numObservations: 1
action 4, numVisits=1, meanQ=-1066.406288, numObservations: 1
action: 5
Next state: 1 0.0274405 0.954922 0.371958 0.58654 0.0341749 0.598871 0.076818 0.867516 0.540395 0.47039 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 6
Initial state: 0 0.856929 0.866075 0.0353645 0.612636 0.707254 0.95287 0.231957 0.15381 0.609949 0.413437 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28260 episodes
GETTING ACTION FROM:
action 5, numVisits=28153, meanQ=10.734579, numObservations: 9
action 3, numVisits=102, meanQ=7.999464, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.856929 0.866075 0.0353645 0.612636 0.707254 0.95287 0.231957 0.15381 0.609949 0.413437 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 7
Initial state: 0 0.547881 0.50128 0.743289 0.0674485 0.826235 0.432875 0.286488 0.175441 0.45687 0.163606 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28080 episodes
GETTING ACTION FROM:
action 1, numVisits=28074, meanQ=10.696794, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.547881 0.50128 0.743289 0.0674485 0.826235 0.432875 0.286488 0.175441 0.45687 0.163606 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 8
Initial state: 0 0.563298 0.501941 0.652663 0.0517673 0.910354 0.8065 0.471804 0.250491 0.757578 0.773037 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28187 episodes
GETTING ACTION FROM:
action 2, numVisits=28172, meanQ=10.991126, numObservations: 9
action 1, numVisits=6, meanQ=3.503367, numObservations: 4
action 5, numVisits=3, meanQ=3.330000, numObservations: 2
action 4, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 2 0.563298 0.501941 0.652663 0.0517673 0.910354 0.8065 0.471804 0.250491 0.757578 0.773037 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 9
Initial state: 0 0.516851 0.625955 0.360258 0.972983 0.0687 0.329273 0.760419 0.762866 0.537536 0.417902 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26014 episodes
GETTING ACTION FROM:
action 1, numVisits=26008, meanQ=10.219072, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.516851 0.625955 0.360258 0.972983 0.0687 0.329273 0.760419 0.762866 0.537536 0.417902 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 10
Initial state: 0 0.593444 0.416641 0.248029 0.813637 0.165488 0.925838 0.70013 0.172177 0.708623 0.549228 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28308 episodes
GETTING ACTION FROM:
action 2, numVisits=28288, meanQ=11.011984, numObservations: 9
action 5, numVisits=7, meanQ=7.000000, numObservations: 4
action 1, numVisits=9, meanQ=6.888889, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.593444 0.416641 0.248029 0.813637 0.165488 0.925838 0.70013 0.172177 0.708623 0.549228 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=3469, meanQ=12.141058, numObservations: 9
action 3, numVisits=3, meanQ=5.993333, numObservations: 3
action 4, numVisits=5, meanQ=4.598000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 10517 episodes
GETTING ACTION FROM:
action 1, numVisits=13915, meanQ=12.811194, numObservations: 9
action 3, numVisits=66, meanQ=7.877468, numObservations: 8
action 4, numVisits=6, meanQ=2.358588, numObservations: 4
action 0, numVisits=5, meanQ=-1.208000, numObservations: 5
action -1, numVisits=4, meanQ=-1.257500, numObservations: 4
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.593444 0.416641 0.248029 0.813637 0.165488 0.925838 0.70013 0.172177 0.708623 0.549228 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 11
Initial state: 0 0.740027 0.310384 0.452441 0.227724 0.32342 0.785092 0.605167 0.449722 0.367421 0.221853 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28278 episodes
GETTING ACTION FROM:
action 3, numVisits=28266, meanQ=10.765845, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 1, numVisits=2, meanQ=-7.500000, numObservations: 2
action 2, numVisits=2, meanQ=-7.500000, numObservations: 2
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.740027 0.310384 0.452441 0.227724 0.32342 0.785092 0.605167 0.449722 0.367421 0.221853 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 12
Initial state: 0 0.91905 0.0754327 0.0552377 0.617281 0.649376 0.211444 0.360515 0.482179 0.612848 0.460173 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27415 episodes
GETTING ACTION FROM:
action 1, numVisits=27401, meanQ=11.255718, numObservations: 9
action 2, numVisits=9, meanQ=7.775567, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.91905 0.0754327 0.0552377 0.617281 0.649376 0.211444 0.360515 0.482179 0.612848 0.460173 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 13
Initial state: 0 0.532218 0.382792 0.490944 0.141693 0.467243 0.275454 0.0645951 0.290395 0.535128 0.397252 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28470 episodes
GETTING ACTION FROM:
action 2, numVisits=28449, meanQ=10.930536, numObservations: 9
action 4, numVisits=11, meanQ=7.370909, numObservations: 7
action 3, numVisits=4, meanQ=6.500000, numObservations: 4
action 1, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.532218 0.382792 0.490944 0.141693 0.467243 0.275454 0.0645951 0.290395 0.535128 0.397252 w: 1
Observation: 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=440, meanQ=12.127347, numObservations: 9
action 3, numVisits=7, meanQ=5.141429, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 11648 episodes
GETTING ACTION FROM:
action 1, numVisits=12076, meanQ=9.690554, numObservations: 9
action 3, numVisits=7, meanQ=5.141429, numObservations: 6
action -1, numVisits=8, meanQ=-1.381250, numObservations: 8
action 0, numVisits=6, meanQ=-1.835000, numObservations: 6
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.532218 0.382792 0.490944 0.141693 0.467243 0.275454 0.0645951 0.290395 0.535128 0.397252 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 14
Initial state: 0 0.0167491 0.33585 0.773727 0.692997 0.406866 0.788605 0.025215 0.855964 0.565922 0.463773 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28688 episodes
GETTING ACTION FROM:
action 3, numVisits=28665, meanQ=10.811497, numObservations: 9
action 2, numVisits=14, meanQ=6.785029, numObservations: 7
action 5, numVisits=3, meanQ=3.330000, numObservations: 3
action 1, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.0167491 0.33585 0.773727 0.692997 0.406866 0.788605 0.025215 0.855964 0.565922 0.463773 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=3561, meanQ=11.962250, numObservations: 9
action 1, numVisits=18, meanQ=7.721117, numObservations: 7
action 5, numVisits=12, meanQ=6.415850, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 10555 episodes
GETTING ACTION FROM:
action 1, numVisits=10552, meanQ=14.537119, numObservations: 9
action 2, numVisits=3578, meanQ=11.993173, numObservations: 9
action 5, numVisits=12, meanQ=6.415850, numObservations: 6
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action -1, numVisits=3, meanQ=-1.340000, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.0167491 0.33585 0.773727 0.692997 0.406866 0.788605 0.025215 0.855964 0.565922 0.463773 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=18, meanQ=14.094367, numObservations: 8
action 4, numVisits=9, meanQ=12.574351, numObservations: 5
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-10.760697, numObservations: 1
action 3, numVisits=1, meanQ=-1067.783218, numObservations: 1
Sampled 19700 episodes
GETTING ACTION FROM:
action 2, numVisits=19685, meanQ=13.973893, numObservations: 9
action 4, numVisits=39, meanQ=2.657723, numObservations: 9
action 5, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 1, numVisits=1, meanQ=-10.760697, numObservations: 1
action 3, numVisits=1, meanQ=-1067.783218, numObservations: 1
action: 2
Next state: 1 0.0167491 0.33585 0.773727 0.692997 0.406866 0.788605 0.025215 0.855964 0.565922 0.463773 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 15
Initial state: 0 0.464565 0.0988607 0.605634 0.493902 0.194314 0.627767 0.695853 0.13882 0.266343 0.898708 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26766 episodes
GETTING ACTION FROM:
action 5, numVisits=26754, meanQ=10.854205, numObservations: 9
action 1, numVisits=7, meanQ=5.141429, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.464565 0.0988607 0.605634 0.493902 0.194314 0.627767 0.695853 0.13882 0.266343 0.898708 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=840, meanQ=11.630284, numObservations: 9
action 4, numVisits=9, meanQ=3.344456, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 9353 episodes
GETTING ACTION FROM:
action 1, numVisits=10152, meanQ=11.328469, numObservations: 9
action 4, numVisits=9, meanQ=3.344456, numObservations: 6
action 3, numVisits=4, meanQ=-0.252500, numObservations: 3
action 0, numVisits=17, meanQ=-1.301176, numObservations: 17
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=23, meanQ=-43.899527, numObservations: 17
action: 1
Next state: 0 0.464565 0.0988607 0.605634 0.493902 0.194314 0.627767 0.695853 0.13882 0.266343 0.898708 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=584, meanQ=12.133846, numObservations: 9
action 2, numVisits=6, meanQ=8.501683, numObservations: 5
action 3, numVisits=116, meanQ=2.019242, numObservations: 9
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=19, meanQ=-54.499313, numObservations: 13
Sampled 6391 episodes
GETTING ACTION FROM:
action 4, numVisits=6961, meanQ=12.582226, numObservations: 9
action 2, numVisits=19, meanQ=6.401173, numObservations: 7
action 3, numVisits=116, meanQ=2.019242, numObservations: 9
action 0, numVisits=5, meanQ=-1.208000, numObservations: 5
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=19, meanQ=-54.499313, numObservations: 13
action: 4
Next state: 2 0.464565 0.0988607 0.605634 0.493902 0.194314 0.627767 0.695853 0.13882 0.266343 0.898708 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -18.7411
Run # 16
Initial state: 0 0.859683 0.926357 0.550056 0.183183 0.514301 0.502318 0.33367 0.987634 0.467176 0.64104 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28763 episodes
GETTING ACTION FROM:
action 5, numVisits=28757, meanQ=10.876322, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.859683 0.926357 0.550056 0.183183 0.514301 0.502318 0.33367 0.987634 0.467176 0.64104 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=3481, meanQ=12.111594, numObservations: 9
action -1, numVisits=32, meanQ=0.165006, numObservations: 28
action 0, numVisits=5, meanQ=-1.010000, numObservations: 5
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 10167 episodes
GETTING ACTION FROM:
action 2, numVisits=13648, meanQ=13.242479, numObservations: 9
action -1, numVisits=32, meanQ=0.165006, numObservations: 28
action 0, numVisits=5, meanQ=-1.010000, numObservations: 5
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.859683 0.926357 0.550056 0.183183 0.514301 0.502318 0.33367 0.987634 0.467176 0.64104 w: 1
Observation: 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=36, meanQ=10.435773, numObservations: 9
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=13, meanQ=-3.253481, numObservations: 8
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=50, meanQ=-11.652566, numObservations: 9
action -1, numVisits=55, meanQ=-18.384566, numObservations: 37
action 0, numVisits=9, meanQ=-118.802395, numObservations: 7
Sampled 12765 episodes
GETTING ACTION FROM:
action 3, numVisits=12801, meanQ=11.977344, numObservations: 9
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=13, meanQ=-3.253481, numObservations: 8
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=50, meanQ=-11.652566, numObservations: 9
action -1, numVisits=55, meanQ=-18.384566, numObservations: 37
action 0, numVisits=9, meanQ=-118.802395, numObservations: 7
action: 3
Next state: 1 0.859683 0.926357 0.550056 0.183183 0.514301 0.502318 0.33367 0.987634 0.467176 0.64104 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 17
Initial state: 0 0.495792 0.426581 0.928974 0.862383 0.886625 0.313132 0.558273 0.288733 0.450127 0.351152 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27321 episodes
GETTING ACTION FROM:
action 3, numVisits=27309, meanQ=10.814620, numObservations: 9
action 4, numVisits=3, meanQ=5.663333, numObservations: 3
action 5, numVisits=3, meanQ=5.000033, numObservations: 1
action 2, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 2 0.495792 0.426581 0.928974 0.862383 0.886625 0.313132 0.558273 0.288733 0.450127 0.351152 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 18
Initial state: 0 0.347803 0.0427819 0.471862 0.525707 0.718934 0.889264 0.762799 0.441739 0.389454 0.115797 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18066 episodes
GETTING ACTION FROM:
action -1, numVisits=18024, meanQ=14.408846, numObservations: 243
action 0, numVisits=32, meanQ=-1.258119, numObservations: 30
action 5, numVisits=2, meanQ=-3.505000, numObservations: 2
action 3, numVisits=2, meanQ=-4.499950, numObservations: 1
action 1, numVisits=2, meanQ=-7.500000, numObservations: 2
action 2, numVisits=2, meanQ=-7.500000, numObservations: 2
action 4, numVisits=2, meanQ=-7.500000, numObservations: 1
action: -1
Next state: 0 0.347803 0.0427819 0.471862 0.525707 0.718934 0.889264 0.762799 0.441739 0.389454 0.115797 w: 1
Observation: 0 1 0 2 0 3 0 3 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=129, meanQ=7.313179, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 39227 episodes
GETTING ACTION FROM:
action 3, numVisits=39356, meanQ=13.146434, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.347803 0.0427819 0.471862 0.525707 0.718934 0.889264 0.762799 0.441739 0.389454 0.115797 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 19
Initial state: 0 0.390933 0.0209834 0.367657 0.390703 0.574909 0.477699 0.255986 0.655592 0.185314 0.376194 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28729 episodes
GETTING ACTION FROM:
action 3, numVisits=28711, meanQ=11.061873, numObservations: 9
action 2, numVisits=10, meanQ=2.349010, numObservations: 6
action 4, numVisits=4, meanQ=-0.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.390933 0.0209834 0.367657 0.390703 0.574909 0.477699 0.255986 0.655592 0.185314 0.376194 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 20
Initial state: 0 0.824629 0.956971 0.424925 0.38627 0.389758 0.0270471 0.635862 0.920481 0.578342 0.454073 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26693 episodes
GETTING ACTION FROM:
action 1, numVisits=26681, meanQ=10.816148, numObservations: 9
action 4, numVisits=5, meanQ=6.196000, numObservations: 4
action 2, numVisits=3, meanQ=5.663333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.824629 0.956971 0.424925 0.38627 0.389758 0.0270471 0.635862 0.920481 0.578342 0.454073 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 21
Initial state: 0 0.0279072 0.17185 0.969122 0.449296 0.672979 0.57469 0.685308 0.942854 0.549555 0.40663 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28348 episodes
GETTING ACTION FROM:
action 4, numVisits=28334, meanQ=10.838075, numObservations: 9
action 1, numVisits=6, meanQ=7.666667, numObservations: 4
action 3, numVisits=4, meanQ=6.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 1 0.0279072 0.17185 0.969122 0.449296 0.672979 0.57469 0.685308 0.942854 0.549555 0.40663 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 22
Initial state: 0 0.741373 0.927988 0.096892 0.123264 0.996477 0.241634 0.717585 0.902457 0.506662 0.494888 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28579 episodes
GETTING ACTION FROM:
action 4, numVisits=28573, meanQ=10.931396, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.741373 0.927988 0.096892 0.123264 0.996477 0.241634 0.717585 0.902457 0.506662 0.494888 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 23
Initial state: 0 0.044133 0.527444 0.489015 0.462627 0.186063 0.627548 0.937039 0.0650708 0.0263607 0.701102 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28628 episodes
GETTING ACTION FROM:
action 1, numVisits=28609, meanQ=11.013839, numObservations: 9
action 3, numVisits=12, meanQ=7.896667, numObservations: 7
action 4, numVisits=3, meanQ=4.340033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.044133 0.527444 0.489015 0.462627 0.186063 0.627548 0.937039 0.0650708 0.0263607 0.701102 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 24
Initial state: 0 0.435578 0.843502 0.806224 0.550448 0.638399 0.922207 0.23705 0.650748 0.479762 0.524257 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27402 episodes
GETTING ACTION FROM:
action 1, numVisits=27392, meanQ=10.786365, numObservations: 9
action 4, numVisits=3, meanQ=3.000000, numObservations: 3
action 5, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.435578 0.843502 0.806224 0.550448 0.638399 0.922207 0.23705 0.650748 0.479762 0.524257 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 25
Initial state: 0 0.700958 0.48443 0.519326 0.475518 0.168697 0.836852 0.193159 0.132157 0.787742 0.0628267 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28491 episodes
GETTING ACTION FROM:
action 1, numVisits=28485, meanQ=11.001522, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.700958 0.48443 0.519326 0.475518 0.168697 0.836852 0.193159 0.132157 0.787742 0.0628267 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 26
Initial state: 0 0.509086 0.516833 0.1726 0.0383276 0.629727 0.794617 0.489391 0.661518 0.243972 0.963695 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28273 episodes
GETTING ACTION FROM:
action 5, numVisits=28260, meanQ=11.100084, numObservations: 9
action 4, numVisits=6, meanQ=1.833333, numObservations: 5
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 0 0.509086 0.516833 0.1726 0.0383276 0.629727 0.794617 0.489391 0.661518 0.243972 0.963695 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=3402, meanQ=12.281626, numObservations: 9
action 4, numVisits=4, meanQ=-0.252500, numObservations: 3
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 11154 episodes
GETTING ACTION FROM:
action 1, numVisits=14556, meanQ=13.368836, numObservations: 9
action 4, numVisits=4, meanQ=-0.252500, numObservations: 3
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.509086 0.516833 0.1726 0.0383276 0.629727 0.794617 0.489391 0.661518 0.243972 0.963695 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 27
Initial state: 0 0.387758 0.260022 0.596616 0.30812 0.341691 0.976614 0.305266 0.650357 0.519334 0.414401 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26898 episodes
GETTING ACTION FROM:
action 3, numVisits=26883, meanQ=11.159875, numObservations: 9
action 2, numVisits=10, meanQ=5.898010, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.387758 0.260022 0.596616 0.30812 0.341691 0.976614 0.305266 0.650357 0.519334 0.414401 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=3325, meanQ=12.545121, numObservations: 9
action 4, numVisits=13, meanQ=7.459238, numObservations: 7
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 11080 episodes
GETTING ACTION FROM:
action 4, numVisits=11090, meanQ=14.932146, numObservations: 9
action 3, numVisits=3326, meanQ=12.543890, numObservations: 9
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 1 0.387758 0.260022 0.596616 0.30812 0.341691 0.976614 0.305266 0.650357 0.519334 0.414401 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 28
Initial state: 0 0.666098 0.762217 0.92484 0.262276 0.658946 0.957532 0.471611 0.48397 0.147066 0.246355 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28574 episodes
GETTING ACTION FROM:
action 2, numVisits=28568, meanQ=10.817871, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.666098 0.762217 0.92484 0.262276 0.658946 0.957532 0.471611 0.48397 0.147066 0.246355 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 29
Initial state: 0 0.751452 0.614132 0.460052 0.666626 0.835107 0.335234 0.544968 0.531285 0.33351 0.137232 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28651 episodes
GETTING ACTION FROM:
action 2, numVisits=28645, meanQ=10.906554, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.751452 0.614132 0.460052 0.666626 0.835107 0.335234 0.544968 0.531285 0.33351 0.137232 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=3575, meanQ=12.385503, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 10457 episodes
GETTING ACTION FROM:
action 4, numVisits=14030, meanQ=13.030810, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.751452 0.614132 0.460052 0.666626 0.835107 0.335234 0.544968 0.531285 0.33351 0.137232 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 30
Initial state: 0 0.514965 0.506805 0.14738 0.233065 0.415378 0.99193 0.400539 0.906848 0.655745 0.519598 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28459 episodes
GETTING ACTION FROM:
action 1, numVisits=28447, meanQ=11.095273, numObservations: 9
action 5, numVisits=5, meanQ=6.604020, numObservations: 4
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.514965 0.506805 0.14738 0.233065 0.415378 0.99193 0.400539 0.906848 0.655745 0.519598 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 31
Initial state: 0 0.791735 0.659235 0.367513 0.741141 0.583163 0.409562 0.228415 0.667014 0.864975 0.35816 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28445 episodes
GETTING ACTION FROM:
action 4, numVisits=28413, meanQ=10.889997, numObservations: 9
action 5, numVisits=21, meanQ=8.090014, numObservations: 7
action 3, numVisits=5, meanQ=7.398000, numObservations: 4
action 1, numVisits=3, meanQ=5.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 0 0.791735 0.659235 0.367513 0.741141 0.583163 0.409562 0.228415 0.667014 0.864975 0.35816 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=3492, meanQ=11.873370, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 11223 episodes
GETTING ACTION FROM:
action 3, numVisits=14711, meanQ=14.242718, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.791735 0.659235 0.367513 0.741141 0.583163 0.409562 0.228415 0.667014 0.864975 0.35816 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 32
Initial state: 0 0.292483 0.82761 0.899655 0.283756 0.507551 0.512836 0.210818 0.68201 0.789941 0.399329 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28497 episodes
GETTING ACTION FROM:
action 3, numVisits=28450, meanQ=10.778589, numObservations: 9
action 1, numVisits=22, meanQ=5.999568, numObservations: 8
action 4, numVisits=15, meanQ=5.798680, numObservations: 7
action 5, numVisits=7, meanQ=5.000000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.292483 0.82761 0.899655 0.283756 0.507551 0.512836 0.210818 0.68201 0.789941 0.399329 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 33
Initial state: 0 0.158365 0.704888 0.147986 0.619563 0.950592 0.0515999 0.648465 0.331889 0.576153 0.492646 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28385 episodes
GETTING ACTION FROM:
action 4, numVisits=28373, meanQ=10.654046, numObservations: 9
action 1, numVisits=5, meanQ=4.400000, numObservations: 4
action 2, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 2 0.158365 0.704888 0.147986 0.619563 0.950592 0.0515999 0.648465 0.331889 0.576153 0.492646 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 34
Initial state: 0 0.544323 0.703022 0.315401 0.625122 0.273489 0.859819 0.742558 0.178836 0.603538 0.540867 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28568 episodes
GETTING ACTION FROM:
action 4, numVisits=28558, meanQ=10.865561, numObservations: 9
action 3, numVisits=5, meanQ=4.400000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.544323 0.703022 0.315401 0.625122 0.273489 0.859819 0.742558 0.178836 0.603538 0.540867 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 35
Initial state: 0 0.518074 0.453253 0.858896 0.250059 0.0182485 0.515974 0.332444 0.473255 0.0416875 0.862693 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28355 episodes
GETTING ACTION FROM:
action 3, numVisits=28340, meanQ=10.986842, numObservations: 9
action 4, numVisits=10, meanQ=5.899000, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.518074 0.453253 0.858896 0.250059 0.0182485 0.515974 0.332444 0.473255 0.0416875 0.862693 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=956, meanQ=10.887396, numObservations: 9
action 5, numVisits=4, meanQ=1.745000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 9213 episodes
GETTING ACTION FROM:
action 2, numVisits=10120, meanQ=10.971416, numObservations: 9
action 5, numVisits=5, meanQ=-0.435577, numObservations: 5
action -1, numVisits=25, meanQ=-1.485200, numObservations: 25
action 0, numVisits=25, meanQ=-1.485200, numObservations: 24
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.518074 0.453253 0.858896 0.250059 0.0182485 0.515974 0.332444 0.473255 0.0416875 0.862693 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 36
Initial state: 0 0.782183 0.0757059 0.662438 0.173785 0.00698747 0.647285 0.522602 0.515964 0.137881 0.0992365 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28131 episodes
GETTING ACTION FROM:
action 2, numVisits=28118, meanQ=10.716299, numObservations: 9
action 4, numVisits=4, meanQ=6.500000, numObservations: 3
action 1, numVisits=5, meanQ=4.598000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 2 0.782183 0.0757059 0.662438 0.173785 0.00698747 0.647285 0.522602 0.515964 0.137881 0.0992365 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 37
Initial state: 0 0.47757 0.403766 0.46339 0.699224 0.0327582 0.757713 0.606801 0.206298 0.808624 0.490366 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28098 episodes
GETTING ACTION FROM:
action 2, numVisits=28084, meanQ=11.080126, numObservations: 9
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 1, numVisits=2, meanQ=-4.000000, numObservations: 2
action 4, numVisits=2, meanQ=-4.000000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.47757 0.403766 0.46339 0.699224 0.0327582 0.757713 0.606801 0.206298 0.808624 0.490366 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=3417, meanQ=12.129911, numObservations: 9
action 5, numVisits=13, meanQ=8.711538, numObservations: 6
action 3, numVisits=8, meanQ=8.497500, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 10036 episodes
GETTING ACTION FROM:
action 1, numVisits=13293, meanQ=13.070429, numObservations: 9
action 5, numVisits=165, meanQ=4.608910, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=12, meanQ=-80.164084, numObservations: 6
action: 1
Next state: 1 0.47757 0.403766 0.46339 0.699224 0.0327582 0.757713 0.606801 0.206298 0.808624 0.490366 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 38
Initial state: 0 0.77208 0.20924 0.493373 0.523817 0.257181 0.404982 0.548214 0.32601 0.795685 0.929804 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28591 episodes
GETTING ACTION FROM:
action 5, numVisits=28573, meanQ=10.789541, numObservations: 9
action 4, numVisits=8, meanQ=3.388750, numObservations: 5
action 1, numVisits=6, meanQ=3.165000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.77208 0.20924 0.493373 0.523817 0.257181 0.404982 0.548214 0.32601 0.795685 0.929804 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 39
Initial state: 0 0.777214 0.876781 0.882981 0.943483 0.0571956 0.558966 0.510948 0.500981 0.907079 0.933733 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28885 episodes
GETTING ACTION FROM:
action 2, numVisits=28843, meanQ=11.039435, numObservations: 9
action 3, numVisits=31, meanQ=8.501297, numObservations: 7
action 5, numVisits=5, meanQ=5.998000, numObservations: 4
action 4, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.777214 0.876781 0.882981 0.943483 0.0571956 0.558966 0.510948 0.500981 0.907079 0.933733 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 40
Initial state: 0 0.23114 0.27741 0.0545977 0.758184 0.48216 0.639267 0.650372 0.386899 0.502405 0.394658 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28391 episodes
GETTING ACTION FROM:
action 5, numVisits=28383, meanQ=10.851920, numObservations: 9
action 3, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 1 0.23114 0.27741 0.0545977 0.758184 0.48216 0.639267 0.650372 0.386899 0.502405 0.394658 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 41
Initial state: 0 0.814221 0.722211 0.156971 0.0784689 0.75066 0.197495 0.0414481 0.487464 0.530168 0.521895 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28538 episodes
GETTING ACTION FROM:
action 2, numVisits=28522, meanQ=10.594589, numObservations: 9
action 1, numVisits=7, meanQ=0.000000, numObservations: 3
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.814221 0.722211 0.156971 0.0784689 0.75066 0.197495 0.0414481 0.487464 0.530168 0.521895 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=3893, meanQ=12.061045, numObservations: 9
action 5, numVisits=13, meanQ=4.923862, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 8366 episodes
GETTING ACTION FROM:
action 3, numVisits=12169, meanQ=11.556389, numObservations: 9
action 5, numVisits=14, meanQ=4.073593, numObservations: 7
action 1, numVisits=6, meanQ=2.398892, numObservations: 4
action -1, numVisits=6, meanQ=-1.175000, numObservations: 6
action 0, numVisits=6, meanQ=-1.175000, numObservations: 6
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=75, meanQ=-5.367690, numObservations: 9
action: 3
Next state: 2 0.814221 0.722211 0.156971 0.0784689 0.75066 0.197495 0.0414481 0.487464 0.530168 0.521895 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 42
Initial state: 0 0.480975 0.537066 0.422481 0.249908 0.814211 0.655766 0.409767 0.257609 0.423441 0.576205 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28635 episodes
GETTING ACTION FROM:
action 3, numVisits=28628, meanQ=11.110242, numObservations: 9
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.480975 0.537066 0.422481 0.249908 0.814211 0.655766 0.409767 0.257609 0.423441 0.576205 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 43
Initial state: 0 0.278689 0.785962 0.314309 0.0819197 0.698096 0.961963 0.922444 0.915318 0.606999 0.51516 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28402 episodes
GETTING ACTION FROM:
action 1, numVisits=28389, meanQ=10.797471, numObservations: 9
action 3, numVisits=5, meanQ=4.400000, numObservations: 4
action 4, numVisits=4, meanQ=3.495000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.278689 0.785962 0.314309 0.0819197 0.698096 0.961963 0.922444 0.915318 0.606999 0.51516 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=3642, meanQ=11.858729, numObservations: 9
action 2, numVisits=6, meanQ=4.661667, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 8917 episodes
GETTING ACTION FROM:
action 3, numVisits=12548, meanQ=13.879916, numObservations: 9
action 2, numVisits=11, meanQ=4.024579, numObservations: 7
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=4, meanQ=-266.424752, numObservations: 3
action: 3
Next state: 1 0.278689 0.785962 0.314309 0.0819197 0.698096 0.961963 0.922444 0.915318 0.606999 0.51516 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 44
Initial state: 0 0.429672 0.606596 0.719054 0.568677 0.84478 0.0561942 0.474281 0.537373 0.281007 0.367972 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28430 episodes
GETTING ACTION FROM:
action 1, numVisits=28424, meanQ=10.732262, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.429672 0.606596 0.719054 0.568677 0.84478 0.0561942 0.474281 0.537373 0.281007 0.367972 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=999, meanQ=11.364040, numObservations: 9
action 4, numVisits=12, meanQ=6.246667, numObservations: 7
action 2, numVisits=6, meanQ=4.661667, numObservations: 6
action 5, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 7977 episodes
GETTING ACTION FROM:
action 3, numVisits=8900, meanQ=11.239664, numObservations: 9
action 4, numVisits=13, meanQ=4.920000, numObservations: 7
action 5, numVisits=10, meanQ=3.021000, numObservations: 4
action 2, numVisits=7, meanQ=2.424286, numObservations: 7
action -1, numVisits=41, meanQ=-1.541702, numObservations: 34
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=28, meanQ=-38.719740, numObservations: 24
action: 3
Next state: 2 0.429672 0.606596 0.719054 0.568677 0.84478 0.0561942 0.474281 0.537373 0.281007 0.367972 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 45
Initial state: 0 0.239518 0.406152 0.959458 0.478168 0.843757 0.0921176 0.755277 0.138988 0.606277 0.397107 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28320 episodes
GETTING ACTION FROM:
action 4, numVisits=28297, meanQ=10.994475, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=7, meanQ=-1.010000, numObservations: 7
action 2, numVisits=6, meanQ=-2.833333, numObservations: 5
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.239518 0.406152 0.959458 0.478168 0.843757 0.0921176 0.755277 0.138988 0.606277 0.397107 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 46
Initial state: 0 0.246522 0.507775 0.853386 0.672536 0.49528 0.475623 0.319005 0.283791 0.208033 0.846826 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28207 episodes
GETTING ACTION FROM:
action 2, numVisits=28198, meanQ=11.085029, numObservations: 9
action 4, numVisits=4, meanQ=2.502525, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.246522 0.507775 0.853386 0.672536 0.49528 0.475623 0.319005 0.283791 0.208033 0.846826 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 47
Initial state: 0 0.479415 0.449576 0.623736 0.603532 0.962379 0.555625 0.292896 0.124938 0.797372 0.258222 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28728 episodes
GETTING ACTION FROM:
action 4, numVisits=28680, meanQ=10.834434, numObservations: 9
action 1, numVisits=41, meanQ=9.397327, numObservations: 9
action 3, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 0 0.479415 0.449576 0.623736 0.603532 0.962379 0.555625 0.292896 0.124938 0.797372 0.258222 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=3767, meanQ=11.955757, numObservations: 9
action 3, numVisits=5, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 8043 episodes
GETTING ACTION FROM:
action 2, numVisits=11806, meanQ=11.653265, numObservations: 9
action 3, numVisits=5, meanQ=3.000000, numObservations: 3
action -1, numVisits=3, meanQ=-1.340000, numObservations: 3
action 0, numVisits=3, meanQ=-1.340000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.479415 0.449576 0.623736 0.603532 0.962379 0.555625 0.292896 0.124938 0.797372 0.258222 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 48
Initial state: 0 0.740482 0.827798 0.206657 0.710939 0.524631 0.453413 0.968089 0.231452 0.791777 0.252295 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28450 episodes
GETTING ACTION FROM:
action 4, numVisits=28443, meanQ=11.056153, numObservations: 9
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 2 0.740482 0.827798 0.206657 0.710939 0.524631 0.453413 0.968089 0.231452 0.791777 0.252295 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 49
Initial state: 0 0.138324 0.751788 0.870217 0.356202 0.844703 0.711522 0.714129 0.77763 0.614015 0.483913 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28049 episodes
GETTING ACTION FROM:
action 5, numVisits=28039, meanQ=10.922796, numObservations: 9
action 2, numVisits=3, meanQ=3.000000, numObservations: 3
action 3, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.138324 0.751788 0.870217 0.356202 0.844703 0.711522 0.714129 0.77763 0.614015 0.483913 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 50
Initial state: 0 0.974256 0.777321 0.419867 0.736994 0.603309 0.415875 0.00200535 0.799865 0.166981 0.29131 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28749 episodes
GETTING ACTION FROM:
action 4, numVisits=28731, meanQ=11.065423, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=7, meanQ=-1.010000, numObservations: 7
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.974256 0.777321 0.419867 0.736994 0.603309 0.415875 0.00200535 0.799865 0.166981 0.29131 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
[32m ProblemEnvironment.hpp 351: Done.[39m
