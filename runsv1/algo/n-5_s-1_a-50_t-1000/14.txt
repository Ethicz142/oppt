Run # 1
Initial state: 0 0.225211 0.548995 0.54334 0.951492 0.137646 0.748165 0.823917 0.228349 0.384305 0.651969 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30030 episodes
GETTING ACTION FROM:
action 4, numVisits=30021, meanQ=6.750454, numObservations: 9
action 1, numVisits=4, meanQ=1.000025, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.225211 0.548995 0.54334 0.951492 0.137646 0.748165 0.823917 0.228349 0.384305 0.651969 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 2
Initial state: 0 0.874091 0.793592 0.722406 0.809997 0.394257 0.594983 0.984987 0.586568 0.306514 0.999525 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30830 episodes
GETTING ACTION FROM:
action 1, numVisits=29708, meanQ=7.151244, numObservations: 9
action 3, numVisits=1117, meanQ=6.941319, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.874091 0.793592 0.722406 0.809997 0.394257 0.594983 0.984987 0.586568 0.306514 0.999525 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 3
Initial state: 0 0.451479 0.577862 0.250509 0.340843 0.0487223 0.13749 0.280823 0.0621822 0.147624 0.421812 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30563 episodes
GETTING ACTION FROM:
action 5, numVisits=30535, meanQ=6.877302, numObservations: 9
action 2, numVisits=21, meanQ=5.332862, numObservations: 9
action 1, numVisits=3, meanQ=1.703333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.451479 0.577862 0.250509 0.340843 0.0487223 0.13749 0.280823 0.0621822 0.147624 0.421812 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 4
Initial state: 0 0.573859 0.182874 0.230567 0.775909 0.265554 0.678042 0.946759 0.509432 0.500301 0.542566 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30612 episodes
GETTING ACTION FROM:
action 5, numVisits=30591, meanQ=6.988020, numObservations: 9
action 4, numVisits=13, meanQ=2.613846, numObservations: 7
action 2, numVisits=4, meanQ=-0.252500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.573859 0.182874 0.230567 0.775909 0.265554 0.678042 0.946759 0.509432 0.500301 0.542566 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 5
Initial state: 0 0.481715 0.572042 0.958904 0.793436 0.772702 0.44378 0.612806 0.484924 0.466576 0.306582 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30745 episodes
GETTING ACTION FROM:
action 1, numVisits=30739, meanQ=6.982843, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.481715 0.572042 0.958904 0.793436 0.772702 0.44378 0.612806 0.484924 0.466576 0.306582 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 6
Initial state: 0 0.876263 0.0505653 0.44032 0.704231 0.0974319 0.42547 0.211328 0.0753945 0.193948 0.797502 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30570 episodes
GETTING ACTION FROM:
action 3, numVisits=30527, meanQ=7.052415, numObservations: 9
action -1, numVisits=14, meanQ=-1.152136, numObservations: 13
action 0, numVisits=16, meanQ=-1.752500, numObservations: 15
action 4, numVisits=10, meanQ=-2.289990, numObservations: 5
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.876263 0.0505653 0.44032 0.704231 0.0974319 0.42547 0.211328 0.0753945 0.193948 0.797502 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=4064, meanQ=7.610610, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 8821 episodes
GETTING ACTION FROM:
action 4, numVisits=12847, meanQ=7.368255, numObservations: 9
action -1, numVisits=23, meanQ=-1.182174, numObservations: 23
action 0, numVisits=15, meanQ=-2.021455, numObservations: 13
action 5, numVisits=2, meanQ=-7.005000, numObservations: 2
action 3, numVisits=2, meanQ=-10.721227, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.876263 0.0505653 0.44032 0.704231 0.0974319 0.42547 0.211328 0.0753945 0.193948 0.797502 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=1416, meanQ=9.879342, numObservations: 9
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 6535 episodes
GETTING ACTION FROM:
action 2, numVisits=7492, meanQ=9.265629, numObservations: 9
action 1, numVisits=416, meanQ=3.505010, numObservations: 9
action 5, numVisits=8, meanQ=-1.575316, numObservations: 6
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=24, meanQ=-21.897446, numObservations: 20
action 0, numVisits=21, meanQ=-24.165497, numObservations: 17
action: 2
Next state: 1 0.876263 0.0505653 0.44032 0.704231 0.0974319 0.42547 0.211328 0.0753945 0.193948 0.797502 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 7
Initial state: 0 0.150299 0.518322 0.374647 0.628571 0.156562 0.187649 0.181401 0.452765 0.0021844 0.129891 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17800 episodes
GETTING ACTION FROM:
action -1, numVisits=17778, meanQ=12.242360, numObservations: 243
action 0, numVisits=13, meanQ=-1.010000, numObservations: 13
action 2, numVisits=2, meanQ=-7.500000, numObservations: 2
action 3, numVisits=2, meanQ=-7.500000, numObservations: 2
action 4, numVisits=2, meanQ=-7.500000, numObservations: 2
action 5, numVisits=2, meanQ=-7.500000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.150299 0.518322 0.374647 0.628571 0.156562 0.187649 0.181401 0.452765 0.0021844 0.129891 w: 1
Observation: 0 1 0 2 0 1 0 1 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=34, meanQ=22.352650, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 36588 episodes
GETTING ACTION FROM:
action 2, numVisits=36622, meanQ=19.901343, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.150299 0.518322 0.374647 0.628571 0.156562 0.187649 0.181401 0.452765 0.0021844 0.129891 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 8
Initial state: 0 0.144838 0.18668 0.664971 0.904321 0.914556 0.518678 0.480816 0.598973 0.997924 0.680724 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30645 episodes
GETTING ACTION FROM:
action 3, numVisits=30637, meanQ=6.809878, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.144838 0.18668 0.664971 0.904321 0.914556 0.518678 0.480816 0.598973 0.997924 0.680724 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 9
Initial state: 0 0.797724 0.884585 0.392223 0.657205 0.331556 0.174443 0.21813 0.95664 0.126075 0.049422 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30558 episodes
GETTING ACTION FROM:
action 4, numVisits=30552, meanQ=6.800460, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.797724 0.884585 0.392223 0.657205 0.331556 0.174443 0.21813 0.95664 0.126075 0.049422 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=148, meanQ=12.090216, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 21635 episodes
GETTING ACTION FROM:
action 4, numVisits=150, meanQ=12.151143, numObservations: 9
action 3, numVisits=21616, meanQ=10.368836, numObservations: 9
action 0, numVisits=11, meanQ=-1.550000, numObservations: 11
action -1, numVisits=9, meanQ=-1.780000, numObservations: 9
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.797724 0.884585 0.392223 0.657205 0.331556 0.174443 0.21813 0.95664 0.126075 0.049422 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=39, meanQ=13.454139, numObservations: 5
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action 2, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 20233 episodes
GETTING ACTION FROM:
action 4, numVisits=40, meanQ=13.156943, numObservations: 5
action 2, numVisits=20219, meanQ=12.371620, numObservations: 9
action 1, numVisits=9, meanQ=1.068663, numObservations: 6
action 0, numVisits=6, meanQ=-1.505000, numObservations: 6
action -1, numVisits=5, meanQ=-1.802000, numObservations: 5
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.797724 0.884585 0.392223 0.657205 0.331556 0.174443 0.21813 0.95664 0.126075 0.049422 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 10
Initial state: 0 0.419321 0.618096 0.063677 0.979942 0.811782 0.38043 0.844006 0.817508 0.859881 0.116754 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30760 episodes
GETTING ACTION FROM:
action 4, numVisits=30743, meanQ=6.769001, numObservations: 9
action -1, numVisits=9, meanQ=-1.010000, numObservations: 9
action 0, numVisits=4, meanQ=-3.980000, numObservations: 3
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.419321 0.618096 0.063677 0.979942 0.811782 0.38043 0.844006 0.817508 0.859881 0.116754 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 11
Initial state: 0 0.185062 0.905102 0.431033 0.368595 0.104906 0.964926 0.372254 0.550339 0.215428 0.929927 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30663 episodes
GETTING ACTION FROM:
action 1, numVisits=30654, meanQ=6.727286, numObservations: 9
action 3, numVisits=4, meanQ=1.000025, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.185062 0.905102 0.431033 0.368595 0.104906 0.964926 0.372254 0.550339 0.215428 0.929927 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 12
Initial state: 0 0.664322 0.659943 0.393401 0.65879 0.645404 0.821527 0.924222 0.434826 0.217538 0.973334 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30396 episodes
GETTING ACTION FROM:
action 3, numVisits=30385, meanQ=6.938240, numObservations: 9
action 2, numVisits=6, meanQ=3.165000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.664322 0.659943 0.393401 0.65879 0.645404 0.821527 0.924222 0.434826 0.217538 0.973334 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 13
Initial state: 0 0.17667 0.409827 0.668397 0.188091 0.977713 0.795186 0.3616 0.598328 0.744168 0.510226 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30733 episodes
GETTING ACTION FROM:
action 1, numVisits=30717, meanQ=6.890106, numObservations: 9
action 4, numVisits=9, meanQ=2.567778, numObservations: 4
action 5, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.17667 0.409827 0.668397 0.188091 0.977713 0.795186 0.3616 0.598328 0.744168 0.510226 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=3974, meanQ=8.374184, numObservations: 9
action 3, numVisits=3, meanQ=3.330000, numObservations: 3
action 4, numVisits=6, meanQ=3.330000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 9310 episodes
GETTING ACTION FROM:
action 2, numVisits=13263, meanQ=8.038143, numObservations: 9
action 4, numVisits=7, meanQ=1.433666, numObservations: 4
action 3, numVisits=5, meanQ=-0.728827, numObservations: 4
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=12, meanQ=-89.255629, numObservations: 11
action -1, numVisits=8, meanQ=-133.645934, numObservations: 7
action: 2
Next state: 2 0.17667 0.409827 0.668397 0.188091 0.977713 0.795186 0.3616 0.598328 0.744168 0.510226 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 14
Initial state: 0 0.798233 0.506485 0.991144 0.471058 0.372481 0.550968 0.683371 0.919886 0.963248 0.380386 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29998 episodes
GETTING ACTION FROM:
action 5, numVisits=29987, meanQ=7.138410, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 3, numVisits=2, meanQ=-4.000000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.798233 0.506485 0.991144 0.471058 0.372481 0.550968 0.683371 0.919886 0.963248 0.380386 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 15
Initial state: 0 0.46872 0.659414 0.190881 0.0584514 0.966777 0.23833 0.720333 0.0688886 0.0877713 0.0647291 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30295 episodes
GETTING ACTION FROM:
action 4, numVisits=30277, meanQ=6.795035, numObservations: 9
action 1, numVisits=9, meanQ=-0.002211, numObservations: 5
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.46872 0.659414 0.190881 0.0584514 0.966777 0.23833 0.720333 0.0688886 0.0877713 0.0647291 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 16
Initial state: 0 0.847062 0.388945 0.47194 0.645874 0.219758 0.345265 0.185175 0.129004 0.80738 0.806637 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30216 episodes
GETTING ACTION FROM:
action 2, numVisits=30133, meanQ=6.859609, numObservations: 9
action 3, numVisits=67, meanQ=5.319575, numObservations: 9
action 5, numVisits=10, meanQ=4.075000, numObservations: 6
action 4, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.847062 0.388945 0.47194 0.645874 0.219758 0.345265 0.185175 0.129004 0.80738 0.806637 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 17
Initial state: 0 0.735221 0.230604 0.461739 0.696489 0.822721 0.671682 0.617851 0.839025 0.735766 0.764055 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30793 episodes
GETTING ACTION FROM:
action 4, numVisits=30777, meanQ=6.861473, numObservations: 9
action 2, numVisits=9, meanQ=2.222222, numObservations: 7
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.735221 0.230604 0.461739 0.696489 0.822721 0.671682 0.617851 0.839025 0.735766 0.764055 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 18
Initial state: 0 0.509082 0.676669 0.803298 0.683241 0.680379 0.814412 0.072492 0.962272 0.730498 0.608239 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30847 episodes
GETTING ACTION FROM:
action 1, numVisits=30802, meanQ=6.902622, numObservations: 9
action 0, numVisits=18, meanQ=-1.010000, numObservations: 18
action -1, numVisits=18, meanQ=-1.230550, numObservations: 17
action 3, numVisits=6, meanQ=-3.316667, numObservations: 4
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.509082 0.676669 0.803298 0.683241 0.680379 0.814412 0.072492 0.962272 0.730498 0.608239 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 19
Initial state: 0 0.874903 0.990834 0.474181 0.000682352 0.0206371 0.0487835 0.381179 0.639276 0.212691 0.199095 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30548 episodes
GETTING ACTION FROM:
action 2, numVisits=30537, meanQ=6.787260, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=2, meanQ=-7.500000, numObservations: 2
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.874903 0.990834 0.474181 0.000682352 0.0206371 0.0487835 0.381179 0.639276 0.212691 0.199095 w: 1
Observation: 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 20
Initial state: 0 0.530477 0.0503874 0.718182 0.727798 0.0451207 0.883911 0.369612 0.625219 0.535597 0.33951 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30588 episodes
GETTING ACTION FROM:
action 1, numVisits=30570, meanQ=6.890671, numObservations: 9
action 4, numVisits=8, meanQ=0.092500, numObservations: 5
action 3, numVisits=4, meanQ=-0.252500, numObservations: 3
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.530477 0.0503874 0.718182 0.727798 0.0451207 0.883911 0.369612 0.625219 0.535597 0.33951 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 21
Initial state: 0 0.267441 0.674883 0.601758 0.334589 0.953413 0.527412 0.743799 0.0117289 0.40646 0.577093 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29760 episodes
GETTING ACTION FROM:
action 3, numVisits=29754, meanQ=6.672122, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.267441 0.674883 0.601758 0.334589 0.953413 0.527412 0.743799 0.0117289 0.40646 0.577093 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 22
Initial state: 0 0.792521 0.75416 0.0690999 0.741827 0.584942 0.276181 0.469569 0.661517 0.318349 0.514194 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30817 episodes
GETTING ACTION FROM:
action 3, numVisits=30806, meanQ=6.874937, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 2, numVisits=2, meanQ=-4.000000, numObservations: 2
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.792521 0.75416 0.0690999 0.741827 0.584942 0.276181 0.469569 0.661517 0.318349 0.514194 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=930, meanQ=7.446649, numObservations: 9
action 2, numVisits=8, meanQ=3.636250, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 26526 episodes
GETTING ACTION FROM:
action 4, numVisits=27111, meanQ=4.337491, numObservations: 9
action 2, numVisits=13, meanQ=0.699231, numObservations: 5
action 5, numVisits=13, meanQ=0.084615, numObservations: 5
action -1, numVisits=223, meanQ=-1.818115, numObservations: 95
action 0, numVisits=106, meanQ=-1.981321, numObservations: 61
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.792521 0.75416 0.0690999 0.741827 0.584942 0.276181 0.469569 0.661517 0.318349 0.514194 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 0, numVisits=21, meanQ=3.778752, numObservations: 14
action 4, numVisits=67, meanQ=1.253565, numObservations: 8
action -1, numVisits=4, meanQ=-1.507475, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 40310 episodes
GETTING ACTION FROM:
action 1, numVisits=40273, meanQ=9.800488, numObservations: 9
action 4, numVisits=67, meanQ=1.253565, numObservations: 8
action 0, numVisits=56, meanQ=0.184710, numObservations: 34
action -1, numVisits=6, meanQ=-1.671650, numObservations: 4
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.792521 0.75416 0.0690999 0.741827 0.584942 0.276181 0.469569 0.661517 0.318349 0.514194 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 23
Initial state: 0 0.300566 0.827019 0.830535 0.111495 0.465361 0.898506 0.817107 0.785277 0.34326 0.652653 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30660 episodes
GETTING ACTION FROM:
action 2, numVisits=30626, meanQ=6.629944, numObservations: 9
action 1, numVisits=27, meanQ=3.546674, numObservations: 8
action 4, numVisits=3, meanQ=1.703333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 2 0.300566 0.827019 0.830535 0.111495 0.465361 0.898506 0.817107 0.785277 0.34326 0.652653 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 24
Initial state: 0 0.577471 0.366908 0.79151 0.790165 0.980634 0.941823 0.48176 0.721171 0.57673 0.777444 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30975 episodes
GETTING ACTION FROM:
action 1, numVisits=28720, meanQ=6.832902, numObservations: 9
action 3, numVisits=2250, meanQ=6.717852, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.577471 0.366908 0.79151 0.790165 0.980634 0.941823 0.48176 0.721171 0.57673 0.777444 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 25
Initial state: 0 0.456006 0.642198 0.718662 0.425108 0.0481442 0.290663 0.0281099 0.026755 0.0759845 0.470258 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30580 episodes
GETTING ACTION FROM:
action 3, numVisits=30445, meanQ=6.750258, numObservations: 9
action 1, numVisits=114, meanQ=6.099413, numObservations: 9
action 5, numVisits=10, meanQ=4.598000, numObservations: 6
action 4, numVisits=3, meanQ=3.000000, numObservations: 3
action 2, numVisits=6, meanQ=1.350000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 2 0.456006 0.642198 0.718662 0.425108 0.0481442 0.290663 0.0281099 0.026755 0.0759845 0.470258 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 26
Initial state: 0 0.586151 0.904275 0.00834848 0.875994 0.656186 0.476339 0.465279 0.67088 0.0866607 0.18462 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30121 episodes
GETTING ACTION FROM:
action 3, numVisits=30115, meanQ=6.786182, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.586151 0.904275 0.00834848 0.875994 0.656186 0.476339 0.465279 0.67088 0.0866607 0.18462 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 27
Initial state: 0 0.907331 0.793215 0.781181 0.705 0.717483 0.00276204 0.0550937 0.986644 0.374348 0.625878 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30687 episodes
GETTING ACTION FROM:
action 4, numVisits=30652, meanQ=6.907458, numObservations: 9
action 2, numVisits=25, meanQ=3.281216, numObservations: 6
action 1, numVisits=6, meanQ=1.833333, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.907331 0.793215 0.781181 0.705 0.717483 0.00276204 0.0550937 0.986644 0.374348 0.625878 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=1660, meanQ=8.244372, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 11620 episodes
GETTING ACTION FROM:
action 5, numVisits=13268, meanQ=8.454737, numObservations: 9
action 0, numVisits=6, meanQ=-1.505000, numObservations: 5
action -1, numVisits=5, meanQ=-1.604000, numObservations: 5
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=3, meanQ=-232.517983, numObservations: 2
action: 5
Next state: 1 0.907331 0.793215 0.781181 0.705 0.717483 0.00276204 0.0550937 0.986644 0.374348 0.625878 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 28
Initial state: 0 0.557399 0.475392 0.469526 0.644281 0.328356 0.286932 0.916849 0.381283 0.955935 0.571795 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30432 episodes
GETTING ACTION FROM:
action 5, numVisits=30414, meanQ=6.828876, numObservations: 9
action -1, numVisits=6, meanQ=-1.010000, numObservations: 6
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 1, numVisits=2, meanQ=-4.000000, numObservations: 2
action 2, numVisits=2, meanQ=-4.000000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.557399 0.475392 0.469526 0.644281 0.328356 0.286932 0.916849 0.381283 0.955935 0.571795 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 29
Initial state: 0 0.761569 0.148448 0.878852 0.0109896 0.303397 0.738608 0.730298 0.136121 0.33353 0.603108 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30436 episodes
GETTING ACTION FROM:
action 5, numVisits=30403, meanQ=6.925897, numObservations: 9
action 4, numVisits=19, meanQ=3.527379, numObservations: 8
action 2, numVisits=7, meanQ=1.574300, numObservations: 4
action 1, numVisits=4, meanQ=1.497500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 1 0.761569 0.148448 0.878852 0.0109896 0.303397 0.738608 0.730298 0.136121 0.33353 0.603108 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 30
Initial state: 0 0.499473 0.110419 0.886694 0.0961301 0.73134 0.776079 0.902241 0.216295 0.435405 0.667128 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30479 episodes
GETTING ACTION FROM:
action 2, numVisits=30468, meanQ=6.745691, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 1, numVisits=2, meanQ=-4.000000, numObservations: 2
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.499473 0.110419 0.886694 0.0961301 0.73134 0.776079 0.902241 0.216295 0.435405 0.667128 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 31
Initial state: 0 0.233213 0.493036 0.9465 0.592753 0.683016 0.40071 0.346878 0.548449 0.57392 0.333237 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30627 episodes
GETTING ACTION FROM:
action 5, numVisits=30614, meanQ=6.917737, numObservations: 9
action 1, numVisits=6, meanQ=1.998333, numObservations: 4
action 3, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.233213 0.493036 0.9465 0.592753 0.683016 0.40071 0.346878 0.548449 0.57392 0.333237 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 32
Initial state: 0 0.321879 0.891748 0.325058 0.378839 0.613394 0.781548 0.175877 0.174207 0.404083 0.587242 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30002 episodes
GETTING ACTION FROM:
action 5, numVisits=29945, meanQ=7.069767, numObservations: 9
action 0, numVisits=44, meanQ=-0.762500, numObservations: 42
action 4, numVisits=4, meanQ=-2.250000, numObservations: 3
action 2, numVisits=2, meanQ=-3.505000, numObservations: 2
action -1, numVisits=4, meanQ=-3.980000, numObservations: 3
action 1, numVisits=2, meanQ=-7.500000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.321879 0.891748 0.325058 0.378839 0.613394 0.781548 0.175877 0.174207 0.404083 0.587242 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 33
Initial state: 0 0.909184 0.49153 0.383776 0.721401 0.786285 0.847543 0.41205 0.805019 0.778361 0.335484 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30678 episodes
GETTING ACTION FROM:
action 1, numVisits=30650, meanQ=6.854551, numObservations: 9
action -1, numVisits=12, meanQ=-1.010000, numObservations: 12
action 0, numVisits=12, meanQ=-1.010000, numObservations: 12
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.909184 0.49153 0.383776 0.721401 0.786285 0.847543 0.41205 0.805019 0.778361 0.335484 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 34
Initial state: 0 0.694488 0.508915 0.569158 0.755961 0.353474 0.586889 0.220337 0.413339 0.107736 0.48222 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30760 episodes
GETTING ACTION FROM:
action 1, numVisits=30754, meanQ=6.939008, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.694488 0.508915 0.569158 0.755961 0.353474 0.586889 0.220337 0.413339 0.107736 0.48222 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 35
Initial state: 0 0.621971 0.0255087 0.0959905 0.322761 0.956591 0.414871 0.42048 0.611599 0.97863 0.994537 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28400 episodes
GETTING ACTION FROM:
action 3, numVisits=28394, meanQ=6.811374, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.621971 0.0255087 0.0959905 0.322761 0.956591 0.414871 0.42048 0.611599 0.97863 0.994537 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 36
Initial state: 0 0.660789 0.470853 0.197133 0.927525 0.362655 0.577768 0.899205 0.18379 0.414658 0.354587 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17743 episodes
GETTING ACTION FROM:
action -1, numVisits=17711, meanQ=12.654733, numObservations: 243
action 0, numVisits=23, meanQ=-1.699126, numObservations: 21
action 3, numVisits=2, meanQ=-5.489950, numObservations: 1
action 1, numVisits=2, meanQ=-7.500000, numObservations: 2
action 2, numVisits=2, meanQ=-7.500000, numObservations: 2
action 5, numVisits=2, meanQ=-7.500000, numObservations: 2
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.660789 0.470853 0.197133 0.927525 0.362655 0.577768 0.899205 0.18379 0.414658 0.354587 w: 1
Observation: 0 3 0 1 0 2 0 3 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=54, meanQ=9.997972, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 33287 episodes
GETTING ACTION FROM:
action 5, numVisits=33341, meanQ=11.281093, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.660789 0.470853 0.197133 0.927525 0.362655 0.577768 0.899205 0.18379 0.414658 0.354587 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 37
Initial state: 0 0.667073 0.971119 0.333021 0.648709 0.62753 0.49506 0.993972 0.888504 0.692144 0.671572 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30634 episodes
GETTING ACTION FROM:
action 1, numVisits=27418, meanQ=6.989394, numObservations: 9
action 3, numVisits=3206, meanQ=6.179109, numObservations: 9
action 2, numVisits=6, meanQ=1.185000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.667073 0.971119 0.333021 0.648709 0.62753 0.49506 0.993972 0.888504 0.692144 0.671572 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 38
Initial state: 0 0.455911 0.583762 0.974557 0.49302 0.643196 0.774399 0.0808561 0.313683 0.905801 0.0930358 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30664 episodes
GETTING ACTION FROM:
action 3, numVisits=30653, meanQ=7.172832, numObservations: 9
action 2, numVisits=6, meanQ=1.185000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.455911 0.583762 0.974557 0.49302 0.643196 0.774399 0.0808561 0.313683 0.905801 0.0930358 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 39
Initial state: 0 0.794318 0.622227 0.597318 0.456938 0.241073 0.477763 0.0887649 0.897777 0.357917 0.612674 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28326 episodes
GETTING ACTION FROM:
action 4, numVisits=28277, meanQ=6.832223, numObservations: 9
action 2, numVisits=31, meanQ=0.999381, numObservations: 8
action 3, numVisits=7, meanQ=0.000000, numObservations: 3
action 1, numVisits=4, meanQ=-0.500000, numObservations: 3
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 1 0.794318 0.622227 0.597318 0.456938 0.241073 0.477763 0.0887649 0.897777 0.357917 0.612674 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 40
Initial state: 0 0.987136 0.242843 0.917345 0.250885 0.855781 0.97956 0.457824 0.196804 0.461087 0.587665 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30577 episodes
GETTING ACTION FROM:
action 2, numVisits=30571, meanQ=6.698527, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.987136 0.242843 0.917345 0.250885 0.855781 0.97956 0.457824 0.196804 0.461087 0.587665 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 41
Initial state: 0 0.0761903 0.261272 0.473863 0.66498 0.779138 0.0388136 0.208238 0.953063 0.716892 0.205533 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30847 episodes
GETTING ACTION FROM:
action 5, numVisits=30838, meanQ=7.247836, numObservations: 9
action 4, numVisits=4, meanQ=1.497500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.0761903 0.261272 0.473863 0.66498 0.779138 0.0388136 0.208238 0.953063 0.716892 0.205533 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 42
Initial state: 0 0.491432 0.611199 0.319452 0.648378 0.14125 0.572958 0.551639 0.458055 0.642333 0.221798 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30662 episodes
GETTING ACTION FROM:
action 1, numVisits=30636, meanQ=6.765524, numObservations: 9
action 3, numVisits=14, meanQ=4.787150, numObservations: 7
action 5, numVisits=3, meanQ=3.000000, numObservations: 3
action 4, numVisits=6, meanQ=1.998333, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.491432 0.611199 0.319452 0.648378 0.14125 0.572958 0.551639 0.458055 0.642333 0.221798 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 43
Initial state: 0 0.320965 0.25054 0.655387 0.385238 0.416589 0.887486 0.0556074 0.73348 0.502899 0.602793 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30578 episodes
GETTING ACTION FROM:
action 3, numVisits=30564, meanQ=6.822671, numObservations: 9
action 1, numVisits=4, meanQ=-0.500000, numObservations: 4
action 4, numVisits=4, meanQ=-0.500000, numObservations: 4
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.320965 0.25054 0.655387 0.385238 0.416589 0.887486 0.0556074 0.73348 0.502899 0.602793 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 44
Initial state: 0 0.653265 0.231353 0.145302 0.471051 0.0113279 0.137608 0.831473 0.793047 0.490598 0.707915 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30765 episodes
GETTING ACTION FROM:
action 4, numVisits=30738, meanQ=7.055941, numObservations: 9
action 5, numVisits=12, meanQ=4.832500, numObservations: 5
action 3, numVisits=11, meanQ=4.728191, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 1 0.653265 0.231353 0.145302 0.471051 0.0113279 0.137608 0.831473 0.793047 0.490598 0.707915 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 45
Initial state: 0 0.573694 0.792018 0.0364723 0.959037 0.946893 0.073379 0.659706 0.425458 0.396567 0.708711 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30410 episodes
GETTING ACTION FROM:
action 3, numVisits=30359, meanQ=6.986568, numObservations: 9
action 5, numVisits=42, meanQ=3.351198, numObservations: 9
action 1, numVisits=5, meanQ=0.596000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.573694 0.792018 0.0364723 0.959037 0.946893 0.073379 0.659706 0.425458 0.396567 0.708711 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 46
Initial state: 0 0.721283 0.665905 0.450901 0.650066 0.956319 0.180559 0.515796 0.00543675 0.0706671 0.320097 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30518 episodes
GETTING ACTION FROM:
action 5, numVisits=30502, meanQ=6.755263, numObservations: 9
action 2, numVisits=8, meanQ=3.123750, numObservations: 5
action 4, numVisits=4, meanQ=0.505025, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.721283 0.665905 0.450901 0.650066 0.956319 0.180559 0.515796 0.00543675 0.0706671 0.320097 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=4048, meanQ=8.079359, numObservations: 9
action 4, numVisits=7, meanQ=5.727143, numObservations: 4
action 1, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 9215 episodes
GETTING ACTION FROM:
action 2, numVisits=11198, meanQ=7.137642, numObservations: 9
action 1, numVisits=2035, meanQ=6.729297, numObservations: 9
action 4, numVisits=19, meanQ=3.181074, numObservations: 5
action -1, numVisits=15, meanQ=-2.146663, numObservations: 14
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=8, meanQ=-132.990366, numObservations: 7
action: 2
Next state: 1 0.721283 0.665905 0.450901 0.650066 0.956319 0.180559 0.515796 0.00543675 0.0706671 0.320097 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 47
Initial state: 0 0.842326 0.92634 0.441643 0.56386 0.470396 0.0544333 0.501162 0.263933 0.910495 0.186514 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30773 episodes
GETTING ACTION FROM:
action 4, numVisits=30753, meanQ=6.905330, numObservations: 9
action 1, numVisits=13, meanQ=4.305385, numObservations: 7
action 3, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 2 0.842326 0.92634 0.441643 0.56386 0.470396 0.0544333 0.501162 0.263933 0.910495 0.186514 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 48
Initial state: 0 0.401698 0.101829 0.241204 0.347675 0.366131 0.641247 0.347835 0.799435 0.114798 0.506384 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30676 episodes
GETTING ACTION FROM:
action 1, numVisits=30662, meanQ=6.726376, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 3, numVisits=5, meanQ=-1.200000, numObservations: 4
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.401698 0.101829 0.241204 0.347675 0.366131 0.641247 0.347835 0.799435 0.114798 0.506384 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=985, meanQ=8.566467, numObservations: 9
action 2, numVisits=39, meanQ=7.694372, numObservations: 9
action 3, numVisits=7, meanQ=5.141429, numObservations: 3
action 4, numVisits=5, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 30461 episodes
GETTING ACTION FROM:
action 5, numVisits=30857, meanQ=5.216834, numObservations: 9
action 2, numVisits=374, meanQ=4.678037, numObservations: 9
action 4, numVisits=217, meanQ=4.492056, numObservations: 9
action 3, numVisits=10, meanQ=0.299000, numObservations: 4
action -1, numVisits=21, meanQ=-1.858571, numObservations: 17
action 0, numVisits=20, meanQ=-1.901000, numObservations: 16
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.401698 0.101829 0.241204 0.347675 0.366131 0.641247 0.347835 0.799435 0.114798 0.506384 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=444, meanQ=8.786486, numObservations: 9
action 4, numVisits=6, meanQ=1.998333, numObservations: 3
action -1, numVisits=5, meanQ=-1.010000, numObservations: 5
action 0, numVisits=5, meanQ=-1.010000, numObservations: 5
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 27166 episodes
GETTING ACTION FROM:
action 4, numVisits=26536, meanQ=7.636445, numObservations: 9
action 3, numVisits=1001, meanQ=4.889146, numObservations: 9
action -1, numVisits=58, meanQ=-1.419655, numObservations: 34
action 0, numVisits=30, meanQ=-1.703000, numObservations: 21
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 4
Next state: 1 0.401698 0.101829 0.241204 0.347675 0.366131 0.641247 0.347835 0.799435 0.114798 0.506384 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 49
Initial state: 0 0.772117 0.942975 0.414649 0.679264 0.774475 0.990718 0.770213 0.118334 0.652106 0.166134 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29982 episodes
GETTING ACTION FROM:
action 5, numVisits=29976, meanQ=6.868492, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.772117 0.942975 0.414649 0.679264 0.774475 0.990718 0.770213 0.118334 0.652106 0.166134 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 50
Initial state: 0 0.868078 0.027482 0.809487 0.247484 0.334357 0.54913 0.240533 0.834622 0.131177 0.40674 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30715 episodes
GETTING ACTION FROM:
action 1, numVisits=30701, meanQ=6.882631, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 2, numVisits=5, meanQ=-1.200000, numObservations: 5
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.868078 0.027482 0.809487 0.247484 0.334357 0.54913 0.240533 0.834622 0.131177 0.40674 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=972, meanQ=7.657872, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 28757 episodes
GETTING ACTION FROM:
action 4, numVisits=29656, meanQ=4.837971, numObservations: 9
action -1, numVisits=37, meanQ=-1.866216, numObservations: 34
action 0, numVisits=37, meanQ=-1.866216, numObservations: 31
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.868078 0.027482 0.809487 0.247484 0.334357 0.54913 0.240533 0.834622 0.131177 0.40674 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action -1, numVisits=77, meanQ=3.698087, numObservations: 40
action 3, numVisits=4, meanQ=-0.252500, numObservations: 3
action 0, numVisits=22, meanQ=-2.191485, numObservations: 18
action 4, numVisits=91, meanQ=-3.981506, numObservations: 8
action 2, numVisits=2, meanQ=-6.450102, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 12940 episodes
GETTING ACTION FROM:
action -1, numVisits=12843, meanQ=-1.055198, numObservations: 231
action 3, numVisits=10, meanQ=-3.201000, numObservations: 6
action 4, numVisits=91, meanQ=-3.981506, numObservations: 8
action 0, numVisits=189, meanQ=-4.697483, numObservations: 74
action 2, numVisits=3, meanQ=-7.966735, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.868078 0.027482 0.809487 0.247484 0.334357 0.54913 0.240533 0.834622 0.131177 0.40674 w: 1
Observation: 0 3 0 1 0 2 0 1 0 1 0 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=41, meanQ=21.369860, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-9.783776, numObservations: 1
action 2, numVisits=1, meanQ=-9.898306, numObservations: 1
action 4, numVisits=1, meanQ=-10.436662, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 33733 episodes
GETTING ACTION FROM:
action 3, numVisits=33774, meanQ=20.639963, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-9.783776, numObservations: 1
action 2, numVisits=1, meanQ=-9.898306, numObservations: 1
action 4, numVisits=1, meanQ=-10.436662, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.868078 0.027482 0.809487 0.247484 0.334357 0.54913 0.240533 0.834622 0.131177 0.40674 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 13.367
[32m ProblemEnvironment.hpp 351: Done.[39m
