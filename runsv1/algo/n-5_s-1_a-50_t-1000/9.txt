Run # 1
Initial state: 0 0.871298 0.94652 0.743905 0.73784 0.230074 0.572102 0.848533 0.842183 0.409604 0.501814 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31736 episodes
GETTING ACTION FROM:
action 3, numVisits=31725, meanQ=8.725567, numObservations: 9
action 1, numVisits=6, meanQ=3.000000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.871298 0.94652 0.743905 0.73784 0.230074 0.572102 0.848533 0.842183 0.409604 0.501814 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 2
Initial state: 0 0.326469 0.523254 0.69424 0.25171 0.854862 0.123019 0.774424 0.967668 0.722126 0.239562 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31693 episodes
GETTING ACTION FROM:
action 1, numVisits=31676, meanQ=9.051377, numObservations: 9
action 2, numVisits=6, meanQ=0.666667, numObservations: 5
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 5, numVisits=5, meanQ=-1.200000, numObservations: 4
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.326469 0.523254 0.69424 0.25171 0.854862 0.123019 0.774424 0.967668 0.722126 0.239562 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=449, meanQ=20.617601, numObservations: 9
action 2, numVisits=15, meanQ=12.866000, numObservations: 6
action 3, numVisits=4, meanQ=8.497500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 32804 episodes
GETTING ACTION FROM:
action 1, numVisits=527, meanQ=20.701137, numObservations: 9
action 2, numVisits=31959, meanQ=10.090059, numObservations: 9
action 3, numVisits=775, meanQ=7.859639, numObservations: 9
action 0, numVisits=7, meanQ=-1.717143, numObservations: 7
action -1, numVisits=6, meanQ=-1.835000, numObservations: 5
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.326469 0.523254 0.69424 0.25171 0.854862 0.123019 0.774424 0.967668 0.722126 0.239562 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 3
Initial state: 0 0.0392261 0.811856 0.991925 0.995032 0.384054 0.527759 0.245734 0.14483 0.197115 0.0725705 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31358 episodes
GETTING ACTION FROM:
action 5, numVisits=31346, meanQ=8.866465, numObservations: 9
action 1, numVisits=5, meanQ=4.400000, numObservations: 4
action 4, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 0 0.0392261 0.811856 0.991925 0.995032 0.384054 0.527759 0.245734 0.14483 0.197115 0.0725705 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=2937, meanQ=10.033447, numObservations: 9
action 1, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 11398 episodes
GETTING ACTION FROM:
action 4, numVisits=14228, meanQ=8.481399, numObservations: 9
action 3, numVisits=6, meanQ=2.177226, numObservations: 6
action -1, numVisits=8, meanQ=-2.350563, numObservations: 7
action 0, numVisits=10, meanQ=-2.396000, numObservations: 8
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=89, meanQ=-3.472369, numObservations: 9
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.0392261 0.811856 0.991925 0.995032 0.384054 0.527759 0.245734 0.14483 0.197115 0.0725705 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=237, meanQ=1.921745, numObservations: 9
action 2, numVisits=47, meanQ=-8.774173, numObservations: 9
action 4, numVisits=2, meanQ=-11.000000, numObservations: 2
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=25, meanQ=-43.646776, numObservations: 18
action -1, numVisits=11, meanQ=-95.297715, numObservations: 9
action 3, numVisits=10, meanQ=-108.064597, numObservations: 5
Sampled 21028 episodes
GETTING ACTION FROM:
action 1, numVisits=21265, meanQ=6.660308, numObservations: 9
action 2, numVisits=47, meanQ=-8.774173, numObservations: 9
action 4, numVisits=2, meanQ=-11.000000, numObservations: 2
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=25, meanQ=-43.646776, numObservations: 18
action -1, numVisits=11, meanQ=-95.297715, numObservations: 9
action 3, numVisits=10, meanQ=-108.064597, numObservations: 5
action: 1
Next state: 1 0.0392261 0.811856 0.991925 0.995032 0.384054 0.527759 0.245734 0.14483 0.197115 0.0725705 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 4
Initial state: 0 0.678723 0.738801 0.88699 0.781001 0.434715 0.502199 0.0432606 0.880517 0.997949 0.550883 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32339 episodes
GETTING ACTION FROM:
action 1, numVisits=32331, meanQ=8.829613, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.678723 0.738801 0.88699 0.781001 0.434715 0.502199 0.0432606 0.880517 0.997949 0.550883 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 5
Initial state: 0 0.00399706 0.565992 0.171668 0.0513979 0.999723 0.546823 0.895715 0.632322 0.410023 0.571745 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32338 episodes
GETTING ACTION FROM:
action 2, numVisits=32308, meanQ=8.684362, numObservations: 9
action 5, numVisits=22, meanQ=4.362727, numObservations: 7
action 3, numVisits=4, meanQ=-0.252500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.00399706 0.565992 0.171668 0.0513979 0.999723 0.546823 0.895715 0.632322 0.410023 0.571745 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 6
Initial state: 0 0.213716 0.0332378 0.412658 0.491918 0.499971 0.0444959 0.833622 0.0162987 0.263478 0.920171 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32409 episodes
GETTING ACTION FROM:
action 2, numVisits=32380, meanQ=8.904493, numObservations: 9
action 5, numVisits=16, meanQ=6.504375, numObservations: 8
action 3, numVisits=7, meanQ=6.000000, numObservations: 5
action 1, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.213716 0.0332378 0.412658 0.491918 0.499971 0.0444959 0.833622 0.0162987 0.263478 0.920171 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 7
Initial state: 0 0.0136566 0.362766 0.515102 0.90731 0.991657 0.0943277 0.784896 0.214045 0.419303 0.498003 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31110 episodes
GETTING ACTION FROM:
action 1, numVisits=31092, meanQ=8.970336, numObservations: 9
action 5, numVisits=11, meanQ=6.818182, numObservations: 5
action 3, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.0136566 0.362766 0.515102 0.90731 0.991657 0.0943277 0.784896 0.214045 0.419303 0.498003 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=2957, meanQ=9.538733, numObservations: 9
action 2, numVisits=25, meanQ=6.910808, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 11642 episodes
GETTING ACTION FROM:
action 5, numVisits=14576, meanQ=8.026287, numObservations: 9
action 2, numVisits=34, meanQ=5.331384, numObservations: 8
action -1, numVisits=8, meanQ=-1.257500, numObservations: 8
action 0, numVisits=7, meanQ=-2.707143, numObservations: 6
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=2, meanQ=-5.637068, numObservations: 2
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.0136566 0.362766 0.515102 0.90731 0.991657 0.0943277 0.784896 0.214045 0.419303 0.498003 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 8
Initial state: 0 0.060459 0.224702 0.0907671 0.638327 0.289849 0.00287161 0.440428 0.534954 0.810546 0.477023 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32360 episodes
GETTING ACTION FROM:
action 4, numVisits=32336, meanQ=8.566126, numObservations: 9
action 2, numVisits=10, meanQ=4.901010, numObservations: 8
action 3, numVisits=10, meanQ=4.598000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.060459 0.224702 0.0907671 0.638327 0.289849 0.00287161 0.440428 0.534954 0.810546 0.477023 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 9
Initial state: 0 0.0511816 0.730457 0.432484 0.569084 0.206094 0.322726 0.167532 0.458564 0.140589 0.361947 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32336 episodes
GETTING ACTION FROM:
action 2, numVisits=32325, meanQ=8.912935, numObservations: 9
action 1, numVisits=6, meanQ=3.000000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.0511816 0.730457 0.432484 0.569084 0.206094 0.322726 0.167532 0.458564 0.140589 0.361947 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=458, meanQ=20.380601, numObservations: 9
action 3, numVisits=7, meanQ=4.000000, numObservations: 4
action 5, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 30803 episodes
GETTING ACTION FROM:
action 2, numVisits=500, meanQ=20.676150, numObservations: 9
action 5, numVisits=30751, meanQ=9.798440, numObservations: 9
action 3, numVisits=8, meanQ=2.125000, numObservations: 4
action -1, numVisits=7, meanQ=-1.717143, numObservations: 7
action 0, numVisits=6, meanQ=-1.835000, numObservations: 6
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 2
Next state: 1 0.0511816 0.730457 0.432484 0.569084 0.206094 0.322726 0.167532 0.458564 0.140589 0.361947 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 10
Initial state: 0 0.432049 0.526424 0.318348 0.680264 0.954969 0.0610737 0.936452 0.96059 0.0141182 0.988546 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32535 episodes
GETTING ACTION FROM:
action 5, numVisits=32514, meanQ=8.691157, numObservations: 9
action 2, numVisits=10, meanQ=1.098000, numObservations: 6
action 4, numVisits=7, meanQ=0.141429, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.432049 0.526424 0.318348 0.680264 0.954969 0.0610737 0.936452 0.96059 0.0141182 0.988546 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 11
Initial state: 0 0.425163 0.504238 0.664797 0.357494 0.190522 0.159846 0.252976 0.676915 0.852603 0.0297231 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32544 episodes
GETTING ACTION FROM:
action 2, numVisits=32529, meanQ=8.669694, numObservations: 9
action 4, numVisits=10, meanQ=5.100000, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.425163 0.504238 0.664797 0.357494 0.190522 0.159846 0.252976 0.676915 0.852603 0.0297231 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 12
Initial state: 0 0.186163 0.321831 0.453881 0.334749 0.958285 0.601957 0.50698 0.909588 0.418265 0.495051 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31597 episodes
GETTING ACTION FROM:
action 2, numVisits=31571, meanQ=8.687671, numObservations: 9
action 4, numVisits=12, meanQ=4.750000, numObservations: 7
action 5, numVisits=10, meanQ=4.102010, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 2 0.186163 0.321831 0.453881 0.334749 0.958285 0.601957 0.50698 0.909588 0.418265 0.495051 w: 1
Observation: 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 13
Initial state: 0 0.290248 0.609946 0.993501 0.396306 0.462156 0.792704 0.855568 0.727804 0.866643 0.95234 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32078 episodes
GETTING ACTION FROM:
action 3, numVisits=32063, meanQ=8.633867, numObservations: 9
action 5, numVisits=5, meanQ=3.820000, numObservations: 3
action 1, numVisits=6, meanQ=3.165000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.290248 0.609946 0.993501 0.396306 0.462156 0.792704 0.855568 0.727804 0.866643 0.95234 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 14
Initial state: 0 0.0130033 0.0726843 0.758455 0.457639 0.368974 0.548195 0.458125 0.522801 0.789392 0.25322 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32224 episodes
GETTING ACTION FROM:
action 5, numVisits=32200, meanQ=8.680326, numObservations: 9
action 1, numVisits=17, meanQ=6.410588, numObservations: 8
action 4, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.0130033 0.0726843 0.758455 0.457639 0.368974 0.548195 0.458125 0.522801 0.789392 0.25322 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 15
Initial state: 0 0.755284 0.143573 0.420255 0.607905 0.113365 0.217788 0.792529 0.446517 0.0320675 0.884689 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32283 episodes
GETTING ACTION FROM:
action 5, numVisits=32274, meanQ=8.735720, numObservations: 9
action 1, numVisits=4, meanQ=1.250000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 1 0.755284 0.143573 0.420255 0.607905 0.113365 0.217788 0.792529 0.446517 0.0320675 0.884689 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 16
Initial state: 0 0.629169 0.80273 0.753689 0.0895336 0.859164 0.200245 0.103047 0.893257 0.297987 0.588429 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30678 episodes
GETTING ACTION FROM:
action 4, numVisits=30642, meanQ=8.599305, numObservations: 9
action 5, numVisits=24, meanQ=6.004588, numObservations: 8
action 1, numVisits=8, meanQ=4.873750, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.629169 0.80273 0.753689 0.0895336 0.859164 0.200245 0.103047 0.893257 0.297987 0.588429 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 17
Initial state: 0 0.483159 0.229024 0.459615 0.0759793 0.748911 0.0973343 0.527416 0.661165 0.330948 0.603597 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31904 episodes
GETTING ACTION FROM:
action 2, numVisits=31885, meanQ=8.673871, numObservations: 9
action 1, numVisits=11, meanQ=1.727273, numObservations: 5
action 5, numVisits=4, meanQ=1.497500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 2 0.483159 0.229024 0.459615 0.0759793 0.748911 0.0973343 0.527416 0.661165 0.330948 0.603597 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 18
Initial state: 0 0.111305 0.140024 0.8299 0.861238 0.36268 0.529759 0.358605 0.397354 0.100682 0.215278 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31721 episodes
GETTING ACTION FROM:
action 3, numVisits=31661, meanQ=8.636099, numObservations: 9
action 5, numVisits=55, meanQ=6.931093, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.111305 0.140024 0.8299 0.861238 0.36268 0.529759 0.358605 0.397354 0.100682 0.215278 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 19
Initial state: 0 0.687567 0.830418 0.124786 0.00614336 0.163424 0.557103 0.49793 0.15069 0.366303 0.496204 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32438 episodes
GETTING ACTION FROM:
action 3, numVisits=32406, meanQ=8.859806, numObservations: 9
action 5, numVisits=21, meanQ=3.001448, numObservations: 8
action 2, numVisits=7, meanQ=1.585714, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.687567 0.830418 0.124786 0.00614336 0.163424 0.557103 0.49793 0.15069 0.366303 0.496204 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=683, meanQ=6.450169, numObservations: 9
action 2, numVisits=20, meanQ=5.286510, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 13061 episodes
GETTING ACTION FROM:
action 2, numVisits=12855, meanQ=7.995073, numObservations: 9
action 3, numVisits=683, meanQ=6.450169, numObservations: 9
action 4, numVisits=77, meanQ=-6.198977, numObservations: 9
action 5, numVisits=2, meanQ=-7.005000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=85, meanQ=-13.903948, numObservations: 69
action -1, numVisits=66, meanQ=-17.186442, numObservations: 49
action: 2
Next state: 0 0.687567 0.830418 0.124786 0.00614336 0.163424 0.557103 0.49793 0.15069 0.366303 0.496204 w: 1
Observation: 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=1, meanQ=24.000000, numObservations: 1
action 1, numVisits=36, meanQ=9.322998, numObservations: 9
action 5, numVisits=2, meanQ=-10.974963, numObservations: 2
action 2, numVisits=2, meanQ=-11.000000, numObservations: 2
action 4, numVisits=1, meanQ=-12.276865, numObservations: 1
action 0, numVisits=57, meanQ=-20.047322, numObservations: 47
action -1, numVisits=4, meanQ=-263.614354, numObservations: 3
Sampled 21230 episodes
GETTING ACTION FROM:
action 1, numVisits=21262, meanQ=5.041335, numObservations: 9
action 3, numVisits=5, meanQ=3.000000, numObservations: 4
action 5, numVisits=2, meanQ=-10.974963, numObservations: 2
action 2, numVisits=2, meanQ=-11.000000, numObservations: 2
action 4, numVisits=1, meanQ=-12.276865, numObservations: 1
action 0, numVisits=57, meanQ=-20.047322, numObservations: 47
action -1, numVisits=4, meanQ=-263.614354, numObservations: 3
action: 1
Next state: 1 0.687567 0.830418 0.124786 0.00614336 0.163424 0.557103 0.49793 0.15069 0.366303 0.496204 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 20
Initial state: 0 0.976632 0.735495 0.91984 0.140201 0.433597 0.558868 0.293023 0.344321 0.332494 0.357765 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32614 episodes
GETTING ACTION FROM:
action 5, numVisits=32592, meanQ=8.728271, numObservations: 9
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 3, numVisits=8, meanQ=-1.375000, numObservations: 4
action 1, numVisits=4, meanQ=-2.250000, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.976632 0.735495 0.91984 0.140201 0.433597 0.558868 0.293023 0.344321 0.332494 0.357765 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=504, meanQ=11.812975, numObservations: 9
action 2, numVisits=10, meanQ=8.098000, numObservations: 5
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 15920 episodes
GETTING ACTION FROM:
action 1, numVisits=16371, meanQ=8.137406, numObservations: 9
action 2, numVisits=14, meanQ=5.415683, numObservations: 6
action 3, numVisits=16, meanQ=5.129574, numObservations: 7
action 4, numVisits=4, meanQ=-0.550166, numObservations: 4
action -1, numVisits=18, meanQ=-1.670000, numObservations: 17
action 0, numVisits=16, meanQ=-1.752500, numObservations: 14
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.976632 0.735495 0.91984 0.140201 0.433597 0.558868 0.293023 0.344321 0.332494 0.357765 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 21
Initial state: 0 0.214685 0.744987 0.892589 0.642172 0.333361 0.466758 0.210685 0.754404 0.6989 0.0222612 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32354 episodes
GETTING ACTION FROM:
action 3, numVisits=32320, meanQ=8.730327, numObservations: 9
action 5, numVisits=11, meanQ=6.702727, numObservations: 6
action 4, numVisits=13, meanQ=6.383077, numObservations: 5
action 2, numVisits=7, meanQ=6.141429, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.214685 0.744987 0.892589 0.642172 0.333361 0.466758 0.210685 0.754404 0.6989 0.0222612 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 22
Initial state: 0 0.892923 0.565841 0.829189 0.600229 0.418781 0.595841 0.952197 0.100669 0.771017 0.0446436 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31541 episodes
GETTING ACTION FROM:
action 4, numVisits=31530, meanQ=8.729794, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=4, meanQ=-2.250000, numObservations: 4
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.892923 0.565841 0.829189 0.600229 0.418781 0.595841 0.952197 0.100669 0.771017 0.0446436 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 23
Initial state: 0 0.408067 0.557963 0.580491 0.117638 0.0667626 0.761036 0.239947 0.335842 0.537613 0.911678 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32683 episodes
GETTING ACTION FROM:
action 1, numVisits=32649, meanQ=8.730409, numObservations: 9
action 4, numVisits=16, meanQ=6.685006, numObservations: 6
action 2, numVisits=12, meanQ=5.415833, numObservations: 6
action 5, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.408067 0.557963 0.580491 0.117638 0.0667626 0.761036 0.239947 0.335842 0.537613 0.911678 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 24
Initial state: 0 0.0118296 0.38429 0.109031 0.682111 0.287957 0.117579 0.418523 0.48371 0.885627 0.903218 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32284 episodes
GETTING ACTION FROM:
action 4, numVisits=32255, meanQ=8.772048, numObservations: 9
action 3, numVisits=10, meanQ=3.000000, numObservations: 4
action 1, numVisits=12, meanQ=2.487500, numObservations: 6
action 2, numVisits=4, meanQ=-0.252500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.0118296 0.38429 0.109031 0.682111 0.287957 0.117579 0.418523 0.48371 0.885627 0.903218 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 25
Initial state: 0 0.525661 0.661145 0.37466 0.61148 0.0831616 0.914646 0.946637 0.512499 0.549379 0.418527 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32193 episodes
GETTING ACTION FROM:
action 4, numVisits=32101, meanQ=8.712777, numObservations: 9
action 5, numVisits=79, meanQ=7.668232, numObservations: 9
action 1, numVisits=9, meanQ=5.333333, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.525661 0.661145 0.37466 0.61148 0.0831616 0.914646 0.946637 0.512499 0.549379 0.418527 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 26
Initial state: 0 0.216309 0.200972 0.437133 0.473646 0.868866 0.423699 0.495709 0.845568 0.906668 0.280902 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32498 episodes
GETTING ACTION FROM:
action 1, numVisits=32490, meanQ=8.812987, numObservations: 9
action 2, numVisits=3, meanQ=4.340033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.216309 0.200972 0.437133 0.473646 0.868866 0.423699 0.495709 0.845568 0.906668 0.280902 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=3029, meanQ=10.247754, numObservations: 9
action 4, numVisits=21, meanQ=8.770481, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 11094 episodes
GETTING ACTION FROM:
action 3, numVisits=14093, meanQ=9.618128, numObservations: 9
action 4, numVisits=44, meanQ=7.714494, numObservations: 8
action -1, numVisits=5, meanQ=-1.208000, numObservations: 5
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=4, meanQ=-4.159801, numObservations: 3
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.216309 0.200972 0.437133 0.473646 0.868866 0.423699 0.495709 0.845568 0.906668 0.280902 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=245, meanQ=9.494943, numObservations: 9
action -1, numVisits=6, meanQ=-1.010000, numObservations: 6
action 0, numVisits=6, meanQ=-2.990000, numObservations: 5
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 22428 episodes
GETTING ACTION FROM:
action 2, numVisits=22653, meanQ=6.224004, numObservations: 9
action -1, numVisits=17, meanQ=-2.177860, numObservations: 14
action 0, numVisits=15, meanQ=-2.990000, numObservations: 13
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.216309 0.200972 0.437133 0.473646 0.868866 0.423699 0.495709 0.845568 0.906668 0.280902 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 27
Initial state: 0 0.374168 0.529046 0.250183 0.433269 0.892431 0.236746 0.883716 0.0191542 0.132014 0.879602 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32594 episodes
GETTING ACTION FROM:
action 2, numVisits=32576, meanQ=8.793653, numObservations: 9
action 3, numVisits=8, meanQ=3.468750, numObservations: 4
action 5, numVisits=6, meanQ=3.165000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.374168 0.529046 0.250183 0.433269 0.892431 0.236746 0.883716 0.0191542 0.132014 0.879602 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=3106, meanQ=10.977922, numObservations: 9
action 3, numVisits=9, meanQ=7.664467, numObservations: 6
action 5, numVisits=9, meanQ=6.777789, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 10857 episodes
GETTING ACTION FROM:
action 1, numVisits=13936, meanQ=10.262996, numObservations: 9
action 3, numVisits=27, meanQ=6.859267, numObservations: 8
action 5, numVisits=10, meanQ=5.000010, numObservations: 6
action 0, numVisits=5, meanQ=-1.208000, numObservations: 5
action -1, numVisits=5, meanQ=-1.208000, numObservations: 5
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.374168 0.529046 0.250183 0.433269 0.892431 0.236746 0.883716 0.0191542 0.132014 0.879602 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=51, meanQ=8.822159, numObservations: 8
action 3, numVisits=16, meanQ=7.030620, numObservations: 8
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 39356 episodes
GETTING ACTION FROM:
action 5, numVisits=39407, meanQ=13.913046, numObservations: 9
action 3, numVisits=16, meanQ=7.030620, numObservations: 8
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.374168 0.529046 0.250183 0.433269 0.892431 0.236746 0.883716 0.0191542 0.132014 0.879602 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 28
Initial state: 0 0.372311 0.508427 0.507002 0.123104 0.0975424 0.305763 0.727873 0.163107 0.571816 0.10729 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32502 episodes
GETTING ACTION FROM:
action 3, numVisits=32469, meanQ=8.717624, numObservations: 9
action 5, numVisits=10, meanQ=5.298000, numObservations: 7
action 4, numVisits=16, meanQ=5.249375, numObservations: 7
action 2, numVisits=4, meanQ=3.247500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.372311 0.508427 0.507002 0.123104 0.0975424 0.305763 0.727873 0.163107 0.571816 0.10729 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=985, meanQ=9.089162, numObservations: 9
action 1, numVisits=28, meanQ=7.575007, numObservations: 9
action 5, numVisits=19, meanQ=7.472637, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 33940 episodes
GETTING ACTION FROM:
action 1, numVisits=31850, meanQ=7.339992, numObservations: 9
action 2, numVisits=2929, meanQ=6.733252, numObservations: 9
action 5, numVisits=171, meanQ=5.224398, numObservations: 9
action 0, numVisits=12, meanQ=-1.835000, numObservations: 11
action -1, numVisits=11, meanQ=-1.910000, numObservations: 11
action 4, numVisits=2, meanQ=-7.005000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.372311 0.508427 0.507002 0.123104 0.0975424 0.305763 0.727873 0.163107 0.571816 0.10729 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 29
Initial state: 0 0.842543 0.733705 0.721894 0.484313 0.456307 0.620506 0.138921 0.271956 0.0356979 0.460197 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32541 episodes
GETTING ACTION FROM:
action 4, numVisits=32535, meanQ=8.744022, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.842543 0.733705 0.721894 0.484313 0.456307 0.620506 0.138921 0.271956 0.0356979 0.460197 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=1023, meanQ=10.635905, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 32652 episodes
GETTING ACTION FROM:
action 3, numVisits=33657, meanQ=6.956562, numObservations: 9
action -1, numVisits=10, meanQ=-1.802000, numObservations: 10
action 0, numVisits=10, meanQ=-1.802000, numObservations: 9
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.842543 0.733705 0.721894 0.484313 0.456307 0.620506 0.138921 0.271956 0.0356979 0.460197 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 30
Initial state: 0 0.33602 0.478337 0.723357 0.0190727 0.786393 0.68644 0.762063 0.631464 0.801578 0.979185 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32432 episodes
GETTING ACTION FROM:
action 4, numVisits=32406, meanQ=8.894203, numObservations: 9
action 1, numVisits=16, meanQ=3.373150, numObservations: 8
action 2, numVisits=6, meanQ=1.998333, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 1 0.33602 0.478337 0.723357 0.0190727 0.786393 0.68644 0.762063 0.631464 0.801578 0.979185 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 31
Initial state: 0 0.0114176 0.797624 0.384374 0.898031 0.34382 0.514523 0.866202 0.74022 0.642063 0.0664139 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32362 episodes
GETTING ACTION FROM:
action 1, numVisits=32333, meanQ=8.631225, numObservations: 9
action 5, numVisits=15, meanQ=4.065333, numObservations: 7
action 3, numVisits=10, meanQ=2.999010, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.0114176 0.797624 0.384374 0.898031 0.34382 0.514523 0.866202 0.74022 0.642063 0.0664139 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 32
Initial state: 0 0.648772 0.633557 0.957931 0.820693 0.973921 0.22643 0.632168 0.672044 0.332597 0.535607 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32173 episodes
GETTING ACTION FROM:
action 3, numVisits=32167, meanQ=8.643965, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.648772 0.633557 0.957931 0.820693 0.973921 0.22643 0.632168 0.672044 0.332597 0.535607 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 33
Initial state: 0 0.13369 0.0198143 0.535604 0.222569 0.00928121 0.58681 0.524888 0.743954 0.32039 0.582629 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32332 episodes
GETTING ACTION FROM:
action 1, numVisits=32297, meanQ=8.589513, numObservations: 9
action 4, numVisits=22, meanQ=0.550009, numObservations: 9
action 3, numVisits=5, meanQ=-0.804000, numObservations: 4
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.13369 0.0198143 0.535604 0.222569 0.00928121 0.58681 0.524888 0.743954 0.32039 0.582629 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=3033, meanQ=9.456445, numObservations: 9
action -1, numVisits=6, meanQ=-1.010000, numObservations: 6
action 0, numVisits=6, meanQ=-1.671650, numObservations: 5
action 2, numVisits=6, meanQ=-2.503333, numObservations: 6
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 9813 episodes
GETTING ACTION FROM:
action 4, numVisits=12839, meanQ=9.035582, numObservations: 9
action -1, numVisits=12, meanQ=-1.010000, numObservations: 12
action 0, numVisits=7, meanQ=-1.577129, numObservations: 6
action 2, numVisits=6, meanQ=-2.503333, numObservations: 6
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.13369 0.0198143 0.535604 0.222569 0.00928121 0.58681 0.524888 0.743954 0.32039 0.582629 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 34
Initial state: 0 0.388325 0.477844 0.016243 0.942631 0.764136 0.11099 0.397357 0.0230243 0.785931 0.777591 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32447 episodes
GETTING ACTION FROM:
action 4, numVisits=32396, meanQ=8.772850, numObservations: 9
action 3, numVisits=46, meanQ=7.533261, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.388325 0.477844 0.016243 0.942631 0.764136 0.11099 0.397357 0.0230243 0.785931 0.777591 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=529, meanQ=12.098035, numObservations: 9
action 3, numVisits=3, meanQ=3.330000, numObservations: 2
action 1, numVisits=5, meanQ=3.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 20473 episodes
GETTING ACTION FROM:
action 2, numVisits=20972, meanQ=8.807053, numObservations: 9
action 1, numVisits=6, meanQ=0.666667, numObservations: 5
action 3, numVisits=4, meanQ=-0.252500, numObservations: 3
action -1, numVisits=16, meanQ=-1.505000, numObservations: 16
action 0, numVisits=14, meanQ=-1.646429, numObservations: 13
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.388325 0.477844 0.016243 0.942631 0.764136 0.11099 0.397357 0.0230243 0.785931 0.777591 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 35
Initial state: 0 0.659034 0.465326 0.122136 0.303222 0.445857 0.60014 0.252988 0.735831 0.583551 0.944656 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32468 episodes
GETTING ACTION FROM:
action 5, numVisits=32447, meanQ=8.596371, numObservations: 9
action 3, numVisits=7, meanQ=5.000000, numObservations: 5
action 2, numVisits=10, meanQ=4.499000, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.659034 0.465326 0.122136 0.303222 0.445857 0.60014 0.252988 0.735831 0.583551 0.944656 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 36
Initial state: 0 0.342495 0.554927 0.717978 0.432815 0.0499892 0.292109 0.00343744 0.391428 0.273304 0.164107 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32629 episodes
GETTING ACTION FROM:
action 3, numVisits=32614, meanQ=8.798233, numObservations: 9
action 5, numVisits=3, meanQ=3.330000, numObservations: 3
action 1, numVisits=6, meanQ=3.165000, numObservations: 5
action 4, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.342495 0.554927 0.717978 0.432815 0.0499892 0.292109 0.00343744 0.391428 0.273304 0.164107 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=3119, meanQ=10.302047, numObservations: 9
action 5, numVisits=5, meanQ=4.598000, numObservations: 5
action 1, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 11194 episodes
GETTING ACTION FROM:
action 4, numVisits=14306, meanQ=10.183928, numObservations: 9
action 5, numVisits=6, meanQ=1.998333, numObservations: 6
action 1, numVisits=3, meanQ=0.666667, numObservations: 2
action 0, numVisits=4, meanQ=-1.505000, numObservations: 4
action -1, numVisits=4, meanQ=-1.507475, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 0 0.342495 0.554927 0.717978 0.432815 0.0499892 0.292109 0.00343744 0.391428 0.273304 0.164107 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=799, meanQ=14.406862, numObservations: 9
action 2, numVisits=226, meanQ=9.437311, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 9332 episodes
GETTING ACTION FROM:
action 5, numVisits=10131, meanQ=12.491723, numObservations: 9
action 2, numVisits=226, meanQ=9.437311, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.342495 0.554927 0.717978 0.432815 0.0499892 0.292109 0.00343744 0.391428 0.273304 0.164107 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=500, meanQ=19.556294, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.155105, numObservations: 1
action 2, numVisits=1, meanQ=-10.216989, numObservations: 1
action 4, numVisits=1, meanQ=-10.480782, numObservations: 1
action 3, numVisits=1, meanQ=-1069.974751, numObservations: 1
Sampled 15594 episodes
GETTING ACTION FROM:
action 1, numVisits=16094, meanQ=16.654561, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.155105, numObservations: 1
action 2, numVisits=1, meanQ=-10.216989, numObservations: 1
action 4, numVisits=1, meanQ=-10.480782, numObservations: 1
action 3, numVisits=1, meanQ=-1069.974751, numObservations: 1
action: 1
Next state: 1 0.342495 0.554927 0.717978 0.432815 0.0499892 0.292109 0.00343744 0.391428 0.273304 0.164107 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 11.4068
Run # 37
Initial state: 0 0.895038 0.236826 0.299758 0.519559 0.0589565 0.395647 0.965979 0.87824 0.968442 0.302387 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32430 episodes
GETTING ACTION FROM:
action 2, numVisits=32407, meanQ=8.658404, numObservations: 9
action 4, numVisits=18, meanQ=4.723344, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.895038 0.236826 0.299758 0.519559 0.0589565 0.395647 0.965979 0.87824 0.968442 0.302387 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 38
Initial state: 0 0.339992 0.587211 0.94716 0.222596 0.257567 0.0626636 0.532204 0.883205 0.552108 0.212841 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32494 episodes
GETTING ACTION FROM:
action 2, numVisits=32488, meanQ=8.670084, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.339992 0.587211 0.94716 0.222596 0.257567 0.0626636 0.532204 0.883205 0.552108 0.212841 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 39
Initial state: 0 0.176319 0.960797 0.333867 0.471611 0.37523 0.954869 0.841373 0.213829 0.0101092 0.328776 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32563 episodes
GETTING ACTION FROM:
action 1, numVisits=32514, meanQ=8.749621, numObservations: 9
action 0, numVisits=17, meanQ=-1.010000, numObservations: 17
action -1, numVisits=18, meanQ=-1.010000, numObservations: 18
action 5, numVisits=11, meanQ=-1.635445, numObservations: 6
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.176319 0.960797 0.333867 0.471611 0.37523 0.954869 0.841373 0.213829 0.0101092 0.328776 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=1956, meanQ=10.104048, numObservations: 9
action 1, numVisits=3, meanQ=5.993333, numObservations: 2
action 2, numVisits=5, meanQ=5.402020, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 11426 episodes
GETTING ACTION FROM:
action 1, numVisits=15, meanQ=16.382667, numObservations: 5
action 2, numVisits=11416, meanQ=12.379382, numObservations: 9
action 3, numVisits=1956, meanQ=10.104048, numObservations: 9
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.176319 0.960797 0.333867 0.471611 0.37523 0.954869 0.841373 0.213829 0.0101092 0.328776 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18065 episodes
GETTING ACTION FROM:
action 1, numVisits=11, meanQ=15.978182, numObservations: 3
action 3, numVisits=17987, meanQ=14.313659, numObservations: 9
action -1, numVisits=17, meanQ=-1.242941, numObservations: 17
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=47, meanQ=-23.323415, numObservations: 34
action: 1
Next state: 0 0.176319 0.960797 0.333867 0.471611 0.37523 0.954869 0.841373 0.213829 0.0101092 0.328776 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=1, meanQ=24.000000, numObservations: 1
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29431 episodes
GETTING ACTION FROM:
action 1, numVisits=13, meanQ=17.461546, numObservations: 4
action 5, numVisits=29397, meanQ=10.874825, numObservations: 9
action 3, numVisits=8, meanQ=6.500000, numObservations: 4
action 2, numVisits=5, meanQ=4.400000, numObservations: 3
action 4, numVisits=4, meanQ=1.000025, numObservations: 2
action -1, numVisits=3, meanQ=-1.340000, numObservations: 3
action 0, numVisits=2, meanQ=-2.000000, numObservations: 2
action: 1
Next state: 1 0.176319 0.960797 0.333867 0.471611 0.37523 0.954869 0.841373 0.213829 0.0101092 0.328776 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 11.4068
Run # 40
Initial state: 0 0.374062 0.426108 0.218455 0.307621 0.981732 0.312103 0.216225 0.363964 0.451403 0.531118 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31819 episodes
GETTING ACTION FROM:
action 2, numVisits=31813, meanQ=8.599870, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.374062 0.426108 0.218455 0.307621 0.981732 0.312103 0.216225 0.363964 0.451403 0.531118 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=3021, meanQ=8.933646, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 8890 episodes
GETTING ACTION FROM:
action 1, numVisits=11876, meanQ=8.405246, numObservations: 9
action -1, numVisits=22, meanQ=-1.895709, numObservations: 17
action 0, numVisits=14, meanQ=-2.000000, numObservations: 12
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=2, meanQ=-7.005000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.374062 0.426108 0.218455 0.307621 0.981732 0.312103 0.216225 0.363964 0.451403 0.531118 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 41
Initial state: 0 0.358914 0.557732 0.0131093 0.875963 0.890881 0.192714 0.646942 0.963455 0.690745 0.249084 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32437 episodes
GETTING ACTION FROM:
action 5, numVisits=32431, meanQ=8.617097, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.358914 0.557732 0.0131093 0.875963 0.890881 0.192714 0.646942 0.963455 0.690745 0.249084 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 42
Initial state: 0 0.541143 0.129164 0.246209 0.726908 0.899065 0.106794 0.535715 0.315585 0.308492 0.592995 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32508 episodes
GETTING ACTION FROM:
action 4, numVisits=32502, meanQ=8.703382, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.541143 0.129164 0.246209 0.726908 0.899065 0.106794 0.535715 0.315585 0.308492 0.592995 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 43
Initial state: 0 0.413765 0.55595 0.435749 0.304231 0.772974 0.862942 0.709345 0.861618 0.324648 0.256704 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32387 episodes
GETTING ACTION FROM:
action 2, numVisits=32375, meanQ=8.476395, numObservations: 9
action 1, numVisits=5, meanQ=4.400000, numObservations: 3
action 5, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.413765 0.55595 0.435749 0.304231 0.772974 0.862942 0.709345 0.861618 0.324648 0.256704 w: 1
Observation: 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 44
Initial state: 0 0.720608 0.566399 0.680279 0.242048 0.72069 0.435344 0.82481 0.124633 0.450206 0.474282 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32504 episodes
GETTING ACTION FROM:
action 2, numVisits=32498, meanQ=8.718230, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.720608 0.566399 0.680279 0.242048 0.72069 0.435344 0.82481 0.124633 0.450206 0.474282 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 45
Initial state: 0 0.407125 0.546142 0.463922 0.650888 0.885035 0.401359 0.0837092 0.772601 0.519067 0.824369 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31785 episodes
GETTING ACTION FROM:
action 4, numVisits=31771, meanQ=9.054488, numObservations: 9
action 5, numVisits=6, meanQ=1.833333, numObservations: 6
action 1, numVisits=4, meanQ=-0.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.407125 0.546142 0.463922 0.650888 0.885035 0.401359 0.0837092 0.772601 0.519067 0.824369 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=1811, meanQ=11.205013, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 12929 episodes
GETTING ACTION FROM:
action 5, numVisits=12901, meanQ=11.515218, numObservations: 9
action 4, numVisits=1812, meanQ=11.202430, numObservations: 9
action -1, numVisits=23, meanQ=-1.182174, numObservations: 21
action 0, numVisits=18, meanQ=-1.340550, numObservations: 17
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.407125 0.546142 0.463922 0.650888 0.885035 0.401359 0.0837092 0.772601 0.519067 0.824369 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 46
Initial state: 0 0.413168 0.543856 0.0116042 0.746856 0.575757 0.0806047 0.381426 0.306846 0.755619 0.795764 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32359 episodes
GETTING ACTION FROM:
action 4, numVisits=32351, meanQ=8.727811, numObservations: 9
action 1, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.413168 0.543856 0.0116042 0.746856 0.575757 0.0806047 0.381426 0.306846 0.755619 0.795764 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 47
Initial state: 0 0.978469 0.246413 0.0585623 0.0797838 0.0640781 0.593931 0.365662 0.495241 0.722328 0.944328 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32354 episodes
GETTING ACTION FROM:
action 2, numVisits=32340, meanQ=8.886983, numObservations: 9
action 4, numVisits=7, meanQ=1.000000, numObservations: 5
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.978469 0.246413 0.0585623 0.0797838 0.0640781 0.593931 0.365662 0.495241 0.722328 0.944328 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=3023, meanQ=9.840418, numObservations: 9
action 4, numVisits=8, meanQ=-0.252500, numObservations: 5
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 10738 episodes
GETTING ACTION FROM:
action 1, numVisits=13757, meanQ=10.376987, numObservations: 9
action 4, numVisits=8, meanQ=-0.252500, numObservations: 5
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.978469 0.246413 0.0585623 0.0797838 0.0640781 0.593931 0.365662 0.495241 0.722328 0.944328 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 48
Initial state: 0 0.391472 0.525593 0.562851 0.707268 0.997656 0.310325 0.829882 0.354965 0.554973 0.807467 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32346 episodes
GETTING ACTION FROM:
action 3, numVisits=32338, meanQ=8.472317, numObservations: 9
action 5, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.391472 0.525593 0.562851 0.707268 0.997656 0.310325 0.829882 0.354965 0.554973 0.807467 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 49
Initial state: 0 0.811657 0.886893 0.291295 0.509362 0.126105 0.934409 0.61304 0.896183 0.834344 0.054018 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32456 episodes
GETTING ACTION FROM:
action 3, numVisits=32410, meanQ=8.747759, numObservations: 9
action 4, numVisits=39, meanQ=7.487959, numObservations: 8
action 5, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.811657 0.886893 0.291295 0.509362 0.126105 0.934409 0.61304 0.896183 0.834344 0.054018 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=2003, meanQ=10.393043, numObservations: 9
action 5, numVisits=6, meanQ=6.500000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 11003 episodes
GETTING ACTION FROM:
action 5, numVisits=11005, meanQ=10.776772, numObservations: 9
action 4, numVisits=2003, meanQ=10.393043, numObservations: 9
action -1, numVisits=3, meanQ=-1.670000, numObservations: 3
action 0, numVisits=3, meanQ=-1.670000, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.811657 0.886893 0.291295 0.509362 0.126105 0.934409 0.61304 0.896183 0.834344 0.054018 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 50
Initial state: 0 0.68937 0.994756 0.318689 0.481921 0.490714 0.241804 0.580937 0.332206 0.508227 0.690601 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32078 episodes
GETTING ACTION FROM:
action 2, numVisits=32059, meanQ=8.703490, numObservations: 9
action 1, numVisits=12, meanQ=1.585008, numObservations: 7
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.68937 0.994756 0.318689 0.481921 0.490714 0.241804 0.580937 0.332206 0.508227 0.690601 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
[32m ProblemEnvironment.hpp 351: Done.[39m
