Run # 1
Initial state: 0 0.12902 0.842524 0.9358 0.215081 0.898888 0.0666724 0.572873 0.789173 0.325605 0.547006 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31982 episodes
GETTING ACTION FROM:
action 5, numVisits=31971, meanQ=7.815955, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 2, numVisits=2, meanQ=-4.000000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.12902 0.842524 0.9358 0.215081 0.898888 0.0666724 0.572873 0.789173 0.325605 0.547006 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 2
Initial state: 0 0.196225 0.252203 0.224894 0.371218 0.338888 0.498662 0.910316 0.510221 0.243768 0.812284 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30349 episodes
GETTING ACTION FROM:
action 3, numVisits=30335, meanQ=7.712119, numObservations: 9
action 5, numVisits=6, meanQ=1.998333, numObservations: 3
action 1, numVisits=4, meanQ=1.497500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.196225 0.252203 0.224894 0.371218 0.338888 0.498662 0.910316 0.510221 0.243768 0.812284 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 3
Initial state: 0 0.55296 0.215623 0.845294 0.485393 0.498044 0.643468 0.809012 0.196052 0.396242 0.502674 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32873 episodes
GETTING ACTION FROM:
action 1, numVisits=11746, meanQ=8.003143, numObservations: 9
action 5, numVisits=21098, meanQ=7.896434, numObservations: 9
action 4, numVisits=25, meanQ=6.320004, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.55296 0.215623 0.845294 0.485393 0.498044 0.643468 0.809012 0.196052 0.396242 0.502674 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=323, meanQ=9.349303, numObservations: 9
action 3, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 30285 episodes
GETTING ACTION FROM:
action 2, numVisits=30538, meanQ=5.621025, numObservations: 9
action 4, numVisits=12, meanQ=1.381333, numObservations: 7
action 0, numVisits=41, meanQ=-1.348049, numObservations: 32
action -1, numVisits=17, meanQ=-1.941765, numObservations: 13
action 3, numVisits=5, meanQ=-2.434387, numObservations: 4
action 5, numVisits=2, meanQ=-7.005000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.55296 0.215623 0.845294 0.485393 0.498044 0.643468 0.809012 0.196052 0.396242 0.502674 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 4
Initial state: 0 0.667741 0.760876 0.412218 0.956613 0.356775 0.589175 0.684686 0.402815 0.191004 0.232274 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32474 episodes
GETTING ACTION FROM:
action 1, numVisits=32468, meanQ=7.832483, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.667741 0.760876 0.412218 0.956613 0.356775 0.589175 0.684686 0.402815 0.191004 0.232274 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 5
Initial state: 0 0.297436 0.567129 0.0142454 0.464823 0.774134 0.979434 0.212779 0.264961 0.34984 0.827652 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18033 episodes
GETTING ACTION FROM:
action -1, numVisits=17997, meanQ=12.755321, numObservations: 242
action 0, numVisits=30, meanQ=-1.472330, numObservations: 28
action 4, numVisits=2, meanQ=-7.500000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.297436 0.567129 0.0142454 0.464823 0.774134 0.979434 0.212779 0.264961 0.34984 0.827652 w: 1
Observation: 0 2 0 1 0 3 0 1 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=30, meanQ=4.201690, numObservations: 14
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 18224 episodes
GETTING ACTION FROM:
action -1, numVisits=18254, meanQ=13.598239, numObservations: 217
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.297436 0.567129 0.0142454 0.464823 0.774134 0.979434 0.212779 0.264961 0.34984 0.827652 w: 1
Observation: 0 2 0 3 0 3 0 1 0 3 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=245, meanQ=3.451268, numObservations: 9
action 3, numVisits=63, meanQ=2.398413, numObservations: 5
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 38432 episodes
GETTING ACTION FROM:
action 1, numVisits=38433, meanQ=21.853749, numObservations: 9
action 5, numVisits=245, meanQ=3.451268, numObservations: 9
action 3, numVisits=63, meanQ=2.398413, numObservations: 5
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.297436 0.567129 0.0142454 0.464823 0.774134 0.979434 0.212779 0.264961 0.34984 0.827652 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.5424
Run # 6
Initial state: 0 0.760341 0.35839 0.536319 0.930915 0.333264 0.518624 0.548805 0.879403 0.049345 0.424637 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32668 episodes
GETTING ACTION FROM:
action 1, numVisits=32654, meanQ=7.795125, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 5, numVisits=5, meanQ=-1.200000, numObservations: 4
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.760341 0.35839 0.536319 0.930915 0.333264 0.518624 0.548805 0.879403 0.049345 0.424637 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 7
Initial state: 0 0.579331 0.794 0.296804 0.637948 0.539409 0.974519 0.746548 0.119465 0.512559 0.957425 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32484 episodes
GETTING ACTION FROM:
action 3, numVisits=32476, meanQ=7.791416, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.579331 0.794 0.296804 0.637948 0.539409 0.974519 0.746548 0.119465 0.512559 0.957425 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 8
Initial state: 0 0.946195 0.683365 0.223944 0.00532944 0.31303 0.529032 0.152071 0.800766 0.029093 0.917481 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32106 episodes
GETTING ACTION FROM:
action 3, numVisits=32095, meanQ=7.804811, numObservations: 9
action 5, numVisits=6, meanQ=3.000000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.946195 0.683365 0.223944 0.00532944 0.31303 0.529032 0.152071 0.800766 0.029093 0.917481 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 9
Initial state: 0 0.410429 0.568085 0.506326 0.695653 0.870144 0.821585 0.765939 0.756685 0.634838 0.166432 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31645 episodes
GETTING ACTION FROM:
action 1, numVisits=31624, meanQ=7.660834, numObservations: 9
action 3, numVisits=16, meanQ=4.686269, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.410429 0.568085 0.506326 0.695653 0.870144 0.821585 0.765939 0.756685 0.634838 0.166432 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 10
Initial state: 0 0.940964 0.588812 0.370929 0.64424 0.723873 0.270764 0.559418 0.301835 0.500644 0.462878 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30910 episodes
GETTING ACTION FROM:
action 2, numVisits=30872, meanQ=8.075300, numObservations: 9
action -1, numVisits=17, meanQ=-1.010000, numObservations: 17
action 0, numVisits=17, meanQ=-1.010000, numObservations: 17
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.940964 0.588812 0.370929 0.64424 0.723873 0.270764 0.559418 0.301835 0.500644 0.462878 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 11
Initial state: 0 0.37202 0.518652 0.304651 0.292015 0.396274 0.0202776 0.739264 0.876533 0.987068 0.949813 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32598 episodes
GETTING ACTION FROM:
action 5, numVisits=32581, meanQ=7.800306, numObservations: 9
action 3, numVisits=6, meanQ=0.666667, numObservations: 4
action 4, numVisits=7, meanQ=0.000000, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.37202 0.518652 0.304651 0.292015 0.396274 0.0202776 0.739264 0.876533 0.987068 0.949813 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 12
Initial state: 0 0.22167 0.4126 0.312844 0.518737 0.84835 0.21832 0.954366 0.575177 0.15565 0.729209 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32512 episodes
GETTING ACTION FROM:
action 3, numVisits=32504, meanQ=7.778463, numObservations: 9
action 4, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.22167 0.4126 0.312844 0.518737 0.84835 0.21832 0.954366 0.575177 0.15565 0.729209 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 13
Initial state: 0 0.342902 0.516436 0.204397 0.250908 0.983034 0.067626 0.155187 0.521172 0.559933 0.232732 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32636 episodes
GETTING ACTION FROM:
action 4, numVisits=32630, meanQ=7.817273, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.342902 0.516436 0.204397 0.250908 0.983034 0.067626 0.155187 0.521172 0.559933 0.232732 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=731, meanQ=8.387145, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 12499 episodes
GETTING ACTION FROM:
action 3, numVisits=13157, meanQ=8.182757, numObservations: 9
action 5, numVisits=6, meanQ=1.998333, numObservations: 5
action 0, numVisits=30, meanQ=-1.852030, numObservations: 27
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=40, meanQ=-27.170590, numObservations: 34
action: 3
Next state: 2 0.342902 0.516436 0.204397 0.250908 0.983034 0.067626 0.155187 0.521172 0.559933 0.232732 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 14
Initial state: 0 0.9709 0.803067 0.202665 0.610904 0.432129 0.631023 0.459983 0.848745 0.244135 0.389283 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32670 episodes
GETTING ACTION FROM:
action 3, numVisits=32657, meanQ=7.714439, numObservations: 9
action 2, numVisits=6, meanQ=0.666667, numObservations: 4
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.9709 0.803067 0.202665 0.610904 0.432129 0.631023 0.459983 0.848745 0.244135 0.389283 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 15
Initial state: 0 0.0716272 0.815708 0.654542 0.688798 0.967847 0.261283 0.387088 0.517028 0.80012 0.128939 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32287 episodes
GETTING ACTION FROM:
action 2, numVisits=32281, meanQ=7.821542, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.0716272 0.815708 0.654542 0.688798 0.967847 0.261283 0.387088 0.517028 0.80012 0.128939 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 16
Initial state: 0 0.389124 0.639222 0.787041 0.451834 0.58101 0.329161 0.938014 0.728793 0.459956 0.364319 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17887 episodes
GETTING ACTION FROM:
action -1, numVisits=17866, meanQ=12.802603, numObservations: 243
action 0, numVisits=14, meanQ=-1.293564, numObservations: 13
action 1, numVisits=2, meanQ=-7.500000, numObservations: 2
action 2, numVisits=2, meanQ=-7.500000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.389124 0.639222 0.787041 0.451834 0.58101 0.329161 0.938014 0.728793 0.459956 0.364319 w: 1
Observation: 0 2 0 1 0 3 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=211, meanQ=21.077869, numObservations: 8
action 3, numVisits=7, meanQ=9.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 38126 episodes
GETTING ACTION FROM:
action 1, numVisits=38337, meanQ=21.863378, numObservations: 9
action 3, numVisits=7, meanQ=9.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.389124 0.639222 0.787041 0.451834 0.58101 0.329161 0.938014 0.728793 0.459956 0.364319 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 17
Initial state: 0 0.326541 0.574886 0.474987 0.0293714 0.522109 0.131714 0.189535 0.365116 0.661806 0.841106 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32413 episodes
GETTING ACTION FROM:
action 2, numVisits=32398, meanQ=7.897681, numObservations: 9
action 1, numVisits=6, meanQ=-0.500000, numObservations: 5
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.326541 0.574886 0.474987 0.0293714 0.522109 0.131714 0.189535 0.365116 0.661806 0.841106 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=939, meanQ=9.653909, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 32230 episodes
GETTING ACTION FROM:
action 3, numVisits=33144, meanQ=7.172036, numObservations: 9
action 1, numVisits=9, meanQ=1.643004, numObservations: 5
action 4, numVisits=4, meanQ=0.073281, numObservations: 2
action -1, numVisits=8, meanQ=-1.752500, numObservations: 8
action 0, numVisits=8, meanQ=-1.876250, numObservations: 8
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.326541 0.574886 0.474987 0.0293714 0.522109 0.131714 0.189535 0.365116 0.661806 0.841106 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 18
Initial state: 0 0.366448 0.151983 0.388351 0.568533 0.652124 0.766233 0.369819 0.0335184 0.501736 0.105011 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32309 episodes
GETTING ACTION FROM:
action 1, numVisits=32293, meanQ=7.514110, numObservations: 9
action 4, numVisits=7, meanQ=0.000000, numObservations: 5
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.366448 0.151983 0.388351 0.568533 0.652124 0.766233 0.369819 0.0335184 0.501736 0.105011 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 19
Initial state: 0 0.416271 0.633857 0.529706 0.891932 0.8502 0.870727 0.376963 0.468258 0.418709 0.462844 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32723 episodes
GETTING ACTION FROM:
action 1, numVisits=32709, meanQ=7.677966, numObservations: 9
action 5, numVisits=6, meanQ=3.000000, numObservations: 4
action 4, numVisits=4, meanQ=0.505025, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.416271 0.633857 0.529706 0.891932 0.8502 0.870727 0.376963 0.468258 0.418709 0.462844 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 20
Initial state: 0 0.871512 0.211883 0.654101 0.0926436 0.378016 0.359466 0.0937235 0.571732 0.380221 0.667578 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32803 episodes
GETTING ACTION FROM:
action 5, numVisits=32788, meanQ=7.539294, numObservations: 9
action 2, numVisits=8, meanQ=3.998750, numObservations: 6
action 3, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.871512 0.211883 0.654101 0.0926436 0.378016 0.359466 0.0937235 0.571732 0.380221 0.667578 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 21
Initial state: 0 0.438394 0.342028 0.965451 0.690464 0.853372 0.100769 0.392272 0.505506 0.907816 0.030587 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32421 episodes
GETTING ACTION FROM:
action 3, numVisits=32375, meanQ=7.849385, numObservations: 9
action 1, numVisits=41, meanQ=6.417566, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.438394 0.342028 0.965451 0.690464 0.853372 0.100769 0.392272 0.505506 0.907816 0.030587 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 22
Initial state: 0 0.159843 0.977187 0.530457 0.929454 0.316053 0.514308 0.734401 0.978123 0.599293 0.77142 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30983 episodes
GETTING ACTION FROM:
action 1, numVisits=30977, meanQ=7.202182, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.159843 0.977187 0.530457 0.929454 0.316053 0.514308 0.734401 0.978123 0.599293 0.77142 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=664, meanQ=10.214962, numObservations: 9
action 5, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 18688 episodes
GETTING ACTION FROM:
action 3, numVisits=18949, meanQ=6.736133, numObservations: 9
action 2, numVisits=4, meanQ=-0.819498, numObservations: 4
action 5, numVisits=4, meanQ=-2.250000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=301, meanQ=-4.887534, numObservations: 122
action 4, numVisits=2, meanQ=-7.005000, numObservations: 2
action -1, numVisits=99, meanQ=-12.199628, numObservations: 66
action: 3
Next state: 1 0.159843 0.977187 0.530457 0.929454 0.316053 0.514308 0.734401 0.978123 0.599293 0.77142 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 23
Initial state: 0 0.927038 0.504685 0.887145 0.169383 0.315339 0.665723 0.973065 0.977452 0.166862 0.632774 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32523 episodes
GETTING ACTION FROM:
action 2, numVisits=32467, meanQ=7.800416, numObservations: 9
action 0, numVisits=48, meanQ=0.763338, numObservations: 42
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.927038 0.504685 0.887145 0.169383 0.315339 0.665723 0.973065 0.977452 0.166862 0.632774 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 24
Initial state: 0 0.100408 0.102578 0.853484 0.798869 0.590533 0.284645 0.302101 0.520228 0.214273 0.0300651 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32573 episodes
GETTING ACTION FROM:
action 2, numVisits=32558, meanQ=7.886105, numObservations: 9
action 3, numVisits=7, meanQ=4.000000, numObservations: 5
action 5, numVisits=4, meanQ=3.247500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.100408 0.102578 0.853484 0.798869 0.590533 0.284645 0.302101 0.520228 0.214273 0.0300651 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 25
Initial state: 0 0.346003 0.632654 0.462538 0.0847342 0.252388 0.927897 0.0732405 0.814701 0.00367175 0.607863 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32185 episodes
GETTING ACTION FROM:
action 3, numVisits=29064, meanQ=7.662496, numObservations: 9
action 1, numVisits=3112, meanQ=7.368996, numObservations: 9
action 2, numVisits=5, meanQ=3.622000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.346003 0.632654 0.462538 0.0847342 0.252388 0.927897 0.0732405 0.814701 0.00367175 0.607863 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=1420, meanQ=11.731789, numObservations: 205
action -1, numVisits=23, meanQ=-1.786074, numObservations: 19
action 1, numVisits=7, meanQ=-2.575714, numObservations: 4
action 4, numVisits=12, meanQ=-2.669158, numObservations: 6
action 3, numVisits=3, meanQ=-3.673300, numObservations: 2
action 5, numVisits=2, meanQ=-7.005000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 5164 episodes
GETTING ACTION FROM:
action 0, numVisits=6584, meanQ=8.174124, numObservations: 241
action -1, numVisits=23, meanQ=-1.786074, numObservations: 19
action 1, numVisits=7, meanQ=-2.575714, numObservations: 4
action 4, numVisits=12, meanQ=-2.669158, numObservations: 6
action 3, numVisits=3, meanQ=-3.673300, numObservations: 2
action 5, numVisits=2, meanQ=-7.005000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.346003 0.632654 0.462538 0.0847342 0.252388 0.927897 0.0732405 0.814701 0.00367175 0.607863 w: 1
Observation: 0 0 2 0 1 0 3 0 1 0 2 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=22, meanQ=16.414290, numObservations: 7
action 1, numVisits=11, meanQ=14.600829, numObservations: 7
action 3, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 25852 episodes
GETTING ACTION FROM:
action 5, numVisits=25868, meanQ=16.770882, numObservations: 9
action 1, numVisits=14, meanQ=8.837080, numObservations: 7
action 3, numVisits=3, meanQ=5.330033, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.346003 0.632654 0.462538 0.0847342 0.252388 0.927897 0.0732405 0.814701 0.00367175 0.607863 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=1, meanQ=24.000000, numObservations: 1
action 0, numVisits=50, meanQ=4.478106, numObservations: 27
action -1, numVisits=5, meanQ=-3.256862, numObservations: 4
action 1, numVisits=1, meanQ=-9.220275, numObservations: 1
action 5, numVisits=1, meanQ=-9.936959, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 18713 episodes
GETTING ACTION FROM:
action 3, numVisits=45, meanQ=15.824667, numObservations: 8
action 0, numVisits=18647, meanQ=-1.356654, numObservations: 191
action 1, numVisits=1, meanQ=-9.220275, numObservations: 1
action -1, numVisits=77, meanQ=-9.350715, numObservations: 43
action 5, numVisits=1, meanQ=-9.936959, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.346003 0.632654 0.462538 0.0847342 0.252388 0.927897 0.0732405 0.814701 0.00367175 0.607863 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32337 episodes
GETTING ACTION FROM:
action 1, numVisits=32289, meanQ=19.422735, numObservations: 9
action 3, numVisits=43, meanQ=7.794831, numObservations: 5
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-2.000000, numObservations: 1
action 0, numVisits=1, meanQ=-2.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.346003 0.632654 0.462538 0.0847342 0.252388 0.927897 0.0732405 0.814701 0.00367175 0.607863 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9.27271
Run # 26
Initial state: 0 0.40477 0.578303 0.0189566 0.809097 0.253428 0.924137 0.922991 0.773481 0.212151 0.734898 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32550 episodes
GETTING ACTION FROM:
action 2, numVisits=32528, meanQ=7.902559, numObservations: 9
action 4, numVisits=17, meanQ=5.058824, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.40477 0.578303 0.0189566 0.809097 0.253428 0.924137 0.922991 0.773481 0.212151 0.734898 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=83, meanQ=8.424949, numObservations: 9
action 5, numVisits=61, meanQ=6.981154, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 37994 episodes
GETTING ACTION FROM:
action 1, numVisits=38075, meanQ=12.242676, numObservations: 9
action 5, numVisits=61, meanQ=6.981154, numObservations: 9
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.40477 0.578303 0.0189566 0.809097 0.253428 0.924137 0.922991 0.773481 0.212151 0.734898 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 27
Initial state: 0 0.12853 0.806659 0.865458 0.389598 0.432341 0.523184 0.877018 0.286537 0.839425 0.756599 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32520 episodes
GETTING ACTION FROM:
action 3, numVisits=32512, meanQ=7.902337, numObservations: 9
action 1, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.12853 0.806659 0.865458 0.389598 0.432341 0.523184 0.877018 0.286537 0.839425 0.756599 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 28
Initial state: 0 0.691393 0.684713 0.688915 0.500363 0.663036 0.835817 0.345802 0.571881 0.483994 0.41229 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32003 episodes
GETTING ACTION FROM:
action 4, numVisits=31995, meanQ=7.628234, numObservations: 9
action 5, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 0 0.691393 0.684713 0.688915 0.500363 0.663036 0.835817 0.345802 0.571881 0.483994 0.41229 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=515, meanQ=19.916075, numObservations: 9
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 27308 episodes
GETTING ACTION FROM:
action 4, numVisits=519, meanQ=19.932822, numObservations: 9
action 5, numVisits=27295, meanQ=10.166169, numObservations: 9
action -1, numVisits=7, meanQ=-1.717143, numObservations: 6
action 0, numVisits=6, meanQ=-1.835000, numObservations: 5
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.691393 0.684713 0.688915 0.500363 0.663036 0.835817 0.345802 0.571881 0.483994 0.41229 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 29
Initial state: 0 0.0702964 0.335433 0.760314 0.337556 0.00750734 0.783196 0.40747 0.548938 0.653511 0.936985 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32479 episodes
GETTING ACTION FROM:
action 4, numVisits=32448, meanQ=7.790308, numObservations: 9
action 5, numVisits=22, meanQ=6.409550, numObservations: 8
action 3, numVisits=5, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.0702964 0.335433 0.760314 0.337556 0.00750734 0.783196 0.40747 0.548938 0.653511 0.936985 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 30
Initial state: 0 0.397755 0.602445 0.259169 0.329768 0.174417 0.154786 0.498512 0.167842 0.0526721 0.367017 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32510 episodes
GETTING ACTION FROM:
action 5, numVisits=32491, meanQ=8.054992, numObservations: 9
action 2, numVisits=12, meanQ=1.833333, numObservations: 7
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.397755 0.602445 0.259169 0.329768 0.174417 0.154786 0.498512 0.167842 0.0526721 0.367017 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 31
Initial state: 0 0.335318 0.646288 0.264403 0.0131142 0.341073 0.47223 0.733384 0.587661 0.730385 0.639478 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31835 episodes
GETTING ACTION FROM:
action 4, numVisits=31826, meanQ=8.022231, numObservations: 9
action 5, numVisits=4, meanQ=1.250000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.335318 0.646288 0.264403 0.0131142 0.341073 0.47223 0.733384 0.587661 0.730385 0.639478 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 32
Initial state: 0 0.847585 0.0240469 0.28064 0.574552 0.211245 0.698597 0.964927 0.748919 0.818771 0.808752 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32462 episodes
GETTING ACTION FROM:
action 4, numVisits=32445, meanQ=7.691936, numObservations: 9
action 1, numVisits=9, meanQ=2.167778, numObservations: 5
action 3, numVisits=4, meanQ=-0.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 1 0.847585 0.0240469 0.28064 0.574552 0.211245 0.698597 0.964927 0.748919 0.818771 0.808752 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 33
Initial state: 0 0.983142 0.837211 0.851386 0.396682 0.513441 0.257245 0.291656 0.677961 0.123268 0.417115 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30803 episodes
GETTING ACTION FROM:
action 2, numVisits=30780, meanQ=7.404448, numObservations: 9
action 4, numVisits=16, meanQ=2.186875, numObservations: 9
action 3, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.983142 0.837211 0.851386 0.396682 0.513441 0.257245 0.291656 0.677961 0.123268 0.417115 w: 1
Observation: 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 34
Initial state: 0 0.300674 0.798631 0.398411 0.663512 0.667114 0.908577 0.117066 0.892812 0.146406 0.409755 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32590 episodes
GETTING ACTION FROM:
action 3, numVisits=32565, meanQ=7.455769, numObservations: 9
action 4, numVisits=13, meanQ=3.538462, numObservations: 6
action 5, numVisits=6, meanQ=1.833333, numObservations: 4
action 1, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.300674 0.798631 0.398411 0.663512 0.667114 0.908577 0.117066 0.892812 0.146406 0.409755 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 35
Initial state: 0 0.602299 0.088746 0.329453 0.611215 0.189795 0.781118 0.573146 0.837844 0.624997 0.24379 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32416 episodes
GETTING ACTION FROM:
action 4, numVisits=32410, meanQ=7.740723, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.602299 0.088746 0.329453 0.611215 0.189795 0.781118 0.573146 0.837844 0.624997 0.24379 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 36
Initial state: 0 0.269436 0.689 0.316271 0.64406 0.0621278 0.918014 0.719464 0.665231 0.663503 0.164664 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31749 episodes
GETTING ACTION FROM:
action 2, numVisits=31728, meanQ=7.755331, numObservations: 9
action 3, numVisits=12, meanQ=5.498333, numObservations: 7
action 5, numVisits=5, meanQ=4.598000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.269436 0.689 0.316271 0.64406 0.0621278 0.918014 0.719464 0.665231 0.663503 0.164664 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 37
Initial state: 0 0.0829848 0.430871 0.683475 0.346341 0.325079 0.671609 0.168012 0.294391 0.375068 0.822073 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32617 episodes
GETTING ACTION FROM:
action 5, numVisits=32563, meanQ=7.736303, numObservations: 9
action 4, numVisits=30, meanQ=4.387343, numObservations: 8
action 3, numVisits=11, meanQ=3.976373, numObservations: 6
action 1, numVisits=10, meanQ=3.700000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 1 0.0829848 0.430871 0.683475 0.346341 0.325079 0.671609 0.168012 0.294391 0.375068 0.822073 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 38
Initial state: 0 0.723286 0.532646 0.398518 0.501015 0.481744 0.739401 0.247731 0.448528 0.276172 0.716699 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32092 episodes
GETTING ACTION FROM:
action 3, numVisits=32086, meanQ=7.532614, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.723286 0.532646 0.398518 0.501015 0.481744 0.739401 0.247731 0.448528 0.276172 0.716699 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 39
Initial state: 0 0.467847 0.959322 0.246017 0.476451 0.392064 0.679834 0.13781 0.197814 0.875335 0.666789 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18013 episodes
GETTING ACTION FROM:
action -1, numVisits=17977, meanQ=13.178786, numObservations: 243
action 0, numVisits=18, meanQ=-1.010000, numObservations: 18
action 4, numVisits=6, meanQ=-1.998317, numObservations: 5
action 5, numVisits=7, meanQ=-2.142843, numObservations: 5
action 1, numVisits=2, meanQ=-7.500000, numObservations: 2
action 2, numVisits=2, meanQ=-7.500000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.467847 0.959322 0.246017 0.476451 0.392064 0.679834 0.13781 0.197814 0.875335 0.666789 w: 1
Observation: 0 3 0 1 0 2 0 1 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=32, meanQ=13.093128, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 36236 episodes
GETTING ACTION FROM:
action 3, numVisits=36268, meanQ=12.145897, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.467847 0.959322 0.246017 0.476451 0.392064 0.679834 0.13781 0.197814 0.875335 0.666789 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 40
Initial state: 0 0.168339 0.218363 0.417279 0.586961 0.444718 0.277357 0.81329 0.197853 0.953059 0.35015 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32678 episodes
GETTING ACTION FROM:
action 4, numVisits=32667, meanQ=7.618382, numObservations: 9
action 2, numVisits=6, meanQ=1.998333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.168339 0.218363 0.417279 0.586961 0.444718 0.277357 0.81329 0.197853 0.953059 0.35015 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 41
Initial state: 0 0.909301 0.370957 0.314814 0.57216 0.983648 0.0427963 0.783602 0.0485757 0.0281838 0.436734 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32697 episodes
GETTING ACTION FROM:
action 1, numVisits=28729, meanQ=7.922922, numObservations: 9
action 5, numVisits=3945, meanQ=7.844282, numObservations: 9
action 2, numVisits=12, meanQ=5.999167, numObservations: 7
action 3, numVisits=6, meanQ=3.165000, numObservations: 4
action 4, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 2 0.909301 0.370957 0.314814 0.57216 0.983648 0.0427963 0.783602 0.0485757 0.0281838 0.436734 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 42
Initial state: 0 0.418681 0.544388 0.064513 0.315212 0.183819 0.208189 0.940137 0.293263 0.46137 0.341385 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32585 episodes
GETTING ACTION FROM:
action 2, numVisits=32568, meanQ=7.375107, numObservations: 9
action 4, numVisits=6, meanQ=0.666667, numObservations: 5
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=5, meanQ=-1.200000, numObservations: 5
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.418681 0.544388 0.064513 0.315212 0.183819 0.208189 0.940137 0.293263 0.46137 0.341385 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=681, meanQ=9.249486, numObservations: 9
action 3, numVisits=7, meanQ=4.000000, numObservations: 4
action 1, numVisits=11, meanQ=3.725464, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 12230 episodes
GETTING ACTION FROM:
action 5, numVisits=12831, meanQ=7.201635, numObservations: 9
action 1, numVisits=12, meanQ=2.498342, numObservations: 7
action 3, numVisits=24, meanQ=2.250280, numObservations: 8
action -1, numVisits=43, meanQ=-1.816274, numObservations: 36
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=2, meanQ=-7.889944, numObservations: 2
action 0, numVisits=20, meanQ=-53.205506, numObservations: 18
action: 5
Next state: 2 0.418681 0.544388 0.064513 0.315212 0.183819 0.208189 0.940137 0.293263 0.46137 0.341385 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 43
Initial state: 0 0.119156 0.141997 0.421781 0.61755 0.152005 0.884779 0.147926 0.430178 0.654038 0.733258 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32690 episodes
GETTING ACTION FROM:
action 3, numVisits=32682, meanQ=7.668219, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.119156 0.141997 0.421781 0.61755 0.152005 0.884779 0.147926 0.430178 0.654038 0.733258 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1607, meanQ=8.901431, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 4, numVisits=4, meanQ=-2.250000, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 14053 episodes
GETTING ACTION FROM:
action 1, numVisits=15638, meanQ=10.123543, numObservations: 9
action 0, numVisits=11, meanQ=-1.370000, numObservations: 11
action -1, numVisits=13, meanQ=-2.152308, numObservations: 12
action 4, numVisits=4, meanQ=-2.250000, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=2, meanQ=-5.885783, numObservations: 2
action 5, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 1
Next state: 2 0.119156 0.141997 0.421781 0.61755 0.152005 0.884779 0.147926 0.430178 0.654038 0.733258 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 44
Initial state: 0 0.507619 0.136579 0.878886 0.92663 0.706212 0.691329 0.376079 0.617489 0.648062 0.162424 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30672 episodes
GETTING ACTION FROM:
action 2, numVisits=30651, meanQ=7.790124, numObservations: 9
action -1, numVisits=8, meanQ=-1.010000, numObservations: 8
action 0, numVisits=8, meanQ=-1.010000, numObservations: 8
action 1, numVisits=2, meanQ=-7.500000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.507619 0.136579 0.878886 0.92663 0.706212 0.691329 0.376079 0.617489 0.648062 0.162424 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 45
Initial state: 0 0.68128 0.288095 0.97056 0.718845 0.68704 0.247682 0.304961 0.58024 0.435806 0.737835 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32484 episodes
GETTING ACTION FROM:
action 4, numVisits=32470, meanQ=7.672317, numObservations: 9
action 5, numVisits=9, meanQ=5.443333, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.68128 0.288095 0.97056 0.718845 0.68704 0.247682 0.304961 0.58024 0.435806 0.737835 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 46
Initial state: 0 0.916457 0.243117 0.303359 0.566046 0.0355034 0.921925 0.380811 0.685796 0.661625 0.693533 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32579 episodes
GETTING ACTION FROM:
action 1, numVisits=32571, meanQ=7.956326, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.916457 0.243117 0.303359 0.566046 0.0355034 0.921925 0.380811 0.685796 0.661625 0.693533 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 47
Initial state: 0 0.122298 0.415009 0.867093 0.953152 0.35373 0.570546 0.494837 0.386539 0.415024 0.194669 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32347 episodes
GETTING ACTION FROM:
action 1, numVisits=32322, meanQ=7.561511, numObservations: 9
action 2, numVisits=16, meanQ=5.624381, numObservations: 7
action 3, numVisits=5, meanQ=4.400000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.122298 0.415009 0.867093 0.953152 0.35373 0.570546 0.494837 0.386539 0.415024 0.194669 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=3116, meanQ=9.117610, numObservations: 9
action 2, numVisits=9, meanQ=7.218889, numObservations: 6
action 4, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 12116 episodes
GETTING ACTION FROM:
action 5, numVisits=14942, meanQ=8.231516, numObservations: 9
action 4, numVisits=190, meanQ=7.181661, numObservations: 9
action 2, numVisits=100, meanQ=6.829056, numObservations: 9
action 0, numVisits=7, meanQ=-1.292857, numObservations: 7
action -1, numVisits=7, meanQ=-1.292857, numObservations: 7
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.122298 0.415009 0.867093 0.953152 0.35373 0.570546 0.494837 0.386539 0.415024 0.194669 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 48
Initial state: 0 0.491202 0.688962 0.536714 0.383318 0.581796 0.852606 0.394383 0.583245 0.226735 0.0197238 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32451 episodes
GETTING ACTION FROM:
action 2, numVisits=32440, meanQ=7.800994, numObservations: 9
action 4, numVisits=6, meanQ=1.833333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.491202 0.688962 0.536714 0.383318 0.581796 0.852606 0.394383 0.583245 0.226735 0.0197238 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 49
Initial state: 0 0.345166 0.58867 0.981108 0.242889 0.859337 0.745934 0.656736 0.200628 0.775455 0.36271 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32483 episodes
GETTING ACTION FROM:
action 2, numVisits=32411, meanQ=7.695395, numObservations: 9
action 3, numVisits=36, meanQ=4.494447, numObservations: 8
action 5, numVisits=25, meanQ=4.489212, numObservations: 8
action 1, numVisits=8, meanQ=3.000000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.345166 0.58867 0.981108 0.242889 0.859337 0.745934 0.656736 0.200628 0.775455 0.36271 w: 1
Observation: 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=745, meanQ=7.980445, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 3, numVisits=2, meanQ=-7.005000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 17997 episodes
GETTING ACTION FROM:
action 5, numVisits=18276, meanQ=7.419179, numObservations: 9
action -1, numVisits=318, meanQ=-4.118433, numObservations: 145
action 3, numVisits=2, meanQ=-7.005000, numObservations: 1
action 0, numVisits=161, meanQ=-7.665906, numObservations: 86
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.345166 0.58867 0.981108 0.242889 0.859337 0.745934 0.656736 0.200628 0.775455 0.36271 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 50
Initial state: 0 0.455024 0.818067 0.400687 0.502485 0.737863 0.734451 0.166388 0.706541 0.0429131 0.720106 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30879 episodes
GETTING ACTION FROM:
action 4, numVisits=30856, meanQ=7.932455, numObservations: 9
action 3, numVisits=13, meanQ=0.693085, numObservations: 6
action 5, numVisits=4, meanQ=-0.500000, numObservations: 3
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.455024 0.818067 0.400687 0.502485 0.737863 0.734451 0.166388 0.706541 0.0429131 0.720106 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
[32m ProblemEnvironment.hpp 351: Done.[39m
