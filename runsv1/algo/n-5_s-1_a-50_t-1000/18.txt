Run # 1
Initial state: 0 0.129913 0.304157 0.70066 0.0445896 0.867047 0.677502 0.763946 0.353396 0.551291 0.468214 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28033 episodes
GETTING ACTION FROM:
action 1, numVisits=28023, meanQ=9.279828, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.129913 0.304157 0.70066 0.0445896 0.867047 0.677502 0.763946 0.353396 0.551291 0.468214 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=4349, meanQ=10.302736, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 8078 episodes
GETTING ACTION FROM:
action 3, numVisits=12388, meanQ=9.605812, numObservations: 9
action 2, numVisits=25, meanQ=5.103452, numObservations: 7
action 5, numVisits=4, meanQ=-0.252500, numObservations: 3
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.175000, numObservations: 6
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 3
Next state: 1 0.129913 0.304157 0.70066 0.0445896 0.867047 0.677502 0.763946 0.353396 0.551291 0.468214 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 2
Initial state: 0 0.17131 0.393145 0.505068 0.553014 0.279503 0.103751 0.24193 0.196994 0.0815928 0.430388 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27721 episodes
GETTING ACTION FROM:
action 2, numVisits=27715, meanQ=9.557395, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.17131 0.393145 0.505068 0.553014 0.279503 0.103751 0.24193 0.196994 0.0815928 0.430388 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 3
Initial state: 0 0.439165 0.394578 0.567856 0.482815 0.677543 0.197395 0.464146 0.927691 0.676991 0.733333 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28275 episodes
GETTING ACTION FROM:
action 3, numVisits=28255, meanQ=9.132307, numObservations: 9
action -1, numVisits=5, meanQ=-1.010000, numObservations: 5
action 0, numVisits=5, meanQ=-1.010000, numObservations: 5
action 1, numVisits=6, meanQ=-1.666667, numObservations: 4
action 2, numVisits=2, meanQ=-7.500000, numObservations: 2
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.439165 0.394578 0.567856 0.482815 0.677543 0.197395 0.464146 0.927691 0.676991 0.733333 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 4
Initial state: 0 0.315944 0.996153 0.536504 0.487154 0.47786 0.931702 0.746131 0.215246 0.0628627 0.66933 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28561 episodes
GETTING ACTION FROM:
action 3, numVisits=28549, meanQ=9.003315, numObservations: 9
action 5, numVisits=7, meanQ=6.282857, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.315944 0.996153 0.536504 0.487154 0.47786 0.931702 0.746131 0.215246 0.0628627 0.66933 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 5
Initial state: 0 0.883603 0.525168 0.0849549 0.749104 0.0320828 0.262714 0.782321 0.391692 0.569945 0.598425 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28212 episodes
GETTING ACTION FROM:
action 4, numVisits=28177, meanQ=8.913711, numObservations: 9
action 3, numVisits=24, meanQ=4.791667, numObservations: 8
action 5, numVisits=7, meanQ=4.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 2 0.883603 0.525168 0.0849549 0.749104 0.0320828 0.262714 0.782321 0.391692 0.569945 0.598425 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 6
Initial state: 0 0.524735 0.499244 0.00352452 0.168679 0.783436 0.142643 0.0106447 0.708705 0.378213 0.715273 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28418 episodes
GETTING ACTION FROM:
action 5, numVisits=28400, meanQ=9.094470, numObservations: 9
action 3, numVisits=13, meanQ=4.924623, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.524735 0.499244 0.00352452 0.168679 0.783436 0.142643 0.0106447 0.708705 0.378213 0.715273 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 7
Initial state: 0 0.742921 0.999167 0.00676282 0.683764 0.529482 0.491279 0.141616 0.28124 0.816911 0.0937289 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27680 episodes
GETTING ACTION FROM:
action 3, numVisits=27661, meanQ=9.044426, numObservations: 9
action 2, numVisits=10, meanQ=6.400010, numObservations: 7
action 1, numVisits=3, meanQ=4.340033, numObservations: 2
action 4, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.742921 0.999167 0.00676282 0.683764 0.529482 0.491279 0.141616 0.28124 0.816911 0.0937289 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 8
Initial state: 0 0.788415 0.161815 0.459774 0.225608 0.833078 0.820154 0.513477 0.5839 0.694643 0.509412 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27520 episodes
GETTING ACTION FROM:
action 2, numVisits=27497, meanQ=9.348604, numObservations: 9
action 4, numVisits=14, meanQ=7.363571, numObservations: 8
action 5, numVisits=5, meanQ=4.400000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.788415 0.161815 0.459774 0.225608 0.833078 0.820154 0.513477 0.5839 0.694643 0.509412 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 9
Initial state: 0 0.615204 0.0378013 0.517573 0.556395 0.298456 0.328118 0.280056 0.516975 0.588058 0.505982 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27068 episodes
GETTING ACTION FROM:
action 1, numVisits=27058, meanQ=9.266741, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.615204 0.0378013 0.517573 0.556395 0.298456 0.328118 0.280056 0.516975 0.588058 0.505982 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 10
Initial state: 0 0.0209904 0.308425 0.645049 0.153215 0.794511 0.977251 0.567881 0.861125 0.469304 0.570159 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28543 episodes
GETTING ACTION FROM:
action 2, numVisits=28463, meanQ=9.368093, numObservations: 9
action 5, numVisits=34, meanQ=6.535897, numObservations: 9
action 1, numVisits=38, meanQ=6.503703, numObservations: 9
action 4, numVisits=5, meanQ=4.400000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 2 0.0209904 0.308425 0.645049 0.153215 0.794511 0.977251 0.567881 0.861125 0.469304 0.570159 w: 1
Observation: 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 11
Initial state: 0 0.933604 0.0649255 0.121575 0.650321 0.524218 0.625641 0.929101 0.632513 0.505252 0.0822318 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28178 episodes
GETTING ACTION FROM:
action 5, numVisits=28162, meanQ=9.426673, numObservations: 9
action 2, numVisits=9, meanQ=6.777789, numObservations: 5
action 4, numVisits=3, meanQ=5.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.933604 0.0649255 0.121575 0.650321 0.524218 0.625641 0.929101 0.632513 0.505252 0.0822318 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=401, meanQ=11.153416, numObservations: 9
action 0, numVisits=19, meanQ=-1.218942, numObservations: 18
action -1, numVisits=7, meanQ=-2.707143, numObservations: 6
action 1, numVisits=2, meanQ=-4.994950, numObservations: 1
action 3, numVisits=3, meanQ=-5.673333, numObservations: 3
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 12732 episodes
GETTING ACTION FROM:
action 4, numVisits=13025, meanQ=7.220450, numObservations: 9
action 1, numVisits=2, meanQ=-4.994950, numObservations: 1
action 3, numVisits=3, meanQ=-5.673333, numObservations: 3
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=72, meanQ=-16.217677, numObservations: 65
action 0, numVisits=62, meanQ=-18.102963, numObservations: 44
action: 4
Next state: 1 0.933604 0.0649255 0.121575 0.650321 0.524218 0.625641 0.929101 0.632513 0.505252 0.0822318 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 12
Initial state: 0 0.537193 0.485275 0.776821 0.220236 0.23151 0.348125 0.554002 0.103448 0.0374998 0.281574 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28212 episodes
GETTING ACTION FROM:
action 4, numVisits=28200, meanQ=8.886798, numObservations: 9
action 1, numVisits=5, meanQ=4.400000, numObservations: 4
action 3, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 2 0.537193 0.485275 0.776821 0.220236 0.23151 0.348125 0.554002 0.103448 0.0374998 0.281574 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 13
Initial state: 0 0.984457 0.916348 0.567818 0.477651 0.0824377 0.653404 0.43223 0.126202 0.654814 0.54714 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28332 episodes
GETTING ACTION FROM:
action 1, numVisits=28323, meanQ=9.213572, numObservations: 9
action 3, numVisits=4, meanQ=1.497500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.984457 0.916348 0.567818 0.477651 0.0824377 0.653404 0.43223 0.126202 0.654814 0.54714 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 14
Initial state: 0 0.715324 0.125479 0.180686 0.750865 0.881963 0.314106 0.572638 0.495576 0.211896 0.641691 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28567 episodes
GETTING ACTION FROM:
action 3, numVisits=28555, meanQ=9.485071, numObservations: 9
action 4, numVisits=5, meanQ=6.196000, numObservations: 4
action 2, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 2 0.715324 0.125479 0.180686 0.750865 0.881963 0.314106 0.572638 0.495576 0.211896 0.641691 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 15
Initial state: 0 0.571548 0.747539 0.136948 0.26372 0.496982 0.533333 0.284632 0.18711 0.703655 0.63732 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28539 episodes
GETTING ACTION FROM:
action 2, numVisits=28533, meanQ=9.075651, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.571548 0.747539 0.136948 0.26372 0.496982 0.533333 0.284632 0.18711 0.703655 0.63732 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=4378, meanQ=10.560818, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 8672 episodes
GETTING ACTION FROM:
action 5, numVisits=13043, meanQ=10.204018, numObservations: 9
action 0, numVisits=5, meanQ=-1.208000, numObservations: 5
action -1, numVisits=4, meanQ=-1.257500, numObservations: 4
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.571548 0.747539 0.136948 0.26372 0.496982 0.533333 0.284632 0.18711 0.703655 0.63732 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 16
Initial state: 0 0.792721 0.121603 0.339007 0.631893 0.0910869 0.502369 0.100781 0.680006 0.531347 0.518798 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28217 episodes
GETTING ACTION FROM:
action 4, numVisits=28209, meanQ=9.299683, numObservations: 9
action 3, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.792721 0.121603 0.339007 0.631893 0.0910869 0.502369 0.100781 0.680006 0.531347 0.518798 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=4324, meanQ=10.461504, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 6582 episodes
GETTING ACTION FROM:
action 5, numVisits=10863, meanQ=9.454625, numObservations: 9
action 0, numVisits=21, meanQ=-1.497183, numObservations: 19
action -1, numVisits=23, meanQ=-1.742170, numObservations: 21
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=2, meanQ=-5.283402, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.792721 0.121603 0.339007 0.631893 0.0910869 0.502369 0.100781 0.680006 0.531347 0.518798 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 17
Initial state: 0 0.570794 0.499356 0.316979 0.502198 0.163008 0.595703 0.682173 0.79816 0.857321 0.991349 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28662 episodes
GETTING ACTION FROM:
action 5, numVisits=28653, meanQ=9.310416, numObservations: 9
action 3, numVisits=4, meanQ=1.250000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 1 0.570794 0.499356 0.316979 0.502198 0.163008 0.595703 0.682173 0.79816 0.857321 0.991349 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 18
Initial state: 0 0.259798 0.726471 0.045939 0.218208 0.857377 0.206141 0.557577 0.591589 0.389565 0.0586559 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27545 episodes
GETTING ACTION FROM:
action 1, numVisits=27531, meanQ=9.197556, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 3, numVisits=5, meanQ=-1.200000, numObservations: 4
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.259798 0.726471 0.045939 0.218208 0.857377 0.206141 0.557577 0.591589 0.389565 0.0586559 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 19
Initial state: 0 0.356559 0.721891 0.0648527 0.0578154 0.455383 0.258873 0.614363 0.341719 0.527723 0.502548 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27780 episodes
GETTING ACTION FROM:
action 3, numVisits=27760, meanQ=9.227173, numObservations: 9
action -1, numVisits=6, meanQ=-1.010000, numObservations: 6
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 4, numVisits=5, meanQ=-2.600000, numObservations: 4
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.356559 0.721891 0.0648527 0.0578154 0.455383 0.258873 0.614363 0.341719 0.527723 0.502548 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=2683, meanQ=10.406879, numObservations: 9
action 1, numVisits=18, meanQ=6.331111, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 10691 episodes
GETTING ACTION FROM:
action 4, numVisits=10295, meanQ=11.171039, numObservations: 9
action 3, numVisits=2684, meanQ=10.405262, numObservations: 9
action 1, numVisits=192, meanQ=-1.356909, numObservations: 9
action 5, numVisits=76, meanQ=-2.954074, numObservations: 9
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=103, meanQ=-11.928693, numObservations: 70
action -1, numVisits=46, meanQ=-24.149202, numObservations: 36
action: 4
Next state: 0 0.356559 0.721891 0.0648527 0.0578154 0.455383 0.258873 0.614363 0.341719 0.527723 0.502548 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=828, meanQ=11.839911, numObservations: 9
action 5, numVisits=1, meanQ=-9.512671, numObservations: 1
action 4, numVisits=1, meanQ=-9.578405, numObservations: 1
action 0, numVisits=81, meanQ=-12.098186, numObservations: 42
action -1, numVisits=46, meanQ=-22.795386, numObservations: 25
action 1, numVisits=36, meanQ=-24.034390, numObservations: 9
action 3, numVisits=1, meanQ=-1068.558733, numObservations: 1
Sampled 11616 episodes
GETTING ACTION FROM:
action 2, numVisits=12444, meanQ=14.234694, numObservations: 9
action 5, numVisits=1, meanQ=-9.512671, numObservations: 1
action 4, numVisits=1, meanQ=-9.578405, numObservations: 1
action 0, numVisits=81, meanQ=-12.098186, numObservations: 42
action -1, numVisits=46, meanQ=-22.795386, numObservations: 25
action 1, numVisits=36, meanQ=-24.034390, numObservations: 9
action 3, numVisits=1, meanQ=-1068.558733, numObservations: 1
action: 2
Next state: 0 0.356559 0.721891 0.0648527 0.0578154 0.455383 0.258873 0.614363 0.341719 0.527723 0.502548 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=393, meanQ=14.603747, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 4, numVisits=1, meanQ=-10.191081, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-1068.506805, numObservations: 1
Sampled 12517 episodes
GETTING ACTION FROM:
action 1, numVisits=12910, meanQ=14.799659, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 4, numVisits=1, meanQ=-10.191081, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-1068.506805, numObservations: 1
action: 1
Next state: 0 0.356559 0.721891 0.0648527 0.0578154 0.455383 0.258873 0.614363 0.341719 0.527723 0.502548 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 3, numVisits=1, meanQ=24.000000, numObservations: 1
action 0, numVisits=299, meanQ=4.497579, numObservations: 44
action 2, numVisits=1, meanQ=-10.089520, numObservations: 1
action 5, numVisits=1, meanQ=-10.955258, numObservations: 1
action -1, numVisits=11, meanQ=-41.282925, numObservations: 6
action 1, numVisits=3, meanQ=-174.647610, numObservations: 1
action 4, numVisits=1, meanQ=-538.631544, numObservations: 1
Sampled 4202 episodes
GETTING ACTION FROM:
action 3, numVisits=107, meanQ=15.175549, numObservations: 8
action 0, numVisits=4395, meanQ=3.178890, numObservations: 166
action 2, numVisits=1, meanQ=-10.089520, numObservations: 1
action 5, numVisits=1, meanQ=-10.955258, numObservations: 1
action -1, numVisits=11, meanQ=-41.282925, numObservations: 6
action 1, numVisits=3, meanQ=-174.647610, numObservations: 1
action 4, numVisits=1, meanQ=-538.631544, numObservations: 1
action: 3
Next state: 0 0.356559 0.721891 0.0648527 0.0578154 0.455383 0.258873 0.614363 0.341719 0.527723 0.502548 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 5
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 38995 episodes
GETTING ACTION FROM:
action 5, numVisits=38986, meanQ=21.972814, numObservations: 9
action 3, numVisits=3, meanQ=12.333333, numObservations: 2
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-2.000000, numObservations: 1
action 0, numVisits=1, meanQ=-2.000000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.356559 0.721891 0.0648527 0.0578154 0.455383 0.258873 0.614363 0.341719 0.527723 0.502548 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 3.21978
Run # 20
Initial state: 0 0.725719 0.230448 0.50652 0.577938 0.758661 0.888188 0.381249 0.954432 0.391249 0.664511 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28407 episodes
GETTING ACTION FROM:
action 3, numVisits=28401, meanQ=9.369467, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.725719 0.230448 0.50652 0.577938 0.758661 0.888188 0.381249 0.954432 0.391249 0.664511 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 21
Initial state: 0 0.293521 0.518772 0.693128 0.752503 0.00710243 0.369802 0.00918097 0.446088 0.567603 0.495077 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28465 episodes
GETTING ACTION FROM:
action 4, numVisits=28452, meanQ=9.182346, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 2, numVisits=2, meanQ=-4.000000, numObservations: 2
action 3, numVisits=2, meanQ=-4.000000, numObservations: 2
action 1, numVisits=2, meanQ=-7.500000, numObservations: 2
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.293521 0.518772 0.693128 0.752503 0.00710243 0.369802 0.00918097 0.446088 0.567603 0.495077 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=4379, meanQ=10.723751, numObservations: 9
action 5, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 9067 episodes
GETTING ACTION FROM:
action 1, numVisits=13434, meanQ=9.663389, numObservations: 9
action 5, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=7, meanQ=-1.151429, numObservations: 6
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.293521 0.518772 0.693128 0.752503 0.00710243 0.369802 0.00918097 0.446088 0.567603 0.495077 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=344, meanQ=10.176705, numObservations: 9
action 5, numVisits=20, meanQ=7.973515, numObservations: 7
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 6589 episodes
GETTING ACTION FROM:
action 3, numVisits=6925, meanQ=10.941604, numObservations: 9
action 5, numVisits=23, meanQ=6.836100, numObservations: 7
action 0, numVisits=5, meanQ=-1.406000, numObservations: 5
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=6, meanQ=-3.184150, numObservations: 5
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.293521 0.518772 0.693128 0.752503 0.00710243 0.369802 0.00918097 0.446088 0.567603 0.495077 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -18.7411
Run # 22
Initial state: 0 0.598429 0.851359 0.181432 0.451933 0.82721 0.66581 0.241762 0.630942 0.544898 0.545025 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27029 episodes
GETTING ACTION FROM:
action 1, numVisits=27015, meanQ=9.047025, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 4, numVisits=5, meanQ=-1.200000, numObservations: 4
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.598429 0.851359 0.181432 0.451933 0.82721 0.66581 0.241762 0.630942 0.544898 0.545025 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 23
Initial state: 0 0.36025 0.0927835 0.770136 0.561064 0.806865 0.189139 0.113823 0.256544 0.552428 0.535385 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28198 episodes
GETTING ACTION FROM:
action 3, numVisits=28186, meanQ=9.162908, numObservations: 9
action 4, numVisits=4, meanQ=2.502525, numObservations: 3
action 1, numVisits=4, meanQ=1.250000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 2 0.36025 0.0927835 0.770136 0.561064 0.806865 0.189139 0.113823 0.256544 0.552428 0.535385 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 24
Initial state: 0 0.628342 0.944553 0.570592 0.540267 0.679923 0.228514 0.761475 0.131217 0.0540746 0.796373 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27717 episodes
GETTING ACTION FROM:
action 5, numVisits=27711, meanQ=9.516805, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.628342 0.944553 0.570592 0.540267 0.679923 0.228514 0.761475 0.131217 0.0540746 0.796373 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=4236, meanQ=11.309795, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 8500 episodes
GETTING ACTION FROM:
action 2, numVisits=12736, meanQ=10.121203, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.628342 0.944553 0.570592 0.540267 0.679923 0.228514 0.761475 0.131217 0.0540746 0.796373 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 25
Initial state: 0 0.525714 0.499578 0.757287 0.864484 0.212814 0.968801 0.602669 0.533939 0.138324 0.866405 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28540 episodes
GETTING ACTION FROM:
action 2, numVisits=28532, meanQ=9.403800, numObservations: 9
action 5, numVisits=3, meanQ=5.663333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.525714 0.499578 0.757287 0.864484 0.212814 0.968801 0.602669 0.533939 0.138324 0.866405 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 26
Initial state: 0 0.0855682 0.706116 0.713499 0.252508 0.246306 0.987382 0.487595 0.516111 0.960023 0.732986 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28533 episodes
GETTING ACTION FROM:
action 4, numVisits=28527, meanQ=9.303549, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.0855682 0.706116 0.713499 0.252508 0.246306 0.987382 0.487595 0.516111 0.960023 0.732986 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 27
Initial state: 0 0.0297121 0.794852 0.107111 0.0630331 0.0884473 0.947438 0.528565 0.584648 0.105873 0.523155 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28678 episodes
GETTING ACTION FROM:
action 5, numVisits=28665, meanQ=9.419753, numObservations: 9
action 1, numVisits=8, meanQ=1.001263, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 0 0.0297121 0.794852 0.107111 0.0630331 0.0884473 0.947438 0.528565 0.584648 0.105873 0.523155 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=947, meanQ=10.879423, numObservations: 9
action 4, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 8286 episodes
GETTING ACTION FROM:
action 1, numVisits=9095, meanQ=10.026779, numObservations: 9
action -1, numVisits=44, meanQ=-1.247366, numObservations: 36
action 0, numVisits=28, meanQ=-1.469996, numObservations: 26
action 4, numVisits=69, meanQ=-2.933513, numObservations: 9
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=2, meanQ=-10.052914, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.0297121 0.794852 0.107111 0.0630331 0.0884473 0.947438 0.528565 0.584648 0.105873 0.523155 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 28
Initial state: 0 0.587496 0.961818 0.521099 0.558733 0.339241 0.138444 0.291011 0.371297 0.248712 0.882079 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28515 episodes
GETTING ACTION FROM:
action 2, numVisits=28507, meanQ=9.107694, numObservations: 9
action 4, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.587496 0.961818 0.521099 0.558733 0.339241 0.138444 0.291011 0.371297 0.248712 0.882079 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 29
Initial state: 0 0.122031 0.318857 0.370172 0.499997 0.00778659 0.403145 0.444334 0.894043 0.490073 0.557872 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28523 episodes
GETTING ACTION FROM:
action 4, numVisits=28482, meanQ=9.252354, numObservations: 9
action 2, numVisits=31, meanQ=4.180655, numObservations: 9
action 5, numVisits=3, meanQ=0.666667, numObservations: 3
action 3, numVisits=4, meanQ=-0.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.122031 0.318857 0.370172 0.499997 0.00778659 0.403145 0.444334 0.894043 0.490073 0.557872 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 30
Initial state: 0 0.728386 0.82588 0.542251 0.479815 0.150729 0.967665 0.865677 0.562167 0.732871 0.544737 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28359 episodes
GETTING ACTION FROM:
action 1, numVisits=28308, meanQ=9.276582, numObservations: 9
action 0, numVisits=29, meanQ=-0.498614, numObservations: 26
action -1, numVisits=10, meanQ=-1.010000, numObservations: 10
action 5, numVisits=9, meanQ=-1.109989, numObservations: 5
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.728386 0.82588 0.542251 0.479815 0.150729 0.967665 0.865677 0.562167 0.732871 0.544737 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 31
Initial state: 0 0.646178 0.397453 0.424682 0.422059 0.668713 0.857804 0.504854 0.61218 0.172625 0.764908 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28451 episodes
GETTING ACTION FROM:
action 4, numVisits=28436, meanQ=8.814788, numObservations: 9
action 5, numVisits=10, meanQ=3.700000, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.646178 0.397453 0.424682 0.422059 0.668713 0.857804 0.504854 0.61218 0.172625 0.764908 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 32
Initial state: 0 0.0309779 0.742087 0.0317812 0.630508 0.635852 0.919279 0.522179 0.579962 0.306695 0.416953 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26555 episodes
GETTING ACTION FROM:
action 3, numVisits=26542, meanQ=9.297862, numObservations: 9
action 2, numVisits=6, meanQ=3.165000, numObservations: 5
action 5, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.0309779 0.742087 0.0317812 0.630508 0.635852 0.919279 0.522179 0.579962 0.306695 0.416953 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 33
Initial state: 0 0.540352 0.57163 0.370544 0.769833 0.917627 0.450202 0.7689 0.428645 0.338619 0.0256263 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28434 episodes
GETTING ACTION FROM:
action 1, numVisits=28417, meanQ=9.032792, numObservations: 9
action 4, numVisits=6, meanQ=3.165000, numObservations: 6
action 2, numVisits=7, meanQ=1.574300, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.540352 0.57163 0.370544 0.769833 0.917627 0.450202 0.7689 0.428645 0.338619 0.0256263 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=392, meanQ=19.941471, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 26924 episodes
GETTING ACTION FROM:
action 1, numVisits=417, meanQ=20.006754, numObservations: 9
action 5, numVisits=26890, meanQ=13.020230, numObservations: 9
action -1, numVisits=6, meanQ=-1.835000, numObservations: 5
action 0, numVisits=6, meanQ=-1.835000, numObservations: 6
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.540352 0.57163 0.370544 0.769833 0.917627 0.450202 0.7689 0.428645 0.338619 0.0256263 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 34
Initial state: 0 0.413377 0.988925 0.288485 0.630965 0.652302 0.259323 0.472525 0.62505 0.293954 0.305147 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28445 episodes
GETTING ACTION FROM:
action 2, numVisits=28439, meanQ=9.201738, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.413377 0.988925 0.288485 0.630965 0.652302 0.259323 0.472525 0.62505 0.293954 0.305147 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=2705, meanQ=11.494431, numObservations: 9
action 4, numVisits=17, meanQ=5.881188, numObservations: 7
action 1, numVisits=20, meanQ=5.524500, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 12961 episodes
GETTING ACTION FROM:
action 3, numVisits=15662, meanQ=12.756610, numObservations: 9
action 4, numVisits=17, meanQ=5.881188, numObservations: 7
action 1, numVisits=20, meanQ=5.524500, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.413377 0.988925 0.288485 0.630965 0.652302 0.259323 0.472525 0.62505 0.293954 0.305147 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 35
Initial state: 0 0.387091 0.980593 0.736814 0.977545 0.846432 0.438194 0.0670595 0.274463 0.50615 0.546421 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26428 episodes
GETTING ACTION FROM:
action 2, numVisits=26392, meanQ=9.295380, numObservations: 9
action 4, numVisits=23, meanQ=4.141757, numObservations: 8
action 1, numVisits=7, meanQ=2.857157, numObservations: 5
action 5, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.387091 0.980593 0.736814 0.977545 0.846432 0.438194 0.0670595 0.274463 0.50615 0.546421 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 36
Initial state: 0 0.300072 0.442313 0.256936 0.325254 0.572273 0.523793 0.868851 0.671827 0.134903 0.115019 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27560 episodes
GETTING ACTION FROM:
action 2, numVisits=27516, meanQ=9.543205, numObservations: 9
action 4, numVisits=32, meanQ=6.671572, numObservations: 8
action 3, numVisits=8, meanQ=4.997500, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.300072 0.442313 0.256936 0.325254 0.572273 0.523793 0.868851 0.671827 0.134903 0.115019 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=4252, meanQ=10.779498, numObservations: 9
action 5, numVisits=59, meanQ=8.663229, numObservations: 9
action 3, numVisits=4, meanQ=6.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 8906 episodes
GETTING ACTION FROM:
action 4, numVisits=13148, meanQ=9.924313, numObservations: 9
action 5, numVisits=59, meanQ=8.663229, numObservations: 9
action 3, numVisits=7, meanQ=5.000000, numObservations: 5
action -1, numVisits=5, meanQ=-1.208000, numObservations: 5
action 0, numVisits=4, meanQ=-1.257500, numObservations: 4
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 1 0.300072 0.442313 0.256936 0.325254 0.572273 0.523793 0.868851 0.671827 0.134903 0.115019 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 37
Initial state: 0 0.188722 0.715799 0.672195 0.955371 0.671498 0.824979 0.595349 0.775312 0.525279 0.540664 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28412 episodes
GETTING ACTION FROM:
action 3, numVisits=28391, meanQ=9.088933, numObservations: 9
action 1, numVisits=7, meanQ=0.000000, numObservations: 3
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 2, numVisits=6, meanQ=-1.666667, numObservations: 4
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.188722 0.715799 0.672195 0.955371 0.671498 0.824979 0.595349 0.775312 0.525279 0.540664 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 38
Initial state: 0 0.141038 0.130001 0.573942 0.593851 0.209881 0.463682 0.611846 0.287112 0.791143 0.987521 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17917 episodes
GETTING ACTION FROM:
action -1, numVisits=17870, meanQ=13.746595, numObservations: 243
action 0, numVisits=30, meanQ=-1.274660, numObservations: 28
action 1, numVisits=11, meanQ=-3.363636, numObservations: 6
action 2, numVisits=3, meanQ=-6.333333, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.141038 0.130001 0.573942 0.593851 0.209881 0.463682 0.611846 0.287112 0.791143 0.987521 w: 1
Observation: 0 1 0 2 0 1 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=119, meanQ=19.707144, numObservations: 9
action 4, numVisits=3, meanQ=12.333333, numObservations: 2
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 37960 episodes
GETTING ACTION FROM:
action 2, numVisits=38079, meanQ=22.202710, numObservations: 9
action 4, numVisits=3, meanQ=12.333333, numObservations: 2
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.141038 0.130001 0.573942 0.593851 0.209881 0.463682 0.611846 0.287112 0.791143 0.987521 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 39
Initial state: 0 0.762087 0.0101344 0.899778 0.410458 0.014754 0.132903 0.552855 0.567815 0.6541 0.676695 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28224 episodes
GETTING ACTION FROM:
action 2, numVisits=28218, meanQ=9.266533, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.762087 0.0101344 0.899778 0.410458 0.014754 0.132903 0.552855 0.567815 0.6541 0.676695 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 40
Initial state: 0 0.790448 0.0165909 0.563785 0.27086 0.496883 0.595361 0.205399 0.12938 0.200543 0.430763 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28286 episodes
GETTING ACTION FROM:
action 1, numVisits=28271, meanQ=9.298781, numObservations: 9
action 2, numVisits=7, meanQ=6.141429, numObservations: 5
action 5, numVisits=4, meanQ=2.502525, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.790448 0.0165909 0.563785 0.27086 0.496883 0.595361 0.205399 0.12938 0.200543 0.430763 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 41
Initial state: 0 0.470996 0.940401 0.719807 0.0813018 0.677098 0.322678 0.534796 0.538856 0.746292 0.793649 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27161 episodes
GETTING ACTION FROM:
action 5, numVisits=27146, meanQ=9.482087, numObservations: 9
action 2, numVisits=5, meanQ=4.400000, numObservations: 4
action 3, numVisits=6, meanQ=4.340033, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 1 0.470996 0.940401 0.719807 0.0813018 0.677098 0.322678 0.534796 0.538856 0.746292 0.793649 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 42
Initial state: 0 0.558602 0.175565 0.279882 0.536127 0.554892 0.583809 0.481155 0.648676 0.542948 0.0275472 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28495 episodes
GETTING ACTION FROM:
action 4, numVisits=28481, meanQ=9.083205, numObservations: 9
action 5, numVisits=9, meanQ=3.220000, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.558602 0.175565 0.279882 0.536127 0.554892 0.583809 0.481155 0.648676 0.542948 0.0275472 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 43
Initial state: 0 0.618099 0.278749 0.944996 0.676425 0.864093 0.129797 0.853417 0.314902 0.500914 0.536371 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28532 episodes
GETTING ACTION FROM:
action 5, numVisits=28526, meanQ=9.196803, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.618099 0.278749 0.944996 0.676425 0.864093 0.129797 0.853417 0.314902 0.500914 0.536371 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 44
Initial state: 0 0.814866 0.363793 0.266147 0.146305 0.564494 0.58516 0.627612 0.282574 0.393701 0.335075 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27759 episodes
GETTING ACTION FROM:
action 2, numVisits=27724, meanQ=9.328342, numObservations: 9
action 4, numVisits=30, meanQ=4.168013, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.814866 0.363793 0.266147 0.146305 0.564494 0.58516 0.627612 0.282574 0.393701 0.335075 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=4262, meanQ=10.884170, numObservations: 9
action 4, numVisits=26, meanQ=6.999242, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 8000 episodes
GETTING ACTION FROM:
action 3, numVisits=12220, meanQ=10.156800, numObservations: 9
action 4, numVisits=60, meanQ=7.611271, numObservations: 9
action 0, numVisits=5, meanQ=-1.010000, numObservations: 5
action -1, numVisits=5, meanQ=-1.208000, numObservations: 5
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.814866 0.363793 0.266147 0.146305 0.564494 0.58516 0.627612 0.282574 0.393701 0.335075 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 45
Initial state: 0 0.940654 0.543839 0.560201 0.571408 0.276897 0.885837 0.0564986 0.623493 0.949561 0.629239 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27930 episodes
GETTING ACTION FROM:
action 2, numVisits=27921, meanQ=8.946410, numObservations: 9
action 4, numVisits=4, meanQ=-0.500000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.940654 0.543839 0.560201 0.571408 0.276897 0.885837 0.0564986 0.623493 0.949561 0.629239 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 46
Initial state: 0 0.523647 0.507284 0.389752 0.645777 0.306561 0.790866 0.763339 0.156957 0.446097 0.413537 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28430 episodes
GETTING ACTION FROM:
action 3, numVisits=28422, meanQ=9.130379, numObservations: 9
action 5, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.523647 0.507284 0.389752 0.645777 0.306561 0.790866 0.763339 0.156957 0.446097 0.413537 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=2835, meanQ=9.721193, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 10704 episodes
GETTING ACTION FROM:
action 2, numVisits=13533, meanQ=11.612753, numObservations: 9
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.257500, numObservations: 4
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.523647 0.507284 0.389752 0.645777 0.306561 0.790866 0.763339 0.156957 0.446097 0.413537 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=740, meanQ=10.959168, numObservations: 9
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 7541 episodes
GETTING ACTION FROM:
action 5, numVisits=8281, meanQ=14.897774, numObservations: 9
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.523647 0.507284 0.389752 0.645777 0.306561 0.790866 0.763339 0.156957 0.446097 0.413537 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -18.7411
Run # 47
Initial state: 0 0.770633 0.811947 0.0203059 0.221538 0.483176 0.613642 0.984248 0.346006 0.887849 0.00680176 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28489 episodes
GETTING ACTION FROM:
action 4, numVisits=28465, meanQ=9.258179, numObservations: 9
action 0, numVisits=11, meanQ=-1.010000, numObservations: 11
action -1, numVisits=9, meanQ=-1.231100, numObservations: 8
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.770633 0.811947 0.0203059 0.221538 0.483176 0.613642 0.984248 0.346006 0.887849 0.00680176 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 48
Initial state: 0 0.230893 0.29608 0.479999 0.513463 0.69386 0.721091 0.801078 0.127379 0.370852 0.0251264 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28351 episodes
GETTING ACTION FROM:
action 5, numVisits=28345, meanQ=9.240556, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.230893 0.29608 0.479999 0.513463 0.69386 0.721091 0.801078 0.127379 0.370852 0.0251264 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=4413, meanQ=9.933517, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 8922 episodes
GETTING ACTION FROM:
action 2, numVisits=8224, meanQ=9.234418, numObservations: 9
action 3, numVisits=5101, meanQ=8.906719, numObservations: 9
action -1, numVisits=6, meanQ=-1.175000, numObservations: 6
action 0, numVisits=6, meanQ=-1.341650, numObservations: 5
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 2
Next state: 1 0.230893 0.29608 0.479999 0.513463 0.69386 0.721091 0.801078 0.127379 0.370852 0.0251264 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 49
Initial state: 0 0.106422 0.436291 0.494353 0.497171 0.436066 0.306509 0.876293 0.822265 0.294043 0.997357 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28533 episodes
GETTING ACTION FROM:
action 2, numVisits=28512, meanQ=9.071571, numObservations: 9
action 4, numVisits=7, meanQ=5.141429, numObservations: 6
action 5, numVisits=5, meanQ=4.400000, numObservations: 3
action 3, numVisits=3, meanQ=3.000000, numObservations: 3
action 1, numVisits=4, meanQ=1.497500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.106422 0.436291 0.494353 0.497171 0.436066 0.306509 0.876293 0.822265 0.294043 0.997357 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=104, meanQ=9.610325, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 23134 episodes
GETTING ACTION FROM:
action 5, numVisits=23231, meanQ=12.144138, numObservations: 9
action 0, numVisits=5, meanQ=-1.406000, numObservations: 5
action -1, numVisits=4, meanQ=-1.752500, numObservations: 4
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.106422 0.436291 0.494353 0.497171 0.436066 0.306509 0.876293 0.822265 0.294043 0.997357 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 50
Initial state: 0 0.592583 0.333561 0.305905 0.284553 0.526638 0.482097 0.0972573 0.957943 0.160539 0.795766 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28555 episodes
GETTING ACTION FROM:
action 2, numVisits=28532, meanQ=9.143492, numObservations: 9
action 1, numVisits=18, meanQ=3.667228, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.592583 0.333561 0.305905 0.284553 0.526638 0.482097 0.0972573 0.957943 0.160539 0.795766 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
[32m ProblemEnvironment.hpp 351: Done.[39m
