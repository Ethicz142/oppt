Run # 1
Initial state: 0 0.446876 0.97929 0.820285 0.396643 0.354495 0.586204 0.982399 0.256275 0.470996 0.551656 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28528 episodes
GETTING ACTION FROM:
action 5, numVisits=28519, meanQ=8.657751, numObservations: 9
action 1, numVisits=4, meanQ=-0.500000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.446876 0.97929 0.820285 0.396643 0.354495 0.586204 0.982399 0.256275 0.470996 0.551656 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 2
Initial state: 0 0.456189 0.52795 0.360935 0.19941 0.818057 0.0372152 0.938636 0.487257 0.369264 0.761917 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30767 episodes
GETTING ACTION FROM:
action 1, numVisits=30752, meanQ=8.843220, numObservations: 9
action 2, numVisits=10, meanQ=5.700010, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.456189 0.52795 0.360935 0.19941 0.818057 0.0372152 0.938636 0.487257 0.369264 0.761917 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 3
Initial state: 0 0.425655 0.589812 0.0662946 0.20142 0.308052 0.625297 0.327052 0.365416 0.974259 0.415816 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30524 episodes
GETTING ACTION FROM:
action 1, numVisits=30516, meanQ=8.628202, numObservations: 9
action 2, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.425655 0.589812 0.0662946 0.20142 0.308052 0.625297 0.327052 0.365416 0.974259 0.415816 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 4
Initial state: 0 0.429967 0.624066 0.178157 0.873553 0.742964 0.501934 0.573589 0.323821 0.196404 0.150645 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30563 episodes
GETTING ACTION FROM:
action 5, numVisits=30538, meanQ=8.778159, numObservations: 9
action 3, numVisits=7, meanQ=2.857157, numObservations: 4
action 4, numVisits=7, meanQ=2.282857, numObservations: 6
action 1, numVisits=8, meanQ=2.125000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.429967 0.624066 0.178157 0.873553 0.742964 0.501934 0.573589 0.323821 0.196404 0.150645 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=3794, meanQ=9.898677, numObservations: 9
action 4, numVisits=131, meanQ=9.227675, numObservations: 9
action 2, numVisits=53, meanQ=8.544915, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 8561 episodes
GETTING ACTION FROM:
action 1, numVisits=12128, meanQ=9.250645, numObservations: 9
action 4, numVisits=252, meanQ=4.556887, numObservations: 9
action 2, numVisits=137, meanQ=3.667971, numObservations: 9
action -1, numVisits=12, meanQ=-1.092500, numObservations: 12
action 0, numVisits=12, meanQ=-1.175000, numObservations: 11
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.429967 0.624066 0.178157 0.873553 0.742964 0.501934 0.573589 0.323821 0.196404 0.150645 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 5
Initial state: 0 0.442622 0.609271 0.755234 0.219639 0.632599 0.0631897 0.978477 0.321142 0.0844446 0.816887 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30469 episodes
GETTING ACTION FROM:
action 3, numVisits=30463, meanQ=8.710851, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.442622 0.609271 0.755234 0.219639 0.632599 0.0631897 0.978477 0.321142 0.0844446 0.816887 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 6
Initial state: 0 0.266345 0.277919 0.032753 0.821611 0.355268 0.472737 0.470782 0.58316 0.0210116 0.214017 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30376 episodes
GETTING ACTION FROM:
action 5, numVisits=30368, meanQ=8.806916, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.266345 0.277919 0.032753 0.821611 0.355268 0.472737 0.470782 0.58316 0.0210116 0.214017 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=876, meanQ=9.201001, numObservations: 9
action 3, numVisits=15, meanQ=5.139340, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 11052 episodes
GETTING ACTION FROM:
action 4, numVisits=11801, meanQ=8.760524, numObservations: 9
action 3, numVisits=20, meanQ=2.854505, numObservations: 7
action 0, numVisits=15, meanQ=-2.198000, numObservations: 14
action 1, numVisits=82, meanQ=-3.643343, numObservations: 9
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=28, meanQ=-38.728478, numObservations: 25
action: 4
Next state: 1 0.266345 0.277919 0.032753 0.821611 0.355268 0.472737 0.470782 0.58316 0.0210116 0.214017 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 7
Initial state: 0 0.462091 0.480128 0.943875 0.873746 0.0432335 0.603994 0.282835 0.0530779 0.78361 0.610033 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30585 episodes
GETTING ACTION FROM:
action 2, numVisits=30573, meanQ=8.839765, numObservations: 9
action 5, numVisits=7, meanQ=1.998586, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.462091 0.480128 0.943875 0.873746 0.0432335 0.603994 0.282835 0.0530779 0.78361 0.610033 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 8
Initial state: 0 0.158689 0.362168 0.887646 0.287903 0.0760745 0.286089 0.389372 0.52249 0.598887 0.771778 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30458 episodes
GETTING ACTION FROM:
action 3, numVisits=30421, meanQ=8.727304, numObservations: 9
action 4, numVisits=15, meanQ=4.799347, numObservations: 7
action 1, numVisits=18, meanQ=4.417233, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.158689 0.362168 0.887646 0.287903 0.0760745 0.286089 0.389372 0.52249 0.598887 0.771778 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=3972, meanQ=9.278683, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 7996 episodes
GETTING ACTION FROM:
action 2, numVisits=11920, meanQ=9.631321, numObservations: 9
action 1, numVisits=39, meanQ=6.436882, numObservations: 8
action -1, numVisits=8, meanQ=-2.495000, numObservations: 7
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=2, meanQ=-7.005000, numObservations: 2
action 5, numVisits=2, meanQ=-7.005000, numObservations: 2
action 0, numVisits=2, meanQ=-531.252235, numObservations: 1
action: 2
Next state: 2 0.158689 0.362168 0.887646 0.287903 0.0760745 0.286089 0.389372 0.52249 0.598887 0.771778 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 9
Initial state: 0 0.783491 0.862725 0.473838 0.47579 0.0976907 0.122151 0.029957 0.0231904 0.505127 0.359509 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28833 episodes
GETTING ACTION FROM:
action 1, numVisits=28730, meanQ=7.904246, numObservations: 9
action 3, numVisits=86, meanQ=6.981750, numObservations: 9
action 2, numVisits=13, meanQ=5.931538, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.783491 0.862725 0.473838 0.47579 0.0976907 0.122151 0.029957 0.0231904 0.505127 0.359509 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 10
Initial state: 0 0.140267 0.264153 0.669811 0.652748 0.420723 0.555031 0.869874 0.539537 0.101279 0.0542811 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30528 episodes
GETTING ACTION FROM:
action 5, numVisits=30520, meanQ=9.017579, numObservations: 9
action 1, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.140267 0.264153 0.669811 0.652748 0.420723 0.555031 0.869874 0.539537 0.101279 0.0542811 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=2471, meanQ=10.327176, numObservations: 9
action 4, numVisits=1483, meanQ=10.279783, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 10789 episodes
GETTING ACTION FROM:
action 4, numVisits=10218, meanQ=9.278759, numObservations: 9
action 1, numVisits=4517, meanQ=9.117280, numObservations: 9
action 0, numVisits=5, meanQ=-1.010000, numObservations: 5
action -1, numVisits=4, meanQ=-1.257500, numObservations: 4
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=2, meanQ=-6.269900, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.140267 0.264153 0.669811 0.652748 0.420723 0.555031 0.869874 0.539537 0.101279 0.0542811 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 11
Initial state: 0 0.49957 0.346627 0.499587 0.526128 0.467687 0.636162 0.716982 0.308644 0.566719 0.669807 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30210 episodes
GETTING ACTION FROM:
action 3, numVisits=30195, meanQ=8.944269, numObservations: 9
action 2, numVisits=8, meanQ=4.873750, numObservations: 6
action 1, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.49957 0.346627 0.499587 0.526128 0.467687 0.636162 0.716982 0.308644 0.566719 0.669807 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 12
Initial state: 0 0.798335 0.189636 0.229413 0.818672 0.512255 0.170471 0.492253 0.636359 0.872135 0.520389 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29251 episodes
GETTING ACTION FROM:
action 5, numVisits=29245, meanQ=8.886824, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.798335 0.189636 0.229413 0.818672 0.512255 0.170471 0.492253 0.636359 0.872135 0.520389 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 13
Initial state: 0 0.197007 0.907307 0.09042 0.183967 0.394837 0.619463 0.16605 0.538745 0.937029 0.815337 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30487 episodes
GETTING ACTION FROM:
action 1, numVisits=30474, meanQ=8.848006, numObservations: 9
action 5, numVisits=8, meanQ=3.875000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.197007 0.907307 0.09042 0.183967 0.394837 0.619463 0.16605 0.538745 0.937029 0.815337 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=241, meanQ=8.439363, numObservations: 9
action 2, numVisits=6, meanQ=4.000017, numObservations: 5
action 1, numVisits=6, meanQ=3.351683, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 35822 episodes
GETTING ACTION FROM:
action 4, numVisits=36060, meanQ=14.199455, numObservations: 9
action 2, numVisits=6, meanQ=4.000017, numObservations: 5
action 1, numVisits=6, meanQ=3.351683, numObservations: 2
action 0, numVisits=3, meanQ=-1.340000, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.197007 0.907307 0.09042 0.183967 0.394837 0.619463 0.16605 0.538745 0.937029 0.815337 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=1, meanQ=24.000000, numObservations: 1
action 2, numVisits=1, meanQ=24.000000, numObservations: 1
action 4, numVisits=1, meanQ=24.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-10.201883, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 49465 episodes
GETTING ACTION FROM:
action 1, numVisits=2689, meanQ=18.693235, numObservations: 9
action 4, numVisits=7, meanQ=14.000000, numObservations: 3
action 2, numVisits=46764, meanQ=10.318019, numObservations: 9
action -1, numVisits=5, meanQ=-1.802000, numObservations: 5
action 0, numVisits=5, meanQ=-1.802000, numObservations: 4
action 3, numVisits=1, meanQ=-10.201883, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.197007 0.907307 0.09042 0.183967 0.394837 0.619463 0.16605 0.538745 0.937029 0.815337 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 61214 episodes
GETTING ACTION FROM:
action 1, numVisits=10089, meanQ=18.643980, numObservations: 9
action 5, numVisits=51117, meanQ=15.772584, numObservations: 9
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=2, meanQ=-2.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.000000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.197007 0.907307 0.09042 0.183967 0.394837 0.619463 0.16605 0.538745 0.937029 0.815337 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 74290 episodes
GETTING ACTION FROM:
action 1, numVisits=74284, meanQ=18.559461, numObservations: 9
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-2.000000, numObservations: 1
action 0, numVisits=1, meanQ=-2.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.197007 0.907307 0.09042 0.183967 0.394837 0.619463 0.16605 0.538745 0.937029 0.815337 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 5
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 74392 episodes
GETTING ACTION FROM:
action 5, numVisits=74386, meanQ=12.860001, numObservations: 9
action -1, numVisits=1, meanQ=-2.000000, numObservations: 1
action 0, numVisits=1, meanQ=-2.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.197007 0.907307 0.09042 0.183967 0.394837 0.619463 0.16605 0.538745 0.937029 0.815337 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 3.21978
Run # 14
Initial state: 0 0.367249 0.218263 0.22486 0.143105 0.463549 0.576733 0.678144 0.661699 0.583878 0.550134 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28455 episodes
GETTING ACTION FROM:
action 1, numVisits=28447, meanQ=8.639205, numObservations: 9
action 5, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.367249 0.218263 0.22486 0.143105 0.463549 0.576733 0.678144 0.661699 0.583878 0.550134 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=3608, meanQ=14.091884, numObservations: 222
action -1, numVisits=17, meanQ=-1.243524, numObservations: 16
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 5, numVisits=2, meanQ=-3.010000, numObservations: 2
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 4503 episodes
GETTING ACTION FROM:
action 0, numVisits=8111, meanQ=12.484389, numObservations: 236
action -1, numVisits=17, meanQ=-1.243524, numObservations: 16
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 5, numVisits=2, meanQ=-3.010000, numObservations: 2
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.367249 0.218263 0.22486 0.143105 0.463549 0.576733 0.678144 0.661699 0.583878 0.550134 w: 1
Observation: 0 0 1 0 1 0 2 0 3 0 2 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action -1, numVisits=23, meanQ=1.873483, numObservations: 19
action 0, numVisits=11, meanQ=-2.014707, numObservations: 10
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=30, meanQ=-23.576851, numObservations: 7
Sampled 20529 episodes
GETTING ACTION FROM:
action 5, numVisits=20522, meanQ=16.981583, numObservations: 9
action 1, numVisits=2, meanQ=8.375000, numObservations: 1
action 0, numVisits=11, meanQ=-2.014707, numObservations: 10
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=30, meanQ=-23.576851, numObservations: 7
action -1, numVisits=30, meanQ=-34.000110, numObservations: 25
action: 5
Next state: 1 0.367249 0.218263 0.22486 0.143105 0.463549 0.576733 0.678144 0.661699 0.583878 0.550134 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 17.5424
Run # 15
Initial state: 0 0.884023 0.145112 0.60749 0.474068 0.265767 0.334458 0.0941901 0.26036 0.467995 0.523745 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28617 episodes
GETTING ACTION FROM:
action 1, numVisits=28611, meanQ=7.713438, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.884023 0.145112 0.60749 0.474068 0.265767 0.334458 0.0941901 0.26036 0.467995 0.523745 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 16
Initial state: 0 0.641663 0.532194 0.597926 0.10877 0.332617 0.588975 0.436606 0.564533 0.628375 0.0981835 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30491 episodes
GETTING ACTION FROM:
action 4, numVisits=30481, meanQ=8.468394, numObservations: 9
action 1, numVisits=5, meanQ=0.200000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.641663 0.532194 0.597926 0.10877 0.332617 0.588975 0.436606 0.564533 0.628375 0.0981835 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 17
Initial state: 0 0.523383 0.558124 0.462251 0.612919 0.765492 0.753785 0.511672 0.438426 0.723302 0.0643692 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30389 episodes
GETTING ACTION FROM:
action 2, numVisits=30372, meanQ=8.719514, numObservations: 9
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 5, numVisits=6, meanQ=-2.315000, numObservations: 4
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.523383 0.558124 0.462251 0.612919 0.765492 0.753785 0.511672 0.438426 0.723302 0.0643692 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 18
Initial state: 0 0.569235 0.458963 0.876378 0.419531 0.773686 0.335402 0.664317 0.855818 0.437755 0.48876 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30529 episodes
GETTING ACTION FROM:
action 1, numVisits=30523, meanQ=8.787418, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.569235 0.458963 0.876378 0.419531 0.773686 0.335402 0.664317 0.855818 0.437755 0.48876 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 19
Initial state: 0 0.448248 0.0280187 0.619808 0.533109 0.558021 0.173407 0.409983 0.525344 0.0523062 0.276405 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29464 episodes
GETTING ACTION FROM:
action 5, numVisits=29446, meanQ=8.809300, numObservations: 9
action 3, numVisits=9, meanQ=6.110011, numObservations: 5
action 2, numVisits=3, meanQ=0.666667, numObservations: 2
action 4, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 0 0.448248 0.0280187 0.619808 0.533109 0.558021 0.173407 0.409983 0.525344 0.0523062 0.276405 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=3779, meanQ=9.865257, numObservations: 9
action 3, numVisits=5, meanQ=4.598000, numObservations: 5
action 2, numVisits=4, meanQ=3.245025, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 12541 episodes
GETTING ACTION FROM:
action 4, numVisits=16312, meanQ=10.364457, numObservations: 9
action 3, numVisits=7, meanQ=5.141429, numObservations: 5
action 2, numVisits=4, meanQ=3.245025, numObservations: 3
action -1, numVisits=4, meanQ=-1.257500, numObservations: 4
action 0, numVisits=4, meanQ=-1.257500, numObservations: 4
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.448248 0.0280187 0.619808 0.533109 0.558021 0.173407 0.409983 0.525344 0.0523062 0.276405 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 20
Initial state: 0 0.78457 0.749993 0.978324 0.178154 0.454657 0.522394 0.262943 0.99948 0.936074 0.780258 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30286 episodes
GETTING ACTION FROM:
action 5, numVisits=30255, meanQ=8.720273, numObservations: 9
action 4, numVisits=18, meanQ=6.672228, numObservations: 7
action 1, numVisits=9, meanQ=6.000011, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.78457 0.749993 0.978324 0.178154 0.454657 0.522394 0.262943 0.99948 0.936074 0.780258 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 21
Initial state: 0 0.249886 0.102422 0.228211 0.382313 0.626391 0.069653 0.416973 0.576799 0.488588 0.950865 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27761 episodes
GETTING ACTION FROM:
action 4, numVisits=27749, meanQ=8.855538, numObservations: 9
action 3, numVisits=7, meanQ=4.444286, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.249886 0.102422 0.228211 0.382313 0.626391 0.069653 0.416973 0.576799 0.488588 0.950865 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 22
Initial state: 0 0.215967 0.31163 0.0747329 0.0687879 0.109411 0.453531 0.489686 0.622422 0.851976 0.395784 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30408 episodes
GETTING ACTION FROM:
action 5, numVisits=30399, meanQ=8.674785, numObservations: 9
action 1, numVisits=4, meanQ=1.250000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.215967 0.31163 0.0747329 0.0687879 0.109411 0.453531 0.489686 0.622422 0.851976 0.395784 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 23
Initial state: 0 0.892032 0.599724 0.62043 0.88722 0.0747973 0.724251 0.433252 0.532798 0.557111 0.276983 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18045 episodes
GETTING ACTION FROM:
action -1, numVisits=18016, meanQ=13.490174, numObservations: 241
action 0, numVisits=20, meanQ=-1.010000, numObservations: 20
action 4, numVisits=3, meanQ=-6.333333, numObservations: 2
action 1, numVisits=2, meanQ=-7.500000, numObservations: 2
action 2, numVisits=2, meanQ=-7.500000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.892032 0.599724 0.62043 0.88722 0.0747973 0.724251 0.433252 0.532798 0.557111 0.276983 w: 1
Observation: 0 3 0 3 0 2 0 1 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=162, meanQ=20.422812, numObservations: 8
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 37880 episodes
GETTING ACTION FROM:
action 3, numVisits=38042, meanQ=21.216069, numObservations: 9
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.892032 0.599724 0.62043 0.88722 0.0747973 0.724251 0.433252 0.532798 0.557111 0.276983 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 24
Initial state: 0 0.900491 0.107212 0.0200239 0.253318 0.30112 0.359763 0.264902 0.808187 0.426386 0.479794 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30431 episodes
GETTING ACTION FROM:
action 5, numVisits=30418, meanQ=8.460771, numObservations: 9
action 4, numVisits=6, meanQ=4.496667, numObservations: 5
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.900491 0.107212 0.0200239 0.253318 0.30112 0.359763 0.264902 0.808187 0.426386 0.479794 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 25
Initial state: 0 0.440882 0.521655 0.592543 0.444684 0.277894 0.975573 0.160759 0.988861 0.937619 0.871802 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30333 episodes
GETTING ACTION FROM:
action 5, numVisits=30327, meanQ=8.762589, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.440882 0.521655 0.592543 0.444684 0.277894 0.975573 0.160759 0.988861 0.937619 0.871802 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 26
Initial state: 0 0.245451 0.103078 0.535424 0.614503 0.464212 0.495048 0.837839 0.870719 0.160595 0.60199 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30435 episodes
GETTING ACTION FROM:
action 4, numVisits=30423, meanQ=8.772365, numObservations: 9
action 2, numVisits=7, meanQ=5.000000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.245451 0.103078 0.535424 0.614503 0.464212 0.495048 0.837839 0.870719 0.160595 0.60199 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 27
Initial state: 0 0.566339 0.33302 0.909462 0.389505 0.408962 0.543649 0.580024 0.735269 0.542757 0.919104 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29709 episodes
GETTING ACTION FROM:
action 5, numVisits=29701, meanQ=8.672010, numObservations: 9
action 4, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.566339 0.33302 0.909462 0.389505 0.408962 0.543649 0.580024 0.735269 0.542757 0.919104 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 28
Initial state: 0 0.569005 0.568002 0.69488 0.107591 0.478806 0.586179 0.284271 0.379478 0.672157 0.271496 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30112 episodes
GETTING ACTION FROM:
action 2, numVisits=30097, meanQ=8.682557, numObservations: 9
action 5, numVisits=10, meanQ=6.500000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.569005 0.568002 0.69488 0.107591 0.478806 0.586179 0.284271 0.379478 0.672157 0.271496 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 29
Initial state: 0 0.0857697 0.245296 0.985236 0.446421 0.597901 0.23249 0.250838 0.0241372 0.464034 0.535907 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27923 episodes
GETTING ACTION FROM:
action 4, numVisits=27905, meanQ=8.919073, numObservations: 9
action 3, numVisits=9, meanQ=3.777778, numObservations: 6
action 2, numVisits=5, meanQ=0.200000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.0857697 0.245296 0.985236 0.446421 0.597901 0.23249 0.250838 0.0241372 0.464034 0.535907 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=394, meanQ=21.241061, numObservations: 9
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 28643 episodes
GETTING ACTION FROM:
action 4, numVisits=445, meanQ=21.469074, numObservations: 9
action 1, numVisits=28580, meanQ=11.123325, numObservations: 9
action 5, numVisits=3, meanQ=0.666667, numObservations: 3
action 0, numVisits=8, meanQ=-1.752500, numObservations: 8
action -1, numVisits=7, meanQ=-1.858571, numObservations: 7
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.0857697 0.245296 0.985236 0.446421 0.597901 0.23249 0.250838 0.0241372 0.464034 0.535907 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=3, meanQ=12.333333, numObservations: 3
action 3, numVisits=3, meanQ=12.333333, numObservations: 3
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 26820 episodes
GETTING ACTION FROM:
action 2, numVisits=26595, meanQ=13.364242, numObservations: 9
action 3, numVisits=6, meanQ=0.666667, numObservations: 5
action 5, numVisits=3, meanQ=0.666667, numObservations: 3
action 0, numVisits=33, meanQ=-1.395543, numObservations: 25
action -1, numVisits=193, meanQ=-2.280440, numObservations: 88
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.0857697 0.245296 0.985236 0.446421 0.597901 0.23249 0.250838 0.0241372 0.464034 0.535907 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -18.7411
Run # 30
Initial state: 0 0.398186 0.528529 0.800284 0.00749473 0.501705 0.775179 0.819323 0.473006 0.844413 0.973952 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18000 episodes
GETTING ACTION FROM:
action -1, numVisits=17988, meanQ=13.124687, numObservations: 242
action 0, numVisits=6, meanQ=-2.990000, numObservations: 5
action 1, numVisits=2, meanQ=-5.489950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.398186 0.528529 0.800284 0.00749473 0.501705 0.775179 0.819323 0.473006 0.844413 0.973952 w: 1
Observation: 0 3 0 3 0 3 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=58, meanQ=7.892414, numObservations: 8
action 1, numVisits=49, meanQ=6.080816, numObservations: 8
action 4, numVisits=7, meanQ=5.141429, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 39279 episodes
GETTING ACTION FROM:
action 2, numVisits=39337, meanQ=9.962553, numObservations: 9
action 1, numVisits=49, meanQ=6.080816, numObservations: 8
action 4, numVisits=7, meanQ=5.141429, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.398186 0.528529 0.800284 0.00749473 0.501705 0.775179 0.819323 0.473006 0.844413 0.973952 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 31
Initial state: 0 0.00076077 0.366341 0.401986 0.511857 0.0950045 0.823119 0.842439 0.936402 0.249333 0.781903 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29984 episodes
GETTING ACTION FROM:
action 1, numVisits=29963, meanQ=8.604555, numObservations: 9
action 3, numVisits=7, meanQ=5.585714, numObservations: 4
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action 4, numVisits=6, meanQ=2.833350, numObservations: 4
action 5, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 0 0.00076077 0.366341 0.401986 0.511857 0.0950045 0.823119 0.842439 0.936402 0.249333 0.781903 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=3905, meanQ=9.278845, numObservations: 9
action 4, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 11619 episodes
GETTING ACTION FROM:
action 2, numVisits=15513, meanQ=9.275590, numObservations: 9
action 4, numVisits=4, meanQ=-0.252500, numObservations: 4
action 0, numVisits=7, meanQ=-1.435700, numObservations: 6
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=4, meanQ=-3.792100, numObservations: 3
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.00076077 0.366341 0.401986 0.511857 0.0950045 0.823119 0.842439 0.936402 0.249333 0.781903 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 32
Initial state: 0 0.596519 0.202654 0.456501 0.543738 0.76489 0.856974 0.21951 0.804799 0.797306 0.28041 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29605 episodes
GETTING ACTION FROM:
action 3, numVisits=29599, meanQ=8.733317, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.596519 0.202654 0.456501 0.543738 0.76489 0.856974 0.21951 0.804799 0.797306 0.28041 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 33
Initial state: 0 0.45105 0.612876 0.655389 0.71509 0.763806 0.00437702 0.349274 0.695944 0.339703 0.942448 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30597 episodes
GETTING ACTION FROM:
action 5, numVisits=30583, meanQ=8.835754, numObservations: 9
action 2, numVisits=5, meanQ=4.400000, numObservations: 3
action 3, numVisits=5, meanQ=4.400000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.45105 0.612876 0.655389 0.71509 0.763806 0.00437702 0.349274 0.695944 0.339703 0.942448 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 34
Initial state: 0 0.251655 0.769957 0.342797 0.374806 0.899871 0.00445404 0.407603 0.551985 0.0163388 0.423394 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30718 episodes
GETTING ACTION FROM:
action 1, numVisits=27116, meanQ=8.806219, numObservations: 9
action 5, numVisits=3548, meanQ=8.680318, numObservations: 9
action 2, numVisits=50, meanQ=7.829612, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.251655 0.769957 0.342797 0.374806 0.899871 0.00445404 0.407603 0.551985 0.0163388 0.423394 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 35
Initial state: 0 0.807278 0.266012 0.593583 0.278877 0.0225214 0.251471 0.708576 0.84745 0.441674 0.54669 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30535 episodes
GETTING ACTION FROM:
action 3, numVisits=30522, meanQ=8.881751, numObservations: 9
action 5, numVisits=8, meanQ=3.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.807278 0.266012 0.593583 0.278877 0.0225214 0.251471 0.708576 0.84745 0.441674 0.54669 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=891, meanQ=9.980918, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 11475 episodes
GETTING ACTION FROM:
action 4, numVisits=12309, meanQ=9.788656, numObservations: 9
action 0, numVisits=41, meanQ=-1.058293, numObservations: 36
action -1, numVisits=20, meanQ=-1.505000, numObservations: 20
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.807278 0.266012 0.593583 0.278877 0.0225214 0.251471 0.708576 0.84745 0.441674 0.54669 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 36
Initial state: 0 0.772833 0.383856 0.348221 0.260371 0.414137 0.546004 0.786419 0.168899 0.738017 0.406296 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18133 episodes
GETTING ACTION FROM:
action -1, numVisits=18096, meanQ=13.845233, numObservations: 242
action 0, numVisits=28, meanQ=-1.010000, numObservations: 28
action 1, numVisits=2, meanQ=-7.500000, numObservations: 2
action 2, numVisits=2, meanQ=-7.500000, numObservations: 2
action 3, numVisits=2, meanQ=-7.500000, numObservations: 2
action 4, numVisits=2, meanQ=-7.500000, numObservations: 2
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.772833 0.383856 0.348221 0.260371 0.414137 0.546004 0.786419 0.168899 0.738017 0.406296 w: 1
Observation: 0 3 0 1 0 2 0 2 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=25, meanQ=11.122800, numObservations: 7
action 5, numVisits=22, meanQ=8.817273, numObservations: 5
action 4, numVisits=9, meanQ=7.218889, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 34674 episodes
GETTING ACTION FROM:
action 3, numVisits=34699, meanQ=14.919787, numObservations: 9
action 5, numVisits=22, meanQ=8.817273, numObservations: 5
action 4, numVisits=9, meanQ=7.218889, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.772833 0.383856 0.348221 0.260371 0.414137 0.546004 0.786419 0.168899 0.738017 0.406296 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=1195, meanQ=21.538238, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 20622 episodes
GETTING ACTION FROM:
action 3, numVisits=1459, meanQ=21.884821, numObservations: 9
action 2, numVisits=20351, meanQ=17.836205, numObservations: 9
action -1, numVisits=5, meanQ=-1.802000, numObservations: 4
action 0, numVisits=5, meanQ=-1.802000, numObservations: 5
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.772833 0.383856 0.348221 0.260371 0.414137 0.546004 0.786419 0.168899 0.738017 0.406296 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 17.5624
Run # 37
Initial state: 0 0.622455 0.759053 0.710994 0.0362993 0.307158 0.00754432 0.21457 0.622644 0.464512 0.587692 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29504 episodes
GETTING ACTION FROM:
action 3, numVisits=29495, meanQ=8.769779, numObservations: 9
action 1, numVisits=4, meanQ=-0.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.622455 0.759053 0.710994 0.0362993 0.307158 0.00754432 0.21457 0.622644 0.464512 0.587692 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=2247, meanQ=10.087775, numObservations: 9
action 2, numVisits=8, meanQ=6.500000, numObservations: 4
action 5, numVisits=9, meanQ=6.331111, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 13494 episodes
GETTING ACTION FROM:
action 4, numVisits=13352, meanQ=10.709175, numObservations: 9
action 3, numVisits=2248, meanQ=10.085923, numObservations: 9
action 5, numVisits=73, meanQ=-6.463137, numObservations: 9
action 1, numVisits=2, meanQ=-8.950000, numObservations: 1
action 2, numVisits=51, meanQ=-12.541742, numObservations: 9
action 0, numVisits=22, meanQ=-50.435740, numObservations: 17
action -1, numVisits=14, meanQ=-75.340684, numObservations: 11
action: 4
Next state: 0 0.622455 0.759053 0.710994 0.0362993 0.307158 0.00754432 0.21457 0.622644 0.464512 0.587692 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=184, meanQ=13.879602, numObservations: 9
action 5, numVisits=3, meanQ=1.864859, numObservations: 3
action 2, numVisits=3, meanQ=1.220464, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-9.372151, numObservations: 1
action 3, numVisits=1, meanQ=-1071.320713, numObservations: 1
Sampled 14872 episodes
GETTING ACTION FROM:
action 1, numVisits=15054, meanQ=15.394888, numObservations: 9
action 5, numVisits=3, meanQ=1.864859, numObservations: 3
action 2, numVisits=3, meanQ=1.220464, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 4, numVisits=1, meanQ=-9.372151, numObservations: 1
action 3, numVisits=1, meanQ=-1071.320713, numObservations: 1
action: 1
Next state: 1 0.622455 0.759053 0.710994 0.0362993 0.307158 0.00754432 0.21457 0.622644 0.464512 0.587692 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 38
Initial state: 0 0.0786856 0.949203 0.190652 0.0708677 0.478279 0.620847 0.970113 0.799067 0.841453 0.197466 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30375 episodes
GETTING ACTION FROM:
action 4, numVisits=30367, meanQ=8.781852, numObservations: 9
action 5, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.0786856 0.949203 0.190652 0.0708677 0.478279 0.620847 0.970113 0.799067 0.841453 0.197466 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 39
Initial state: 0 0.433984 0.526709 0.043619 0.0763697 0.251644 0.0213551 0.502454 0.13455 0.401043 0.105259 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29556 episodes
GETTING ACTION FROM:
action 1, numVisits=29537, meanQ=8.293225, numObservations: 9
action 5, numVisits=10, meanQ=4.400000, numObservations: 6
action 2, numVisits=3, meanQ=0.666667, numObservations: 2
action 4, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.433984 0.526709 0.043619 0.0763697 0.251644 0.0213551 0.502454 0.13455 0.401043 0.105259 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 40
Initial state: 0 0.774506 0.326593 0.886155 0.925302 0.237596 0.26406 0.470456 0.557063 0.567765 0.89699 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30325 episodes
GETTING ACTION FROM:
action 5, numVisits=30313, meanQ=8.712861, numObservations: 9
action 2, numVisits=7, meanQ=6.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.774506 0.326593 0.886155 0.925302 0.237596 0.26406 0.470456 0.557063 0.567765 0.89699 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 41
Initial state: 0 0.39788 0.551762 0.624654 0.65994 0.498788 0.741239 0.226326 0.386389 0.9037 0.10819 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30356 episodes
GETTING ACTION FROM:
action 5, numVisits=30347, meanQ=8.862837, numObservations: 9
action 1, numVisits=4, meanQ=-0.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.39788 0.551762 0.624654 0.65994 0.498788 0.741239 0.226326 0.386389 0.9037 0.10819 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 42
Initial state: 0 0.443959 0.640771 0.529924 0.0602464 0.00896935 0.643585 0.575093 0.622479 0.685832 0.91658 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30549 episodes
GETTING ACTION FROM:
action 2, numVisits=30543, meanQ=8.744645, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.443959 0.640771 0.529924 0.0602464 0.00896935 0.643585 0.575093 0.622479 0.685832 0.91658 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 43
Initial state: 0 0.389552 0.609342 0.0772013 0.0578868 0.0417329 0.1816 0.701093 0.792573 0.572878 0.263821 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29711 episodes
GETTING ACTION FROM:
action 5, numVisits=29685, meanQ=8.895628, numObservations: 9
action 4, numVisits=16, meanQ=2.812519, numObservations: 7
action 2, numVisits=4, meanQ=1.250000, numObservations: 3
action 1, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 2 0.389552 0.609342 0.0772013 0.0578868 0.0417329 0.1816 0.701093 0.792573 0.572878 0.263821 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 44
Initial state: 0 0.264756 0.316735 0.261576 0.448621 0.352792 0.933843 0.434397 0.628589 0.544031 0.685431 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29459 episodes
GETTING ACTION FROM:
action 1, numVisits=29444, meanQ=8.454808, numObservations: 9
action 4, numVisits=7, meanQ=1.141429, numObservations: 4
action 2, numVisits=4, meanQ=-0.500000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.264756 0.316735 0.261576 0.448621 0.352792 0.933843 0.434397 0.628589 0.544031 0.685431 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 45
Initial state: 0 0.432337 0.593051 0.195703 0.340965 0.0914893 0.285224 0.177794 0.875558 0.947731 0.123198 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29238 episodes
GETTING ACTION FROM:
action 2, numVisits=29224, meanQ=8.648638, numObservations: 9
action 4, numVisits=7, meanQ=4.444286, numObservations: 4
action 3, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.432337 0.593051 0.195703 0.340965 0.0914893 0.285224 0.177794 0.875558 0.947731 0.123198 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=3766, meanQ=9.942707, numObservations: 9
action 5, numVisits=34, meanQ=7.969712, numObservations: 9
action 4, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 11550 episodes
GETTING ACTION FROM:
action 3, numVisits=15296, meanQ=9.245694, numObservations: 9
action 4, numVisits=4, meanQ=1.622494, numObservations: 2
action -1, numVisits=8, meanQ=-1.010000, numObservations: 8
action 0, numVisits=8, meanQ=-1.133750, numObservations: 8
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=39, meanQ=-18.636941, numObservations: 9
action: 3
Next state: 0 0.432337 0.593051 0.195703 0.340965 0.0914893 0.285224 0.177794 0.875558 0.947731 0.123198 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=389, meanQ=9.273341, numObservations: 9
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 21706 episodes
GETTING ACTION FROM:
action 5, numVisits=22002, meanQ=5.189374, numObservations: 9
action -1, numVisits=75, meanQ=-1.406000, numObservations: 41
action 0, numVisits=26, meanQ=-1.847692, numObservations: 17
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.432337 0.593051 0.195703 0.340965 0.0914893 0.285224 0.177794 0.875558 0.947731 0.123198 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -18.7411
Run # 46
Initial state: 0 0.211102 0.284529 0.418815 0.588171 0.0672276 0.382806 0.208269 0.435896 0.402227 0.764876 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29596 episodes
GETTING ACTION FROM:
action 4, numVisits=29590, meanQ=8.728248, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.211102 0.284529 0.418815 0.588171 0.0672276 0.382806 0.208269 0.435896 0.402227 0.764876 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=161, meanQ=8.111903, numObservations: 9
action 3, numVisits=11, meanQ=3.552727, numObservations: 6
action 5, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 16002 episodes
GETTING ACTION FROM:
action 1, numVisits=16149, meanQ=11.682271, numObservations: 9
action 3, numVisits=11, meanQ=3.552727, numObservations: 6
action 5, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=8, meanQ=-1.628750, numObservations: 8
action 0, numVisits=8, meanQ=-1.628750, numObservations: 8
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.211102 0.284529 0.418815 0.588171 0.0672276 0.382806 0.208269 0.435896 0.402227 0.764876 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 0, numVisits=359, meanQ=3.931338, numObservations: 99
action 3, numVisits=82, meanQ=-0.785567, numObservations: 9
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=5, meanQ=-3.962435, numObservations: 2
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=44, meanQ=-11.959322, numObservations: 9
action -1, numVisits=46, meanQ=-21.983096, numObservations: 22
Sampled 5487 episodes
GETTING ACTION FROM:
action 0, numVisits=5846, meanQ=0.842964, numObservations: 230
action 3, numVisits=82, meanQ=-0.785567, numObservations: 9
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=5, meanQ=-3.962435, numObservations: 2
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=44, meanQ=-11.959322, numObservations: 9
action -1, numVisits=46, meanQ=-21.983096, numObservations: 22
action: 0
Next state: 0 0.211102 0.284529 0.418815 0.588171 0.0672276 0.382806 0.208269 0.435896 0.402227 0.764876 w: 1
Observation: 0 0 1 0 2 0 1 0 1 0 3 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=8, meanQ=24.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.728231, numObservations: 1
action 1, numVisits=1, meanQ=-536.725471, numObservations: 1
Sampled 31172 episodes
GETTING ACTION FROM:
action 2, numVisits=31180, meanQ=20.702976, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.728231, numObservations: 1
action 1, numVisits=1, meanQ=-536.725471, numObservations: 1
action: 2
Next state: 0 0.211102 0.284529 0.418815 0.588171 0.0672276 0.382806 0.208269 0.435896 0.402227 0.764876 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 2, numVisits=436, meanQ=22.363607, numObservations: 9
action 5, numVisits=2, meanQ=8.005918, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-15.884792, numObservations: 1
action 1, numVisits=1, meanQ=-537.702323, numObservations: 1
Sampled 31495 episodes
GETTING ACTION FROM:
action 2, numVisits=767, meanQ=22.973002, numObservations: 9
action 5, numVisits=31166, meanQ=21.124901, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-15.884792, numObservations: 1
action 1, numVisits=1, meanQ=-537.702323, numObservations: 1
action: 2
Next state: 1 0.211102 0.284529 0.418815 0.588171 0.0672276 0.382806 0.208269 0.435896 0.402227 0.764876 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9.25291
Run # 47
Initial state: 0 0.415884 0.523972 0.14808 0.103666 0.798435 0.429159 0.242962 0.196172 0.761716 0.0742938 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31030 episodes
GETTING ACTION FROM:
action 1, numVisits=25573, meanQ=8.843702, numObservations: 9
action 5, numVisits=5452, meanQ=8.773047, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.415884 0.523972 0.14808 0.103666 0.798435 0.429159 0.242962 0.196172 0.761716 0.0742938 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=351, meanQ=21.485682, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 28588 episodes
GETTING ACTION FROM:
action 1, numVisits=472, meanQ=21.246927, numObservations: 9
action 5, numVisits=28447, meanQ=11.719630, numObservations: 9
action -1, numVisits=13, meanQ=-1.619231, numObservations: 13
action 0, numVisits=10, meanQ=-1.802000, numObservations: 9
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.415884 0.523972 0.14808 0.103666 0.798435 0.429159 0.242962 0.196172 0.761716 0.0742938 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 48
Initial state: 0 0.82136 0.140033 0.457795 0.62021 0.00114161 0.350764 0.218367 0.722865 0.74916 0.319614 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30373 episodes
GETTING ACTION FROM:
action 2, numVisits=30356, meanQ=8.762899, numObservations: 9
action 3, numVisits=8, meanQ=-0.500000, numObservations: 5
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.82136 0.140033 0.457795 0.62021 0.00114161 0.350764 0.218367 0.722865 0.74916 0.319614 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 49
Initial state: 0 0.00155479 0.186599 0.705441 0.885966 0.25492 0.975203 0.387163 0.51745 0.0422733 0.66439 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30406 episodes
GETTING ACTION FROM:
action 3, numVisits=30377, meanQ=8.867720, numObservations: 9
action 5, numVisits=21, meanQ=6.595719, numObservations: 6
action 2, numVisits=4, meanQ=3.247500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.00155479 0.186599 0.705441 0.885966 0.25492 0.975203 0.387163 0.51745 0.0422733 0.66439 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=898, meanQ=8.810813, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 10903 episodes
GETTING ACTION FROM:
action 1, numVisits=11714, meanQ=10.171042, numObservations: 9
action 0, numVisits=24, meanQ=-1.587500, numObservations: 24
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=43, meanQ=-14.740380, numObservations: 8
action -1, numVisits=23, meanQ=-46.995769, numObservations: 20
action: 1
Next state: 0 0.00155479 0.186599 0.705441 0.885966 0.25492 0.975203 0.387163 0.51745 0.0422733 0.66439 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=7, meanQ=-0.390381, numObservations: 3
action 1, numVisits=4, meanQ=-9.975000, numObservations: 3
action 4, numVisits=7, meanQ=-9.989433, numObservations: 5
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=89, meanQ=-11.492569, numObservations: 9
action 0, numVisits=43, meanQ=-25.313934, numObservations: 36
action -1, numVisits=23, meanQ=-45.712549, numObservations: 20
Sampled 24381 episodes
GETTING ACTION FROM:
action 2, numVisits=24388, meanQ=5.822403, numObservations: 9
action 1, numVisits=4, meanQ=-9.975000, numObservations: 3
action 4, numVisits=7, meanQ=-9.989433, numObservations: 5
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=89, meanQ=-11.492569, numObservations: 9
action 0, numVisits=43, meanQ=-25.313934, numObservations: 36
action -1, numVisits=23, meanQ=-45.712549, numObservations: 20
action: 2
Next state: 1 0.00155479 0.186599 0.705441 0.885966 0.25492 0.975203 0.387163 0.51745 0.0422733 0.66439 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 50
Initial state: 0 0.0380851 0.709011 0.505553 0.46551 0.991422 0.496227 0.386371 0.582968 0.906493 0.029593 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29151 episodes
GETTING ACTION FROM:
action 5, numVisits=29142, meanQ=8.890507, numObservations: 9
action 1, numVisits=4, meanQ=1.745000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.0380851 0.709011 0.505553 0.46551 0.991422 0.496227 0.386371 0.582968 0.906493 0.029593 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
[32m ProblemEnvironment.hpp 351: Done.[39m
