Run # 1
Initial state: 0 0.858065 0.0656272 0.0309611 0.649862 0.534535 0.209992 0.747481 0.517315 0.551006 0.369144 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26987 episodes
GETTING ACTION FROM:
action 1, numVisits=26579, meanQ=12.764984, numObservations: 9
action 3, numVisits=401, meanQ=10.373858, numObservations: 9
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.858065 0.0656272 0.0309611 0.649862 0.534535 0.209992 0.747481 0.517315 0.551006 0.369144 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 2
Initial state: 0 0.690408 0.630029 0.807294 0.997435 0.801529 0.220622 0.552454 0.322229 0.898065 0.256423 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27598 episodes
GETTING ACTION FROM:
action 1, numVisits=27588, meanQ=12.965693, numObservations: 9
action 2, numVisits=3, meanQ=3.000000, numObservations: 3
action 5, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.690408 0.630029 0.807294 0.997435 0.801529 0.220622 0.552454 0.322229 0.898065 0.256423 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 3
Initial state: 0 0.0924684 0.0182452 0.232659 0.555527 0.55582 0.378679 0.776486 0.981193 0.173505 0.0958646 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26258 episodes
GETTING ACTION FROM:
action 5, numVisits=26250, meanQ=12.723377, numObservations: 9
action 2, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.0924684 0.0182452 0.232659 0.555527 0.55582 0.378679 0.776486 0.981193 0.173505 0.0958646 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=974, meanQ=13.442258, numObservations: 9
action 4, numVisits=10, meanQ=11.598000, numObservations: 6
action 2, numVisits=6, meanQ=9.501700, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 6853 episodes
GETTING ACTION FROM:
action 3, numVisits=7543, meanQ=12.667229, numObservations: 9
action 4, numVisits=240, meanQ=8.834907, numObservations: 9
action 2, numVisits=44, meanQ=8.070229, numObservations: 8
action -1, numVisits=9, meanQ=-1.340000, numObservations: 8
action 0, numVisits=9, meanQ=-1.340000, numObservations: 9
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.0924684 0.0182452 0.232659 0.555527 0.55582 0.378679 0.776486 0.981193 0.173505 0.0958646 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 4
Initial state: 0 0.630237 0.454512 0.497811 0.776267 0.73443 0.706719 0.0602072 0.112681 0.386862 0.994043 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26330 episodes
GETTING ACTION FROM:
action 2, numVisits=26324, meanQ=12.731152, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.630237 0.454512 0.497811 0.776267 0.73443 0.706719 0.0602072 0.112681 0.386862 0.994043 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=4383, meanQ=13.732688, numObservations: 9
action 1, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 10262 episodes
GETTING ACTION FROM:
action 4, numVisits=14643, meanQ=15.521102, numObservations: 9
action 1, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.630237 0.454512 0.497811 0.776267 0.73443 0.706719 0.0602072 0.112681 0.386862 0.994043 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=768, meanQ=17.759429, numObservations: 9
action 2, numVisits=479, meanQ=13.982239, numObservations: 9
action 3, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=13, meanQ=-1.163069, numObservations: 12
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=38, meanQ=-14.965547, numObservations: 9
action 0, numVisits=11, meanQ=-94.787796, numObservations: 9
Sampled 7967 episodes
GETTING ACTION FROM:
action 5, numVisits=8735, meanQ=17.846223, numObservations: 9
action 2, numVisits=479, meanQ=13.982239, numObservations: 9
action 3, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=13, meanQ=-1.163069, numObservations: 12
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=38, meanQ=-14.965547, numObservations: 9
action 0, numVisits=11, meanQ=-94.787796, numObservations: 9
action: 5
Next state: 1 0.630237 0.454512 0.497811 0.776267 0.73443 0.706719 0.0602072 0.112681 0.386862 0.994043 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 5
Initial state: 0 0.685927 0.388908 0.361234 0.602007 0.552659 0.385395 0.872981 0.90299 0.0613291 0.185366 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27615 episodes
GETTING ACTION FROM:
action 1, numVisits=27606, meanQ=12.635916, numObservations: 9
action 4, numVisits=4, meanQ=0.752525, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.685927 0.388908 0.361234 0.602007 0.552659 0.385395 0.872981 0.90299 0.0613291 0.185366 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 6
Initial state: 0 0.633183 0.663332 0.970895 0.65799 0.60848 0.394378 0.780646 0.686901 0.837499 0.681112 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27515 episodes
GETTING ACTION FROM:
action 4, numVisits=27509, meanQ=12.760295, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.633183 0.663332 0.970895 0.65799 0.60848 0.394378 0.780646 0.686901 0.837499 0.681112 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 7
Initial state: 0 0.611663 0.392461 0.0978598 0.583022 0.371344 0.549013 0.0243913 0.221997 0.846028 0.107766 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27278 episodes
GETTING ACTION FROM:
action 3, numVisits=27267, meanQ=12.443979, numObservations: 9
action 5, numVisits=4, meanQ=8.250000, numObservations: 2
action 4, numVisits=3, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.611663 0.392461 0.0978598 0.583022 0.371344 0.549013 0.0243913 0.221997 0.846028 0.107766 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=3367, meanQ=12.628175, numObservations: 9
action 5, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 7473 episodes
GETTING ACTION FROM:
action 2, numVisits=10830, meanQ=12.407188, numObservations: 9
action 5, numVisits=8, meanQ=4.794170, numObservations: 5
action -1, numVisits=4, meanQ=-1.257500, numObservations: 4
action 0, numVisits=3, meanQ=-1.340000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.611663 0.392461 0.0978598 0.583022 0.371344 0.549013 0.0243913 0.221997 0.846028 0.107766 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=981, meanQ=14.523873, numObservations: 9
action 1, numVisits=3, meanQ=3.330000, numObservations: 3
action 5, numVisits=4, meanQ=2.750025, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 5881 episodes
GETTING ACTION FROM:
action 4, numVisits=6862, meanQ=13.438339, numObservations: 9
action 1, numVisits=3, meanQ=3.330000, numObservations: 3
action 5, numVisits=4, meanQ=2.750025, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 0 0.611663 0.392461 0.0978598 0.583022 0.371344 0.549013 0.0243913 0.221997 0.846028 0.107766 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=383, meanQ=12.855724, numObservations: 9
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action -1, numVisits=7, meanQ=-1.577129, numObservations: 6
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 5057 episodes
GETTING ACTION FROM:
action 1, numVisits=5440, meanQ=11.183583, numObservations: 9
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action -1, numVisits=7, meanQ=-1.577129, numObservations: 6
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.611663 0.392461 0.0978598 0.583022 0.371344 0.549013 0.0243913 0.221997 0.846028 0.107766 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 5, numVisits=99, meanQ=12.159051, numObservations: 9
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=21, meanQ=-11.979312, numObservations: 12
action -1, numVisits=7, meanQ=-53.211713, numObservations: 5
action 3, numVisits=1, meanQ=-539.467153, numObservations: 1
action 2, numVisits=1, meanQ=-539.501850, numObservations: 1
Sampled 18895 episodes
GETTING ACTION FROM:
action 5, numVisits=18994, meanQ=17.451852, numObservations: 9
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=21, meanQ=-11.979312, numObservations: 12
action -1, numVisits=7, meanQ=-53.211713, numObservations: 5
action 3, numVisits=1, meanQ=-539.467153, numObservations: 1
action 2, numVisits=1, meanQ=-539.501850, numObservations: 1
action: 5
Next state: 2 0.611663 0.392461 0.0978598 0.583022 0.371344 0.549013 0.0243913 0.221997 0.846028 0.107766 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -26.3282
Run # 8
Initial state: 0 0.729738 0.366425 0.557181 0.367684 0.772747 0.897781 0.123244 0.559764 0.452936 0.219603 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27409 episodes
GETTING ACTION FROM:
action 5, numVisits=27401, meanQ=12.690817, numObservations: 9
action 4, numVisits=3, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.729738 0.366425 0.557181 0.367684 0.772747 0.897781 0.123244 0.559764 0.452936 0.219603 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 9
Initial state: 0 0.474027 0.761624 0.855152 0.403139 0.172053 0.987238 0.568953 0.310298 0.930932 0.752229 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27469 episodes
GETTING ACTION FROM:
action 5, numVisits=27417, meanQ=12.472917, numObservations: 9
action 1, numVisits=45, meanQ=7.466922, numObservations: 9
action 2, numVisits=3, meanQ=5.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.474027 0.761624 0.855152 0.403139 0.172053 0.987238 0.568953 0.310298 0.930932 0.752229 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 10
Initial state: 0 0.408329 0.239955 0.607312 0.620968 0.573115 0.454839 0.0569948 0.312395 0.811238 0.634682 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27505 episodes
GETTING ACTION FROM:
action 5, numVisits=27495, meanQ=12.734060, numObservations: 9
action 2, numVisits=3, meanQ=5.663333, numObservations: 2
action 3, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.408329 0.239955 0.607312 0.620968 0.573115 0.454839 0.0569948 0.312395 0.811238 0.634682 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 11
Initial state: 0 0.435258 0.0542597 0.511639 0.417664 0.564206 0.44845 0.923577 0.762818 0.253968 0.972145 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27248 episodes
GETTING ACTION FROM:
action 1, numVisits=27237, meanQ=12.963062, numObservations: 9
action 2, numVisits=6, meanQ=8.833333, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.435258 0.0542597 0.511639 0.417664 0.564206 0.44845 0.923577 0.762818 0.253968 0.972145 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=3305, meanQ=13.600857, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 6410 episodes
GETTING ACTION FROM:
action 5, numVisits=9713, meanQ=13.419295, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 0 0.435258 0.0542597 0.511639 0.417664 0.564206 0.44845 0.923577 0.762818 0.253968 0.972145 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=1457, meanQ=16.777977, numObservations: 9
action 3, numVisits=14, meanQ=12.641429, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 6638 episodes
GETTING ACTION FROM:
action 2, numVisits=8091, meanQ=17.162367, numObservations: 9
action 3, numVisits=16, meanQ=10.061256, numObservations: 7
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.435258 0.0542597 0.511639 0.417664 0.564206 0.44845 0.923577 0.762818 0.253968 0.972145 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=21, meanQ=9.463493, numObservations: 5
action 3, numVisits=3, meanQ=0.874721, numObservations: 3
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action -1, numVisits=4, meanQ=-3.840918, numObservations: 3
action 4, numVisits=1, meanQ=-10.385739, numObservations: 1
action 5, numVisits=1, meanQ=-10.784209, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 18747 episodes
GETTING ACTION FROM:
action 3, numVisits=18697, meanQ=19.135583, numObservations: 9
action 2, numVisits=55, meanQ=8.235569, numObservations: 9
action 0, numVisits=23, meanQ=-1.827826, numObservations: 17
action -1, numVisits=4, meanQ=-3.840918, numObservations: 3
action 4, numVisits=1, meanQ=-10.385739, numObservations: 1
action 5, numVisits=1, meanQ=-10.784209, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.435258 0.0542597 0.511639 0.417664 0.564206 0.44845 0.923577 0.762818 0.253968 0.972145 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 11.4068
Run # 12
Initial state: 0 0.0542975 0.717933 0.555128 0.309604 0.188659 0.810019 0.181811 0.844658 0.481535 0.653419 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27517 episodes
GETTING ACTION FROM:
action 1, numVisits=27508, meanQ=12.880899, numObservations: 9
action 4, numVisits=2, meanQ=6.500000, numObservations: 2
action 2, numVisits=3, meanQ=5.663333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.0542975 0.717933 0.555128 0.309604 0.188659 0.810019 0.181811 0.844658 0.481535 0.653419 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=4541, meanQ=14.083318, numObservations: 9
action 5, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 9824 episodes
GETTING ACTION FROM:
action 4, numVisits=14363, meanQ=14.873157, numObservations: 9
action 5, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 0 0.0542975 0.717933 0.555128 0.309604 0.188659 0.810019 0.181811 0.844658 0.481535 0.653419 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=1758, meanQ=15.651543, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 9786 episodes
GETTING ACTION FROM:
action 3, numVisits=11544, meanQ=15.852823, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.0542975 0.717933 0.555128 0.309604 0.188659 0.810019 0.181811 0.844658 0.481535 0.653419 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=595, meanQ=18.892668, numObservations: 9
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 7944 episodes
GETTING ACTION FROM:
action 2, numVisits=8539, meanQ=18.714013, numObservations: 9
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.0542975 0.717933 0.555128 0.309604 0.188659 0.810019 0.181811 0.844658 0.481535 0.653419 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 2, numVisits=127, meanQ=9.554907, numObservations: 9
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=6, meanQ=-63.090054, numObservations: 4
action -1, numVisits=5, meanQ=-73.521411, numObservations: 4
action 4, numVisits=1, meanQ=-539.629308, numObservations: 1
action 1, numVisits=1, meanQ=-1067.412833, numObservations: 1
Sampled 26771 episodes
GETTING ACTION FROM:
action 5, numVisits=26706, meanQ=17.890911, numObservations: 9
action 2, numVisits=193, meanQ=14.344421, numObservations: 9
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=6, meanQ=-63.090054, numObservations: 4
action -1, numVisits=5, meanQ=-73.521411, numObservations: 4
action 4, numVisits=1, meanQ=-539.629308, numObservations: 1
action 1, numVisits=1, meanQ=-1067.412833, numObservations: 1
action: 5
Next state: 1 0.0542975 0.717933 0.555128 0.309604 0.188659 0.810019 0.181811 0.844658 0.481535 0.653419 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.29271
Run # 13
Initial state: 0 0.344645 0.252019 0.0270404 0.837337 0.77711 0.478922 0.470112 0.775628 0.599429 0.427136 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27497 episodes
GETTING ACTION FROM:
action 3, numVisits=26951, meanQ=12.704770, numObservations: 9
action 5, numVisits=539, meanQ=11.033830, numObservations: 9
action 2, numVisits=3, meanQ=5.663333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 2 0.344645 0.252019 0.0270404 0.837337 0.77711 0.478922 0.470112 0.775628 0.599429 0.427136 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 14
Initial state: 0 0.644862 0.456099 0.963625 0.247477 0.292349 0.112915 0.660803 0.58098 0.284152 0.75531 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26065 episodes
GETTING ACTION FROM:
action 2, numVisits=26058, meanQ=12.609867, numObservations: 9
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.644862 0.456099 0.963625 0.247477 0.292349 0.112915 0.660803 0.58098 0.284152 0.75531 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 15
Initial state: 0 0.969352 0.859064 0.114937 0.992214 0.942626 0.520553 0.618625 0.0968598 0.643508 0.364571 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27586 episodes
GETTING ACTION FROM:
action 3, numVisits=27448, meanQ=12.865766, numObservations: 9
action 2, numVisits=128, meanQ=9.500595, numObservations: 9
action 4, numVisits=5, meanQ=6.604020, numObservations: 3
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.969352 0.859064 0.114937 0.992214 0.942626 0.520553 0.618625 0.0968598 0.643508 0.364571 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 16
Initial state: 0 0.641751 0.396439 0.0921957 0.0327674 0.776521 0.311034 0.8227 0.143848 0.230264 0.903398 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27692 episodes
GETTING ACTION FROM:
action 5, numVisits=27663, meanQ=12.845454, numObservations: 9
action 1, numVisits=24, meanQ=8.844592, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 1 0.641751 0.396439 0.0921957 0.0327674 0.776521 0.311034 0.8227 0.143848 0.230264 0.903398 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 17
Initial state: 0 0.515056 0.8043 0.612522 0.379267 0.297334 0.450234 0.29739 0.288486 0.0468839 0.451452 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27383 episodes
GETTING ACTION FROM:
action 4, numVisits=27371, meanQ=12.631791, numObservations: 9
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.515056 0.8043 0.612522 0.379267 0.297334 0.450234 0.29739 0.288486 0.0468839 0.451452 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=3274, meanQ=13.332016, numObservations: 9
action 2, numVisits=14, meanQ=8.070007, numObservations: 7
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 7658 episodes
GETTING ACTION FROM:
action 1, numVisits=10929, meanQ=14.002371, numObservations: 9
action 2, numVisits=14, meanQ=8.070007, numObservations: 7
action 5, numVisits=3, meanQ=0.666667, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.515056 0.8043 0.612522 0.379267 0.297334 0.450234 0.29739 0.288486 0.0468839 0.451452 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=1377, meanQ=13.671578, numObservations: 9
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action -1, numVisits=5, meanQ=-1.407980, numObservations: 4
action 4, numVisits=7, meanQ=-1.711386, numObservations: 3
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 5851 episodes
GETTING ACTION FROM:
action 3, numVisits=7228, meanQ=15.821499, numObservations: 9
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action -1, numVisits=5, meanQ=-1.407980, numObservations: 4
action 4, numVisits=7, meanQ=-1.711386, numObservations: 3
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.515056 0.8043 0.612522 0.379267 0.297334 0.450234 0.29739 0.288486 0.0468839 0.451452 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=1, meanQ=24.000000, numObservations: 1
action 2, numVisits=9, meanQ=16.341405, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 29850 episodes
GETTING ACTION FROM:
action 1, numVisits=234, meanQ=18.521368, numObservations: 8
action 2, numVisits=29624, meanQ=15.005722, numObservations: 9
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.515056 0.8043 0.612522 0.379267 0.297334 0.450234 0.29739 0.288486 0.0468839 0.451452 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30335 episodes
GETTING ACTION FROM:
action 5, numVisits=30141, meanQ=16.011945, numObservations: 9
action 2, numVisits=188, meanQ=12.485712, numObservations: 9
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 0, numVisits=2, meanQ=-2.000000, numObservations: 2
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.515056 0.8043 0.612522 0.379267 0.297334 0.450234 0.29739 0.288486 0.0468839 0.451452 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: -4
Updated belief

t = 5
Improving policy...
PLANNING FROM:
action 3, numVisits=1, meanQ=24.000000, numObservations: 1
action 2, numVisits=11, meanQ=8.378874, numObservations: 4
action 5, numVisits=2, meanQ=-11.847623, numObservations: 2
action -1, numVisits=9, meanQ=-40.870214, numObservations: 8
action 0, numVisits=4, meanQ=-90.668300, numObservations: 3
action 1, numVisits=1, meanQ=-361.204183, numObservations: 1
action 4, numVisits=1, meanQ=-361.480698, numObservations: 1
Sampled 30416 episodes
GETTING ACTION FROM:
action 3, numVisits=130, meanQ=17.638462, numObservations: 9
action 2, numVisits=30298, meanQ=15.933410, numObservations: 9
action 5, numVisits=2, meanQ=-11.847623, numObservations: 2
action -1, numVisits=9, meanQ=-40.870214, numObservations: 8
action 0, numVisits=4, meanQ=-90.668300, numObservations: 3
action 1, numVisits=1, meanQ=-361.204183, numObservations: 1
action 4, numVisits=1, meanQ=-361.480698, numObservations: 1
action: 3
Next state: 0 0.515056 0.8043 0.612522 0.379267 0.297334 0.450234 0.29739 0.288486 0.0468839 0.451452 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: -4
Updated belief

t = 6
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 36048 episodes
GETTING ACTION FROM:
action 5, numVisits=35, meanQ=19.000000, numObservations: 7
action 2, numVisits=35972, meanQ=18.953077, numObservations: 9
action 4, numVisits=3, meanQ=12.333333, numObservations: 3
action 1, numVisits=35, meanQ=10.654405, numObservations: 4
action -1, numVisits=1, meanQ=-2.000000, numObservations: 1
action 0, numVisits=1, meanQ=-2.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.515056 0.8043 0.612522 0.379267 0.297334 0.450234 0.29739 0.288486 0.0468839 0.451452 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: -4
Updated belief

t = 7
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 56691 episodes
GETTING ACTION FROM:
action 3, numVisits=316, meanQ=17.740361, numObservations: 9
action 2, numVisits=56363, meanQ=16.311084, numObservations: 9
action 4, numVisits=5, meanQ=10.000000, numObservations: 3
action 1, numVisits=4, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-2.000000, numObservations: 1
action 0, numVisits=1, meanQ=-2.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.515056 0.8043 0.612522 0.379267 0.297334 0.450234 0.29739 0.288486 0.0468839 0.451452 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 8
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 39520 episodes
GETTING ACTION FROM:
action 2, numVisits=39513, meanQ=22.286808, numObservations: 9
action 4, numVisits=2, meanQ=10.000000, numObservations: 1
action -1, numVisits=1, meanQ=-2.000000, numObservations: 1
action 0, numVisits=1, meanQ=-2.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.515056 0.8043 0.612522 0.379267 0.297334 0.450234 0.29739 0.288486 0.0468839 0.451452 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -8.75625
Run # 18
Initial state: 0 0.555969 0.396033 0.964847 0.13798 0.0121296 0.388377 0.27686 0.120476 0.00900451 0.228555 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27382 episodes
GETTING ACTION FROM:
action 3, numVisits=27359, meanQ=12.580761, numObservations: 9
action 2, numVisits=11, meanQ=5.793664, numObservations: 5
action 1, numVisits=8, meanQ=4.377512, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.555969 0.396033 0.964847 0.13798 0.0121296 0.388377 0.27686 0.120476 0.00900451 0.228555 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=86, meanQ=12.239936, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 20212 episodes
GETTING ACTION FROM:
action 4, numVisits=20296, meanQ=14.925547, numObservations: 9
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 0 0.555969 0.396033 0.964847 0.13798 0.0121296 0.388377 0.27686 0.120476 0.00900451 0.228555 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=2, meanQ=24.000000, numObservations: 2
action 5, numVisits=327, meanQ=17.951737, numObservations: 9
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=4, meanQ=-4.434088, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 15254 episodes
GETTING ACTION FROM:
action 5, numVisits=15578, meanQ=15.812194, numObservations: 9
action 3, numVisits=5, meanQ=10.000000, numObservations: 4
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=4, meanQ=-4.434088, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.555969 0.396033 0.964847 0.13798 0.0121296 0.388377 0.27686 0.120476 0.00900451 0.228555 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -18.7411
Run # 19
Initial state: 0 0.998771 0.139655 0.872859 0.87679 0.613208 0.40357 0.673837 0.824545 0.0728747 0.788936 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27523 episodes
GETTING ACTION FROM:
action 2, numVisits=27500, meanQ=12.965917, numObservations: 9
action 1, numVisits=13, meanQ=7.449231, numObservations: 8
action 4, numVisits=2, meanQ=6.500000, numObservations: 2
action 3, numVisits=5, meanQ=4.400000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.998771 0.139655 0.872859 0.87679 0.613208 0.40357 0.673837 0.824545 0.0728747 0.788936 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 20
Initial state: 0 0.616392 0.394263 0.111539 0.663866 0.232232 0.0750502 0.718727 0.211859 0.170748 0.684981 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 25372 episodes
GETTING ACTION FROM:
action 4, numVisits=25363, meanQ=12.718189, numObservations: 9
action 3, numVisits=4, meanQ=8.250000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.616392 0.394263 0.111539 0.663866 0.232232 0.0750502 0.718727 0.211859 0.170748 0.684981 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 21
Initial state: 0 0.473226 0.167911 0.499991 0.613688 0.118523 0.165647 0.194197 0.270917 0.602966 0.370691 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27443 episodes
GETTING ACTION FROM:
action 4, numVisits=27433, meanQ=12.754511, numObservations: 9
action 5, numVisits=5, meanQ=7.596000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 0 0.473226 0.167911 0.499991 0.613688 0.118523 0.165647 0.194197 0.270917 0.602966 0.370691 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=3258, meanQ=13.547315, numObservations: 9
action 5, numVisits=8, meanQ=9.000012, numObservations: 5
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 6277 episodes
GETTING ACTION FROM:
action 2, numVisits=9500, meanQ=13.077090, numObservations: 9
action 5, numVisits=33, meanQ=6.166919, numObservations: 8
action 3, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=6, meanQ=-1.340000, numObservations: 5
action 0, numVisits=5, meanQ=-1.605980, numObservations: 4
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.473226 0.167911 0.499991 0.613688 0.118523 0.165647 0.194197 0.270917 0.602966 0.370691 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=1108, meanQ=14.388634, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 4927 episodes
GETTING ACTION FROM:
action 3, numVisits=6035, meanQ=13.357989, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.473226 0.167911 0.499991 0.613688 0.118523 0.165647 0.194197 0.270917 0.602966 0.370691 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=619, meanQ=12.967647, numObservations: 9
action 2, numVisits=6, meanQ=6.292525, numObservations: 3
action 5, numVisits=89, meanQ=5.654607, numObservations: 9
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=8, meanQ=-130.053536, numObservations: 6
Sampled 8291 episodes
GETTING ACTION FROM:
action 1, numVisits=8910, meanQ=11.220988, numObservations: 9
action 2, numVisits=6, meanQ=6.292525, numObservations: 3
action 5, numVisits=89, meanQ=5.654607, numObservations: 9
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=8, meanQ=-130.053536, numObservations: 6
action: 1
Next state: 0 0.473226 0.167911 0.499991 0.613688 0.118523 0.165647 0.194197 0.270917 0.602966 0.370691 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 5, numVisits=262, meanQ=18.804851, numObservations: 9
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.582870, numObservations: 1
action 0, numVisits=4, meanQ=-90.195285, numObservations: 3
action -1, numVisits=2, meanQ=-178.508545, numObservations: 1
action 2, numVisits=1, meanQ=-538.350568, numObservations: 1
action 4, numVisits=1, meanQ=-1064.805314, numObservations: 1
Sampled 21859 episodes
GETTING ACTION FROM:
action 5, numVisits=22121, meanQ=21.648703, numObservations: 9
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.582870, numObservations: 1
action 0, numVisits=4, meanQ=-90.195285, numObservations: 3
action -1, numVisits=2, meanQ=-178.508545, numObservations: 1
action 2, numVisits=1, meanQ=-538.350568, numObservations: 1
action 4, numVisits=1, meanQ=-1064.805314, numObservations: 1
action: 5
Next state: 1 0.473226 0.167911 0.499991 0.613688 0.118523 0.165647 0.194197 0.270917 0.602966 0.370691 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.29271
Run # 22
Initial state: 0 0.03222 0.245661 0.807841 0.963168 0.79328 0.906405 0.0608894 0.528882 0.630996 0.452235 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26974 episodes
GETTING ACTION FROM:
action 2, numVisits=26947, meanQ=12.740648, numObservations: 9
action 3, numVisits=16, meanQ=10.936256, numObservations: 8
action 4, numVisits=4, meanQ=9.255025, numObservations: 3
action 1, numVisits=4, meanQ=8.250000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 2 0.03222 0.245661 0.807841 0.963168 0.79328 0.906405 0.0608894 0.528882 0.630996 0.452235 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 23
Initial state: 0 0.503724 0.056279 0.0356902 0.92906 0.300414 0.341624 0.560896 0.313318 0.42871 0.784731 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27583 episodes
GETTING ACTION FROM:
action 5, numVisits=27577, meanQ=12.874456, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.503724 0.056279 0.0356902 0.92906 0.300414 0.341624 0.560896 0.313318 0.42871 0.784731 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 24
Initial state: 0 0.382931 0.268719 0.0972456 0.152085 0.41714 0.524998 0.783399 0.524155 0.632241 0.372724 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27226 episodes
GETTING ACTION FROM:
action 2, numVisits=27216, meanQ=12.916204, numObservations: 9
action 5, numVisits=5, meanQ=7.200000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.382931 0.268719 0.0972456 0.152085 0.41714 0.524998 0.783399 0.524155 0.632241 0.372724 w: 1
Observation: 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=297, meanQ=14.450741, numObservations: 9
action 5, numVisits=4, meanQ=10.495000, numObservations: 4
action 3, numVisits=4, meanQ=9.502525, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 10962 episodes
GETTING ACTION FROM:
action 4, numVisits=11248, meanQ=11.686276, numObservations: 9
action 3, numVisits=5, meanQ=4.878318, numObservations: 3
action 5, numVisits=6, meanQ=4.330017, numObservations: 4
action 0, numVisits=5, meanQ=-1.406000, numObservations: 5
action -1, numVisits=5, meanQ=-1.604000, numObservations: 5
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.382931 0.268719 0.0972456 0.152085 0.41714 0.524998 0.783399 0.524155 0.632241 0.372724 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 25
Initial state: 0 0.628668 0.378523 0.375208 0.402649 0.00311773 0.870309 0.966243 0.799378 0.450497 0.982188 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27666 episodes
GETTING ACTION FROM:
action 5, numVisits=27645, meanQ=12.965678, numObservations: 9
action 3, numVisits=16, meanQ=6.436888, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 0 0.628668 0.378523 0.375208 0.402649 0.00311773 0.870309 0.966243 0.799378 0.450497 0.982188 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=4705, meanQ=14.073402, numObservations: 9
action 2, numVisits=4, meanQ=10.495000, numObservations: 2
action 3, numVisits=3, meanQ=5.993333, numObservations: 3
action 1, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 8961 episodes
GETTING ACTION FROM:
action 4, numVisits=13657, meanQ=15.362939, numObservations: 9
action 2, numVisits=6, meanQ=5.496683, numObservations: 3
action 3, numVisits=4, meanQ=1.745000, numObservations: 3
action 1, numVisits=4, meanQ=-0.252500, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action -1, numVisits=3, meanQ=-1.340000, numObservations: 2
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 1 0.628668 0.378523 0.375208 0.402649 0.00311773 0.870309 0.966243 0.799378 0.450497 0.982188 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 26
Initial state: 0 0.244879 0.553683 0.15345 0.0718511 0.687524 0.973835 0.365048 0.609201 0.568496 0.398468 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27304 episodes
GETTING ACTION FROM:
action 5, numVisits=27298, meanQ=12.616254, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 1 0.244879 0.553683 0.15345 0.0718511 0.687524 0.973835 0.365048 0.609201 0.568496 0.398468 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 27
Initial state: 0 0.307334 0.555638 0.654948 0.538199 0.824383 0.0659355 0.575 0.419886 0.952735 0.911148 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27446 episodes
GETTING ACTION FROM:
action 4, numVisits=27440, meanQ=12.949805, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.307334 0.555638 0.654948 0.538199 0.824383 0.0659355 0.575 0.419886 0.952735 0.911148 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 28
Initial state: 0 0.386517 0.12197 0.829528 0.92434 0.481894 0.0116506 0.59153 0.401439 0.785017 0.477532 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27554 episodes
GETTING ACTION FROM:
action 5, numVisits=24423, meanQ=12.688885, numObservations: 9
action 2, numVisits=3118, meanQ=12.353531, numObservations: 9
action 4, numVisits=7, meanQ=10.141429, numObservations: 5
action 1, numVisits=3, meanQ=5.663333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.386517 0.12197 0.829528 0.92434 0.481894 0.0116506 0.59153 0.401439 0.785017 0.477532 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 29
Initial state: 0 0.603658 0.318813 0.895073 0.778553 0.0189324 0.867401 0.923541 0.155618 0.363465 0.971364 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27279 episodes
GETTING ACTION FROM:
action 1, numVisits=27273, meanQ=12.883782, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.603658 0.318813 0.895073 0.778553 0.0189324 0.867401 0.923541 0.155618 0.363465 0.971364 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 30
Initial state: 0 0.733522 0.478604 0.94597 0.00385352 0.557908 0.451561 0.714402 0.624087 0.32383 0.024885 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27528 episodes
GETTING ACTION FROM:
action 1, numVisits=27382, meanQ=12.970774, numObservations: 9
action 3, numVisits=141, meanQ=10.691006, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.733522 0.478604 0.94597 0.00385352 0.557908 0.451561 0.714402 0.624087 0.32383 0.024885 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 31
Initial state: 0 0.117758 0.662256 0.200502 0.906107 0.848423 0.998527 0.3201 0.99644 0.633994 0.417374 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27286 episodes
GETTING ACTION FROM:
action 2, numVisits=27272, meanQ=12.883684, numObservations: 9
action 4, numVisits=7, meanQ=9.000000, numObservations: 6
action 1, numVisits=3, meanQ=5.000033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.117758 0.662256 0.200502 0.906107 0.848423 0.998527 0.3201 0.99644 0.633994 0.417374 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=198, meanQ=15.115985, numObservations: 9
action 4, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 31863 episodes
GETTING ACTION FROM:
action 1, numVisits=32059, meanQ=16.611268, numObservations: 9
action 4, numVisits=3, meanQ=3.330000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.117758 0.662256 0.200502 0.906107 0.848423 0.998527 0.3201 0.99644 0.633994 0.417374 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 32
Initial state: 0 0.642973 0.349144 0.986698 0.10324 0.0857119 0.710202 0.160092 0.194875 0.421634 0.379236 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26870 episodes
GETTING ACTION FROM:
action 2, numVisits=26864, meanQ=12.486247, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.642973 0.349144 0.986698 0.10324 0.0857119 0.710202 0.160092 0.194875 0.421634 0.379236 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 33
Initial state: 0 0.708768 0.655226 0.167791 0.0461266 0.00550765 0.0209627 0.575627 0.445049 0.797873 0.525312 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26648 episodes
GETTING ACTION FROM:
action 1, numVisits=26622, meanQ=12.749812, numObservations: 9
action 2, numVisits=13, meanQ=8.383092, numObservations: 6
action 4, numVisits=9, meanQ=7.554467, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.708768 0.655226 0.167791 0.0461266 0.00550765 0.0209627 0.575627 0.445049 0.797873 0.525312 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 34
Initial state: 0 0.631083 0.336622 0.801591 0.0704307 0.582957 0.529278 0.0678878 0.211613 0.264951 0.55996 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27467 episodes
GETTING ACTION FROM:
action 4, numVisits=27459, meanQ=12.825076, numObservations: 9
action 5, numVisits=3, meanQ=5.663333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.631083 0.336622 0.801591 0.0704307 0.582957 0.529278 0.0678878 0.211613 0.264951 0.55996 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 35
Initial state: 0 0.469136 0.186664 0.00975866 0.205834 0.597952 0.451459 0.405057 0.683659 0.516621 0.951983 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27352 episodes
GETTING ACTION FROM:
action 1, numVisits=27323, meanQ=12.506815, numObservations: 9
action 5, numVisits=22, meanQ=10.910000, numObservations: 9
action 4, numVisits=3, meanQ=5.663333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.469136 0.186664 0.00975866 0.205834 0.597952 0.451459 0.405057 0.683659 0.516621 0.951983 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=3304, meanQ=13.544884, numObservations: 9
action 4, numVisits=6, meanQ=8.501683, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 7259 episodes
GETTING ACTION FROM:
action 5, numVisits=10555, meanQ=11.934160, numObservations: 9
action 4, numVisits=10, meanQ=7.779300, numObservations: 6
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.340000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 0 0.469136 0.186664 0.00975866 0.205834 0.597952 0.451459 0.405057 0.683659 0.516621 0.951983 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=1396, meanQ=15.835291, numObservations: 9
action 3, numVisits=5, meanQ=6.196000, numObservations: 4
action 2, numVisits=5, meanQ=4.598000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 8029 episodes
GETTING ACTION FROM:
action 4, numVisits=9425, meanQ=16.910307, numObservations: 9
action 3, numVisits=5, meanQ=6.196000, numObservations: 4
action 2, numVisits=5, meanQ=4.598000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 1 0.469136 0.186664 0.00975866 0.205834 0.597952 0.451459 0.405057 0.683659 0.516621 0.951983 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 36
Initial state: 0 0.00849565 0.956913 0.760492 0.293546 0.684013 0.682714 0.218613 0.916402 0.55231 0.331396 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27426 episodes
GETTING ACTION FROM:
action 2, numVisits=27420, meanQ=12.964471, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.00849565 0.956913 0.760492 0.293546 0.684013 0.682714 0.218613 0.916402 0.55231 0.331396 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 37
Initial state: 0 0.48682 0.106461 0.125418 0.0368466 0.997744 0.284488 0.834919 0.198948 0.582335 0.397817 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27253 episodes
GETTING ACTION FROM:
action 5, numVisits=27247, meanQ=12.749232, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.48682 0.106461 0.125418 0.0368466 0.997744 0.284488 0.834919 0.198948 0.582335 0.397817 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=416, meanQ=19.530769, numObservations: 9
action 4, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 22325 episodes
GETTING ACTION FROM:
action 5, numVisits=462, meanQ=19.874092, numObservations: 9
action 4, numVisits=22279, meanQ=16.544866, numObservations: 9
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.48682 0.106461 0.125418 0.0368466 0.997744 0.284488 0.834919 0.198948 0.582335 0.397817 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 38
Initial state: 0 0.223518 0.300975 0.546744 0.444155 0.103984 0.844235 0.537734 0.0318194 0.021667 0.409742 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27544 episodes
GETTING ACTION FROM:
action 3, numVisits=27537, meanQ=12.961801, numObservations: 9
action 4, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.223518 0.300975 0.546744 0.444155 0.103984 0.844235 0.537734 0.0318194 0.021667 0.409742 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=4371, meanQ=13.412955, numObservations: 9
action 4, numVisits=7, meanQ=11.282857, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 8289 episodes
GETTING ACTION FROM:
action 1, numVisits=12639, meanQ=14.843582, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=26, meanQ=-27.398607, numObservations: 9
action: 1
Next state: 0 0.223518 0.300975 0.546744 0.444155 0.103984 0.844235 0.537734 0.0318194 0.021667 0.409742 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=30, meanQ=17.067737, numObservations: 5
action 2, numVisits=11, meanQ=8.443463, numObservations: 7
action 1, numVisits=10, meanQ=1.725984, numObservations: 5
action -1, numVisits=23, meanQ=-2.120588, numObservations: 20
action 4, numVisits=2, meanQ=-6.887041, numObservations: 2
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=34, meanQ=-28.790492, numObservations: 21
Sampled 12475 episodes
GETTING ACTION FROM:
action 2, numVisits=12473, meanQ=14.545825, numObservations: 9
action 3, numVisits=43, meanQ=14.142549, numObservations: 6
action 1, numVisits=10, meanQ=1.725984, numObservations: 5
action -1, numVisits=23, meanQ=-2.120588, numObservations: 20
action 4, numVisits=2, meanQ=-6.887041, numObservations: 2
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=34, meanQ=-28.790492, numObservations: 21
action: 2
Next state: 1 0.223518 0.300975 0.546744 0.444155 0.103984 0.844235 0.537734 0.0318194 0.021667 0.409742 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 39
Initial state: 0 0.587211 0.390573 0.332238 0.902144 0.190332 0.861805 0.79257 0.731219 0.888825 0.483216 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27493 episodes
GETTING ACTION FROM:
action 4, numVisits=27487, meanQ=12.815160, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.587211 0.390573 0.332238 0.902144 0.190332 0.861805 0.79257 0.731219 0.888825 0.483216 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 40
Initial state: 0 0.51729 0.357824 0.39658 0.847304 0.706153 0.0448608 0.650609 0.322144 0.356532 0.0365607 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27227 episodes
GETTING ACTION FROM:
action 3, numVisits=27214, meanQ=12.733307, numObservations: 9
action 4, numVisits=8, meanQ=3.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.51729 0.357824 0.39658 0.847304 0.706153 0.0448608 0.650609 0.322144 0.356532 0.0365607 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 41
Initial state: 0 0.618919 0.390181 0.624654 0.960849 0.460977 0.966017 0.823255 0.0423261 0.746688 0.111515 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27588 episodes
GETTING ACTION FROM:
action 3, numVisits=27579, meanQ=12.972479, numObservations: 9
action 5, numVisits=4, meanQ=8.250000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.618919 0.390181 0.624654 0.960849 0.460977 0.966017 0.823255 0.0423261 0.746688 0.111515 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 42
Initial state: 0 0.182281 0.105187 0.271121 0.620576 0.562996 0.41963 0.949395 0.455942 0.689864 0.719723 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27496 episodes
GETTING ACTION FROM:
action 5, numVisits=26745, meanQ=12.874453, numObservations: 9
action 4, numVisits=745, meanQ=12.567445, numObservations: 9
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.182281 0.105187 0.271121 0.620576 0.562996 0.41963 0.949395 0.455942 0.689864 0.719723 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 43
Initial state: 0 0.539396 0.611565 0.483238 0.26427 0.177256 0.224595 0.599441 0.454058 0.963574 0.334367 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27458 episodes
GETTING ACTION FROM:
action 1, numVisits=27432, meanQ=12.703066, numObservations: 9
action 5, numVisits=19, meanQ=6.079495, numObservations: 7
action 3, numVisits=3, meanQ=5.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.539396 0.611565 0.483238 0.26427 0.177256 0.224595 0.599441 0.454058 0.963574 0.334367 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 44
Initial state: 0 0.225746 0.652298 0.581533 0.358334 0.352846 0.895019 0.384805 0.440143 0.265616 0.703228 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27353 episodes
GETTING ACTION FROM:
action 1, numVisits=27338, meanQ=12.912545, numObservations: 9
action 3, numVisits=8, meanQ=6.498762, numObservations: 5
action 2, numVisits=3, meanQ=5.000033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.225746 0.652298 0.581533 0.358334 0.352846 0.895019 0.384805 0.440143 0.265616 0.703228 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=4490, meanQ=13.932882, numObservations: 9
action -1, numVisits=6, meanQ=-1.010000, numObservations: 6
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 4, numVisits=6, meanQ=-1.171667, numObservations: 6
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 9181 episodes
GETTING ACTION FROM:
action 3, numVisits=13671, meanQ=14.444505, numObservations: 9
action -1, numVisits=6, meanQ=-1.010000, numObservations: 6
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 4, numVisits=6, meanQ=-1.171667, numObservations: 6
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.225746 0.652298 0.581533 0.358334 0.352846 0.895019 0.384805 0.440143 0.265616 0.703228 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 45
Initial state: 0 0.247244 0.282989 0.405211 0.293662 0.604648 0.42317 0.962381 0.433701 0.165911 0.062156 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27087 episodes
GETTING ACTION FROM:
action 1, numVisits=27078, meanQ=12.553447, numObservations: 9
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action 5, numVisits=3, meanQ=5.663333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.247244 0.282989 0.405211 0.293662 0.604648 0.42317 0.962381 0.433701 0.165911 0.062156 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 46
Initial state: 0 0.825927 0.538692 0.608143 0.326357 0.0957218 0.410451 0.806014 0.283412 0.799885 0.68089 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27521 episodes
GETTING ACTION FROM:
action 2, numVisits=27497, meanQ=12.699012, numObservations: 9
action 5, numVisits=14, meanQ=8.499293, numObservations: 8
action 1, numVisits=6, meanQ=7.666667, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.825927 0.538692 0.608143 0.326357 0.0957218 0.410451 0.806014 0.283412 0.799885 0.68089 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 47
Initial state: 0 0.179145 0.209045 0.524772 0.190179 0.555684 0.459789 0.114343 0.669135 0.549267 0.973186 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27513 episodes
GETTING ACTION FROM:
action 4, numVisits=27506, meanQ=12.899808, numObservations: 9
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.179145 0.209045 0.524772 0.190179 0.555684 0.459789 0.114343 0.669135 0.549267 0.973186 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=4593, meanQ=13.723355, numObservations: 9
action 5, numVisits=8, meanQ=10.246263, numObservations: 5
action 3, numVisits=4, meanQ=8.497500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 9616 episodes
GETTING ACTION FROM:
action 2, numVisits=14204, meanQ=14.434679, numObservations: 9
action 3, numVisits=6, meanQ=7.831667, numObservations: 3
action 5, numVisits=9, meanQ=7.453344, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.179145 0.209045 0.524772 0.190179 0.555684 0.459789 0.114343 0.669135 0.549267 0.973186 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=481, meanQ=14.063755, numObservations: 8
action 3, numVisits=644, meanQ=12.962541, numObservations: 9
action 5, numVisits=5, meanQ=0.396020, numObservations: 4
action 1, numVisits=3, meanQ=-7.805923, numObservations: 3
action 0, numVisits=23, meanQ=-45.785044, numObservations: 16
action 2, numVisits=4, meanQ=-65.192861, numObservations: 3
action -1, numVisits=8, meanQ=-132.288296, numObservations: 7
Sampled 5426 episodes
GETTING ACTION FROM:
action 3, numVisits=6069, meanQ=15.633519, numObservations: 9
action 4, numVisits=482, meanQ=14.055710, numObservations: 8
action 5, numVisits=5, meanQ=0.396020, numObservations: 4
action 1, numVisits=3, meanQ=-7.805923, numObservations: 3
action 0, numVisits=23, meanQ=-45.785044, numObservations: 16
action 2, numVisits=4, meanQ=-65.192861, numObservations: 3
action -1, numVisits=8, meanQ=-132.288296, numObservations: 7
action: 3
Next state: 1 0.179145 0.209045 0.524772 0.190179 0.555684 0.459789 0.114343 0.669135 0.549267 0.973186 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 48
Initial state: 0 0.628132 0.322436 0.108987 0.609482 0.766147 0.273628 0.61299 0.674197 0.903054 0.963921 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27211 episodes
GETTING ACTION FROM:
action 4, numVisits=27196, meanQ=12.679315, numObservations: 9
action 5, numVisits=10, meanQ=9.300000, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.628132 0.322436 0.108987 0.609482 0.766147 0.273628 0.61299 0.674197 0.903054 0.963921 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 49
Initial state: 0 0.14215 0.0165947 0.632532 0.389587 0.740977 0.815227 0.540432 0.79294 0.851096 0.761576 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27128 episodes
GETTING ACTION FROM:
action 4, numVisits=27120, meanQ=12.578156, numObservations: 9
action 1, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 0 0.14215 0.0165947 0.632532 0.389587 0.740977 0.815227 0.540432 0.79294 0.851096 0.761576 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=4546, meanQ=13.885744, numObservations: 9
action 2, numVisits=12, meanQ=6.580850, numObservations: 6
action 5, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 8854 episodes
GETTING ACTION FROM:
action 1, numVisits=13396, meanQ=14.601443, numObservations: 9
action 2, numVisits=12, meanQ=6.580850, numObservations: 6
action 5, numVisits=5, meanQ=6.196000, numObservations: 4
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.14215 0.0165947 0.632532 0.389587 0.740977 0.815227 0.540432 0.79294 0.851096 0.761576 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=1147, meanQ=12.477519, numObservations: 9
action 3, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 4629 episodes
GETTING ACTION FROM:
action 2, numVisits=5776, meanQ=13.928349, numObservations: 9
action 3, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.14215 0.0165947 0.632532 0.389587 0.740977 0.815227 0.540432 0.79294 0.851096 0.761576 w: 1
Observation: 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 50
Initial state: 0 0.491327 0.981436 0.595367 0.343843 0.989986 0.859535 0.208454 0.840318 0.720712 0.137859 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26839 episodes
GETTING ACTION FROM:
action 4, numVisits=26831, meanQ=12.752798, numObservations: 9
action 3, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.491327 0.981436 0.595367 0.343843 0.989986 0.859535 0.208454 0.840318 0.720712 0.137859 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=4510, meanQ=13.912722, numObservations: 9
action 4, numVisits=58, meanQ=13.155322, numObservations: 5
action 5, numVisits=13, meanQ=12.039238, numObservations: 7
action 1, numVisits=15, meanQ=11.598000, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 8316 episodes
GETTING ACTION FROM:
action 3, numVisits=12636, meanQ=14.865277, numObservations: 9
action 4, numVisits=60, meanQ=13.446144, numObservations: 6
action 1, numVisits=16, meanQ=10.139060, numObservations: 7
action 5, numVisits=198, meanQ=7.943679, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.491327 0.981436 0.595367 0.343843 0.989986 0.859535 0.208454 0.840318 0.720712 0.137859 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
[32m ProblemEnvironment.hpp 351: Done.[39m
