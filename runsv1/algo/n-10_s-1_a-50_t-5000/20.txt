Run # 1
Initial state: 0 0.546602 0.134513 0.714944 0.284943 0.531069 0.343678 0.42876 0.220172 0.442056 0.446618 0.982833 0.126147 0.00598746 0.311627 0.32218 0.652469 0.249853 0.511971 0.665311 0.707968 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 101265 episodes
GETTING ACTION FROM:
action 10, numVisits=101241, meanQ=9.903957, numObservations: 9
action 5, numVisits=8, meanQ=6.888750, numObservations: 6
action 9, numVisits=7, meanQ=5.141429, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 10
Next state: 2 0.546602 0.134513 0.714944 0.284943 0.531069 0.343678 0.42876 0.220172 0.442056 0.446618 0.982833 0.126147 0.00598746 0.311627 0.32218 0.652469 0.249853 0.511971 0.665311 0.707968 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 2
Initial state: 0 0.16624 0.299461 0.748438 0.00833511 0.398052 0.476673 0.181909 0.324333 0.665875 0.814956 0.854801 0.863708 0.965501 0.644112 0.110597 0.889246 0.7805 0.551445 0.287957 0.16827 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 106936 episodes
GETTING ACTION FROM:
action 10, numVisits=106908, meanQ=9.774275, numObservations: 9
action 7, numVisits=12, meanQ=5.580833, numObservations: 7
action 9, numVisits=3, meanQ=5.333333, numObservations: 3
action 8, numVisits=3, meanQ=3.330000, numObservations: 3
action 6, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 10
Next state: 0 0.16624 0.299461 0.748438 0.00833511 0.398052 0.476673 0.181909 0.324333 0.665875 0.814956 0.854801 0.863708 0.965501 0.644112 0.110597 0.889246 0.7805 0.551445 0.287957 0.16827 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=10031, meanQ=10.278814, numObservations: 9
action 1, numVisits=12, meanQ=4.165017, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 6, numVisits=1, meanQ=-3.010000, numObservations: 1
action 9, numVisits=1, meanQ=-3.010000, numObservations: 1
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 26019 episodes
GETTING ACTION FROM:
action 5, numVisits=36009, meanQ=9.647643, numObservations: 9
action 6, numVisits=18, meanQ=5.191797, numObservations: 7
action 9, numVisits=14, meanQ=5.103536, numObservations: 8
action 1, numVisits=12, meanQ=4.165017, numObservations: 6
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action -1, numVisits=5, meanQ=-1.208000, numObservations: 5
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 1
action 4, numVisits=2, meanQ=-7.005000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.16624 0.299461 0.748438 0.00833511 0.398052 0.476673 0.181909 0.324333 0.665875 0.814956 0.854801 0.863708 0.965501 0.644112 0.110597 0.889246 0.7805 0.551445 0.287957 0.16827 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 3
Initial state: 0 0.0150086 0.599154 0.0817234 0.816118 0.0202577 0.865232 0.432305 0.475877 0.837186 0.539196 0.840104 0.206643 0.0734413 0.239266 0.766261 0.821227 0.350062 0.705353 0.104474 0.831005 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 106065 episodes
GETTING ACTION FROM:
action 9, numVisits=106043, meanQ=9.791968, numObservations: 9
action 4, numVisits=7, meanQ=4.000000, numObservations: 5
action 2, numVisits=3, meanQ=3.000000, numObservations: 2
action 1, numVisits=4, meanQ=1.497500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 7, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 9
Next state: 1 0.0150086 0.599154 0.0817234 0.816118 0.0202577 0.865232 0.432305 0.475877 0.837186 0.539196 0.840104 0.206643 0.0734413 0.239266 0.766261 0.821227 0.350062 0.705353 0.104474 0.831005 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 4
Initial state: 0 0.165178 0.0613027 0.844284 0.445393 0.52334 0.501523 0.354165 0.471315 0.116726 0.34051 0.570488 0.644469 0.736703 0.204712 0.651726 0.414642 0.163775 0.522561 0.628171 0.946477 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 104722 episodes
GETTING ACTION FROM:
action 5, numVisits=104669, meanQ=9.769624, numObservations: 9
action 2, numVisits=34, meanQ=8.529124, numObservations: 8
action 8, numVisits=6, meanQ=6.500000, numObservations: 5
action 1, numVisits=3, meanQ=3.000000, numObservations: 3
action 3, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-4.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.165178 0.0613027 0.844284 0.445393 0.52334 0.501523 0.354165 0.471315 0.116726 0.34051 0.570488 0.644469 0.736703 0.204712 0.651726 0.414642 0.163775 0.522561 0.628171 0.946477 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=10086, meanQ=10.147781, numObservations: 9
action 7, numVisits=5, meanQ=4.598000, numObservations: 5
action 10, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 9, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 22702 episodes
GETTING ACTION FROM:
action 2, numVisits=32780, meanQ=10.031126, numObservations: 9
action 7, numVisits=5, meanQ=4.598000, numObservations: 5
action 10, numVisits=5, meanQ=4.598000, numObservations: 4
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.257500, numObservations: 4
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 9, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.165178 0.0613027 0.844284 0.445393 0.52334 0.501523 0.354165 0.471315 0.116726 0.34051 0.570488 0.644469 0.736703 0.204712 0.651726 0.414642 0.163775 0.522561 0.628171 0.946477 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 5
Initial state: 0 0.862789 0.112507 0.977274 0.381568 0.244079 0.0915123 0.925786 0.881301 0.889141 0.248206 0.387893 0.385506 0.595855 0.0154441 0.288247 0.849928 0.260205 0.804513 0.197078 0.294053 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 105655 episodes
GETTING ACTION FROM:
action 7, numVisits=105598, meanQ=9.780298, numObservations: 9
action 5, numVisits=10, meanQ=7.299000, numObservations: 5
action 9, numVisits=20, meanQ=7.225000, numObservations: 6
action 2, numVisits=9, meanQ=6.998889, numObservations: 5
action 4, numVisits=9, meanQ=6.331111, numObservations: 7
action 1, numVisits=3, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 7
Next state: 0 0.862789 0.112507 0.977274 0.381568 0.244079 0.0915123 0.925786 0.881301 0.889141 0.248206 0.387893 0.385506 0.595855 0.0154441 0.288247 0.849928 0.260205 0.804513 0.197078 0.294053 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1038, meanQ=11.888186, numObservations: 9
action 10, numVisits=130, meanQ=11.833232, numObservations: 9
action 4, numVisits=456, meanQ=11.803519, numObservations: 9
action 5, numVisits=4, meanQ=8.497500, numObservations: 4
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action 8, numVisits=4, meanQ=6.500000, numObservations: 2
action 9, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 6, numVisits=1, meanQ=-3.010000, numObservations: 1
action 7, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 44911 episodes
GETTING ACTION FROM:
action 2, numVisits=2572, meanQ=9.742846, numObservations: 9
action 10, numVisits=37955, meanQ=9.418218, numObservations: 9
action 4, numVisits=5953, meanQ=8.579812, numObservations: 9
action 8, numVisits=27, meanQ=7.000062, numObservations: 9
action 5, numVisits=11, meanQ=5.635455, numObservations: 7
action 3, numVisits=9, meanQ=5.333333, numObservations: 6
action 9, numVisits=3, meanQ=0.666667, numObservations: 2
action 6, numVisits=4, meanQ=-0.252500, numObservations: 3
action -1, numVisits=8, meanQ=-1.628750, numObservations: 8
action 0, numVisits=8, meanQ=-1.628750, numObservations: 8
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 7, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.862789 0.112507 0.977274 0.381568 0.244079 0.0915123 0.925786 0.881301 0.889141 0.248206 0.387893 0.385506 0.595855 0.0154441 0.288247 0.849928 0.260205 0.804513 0.197078 0.294053 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 6
Initial state: 0 0.852695 0.80166 0.0315045 0.896411 0.707502 0.0173038 0.567742 0.698869 0.245826 0.265062 0.974525 0.622197 0.865241 0.831152 0.383569 0.704066 0.47131 0.443424 0.586069 0.508973 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 105227 episodes
GETTING ACTION FROM:
action 2, numVisits=105190, meanQ=9.900256, numObservations: 9
action 6, numVisits=13, meanQ=6.230769, numObservations: 6
action 3, numVisits=9, meanQ=6.111111, numObservations: 6
action 10, numVisits=7, meanQ=6.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.852695 0.80166 0.0315045 0.896411 0.707502 0.0173038 0.567742 0.698869 0.245826 0.265062 0.974525 0.622197 0.865241 0.831152 0.383569 0.704066 0.47131 0.443424 0.586069 0.508973 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 6, numVisits=11445, meanQ=10.621521, numObservations: 9
action 3, numVisits=15, meanQ=4.866007, numObservations: 8
action 8, numVisits=9, meanQ=4.217778, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 7, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 27415 episodes
GETTING ACTION FROM:
action 1, numVisits=27385, meanQ=12.989775, numObservations: 9
action 6, numVisits=11455, meanQ=10.627311, numObservations: 9
action 7, numVisits=15, meanQ=5.462709, numObservations: 7
action 3, numVisits=15, meanQ=4.866007, numObservations: 8
action 8, numVisits=9, meanQ=4.217778, numObservations: 7
action 0, numVisits=5, meanQ=-1.010000, numObservations: 5
action -1, numVisits=4, meanQ=-1.257500, numObservations: 4
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.852695 0.80166 0.0315045 0.896411 0.707502 0.0173038 0.567742 0.698869 0.245826 0.265062 0.974525 0.622197 0.865241 0.831152 0.383569 0.704066 0.47131 0.443424 0.586069 0.508973 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 7
Initial state: 0 0.241294 0.918759 0.344249 0.307909 0.286787 0.714895 0.665475 0.587659 0.419016 0.883398 0.251988 0.830972 0.791942 0.780681 0.616773 0.811404 0.402548 0.400771 0.421661 0.679541 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 104561 episodes
GETTING ACTION FROM:
action 8, numVisits=104509, meanQ=9.840267, numObservations: 9
action 1, numVisits=28, meanQ=7.856804, numObservations: 8
action 2, numVisits=5, meanQ=5.800000, numObservations: 3
action 6, numVisits=5, meanQ=5.800000, numObservations: 3
action 9, numVisits=3, meanQ=3.000000, numObservations: 3
action 4, numVisits=3, meanQ=0.666667, numObservations: 2
action 5, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 7, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 8
Next state: 1 0.241294 0.918759 0.344249 0.307909 0.286787 0.714895 0.665475 0.587659 0.419016 0.883398 0.251988 0.830972 0.791942 0.780681 0.616773 0.811404 0.402548 0.400771 0.421661 0.679541 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 8
Initial state: 0 0.475717 0.3739 0.0831241 0.996833 0.0884213 0.811198 0.223036 0.361946 0.491629 0.670033 0.878616 0.20952 0.172368 0.986878 0.783054 0.0265643 0.778774 0.775304 0.625962 0.0414777 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 106516 episodes
GETTING ACTION FROM:
action 1, numVisits=106493, meanQ=9.961219, numObservations: 9
action 9, numVisits=11, meanQ=7.273645, numObservations: 7
action 5, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 6, numVisits=1, meanQ=-4.000000, numObservations: 1
action 7, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.475717 0.3739 0.0831241 0.996833 0.0884213 0.811198 0.223036 0.361946 0.491629 0.670033 0.878616 0.20952 0.172368 0.986878 0.783054 0.0265643 0.778774 0.775304 0.625962 0.0414777 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 9
Initial state: 0 0.569816 0.1056 0.699502 0.978686 0.557219 0.684099 0.557957 0.578166 0.242288 0.835672 0.900429 0.869562 0.788841 0.328188 0.03951 0.181314 0.872157 0.423543 0.410973 0.390123 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 103000 episodes
GETTING ACTION FROM:
action 9, numVisits=102957, meanQ=9.986052, numObservations: 9
action 10, numVisits=15, meanQ=6.940007, numObservations: 5
action 3, numVisits=9, meanQ=6.221111, numObservations: 6
action 2, numVisits=5, meanQ=4.400000, numObservations: 4
action 6, numVisits=3, meanQ=3.330000, numObservations: 3
action 1, numVisits=3, meanQ=3.000000, numObservations: 3
action 8, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 7, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 9
Next state: 1 0.569816 0.1056 0.699502 0.978686 0.557219 0.684099 0.557957 0.578166 0.242288 0.835672 0.900429 0.869562 0.788841 0.328188 0.03951 0.181314 0.872157 0.423543 0.410973 0.390123 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 10
Initial state: 0 0.243698 0.847164 0.458607 0.454842 0.652289 0.188816 0.286048 0.88697 0.939608 0.677821 0.0715977 0.520273 0.177439 0.818277 0.871607 0.822272 0.685615 0.603832 0.643378 0.103737 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 107943 episodes
GETTING ACTION FROM:
action 8, numVisits=95649, meanQ=9.957048, numObservations: 9
action 7, numVisits=12260, meanQ=9.907542, numObservations: 9
action 9, numVisits=14, meanQ=8.000000, numObservations: 7
action 5, numVisits=8, meanQ=6.500000, numObservations: 4
action 1, numVisits=5, meanQ=4.426020, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 8
Next state: 1 0.243698 0.847164 0.458607 0.454842 0.652289 0.188816 0.286048 0.88697 0.939608 0.677821 0.0715977 0.520273 0.177439 0.818277 0.871607 0.822272 0.685615 0.603832 0.643378 0.103737 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 11
Initial state: 0 0.080443 0.240426 0.327402 0.555243 0.289286 0.595052 0.49447 0.191452 0.792153 0.733913 0.176943 0.871266 0.974438 0.883895 0.756909 0.179671 0.621485 0.189162 0.374449 0.431322 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 106339 episodes
GETTING ACTION FROM:
action 4, numVisits=106328, meanQ=9.774291, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-4.000000, numObservations: 1
action 7, numVisits=1, meanQ=-4.000000, numObservations: 1
action 9, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.080443 0.240426 0.327402 0.555243 0.289286 0.595052 0.49447 0.191452 0.792153 0.733913 0.176943 0.871266 0.974438 0.883895 0.756909 0.179671 0.621485 0.189162 0.374449 0.431322 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 12
Initial state: 0 0.0632891 0.876208 0.450469 0.803129 0.708509 0.455219 0.122393 0.855829 0.466199 0.456577 0.493096 0.731725 0.267945 0.8402 0.764344 0.519803 0.80888 0.755892 0.0432567 0.593357 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 106698 episodes
GETTING ACTION FROM:
action 10, numVisits=106642, meanQ=9.814641, numObservations: 9
action 2, numVisits=29, meanQ=7.720348, numObservations: 8
action 8, numVisits=12, meanQ=5.915842, numObservations: 7
action 6, numVisits=5, meanQ=4.598000, numObservations: 4
action 5, numVisits=3, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 9, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 10
Next state: 0 0.0632891 0.876208 0.450469 0.803129 0.708509 0.455219 0.122393 0.855829 0.466199 0.456577 0.493096 0.731725 0.267945 0.8402 0.764344 0.519803 0.80888 0.755892 0.0432567 0.593357 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=11596, meanQ=10.351959, numObservations: 9
action 4, numVisits=11, meanQ=6.727282, numObservations: 8
action 1, numVisits=7, meanQ=6.282857, numObservations: 5
action 6, numVisits=7, meanQ=6.282857, numObservations: 5
action 9, numVisits=5, meanQ=6.196000, numObservations: 3
action 7, numVisits=12, meanQ=5.920025, numObservations: 6
action 3, numVisits=5, meanQ=4.598000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 8, numVisits=1, meanQ=-3.010000, numObservations: 1
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 30971 episodes
GETTING ACTION FROM:
action 5, numVisits=42553, meanQ=11.789683, numObservations: 9
action 4, numVisits=11, meanQ=6.727282, numObservations: 8
action 6, numVisits=7, meanQ=6.282857, numObservations: 5
action 9, numVisits=7, meanQ=6.060082, numObservations: 4
action 7, numVisits=12, meanQ=5.920025, numObservations: 6
action 1, numVisits=14, meanQ=5.410507, numObservations: 7
action 3, numVisits=5, meanQ=4.598000, numObservations: 5
action 0, numVisits=4, meanQ=-1.257500, numObservations: 4
action -1, numVisits=3, meanQ=-1.340000, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 8, numVisits=1, meanQ=-3.010000, numObservations: 1
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 1 0.0632891 0.876208 0.450469 0.803129 0.708509 0.455219 0.122393 0.855829 0.466199 0.456577 0.493096 0.731725 0.267945 0.8402 0.764344 0.519803 0.80888 0.755892 0.0432567 0.593357 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 13
Initial state: 0 0.377576 0.201724 0.158143 0.66169 0.385376 0.426817 0.694989 0.391419 0.214364 0.0261579 0.311201 0.113584 0.479164 0.991511 0.817554 0.762234 0.61937 0.222805 0.924182 0.573712 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 106112 episodes
GETTING ACTION FROM:
action 7, numVisits=106079, meanQ=9.819811, numObservations: 9
action 9, numVisits=17, meanQ=7.648253, numObservations: 7
action 6, numVisits=3, meanQ=5.663333, numObservations: 3
action 1, numVisits=3, meanQ=3.000000, numObservations: 3
action 5, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 7
Next state: 1 0.377576 0.201724 0.158143 0.66169 0.385376 0.426817 0.694989 0.391419 0.214364 0.0261579 0.311201 0.113584 0.479164 0.991511 0.817554 0.762234 0.61937 0.222805 0.924182 0.573712 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 14
Initial state: 0 0.721613 0.375167 0.396981 0.415476 0.0434373 0.562235 0.483278 0.955594 0.242861 0.0545005 0.299347 0.634975 0.616235 0.586176 0.753464 0.0484979 0.314864 0.873252 0.987945 0.15829 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 106031 episodes
GETTING ACTION FROM:
action 1, numVisits=106000, meanQ=9.755903, numObservations: 9
action 2, numVisits=14, meanQ=5.645014, numObservations: 6
action 6, numVisits=6, meanQ=4.331667, numObservations: 4
action 7, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action 9, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.721613 0.375167 0.396981 0.415476 0.0434373 0.562235 0.483278 0.955594 0.242861 0.0545005 0.299347 0.634975 0.616235 0.586176 0.753464 0.0484979 0.314864 0.873252 0.987945 0.15829 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 15
Initial state: 0 0.69508 0.288271 0.180055 0.24975 0.42666 0.784999 0.970806 0.808038 0.369061 0.670024 0.54289 0.840582 0.364564 0.47791 0.840234 0.932901 0.731547 0.711093 0.503668 0.649389 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 105839 episodes
GETTING ACTION FROM:
action 9, numVisits=105822, meanQ=9.726008, numObservations: 9
action 1, numVisits=5, meanQ=4.400000, numObservations: 4
action 10, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 9
Next state: 1 0.69508 0.288271 0.180055 0.24975 0.42666 0.784999 0.970806 0.808038 0.369061 0.670024 0.54289 0.840582 0.364564 0.47791 0.840234 0.932901 0.731547 0.711093 0.503668 0.649389 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 16
Initial state: 0 0.308586 0.508618 0.857376 0.49424 0.185401 0.286195 0.64425 0.556631 0.807199 0.885718 0.993697 0.474788 0.659326 0.0502995 0.071818 0.853043 0.885662 0.17712 0.468115 0.490489 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 106207 episodes
GETTING ACTION FROM:
action 7, numVisits=106151, meanQ=9.762946, numObservations: 9
action 4, numVisits=18, meanQ=6.610000, numObservations: 8
action 3, numVisits=19, meanQ=6.103684, numObservations: 6
action 6, numVisits=5, meanQ=4.598000, numObservations: 4
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action 8, numVisits=3, meanQ=3.330000, numObservations: 3
action 9, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 7
Next state: 2 0.308586 0.508618 0.857376 0.49424 0.185401 0.286195 0.64425 0.556631 0.807199 0.885718 0.993697 0.474788 0.659326 0.0502995 0.071818 0.853043 0.885662 0.17712 0.468115 0.490489 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 17
Initial state: 0 0.572149 0.528041 0.331575 0.99152 0.52449 0.904941 0.594938 0.502376 0.209733 0.396371 0.925174 0.584719 0.368909 0.440013 0.109807 0.269331 0.923021 0.243099 0.384244 0.824463 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 106779 episodes
GETTING ACTION FROM:
action 2, numVisits=34787, meanQ=9.917309, numObservations: 9
action 6, numVisits=71972, meanQ=9.833365, numObservations: 9
action 3, numVisits=7, meanQ=7.282857, numObservations: 5
action 8, numVisits=5, meanQ=5.204020, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.572149 0.528041 0.331575 0.99152 0.52449 0.904941 0.594938 0.502376 0.209733 0.396371 0.925174 0.584719 0.368909 0.440013 0.109807 0.269331 0.923021 0.243099 0.384244 0.824463 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 6, numVisits=3716, meanQ=10.413009, numObservations: 9
action 3, numVisits=5, meanQ=4.598000, numObservations: 4
action 9, numVisits=7, meanQ=4.000000, numObservations: 4
action 5, numVisits=3, meanQ=0.666667, numObservations: 2
action 8, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 29477 episodes
GETTING ACTION FROM:
action 6, numVisits=33185, meanQ=11.960941, numObservations: 9
action 3, numVisits=7, meanQ=4.602647, numObservations: 4
action 9, numVisits=7, meanQ=4.000000, numObservations: 4
action 5, numVisits=3, meanQ=0.666667, numObservations: 2
action 8, numVisits=3, meanQ=0.666667, numObservations: 3
action 0, numVisits=4, meanQ=-1.257500, numObservations: 4
action -1, numVisits=4, meanQ=-1.505000, numObservations: 4
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 6
Next state: 1 0.572149 0.528041 0.331575 0.99152 0.52449 0.904941 0.594938 0.502376 0.209733 0.396371 0.925174 0.584719 0.368909 0.440013 0.109807 0.269331 0.923021 0.243099 0.384244 0.824463 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 18
Initial state: 0 0.0019439 0.253615 0.143921 0.876371 0.98597 0.639514 0.45439 0.352215 0.892962 0.557837 0.878109 0.51007 0.697562 0.346256 0.283869 0.459758 0.855436 0.564296 0.791748 0.303182 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 106270 episodes
GETTING ACTION FROM:
action 2, numVisits=105781, meanQ=9.846037, numObservations: 9
action 10, numVisits=423, meanQ=9.518037, numObservations: 9
action 3, numVisits=44, meanQ=8.604555, numObservations: 8
action 1, numVisits=12, meanQ=7.749167, numObservations: 6
action 9, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-4.000000, numObservations: 1
action 7, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.0019439 0.253615 0.143921 0.876371 0.98597 0.639514 0.45439 0.352215 0.892962 0.557837 0.878109 0.51007 0.697562 0.346256 0.283869 0.459758 0.855436 0.564296 0.791748 0.303182 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 19
Initial state: 0 0.745855 0.0259928 0.235376 0.234301 0.967408 0.00276246 0.400259 0.474913 0.177781 0.702089 0.227655 0.00561045 0.350514 0.19959 0.019287 0.285238 0.457233 0.326972 0.402127 0.325902 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 105648 episodes
GETTING ACTION FROM:
action 8, numVisits=105571, meanQ=9.951799, numObservations: 9
action 7, numVisits=47, meanQ=8.412557, numObservations: 8
action 5, numVisits=7, meanQ=7.282857, numObservations: 5
action 1, numVisits=4, meanQ=6.500000, numObservations: 4
action 9, numVisits=4, meanQ=6.500000, numObservations: 3
action 3, numVisits=7, meanQ=6.141429, numObservations: 4
action 2, numVisits=3, meanQ=4.340033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 6, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 8
Next state: 0 0.745855 0.0259928 0.235376 0.234301 0.967408 0.00276246 0.400259 0.474913 0.177781 0.702089 0.227655 0.00561045 0.350514 0.19959 0.019287 0.285238 0.457233 0.326972 0.402127 0.325902 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 7, numVisits=1631, meanQ=10.894399, numObservations: 9
action 5, numVisits=42, meanQ=9.354060, numObservations: 9
action 6, numVisits=16, meanQ=8.373131, numObservations: 8
action 9, numVisits=2, meanQ=6.500000, numObservations: 2
action 10, numVisits=2, meanQ=6.500000, numObservations: 2
action 4, numVisits=5, meanQ=6.196000, numObservations: 4
action 3, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 8, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 42733 episodes
GETTING ACTION FROM:
action 7, numVisits=44022, meanQ=8.572830, numObservations: 9
action 6, numVisits=36, meanQ=7.096948, numObservations: 9
action 5, numVisits=308, meanQ=6.489300, numObservations: 9
action 4, numVisits=6, meanQ=3.330000, numObservations: 4
action 9, numVisits=3, meanQ=0.666667, numObservations: 2
action 10, numVisits=3, meanQ=0.666667, numObservations: 3
action 3, numVisits=4, meanQ=-0.252500, numObservations: 2
action 0, numVisits=11, meanQ=-1.370000, numObservations: 11
action -1, numVisits=7, meanQ=-1.858571, numObservations: 7
action 8, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=37, meanQ=-19.063763, numObservations: 9
action: 7
Next state: 2 0.745855 0.0259928 0.235376 0.234301 0.967408 0.00276246 0.400259 0.474913 0.177781 0.702089 0.227655 0.00561045 0.350514 0.19959 0.019287 0.285238 0.457233 0.326972 0.402127 0.325902 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 20
Initial state: 0 0.194265 0.652588 0.57149 0.666594 0.931536 0.918293 0.415894 0.411255 0.574485 0.776863 0.874806 0.618093 0.347434 0.734208 0.0392037 0.519477 0.824708 0.894104 0.0497478 0.0929261 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 103906 episodes
GETTING ACTION FROM:
action 8, numVisits=22381, meanQ=10.042571, numObservations: 9
action 9, numVisits=81500, meanQ=9.942218, numObservations: 9
action 7, numVisits=10, meanQ=7.511000, numObservations: 6
action 5, numVisits=3, meanQ=3.330000, numObservations: 3
action 3, numVisits=3, meanQ=3.000000, numObservations: 3
action 1, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 8
Next state: 0 0.194265 0.652588 0.57149 0.666594 0.931536 0.918293 0.415894 0.411255 0.574485 0.776863 0.874806 0.618093 0.347434 0.734208 0.0392037 0.519477 0.824708 0.894104 0.0497478 0.0929261 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 10, numVisits=2313, meanQ=10.641097, numObservations: 9
action 7, numVisits=28, meanQ=7.338571, numObservations: 7
action 9, numVisits=18, meanQ=7.111128, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 6, numVisits=1, meanQ=-3.010000, numObservations: 1
action 8, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 29223 episodes
GETTING ACTION FROM:
action 10, numVisits=31532, meanQ=11.781773, numObservations: 9
action 7, numVisits=28, meanQ=7.338571, numObservations: 7
action 9, numVisits=18, meanQ=7.111128, numObservations: 7
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action -1, numVisits=3, meanQ=-1.340000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 6, numVisits=1, meanQ=-3.010000, numObservations: 1
action 8, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 10
Next state: 0 0.194265 0.652588 0.57149 0.666594 0.931536 0.918293 0.415894 0.411255 0.574485 0.776863 0.874806 0.618093 0.347434 0.734208 0.0392037 0.519477 0.824708 0.894104 0.0497478 0.0929261 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 7, numVisits=1889, meanQ=14.676256, numObservations: 9
action 6, numVisits=7, meanQ=6.282857, numObservations: 5
action 5, numVisits=10, meanQ=5.807000, numObservations: 6
action 9, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 8, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 18008 episodes
GETTING ACTION FROM:
action 7, numVisits=19895, meanQ=13.484578, numObservations: 9
action 6, numVisits=7, meanQ=6.282857, numObservations: 5
action 5, numVisits=10, meanQ=5.807000, numObservations: 6
action 9, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 8, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 7
Next state: 0 0.194265 0.652588 0.57149 0.666594 0.931536 0.918293 0.415894 0.411255 0.574485 0.776863 0.874806 0.618093 0.347434 0.734208 0.0392037 0.519477 0.824708 0.894104 0.0497478 0.0929261 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 4, numVisits=1000, meanQ=16.156479, numObservations: 9
action 1, numVisits=67, meanQ=11.169746, numObservations: 6
action 2, numVisits=64, meanQ=10.588570, numObservations: 9
action 7, numVisits=4, meanQ=7.230517, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 8, numVisits=1, meanQ=-3.010000, numObservations: 1
action 9, numVisits=1, meanQ=-3.010000, numObservations: 1
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
action 6, numVisits=11, meanQ=-7.451280, numObservations: 7
action 3, numVisits=12, meanQ=-75.787971, numObservations: 7
Sampled 27780 episodes
GETTING ACTION FROM:
action 4, numVisits=27414, meanQ=14.884589, numObservations: 9
action 1, numVisits=1433, meanQ=13.181305, numObservations: 9
action 2, numVisits=64, meanQ=10.588570, numObservations: 9
action 7, numVisits=4, meanQ=7.230517, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 8, numVisits=1, meanQ=-3.010000, numObservations: 1
action 9, numVisits=1, meanQ=-3.010000, numObservations: 1
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
action 6, numVisits=11, meanQ=-7.451280, numObservations: 7
action 3, numVisits=12, meanQ=-75.787971, numObservations: 7
action: 4
Next state: 1 0.194265 0.652588 0.57149 0.666594 0.931536 0.918293 0.415894 0.411255 0.574485 0.776863 0.874806 0.618093 0.347434 0.734208 0.0392037 0.519477 0.824708 0.894104 0.0497478 0.0929261 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 11.4068
Run # 21
Initial state: 0 0.127491 0.278807 0.761603 0.00309858 0.393868 0.949509 0.37453 0.99553 0.854984 0.508124 0.910374 0.279647 0.376414 0.48615 0.829702 0.462866 0.0568106 0.875995 0.400781 0.554642 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 107956 episodes
GETTING ACTION FROM:
action 6, numVisits=107923, meanQ=9.783676, numObservations: 9
action 3, numVisits=17, meanQ=8.121788, numObservations: 8
action 5, numVisits=5, meanQ=6.196000, numObservations: 5
action 10, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 7, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 6
Next state: 2 0.127491 0.278807 0.761603 0.00309858 0.393868 0.949509 0.37453 0.99553 0.854984 0.508124 0.910374 0.279647 0.376414 0.48615 0.829702 0.462866 0.0568106 0.875995 0.400781 0.554642 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 22
Initial state: 0 0.705025 0.20165 0.0453455 0.391112 0.926759 0.371082 0.363532 0.219431 0.38837 0.397686 0.929043 0.0461369 0.359321 0.350089 0.850241 0.517356 0.558567 0.287564 0.390393 0.325095 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 107429 episodes
GETTING ACTION FROM:
action 6, numVisits=107402, meanQ=9.828498, numObservations: 9
action 3, numVisits=11, meanQ=6.908182, numObservations: 7
action 1, numVisits=5, meanQ=4.400000, numObservations: 4
action 4, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 7, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 6
Next state: 2 0.705025 0.20165 0.0453455 0.391112 0.926759 0.371082 0.363532 0.219431 0.38837 0.397686 0.929043 0.0461369 0.359321 0.350089 0.850241 0.517356 0.558567 0.287564 0.390393 0.325095 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 23
Initial state: 0 0.377986 0.353524 0.624829 0.29878 0.63447 0.454918 0.344333 0.773516 0.323372 0.837325 0.77115 0.374815 0.452056 0.179582 0.260305 0.842515 0.879725 0.590568 0.387768 0.907252 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 106510 episodes
GETTING ACTION FROM:
action 6, numVisits=106467, meanQ=9.674437, numObservations: 9
action 10, numVisits=12, meanQ=7.665842, numObservations: 4
action 8, numVisits=14, meanQ=7.363571, numObservations: 6
action 9, numVisits=7, meanQ=6.141429, numObservations: 5
action 3, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 6
Next state: 2 0.377986 0.353524 0.624829 0.29878 0.63447 0.454918 0.344333 0.773516 0.323372 0.837325 0.77115 0.374815 0.452056 0.179582 0.260305 0.842515 0.879725 0.590568 0.387768 0.907252 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 24
Initial state: 0 0.540329 0.864126 0.548958 0.223541 0.367447 0.364373 0.965749 0.628078 0.667831 0.871541 0.694688 0.48381 0.72147 0.647388 0.0247602 0.959893 0.0747426 0.428315 0.699455 0.716158 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 105806 episodes
GETTING ACTION FROM:
action 9, numVisits=105660, meanQ=9.779820, numObservations: 9
action 6, numVisits=121, meanQ=9.035210, numObservations: 9
action 4, numVisits=14, meanQ=7.787150, numObservations: 6
action 8, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 7, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 9
Next state: 0 0.540329 0.864126 0.548958 0.223541 0.367447 0.364373 0.965749 0.628078 0.667831 0.871541 0.694688 0.48381 0.72147 0.647388 0.0247602 0.959893 0.0747426 0.428315 0.699455 0.716158 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=10206, meanQ=10.178721, numObservations: 9
action 7, numVisits=45, meanQ=8.030233, numObservations: 9
action 1, numVisits=9, meanQ=6.997789, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 6, numVisits=1, meanQ=-3.010000, numObservations: 1
action 8, numVisits=1, meanQ=-3.010000, numObservations: 1
action 9, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 26617 episodes
GETTING ACTION FROM:
action 7, numVisits=2158, meanQ=10.777300, numObservations: 9
action 1, numVisits=6913, meanQ=9.315608, numObservations: 9
action 5, numVisits=27794, meanQ=9.132398, numObservations: 9
action 6, numVisits=4, meanQ=-0.946272, numObservations: 3
action -1, numVisits=5, meanQ=-1.208000, numObservations: 5
action 0, numVisits=5, meanQ=-1.208000, numObservations: 5
action 9, numVisits=1, meanQ=-3.010000, numObservations: 1
action 8, numVisits=2, meanQ=-7.005000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 7
Next state: 2 0.540329 0.864126 0.548958 0.223541 0.367447 0.364373 0.965749 0.628078 0.667831 0.871541 0.694688 0.48381 0.72147 0.647388 0.0247602 0.959893 0.0747426 0.428315 0.699455 0.716158 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 25
Initial state: 0 0.966386 0.995755 0.261493 0.132475 0.687587 0.709404 0.493868 0.640614 0.595907 0.582995 0.801714 0.525936 0.469501 0.359378 0.0298164 0.887277 0.713186 0.358976 0.80317 0.955011 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 106304 episodes
GETTING ACTION FROM:
action 3, numVisits=106230, meanQ=9.734964, numObservations: 9
action 9, numVisits=56, meanQ=8.511973, numObservations: 9
action 6, numVisits=7, meanQ=6.141429, numObservations: 5
action 2, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 10, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.966386 0.995755 0.261493 0.132475 0.687587 0.709404 0.493868 0.640614 0.595907 0.582995 0.801714 0.525936 0.469501 0.359378 0.0298164 0.887277 0.713186 0.358976 0.80317 0.955011 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 26
Initial state: 0 0.583518 0.709688 0.568475 0.64065 0.926406 0.19688 0.42865 0.381893 0.814147 0.589158 0.298905 0.513566 0.285242 0.305246 0.38799 0.0472942 0.126082 0.0981868 0.0971606 0.0101278 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 104818 episodes
GETTING ACTION FROM:
action 2, numVisits=104773, meanQ=9.827937, numObservations: 9
action 10, numVisits=35, meanQ=8.327429, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-4.000000, numObservations: 1
action 7, numVisits=1, meanQ=-4.000000, numObservations: 1
action 9, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.583518 0.709688 0.568475 0.64065 0.926406 0.19688 0.42865 0.381893 0.814147 0.589158 0.298905 0.513566 0.285242 0.305246 0.38799 0.0472942 0.126082 0.0981868 0.0971606 0.0101278 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 27
Initial state: 0 0.58805 0.489446 0.303765 0.176618 0.230674 0.0898963 0.743096 0.656026 0.194516 0.0615084 0.44693 0.488829 0.88865 0.503187 0.360281 0.727692 0.053204 0.395323 0.668559 0.211961 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 106095 episodes
GETTING ACTION FROM:
action 5, numVisits=106068, meanQ=9.880096, numObservations: 9
action 7, numVisits=11, meanQ=6.271818, numObservations: 6
action 3, numVisits=5, meanQ=5.022000, numObservations: 4
action 1, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action 9, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.58805 0.489446 0.303765 0.176618 0.230674 0.0898963 0.743096 0.656026 0.194516 0.0615084 0.44693 0.488829 0.88865 0.503187 0.360281 0.727692 0.053204 0.395323 0.668559 0.211961 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 6, numVisits=10227, meanQ=10.331092, numObservations: 9
action 8, numVisits=4, meanQ=6.500000, numObservations: 2
action 10, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 22805 episodes
GETTING ACTION FROM:
action 6, numVisits=33016, meanQ=9.311949, numObservations: 9
action 8, numVisits=6, meanQ=2.201713, numObservations: 3
action 10, numVisits=4, meanQ=0.223947, numObservations: 4
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action -1, numVisits=6, meanQ=-1.175000, numObservations: 6
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=2, meanQ=-4.271434, numObservations: 2
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 6
Next state: 1 0.58805 0.489446 0.303765 0.176618 0.230674 0.0898963 0.743096 0.656026 0.194516 0.0615084 0.44693 0.488829 0.88865 0.503187 0.360281 0.727692 0.053204 0.395323 0.668559 0.211961 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 28
Initial state: 0 0.00681362 0.825103 0.837906 0.498006 0.911515 0.399643 0.869104 0.675904 0.255907 0.678038 0.633881 0.931619 0.195419 0.985023 0.251509 0.501973 0.371129 0.406918 0.900115 0.802685 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 106197 episodes
GETTING ACTION FROM:
action 5, numVisits=106163, meanQ=9.677604, numObservations: 9
action 7, numVisits=14, meanQ=7.857864, numObservations: 6
action 10, numVisits=3, meanQ=5.663333, numObservations: 3
action 2, numVisits=5, meanQ=4.400000, numObservations: 4
action 4, numVisits=3, meanQ=0.666667, numObservations: 2
action 8, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 9, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.00681362 0.825103 0.837906 0.498006 0.911515 0.399643 0.869104 0.675904 0.255907 0.678038 0.633881 0.931619 0.195419 0.985023 0.251509 0.501973 0.371129 0.406918 0.900115 0.802685 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=11411, meanQ=10.372347, numObservations: 9
action 10, numVisits=26, meanQ=7.002696, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 7, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 28129 episodes
GETTING ACTION FROM:
action 2, numVisits=39532, meanQ=11.815795, numObservations: 9
action 10, numVisits=27, meanQ=6.335930, numObservations: 9
action 0, numVisits=5, meanQ=-1.010000, numObservations: 5
action -1, numVisits=4, meanQ=-1.257500, numObservations: 4
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 7, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.00681362 0.825103 0.837906 0.498006 0.911515 0.399643 0.869104 0.675904 0.255907 0.678038 0.633881 0.931619 0.195419 0.985023 0.251509 0.501973 0.371129 0.406918 0.900115 0.802685 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 29
Initial state: 0 0.436781 0.516222 0.69277 0.24933 0.273412 0.508937 0.721104 0.491368 0.356746 0.454424 0.00359712 0.0724784 0.226654 0.25761 0.088554 0.340939 0.760915 0.126068 0.168046 0.797731 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 105564 episodes
GETTING ACTION FROM:
action 2, numVisits=99663, meanQ=9.820120, numObservations: 9
action 10, numVisits=5885, meanQ=9.745370, numObservations: 9
action 5, numVisits=3, meanQ=3.000000, numObservations: 3
action 8, numVisits=5, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 7, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.436781 0.516222 0.69277 0.24933 0.273412 0.508937 0.721104 0.491368 0.356746 0.454424 0.00359712 0.0724784 0.226654 0.25761 0.088554 0.340939 0.760915 0.126068 0.168046 0.797731 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 30
Initial state: 0 0.0261089 0.310133 0.47511 0.357862 0.323285 0.058522 0.00244815 0.938336 0.935123 0.260311 0.673192 0.0270156 0.196365 0.585395 0.0240781 0.303803 0.871501 0.147028 0.940671 0.773316 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 105767 episodes
GETTING ACTION FROM:
action 6, numVisits=105742, meanQ=9.938141, numObservations: 9
action 4, numVisits=11, meanQ=2.929091, numObservations: 6
action 1, numVisits=3, meanQ=0.666667, numObservations: 2
action 5, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action 9, numVisits=1, meanQ=-4.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 6
Next state: 2 0.0261089 0.310133 0.47511 0.357862 0.323285 0.058522 0.00244815 0.938336 0.935123 0.260311 0.673192 0.0270156 0.196365 0.585395 0.0240781 0.303803 0.871501 0.147028 0.940671 0.773316 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 31
Initial state: 0 0.848573 0.237603 0.189818 0.0145804 0.940385 0.515879 0.251213 0.180923 0.555869 0.0931736 0.468784 0.429242 0.757442 0.631252 0.0964826 0.613283 0.277412 0.256934 0.23015 0.200888 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 105694 episodes
GETTING ACTION FROM:
action 9, numVisits=105669, meanQ=9.837501, numObservations: 9
action 6, numVisits=9, meanQ=6.998889, numObservations: 7
action 7, numVisits=7, meanQ=5.535714, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 9
Next state: 0 0.848573 0.237603 0.189818 0.0145804 0.940385 0.515879 0.251213 0.180923 0.555869 0.0931736 0.468784 0.429242 0.757442 0.631252 0.0964826 0.613283 0.277412 0.256934 0.23015 0.200888 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 8, numVisits=10102, meanQ=10.255033, numObservations: 9
action 10, numVisits=21, meanQ=8.523352, numObservations: 9
action 1, numVisits=31, meanQ=8.427110, numObservations: 9
action 6, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 9, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 31329 episodes
GETTING ACTION FROM:
action 10, numVisits=28590, meanQ=10.615851, numObservations: 9
action 8, numVisits=12852, meanQ=10.119958, numObservations: 9
action 1, numVisits=32, meanQ=7.820013, numObservations: 9
action 6, numVisits=6, meanQ=2.726999, numObservations: 6
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 9, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 10
Next state: 0 0.848573 0.237603 0.189818 0.0145804 0.940385 0.515879 0.251213 0.180923 0.555869 0.0931736 0.468784 0.429242 0.757442 0.631252 0.0964826 0.613283 0.277412 0.256934 0.23015 0.200888 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=2051, meanQ=11.069924, numObservations: 9
action 1, numVisits=5, meanQ=3.337982, numObservations: 4
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=60, meanQ=-3.063579, numObservations: 9
action 4, numVisits=1, meanQ=-8.514482, numObservations: 1
action 6, numVisits=1, meanQ=-8.852867, numObservations: 1
action 10, numVisits=1, meanQ=-9.280820, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=5, meanQ=-201.852727, numObservations: 3
action 9, numVisits=1, meanQ=-1047.075827, numObservations: 1
Sampled 28723 episodes
GETTING ACTION FROM:
action 5, numVisits=30765, meanQ=8.482463, numObservations: 9
action 2, numVisits=6, meanQ=1.998333, numObservations: 4
action 1, numVisits=6, meanQ=0.948318, numObservations: 4
action 0, numVisits=5, meanQ=-1.010000, numObservations: 5
action -1, numVisits=4, meanQ=-1.257500, numObservations: 4
action 3, numVisits=60, meanQ=-3.063579, numObservations: 9
action 4, numVisits=1, meanQ=-8.514482, numObservations: 1
action 6, numVisits=1, meanQ=-8.852867, numObservations: 1
action 10, numVisits=1, meanQ=-9.280820, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=5, meanQ=-201.852727, numObservations: 3
action 9, numVisits=1, meanQ=-1047.075827, numObservations: 1
action: 5
Next state: 2 0.848573 0.237603 0.189818 0.0145804 0.940385 0.515879 0.251213 0.180923 0.555869 0.0931736 0.468784 0.429242 0.757442 0.631252 0.0964826 0.613283 0.277412 0.256934 0.23015 0.200888 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -18.7411
Run # 32
Initial state: 0 0.0223275 0.0616297 0.379814 0.236316 0.324413 0.644484 0.678641 0.0410967 0.115488 0.631829 0.284875 0.829574 0.815808 0.643889 0.381038 0.353012 0.13186 0.709176 0.828309 0.603679 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 105842 episodes
GETTING ACTION FROM:
action 4, numVisits=105810, meanQ=10.046013, numObservations: 9
action 1, numVisits=7, meanQ=6.574300, numObservations: 4
action 2, numVisits=8, meanQ=6.500000, numObservations: 7
action 10, numVisits=7, meanQ=5.394286, numObservations: 4
action 5, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 6, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.0223275 0.0616297 0.379814 0.236316 0.324413 0.644484 0.678641 0.0410967 0.115488 0.631829 0.284875 0.829574 0.815808 0.643889 0.381038 0.353012 0.13186 0.709176 0.828309 0.603679 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 33
Initial state: 0 0.116793 0.290715 0.780073 0.756806 0.00172355 0.981838 0.939645 0.0078076 0.808657 0.434625 0.598618 0.134362 0.254054 0.0305778 0.44206 0.389616 0.233601 0.144341 0.606934 0.186851 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 106211 episodes
GETTING ACTION FROM:
action 6, numVisits=106131, meanQ=9.835937, numObservations: 9
action 7, numVisits=30, meanQ=8.484340, numObservations: 8
action 3, numVisits=24, meanQ=8.458342, numObservations: 7
action 5, numVisits=7, meanQ=7.141429, numObservations: 4
action 1, numVisits=8, meanQ=6.968750, numObservations: 5
action 2, numVisits=3, meanQ=3.000000, numObservations: 3
action 10, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 9, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 6
Next state: 2 0.116793 0.290715 0.780073 0.756806 0.00172355 0.981838 0.939645 0.0078076 0.808657 0.434625 0.598618 0.134362 0.254054 0.0305778 0.44206 0.389616 0.233601 0.144341 0.606934 0.186851 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 34
Initial state: 0 0.609736 0.72174 0.314925 0.623137 0.979328 0.763596 0.685504 0.850155 0.436256 0.396834 0.665439 0.634285 0.719464 0.829423 0.13938 0.769397 0.693856 0.74847 0.651516 0.850625 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 106931 episodes
GETTING ACTION FROM:
action 10, numVisits=106900, meanQ=9.854885, numObservations: 9
action 7, numVisits=11, meanQ=6.271818, numObservations: 5
action 6, numVisits=3, meanQ=5.333333, numObservations: 2
action 8, numVisits=5, meanQ=4.400000, numObservations: 5
action 3, numVisits=5, meanQ=3.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 10
Next state: 1 0.609736 0.72174 0.314925 0.623137 0.979328 0.763596 0.685504 0.850155 0.436256 0.396834 0.665439 0.634285 0.719464 0.829423 0.13938 0.769397 0.693856 0.74847 0.651516 0.850625 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 35
Initial state: 0 0.685874 0.0807407 0.0483392 0.656222 0.124346 0.168575 0.383369 0.371758 0.219299 0.715402 0.0160871 0.623931 0.329015 0.161304 0.981205 0.202244 0.669344 0.175923 0.226381 0.862684 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 107852 episodes
GETTING ACTION FROM:
action 5, numVisits=107823, meanQ=9.799498, numObservations: 9
action 9, numVisits=12, meanQ=7.666667, numObservations: 5
action 8, numVisits=8, meanQ=7.375000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 7, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.685874 0.0807407 0.0483392 0.656222 0.124346 0.168575 0.383369 0.371758 0.219299 0.715402 0.0160871 0.623931 0.329015 0.161304 0.981205 0.202244 0.669344 0.175923 0.226381 0.862684 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 10, numVisits=11786, meanQ=10.721390, numObservations: 9
action 6, numVisits=12, meanQ=4.561667, numObservations: 7
action 2, numVisits=15, meanQ=4.465340, numObservations: 8
action 4, numVisits=3, meanQ=3.330000, numObservations: 3
action 8, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 7, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 28006 episodes
GETTING ACTION FROM:
action 10, numVisits=39783, meanQ=11.874234, numObservations: 9
action 6, numVisits=12, meanQ=4.561667, numObservations: 7
action 2, numVisits=15, meanQ=4.465340, numObservations: 8
action 4, numVisits=6, meanQ=3.577353, numObservations: 4
action 8, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.257500, numObservations: 4
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 7, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 10
Next state: 0 0.685874 0.0807407 0.0483392 0.656222 0.124346 0.168575 0.383369 0.371758 0.219299 0.715402 0.0160871 0.623931 0.329015 0.161304 0.981205 0.202244 0.669344 0.175923 0.226381 0.862684 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 7, numVisits=1905, meanQ=16.422219, numObservations: 9
action 5, numVisits=1139, meanQ=12.422587, numObservations: 9
action 6, numVisits=71, meanQ=9.770289, numObservations: 9
action 4, numVisits=23, meanQ=9.130000, numObservations: 8
action 3, numVisits=7, meanQ=7.424286, numObservations: 6
action 2, numVisits=5, meanQ=3.291229, numObservations: 4
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 27966 episodes
GETTING ACTION FROM:
action 7, numVisits=29871, meanQ=14.341282, numObservations: 9
action 5, numVisits=1139, meanQ=12.422587, numObservations: 9
action 6, numVisits=71, meanQ=9.770289, numObservations: 9
action 4, numVisits=23, meanQ=9.130000, numObservations: 8
action 3, numVisits=7, meanQ=7.424286, numObservations: 6
action 2, numVisits=5, meanQ=3.291229, numObservations: 4
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 7
Next state: 0 0.685874 0.0807407 0.0483392 0.656222 0.124346 0.168575 0.383369 0.371758 0.219299 0.715402 0.0160871 0.623931 0.329015 0.161304 0.981205 0.202244 0.669344 0.175923 0.226381 0.862684 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 5, numVisits=1, meanQ=24.000000, numObservations: 1
action 3, numVisits=758, meanQ=18.030207, numObservations: 9
action 10, numVisits=5, meanQ=2.337188, numObservations: 3
action 0, numVisits=129, meanQ=-3.961105, numObservations: 103
action 7, numVisits=1, meanQ=-9.997863, numObservations: 1
action 8, numVisits=1, meanQ=-10.440541, numObservations: 1
action 9, numVisits=1, meanQ=-10.857588, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=15, meanQ=-19.283325, numObservations: 7
action -1, numVisits=26, meanQ=-21.029511, numObservations: 25
action 1, numVisits=22, meanQ=-34.567915, numObservations: 7
Sampled 28684 episodes
GETTING ACTION FROM:
action 3, numVisits=29439, meanQ=15.669900, numObservations: 9
action 10, numVisits=5, meanQ=2.337188, numObservations: 3
action 0, numVisits=129, meanQ=-3.961105, numObservations: 103
action 7, numVisits=1, meanQ=-9.997863, numObservations: 1
action 8, numVisits=1, meanQ=-10.440541, numObservations: 1
action 9, numVisits=1, meanQ=-10.857588, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=15, meanQ=-19.283325, numObservations: 7
action -1, numVisits=26, meanQ=-21.029511, numObservations: 25
action 1, numVisits=22, meanQ=-34.567915, numObservations: 7
action 5, numVisits=4, meanQ=-77.468893, numObservations: 2
action: 3
Next state: 0 0.685874 0.0807407 0.0483392 0.656222 0.124346 0.168575 0.383369 0.371758 0.219299 0.715402 0.0160871 0.623931 0.329015 0.161304 0.981205 0.202244 0.669344 0.175923 0.226381 0.862684 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 5, numVisits=1, meanQ=24.000000, numObservations: 1
action 1, numVisits=695, meanQ=18.715452, numObservations: 9
action 7, numVisits=4, meanQ=7.233820, numObservations: 3
action 4, numVisits=3, meanQ=1.304793, numObservations: 2
action 8, numVisits=3, meanQ=1.039090, numObservations: 3
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=1, meanQ=-9.488835, numObservations: 1
action 9, numVisits=1, meanQ=-10.044577, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-525.466867, numObservations: 1
Sampled 31193 episodes
GETTING ACTION FROM:
action 1, numVisits=31884, meanQ=15.206035, numObservations: 9
action 5, numVisits=5, meanQ=12.600020, numObservations: 2
action 7, numVisits=4, meanQ=7.233820, numObservations: 3
action 4, numVisits=3, meanQ=1.304793, numObservations: 2
action 8, numVisits=3, meanQ=1.039090, numObservations: 3
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=1, meanQ=-9.488835, numObservations: 1
action 9, numVisits=1, meanQ=-10.044577, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-525.466867, numObservations: 1
action: 1
Next state: 2 0.685874 0.0807407 0.0483392 0.656222 0.124346 0.168575 0.383369 0.371758 0.219299 0.715402 0.0160871 0.623931 0.329015 0.161304 0.981205 0.202244 0.669344 0.175923 0.226381 0.862684 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -26.3282
Run # 36
Initial state: 0 0.200081 0.543082 0.696157 0.396731 0.259031 0.167407 0.898296 0.590612 0.17426 0.545477 0.275915 0.530414 0.905207 0.0522666 0.378281 0.485612 0.778912 0.483984 0.0601363 0.744786 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 105783 episodes
GETTING ACTION FROM:
action 7, numVisits=105734, meanQ=9.770524, numObservations: 9
action 8, numVisits=26, meanQ=8.337319, numObservations: 7
action 9, numVisits=6, meanQ=6.500000, numObservations: 3
action 6, numVisits=7, meanQ=6.282857, numObservations: 5
action 10, numVisits=3, meanQ=5.663333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 7
Next state: 2 0.200081 0.543082 0.696157 0.396731 0.259031 0.167407 0.898296 0.590612 0.17426 0.545477 0.275915 0.530414 0.905207 0.0522666 0.378281 0.485612 0.778912 0.483984 0.0601363 0.744786 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 37
Initial state: 0 0.804764 0.843181 0.892623 0.947944 0.501869 0.790213 0.891909 0.12801 0.438051 0.405026 0.16415 0.966357 0.715023 0.643508 0.501484 0.369253 0.868366 0.0578986 0.536138 0.636607 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 100247 episodes
GETTING ACTION FROM:
action 8, numVisits=100211, meanQ=10.170813, numObservations: 9
action 4, numVisits=11, meanQ=6.978191, numObservations: 6
action 6, numVisits=8, meanQ=6.251263, numObservations: 5
action 2, numVisits=5, meanQ=4.400000, numObservations: 4
action 10, numVisits=3, meanQ=3.330000, numObservations: 3
action 5, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 7, numVisits=1, meanQ=-4.000000, numObservations: 1
action 9, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 8
Next state: 1 0.804764 0.843181 0.892623 0.947944 0.501869 0.790213 0.891909 0.12801 0.438051 0.405026 0.16415 0.966357 0.715023 0.643508 0.501484 0.369253 0.868366 0.0578986 0.536138 0.636607 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 38
Initial state: 0 0.672146 0.770976 0.564924 0.0254734 0.748654 0.880177 0.776082 0.52023 0.0157628 0.869702 0.0365918 0.128982 0.472562 0.424004 0.474671 0.104427 0.399349 0.55664 0.166042 0.817322 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 106130 episodes
GETTING ACTION FROM:
action 2, numVisits=106056, meanQ=9.842908, numObservations: 9
action 8, numVisits=35, meanQ=8.634571, numObservations: 9
action 7, numVisits=18, meanQ=8.208339, numObservations: 8
action 10, numVisits=5, meanQ=5.998000, numObservations: 4
action 9, numVisits=5, meanQ=5.798020, numObservations: 4
action 6, numVisits=3, meanQ=3.000000, numObservations: 2
action 3, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.672146 0.770976 0.564924 0.0254734 0.748654 0.880177 0.776082 0.52023 0.0157628 0.869702 0.0365918 0.128982 0.472562 0.424004 0.474671 0.104427 0.399349 0.55664 0.166042 0.817322 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 39
Initial state: 0 0.967222 0.311585 0.401714 0.377381 0.249197 0.373222 0.45287 0.346406 0.00955739 0.255516 0.226369 0.127917 0.680554 0.137532 0.226812 0.52365 0.240245 0.935573 0.546209 0.55178 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 107571 episodes
GETTING ACTION FROM:
action 7, numVisits=107555, meanQ=9.784104, numObservations: 9
action 3, numVisits=3, meanQ=0.666667, numObservations: 2
action 1, numVisits=4, meanQ=-0.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-4.000000, numObservations: 1
action 9, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 7
Next state: 2 0.967222 0.311585 0.401714 0.377381 0.249197 0.373222 0.45287 0.346406 0.00955739 0.255516 0.226369 0.127917 0.680554 0.137532 0.226812 0.52365 0.240245 0.935573 0.546209 0.55178 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 40
Initial state: 0 0.885407 0.534529 0.182748 0.17863 0.520717 0.545845 0.740441 0.862909 0.884394 0.57052 0.544058 0.577437 0.185204 0.702564 0.297256 0.361718 0.273431 0.537617 0.463551 0.393647 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 106853 episodes
GETTING ACTION FROM:
action 4, numVisits=106829, meanQ=9.842356, numObservations: 9
action 7, numVisits=10, meanQ=7.299000, numObservations: 4
action 10, numVisits=5, meanQ=6.196000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.885407 0.534529 0.182748 0.17863 0.520717 0.545845 0.740441 0.862909 0.884394 0.57052 0.544058 0.577437 0.185204 0.702564 0.297256 0.361718 0.273431 0.537617 0.463551 0.393647 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 41
Initial state: 0 0.435733 0.77414 0.517149 0.752094 0.0931534 0.389366 0.449008 0.374719 0.154846 0.966913 0.0662172 0.253849 0.210415 0.0835534 0.605578 0.301729 0.199756 0.14761 0.146415 0.0301585 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 105107 episodes
GETTING ACTION FROM:
action 2, numVisits=105038, meanQ=9.849456, numObservations: 9
action 4, numVisits=28, meanQ=8.398221, numObservations: 8
action 5, numVisits=16, meanQ=7.750006, numObservations: 6
action 8, numVisits=7, meanQ=7.141429, numObservations: 5
action 3, numVisits=3, meanQ=5.333333, numObservations: 3
action 6, numVisits=7, meanQ=5.141429, numObservations: 3
action 10, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 9, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.435733 0.77414 0.517149 0.752094 0.0931534 0.389366 0.449008 0.374719 0.154846 0.966913 0.0662172 0.253849 0.210415 0.0835534 0.605578 0.301729 0.199756 0.14761 0.146415 0.0301585 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 42
Initial state: 0 0.139453 0.750271 0.473276 0.387512 0.186464 0.746526 0.19176 0.916263 0.140873 0.599421 0.204307 0.898456 0.999978 0.195583 0.845989 0.93716 0.300662 0.693757 0.503639 0.655492 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 105064 episodes
GETTING ACTION FROM:
action 7, numVisits=105043, meanQ=9.675885, numObservations: 9
action 10, numVisits=7, meanQ=6.141429, numObservations: 3
action 3, numVisits=5, meanQ=5.998000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 7
Next state: 2 0.139453 0.750271 0.473276 0.387512 0.186464 0.746526 0.19176 0.916263 0.140873 0.599421 0.204307 0.898456 0.999978 0.195583 0.845989 0.93716 0.300662 0.693757 0.503639 0.655492 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 43
Initial state: 0 0.527898 0.655381 0.689885 0.795328 0.127819 0.120292 0.186496 0.861325 0.600535 0.242183 0.261665 0.157789 0.436481 0.481029 0.62294 0.61984 0.645574 0.0882034 0.288972 0.00275429 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 106924 episodes
GETTING ACTION FROM:
action 7, numVisits=73765, meanQ=9.963586, numObservations: 9
action 6, numVisits=33131, meanQ=9.926801, numObservations: 9
action 3, numVisits=7, meanQ=6.715729, numObservations: 5
action 8, numVisits=4, meanQ=6.500000, numObservations: 3
action 10, numVisits=4, meanQ=6.500000, numObservations: 3
action 4, numVisits=5, meanQ=4.598000, numObservations: 4
action 1, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 9, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 7
Next state: 1 0.527898 0.655381 0.689885 0.795328 0.127819 0.120292 0.186496 0.861325 0.600535 0.242183 0.261665 0.157789 0.436481 0.481029 0.62294 0.61984 0.645574 0.0882034 0.288972 0.00275429 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 44
Initial state: 0 0.62135 0.814924 0.31338 0.300396 0.0780282 0.453098 0.779946 0.149713 0.209048 0.184664 0.307304 0.59158 0.415025 0.418307 0.486768 0.621938 0.812127 0.261089 0.0638772 0.662548 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 106522 episodes
GETTING ACTION FROM:
action 7, numVisits=106483, meanQ=9.991846, numObservations: 9
action 6, numVisits=15, meanQ=7.874000, numObservations: 6
action 5, numVisits=8, meanQ=7.498750, numObservations: 6
action 8, numVisits=4, meanQ=6.500000, numObservations: 3
action 3, numVisits=3, meanQ=5.333333, numObservations: 3
action 1, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 9, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 7
Next state: 1 0.62135 0.814924 0.31338 0.300396 0.0780282 0.453098 0.779946 0.149713 0.209048 0.184664 0.307304 0.59158 0.415025 0.418307 0.486768 0.621938 0.812127 0.261089 0.0638772 0.662548 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 45
Initial state: 0 0.282875 0.330153 0.402653 0.488293 0.0607208 0.895919 0.551214 0.208535 0.179855 0.53705 0.176085 0.365445 0.717962 0.283904 0.16695 0.963873 0.162158 0.699967 0.673915 0.27475 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 107841 episodes
GETTING ACTION FROM:
action 5, numVisits=77874, meanQ=9.894284, numObservations: 9
action 10, numVisits=29940, meanQ=9.875884, numObservations: 9
action 8, numVisits=13, meanQ=7.699231, numObservations: 5
action 9, numVisits=4, meanQ=6.500000, numObservations: 3
action 6, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.282875 0.330153 0.402653 0.488293 0.0607208 0.895919 0.551214 0.208535 0.179855 0.53705 0.176085 0.365445 0.717962 0.283904 0.16695 0.963873 0.162158 0.699967 0.673915 0.27475 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 46
Initial state: 0 0.165637 0.529215 0.397299 0.400912 0.484368 0.896732 0.239376 0.743892 0.978112 0.0160396 0.526326 0.325077 0.0311482 0.575964 0.190994 0.889486 0.933234 0.00791471 0.785728 0.184508 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 108016 episodes
GETTING ACTION FROM:
action 5, numVisits=107988, meanQ=9.920488, numObservations: 9
action 6, numVisits=9, meanQ=5.750000, numObservations: 5
action 2, numVisits=10, meanQ=5.397000, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 7, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.165637 0.529215 0.397299 0.400912 0.484368 0.896732 0.239376 0.743892 0.978112 0.0160396 0.526326 0.325077 0.0311482 0.575964 0.190994 0.889486 0.933234 0.00791471 0.785728 0.184508 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 47
Initial state: 0 0.772171 0.578508 0.442703 0.40231 0.343511 0.129943 0.661546 0.214259 0.585436 0.732864 0.336451 0.29606 0.713884 0.865635 0.943177 0.234475 0.470317 0.839291 0.36002 0.779225 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 105865 episodes
GETTING ACTION FROM:
action 6, numVisits=105846, meanQ=9.545265, numObservations: 9
action 2, numVisits=6, meanQ=1.833333, numObservations: 5
action 7, numVisits=4, meanQ=1.250000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 6
Next state: 0 0.772171 0.578508 0.442703 0.40231 0.343511 0.129943 0.661546 0.214259 0.585436 0.732864 0.336451 0.29606 0.713884 0.865635 0.943177 0.234475 0.470317 0.839291 0.36002 0.779225 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=10236, meanQ=10.120573, numObservations: 9
action 7, numVisits=3, meanQ=4.670033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 6, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 28227 episodes
GETTING ACTION FROM:
action 5, numVisits=38439, meanQ=9.430149, numObservations: 9
action 7, numVisits=10, meanQ=1.401010, numObservations: 6
action -1, numVisits=9, meanQ=-1.120000, numObservations: 9
action 0, numVisits=7, meanQ=-1.434286, numObservations: 7
action 6, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=2, meanQ=-6.275513, numObservations: 2
action 4, numVisits=2, meanQ=-6.534513, numObservations: 2
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.772171 0.578508 0.442703 0.40231 0.343511 0.129943 0.661546 0.214259 0.585436 0.732864 0.336451 0.29606 0.713884 0.865635 0.943177 0.234475 0.470317 0.839291 0.36002 0.779225 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 48
Initial state: 0 0.639954 0.181205 0.345782 0.939653 0.87977 0.653077 0.535376 0.954542 0.39967 0.495873 0.119236 0.698681 0.562194 0.0859827 0.495717 0.0361127 0.505431 0.582084 0.124076 0.853657 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 105409 episodes
GETTING ACTION FROM:
action 6, numVisits=105381, meanQ=9.880848, numObservations: 9
action 3, numVisits=14, meanQ=5.437871, numObservations: 6
action 4, numVisits=3, meanQ=0.666667, numObservations: 1
action 5, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 9, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 6
Next state: 0 0.639954 0.181205 0.345782 0.939653 0.87977 0.653077 0.535376 0.954542 0.39967 0.495873 0.119236 0.698681 0.562194 0.0859827 0.495717 0.0361127 0.505431 0.582084 0.124076 0.853657 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=11370, meanQ=10.272740, numObservations: 9
action 10, numVisits=3, meanQ=5.993333, numObservations: 2
action 9, numVisits=3, meanQ=3.330000, numObservations: 2
action 3, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 6, numVisits=1, meanQ=-3.010000, numObservations: 1
action 8, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 34263 episodes
GETTING ACTION FROM:
action 9, numVisits=34032, meanQ=12.046383, numObservations: 9
action 2, numVisits=11595, meanQ=10.323691, numObservations: 9
action 3, numVisits=6, meanQ=3.165000, numObservations: 5
action 10, numVisits=4, meanQ=1.745000, numObservations: 3
action -1, numVisits=4, meanQ=-1.257500, numObservations: 4
action 0, numVisits=3, meanQ=-1.340000, numObservations: 3
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 6, numVisits=1, meanQ=-3.010000, numObservations: 1
action 8, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 9
Next state: 1 0.639954 0.181205 0.345782 0.939653 0.87977 0.653077 0.535376 0.954542 0.39967 0.495873 0.119236 0.698681 0.562194 0.0859827 0.495717 0.0361127 0.505431 0.582084 0.124076 0.853657 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 49
Initial state: 0 0.192287 0.582609 0.815152 0.732933 0.132131 0.889016 0.729535 0.790074 0.761053 0.884717 0.40424 0.413596 0.935921 0.65565 0.837969 0.763408 0.532402 0.257023 0.933592 0.839421 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 107064 episodes
GETTING ACTION FROM:
action 9, numVisits=106697, meanQ=9.808329, numObservations: 9
action 4, numVisits=349, meanQ=9.445688, numObservations: 9
action 5, numVisits=5, meanQ=4.400000, numObservations: 3
action 7, numVisits=5, meanQ=3.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 9
Next state: 0 0.192287 0.582609 0.815152 0.732933 0.132131 0.889016 0.729535 0.790074 0.761053 0.884717 0.40424 0.413596 0.935921 0.65565 0.837969 0.763408 0.532402 0.257023 0.933592 0.839421 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=2165, meanQ=10.688963, numObservations: 9
action 4, numVisits=15, meanQ=8.396673, numObservations: 8
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action 10, numVisits=3, meanQ=4.670033, numObservations: 2
action 1, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 6, numVisits=1, meanQ=-3.010000, numObservations: 1
action 7, numVisits=1, meanQ=-3.010000, numObservations: 1
action 8, numVisits=1, meanQ=-3.010000, numObservations: 1
action 9, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 86983 episodes
GETTING ACTION FROM:
action 4, numVisits=63184, meanQ=7.024205, numObservations: 9
action 3, numVisits=25388, meanQ=6.187175, numObservations: 9
action 2, numVisits=533, meanQ=5.362019, numObservations: 9
action 1, numVisits=27, meanQ=3.555185, numObservations: 9
action 5, numVisits=9, meanQ=1.554444, numObservations: 5
action 10, numVisits=5, meanQ=-1.597980, numObservations: 4
action -1, numVisits=13, meanQ=-1.771538, numObservations: 13
action 0, numVisits=12, meanQ=-1.835000, numObservations: 12
action 9, numVisits=1, meanQ=-3.010000, numObservations: 1
action 6, numVisits=2, meanQ=-7.005000, numObservations: 1
action 7, numVisits=2, meanQ=-7.005000, numObservations: 2
action 8, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 4
Next state: 1 0.192287 0.582609 0.815152 0.732933 0.132131 0.889016 0.729535 0.790074 0.761053 0.884717 0.40424 0.413596 0.935921 0.65565 0.837969 0.763408 0.532402 0.257023 0.933592 0.839421 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 50
Initial state: 0 0.832394 0.570873 0.884588 0.882252 0.441563 0.245675 0.0642024 0.93031 0.759506 0.944982 0.756802 0.0249505 0.107528 0.571275 0.457355 0.377411 0.458876 0.7155 0.0474544 0.423369 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 106875 episodes
GETTING ACTION FROM:
action 9, numVisits=106853, meanQ=9.711642, numObservations: 9
action 4, numVisits=5, meanQ=2.844000, numObservations: 2
action 1, numVisits=4, meanQ=1.745000, numObservations: 4
action 7, numVisits=3, meanQ=0.666667, numObservations: 2
action 10, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 9
Next state: 1 0.832394 0.570873 0.884588 0.882252 0.441563 0.245675 0.0642024 0.93031 0.759506 0.944982 0.756802 0.0249505 0.107528 0.571275 0.457355 0.377411 0.458876 0.7155 0.0474544 0.423369 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
[32m ProblemEnvironment.hpp 351: Done.[39m
