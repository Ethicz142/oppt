Run # 1
Initial state: 0 0.396304 0.525075 0.655671 0.717558 0.985498 0.0962235 0.830094 0.579511 0.399224 0.435803 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92187 episodes
GETTING ACTION FROM:
action 2, numVisits=90567, meanQ=12.226127, numObservations: 9
action 5, numVisits=1613, meanQ=11.930473, numObservations: 9
action 1, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.396304 0.525075 0.655671 0.717558 0.985498 0.0962235 0.830094 0.579511 0.399224 0.435803 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 2
Initial state: 0 0.414065 0.181713 0.255563 0.0452219 0.730634 0.906244 0.861146 0.549879 0.42609 0.412453 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97539 episodes
GETTING ACTION FROM:
action 4, numVisits=97532, meanQ=12.243722, numObservations: 9
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.414065 0.181713 0.255563 0.0452219 0.730634 0.906244 0.861146 0.549879 0.42609 0.412453 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 3
Initial state: 0 0.303867 0.349675 0.631851 0.588777 0.562818 0.206946 0.450176 0.273225 0.262198 0.873367 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97332 episodes
GETTING ACTION FROM:
action 3, numVisits=97275, meanQ=12.244103, numObservations: 9
action 1, numVisits=50, meanQ=10.520402, numObservations: 9
action 4, numVisits=3, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.303867 0.349675 0.631851 0.588777 0.562818 0.206946 0.450176 0.273225 0.262198 0.873367 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 4
Initial state: 0 0.0938214 0.198519 0.231831 0.718576 0.171263 0.0980924 0.306567 0.43149 0.243887 0.843446 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97358 episodes
GETTING ACTION FROM:
action 1, numVisits=97326, meanQ=12.156547, numObservations: 9
action 4, numVisits=14, meanQ=10.070714, numObservations: 8
action 5, numVisits=14, meanQ=9.767857, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.0938214 0.198519 0.231831 0.718576 0.171263 0.0980924 0.306567 0.43149 0.243887 0.843446 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=1222, meanQ=12.989872, numObservations: 9
action 2, numVisits=12, meanQ=10.424167, numObservations: 7
action 3, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 70028 episodes
GETTING ACTION FROM:
action 5, numVisits=71010, meanQ=11.007167, numObservations: 9
action 3, numVisits=34, meanQ=9.381771, numObservations: 8
action 2, numVisits=211, meanQ=9.070797, numObservations: 9
action 0, numVisits=6, meanQ=-1.505000, numObservations: 6
action -1, numVisits=6, meanQ=-1.670000, numObservations: 6
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.0938214 0.198519 0.231831 0.718576 0.171263 0.0980924 0.306567 0.43149 0.243887 0.843446 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=731, meanQ=14.875104, numObservations: 9
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action 2, numVisits=241, meanQ=9.207770, numObservations: 9
action 3, numVisits=9, meanQ=8.188174, numObservations: 5
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 77653 episodes
GETTING ACTION FROM:
action 4, numVisits=78381, meanQ=12.222286, numObservations: 9
action 2, numVisits=241, meanQ=9.207770, numObservations: 9
action 3, numVisits=9, meanQ=8.188174, numObservations: 5
action 1, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=5, meanQ=-1.208000, numObservations: 5
action 0, numVisits=5, meanQ=-1.208000, numObservations: 5
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 1 0.0938214 0.198519 0.231831 0.718576 0.171263 0.0980924 0.306567 0.43149 0.243887 0.843446 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 5
Initial state: 0 0.137276 0.259443 0.922873 0.237735 0.858613 0.868158 0.342834 0.420844 0.827734 0.900492 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97394 episodes
GETTING ACTION FROM:
action 2, numVisits=97377, meanQ=12.082325, numObservations: 9
action 4, numVisits=9, meanQ=8.444444, numObservations: 4
action 3, numVisits=4, meanQ=6.500000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.137276 0.259443 0.922873 0.237735 0.858613 0.868158 0.342834 0.420844 0.827734 0.900492 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 6
Initial state: 0 0.664691 0.0279931 0.982131 0.186589 0.65566 0.251675 0.384433 0.86881 0.397457 0.477152 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97766 episodes
GETTING ACTION FROM:
action 5, numVisits=97729, meanQ=12.253152, numObservations: 9
action 2, numVisits=23, meanQ=10.260443, numObservations: 9
action 1, numVisits=6, meanQ=8.833333, numObservations: 4
action 3, numVisits=4, meanQ=8.250000, numObservations: 4
action 4, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 5
Next state: 1 0.664691 0.0279931 0.982131 0.186589 0.65566 0.251675 0.384433 0.86881 0.397457 0.477152 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 7
Initial state: 0 0.390084 0.456391 0.441136 0.693946 0.350197 0.0519613 0.126856 0.253711 0.112807 0.785646 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 96740 episodes
GETTING ACTION FROM:
action 2, numVisits=96724, meanQ=12.345658, numObservations: 9
action 4, numVisits=11, meanQ=8.727273, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.390084 0.456391 0.441136 0.693946 0.350197 0.0519613 0.126856 0.253711 0.112807 0.785646 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 8
Initial state: 0 0.451003 0.108516 0.421468 0.639001 0.387872 0.42129 0.476176 0.573411 0.747174 0.900278 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97581 episodes
GETTING ACTION FROM:
action 4, numVisits=97569, meanQ=12.242924, numObservations: 9
action 3, numVisits=5, meanQ=5.800000, numObservations: 4
action 2, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.451003 0.108516 0.421468 0.639001 0.387872 0.42129 0.476176 0.573411 0.747174 0.900278 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 9
Initial state: 0 0.454941 0.198656 0.188345 0.183335 0.0753406 0.512942 0.648304 0.857723 0.28134 0.45121 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89254 episodes
GETTING ACTION FROM:
action 3, numVisits=89225, meanQ=12.013310, numObservations: 9
action 2, numVisits=10, meanQ=8.098000, numObservations: 7
action 5, numVisits=14, meanQ=8.070714, numObservations: 6
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.454941 0.198656 0.188345 0.183335 0.0753406 0.512942 0.648304 0.857723 0.28134 0.45121 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 10
Initial state: 0 0.438112 0.495858 0.539093 0.0317829 0.626247 0.138742 0.594043 0.246275 0.337388 0.371389 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97586 episodes
GETTING ACTION FROM:
action 3, numVisits=97579, meanQ=12.254442, numObservations: 9
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.438112 0.495858 0.539093 0.0317829 0.626247 0.138742 0.594043 0.246275 0.337388 0.371389 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 11
Initial state: 0 0.309276 0.202244 0.405366 0.326894 0.803907 0.605107 0.0314434 0.917323 0.738603 0.0848031 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 96984 episodes
GETTING ACTION FROM:
action 4, numVisits=96973, meanQ=12.339573, numObservations: 9
action 2, numVisits=6, meanQ=6.500000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.309276 0.202244 0.405366 0.326894 0.803907 0.605107 0.0314434 0.917323 0.738603 0.0848031 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 12
Initial state: 0 0.54907 0.903365 0.577189 0.814094 0.277649 0.329908 0.869731 0.800173 0.593 0.0402142 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 93408 episodes
GETTING ACTION FROM:
action 5, numVisits=89327, meanQ=12.391060, numObservations: 9
action 4, numVisits=4076, meanQ=12.252850, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.54907 0.903365 0.577189 0.814094 0.277649 0.329908 0.869731 0.800173 0.593 0.0402142 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 13
Initial state: 0 0.869389 0.553867 0.412073 0.232404 0.428652 0.359775 0.600895 0.0686632 0.846109 0.760269 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97431 episodes
GETTING ACTION FROM:
action 1, numVisits=97424, meanQ=12.278217, numObservations: 9
action 4, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.869389 0.553867 0.412073 0.232404 0.428652 0.359775 0.600895 0.0686632 0.846109 0.760269 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 14
Initial state: 0 0.298592 0.326921 0.760208 0.173056 0.174905 0.896204 0.418429 0.871731 0.855929 0.796687 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 93498 episodes
GETTING ACTION FROM:
action 5, numVisits=93468, meanQ=12.203507, numObservations: 9
action 1, numVisits=17, meanQ=3.647076, numObservations: 6
action 4, numVisits=9, meanQ=2.222222, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.298592 0.326921 0.760208 0.173056 0.174905 0.896204 0.418429 0.871731 0.855929 0.796687 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 15
Initial state: 0 0.137007 0.600541 0.365667 0.341569 0.0899391 0.795134 0.872537 0.661271 0.724285 0.601932 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92546 episodes
GETTING ACTION FROM:
action 5, numVisits=92501, meanQ=12.371719, numObservations: 9
action 3, numVisits=34, meanQ=10.794706, numObservations: 9
action 4, numVisits=5, meanQ=5.998000, numObservations: 4
action 2, numVisits=3, meanQ=5.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 1 0.137007 0.600541 0.365667 0.341569 0.0899391 0.795134 0.872537 0.661271 0.724285 0.601932 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 16
Initial state: 0 0.0591008 0.724135 0.375522 0.412325 0.585765 0.00301968 0.982609 0.503235 0.254667 0.751039 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97322 episodes
GETTING ACTION FROM:
action 4, numVisits=97298, meanQ=12.302991, numObservations: 9
action 5, numVisits=11, meanQ=9.453636, numObservations: 7
action 1, numVisits=9, meanQ=9.222222, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.0591008 0.724135 0.375522 0.412325 0.585765 0.00301968 0.982609 0.503235 0.254667 0.751039 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 17
Initial state: 0 0.963651 0.672142 0.986964 0.962267 0.340606 0.40442 0.848797 0.250144 0.869762 0.708831 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97269 episodes
GETTING ACTION FROM:
action 4, numVisits=97248, meanQ=12.294933, numObservations: 9
action 1, numVisits=15, meanQ=7.850007, numObservations: 7
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.963651 0.672142 0.986964 0.962267 0.340606 0.40442 0.848797 0.250144 0.869762 0.708831 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 18
Initial state: 0 0.648753 0.843396 0.396772 0.394357 0.966955 0.0154739 0.865764 0.0154373 0.102181 0.558979 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97722 episodes
GETTING ACTION FROM:
action 1, numVisits=97714, meanQ=12.356884, numObservations: 9
action 3, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.648753 0.843396 0.396772 0.394357 0.966955 0.0154739 0.865764 0.0154373 0.102181 0.558979 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 19
Initial state: 0 0.0960264 0.0593202 0.421864 0.410153 0.0737371 0.135456 0.572021 0.631194 0.254288 0.299464 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 93802 episodes
GETTING ACTION FROM:
action 1, numVisits=93791, meanQ=12.170688, numObservations: 9
action 5, numVisits=4, meanQ=6.500000, numObservations: 3
action 3, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.0960264 0.0593202 0.421864 0.410153 0.0737371 0.135456 0.572021 0.631194 0.254288 0.299464 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 20
Initial state: 0 0.28974 0.876041 0.375178 0.410659 0.522058 0.652719 0.66745 0.148266 0.945258 0.388536 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97336 episodes
GETTING ACTION FROM:
action 5, numVisits=97325, meanQ=12.316983, numObservations: 9
action 1, numVisits=6, meanQ=6.500000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.28974 0.876041 0.375178 0.410659 0.522058 0.652719 0.66745 0.148266 0.945258 0.388536 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 21
Initial state: 0 0.391028 0.327643 0.141378 0.980939 0.216657 0.281096 0.735076 0.153213 0.0408366 0.0420802 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 94149 episodes
GETTING ACTION FROM:
action 4, numVisits=94132, meanQ=12.146295, numObservations: 9
action 1, numVisits=10, meanQ=8.704020, numObservations: 6
action 2, numVisits=3, meanQ=5.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.391028 0.327643 0.141378 0.980939 0.216657 0.281096 0.735076 0.153213 0.0408366 0.0420802 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 22
Initial state: 0 0.770878 0.731912 0.335711 0.0863837 0.823696 0.253273 0.0639772 0.315583 0.308204 0.448049 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97571 episodes
GETTING ACTION FROM:
action 3, numVisits=97555, meanQ=12.257028, numObservations: 9
action 5, numVisits=8, meanQ=8.373750, numObservations: 5
action 4, numVisits=2, meanQ=6.500000, numObservations: 2
action 2, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.770878 0.731912 0.335711 0.0863837 0.823696 0.253273 0.0639772 0.315583 0.308204 0.448049 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 23
Initial state: 0 0.428459 0.445132 0.0642516 0.487878 0.787899 0.249457 0.125666 0.0417377 0.438166 0.885493 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97172 episodes
GETTING ACTION FROM:
action 2, numVisits=97161, meanQ=12.305069, numObservations: 9
action 5, numVisits=4, meanQ=8.250000, numObservations: 3
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.428459 0.445132 0.0642516 0.487878 0.787899 0.249457 0.125666 0.0417377 0.438166 0.885493 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=2079, meanQ=13.568979, numObservations: 9
action 4, numVisits=23, meanQ=6.786961, numObservations: 7
action 1, numVisits=23, meanQ=6.771743, numObservations: 8
action 3, numVisits=3, meanQ=3.330000, numObservations: 3
action 2, numVisits=4, meanQ=3.245025, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 46710 episodes
GETTING ACTION FROM:
action 5, numVisits=48785, meanQ=13.875775, numObservations: 9
action 4, numVisits=23, meanQ=6.786961, numObservations: 7
action 1, numVisits=23, meanQ=6.771743, numObservations: 8
action 3, numVisits=3, meanQ=3.330000, numObservations: 3
action 2, numVisits=4, meanQ=3.245025, numObservations: 3
action -1, numVisits=3, meanQ=-1.670000, numObservations: 3
action 0, numVisits=3, meanQ=-1.670000, numObservations: 3
action: 5
Next state: 1 0.428459 0.445132 0.0642516 0.487878 0.787899 0.249457 0.125666 0.0417377 0.438166 0.885493 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 24
Initial state: 0 0.447146 0.700411 0.686696 0.455417 0.978965 0.577178 0.397123 0.394002 0.982105 0.29132 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97469 episodes
GETTING ACTION FROM:
action 5, numVisits=97431, meanQ=12.241716, numObservations: 9
action 3, numVisits=12, meanQ=7.831667, numObservations: 6
action 2, numVisits=20, meanQ=7.750510, numObservations: 6
action 1, numVisits=3, meanQ=5.663333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.447146 0.700411 0.686696 0.455417 0.978965 0.577178 0.397123 0.394002 0.982105 0.29132 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 25
Initial state: 0 0.829327 0.968237 0.218451 0.983049 0.514226 0.289027 0.854048 0.920455 0.363328 0.369255 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97338 episodes
GETTING ACTION FROM:
action 1, numVisits=97332, meanQ=12.333435, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.829327 0.968237 0.218451 0.983049 0.514226 0.289027 0.854048 0.920455 0.363328 0.369255 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 26
Initial state: 0 0.560663 0.786702 0.554079 0.292291 0.575682 0.789381 0.383499 0.375193 0.503613 0.894589 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91305 episodes
GETTING ACTION FROM:
action 5, numVisits=91289, meanQ=12.269469, numObservations: 9
action -1, numVisits=6, meanQ=-1.010000, numObservations: 6
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.560663 0.786702 0.554079 0.292291 0.575682 0.789381 0.383499 0.375193 0.503613 0.894589 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 27
Initial state: 0 0.0464472 0.36312 0.197425 0.514752 0.397003 0.466694 0.871764 0.961319 0.74843 0.908796 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97178 episodes
GETTING ACTION FROM:
action 1, numVisits=97144, meanQ=11.997767, numObservations: 9
action 3, numVisits=18, meanQ=9.944450, numObservations: 7
action 4, numVisits=9, meanQ=9.222222, numObservations: 4
action 2, numVisits=4, meanQ=8.250000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.0464472 0.36312 0.197425 0.514752 0.397003 0.466694 0.871764 0.961319 0.74843 0.908796 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=7493, meanQ=12.899340, numObservations: 9
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 43719 episodes
GETTING ACTION FROM:
action 2, numVisits=51043, meanQ=14.701320, numObservations: 9
action 5, numVisits=169, meanQ=8.716013, numObservations: 9
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.0464472 0.36312 0.197425 0.514752 0.397003 0.466694 0.871764 0.961319 0.74843 0.908796 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=2222, meanQ=13.690614, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 51379 episodes
GETTING ACTION FROM:
action 5, numVisits=53596, meanQ=14.846225, numObservations: 9
action -1, numVisits=4, meanQ=-1.505000, numObservations: 4
action 0, numVisits=4, meanQ=-1.505000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 5
Next state: 1 0.0464472 0.36312 0.197425 0.514752 0.397003 0.466694 0.871764 0.961319 0.74843 0.908796 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 28
Initial state: 0 0.387534 0.393487 0.223649 0.537545 0.191253 0.746973 0.038268 0.841613 0.0566057 0.00563907 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 96934 episodes
GETTING ACTION FROM:
action 5, numVisits=96915, meanQ=12.228144, numObservations: 9
action 2, numVisits=10, meanQ=7.900000, numObservations: 6
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action 4, numVisits=4, meanQ=6.500000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 0 0.387534 0.393487 0.223649 0.537545 0.191253 0.746973 0.038268 0.841613 0.0566057 0.00563907 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1847, meanQ=13.956472, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 102016 episodes
GETTING ACTION FROM:
action 2, numVisits=103849, meanQ=7.846880, numObservations: 9
action -1, numVisits=8, meanQ=-1.752500, numObservations: 7
action 0, numVisits=7, meanQ=-1.858571, numObservations: 7
action 3, numVisits=2, meanQ=-7.005000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.387534 0.393487 0.223649 0.537545 0.191253 0.746973 0.038268 0.841613 0.0566057 0.00563907 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=626, meanQ=16.887233, numObservations: 9
action 1, numVisits=16, meanQ=9.531035, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 88860 episodes
GETTING ACTION FROM:
action 3, numVisits=89484, meanQ=13.448458, numObservations: 9
action 1, numVisits=16, meanQ=9.531035, numObservations: 7
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.387534 0.393487 0.223649 0.537545 0.191253 0.746973 0.038268 0.841613 0.0566057 0.00563907 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=1, meanQ=24.000000, numObservations: 1
action 1, numVisits=72, meanQ=18.433804, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-9.868491, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 114432 episodes
GETTING ACTION FROM:
action 1, numVisits=114419, meanQ=16.836742, numObservations: 9
action 2, numVisits=84, meanQ=15.250000, numObservations: 7
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 3, numVisits=1, meanQ=-9.868491, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.387534 0.393487 0.223649 0.537545 0.191253 0.746973 0.038268 0.841613 0.0566057 0.00563907 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 11.4068
Run # 29
Initial state: 0 0.415843 0.442895 0.677013 0.980028 0.753635 0.63745 0.908398 0.828163 0.61094 0.653641 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 94360 episodes
GETTING ACTION FROM:
action 1, numVisits=94349, meanQ=12.160266, numObservations: 9
action 5, numVisits=4, meanQ=6.500000, numObservations: 2
action 2, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.415843 0.442895 0.677013 0.980028 0.753635 0.63745 0.908398 0.828163 0.61094 0.653641 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 30
Initial state: 0 0.523643 0.52241 0.0736321 0.139347 0.335996 0.321889 0.725105 0.601613 0.0873013 0.00433595 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97139 episodes
GETTING ACTION FROM:
action 4, numVisits=97133, meanQ=12.235971, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.523643 0.52241 0.0736321 0.139347 0.335996 0.321889 0.725105 0.601613 0.0873013 0.00433595 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 31
Initial state: 0 0.130049 0.337329 0.87161 0.446926 0.971038 0.631249 0.589872 0.200128 0.371587 0.388088 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97481 episodes
GETTING ACTION FROM:
action 1, numVisits=97473, meanQ=12.260040, numObservations: 9
action 3, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.130049 0.337329 0.87161 0.446926 0.971038 0.631249 0.589872 0.200128 0.371587 0.388088 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 32
Initial state: 0 0.228772 0.318813 0.425219 0.325925 0.522915 0.727848 0.282773 0.281351 0.326366 0.742271 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97681 episodes
GETTING ACTION FROM:
action 3, numVisits=97665, meanQ=12.249891, numObservations: 9
action 1, numVisits=6, meanQ=8.833333, numObservations: 3
action 4, numVisits=6, meanQ=7.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.228772 0.318813 0.425219 0.325925 0.522915 0.727848 0.282773 0.281351 0.326366 0.742271 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 33
Initial state: 0 0.0423784 0.372856 0.505409 0.516867 0.75751 0.947328 0.271523 0.681465 0.372046 0.430768 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 96632 episodes
GETTING ACTION FROM:
action 1, numVisits=96609, meanQ=12.102110, numObservations: 9
action 3, numVisits=14, meanQ=8.000000, numObservations: 7
action 4, numVisits=5, meanQ=4.400000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.0423784 0.372856 0.505409 0.516867 0.75751 0.947328 0.271523 0.681465 0.372046 0.430768 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 34
Initial state: 0 0.78159 0.870466 0.211026 0.108294 0.444969 0.842469 0.187641 0.747663 0.391049 0.365911 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97601 episodes
GETTING ACTION FROM:
action 5, numVisits=97577, meanQ=12.277049, numObservations: 9
action 2, numVisits=15, meanQ=8.600000, numObservations: 9
action 3, numVisits=5, meanQ=5.800000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.78159 0.870466 0.211026 0.108294 0.444969 0.842469 0.187641 0.747663 0.391049 0.365911 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 35
Initial state: 0 0.291381 0.41714 0.955865 0.686672 0.964824 0.889639 0.271857 0.51241 0.796963 0.55029 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97864 episodes
GETTING ACTION FROM:
action 2, numVisits=97843, meanQ=12.255419, numObservations: 9
action 5, numVisits=11, meanQ=10.000000, numObservations: 6
action 1, numVisits=6, meanQ=6.500000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.291381 0.41714 0.955865 0.686672 0.964824 0.889639 0.271857 0.51241 0.796963 0.55029 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 36
Initial state: 0 0.351071 0.468253 0.0216952 0.959549 0.0233966 0.514768 0.25516 0.0470437 0.510598 0.55832 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97944 episodes
GETTING ACTION FROM:
action 1, numVisits=97924, meanQ=12.341186, numObservations: 9
action 2, numVisits=15, meanQ=10.434000, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.351071 0.468253 0.0216952 0.959549 0.0233966 0.514768 0.25516 0.0470437 0.510598 0.55832 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 37
Initial state: 0 0.374341 0.358865 0.603381 0.658499 0.433055 0.716784 0.566742 0.671378 0.766654 0.0755692 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97520 episodes
GETTING ACTION FROM:
action 4, numVisits=97506, meanQ=12.073566, numObservations: 9
action 2, numVisits=6, meanQ=7.666667, numObservations: 6
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action 5, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.374341 0.358865 0.603381 0.658499 0.433055 0.716784 0.566742 0.671378 0.766654 0.0755692 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 38
Initial state: 0 0.0481507 0.868331 0.482169 0.923543 0.413275 0.463204 0.517994 0.117693 0.267181 0.759897 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97699 episodes
GETTING ACTION FROM:
action 1, numVisits=97687, meanQ=12.201249, numObservations: 9
action 5, numVisits=5, meanQ=5.800000, numObservations: 3
action 2, numVisits=3, meanQ=5.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.0481507 0.868331 0.482169 0.923543 0.413275 0.463204 0.517994 0.117693 0.267181 0.759897 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 39
Initial state: 0 0.814602 0.230958 0.681229 0.765438 0.639655 0.725863 0.931889 0.723843 0.277504 0.393737 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97418 episodes
GETTING ACTION FROM:
action 1, numVisits=97391, meanQ=12.239187, numObservations: 9
action 5, numVisits=19, meanQ=9.899474, numObservations: 6
action 4, numVisits=4, meanQ=6.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.814602 0.230958 0.681229 0.765438 0.639655 0.725863 0.931889 0.723843 0.277504 0.393737 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 40
Initial state: 0 0.435776 0.284757 0.492113 0.885805 0.226584 0.762247 0.346376 0.398286 0.129576 0.482984 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97595 episodes
GETTING ACTION FROM:
action 2, numVisits=97574, meanQ=12.308192, numObservations: 9
action 1, numVisits=16, meanQ=10.000000, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.435776 0.284757 0.492113 0.885805 0.226584 0.762247 0.346376 0.398286 0.129576 0.482984 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 41
Initial state: 0 0.0938564 0.893808 0.312224 0.369024 0.455551 0.897667 0.957233 0.504983 0.255405 0.021415 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 94376 episodes
GETTING ACTION FROM:
action 1, numVisits=94353, meanQ=12.221893, numObservations: 9
action 4, numVisits=14, meanQ=4.570714, numObservations: 8
action 5, numVisits=3, meanQ=3.000000, numObservations: 3
action 3, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.0938564 0.893808 0.312224 0.369024 0.455551 0.897667 0.957233 0.504983 0.255405 0.021415 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 42
Initial state: 0 0.906395 0.212935 0.0207662 0.276275 0.443515 0.819505 0.313925 0.43362 0.555976 0.575595 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 96898 episodes
GETTING ACTION FROM:
action 4, numVisits=96890, meanQ=12.158420, numObservations: 9
action 5, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.906395 0.212935 0.0207662 0.276275 0.443515 0.819505 0.313925 0.43362 0.555976 0.575595 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 43
Initial state: 0 0.449077 0.0820168 0.694247 0.294272 0.538061 0.636798 0.159394 0.193582 0.318332 0.452298 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 96935 episodes
GETTING ACTION FROM:
action 1, numVisits=96922, meanQ=12.123759, numObservations: 9
action 2, numVisits=8, meanQ=7.375000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.449077 0.0820168 0.694247 0.294272 0.538061 0.636798 0.159394 0.193582 0.318332 0.452298 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 44
Initial state: 0 0.602352 0.195684 0.333907 0.4879 0.948115 0.0319801 0.883355 0.342724 0.191684 0.827897 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97257 episodes
GETTING ACTION FROM:
action 1, numVisits=97219, meanQ=12.252788, numObservations: 9
action 4, numVisits=15, meanQ=9.901333, numObservations: 7
action 3, numVisits=18, meanQ=9.713333, numObservations: 7
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.602352 0.195684 0.333907 0.4879 0.948115 0.0319801 0.883355 0.342724 0.191684 0.827897 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 45
Initial state: 0 0.580166 0.369235 0.406808 0.491357 0.942056 0.532937 0.916551 0.269861 0.0325872 0.540575 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97547 episodes
GETTING ACTION FROM:
action 2, numVisits=97535, meanQ=12.230858, numObservations: 9
action 5, numVisits=5, meanQ=7.596000, numObservations: 4
action 1, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.580166 0.369235 0.406808 0.491357 0.942056 0.532937 0.916551 0.269861 0.0325872 0.540575 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 46
Initial state: 0 0.944981 0.585514 0.156607 0.878607 0.410828 0.375169 0.176152 0.959301 0.944334 0.0786603 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97284 episodes
GETTING ACTION FROM:
action 4, numVisits=97272, meanQ=12.173182, numObservations: 9
action 3, numVisits=4, meanQ=8.250000, numObservations: 3
action 5, numVisits=4, meanQ=8.250000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.944981 0.585514 0.156607 0.878607 0.410828 0.375169 0.176152 0.959301 0.944334 0.0786603 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 47
Initial state: 0 0.622232 0.0483025 0.290279 0.857641 0.534833 0.290564 0.375767 0.378773 0.52182 0.317697 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 96897 episodes
GETTING ACTION FROM:
action 1, numVisits=96889, meanQ=12.119694, numObservations: 9
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.622232 0.0483025 0.290279 0.857641 0.534833 0.290564 0.375767 0.378773 0.52182 0.317697 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 48
Initial state: 0 0.386396 0.437599 0.565207 0.606529 0.639856 0.859146 0.76215 0.847302 0.590615 0.452769 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97439 episodes
GETTING ACTION FROM:
action 4, numVisits=97424, meanQ=12.186404, numObservations: 9
action 5, numVisits=7, meanQ=9.000000, numObservations: 5
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action 2, numVisits=3, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.386396 0.437599 0.565207 0.606529 0.639856 0.859146 0.76215 0.847302 0.590615 0.452769 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 49
Initial state: 0 0.253409 0.497109 0.0824665 0.761625 0.284884 0.426571 0.184178 0.562289 0.856698 0.84443 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 90602 episodes
GETTING ACTION FROM:
action 4, numVisits=90588, meanQ=12.256004, numObservations: 9
action 2, numVisits=9, meanQ=6.221111, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.253409 0.497109 0.0824665 0.761625 0.284884 0.426571 0.184178 0.562289 0.856698 0.84443 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=7157, meanQ=13.012410, numObservations: 9
action 2, numVisits=8, meanQ=9.247512, numObservations: 3
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 38367 episodes
GETTING ACTION FROM:
action 2, numVisits=38352, meanQ=13.788517, numObservations: 9
action 4, numVisits=7158, meanQ=13.011863, numObservations: 9
action 3, numVisits=3, meanQ=0.666667, numObservations: 3
action 0, numVisits=12, meanQ=-1.340000, numObservations: 11
action -1, numVisits=10, meanQ=-1.505000, numObservations: 9
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.253409 0.497109 0.0824665 0.761625 0.284884 0.426571 0.184178 0.562289 0.856698 0.84443 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=79, meanQ=11.959521, numObservations: 9
action 2, numVisits=2, meanQ=-10.003676, numObservations: 2
action 3, numVisits=2, meanQ=-11.000000, numObservations: 2
action -1, numVisits=55, meanQ=-16.155931, numObservations: 37
action 1, numVisits=29, meanQ=-27.383305, numObservations: 9
action 0, numVisits=16, meanQ=-67.347549, numObservations: 14
action 4, numVisits=1, meanQ=-1069.468315, numObservations: 1
Sampled 108865 episodes
GETTING ACTION FROM:
action 5, numVisits=108944, meanQ=16.005276, numObservations: 9
action 2, numVisits=2, meanQ=-10.003676, numObservations: 2
action 3, numVisits=2, meanQ=-11.000000, numObservations: 2
action -1, numVisits=55, meanQ=-16.155931, numObservations: 37
action 1, numVisits=29, meanQ=-27.383305, numObservations: 9
action 0, numVisits=16, meanQ=-67.347549, numObservations: 14
action 4, numVisits=1, meanQ=-1069.468315, numObservations: 1
action: 5
Next state: 1 0.253409 0.497109 0.0824665 0.761625 0.284884 0.426571 0.184178 0.562289 0.856698 0.84443 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 50
Initial state: 0 0.827492 0.70788 0.703409 0.201391 0.353349 0.434406 0.906808 0.599067 0.0869493 0.612353 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97291 episodes
GETTING ACTION FROM:
action 4, numVisits=97281, meanQ=12.070552, numObservations: 9
action 1, numVisits=3, meanQ=3.000000, numObservations: 3
action 5, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.827492 0.70788 0.703409 0.201391 0.353349 0.434406 0.906808 0.599067 0.0869493 0.612353 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
[32m ProblemEnvironment.hpp 351: Done.[39m
