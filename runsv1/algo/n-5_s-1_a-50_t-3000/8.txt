Run # 1
Initial state: 0 0.731087 0.747629 0.468197 0.444197 0.100933 0.497396 0.422111 0.905883 0.665299 0.543594 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 73178 episodes
GETTING ACTION FROM:
action 4, numVisits=73161, meanQ=7.785581, numObservations: 9
action 2, numVisits=7, meanQ=5.000000, numObservations: 4
action 1, numVisits=3, meanQ=3.000000, numObservations: 3
action 5, numVisits=4, meanQ=1.250000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 0 0.731087 0.747629 0.468197 0.444197 0.100933 0.497396 0.422111 0.905883 0.665299 0.543594 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=6901, meanQ=9.801125, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 22165 episodes
GETTING ACTION FROM:
action 2, numVisits=22013, meanQ=12.166082, numObservations: 9
action 4, numVisits=6902, meanQ=9.800470, numObservations: 9
action 3, numVisits=4, meanQ=-9.558690, numObservations: 3
action 1, numVisits=3, meanQ=-11.090553, numObservations: 2
action -1, numVisits=78, meanQ=-15.016772, numObservations: 50
action 0, numVisits=68, meanQ=-16.288639, numObservations: 47
action 5, numVisits=4, meanQ=-255.151697, numObservations: 2
action: 2
Next state: 0 0.731087 0.747629 0.468197 0.444197 0.100933 0.497396 0.422111 0.905883 0.665299 0.543594 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=1, meanQ=24.000000, numObservations: 1
action 3, numVisits=2846, meanQ=10.093564, numObservations: 9
action 5, numVisits=2, meanQ=-10.553774, numObservations: 2
action 1, numVisits=4, meanQ=-10.904502, numObservations: 3
action 2, numVisits=3, meanQ=-11.219172, numObservations: 2
action 0, numVisits=42, meanQ=-26.854621, numObservations: 32
action -1, numVisits=18, meanQ=-59.703004, numObservations: 14
Sampled 14092 episodes
GETTING ACTION FROM:
action 3, numVisits=16936, meanQ=11.833049, numObservations: 9
action 4, numVisits=3, meanQ=1.368895, numObservations: 2
action 5, numVisits=2, meanQ=-10.553774, numObservations: 2
action 1, numVisits=4, meanQ=-10.904502, numObservations: 3
action 2, numVisits=3, meanQ=-11.219172, numObservations: 2
action 0, numVisits=42, meanQ=-26.854621, numObservations: 32
action -1, numVisits=18, meanQ=-59.703004, numObservations: 14
action: 3
Next state: 0 0.731087 0.747629 0.468197 0.444197 0.100933 0.497396 0.422111 0.905883 0.665299 0.543594 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action -1, numVisits=1775, meanQ=11.140954, numObservations: 105
action 1, numVisits=1, meanQ=-10.079043, numObservations: 1
action 3, numVisits=1, meanQ=-10.097430, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.302094, numObservations: 1
action 0, numVisits=39, meanQ=-26.046428, numObservations: 26
action 4, numVisits=1, meanQ=-1067.193510, numObservations: 1
Sampled 7851 episodes
GETTING ACTION FROM:
action -1, numVisits=9626, meanQ=7.889103, numObservations: 170
action 1, numVisits=1, meanQ=-10.079043, numObservations: 1
action 3, numVisits=1, meanQ=-10.097430, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.302094, numObservations: 1
action 0, numVisits=39, meanQ=-26.046428, numObservations: 26
action 4, numVisits=1, meanQ=-1067.193510, numObservations: 1
action: -1
Next state: 0 0.731087 0.747629 0.468197 0.444197 0.100933 0.497396 0.422111 0.905883 0.665299 0.543594 w: 1
Observation: 0 2 0 1 0 1 0 1 0 2 0 
Immediate reward: -2
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 4, numVisits=1, meanQ=24.000000, numObservations: 1
action 5, numVisits=330, meanQ=8.520903, numObservations: 9
action -1, numVisits=8, meanQ=-2.495000, numObservations: 7
action 1, numVisits=1, meanQ=-9.897947, numObservations: 1
action 3, numVisits=1, meanQ=-10.143003, numObservations: 1
action 2, numVisits=1, meanQ=-10.166715, numObservations: 1
action 0, numVisits=21, meanQ=-20.480857, numObservations: 13
Sampled 18840 episodes
GETTING ACTION FROM:
action 5, numVisits=19165, meanQ=15.051995, numObservations: 9
action -1, numVisits=8, meanQ=-2.495000, numObservations: 7
action 1, numVisits=1, meanQ=-9.897947, numObservations: 1
action 3, numVisits=1, meanQ=-10.143003, numObservations: 1
action 2, numVisits=1, meanQ=-10.166715, numObservations: 1
action 0, numVisits=21, meanQ=-20.480857, numObservations: 13
action 4, numVisits=6, meanQ=-54.508639, numObservations: 3
action: 5
Next state: 1 0.731087 0.747629 0.468197 0.444197 0.100933 0.497396 0.422111 0.905883 0.665299 0.543594 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9.23331
Run # 2
Initial state: 0 0.174503 0.480233 0.860945 0.0710658 0.105292 0.977336 0.548731 0.695686 0.221769 0.613273 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 74012 episodes
GETTING ACTION FROM:
action 5, numVisits=73991, meanQ=7.850146, numObservations: 9
action 2, numVisits=6, meanQ=3.518333, numObservations: 5
action 3, numVisits=11, meanQ=3.365464, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.174503 0.480233 0.860945 0.0710658 0.105292 0.977336 0.548731 0.695686 0.221769 0.613273 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 3
Initial state: 0 0.355958 0.147884 0.52583 0.560165 0.613029 0.799658 0.864036 0.537731 0.568842 0.0243387 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48376 episodes
GETTING ACTION FROM:
action 0, numVisits=48345, meanQ=14.949648, numObservations: 243
action -1, numVisits=15, meanQ=-1.010000, numObservations: 15
action 2, numVisits=6, meanQ=-1.646633, numObservations: 3
action 4, numVisits=6, meanQ=-2.833333, numObservations: 3
action 3, numVisits=2, meanQ=-5.489950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.355958 0.147884 0.52583 0.560165 0.613029 0.799658 0.864036 0.537731 0.568842 0.0243387 w: 1
Observation: 0 0 1 0 2 0 3 0 1 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=475, meanQ=21.057956, numObservations: 9
action 3, numVisits=4, meanQ=10.495000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 110148 episodes
GETTING ACTION FROM:
action 2, numVisits=110623, meanQ=22.284390, numObservations: 9
action 3, numVisits=4, meanQ=10.495000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.355958 0.147884 0.52583 0.560165 0.613029 0.799658 0.864036 0.537731 0.568842 0.0243387 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 4
Initial state: 0 0.303554 0.289422 0.845447 0.739061 0.0777887 0.205572 0.664631 0.654335 0.735546 0.73427 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 75355 episodes
GETTING ACTION FROM:
action 1, numVisits=75052, meanQ=7.783793, numObservations: 9
action 2, numVisits=294, meanQ=6.981773, numObservations: 9
action 4, numVisits=3, meanQ=3.000000, numObservations: 3
action 5, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.303554 0.289422 0.845447 0.739061 0.0777887 0.205572 0.664631 0.654335 0.735546 0.73427 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=15987, meanQ=9.205601, numObservations: 9
action 5, numVisits=8, meanQ=4.122500, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 17863 episodes
GETTING ACTION FROM:
action 3, numVisits=33807, meanQ=8.894980, numObservations: 9
action 5, numVisits=17, meanQ=3.852941, numObservations: 7
action -1, numVisits=17, meanQ=-1.126471, numObservations: 16
action 0, numVisits=15, meanQ=-1.208000, numObservations: 15
action 1, numVisits=2, meanQ=-7.255814, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=4, meanQ=-262.883346, numObservations: 3
action: 3
Next state: 0 0.303554 0.289422 0.845447 0.739061 0.0777887 0.205572 0.664631 0.654335 0.735546 0.73427 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=6332, meanQ=10.724388, numObservations: 9
action 2, numVisits=6, meanQ=2.020017, numObservations: 3
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 12920 episodes
GETTING ACTION FROM:
action 4, numVisits=19237, meanQ=10.023620, numObservations: 9
action 5, numVisits=9, meanQ=1.905204, numObservations: 6
action 2, numVisits=7, meanQ=0.514323, numObservations: 4
action 0, numVisits=6, meanQ=-1.340000, numObservations: 6
action -1, numVisits=8, meanQ=-1.382488, numObservations: 7
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 1 0.303554 0.289422 0.845447 0.739061 0.0777887 0.205572 0.664631 0.654335 0.735546 0.73427 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 5
Initial state: 0 0.760054 0.235622 0.00691947 0.753744 0.509731 0.519201 0.528556 0.566831 0.828492 0.501097 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 75969 episodes
GETTING ACTION FROM:
action 1, numVisits=75959, meanQ=7.882920, numObservations: 9
action 4, numVisits=5, meanQ=4.400000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.760054 0.235622 0.00691947 0.753744 0.509731 0.519201 0.528556 0.566831 0.828492 0.501097 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 6
Initial state: 0 0.10684 0.617305 0.0848518 0.421903 0.99879 0.176617 0.612607 0.598938 0.0331539 0.475602 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 76010 episodes
GETTING ACTION FROM:
action 1, numVisits=76000, meanQ=7.822425, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.10684 0.617305 0.0848518 0.421903 0.99879 0.176617 0.612607 0.598938 0.0331539 0.475602 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 7
Initial state: 0 0.132738 0.0833231 0.666348 0.649874 0.849444 0.798157 0.971904 0.657161 0.155245 0.827536 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 72400 episodes
GETTING ACTION FROM:
action 1, numVisits=72351, meanQ=7.625122, numObservations: 9
action 0, numVisits=17, meanQ=-1.010000, numObservations: 17
action -1, numVisits=18, meanQ=-1.010000, numObservations: 18
action 5, numVisits=11, meanQ=-1.540882, numObservations: 6
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.132738 0.0833231 0.666348 0.649874 0.849444 0.798157 0.971904 0.657161 0.155245 0.827536 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=15431, meanQ=8.695883, numObservations: 9
action 2, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 20097 episodes
GETTING ACTION FROM:
action 3, numVisits=35504, meanQ=8.173301, numObservations: 9
action -1, numVisits=13, meanQ=-1.086154, numObservations: 13
action 0, numVisits=9, meanQ=-1.450000, numObservations: 9
action 2, numVisits=4, meanQ=-1.882767, numObservations: 3
action 1, numVisits=2, meanQ=-3.505000, numObservations: 2
action 4, numVisits=2, meanQ=-3.505000, numObservations: 2
action 5, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 3
Next state: 1 0.132738 0.0833231 0.666348 0.649874 0.849444 0.798157 0.971904 0.657161 0.155245 0.827536 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 8
Initial state: 0 0.264519 0.336162 0.689048 0.578572 0.92872 0.715231 0.495868 0.914302 0.397189 0.0865697 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 75546 episodes
GETTING ACTION FROM:
action 2, numVisits=75524, meanQ=7.892341, numObservations: 9
action -1, numVisits=5, meanQ=-1.010000, numObservations: 5
action 0, numVisits=5, meanQ=-1.010000, numObservations: 5
action 5, numVisits=9, meanQ=-1.219989, numObservations: 4
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.264519 0.336162 0.689048 0.578572 0.92872 0.715231 0.495868 0.914302 0.397189 0.0865697 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1279, meanQ=19.434614, numObservations: 9
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 67235 episodes
GETTING ACTION FROM:
action 2, numVisits=1288, meanQ=19.453695, numObservations: 9
action 5, numVisits=67176, meanQ=12.930715, numObservations: 9
action -1, numVisits=27, meanQ=-1.853333, numObservations: 20
action 0, numVisits=27, meanQ=-1.853333, numObservations: 21
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.264519 0.336162 0.689048 0.578572 0.92872 0.715231 0.495868 0.914302 0.397189 0.0865697 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 9
Initial state: 0 0.810899 0.287662 0.151989 0.76145 0.307945 0.293882 0.678563 0.608009 0.957666 0.993901 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 75929 episodes
GETTING ACTION FROM:
action 2, numVisits=75907, meanQ=7.889809, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=7, meanQ=-1.010000, numObservations: 7
action 3, numVisits=4, meanQ=-2.250000, numObservations: 3
action 4, numVisits=2, meanQ=-4.499950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.810899 0.287662 0.151989 0.76145 0.307945 0.293882 0.678563 0.608009 0.957666 0.993901 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=7235, meanQ=9.798518, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 23241 episodes
GETTING ACTION FROM:
action 1, numVisits=30476, meanQ=10.831424, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.810899 0.287662 0.151989 0.76145 0.307945 0.293882 0.678563 0.608009 0.957666 0.993901 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 10
Initial state: 0 0.71697 0.882495 0.519128 0.300305 0.603257 0.00374517 0.652541 0.581303 0.353427 0.187554 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 75141 episodes
GETTING ACTION FROM:
action 5, numVisits=75133, meanQ=7.633531, numObservations: 9
action 1, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.71697 0.882495 0.519128 0.300305 0.603257 0.00374517 0.652541 0.581303 0.353427 0.187554 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=15782, meanQ=9.055023, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=4, meanQ=-1.507475, numObservations: 3
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 19719 episodes
GETTING ACTION FROM:
action 2, numVisits=35488, meanQ=8.583632, numObservations: 9
action 0, numVisits=15, meanQ=-1.208660, numObservations: 13
action -1, numVisits=8, meanQ=-2.314931, numObservations: 7
action 5, numVisits=2, meanQ=-6.814464, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.71697 0.882495 0.519128 0.300305 0.603257 0.00374517 0.652541 0.581303 0.353427 0.187554 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=6937, meanQ=12.393353, numObservations: 9
action 1, numVisits=9, meanQ=4.002256, numObservations: 5
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=3, meanQ=-4.970000, numObservations: 2
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 13251 episodes
GETTING ACTION FROM:
action 3, numVisits=20177, meanQ=12.299459, numObservations: 9
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=3, meanQ=-4.970000, numObservations: 2
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=17, meanQ=-23.194527, numObservations: 7
action: 3
Next state: 2 0.71697 0.882495 0.519128 0.300305 0.603257 0.00374517 0.652541 0.581303 0.353427 0.187554 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -18.7411
Run # 11
Initial state: 0 0.707919 0.82642 0.617154 0.600656 0.758712 0.505234 0.297274 0.841714 0.922537 0.296199 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 72773 episodes
GETTING ACTION FROM:
action 4, numVisits=72765, meanQ=7.907822, numObservations: 9
action 3, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.707919 0.82642 0.617154 0.600656 0.758712 0.505234 0.297274 0.841714 0.922537 0.296199 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=6920, meanQ=12.546588, numObservations: 228
action 0, numVisits=10, meanQ=-1.605980, numObservations: 8
action 4, numVisits=3, meanQ=-3.010000, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 12953 episodes
GETTING ACTION FROM:
action -1, numVisits=19873, meanQ=10.074513, numObservations: 241
action 0, numVisits=10, meanQ=-1.605980, numObservations: 8
action 4, numVisits=3, meanQ=-3.010000, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.707919 0.82642 0.617154 0.600656 0.758712 0.505234 0.297274 0.841714 0.922537 0.296199 w: 1
Observation: 0 3 0 2 0 3 0 1 0 3 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=82, meanQ=20.487302, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 84206 episodes
GETTING ACTION FROM:
action 2, numVisits=84288, meanQ=22.568569, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.707919 0.82642 0.617154 0.600656 0.758712 0.505234 0.297274 0.841714 0.922537 0.296199 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 17.5424
Run # 12
Initial state: 0 0.642617 0.688293 0.246866 0.2097 0.208403 0.728159 0.443415 0.91975 0.491286 0.18623 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 76465 episodes
GETTING ACTION FROM:
action 2, numVisits=76453, meanQ=7.814431, numObservations: 9
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.642617 0.688293 0.246866 0.2097 0.208403 0.728159 0.443415 0.91975 0.491286 0.18623 w: 1
Observation: 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=2053, meanQ=9.129045, numObservations: 9
action 4, numVisits=6, meanQ=5.000033, numObservations: 4
action 1, numVisits=4, meanQ=3.742500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 20867 episodes
GETTING ACTION FROM:
action 5, numVisits=22693, meanQ=5.351854, numObservations: 9
action 4, numVisits=13, meanQ=1.760720, numObservations: 5
action 1, numVisits=15, meanQ=1.441786, numObservations: 6
action -1, numVisits=121, meanQ=-10.163359, numObservations: 80
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=90, meanQ=-13.619761, numObservations: 59
action: 5
Next state: 0 0.642617 0.688293 0.246866 0.2097 0.208403 0.728159 0.443415 0.91975 0.491286 0.18623 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=173, meanQ=8.462162, numObservations: 9
action 4, numVisits=3, meanQ=-0.658582, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=38, meanQ=-16.373481, numObservations: 9
action -1, numVisits=15, meanQ=-70.572611, numObservations: 14
action 0, numVisits=7, meanQ=-150.233679, numObservations: 6
Sampled 49045 episodes
GETTING ACTION FROM:
action 3, numVisits=49218, meanQ=5.848172, numObservations: 9
action 4, numVisits=3, meanQ=-0.658582, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=38, meanQ=-16.373481, numObservations: 9
action -1, numVisits=15, meanQ=-70.572611, numObservations: 14
action 0, numVisits=7, meanQ=-150.233679, numObservations: 6
action: 3
Next state: 0 0.642617 0.688293 0.246866 0.2097 0.208403 0.728159 0.443415 0.91975 0.491286 0.18623 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=268, meanQ=12.624180, numObservations: 9
action -1, numVisits=6, meanQ=-2.990000, numObservations: 5
action 3, numVisits=1, meanQ=-13.347337, numObservations: 1
action 5, numVisits=1, meanQ=-13.983455, numObservations: 1
action 4, numVisits=1, meanQ=-15.079578, numObservations: 1
action 0, numVisits=10, meanQ=-54.211210, numObservations: 9
action 2, numVisits=1, meanQ=-1052.836388, numObservations: 1
Sampled 70244 episodes
GETTING ACTION FROM:
action 1, numVisits=70512, meanQ=9.119626, numObservations: 9
action -1, numVisits=6, meanQ=-2.990000, numObservations: 5
action 3, numVisits=1, meanQ=-13.347337, numObservations: 1
action 5, numVisits=1, meanQ=-13.983455, numObservations: 1
action 4, numVisits=1, meanQ=-15.079578, numObservations: 1
action 0, numVisits=10, meanQ=-54.211210, numObservations: 9
action 2, numVisits=1, meanQ=-1052.836388, numObservations: 1
action: 1
Next state: 1 0.642617 0.688293 0.246866 0.2097 0.208403 0.728159 0.443415 0.91975 0.491286 0.18623 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 11.4068
Run # 13
Initial state: 0 0.129683 0.918481 0.895769 0.335035 0.57564 0.670616 0.687416 0.422038 0.918829 0.732282 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 75245 episodes
GETTING ACTION FROM:
action 4, numVisits=75239, meanQ=7.771260, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.129683 0.918481 0.895769 0.335035 0.57564 0.670616 0.687416 0.422038 0.918829 0.732282 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=577, meanQ=12.269856, numObservations: 9
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action 2, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 40239 episodes
GETTING ACTION FROM:
action 4, numVisits=578, meanQ=12.257760, numObservations: 9
action 3, numVisits=40221, meanQ=11.933110, numObservations: 9
action 5, numVisits=7, meanQ=1.872884, numObservations: 5
action 2, numVisits=4, meanQ=1.745000, numObservations: 4
action -1, numVisits=7, meanQ=-1.717143, numObservations: 7
action 0, numVisits=7, meanQ=-1.717143, numObservations: 7
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.129683 0.918481 0.895769 0.335035 0.57564 0.670616 0.687416 0.422038 0.918829 0.732282 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 14
Initial state: 0 0.46348 0.366403 0.87909 0.384021 0.940224 0.277272 0.31599 0.363476 0.578844 0.549781 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 75917 episodes
GETTING ACTION FROM:
action 2, numVisits=75908, meanQ=7.392197, numObservations: 9
action 3, numVisits=4, meanQ=1.250000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.46348 0.366403 0.87909 0.384021 0.940224 0.277272 0.31599 0.363476 0.578844 0.549781 w: 1
Observation: 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=1927, meanQ=9.323322, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 20190 episodes
GETTING ACTION FROM:
action 3, numVisits=22003, meanQ=7.681200, numObservations: 9
action 0, numVisits=88, meanQ=-1.531758, numObservations: 59
action -1, numVisits=27, meanQ=-2.083196, numObservations: 25
action 1, numVisits=2, meanQ=-10.426520, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.46348 0.366403 0.87909 0.384021 0.940224 0.277272 0.31599 0.363476 0.578844 0.549781 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 15
Initial state: 0 0.48977 0.922725 0.325178 0.453525 0.0263151 0.765816 0.527379 0.56208 0.985093 0.381292 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 69297 episodes
GETTING ACTION FROM:
action 5, numVisits=69289, meanQ=6.281825, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.48977 0.922725 0.325178 0.453525 0.0263151 0.765816 0.527379 0.56208 0.985093 0.381292 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 16
Initial state: 0 0.127238 0.497084 0.677555 0.902818 0.0757783 0.428372 0.709386 0.574279 0.664645 0.654949 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 76310 episodes
GETTING ACTION FROM:
action 2, numVisits=76291, meanQ=7.841373, numObservations: 9
action 5, numVisits=5, meanQ=4.598000, numObservations: 4
action 3, numVisits=8, meanQ=4.501263, numObservations: 5
action 1, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.127238 0.497084 0.677555 0.902818 0.0757783 0.428372 0.709386 0.574279 0.664645 0.654949 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 17
Initial state: 0 0.865906 0.00278669 0.938004 0.661723 0.88858 0.832178 0.681006 0.64441 0.9677 0.801794 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 76019 episodes
GETTING ACTION FROM:
action 1, numVisits=76011, meanQ=7.918276, numObservations: 9
action 5, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.865906 0.00278669 0.938004 0.661723 0.88858 0.832178 0.681006 0.64441 0.9677 0.801794 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 18
Initial state: 0 0.373676 0.201993 0.486358 0.787056 0.0739875 0.149586 0.777505 0.986465 0.702033 0.693207 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 76475 episodes
GETTING ACTION FROM:
action 1, numVisits=76437, meanQ=7.927973, numObservations: 9
action 3, numVisits=29, meanQ=4.757955, numObservations: 9
action 2, numVisits=3, meanQ=3.000000, numObservations: 3
action 4, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.373676 0.201993 0.486358 0.787056 0.0739875 0.149586 0.777505 0.986465 0.702033 0.693207 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=16226, meanQ=9.294582, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 16506 episodes
GETTING ACTION FROM:
action 4, numVisits=32683, meanQ=8.852132, numObservations: 9
action 5, numVisits=14, meanQ=3.535612, numObservations: 8
action -1, numVisits=21, meanQ=-0.787269, numObservations: 17
action 0, numVisits=15, meanQ=-1.076000, numObservations: 15
action 2, numVisits=2, meanQ=-3.505000, numObservations: 2
action 3, numVisits=2, meanQ=-3.505000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.373676 0.201993 0.486358 0.787056 0.0739875 0.149586 0.777505 0.986465 0.702033 0.693207 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 19
Initial state: 0 0.0332582 0.381885 0.66747 0.559603 0.0749082 0.256046 0.850819 0.316864 0.443453 0.931472 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 75461 episodes
GETTING ACTION FROM:
action 1, numVisits=75452, meanQ=7.693156, numObservations: 9
action 5, numVisits=4, meanQ=2.255025, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.0332582 0.381885 0.66747 0.559603 0.0749082 0.256046 0.850819 0.316864 0.443453 0.931472 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=16037, meanQ=8.678203, numObservations: 9
action 3, numVisits=14, meanQ=3.767150, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 21144 episodes
GETTING ACTION FROM:
action 5, numVisits=31836, meanQ=8.517643, numObservations: 9
action 3, numVisits=5276, meanQ=6.869254, numObservations: 9
action 0, numVisits=4, meanQ=-3.980000, numObservations: 3
action 4, numVisits=64, meanQ=-4.768213, numObservations: 9
action 1, numVisits=2, meanQ=-7.258800, numObservations: 1
action -1, numVisits=16, meanQ=-67.079815, numObservations: 14
action 2, numVisits=2, meanQ=-537.751956, numObservations: 1
action: 5
Next state: 0 0.0332582 0.381885 0.66747 0.559603 0.0749082 0.256046 0.850819 0.316864 0.443453 0.931472 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=104, meanQ=12.178496, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 67864 episodes
GETTING ACTION FROM:
action 3, numVisits=67968, meanQ=13.114364, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.0332582 0.381885 0.66747 0.559603 0.0749082 0.256046 0.850819 0.316864 0.443453 0.931472 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 5, numVisits=1, meanQ=24.000000, numObservations: 1
action 4, numVisits=113, meanQ=1.645923, numObservations: 9
action 3, numVisits=1, meanQ=-10.258082, numObservations: 1
action 2, numVisits=1, meanQ=-10.438698, numObservations: 1
action -1, numVisits=13, meanQ=-42.282770, numObservations: 11
action 0, numVisits=2, meanQ=-268.321423, numObservations: 1
action 1, numVisits=1, meanQ=-539.069954, numObservations: 1
Sampled 87608 episodes
GETTING ACTION FROM:
action 5, numVisits=104, meanQ=11.929765, numObservations: 8
action 4, numVisits=87618, meanQ=10.562003, numObservations: 9
action 3, numVisits=1, meanQ=-10.258082, numObservations: 1
action 2, numVisits=1, meanQ=-10.438698, numObservations: 1
action -1, numVisits=13, meanQ=-42.282770, numObservations: 11
action 0, numVisits=2, meanQ=-268.321423, numObservations: 1
action 1, numVisits=1, meanQ=-539.069954, numObservations: 1
action: 5
Next state: 0 0.0332582 0.381885 0.66747 0.559603 0.0749082 0.256046 0.850819 0.316864 0.443453 0.931472 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 3, numVisits=1, meanQ=-362.933796, numObservations: 1
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 70329 episodes
GETTING ACTION FROM:
action 4, numVisits=70322, meanQ=14.529442, numObservations: 9
action -1, numVisits=2, meanQ=-2.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.000000, numObservations: 2
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-362.933796, numObservations: 1
action: 4
Next state: 2 0.0332582 0.381885 0.66747 0.559603 0.0749082 0.256046 0.850819 0.316864 0.443453 0.931472 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -26.3282
Run # 20
Initial state: 0 0.756322 0.516602 0.804649 0.893324 0.118508 0.461065 0.686644 0.580131 0.258375 0.78234 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 75955 episodes
GETTING ACTION FROM:
action 5, numVisits=75942, meanQ=7.879511, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 4, numVisits=2, meanQ=-4.000000, numObservations: 2
action 1, numVisits=2, meanQ=-7.500000, numObservations: 2
action 3, numVisits=2, meanQ=-7.500000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.756322 0.516602 0.804649 0.893324 0.118508 0.461065 0.686644 0.580131 0.258375 0.78234 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=16409, meanQ=9.615730, numObservations: 9
action 3, numVisits=8, meanQ=0.752525, numObservations: 5
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 19085 episodes
GETTING ACTION FROM:
action 2, numVisits=35488, meanQ=9.327810, numObservations: 9
action 3, numVisits=8, meanQ=0.752525, numObservations: 5
action -1, numVisits=5, meanQ=-3.393383, numObservations: 4
action 0, numVisits=4, meanQ=-4.227500, numObservations: 3
action 1, numVisits=2, meanQ=-8.313712, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.756322 0.516602 0.804649 0.893324 0.118508 0.461065 0.686644 0.580131 0.258375 0.78234 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 21
Initial state: 0 0.930804 0.214898 0.629214 0.612743 0.469132 0.559149 0.521977 0.801008 0.183767 0.809058 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 73112 episodes
GETTING ACTION FROM:
action 4, numVisits=73106, meanQ=7.828239, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 0 0.930804 0.214898 0.629214 0.612743 0.469132 0.559149 0.521977 0.801008 0.183767 0.809058 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=15642, meanQ=9.356858, numObservations: 9
action 3, numVisits=8, meanQ=2.996288, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 20086 episodes
GETTING ACTION FROM:
action 1, numVisits=35705, meanQ=8.833364, numObservations: 9
action 3, numVisits=8, meanQ=2.996288, numObservations: 4
action 0, numVisits=8, meanQ=-2.618750, numObservations: 7
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=2, meanQ=-7.005000, numObservations: 2
action 2, numVisits=2, meanQ=-7.514873, numObservations: 2
action -1, numVisits=15, meanQ=-71.230359, numObservations: 14
action: 1
Next state: 2 0.930804 0.214898 0.629214 0.612743 0.469132 0.559149 0.521977 0.801008 0.183767 0.809058 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 22
Initial state: 0 0.649452 0.59782 0.88801 0.282318 0.637731 0.0650639 0.81773 0.971669 0.969546 0.932248 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 75248 episodes
GETTING ACTION FROM:
action 5, numVisits=75238, meanQ=7.859652, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.649452 0.59782 0.88801 0.282318 0.637731 0.0650639 0.81773 0.971669 0.969546 0.932248 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 23
Initial state: 0 0.580437 0.355257 0.83232 0.505357 0.55322 0.70102 0.563465 0.706893 0.156699 0.598156 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 75930 episodes
GETTING ACTION FROM:
action 5, numVisits=75921, meanQ=7.686169, numObservations: 9
action 3, numVisits=4, meanQ=-0.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.580437 0.355257 0.83232 0.505357 0.55322 0.70102 0.563465 0.706893 0.156699 0.598156 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=16205, meanQ=8.990955, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 17508 episodes
GETTING ACTION FROM:
action 1, numVisits=33699, meanQ=9.033178, numObservations: 9
action 2, numVisits=4, meanQ=-0.252500, numObservations: 4
action 0, numVisits=10, meanQ=-1.208000, numObservations: 10
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=2, meanQ=-534.833710, numObservations: 1
action: 1
Next state: 0 0.580437 0.355257 0.83232 0.505357 0.55322 0.70102 0.563465 0.706893 0.156699 0.598156 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=814, meanQ=10.495465, numObservations: 9
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action -1, numVisits=3, meanQ=-1.673300, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 16398 episodes
GETTING ACTION FROM:
action 3, numVisits=17183, meanQ=7.401681, numObservations: 9
action 0, numVisits=19, meanQ=-1.583158, numObservations: 16
action -1, numVisits=16, meanQ=-1.753119, numObservations: 15
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.580437 0.355257 0.83232 0.505357 0.55322 0.70102 0.563465 0.706893 0.156699 0.598156 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 24
Initial state: 0 0.946966 0.798017 0.606542 0.61397 0.734903 0.30123 0.125153 0.333437 0.733666 0.693387 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 72258 episodes
GETTING ACTION FROM:
action 5, numVisits=72245, meanQ=7.948008, numObservations: 9
action 1, numVisits=8, meanQ=1.875025, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.946966 0.798017 0.606542 0.61397 0.734903 0.30123 0.125153 0.333437 0.733666 0.693387 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 25
Initial state: 0 0.856275 0.734767 0.310068 0.639291 0.634708 0.586897 0.356228 0.148077 0.419645 0.725063 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48594 episodes
GETTING ACTION FROM:
action -1, numVisits=48576, meanQ=12.367209, numObservations: 243
action 0, numVisits=11, meanQ=-2.090000, numObservations: 10
action 1, numVisits=2, meanQ=-7.500000, numObservations: 2
action 2, numVisits=2, meanQ=-7.500000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.856275 0.734767 0.310068 0.639291 0.634708 0.586897 0.356228 0.148077 0.419645 0.725063 w: 1
Observation: 0 3 0 1 0 1 0 1 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=207, meanQ=10.800718, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 57003 episodes
GETTING ACTION FROM:
action 2, numVisits=57210, meanQ=9.525941, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.856275 0.734767 0.310068 0.639291 0.634708 0.586897 0.356228 0.148077 0.419645 0.725063 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=3603, meanQ=12.746852, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 46158 episodes
GETTING ACTION FROM:
action 5, numVisits=4092, meanQ=12.606342, numObservations: 9
action 1, numVisits=45585, meanQ=11.096074, numObservations: 9
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=75, meanQ=-12.633497, numObservations: 35
action 0, numVisits=12, meanQ=-87.891915, numObservations: 11
action: 5
Next state: 0 0.856275 0.734767 0.310068 0.639291 0.634708 0.586897 0.356228 0.148077 0.419645 0.725063 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=914, meanQ=14.571482, numObservations: 9
action 5, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 40057 episodes
GETTING ACTION FROM:
action 1, numVisits=40969, meanQ=14.007977, numObservations: 9
action 5, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.856275 0.734767 0.310068 0.639291 0.634708 0.586897 0.356228 0.148077 0.419645 0.725063 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 13.4068
Run # 26
Initial state: 0 0.750437 0.869698 0.842447 0.443938 0.743455 0.738219 0.170926 0.882635 0.636076 0.580615 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48484 episodes
GETTING ACTION FROM:
action 0, numVisits=48465, meanQ=14.677476, numObservations: 243
action -1, numVisits=11, meanQ=-1.371800, numObservations: 9
action 1, numVisits=3, meanQ=-4.000000, numObservations: 3
action 5, numVisits=2, meanQ=-7.500000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.750437 0.869698 0.842447 0.443938 0.743455 0.738219 0.170926 0.882635 0.636076 0.580615 w: 1
Observation: 0 0 3 0 1 0 1 0 3 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=250, meanQ=19.792949, numObservations: 9
action 4, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 110007 episodes
GETTING ACTION FROM:
action 5, numVisits=110257, meanQ=21.968473, numObservations: 9
action 4, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.750437 0.869698 0.842447 0.443938 0.743455 0.738219 0.170926 0.882635 0.636076 0.580615 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 27
Initial state: 0 0.571139 0.540746 0.567813 0.553413 0.102549 0.221086 0.384643 0.305844 0.10891 0.282944 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 75866 episodes
GETTING ACTION FROM:
action 4, numVisits=75860, meanQ=7.722317, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 0 0.571139 0.540746 0.567813 0.553413 0.102549 0.221086 0.384643 0.305844 0.10891 0.282944 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=16153, meanQ=9.080905, numObservations: 9
action 1, numVisits=14, meanQ=6.292150, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 18731 episodes
GETTING ACTION FROM:
action 5, numVisits=34815, meanQ=8.546313, numObservations: 9
action 1, numVisits=33, meanQ=5.620219, numObservations: 9
action 0, numVisits=41, meanQ=-0.094810, numObservations: 31
action -1, numVisits=9, meanQ=-2.316273, numObservations: 8
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=2, meanQ=-5.968215, numObservations: 2
action 3, numVisits=2, meanQ=-6.444381, numObservations: 2
action: 5
Next state: 0 0.571139 0.540746 0.567813 0.553413 0.102549 0.221086 0.384643 0.305844 0.10891 0.282944 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=6051, meanQ=12.347324, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 17205 episodes
GETTING ACTION FROM:
action 3, numVisits=23256, meanQ=13.278814, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.571139 0.540746 0.567813 0.553413 0.102549 0.221086 0.384643 0.305844 0.10891 0.282944 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=2654, meanQ=16.890745, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 19316 episodes
GETTING ACTION FROM:
action 1, numVisits=21968, meanQ=14.998022, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.571139 0.540746 0.567813 0.553413 0.102549 0.221086 0.384643 0.305844 0.10891 0.282944 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -22.5537
Run # 28
Initial state: 0 0.897597 0.535619 0.61721 0.873342 0.966928 0.528072 0.695837 0.616261 0.402365 0.163076 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 75656 episodes
GETTING ACTION FROM:
action 3, numVisits=75635, meanQ=7.777733, numObservations: 9
action 1, numVisits=16, meanQ=4.760650, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.897597 0.535619 0.61721 0.873342 0.966928 0.528072 0.695837 0.616261 0.402365 0.163076 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 29
Initial state: 0 0.602424 0.637619 0.503215 0.158235 0.914992 0.122997 0.143523 0.288807 0.393246 0.976025 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 76217 episodes
GETTING ACTION FROM:
action 1, numVisits=76207, meanQ=7.799800, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.602424 0.637619 0.503215 0.158235 0.914992 0.122997 0.143523 0.288807 0.393246 0.976025 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 30
Initial state: 0 0.354489 0.487276 0.648418 0.594397 0.352527 0.456025 0.651018 0.790456 0.354152 0.575333 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 75012 episodes
GETTING ACTION FROM:
action 4, numVisits=75006, meanQ=7.713207, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.354489 0.487276 0.648418 0.594397 0.352527 0.456025 0.651018 0.790456 0.354152 0.575333 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 31
Initial state: 0 0.136849 0.338579 0.167535 0.175972 0.48055 0.0465383 0.621938 0.66384 0.738721 0.396938 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 74239 episodes
GETTING ACTION FROM:
action 4, numVisits=74230, meanQ=7.500515, numObservations: 9
action 3, numVisits=4, meanQ=0.505025, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.136849 0.338579 0.167535 0.175972 0.48055 0.0465383 0.621938 0.66384 0.738721 0.396938 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 32
Initial state: 0 0.632437 0.658043 0.457853 0.516759 0.470718 0.853476 0.15144 0.198745 0.526669 0.541894 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 74942 episodes
GETTING ACTION FROM:
action 5, numVisits=74923, meanQ=7.521347, numObservations: 9
action 3, numVisits=14, meanQ=4.215021, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.632437 0.658043 0.457853 0.516759 0.470718 0.853476 0.15144 0.198745 0.526669 0.541894 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 33
Initial state: 0 0.418195 0.240742 0.540426 0.54384 0.501816 0.468731 0.88471 0.247753 0.00622982 0.930177 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 73323 episodes
GETTING ACTION FROM:
action 2, numVisits=73031, meanQ=7.537308, numObservations: 9
action 3, numVisits=269, meanQ=7.134118, numObservations: 9
action 4, numVisits=19, meanQ=5.897384, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.418195 0.240742 0.540426 0.54384 0.501816 0.468731 0.88471 0.247753 0.00622982 0.930177 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 34
Initial state: 0 0.216375 0.0515523 0.423915 0.510786 0.606884 0.582875 0.954401 0.545064 0.346955 0.129931 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 75724 episodes
GETTING ACTION FROM:
action 1, numVisits=75712, meanQ=7.743398, numObservations: 9
action 3, numVisits=5, meanQ=-1.002000, numObservations: 5
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.216375 0.0515523 0.423915 0.510786 0.606884 0.582875 0.954401 0.545064 0.346955 0.129931 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=16203, meanQ=9.762367, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 19467 episodes
GETTING ACTION FROM:
action 3, numVisits=35629, meanQ=9.132725, numObservations: 9
action 4, numVisits=11, meanQ=2.841115, numObservations: 6
action -1, numVisits=22, meanQ=-0.515000, numObservations: 20
action 0, numVisits=9, meanQ=-1.450000, numObservations: 9
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action 5, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 3
Next state: 1 0.216375 0.0515523 0.423915 0.510786 0.606884 0.582875 0.954401 0.545064 0.346955 0.129931 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 35
Initial state: 0 0.710006 0.858139 0.829907 0.857283 0.542463 0.609433 0.646003 0.997986 0.820072 0.964099 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 76102 episodes
GETTING ACTION FROM:
action 4, numVisits=76096, meanQ=7.841028, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.710006 0.858139 0.829907 0.857283 0.542463 0.609433 0.646003 0.997986 0.820072 0.964099 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 36
Initial state: 0 0.471502 0.8436 0.516594 0.718297 0.41653 0.442684 0.94311 0.786487 0.532912 0.612006 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48337 episodes
GETTING ACTION FROM:
action 0, numVisits=48292, meanQ=14.365540, numObservations: 243
action -1, numVisits=36, meanQ=-1.561100, numObservations: 31
action 2, numVisits=3, meanQ=-4.000000, numObservations: 3
action 3, numVisits=2, meanQ=-7.500000, numObservations: 2
action 5, numVisits=2, meanQ=-7.500000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.471502 0.8436 0.516594 0.718297 0.41653 0.442684 0.94311 0.786487 0.532912 0.612006 w: 1
Observation: 0 0 3 0 3 0 1 0 3 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=118, meanQ=17.502462, numObservations: 9
action 2, numVisits=5, meanQ=11.598000, numObservations: 4
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 87038 episodes
GETTING ACTION FROM:
action 4, numVisits=87156, meanQ=17.460839, numObservations: 9
action 2, numVisits=5, meanQ=11.598000, numObservations: 4
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.471502 0.8436 0.516594 0.718297 0.41653 0.442684 0.94311 0.786487 0.532912 0.612006 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 37
Initial state: 0 0.127881 0.141188 0.194716 0.996471 0.101551 0.934248 0.0225731 0.685122 0.536944 0.690782 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 73723 episodes
GETTING ACTION FROM:
action 5, numVisits=73715, meanQ=7.858090, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.127881 0.141188 0.194716 0.996471 0.101551 0.934248 0.0225731 0.685122 0.536944 0.690782 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 38
Initial state: 0 0.706886 0.0500301 0.219545 0.835495 0.0843593 0.498537 0.523517 0.242055 0.576141 0.651068 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 75445 episodes
GETTING ACTION FROM:
action 2, numVisits=75432, meanQ=7.856304, numObservations: 9
action 1, numVisits=8, meanQ=2.873775, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.706886 0.0500301 0.219545 0.835495 0.0843593 0.498537 0.523517 0.242055 0.576141 0.651068 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=7076, meanQ=9.495878, numObservations: 9
action 4, numVisits=7, meanQ=2.140014, numObservations: 5
action 5, numVisits=4, meanQ=1.247525, numObservations: 2
action 3, numVisits=5, meanQ=0.000020, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 22556 episodes
GETTING ACTION FROM:
action 5, numVisits=22545, meanQ=11.354169, numObservations: 9
action 1, numVisits=7079, meanQ=9.497361, numObservations: 9
action 4, numVisits=10, meanQ=1.649765, numObservations: 6
action 3, numVisits=5, meanQ=0.000020, numObservations: 4
action -1, numVisits=6, meanQ=-1.010000, numObservations: 6
action 0, numVisits=5, meanQ=-1.406000, numObservations: 5
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 1 0.706886 0.0500301 0.219545 0.835495 0.0843593 0.498537 0.523517 0.242055 0.576141 0.651068 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 39
Initial state: 0 0.412228 0.422108 0.0614101 0.767945 0.312423 0.910558 0.6967 0.574985 0.305184 0.32471 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 75345 episodes
GETTING ACTION FROM:
action 4, numVisits=75339, meanQ=7.603249, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.412228 0.422108 0.0614101 0.767945 0.312423 0.910558 0.6967 0.574985 0.305184 0.32471 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 40
Initial state: 0 0.286175 0.942619 0.721468 0.237555 0.979008 0.0257747 0.600618 0.597925 0.479472 0.74465 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 74931 episodes
GETTING ACTION FROM:
action 2, numVisits=74920, meanQ=7.691708, numObservations: 9
action 5, numVisits=3, meanQ=3.000000, numObservations: 3
action 1, numVisits=4, meanQ=1.497500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.286175 0.942619 0.721468 0.237555 0.979008 0.0257747 0.600618 0.597925 0.479472 0.74465 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 41
Initial state: 0 0.96475 0.443285 0.474253 0.0594221 0.637804 0.531156 0.666422 0.566691 0.394919 0.0998937 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 73717 episodes
GETTING ACTION FROM:
action 3, numVisits=73702, meanQ=7.873596, numObservations: 9
action 2, numVisits=7, meanQ=1.141429, numObservations: 5
action 5, numVisits=4, meanQ=-0.500000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.96475 0.443285 0.474253 0.0594221 0.637804 0.531156 0.666422 0.566691 0.394919 0.0998937 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=1995, meanQ=9.560159, numObservations: 9
action 2, numVisits=4, meanQ=1.745000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 24745 episodes
GETTING ACTION FROM:
action 5, numVisits=26576, meanQ=6.550908, numObservations: 9
action 2, numVisits=5, meanQ=-1.416923, numObservations: 3
action -1, numVisits=127, meanQ=-2.289147, numObservations: 87
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=38, meanQ=-28.999045, numObservations: 33
action: 5
Next state: 0 0.96475 0.443285 0.474253 0.0594221 0.637804 0.531156 0.666422 0.566691 0.394919 0.0998937 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=2359, meanQ=10.319132, numObservations: 9
action 3, numVisits=3, meanQ=5.330033, numObservations: 2
action 0, numVisits=30, meanQ=-1.322857, numObservations: 24
action -1, numVisits=12, meanQ=-2.000000, numObservations: 11
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=58, meanQ=-5.690915, numObservations: 9
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 20236 episodes
GETTING ACTION FROM:
action 4, numVisits=22556, meanQ=8.195605, numObservations: 9
action 3, numVisits=4, meanQ=1.247525, numObservations: 3
action -1, numVisits=15, meanQ=-2.000000, numObservations: 13
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=58, meanQ=-5.690915, numObservations: 9
action 0, numVisits=65, meanQ=-9.080276, numObservations: 41
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.96475 0.443285 0.474253 0.0594221 0.637804 0.531156 0.666422 0.566691 0.394919 0.0998937 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 42
Initial state: 0 0.466624 0.283095 0.971799 0.118681 0.693889 0.699632 0.672266 0.340524 0.892492 0.0501174 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 74151 episodes
GETTING ACTION FROM:
action 2, numVisits=74131, meanQ=7.809206, numObservations: 9
action 1, numVisits=13, meanQ=0.846154, numObservations: 7
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 2 0.466624 0.283095 0.971799 0.118681 0.693889 0.699632 0.672266 0.340524 0.892492 0.0501174 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 43
Initial state: 0 0.675567 0.547233 0.747981 0.32808 0.171427 0.784349 0.32773 0.172666 0.88274 0.490924 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 73912 episodes
GETTING ACTION FROM:
action 2, numVisits=73906, meanQ=7.856590, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.675567 0.547233 0.747981 0.32808 0.171427 0.784349 0.32773 0.172666 0.88274 0.490924 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 44
Initial state: 0 0.583338 0.789955 0.696348 0.607861 0.759392 0.0510113 0.400045 0.129578 0.418763 0.952919 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 75385 episodes
GETTING ACTION FROM:
action 2, numVisits=75374, meanQ=7.820362, numObservations: 9
action 5, numVisits=6, meanQ=4.496667, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.583338 0.789955 0.696348 0.607861 0.759392 0.0510113 0.400045 0.129578 0.418763 0.952919 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1327, meanQ=18.869440, numObservations: 9
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 67190 episodes
GETTING ACTION FROM:
action 2, numVisits=1348, meanQ=18.932750, numObservations: 9
action 3, numVisits=67167, meanQ=13.515723, numObservations: 9
action -1, numVisits=3, meanQ=-1.670000, numObservations: 3
action 0, numVisits=3, meanQ=-1.670000, numObservations: 3
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.583338 0.789955 0.696348 0.607861 0.759392 0.0510113 0.400045 0.129578 0.418763 0.952919 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 45
Initial state: 0 0.462831 0.144222 0.609728 0.678206 0.426864 0.358526 0.460379 0.635356 0.84774 0.712867 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 76432 episodes
GETTING ACTION FROM:
action 5, numVisits=76426, meanQ=7.851458, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 1 0.462831 0.144222 0.609728 0.678206 0.426864 0.358526 0.460379 0.635356 0.84774 0.712867 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 46
Initial state: 0 0.756784 0.413082 0.460666 0.156831 0.627204 0.644666 0.218095 0.439396 0.685917 0.857194 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 73426 episodes
GETTING ACTION FROM:
action 4, numVisits=73420, meanQ=7.750177, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.756784 0.413082 0.460666 0.156831 0.627204 0.644666 0.218095 0.439396 0.685917 0.857194 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=15781, meanQ=9.447672, numObservations: 9
action 5, numVisits=8, meanQ=3.592500, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 18319 episodes
GETTING ACTION FROM:
action 1, numVisits=33923, meanQ=9.077255, numObservations: 9
action 3, numVisits=123, meanQ=-1.369796, numObservations: 9
action -1, numVisits=7, meanQ=-2.629759, numObservations: 6
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=36, meanQ=-20.879478, numObservations: 9
action 0, numVisits=22, meanQ=-48.162028, numObservations: 19
action: 1
Next state: 2 0.756784 0.413082 0.460666 0.156831 0.627204 0.644666 0.218095 0.439396 0.685917 0.857194 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 47
Initial state: 0 0.488927 0.143404 0.29021 0.090494 0.0668185 0.446296 0.0354076 0.0291197 0.66857 0.664815 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 75095 episodes
GETTING ACTION FROM:
action 2, numVisits=75069, meanQ=7.783350, numObservations: 9
action 1, numVisits=13, meanQ=-0.374592, numObservations: 6
action -1, numVisits=5, meanQ=-1.010000, numObservations: 5
action 0, numVisits=5, meanQ=-1.010000, numObservations: 5
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.488927 0.143404 0.29021 0.090494 0.0668185 0.446296 0.0354076 0.0291197 0.66857 0.664815 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=16080, meanQ=9.155104, numObservations: 9
action 3, numVisits=17, meanQ=-0.528806, numObservations: 7
action -1, numVisits=5, meanQ=-1.010000, numObservations: 5
action 0, numVisits=5, meanQ=-1.010000, numObservations: 5
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 4, numVisits=2, meanQ=-4.994950, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 1
Sampled 18126 episodes
GETTING ACTION FROM:
action 5, numVisits=34192, meanQ=8.825439, numObservations: 9
action 3, numVisits=17, meanQ=-0.528806, numObservations: 7
action 0, numVisits=13, meanQ=-1.086154, numObservations: 12
action -1, numVisits=11, meanQ=-1.280900, numObservations: 10
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 4, numVisits=2, meanQ=-4.994950, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 1
action: 5
Next state: 1 0.488927 0.143404 0.29021 0.090494 0.0668185 0.446296 0.0354076 0.0291197 0.66857 0.664815 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 48
Initial state: 0 0.584929 0.660504 0.632919 0.919293 0.138321 0.0554425 0.491656 0.112806 0.683525 0.726979 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 74258 episodes
GETTING ACTION FROM:
action 2, numVisits=74252, meanQ=8.019390, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.584929 0.660504 0.632919 0.919293 0.138321 0.0554425 0.491656 0.112806 0.683525 0.726979 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 49
Initial state: 0 0.641154 0.682922 0.384772 0.413603 0.33104 0.449052 0.71673 0.437016 0.953262 0.447162 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 76142 episodes
GETTING ACTION FROM:
action 2, numVisits=76129, meanQ=8.013131, numObservations: 9
action 4, numVisits=8, meanQ=3.388750, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 2 0.641154 0.682922 0.384772 0.413603 0.33104 0.449052 0.71673 0.437016 0.953262 0.447162 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 50
Initial state: 0 0.937257 0.123157 0.897075 0.990223 0.533838 0.602925 0.911353 0.835584 0.345952 0.341192 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 76011 episodes
GETTING ACTION FROM:
action 1, numVisits=76001, meanQ=7.743066, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.937257 0.123157 0.897075 0.990223 0.533838 0.602925 0.911353 0.835584 0.345952 0.341192 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
[32m ProblemEnvironment.hpp 351: Done.[39m
