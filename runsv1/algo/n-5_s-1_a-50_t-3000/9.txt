Run # 1
Initial state: 0 0.627463 0.814678 0.759195 0.455888 0.488394 0.92815 0.666176 0.0684423 0.619426 0.600279 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 68115 episodes
GETTING ACTION FROM:
action 4, numVisits=68109, meanQ=9.323471, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.627463 0.814678 0.759195 0.455888 0.488394 0.92815 0.666176 0.0684423 0.619426 0.600279 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 2
Initial state: 0 0.143435 0.0178824 0.338379 0.259446 0.877243 0.267955 0.128588 0.68681 0.692319 0.650859 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 77004 episodes
GETTING ACTION FROM:
action 2, numVisits=76998, meanQ=8.881048, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.143435 0.0178824 0.338379 0.259446 0.877243 0.267955 0.128588 0.68681 0.692319 0.650859 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 3
Initial state: 0 0.939104 0.274979 0.616332 0.527195 0.925267 0.00673704 0.506435 0.996905 0.909709 0.371814 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 76959 episodes
GETTING ACTION FROM:
action 2, numVisits=76945, meanQ=8.792288, numObservations: 9
action 3, numVisits=7, meanQ=5.000000, numObservations: 5
action 4, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.939104 0.274979 0.616332 0.527195 0.925267 0.00673704 0.506435 0.996905 0.909709 0.371814 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 4
Initial state: 0 0.355076 0.13234 0.0440502 0.464142 0.604257 0.604109 0.800713 0.0528574 0.882511 0.737407 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 75717 episodes
GETTING ACTION FROM:
action 4, numVisits=75705, meanQ=8.869404, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 2, numVisits=2, meanQ=-4.000000, numObservations: 2
action 1, numVisits=2, meanQ=-7.500000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.355076 0.13234 0.0440502 0.464142 0.604257 0.604109 0.800713 0.0528574 0.882511 0.737407 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 5
Initial state: 0 0.0169771 0.574329 0.756428 0.0807031 0.150436 0.0533821 0.939863 0.727061 0.549748 0.590628 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 76805 episodes
GETTING ACTION FROM:
action 2, numVisits=76799, meanQ=8.968748, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.0169771 0.574329 0.756428 0.0807031 0.150436 0.0533821 0.939863 0.727061 0.549748 0.590628 w: 1
Observation: 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 6
Initial state: 0 0.611731 0.631142 0.30808 0.507587 0.953528 0.3525 0.918338 0.875053 0.150828 0.522141 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 76728 episodes
GETTING ACTION FROM:
action 3, numVisits=76710, meanQ=8.970953, numObservations: 9
action 2, numVisits=13, meanQ=2.652308, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.611731 0.631142 0.30808 0.507587 0.953528 0.3525 0.918338 0.875053 0.150828 0.522141 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 7
Initial state: 0 0.984002 0.788931 0.100478 0.611767 0.573618 0.646092 0.488549 0.140886 0.947341 0.195323 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 75750 episodes
GETTING ACTION FROM:
action 1, numVisits=75737, meanQ=8.557925, numObservations: 9
action 2, numVisits=5, meanQ=3.000000, numObservations: 4
action 3, numVisits=4, meanQ=0.277500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.984002 0.788931 0.100478 0.611767 0.573618 0.646092 0.488549 0.140886 0.947341 0.195323 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 8
Initial state: 0 0.314998 0.445223 0.893296 0.77485 0.546871 0.568572 0.91386 0.24155 0.584122 0.690571 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 77186 episodes
GETTING ACTION FROM:
action 2, numVisits=77172, meanQ=8.774468, numObservations: 9
action 4, numVisits=9, meanQ=3.886678, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.314998 0.445223 0.893296 0.77485 0.546871 0.568572 0.91386 0.24155 0.584122 0.690571 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 9
Initial state: 0 0.770603 0.569853 0.663337 0.598672 0.95371 0.483369 0.207172 0.251956 0.387802 0.579444 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 76027 episodes
GETTING ACTION FROM:
action 1, numVisits=76021, meanQ=8.966153, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.770603 0.569853 0.663337 0.598672 0.95371 0.483369 0.207172 0.251956 0.387802 0.579444 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 10
Initial state: 0 0.192126 0.369449 0.618539 0.517395 0.931525 0.71228 0.0753709 0.368778 0.763048 0.254956 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 76916 episodes
GETTING ACTION FROM:
action 1, numVisits=76910, meanQ=8.911075, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.192126 0.369449 0.618539 0.517395 0.931525 0.71228 0.0753709 0.368778 0.763048 0.254956 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 11
Initial state: 0 0.109727 0.744482 0.733682 0.490372 0.394672 0.10586 0.233826 0.212973 0.0250059 0.203353 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 73762 episodes
GETTING ACTION FROM:
action 5, numVisits=73746, meanQ=8.982748, numObservations: 9
action 3, numVisits=7, meanQ=5.585714, numObservations: 5
action 1, numVisits=5, meanQ=3.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.109727 0.744482 0.733682 0.490372 0.394672 0.10586 0.233826 0.212973 0.0250059 0.203353 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=14646, meanQ=10.038631, numObservations: 9
action 5, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 19652 episodes
GETTING ACTION FROM:
action 2, numVisits=34281, meanQ=10.205326, numObservations: 9
action 5, numVisits=4, meanQ=9.435000, numObservations: 3
action -1, numVisits=8, meanQ=-1.010000, numObservations: 8
action 0, numVisits=8, meanQ=-1.010000, numObservations: 8
action 3, numVisits=2, meanQ=-4.989796, numObservations: 2
action 4, numVisits=2, meanQ=-5.899161, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.109727 0.744482 0.733682 0.490372 0.394672 0.10586 0.233826 0.212973 0.0250059 0.203353 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 12
Initial state: 0 0.718572 0.554802 0.0635646 0.850966 0.92406 0.710123 0.932865 0.700351 0.11049 0.249425 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 76710 episodes
GETTING ACTION FROM:
action 3, numVisits=76704, meanQ=8.869887, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.718572 0.554802 0.0635646 0.850966 0.92406 0.710123 0.932865 0.700351 0.11049 0.249425 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 13
Initial state: 0 0.999769 0.739708 0.568957 0.686119 0.651895 0.5723 0.758359 0.241633 0.616778 0.160977 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 77100 episodes
GETTING ACTION FROM:
action 3, numVisits=77094, meanQ=8.759419, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.999769 0.739708 0.568957 0.686119 0.651895 0.5723 0.758359 0.241633 0.616778 0.160977 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 14
Initial state: 0 0.208497 0.080845 0.82669 0.666322 0.375062 0.644929 0.544937 0.53241 0.954436 0.241622 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 77091 episodes
GETTING ACTION FROM:
action 4, numVisits=77081, meanQ=8.635942, numObservations: 9
action 2, numVisits=3, meanQ=3.000000, numObservations: 2
action 3, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 1 0.208497 0.080845 0.82669 0.666322 0.375062 0.644929 0.544937 0.53241 0.954436 0.241622 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 15
Initial state: 0 0.5228 0.203917 0.818039 0.853743 0.643634 0.805322 0.0254869 0.29538 0.696278 0.497671 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 76523 episodes
GETTING ACTION FROM:
action 2, numVisits=75921, meanQ=8.812293, numObservations: 9
action 1, numVisits=597, meanQ=8.450380, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.5228 0.203917 0.818039 0.853743 0.643634 0.805322 0.0254869 0.29538 0.696278 0.497671 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 16
Initial state: 0 0.532485 0.141943 0.234058 0.953341 0.295313 0.597945 0.630577 0.885073 0.651493 0.618215 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 76777 episodes
GETTING ACTION FROM:
action 1, numVisits=76763, meanQ=8.835730, numObservations: 9
action 4, numVisits=6, meanQ=4.166667, numObservations: 5
action 2, numVisits=4, meanQ=3.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.532485 0.141943 0.234058 0.953341 0.295313 0.597945 0.630577 0.885073 0.651493 0.618215 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=15433, meanQ=10.253015, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 19880 episodes
GETTING ACTION FROM:
action 5, numVisits=35295, meanQ=9.538137, numObservations: 9
action 4, numVisits=6, meanQ=2.416021, numObservations: 4
action -1, numVisits=9, meanQ=-1.010000, numObservations: 9
action 0, numVisits=7, meanQ=-1.292857, numObservations: 7
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.532485 0.141943 0.234058 0.953341 0.295313 0.597945 0.630577 0.885073 0.651493 0.618215 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 17
Initial state: 0 0.282109 0.170153 0.704848 0.549614 0.0362105 0.463755 0.921448 0.397754 0.289516 0.829112 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 76930 episodes
GETTING ACTION FROM:
action 2, numVisits=76895, meanQ=8.951308, numObservations: 9
action 1, numVisits=18, meanQ=5.334472, numObservations: 7
action 5, numVisits=7, meanQ=5.000000, numObservations: 6
action 4, numVisits=7, meanQ=2.857157, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.282109 0.170153 0.704848 0.549614 0.0362105 0.463755 0.921448 0.397754 0.289516 0.829112 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 18
Initial state: 0 0.679099 0.66202 0.129197 0.792262 0.649236 0.803313 0.157825 0.378195 0.0920631 0.426383 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 76899 episodes
GETTING ACTION FROM:
action 1, numVisits=76893, meanQ=9.008289, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.679099 0.66202 0.129197 0.792262 0.649236 0.803313 0.157825 0.378195 0.0920631 0.426383 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 19
Initial state: 0 0.991996 0.532411 0.235328 0.938718 0.318139 0.22844 0.650044 0.598867 0.585422 0.211156 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 74447 episodes
GETTING ACTION FROM:
action 4, numVisits=74441, meanQ=8.920394, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 1 0.991996 0.532411 0.235328 0.938718 0.318139 0.22844 0.650044 0.598867 0.585422 0.211156 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 20
Initial state: 0 0.63662 0.559272 0.442347 0.696563 0.11567 0.466878 0.378998 0.451812 0.178914 0.318446 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 76959 episodes
GETTING ACTION FROM:
action 2, numVisits=76953, meanQ=8.863622, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.63662 0.559272 0.442347 0.696563 0.11567 0.466878 0.378998 0.451812 0.178914 0.318446 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 21
Initial state: 0 0.268921 0.126166 0.671641 0.552851 0.130027 0.854777 0.908476 0.086677 0.950529 0.0520202 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 75960 episodes
GETTING ACTION FROM:
action 4, numVisits=75947, meanQ=8.809119, numObservations: 9
action 5, numVisits=8, meanQ=2.125000, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.268921 0.126166 0.671641 0.552851 0.130027 0.854777 0.908476 0.086677 0.950529 0.0520202 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 22
Initial state: 0 0.948199 0.381289 0.733321 0.507161 0.266146 0.409349 0.0151953 0.961496 0.428243 0.140353 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 74586 episodes
GETTING ACTION FROM:
action 5, numVisits=74575, meanQ=8.698944, numObservations: 9
action 1, numVisits=3, meanQ=3.000000, numObservations: 3
action 3, numVisits=4, meanQ=2.997525, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.948199 0.381289 0.733321 0.507161 0.266146 0.409349 0.0151953 0.961496 0.428243 0.140353 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=14952, meanQ=9.945485, numObservations: 9
action 1, numVisits=19, meanQ=2.682642, numObservations: 9
action 4, numVisits=5, meanQ=1.598020, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 18875 episodes
GETTING ACTION FROM:
action 3, numVisits=33812, meanQ=9.577701, numObservations: 9
action 1, numVisits=19, meanQ=2.682642, numObservations: 9
action 4, numVisits=5, meanQ=1.598020, numObservations: 4
action 0, numVisits=9, meanQ=-1.010000, numObservations: 9
action -1, numVisits=8, meanQ=-1.133750, numObservations: 8
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.948199 0.381289 0.733321 0.507161 0.266146 0.409349 0.0151953 0.961496 0.428243 0.140353 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=6095, meanQ=11.995401, numObservations: 9
action 0, numVisits=6, meanQ=-1.671650, numObservations: 5
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=4, meanQ=-3.980000, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 13461 episodes
GETTING ACTION FROM:
action 1, numVisits=19164, meanQ=11.263522, numObservations: 9
action 4, numVisits=393, meanQ=10.142502, numObservations: 9
action 0, numVisits=6, meanQ=-1.671650, numObservations: 5
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=4, meanQ=-3.980000, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.948199 0.381289 0.733321 0.507161 0.266146 0.409349 0.0151953 0.961496 0.428243 0.140353 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=326, meanQ=18.263817, numObservations: 9
action 4, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 48803 episodes
GETTING ACTION FROM:
action 2, numVisits=49126, meanQ=15.505785, numObservations: 9
action 4, numVisits=3, meanQ=1.514296, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.948199 0.381289 0.733321 0.507161 0.266146 0.409349 0.0151953 0.961496 0.428243 0.140353 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 2, numVisits=696, meanQ=20.846521, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.292036, numObservations: 1
action 1, numVisits=1, meanQ=-10.303120, numObservations: 1
action 3, numVisits=1, meanQ=-11.193958, numObservations: 1
action 5, numVisits=1, meanQ=-1067.178593, numObservations: 1
Sampled 53394 episodes
GETTING ACTION FROM:
action 2, numVisits=785, meanQ=20.732570, numObservations: 9
action 0, numVisits=53225, meanQ=-1.539364, numObservations: 211
action -1, numVisits=82, meanQ=-5.215990, numObservations: 31
action 4, numVisits=1, meanQ=-10.292036, numObservations: 1
action 1, numVisits=1, meanQ=-10.303120, numObservations: 1
action 3, numVisits=1, meanQ=-11.193958, numObservations: 1
action 5, numVisits=1, meanQ=-1067.178593, numObservations: 1
action: 2
Next state: 1 0.948199 0.381289 0.733321 0.507161 0.266146 0.409349 0.0151953 0.961496 0.428243 0.140353 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.29271
Run # 23
Initial state: 0 0.341713 0.780718 0.190307 0.287634 0.558999 0.657054 0.314044 0.0681755 0.00938793 0.81288 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 75525 episodes
GETTING ACTION FROM:
action 4, numVisits=75519, meanQ=8.833402, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 0 0.341713 0.780718 0.190307 0.287634 0.558999 0.657054 0.314044 0.0681755 0.00938793 0.81288 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=1359, meanQ=10.597806, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 57066 episodes
GETTING ACTION FROM:
action 3, numVisits=58315, meanQ=5.000756, numObservations: 9
action 2, numVisits=11, meanQ=-0.589815, numObservations: 5
action -1, numVisits=61, meanQ=-1.944139, numObservations: 43
action 0, numVisits=42, meanQ=-2.023571, numObservations: 33
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=2, meanQ=-5.317206, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.341713 0.780718 0.190307 0.287634 0.558999 0.657054 0.314044 0.0681755 0.00938793 0.81288 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 24
Initial state: 0 0.37045 0.563286 0.268014 0.306784 0.974745 0.299414 0.707566 0.507504 0.250624 0.609362 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 74153 episodes
GETTING ACTION FROM:
action 5, numVisits=74147, meanQ=8.821848, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.37045 0.563286 0.268014 0.306784 0.974745 0.299414 0.707566 0.507504 0.250624 0.609362 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=3416, meanQ=9.913877, numObservations: 9
action 4, numVisits=7, meanQ=3.854329, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 19068 episodes
GETTING ACTION FROM:
action 1, numVisits=22244, meanQ=10.161063, numObservations: 9
action 4, numVisits=17, meanQ=3.919316, numObservations: 7
action 3, numVisits=7, meanQ=0.141429, numObservations: 6
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action 0, numVisits=140, meanQ=-8.807683, numObservations: 103
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=85, meanQ=-13.120329, numObservations: 53
action: 1
Next state: 0 0.37045 0.563286 0.268014 0.306784 0.974745 0.299414 0.707566 0.507504 0.250624 0.609362 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=783, meanQ=12.602557, numObservations: 9
action 2, numVisits=4, meanQ=0.752525, numObservations: 3
action 0, numVisits=5, meanQ=-1.407980, numObservations: 4
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=6, meanQ=-3.374778, numObservations: 5
Sampled 20225 episodes
GETTING ACTION FROM:
action 4, numVisits=20909, meanQ=10.756610, numObservations: 9
action 2, numVisits=4, meanQ=0.752525, numObservations: 3
action 0, numVisits=45, meanQ=-1.912220, numObservations: 35
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=60, meanQ=-3.095457, numObservations: 9
action -1, numVisits=6, meanQ=-3.374778, numObservations: 5
action: 4
Next state: 0 0.37045 0.563286 0.268014 0.306784 0.974745 0.299414 0.707566 0.507504 0.250624 0.609362 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 4, numVisits=241, meanQ=21.047842, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-14.675681, numObservations: 1
action 5, numVisits=1, meanQ=-1050.887216, numObservations: 1
Sampled 51796 episodes
GETTING ACTION FROM:
action 4, numVisits=472, meanQ=21.689682, numObservations: 9
action -1, numVisits=50253, meanQ=-1.563235, numObservations: 225
action 0, numVisits=1314, meanQ=-2.743346, numObservations: 164
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-14.675681, numObservations: 1
action 5, numVisits=1, meanQ=-1050.887216, numObservations: 1
action: 4
Next state: 1 0.37045 0.563286 0.268014 0.306784 0.974745 0.299414 0.707566 0.507504 0.250624 0.609362 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 11.4068
Run # 25
Initial state: 0 0.803925 0.432718 0.769397 0.401165 0.859916 0.142149 0.303154 0.732784 0.651086 0.63401 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 76112 episodes
GETTING ACTION FROM:
action 5, numVisits=76103, meanQ=8.732292, numObservations: 9
action 1, numVisits=4, meanQ=-0.252500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.803925 0.432718 0.769397 0.401165 0.859916 0.142149 0.303154 0.732784 0.651086 0.63401 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 26
Initial state: 0 0.621638 0.632077 0.117405 0.655581 0.36291 0.785327 0.0590719 0.489505 0.498211 0.737612 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 73773 episodes
GETTING ACTION FROM:
action 4, numVisits=73755, meanQ=8.718246, numObservations: 9
action 2, numVisits=11, meanQ=4.181827, numObservations: 7
action 5, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.621638 0.632077 0.117405 0.655581 0.36291 0.785327 0.0590719 0.489505 0.498211 0.737612 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=272, meanQ=7.877217, numObservations: 9
action 5, numVisits=11, meanQ=3.918191, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 40910 episodes
GETTING ACTION FROM:
action 3, numVisits=41176, meanQ=12.515379, numObservations: 9
action 5, numVisits=11, meanQ=3.918191, numObservations: 6
action -1, numVisits=4, meanQ=-1.752500, numObservations: 4
action 0, numVisits=4, meanQ=-1.752500, numObservations: 4
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.621638 0.632077 0.117405 0.655581 0.36291 0.785327 0.0590719 0.489505 0.498211 0.737612 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=462, meanQ=8.883767, numObservations: 9
action 2, numVisits=73, meanQ=-1.177263, numObservations: 9
action -1, numVisits=97, meanQ=-6.151070, numObservations: 52
action 3, numVisits=2, meanQ=-7.331386, numObservations: 2
action 5, numVisits=2, meanQ=-8.161939, numObservations: 2
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=33, meanQ=-32.002622, numObservations: 26
Sampled 47177 episodes
GETTING ACTION FROM:
action 1, numVisits=47639, meanQ=15.211993, numObservations: 9
action 2, numVisits=73, meanQ=-1.177263, numObservations: 9
action -1, numVisits=97, meanQ=-6.151070, numObservations: 52
action 3, numVisits=2, meanQ=-7.331386, numObservations: 2
action 5, numVisits=2, meanQ=-8.161939, numObservations: 2
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=33, meanQ=-32.002622, numObservations: 26
action: 1
Next state: 1 0.621638 0.632077 0.117405 0.655581 0.36291 0.785327 0.0590719 0.489505 0.498211 0.737612 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 27
Initial state: 0 0.313404 0.936594 0.597288 0.629105 0.306147 0.0371467 0.870024 0.723151 0.767428 0.370362 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 76780 episodes
GETTING ACTION FROM:
action 3, numVisits=76721, meanQ=8.776402, numObservations: 9
action 2, numVisits=54, meanQ=7.796690, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.313404 0.936594 0.597288 0.629105 0.306147 0.0371467 0.870024 0.723151 0.767428 0.370362 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=15501, meanQ=10.239030, numObservations: 9
action 1, numVisits=7, meanQ=6.282857, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 18922 episodes
GETTING ACTION FROM:
action 5, numVisits=34334, meanQ=10.227569, numObservations: 9
action 2, numVisits=8, meanQ=2.815978, numObservations: 6
action -1, numVisits=6, meanQ=-1.010000, numObservations: 6
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=4, meanQ=-3.980000, numObservations: 3
action 1, numVisits=81, meanQ=-4.215160, numObservations: 8
action: 5
Next state: 2 0.313404 0.936594 0.597288 0.629105 0.306147 0.0371467 0.870024 0.723151 0.767428 0.370362 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 28
Initial state: 0 0.837614 0.68057 0.902049 0.333768 0.180501 0.853689 0.560736 0.544335 0.336446 0.366419 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 76572 episodes
GETTING ACTION FROM:
action 5, numVisits=76561, meanQ=8.744404, numObservations: 9
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action 1, numVisits=4, meanQ=1.497500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 0 0.837614 0.68057 0.902049 0.333768 0.180501 0.853689 0.560736 0.544335 0.336446 0.366419 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=15399, meanQ=10.274802, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 18773 episodes
GETTING ACTION FROM:
action 2, numVisits=34161, meanQ=10.431278, numObservations: 9
action 0, numVisits=7, meanQ=-1.010000, numObservations: 7
action -1, numVisits=6, meanQ=-1.175000, numObservations: 6
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.837614 0.68057 0.902049 0.333768 0.180501 0.853689 0.560736 0.544335 0.336446 0.366419 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 29
Initial state: 0 0.73806 0.719744 0.0840896 0.762377 0.466051 0.54045 0.513329 0.601625 0.732776 0.508887 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 77069 episodes
GETTING ACTION FROM:
action 2, numVisits=77058, meanQ=8.851148, numObservations: 9
action 3, numVisits=6, meanQ=4.836683, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.73806 0.719744 0.0840896 0.762377 0.466051 0.54045 0.513329 0.601625 0.732776 0.508887 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 30
Initial state: 0 0.274795 0.0947673 0.216852 0.663266 0.742157 0.215834 0.924662 0.129815 0.615556 0.488825 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 76570 episodes
GETTING ACTION FROM:
action 4, numVisits=76530, meanQ=8.858196, numObservations: 9
action 0, numVisits=9, meanQ=-1.451100, numObservations: 8
action 3, numVisits=16, meanQ=-1.576844, numObservations: 6
action 2, numVisits=7, meanQ=-1.717143, numObservations: 6
action -1, numVisits=6, meanQ=-2.990000, numObservations: 5
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.274795 0.0947673 0.216852 0.663266 0.742157 0.215834 0.924662 0.129815 0.615556 0.488825 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 31
Initial state: 0 0.619058 0.518366 0.765339 0.389281 0.967029 0.193522 0.895852 0.398777 0.544565 0.893803 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 74764 episodes
GETTING ACTION FROM:
action 5, numVisits=74734, meanQ=9.043826, numObservations: 9
action 0, numVisits=17, meanQ=-1.243524, numObservations: 16
action 4, numVisits=6, meanQ=-2.668333, numObservations: 5
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=2, meanQ=-4.499950, numObservations: 1
action 1, numVisits=2, meanQ=-7.500000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.619058 0.518366 0.765339 0.389281 0.967029 0.193522 0.895852 0.398777 0.544565 0.893803 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 32
Initial state: 0 0.933619 0.161505 0.753781 0.957682 0.528737 0.329651 0.588088 0.657531 0.905168 0.793806 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 76758 episodes
GETTING ACTION FROM:
action 4, numVisits=76739, meanQ=8.838944, numObservations: 9
action 2, numVisits=14, meanQ=6.109307, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.933619 0.161505 0.753781 0.957682 0.528737 0.329651 0.588088 0.657531 0.905168 0.793806 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 33
Initial state: 0 0.622046 0.646918 0.733608 0.195707 0.315077 0.85557 0.887679 0.736811 0.420624 0.0946455 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 76544 episodes
GETTING ACTION FROM:
action 4, numVisits=76534, meanQ=8.841199, numObservations: 9
action 5, numVisits=5, meanQ=4.598000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.622046 0.646918 0.733608 0.195707 0.315077 0.85557 0.887679 0.736811 0.420624 0.0946455 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 34
Initial state: 0 0.579982 0.548603 0.137908 0.0176972 0.426173 0.845262 0.800244 0.837509 0.185165 0.648578 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 77160 episodes
GETTING ACTION FROM:
action 4, numVisits=77053, meanQ=9.086656, numObservations: 9
action -1, numVisits=75, meanQ=-1.011056, numObservations: 63
action 0, numVisits=26, meanQ=-1.466923, numObservations: 25
action 3, numVisits=2, meanQ=-4.000000, numObservations: 2
action 5, numVisits=2, meanQ=-7.500000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.579982 0.548603 0.137908 0.0176972 0.426173 0.845262 0.800244 0.837509 0.185165 0.648578 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 35
Initial state: 0 0.694922 0.486012 0.791622 0.0592742 0.145384 0.610254 0.422523 0.841015 0.135226 0.470764 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 76227 episodes
GETTING ACTION FROM:
action 5, numVisits=76216, meanQ=8.957168, numObservations: 9
action 1, numVisits=3, meanQ=3.330000, numObservations: 3
action 4, numVisits=4, meanQ=3.247500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.694922 0.486012 0.791622 0.0592742 0.145384 0.610254 0.422523 0.841015 0.135226 0.470764 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=15199, meanQ=10.387595, numObservations: 9
action 1, numVisits=4, meanQ=1.745000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 19236 episodes
GETTING ACTION FROM:
action 2, numVisits=34419, meanQ=9.743339, numObservations: 9
action 1, numVisits=4, meanQ=1.745000, numObservations: 4
action 0, numVisits=9, meanQ=-1.010000, numObservations: 9
action -1, numVisits=8, meanQ=-1.133750, numObservations: 8
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=2, meanQ=-6.444270, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.694922 0.486012 0.791622 0.0592742 0.145384 0.610254 0.422523 0.841015 0.135226 0.470764 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 36
Initial state: 0 0.781603 0.995282 0.685818 0.502937 0.769964 0.645417 0.204485 0.360835 0.050533 0.278697 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 76918 episodes
GETTING ACTION FROM:
action 1, numVisits=76910, meanQ=8.804586, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.781603 0.995282 0.685818 0.502937 0.769964 0.645417 0.204485 0.360835 0.050533 0.278697 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 37
Initial state: 0 0.610731 0.487797 0.0249412 0.186681 0.0837543 0.598551 0.547969 0.163335 0.577431 0.75438 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 74592 episodes
GETTING ACTION FROM:
action 2, numVisits=74586, meanQ=8.849061, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.610731 0.487797 0.0249412 0.186681 0.0837543 0.598551 0.547969 0.163335 0.577431 0.75438 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=14872, meanQ=10.191532, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 18843 episodes
GETTING ACTION FROM:
action 5, numVisits=33699, meanQ=9.726068, numObservations: 9
action 3, numVisits=6, meanQ=2.475136, numObservations: 3
action 4, numVisits=4, meanQ=0.488980, numObservations: 2
action -1, numVisits=7, meanQ=-2.566804, numObservations: 6
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=3, meanQ=-4.101684, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.610731 0.487797 0.0249412 0.186681 0.0837543 0.598551 0.547969 0.163335 0.577431 0.75438 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 38
Initial state: 0 0.884622 0.617176 0.539617 0.548481 0.943689 0.404988 0.757544 0.387882 0.297728 0.278381 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49273 episodes
GETTING ACTION FROM:
action 0, numVisits=49208, meanQ=14.521514, numObservations: 243
action -1, numVisits=55, meanQ=-1.389260, numObservations: 45
action 1, numVisits=2, meanQ=-4.000000, numObservations: 2
action 3, numVisits=2, meanQ=-4.000000, numObservations: 2
action 4, numVisits=2, meanQ=-4.499950, numObservations: 1
action 5, numVisits=2, meanQ=-4.499950, numObservations: 1
action 2, numVisits=2, meanQ=-7.500000, numObservations: 1
action: 0
Next state: 0 0.884622 0.617176 0.539617 0.548481 0.943689 0.404988 0.757544 0.387882 0.297728 0.278381 w: 1
Observation: 0 0 1 0 2 0 1 0 1 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=600, meanQ=5.694906, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 82534 episodes
GETTING ACTION FROM:
action 4, numVisits=83133, meanQ=4.980834, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=2, meanQ=-4.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.884622 0.617176 0.539617 0.548481 0.943689 0.404988 0.757544 0.387882 0.297728 0.278381 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 39
Initial state: 0 0.41502 0.670626 0.265056 0.0267452 0.35923 0.460794 0.541769 0.498756 0.167695 0.185706 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 76902 episodes
GETTING ACTION FROM:
action 2, numVisits=76896, meanQ=8.918264, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.41502 0.670626 0.265056 0.0267452 0.35923 0.460794 0.541769 0.498756 0.167695 0.185706 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=15052, meanQ=10.018858, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 4, numVisits=2, meanQ=-3.010000, numObservations: 2
action 2, numVisits=2, meanQ=-4.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 20935 episodes
GETTING ACTION FROM:
action 5, numVisits=35958, meanQ=9.199363, numObservations: 9
action 0, numVisits=9, meanQ=-2.389138, numObservations: 7
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 4, numVisits=2, meanQ=-3.010000, numObservations: 2
action 2, numVisits=2, meanQ=-4.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=33, meanQ=-30.489175, numObservations: 26
action: 5
Next state: 0 0.41502 0.670626 0.265056 0.0267452 0.35923 0.460794 0.541769 0.498756 0.167695 0.185706 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=6400, meanQ=12.885678, numObservations: 9
action 1, numVisits=17, meanQ=7.104129, numObservations: 7
action 4, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 17565 episodes
GETTING ACTION FROM:
action 3, numVisits=23965, meanQ=12.818360, numObservations: 9
action 1, numVisits=17, meanQ=7.104129, numObservations: 7
action 4, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.41502 0.670626 0.265056 0.0267452 0.35923 0.460794 0.541769 0.498756 0.167695 0.185706 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=2476, meanQ=18.478161, numObservations: 9
action 4, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 20346 episodes
GETTING ACTION FROM:
action 1, numVisits=22819, meanQ=16.660521, numObservations: 9
action 4, numVisits=3, meanQ=1.046767, numObservations: 3
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.41502 0.670626 0.265056 0.0267452 0.35923 0.460794 0.541769 0.498756 0.167695 0.185706 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 4, numVisits=908, meanQ=20.272376, numObservations: 9
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 51837 episodes
GETTING ACTION FROM:
action 4, numVisits=52745, meanQ=22.252265, numObservations: 9
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.41502 0.670626 0.265056 0.0267452 0.35923 0.460794 0.541769 0.498756 0.167695 0.185706 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.29271
Run # 40
Initial state: 0 0.538334 0.615139 0.394333 0.689779 0.986313 0.803262 0.562589 0.123582 0.442245 0.796225 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 76631 episodes
GETTING ACTION FROM:
action 3, numVisits=76514, meanQ=8.912278, numObservations: 9
action 1, numVisits=80, meanQ=7.806187, numObservations: 9
action 5, numVisits=31, meanQ=7.291326, numObservations: 7
action 4, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.538334 0.615139 0.394333 0.689779 0.986313 0.803262 0.562589 0.123582 0.442245 0.796225 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 41
Initial state: 0 0.899134 0.87519 0.258623 0.419835 0.186836 0.702224 0.715117 0.6255 0.308079 0.720024 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 73510 episodes
GETTING ACTION FROM:
action 4, numVisits=73504, meanQ=8.605302, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 1 0.899134 0.87519 0.258623 0.419835 0.186836 0.702224 0.715117 0.6255 0.308079 0.720024 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 42
Initial state: 0 0.778965 0.401833 0.614913 0.479345 0.161709 0.337837 0.637844 0.963809 0.614773 0.552198 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 76213 episodes
GETTING ACTION FROM:
action 3, numVisits=76205, meanQ=8.480437, numObservations: 9
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.778965 0.401833 0.614913 0.479345 0.161709 0.337837 0.637844 0.963809 0.614773 0.552198 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=15156, meanQ=10.201878, numObservations: 9
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 19504 episodes
GETTING ACTION FROM:
action 5, numVisits=34649, meanQ=9.827239, numObservations: 9
action 2, numVisits=4, meanQ=-1.225000, numObservations: 3
action 0, numVisits=8, meanQ=-1.257500, numObservations: 8
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=2, meanQ=-5.508496, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 4, numVisits=2, meanQ=-7.005000, numObservations: 1
action: 5
Next state: 0 0.778965 0.401833 0.614913 0.479345 0.161709 0.337837 0.637844 0.963809 0.614773 0.552198 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=617, meanQ=19.703877, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 47601 episodes
GETTING ACTION FROM:
action 5, numVisits=634, meanQ=19.812385, numObservations: 9
action 4, numVisits=47575, meanQ=12.584972, numObservations: 9
action 0, numVisits=6, meanQ=-1.670000, numObservations: 6
action -1, numVisits=6, meanQ=-1.835000, numObservations: 6
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 1 0.778965 0.401833 0.614913 0.479345 0.161709 0.337837 0.637844 0.963809 0.614773 0.552198 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 43
Initial state: 0 0.913586 0.178454 0.152595 0.782608 0.670434 0.632748 0.815602 0.312459 0.45224 0.169327 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 76320 episodes
GETTING ACTION FROM:
action 4, numVisits=76305, meanQ=8.624814, numObservations: 9
action 3, numVisits=4, meanQ=2.502525, numObservations: 3
action 5, numVisits=4, meanQ=1.745000, numObservations: 4
action 1, numVisits=4, meanQ=1.497500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 2 0.913586 0.178454 0.152595 0.782608 0.670434 0.632748 0.815602 0.312459 0.45224 0.169327 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 44
Initial state: 0 0.0721897 0.762249 0.259351 0.08838 0.706984 0.600374 0.373601 0.45867 0.61309 0.418012 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 76736 episodes
GETTING ACTION FROM:
action 4, numVisits=76725, meanQ=8.886788, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=2, meanQ=-5.489950, numObservations: 1
action: 4
Next state: 0 0.0721897 0.762249 0.259351 0.08838 0.706984 0.600374 0.373601 0.45867 0.61309 0.418012 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=15337, meanQ=10.368111, numObservations: 9
action 2, numVisits=16, meanQ=8.257513, numObservations: 7
action 3, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 17897 episodes
GETTING ACTION FROM:
action 1, numVisits=33183, meanQ=9.619714, numObservations: 9
action 2, numVisits=31, meanQ=5.714216, numObservations: 9
action 0, numVisits=9, meanQ=-1.120000, numObservations: 9
action -1, numVisits=9, meanQ=-1.231100, numObservations: 8
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=2, meanQ=-7.005000, numObservations: 2
action 3, numVisits=22, meanQ=-42.117309, numObservations: 9
action: 1
Next state: 0 0.0721897 0.762249 0.259351 0.08838 0.706984 0.600374 0.373601 0.45867 0.61309 0.418012 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=3021, meanQ=12.955124, numObservations: 9
action 5, numVisits=18, meanQ=6.227789, numObservations: 7
action 1, numVisits=3, meanQ=5.330033, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 14969 episodes
GETTING ACTION FROM:
action 2, numVisits=17988, meanQ=13.162287, numObservations: 9
action 5, numVisits=18, meanQ=6.227789, numObservations: 7
action 1, numVisits=3, meanQ=5.330033, numObservations: 2
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.340000, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.0721897 0.762249 0.259351 0.08838 0.706984 0.600374 0.373601 0.45867 0.61309 0.418012 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=2296, meanQ=16.272221, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 19426 episodes
GETTING ACTION FROM:
action 3, numVisits=21720, meanQ=13.759104, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.0721897 0.762249 0.259351 0.08838 0.706984 0.600374 0.373601 0.45867 0.61309 0.418012 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 11.4068
Run # 45
Initial state: 0 0.790732 0.0319901 0.409814 0.143319 0.859831 0.0579846 0.566912 0.576107 0.590629 0.0480883 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 75202 episodes
GETTING ACTION FROM:
action 4, numVisits=75196, meanQ=8.882361, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.790732 0.0319901 0.409814 0.143319 0.859831 0.0579846 0.566912 0.576107 0.590629 0.0480883 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 46
Initial state: 0 0.501798 0.479036 0.969191 0.866459 0.716019 0.632749 0.994675 0.218388 0.632342 0.347515 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 75806 episodes
GETTING ACTION FROM:
action 3, numVisits=75622, meanQ=8.662015, numObservations: 9
action 2, numVisits=158, meanQ=7.549533, numObservations: 9
action 5, numVisits=20, meanQ=6.529525, numObservations: 8
action 1, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.501798 0.479036 0.969191 0.866459 0.716019 0.632749 0.994675 0.218388 0.632342 0.347515 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 47
Initial state: 0 0.551034 0.654323 0.833196 0.669394 0.409356 0.140596 0.197895 0.443006 0.537471 0.0844691 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 76858 episodes
GETTING ACTION FROM:
action 5, numVisits=76639, meanQ=8.872284, numObservations: 9
action 3, numVisits=211, meanQ=5.669304, numObservations: 9
action 1, numVisits=4, meanQ=2.502525, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.551034 0.654323 0.833196 0.669394 0.409356 0.140596 0.197895 0.443006 0.537471 0.0844691 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=15309, meanQ=10.378635, numObservations: 9
action 4, numVisits=5, meanQ=4.598000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 18112 episodes
GETTING ACTION FROM:
action 1, numVisits=33222, meanQ=9.754255, numObservations: 9
action 3, numVisits=185, meanQ=4.369299, numObservations: 9
action 4, numVisits=6, meanQ=1.998333, numObservations: 4
action 0, numVisits=8, meanQ=-1.133750, numObservations: 7
action -1, numVisits=8, meanQ=-1.133750, numObservations: 8
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.551034 0.654323 0.833196 0.669394 0.409356 0.140596 0.197895 0.443006 0.537471 0.0844691 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 48
Initial state: 0 0.505107 0.357333 0.717296 0.485187 0.602406 0.911576 0.241518 0.204318 0.066792 0.908038 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49881 episodes
GETTING ACTION FROM:
action -1, numVisits=49767, meanQ=13.040196, numObservations: 243
action 0, numVisits=107, meanQ=-0.964941, numObservations: 83
action 3, numVisits=2, meanQ=-4.000000, numObservations: 2
action 4, numVisits=2, meanQ=-4.000000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.505107 0.357333 0.717296 0.485187 0.602406 0.911576 0.241518 0.204318 0.066792 0.908038 w: 1
Observation: 0 1 0 2 0 2 0 1 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=437, meanQ=13.256183, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 102158 episodes
GETTING ACTION FROM:
action 3, numVisits=102595, meanQ=15.102410, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.505107 0.357333 0.717296 0.485187 0.602406 0.911576 0.241518 0.204318 0.066792 0.908038 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 49
Initial state: 0 0.392816 0.89004 0.600716 0.588335 0.458969 0.185291 0.222175 0.283308 0.341194 0.356017 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 77155 episodes
GETTING ACTION FROM:
action 4, numVisits=77143, meanQ=8.825459, numObservations: 9
action 1, numVisits=7, meanQ=1.574300, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.392816 0.89004 0.600716 0.588335 0.458969 0.185291 0.222175 0.283308 0.341194 0.356017 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=15417, meanQ=10.035793, numObservations: 9
action 2, numVisits=4, meanQ=3.742500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 18585 episodes
GETTING ACTION FROM:
action 3, numVisits=33990, meanQ=10.331761, numObservations: 9
action 2, numVisits=5, meanQ=0.794000, numObservations: 5
action 0, numVisits=7, meanQ=-1.151429, numObservations: 7
action -1, numVisits=5, meanQ=-1.605980, numObservations: 4
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=2, meanQ=-4.004950, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.392816 0.89004 0.600716 0.588335 0.458969 0.185291 0.222175 0.283308 0.341194 0.356017 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=5599, meanQ=12.999362, numObservations: 9
action 2, numVisits=5, meanQ=6.196000, numObservations: 4
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 13912 episodes
GETTING ACTION FROM:
action 1, numVisits=19504, meanQ=12.082791, numObservations: 9
action 2, numVisits=6, meanQ=3.330000, numObservations: 4
action 0, numVisits=5, meanQ=-1.208000, numObservations: 5
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=5, meanQ=-107.825867, numObservations: 4
action: 1
Next state: 0 0.392816 0.89004 0.600716 0.588335 0.458969 0.185291 0.222175 0.283308 0.341194 0.356017 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=1389, meanQ=14.901266, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 12023 episodes
GETTING ACTION FROM:
action 2, numVisits=13412, meanQ=15.451718, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.392816 0.89004 0.600716 0.588335 0.458969 0.185291 0.222175 0.283308 0.341194 0.356017 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 11.4068
Run # 50
Initial state: 0 0.591494 0.482778 0.805833 0.773409 0.589409 0.73171 0.110768 0.993362 0.610399 0.197727 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 77227 episodes
GETTING ACTION FROM:
action 2, numVisits=56418, meanQ=8.755333, numObservations: 9
action 1, numVisits=19620, meanQ=8.502093, numObservations: 9
action 5, numVisits=1183, meanQ=8.351542, numObservations: 9
action 3, numVisits=3, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.591494 0.482778 0.805833 0.773409 0.589409 0.73171 0.110768 0.993362 0.610399 0.197727 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
[32m ProblemEnvironment.hpp 351: Done.[39m
