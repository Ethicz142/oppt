Run # 1
Initial state: 0 0.0976986 0.483554 0.690339 0.414294 0.310599 0.981972 0.615082 0.653024 0.393372 0.525596 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 90584 episodes
GETTING ACTION FROM:
action 5, numVisits=90563, meanQ=8.734395, numObservations: 9
action 3, numVisits=13, meanQ=3.690769, numObservations: 5
action 1, numVisits=4, meanQ=-0.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.0976986 0.483554 0.690339 0.414294 0.310599 0.981972 0.615082 0.653024 0.393372 0.525596 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 2
Initial state: 0 0.88676 0.849528 0.615918 0.270304 0.417624 0.873698 0.943547 0.213448 0.419796 0.552012 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 93759 episodes
GETTING ACTION FROM:
action 3, numVisits=93737, meanQ=8.768603, numObservations: 9
action 1, numVisits=11, meanQ=5.500909, numObservations: 6
action 4, numVisits=7, meanQ=4.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.88676 0.849528 0.615918 0.270304 0.417624 0.873698 0.943547 0.213448 0.419796 0.552012 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 3
Initial state: 0 0.248623 0.108425 0.664347 0.31356 0.852542 0.0624238 0.862924 0.63181 0.405102 0.592289 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 90868 episodes
GETTING ACTION FROM:
action 3, numVisits=90858, meanQ=8.776582, numObservations: 9
action 1, numVisits=3, meanQ=3.000000, numObservations: 2
action 4, numVisits=3, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.248623 0.108425 0.664347 0.31356 0.852542 0.0624238 0.862924 0.63181 0.405102 0.592289 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 4
Initial state: 0 0.348757 0.530691 0.841352 0.665711 0.127288 0.461525 0.664753 0.854272 0.43533 0.867736 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 93151 episodes
GETTING ACTION FROM:
action 4, numVisits=93138, meanQ=8.644312, numObservations: 9
action 2, numVisits=5, meanQ=3.000000, numObservations: 4
action 1, numVisits=4, meanQ=-0.500000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.348757 0.530691 0.841352 0.665711 0.127288 0.461525 0.664753 0.854272 0.43533 0.867736 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 5
Initial state: 0 0.569369 0.0258096 0.157685 0.0883714 0.930722 0.247066 0.921451 0.707118 0.415757 0.600407 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 94020 episodes
GETTING ACTION FROM:
action 2, numVisits=93957, meanQ=8.661566, numObservations: 9
action 1, numVisits=58, meanQ=7.552071, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.569369 0.0258096 0.157685 0.0883714 0.930722 0.247066 0.921451 0.707118 0.415757 0.600407 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 6
Initial state: 0 0.342747 0.545419 0.914381 0.432305 0.0621904 0.629239 0.594355 0.819104 0.107816 0.836009 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 93208 episodes
GETTING ACTION FROM:
action 3, numVisits=93200, meanQ=8.701491, numObservations: 9
action 4, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.342747 0.545419 0.914381 0.432305 0.0621904 0.629239 0.594355 0.819104 0.107816 0.836009 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=6178, meanQ=10.021106, numObservations: 9
action 4, numVisits=12, meanQ=4.915000, numObservations: 5
action 1, numVisits=12, meanQ=4.590833, numObservations: 6
action 3, numVisits=4, meanQ=3.742500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 39396 episodes
GETTING ACTION FROM:
action 5, numVisits=39287, meanQ=10.698546, numObservations: 9
action 2, numVisits=6179, meanQ=10.020560, numObservations: 9
action 3, numVisits=4, meanQ=3.742500, numObservations: 3
action 1, numVisits=44, meanQ=-14.139999, numObservations: 9
action -1, numVisits=56, meanQ=-19.819106, numObservations: 43
action 4, numVisits=17, meanQ=-35.192998, numObservations: 6
action 0, numVisits=18, meanQ=-54.432394, numObservations: 15
action: 5
Next state: 0 0.342747 0.545419 0.914381 0.432305 0.0621904 0.629239 0.594355 0.819104 0.107816 0.836009 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=1, meanQ=24.000000, numObservations: 1
action 2, numVisits=877, meanQ=12.048420, numObservations: 9
action 1, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=7, meanQ=-2.448528, numObservations: 6
action 5, numVisits=1, meanQ=-8.413176, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=77, meanQ=-11.096789, numObservations: 49
Sampled 31766 episodes
GETTING ACTION FROM:
action 3, numVisits=9, meanQ=17.306667, numObservations: 4
action 2, numVisits=32635, meanQ=15.189371, numObservations: 9
action 1, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=7, meanQ=-2.448528, numObservations: 6
action 5, numVisits=1, meanQ=-8.413176, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=77, meanQ=-11.096789, numObservations: 49
action: 3
Next state: 1 0.342747 0.545419 0.914381 0.432305 0.0621904 0.629239 0.594355 0.819104 0.107816 0.836009 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 7
Initial state: 0 0.82591 0.490305 0.64385 0.903842 0.210225 0.211111 0.607899 0.501114 0.4265 0.567144 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 90476 episodes
GETTING ACTION FROM:
action 3, numVisits=90459, meanQ=8.816848, numObservations: 9
action 5, numVisits=12, meanQ=4.000842, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.82591 0.490305 0.64385 0.903842 0.210225 0.211111 0.607899 0.501114 0.4265 0.567144 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=9709, meanQ=9.992537, numObservations: 9
action 5, numVisits=65, meanQ=8.301695, numObservations: 8
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 29957 episodes
GETTING ACTION FROM:
action 4, numVisits=37552, meanQ=9.589382, numObservations: 9
action 5, numVisits=2131, meanQ=8.102509, numObservations: 9
action 0, numVisits=41, meanQ=0.076344, numObservations: 34
action 2, numVisits=4, meanQ=-0.252500, numObservations: 3
action -1, numVisits=8, meanQ=-1.257500, numObservations: 7
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.82591 0.490305 0.64385 0.903842 0.210225 0.211111 0.607899 0.501114 0.4265 0.567144 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 8
Initial state: 0 0.897797 0.286578 0.30749 0.112442 0.0340609 0.977475 0.262124 0.128812 0.324199 0.590227 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 94572 episodes
GETTING ACTION FROM:
action 4, numVisits=94564, meanQ=8.657479, numObservations: 9
action 1, numVisits=3, meanQ=1.703333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.897797 0.286578 0.30749 0.112442 0.0340609 0.977475 0.262124 0.128812 0.324199 0.590227 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=10395, meanQ=9.688414, numObservations: 9
action 2, numVisits=7, meanQ=5.998586, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 28477 episodes
GETTING ACTION FROM:
action 3, numVisits=38840, meanQ=9.852724, numObservations: 9
action 2, numVisits=25, meanQ=6.359604, numObservations: 7
action 1, numVisits=4, meanQ=-0.252500, numObservations: 4
action -1, numVisits=6, meanQ=-1.340000, numObservations: 6
action 0, numVisits=6, meanQ=-1.340000, numObservations: 6
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 3
Next state: 0 0.897797 0.286578 0.30749 0.112442 0.0340609 0.977475 0.262124 0.128812 0.324199 0.590227 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=32, meanQ=14.210543, numObservations: 9
action 5, numVisits=232, meanQ=4.577533, numObservations: 9
action -1, numVisits=10, meanQ=-2.198000, numObservations: 9
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=25, meanQ=-42.688730, numObservations: 20
Sampled 46095 episodes
GETTING ACTION FROM:
action 1, numVisits=46127, meanQ=14.132600, numObservations: 9
action 5, numVisits=232, meanQ=4.577533, numObservations: 9
action -1, numVisits=10, meanQ=-2.198000, numObservations: 9
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=25, meanQ=-42.688730, numObservations: 20
action: 1
Next state: 2 0.897797 0.286578 0.30749 0.112442 0.0340609 0.977475 0.262124 0.128812 0.324199 0.590227 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -18.7411
Run # 9
Initial state: 0 0.786318 0.339184 0.405359 0.570975 0.0283639 0.112958 0.694148 0.451062 0.188446 0.406127 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 93393 episodes
GETTING ACTION FROM:
action 1, numVisits=93352, meanQ=8.621699, numObservations: 9
action 4, numVisits=31, meanQ=5.154206, numObservations: 8
action 3, numVisits=6, meanQ=3.000000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.786318 0.339184 0.405359 0.570975 0.0283639 0.112958 0.694148 0.451062 0.188446 0.406127 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=348, meanQ=6.230455, numObservations: 9
action 2, numVisits=4, meanQ=1.745000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 97841 episodes
GETTING ACTION FROM:
action 3, numVisits=97931, meanQ=8.777884, numObservations: 9
action 2, numVisits=5, meanQ=-0.804000, numObservations: 3
action 0, numVisits=134, meanQ=-1.940896, numObservations: 87
action -1, numVisits=125, meanQ=-1.960400, numObservations: 72
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.786318 0.339184 0.405359 0.570975 0.0283639 0.112958 0.694148 0.451062 0.188446 0.406127 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=317, meanQ=14.379431, numObservations: 9
action 1, numVisits=14, meanQ=10.141429, numObservations: 7
action 2, numVisits=9, meanQ=1.683897, numObservations: 6
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=13, meanQ=-3.646195, numObservations: 10
action 0, numVisits=23, meanQ=-43.870876, numObservations: 17
Sampled 48211 episodes
GETTING ACTION FROM:
action 4, numVisits=48528, meanQ=15.272546, numObservations: 9
action 1, numVisits=14, meanQ=10.141429, numObservations: 7
action 2, numVisits=9, meanQ=1.683897, numObservations: 6
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=13, meanQ=-3.646195, numObservations: 10
action 0, numVisits=23, meanQ=-43.870876, numObservations: 17
action: 4
Next state: 2 0.786318 0.339184 0.405359 0.570975 0.0283639 0.112958 0.694148 0.451062 0.188446 0.406127 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -18.7411
Run # 10
Initial state: 0 0.88315 0.461736 0.902232 0.241001 0.402814 0.526772 0.646927 0.260929 0.979195 0.843822 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 93209 episodes
GETTING ACTION FROM:
action 5, numVisits=93177, meanQ=8.692285, numObservations: 9
action 2, numVisits=27, meanQ=5.592593, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.88315 0.461736 0.902232 0.241001 0.402814 0.526772 0.646927 0.260929 0.979195 0.843822 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 11
Initial state: 0 0.274807 0.858364 0.112016 0.968952 0.357598 0.417462 0.396848 0.529673 0.78614 0.42481 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 90801 episodes
GETTING ACTION FROM:
action 4, numVisits=90793, meanQ=8.828553, numObservations: 9
action 1, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.274807 0.858364 0.112016 0.968952 0.357598 0.417462 0.396848 0.529673 0.78614 0.42481 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 12
Initial state: 0 0.393236 0.514453 0.85146 0.859759 0.115275 0.414681 0.499502 0.72883 0.340187 0.429294 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 94784 episodes
GETTING ACTION FROM:
action 3, numVisits=94756, meanQ=8.552839, numObservations: 9
action 1, numVisits=23, meanQ=7.042609, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.393236 0.514453 0.85146 0.859759 0.115275 0.414681 0.499502 0.72883 0.340187 0.429294 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=10193, meanQ=9.416785, numObservations: 9
action 1, numVisits=13, meanQ=6.698462, numObservations: 6
action 4, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 29035 episodes
GETTING ACTION FROM:
action 5, numVisits=38628, meanQ=9.969098, numObservations: 9
action 1, numVisits=594, meanQ=8.006882, numObservations: 9
action 4, numVisits=8, meanQ=3.123750, numObservations: 4
action 0, numVisits=9, meanQ=-1.010000, numObservations: 9
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=7, meanQ=-152.099395, numObservations: 6
action: 5
Next state: 0 0.393236 0.514453 0.85146 0.859759 0.115275 0.414681 0.499502 0.72883 0.340187 0.429294 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=580, meanQ=11.108127, numObservations: 9
action 1, numVisits=5, meanQ=6.196000, numObservations: 5
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 34817 episodes
GETTING ACTION FROM:
action 2, numVisits=35224, meanQ=9.020063, numObservations: 9
action 1, numVisits=15, meanQ=4.065333, numObservations: 9
action -1, numVisits=98, meanQ=-1.400679, numObservations: 65
action 0, numVisits=70, meanQ=-1.477139, numObservations: 35
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=2, meanQ=-7.005000, numObservations: 2
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.393236 0.514453 0.85146 0.859759 0.115275 0.414681 0.499502 0.72883 0.340187 0.429294 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 13
Initial state: 0 0.00882217 0.320634 0.506211 0.756059 0.886885 0.100359 0.678936 0.842692 0.331961 0.557434 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 94214 episodes
GETTING ACTION FROM:
action 3, numVisits=94172, meanQ=8.719774, numObservations: 9
action 1, numVisits=32, meanQ=5.445631, numObservations: 8
action 4, numVisits=6, meanQ=1.833333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.00882217 0.320634 0.506211 0.756059 0.886885 0.100359 0.678936 0.842692 0.331961 0.557434 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 14
Initial state: 0 0.909269 0.180262 0.618033 0.619467 0.791226 0.952993 0.864197 0.858093 0.333418 0.552542 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91378 episodes
GETTING ACTION FROM:
action 3, numVisits=90951, meanQ=8.637956, numObservations: 9
action 4, numVisits=412, meanQ=7.756393, numObservations: 9
action 2, numVisits=11, meanQ=5.545455, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.909269 0.180262 0.618033 0.619467 0.791226 0.952993 0.864197 0.858093 0.333418 0.552542 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 15
Initial state: 0 0.54255 0.627072 0.346769 0.5166 0.042928 0.214859 0.527518 0.620243 0.115843 0.803825 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 93129 episodes
GETTING ACTION FROM:
action 2, numVisits=93111, meanQ=8.638231, numObservations: 9
action 1, numVisits=7, meanQ=-1.000000, numObservations: 5
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=5, meanQ=-2.600000, numObservations: 3
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.54255 0.627072 0.346769 0.5166 0.042928 0.214859 0.527518 0.620243 0.115843 0.803825 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1404, meanQ=20.072749, numObservations: 9
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action 3, numVisits=4, meanQ=10.495000, numObservations: 3
action 4, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 91863 episodes
GETTING ACTION FROM:
action 2, numVisits=1477, meanQ=20.208460, numObservations: 9
action 1, numVisits=91222, meanQ=11.167077, numObservations: 9
action 3, numVisits=567, meanQ=8.195906, numObservations: 9
action 4, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=4, meanQ=-1.505000, numObservations: 4
action 0, numVisits=4, meanQ=-1.752500, numObservations: 4
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.54255 0.627072 0.346769 0.5166 0.042928 0.214859 0.527518 0.620243 0.115843 0.803825 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 16
Initial state: 0 0.362455 0.563442 0.968793 0.660241 0.282607 0.620993 0.546659 0.378443 0.684716 0.360128 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91028 episodes
GETTING ACTION FROM:
action 4, numVisits=90642, meanQ=8.854244, numObservations: 9
action 1, numVisits=381, meanQ=8.401533, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.362455 0.563442 0.968793 0.660241 0.282607 0.620993 0.546659 0.378443 0.684716 0.360128 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 17
Initial state: 0 0.755981 0.710638 0.598234 0.141245 0.372958 0.711675 0.505067 0.294716 0.418025 0.549366 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 93147 episodes
GETTING ACTION FROM:
action 2, numVisits=93136, meanQ=8.679219, numObservations: 9
action 3, numVisits=6, meanQ=3.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.755981 0.710638 0.598234 0.141245 0.372958 0.711675 0.505067 0.294716 0.418025 0.549366 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 18
Initial state: 0 0.148727 0.646259 0.518307 0.947152 0.413383 0.519363 0.6215 0.982688 0.262184 0.623984 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 93908 episodes
GETTING ACTION FROM:
action 3, numVisits=93897, meanQ=8.516908, numObservations: 9
action 1, numVisits=6, meanQ=4.331667, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.148727 0.646259 0.518307 0.947152 0.413383 0.519363 0.6215 0.982688 0.262184 0.623984 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 19
Initial state: 0 0.350176 0.533655 0.92592 0.620937 0.883729 0.703515 0.700311 0.124761 0.757975 0.786523 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 93343 episodes
GETTING ACTION FROM:
action 3, numVisits=93335, meanQ=8.662887, numObservations: 9
action 1, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.350176 0.533655 0.92592 0.620937 0.883729 0.703515 0.700311 0.124761 0.757975 0.786523 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 20
Initial state: 0 0.0640442 0.423818 0.589554 0.705672 0.0971367 0.830698 0.32866 0.589637 0.770025 0.282763 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 93499 episodes
GETTING ACTION FROM:
action 2, numVisits=93349, meanQ=8.679094, numObservations: 9
action -1, numVisits=125, meanQ=0.041697, numObservations: 88
action 1, numVisits=12, meanQ=-0.979150, numObservations: 6
action 0, numVisits=10, meanQ=-1.010000, numObservations: 10
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.0640442 0.423818 0.589554 0.705672 0.0971367 0.830698 0.32866 0.589637 0.770025 0.282763 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 21
Initial state: 0 0.820426 0.0135524 0.914841 0.146585 0.748565 0.138439 0.883782 0.108509 0.435857 0.598067 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92026 episodes
GETTING ACTION FROM:
action 4, numVisits=92018, meanQ=8.496570, numObservations: 9
action 5, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.820426 0.0135524 0.914841 0.146585 0.748565 0.138439 0.883782 0.108509 0.435857 0.598067 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 22
Initial state: 0 0.386058 0.111767 0.809852 0.514047 0.511599 0.49561 0.664716 0.544563 0.430024 0.590267 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 94192 episodes
GETTING ACTION FROM:
action 3, numVisits=94178, meanQ=8.675656, numObservations: 9
action 2, numVisits=9, meanQ=4.555556, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.386058 0.111767 0.809852 0.514047 0.511599 0.49561 0.664716 0.544563 0.430024 0.590267 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 23
Initial state: 0 0.0256131 0.530321 0.778306 0.349738 0.386974 0.554302 0.196112 0.0168656 0.872187 0.924731 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 94656 episodes
GETTING ACTION FROM:
action 1, numVisits=94644, meanQ=8.707347, numObservations: 9
action 4, numVisits=5, meanQ=4.400000, numObservations: 4
action 3, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.0256131 0.530321 0.778306 0.349738 0.386974 0.554302 0.196112 0.0168656 0.872187 0.924731 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=333, meanQ=6.957634, numObservations: 9
action 4, numVisits=48, meanQ=6.294177, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 84256 episodes
GETTING ACTION FROM:
action 4, numVisits=84226, meanQ=8.757100, numObservations: 9
action 3, numVisits=333, meanQ=6.957634, numObservations: 9
action 0, numVisits=40, meanQ=-1.876250, numObservations: 36
action -1, numVisits=39, meanQ=-1.898462, numObservations: 33
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=2, meanQ=-7.005000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.0256131 0.530321 0.778306 0.349738 0.386974 0.554302 0.196112 0.0168656 0.872187 0.924731 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=641, meanQ=12.684639, numObservations: 9
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=2, meanQ=-8.950000, numObservations: 1
action -1, numVisits=79, meanQ=-10.677822, numObservations: 44
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=52, meanQ=-19.649569, numObservations: 35
Sampled 87144 episodes
GETTING ACTION FROM:
action 5, numVisits=87778, meanQ=9.446670, numObservations: 9
action 2, numVisits=8, meanQ=3.123750, numObservations: 6
action 4, numVisits=2, meanQ=-8.950000, numObservations: 1
action -1, numVisits=79, meanQ=-10.677822, numObservations: 44
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=52, meanQ=-19.649569, numObservations: 35
action: 5
Next state: 1 0.0256131 0.530321 0.778306 0.349738 0.386974 0.554302 0.196112 0.0168656 0.872187 0.924731 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 24
Initial state: 0 0.829665 0.797988 0.331918 0.531116 0.844866 0.244688 0.635297 0.795465 0.789099 0.376394 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91532 episodes
GETTING ACTION FROM:
action 5, numVisits=91500, meanQ=8.681730, numObservations: 9
action 4, numVisits=13, meanQ=6.769231, numObservations: 6
action 1, numVisits=9, meanQ=5.443333, numObservations: 4
action 2, numVisits=7, meanQ=5.000000, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 2 0.829665 0.797988 0.331918 0.531116 0.844866 0.244688 0.635297 0.795465 0.789099 0.376394 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 25
Initial state: 0 0.75121 0.415612 0.973072 0.902731 0.627049 0.883614 0.211651 0.556715 0.376667 0.52498 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 94208 episodes
GETTING ACTION FROM:
action 1, numVisits=94184, meanQ=8.689333, numObservations: 9
action 2, numVisits=17, meanQ=3.702941, numObservations: 8
action 5, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.75121 0.415612 0.973072 0.902731 0.627049 0.883614 0.211651 0.556715 0.376667 0.52498 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 26
Initial state: 0 0.0468051 0.986669 0.646715 0.105227 0.663854 0.0547736 0.370333 0.5887 0.506713 0.443777 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 94001 episodes
GETTING ACTION FROM:
action 3, numVisits=93995, meanQ=8.708957, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.0468051 0.986669 0.646715 0.105227 0.663854 0.0547736 0.370333 0.5887 0.506713 0.443777 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 27
Initial state: 0 0.329802 0.523357 0.232578 0.845354 0.836159 0.292994 0.300268 0.772248 0.479336 0.914732 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 94227 episodes
GETTING ACTION FROM:
action 1, numVisits=94206, meanQ=8.718518, numObservations: 9
action 2, numVisits=14, meanQ=5.857864, numObservations: 7
action 3, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.329802 0.523357 0.232578 0.845354 0.836159 0.292994 0.300268 0.772248 0.479336 0.914732 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 28
Initial state: 0 0.821927 0.444063 0.404684 0.543853 0.257486 0.350293 0.0648033 0.202935 0.80953 0.375006 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91305 episodes
GETTING ACTION FROM:
action 1, numVisits=91293, meanQ=8.825412, numObservations: 9
action 3, numVisits=5, meanQ=4.598000, numObservations: 4
action 2, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.821927 0.444063 0.404684 0.543853 0.257486 0.350293 0.0648033 0.202935 0.80953 0.375006 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 29
Initial state: 0 0.182618 0.994138 0.779131 0.952344 0.435044 0.5933 0.493769 0.906206 0.291782 0.4022 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 93082 episodes
GETTING ACTION FROM:
action 5, numVisits=92994, meanQ=8.763773, numObservations: 9
action 2, numVisits=47, meanQ=5.129581, numObservations: 8
action 1, numVisits=33, meanQ=5.038197, numObservations: 8
action 3, numVisits=3, meanQ=3.330000, numObservations: 3
action 4, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 5
Next state: 0 0.182618 0.994138 0.779131 0.952344 0.435044 0.5933 0.493769 0.906206 0.291782 0.4022 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=10017, meanQ=9.680897, numObservations: 9
action 2, numVisits=3, meanQ=2.033333, numObservations: 2
action 1, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 30784 episodes
GETTING ACTION FROM:
action 3, numVisits=40598, meanQ=8.884546, numObservations: 9
action 1, numVisits=10, meanQ=3.112952, numObservations: 6
action 2, numVisits=177, meanQ=3.082747, numObservations: 9
action -1, numVisits=14, meanQ=-1.010000, numObservations: 14
action 0, numVisits=9, meanQ=-2.661100, numObservations: 7
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 3
Next state: 0 0.182618 0.994138 0.779131 0.952344 0.435044 0.5933 0.493769 0.906206 0.291782 0.4022 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=553, meanQ=20.494545, numObservations: 9
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action 4, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 74281 episodes
GETTING ACTION FROM:
action 3, numVisits=688, meanQ=20.921866, numObservations: 9
action 2, numVisits=74143, meanQ=12.629121, numObservations: 9
action 4, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=3, meanQ=-1.670000, numObservations: 3
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.182618 0.994138 0.779131 0.952344 0.435044 0.5933 0.493769 0.906206 0.291782 0.4022 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 30
Initial state: 0 0.357235 0.5605 0.945393 0.873394 0.574946 0.962157 0.0634834 0.450912 0.168343 0.291025 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 93668 episodes
GETTING ACTION FROM:
action 2, numVisits=93662, meanQ=8.623020, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.357235 0.5605 0.945393 0.873394 0.574946 0.962157 0.0634834 0.450912 0.168343 0.291025 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 31
Initial state: 0 0.802705 0.20012 0.381812 0.522613 0.558448 0.269413 0.473287 0.00679918 0.13572 0.139711 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 94643 episodes
GETTING ACTION FROM:
action 3, numVisits=94637, meanQ=8.772238, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.802705 0.20012 0.381812 0.522613 0.558448 0.269413 0.473287 0.00679918 0.13572 0.139711 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=307, meanQ=9.468409, numObservations: 9
action 2, numVisits=46, meanQ=7.173491, numObservations: 9
action 5, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 87982 episodes
GETTING ACTION FROM:
action 5, numVisits=86240, meanQ=11.402118, numObservations: 9
action 4, numVisits=2022, meanQ=10.060079, numObservations: 9
action 2, numVisits=46, meanQ=7.173491, numObservations: 9
action -1, numVisits=16, meanQ=-1.938125, numObservations: 15
action 0, numVisits=16, meanQ=-1.938125, numObservations: 16
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.802705 0.20012 0.381812 0.522613 0.558448 0.269413 0.473287 0.00679918 0.13572 0.139711 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action -1, numVisits=59, meanQ=-0.075978, numObservations: 36
action 0, numVisits=18, meanQ=-1.120550, numObservations: 17
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-13.009473, numObservations: 1
action 2, numVisits=1, meanQ=-15.186417, numObservations: 1
action 3, numVisits=1, meanQ=-1047.769768, numObservations: 1
Sampled 121390 episodes
GETTING ACTION FROM:
action 4, numVisits=121271, meanQ=11.096123, numObservations: 9
action -1, numVisits=155, meanQ=-1.267630, numObservations: 78
action 0, numVisits=41, meanQ=-1.613900, numObservations: 38
action 1, numVisits=2, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-13.009473, numObservations: 1
action 2, numVisits=1, meanQ=-15.186417, numObservations: 1
action 3, numVisits=1, meanQ=-1047.769768, numObservations: 1
action: 4
Next state: 2 0.802705 0.20012 0.381812 0.522613 0.558448 0.269413 0.473287 0.00679918 0.13572 0.139711 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -18.7411
Run # 32
Initial state: 0 0.387543 0.528737 0.116801 0.842257 0.398151 0.946816 0.623493 0.114191 0.388709 0.628508 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 94415 episodes
GETTING ACTION FROM:
action 1, numVisits=94404, meanQ=8.725654, numObservations: 9
action 3, numVisits=3, meanQ=0.666667, numObservations: 3
action 4, numVisits=4, meanQ=-0.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.387543 0.528737 0.116801 0.842257 0.398151 0.946816 0.623493 0.114191 0.388709 0.628508 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 33
Initial state: 0 0.875626 0.893368 0.346182 0.529064 0.537521 0.288324 0.411071 0.747356 0.437416 0.241544 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 93772 episodes
GETTING ACTION FROM:
action 3, numVisits=93758, meanQ=8.692616, numObservations: 9
action 1, numVisits=7, meanQ=4.000000, numObservations: 4
action 2, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.875626 0.893368 0.346182 0.529064 0.537521 0.288324 0.411071 0.747356 0.437416 0.241544 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 34
Initial state: 0 0.246498 0.280845 0.346945 0.513159 0.877524 0.0585427 0.242676 0.314886 0.0153574 0.08484 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 94862 episodes
GETTING ACTION FROM:
action 3, numVisits=94834, meanQ=8.649722, numObservations: 9
action 5, numVisits=17, meanQ=5.124129, numObservations: 6
action 4, numVisits=3, meanQ=3.330000, numObservations: 2
action 1, numVisits=5, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 2 0.246498 0.280845 0.346945 0.513159 0.877524 0.0585427 0.242676 0.314886 0.0153574 0.08484 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 35
Initial state: 0 0.217356 0.152143 0.324484 0.556888 0.787936 0.233646 0.622531 0.799705 0.267618 0.0380297 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 93750 episodes
GETTING ACTION FROM:
action 1, numVisits=93691, meanQ=8.698676, numObservations: 9
action 5, numVisits=52, meanQ=5.964817, numObservations: 9
action 3, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.217356 0.152143 0.324484 0.556888 0.787936 0.233646 0.622531 0.799705 0.267618 0.0380297 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=10225, meanQ=9.501166, numObservations: 9
action 5, numVisits=5, meanQ=4.598000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 34653 episodes
GETTING ACTION FROM:
action 4, numVisits=44825, meanQ=9.663113, numObservations: 9
action 2, numVisits=26, meanQ=6.022204, numObservations: 9
action 3, numVisits=14, meanQ=4.642593, numObservations: 8
action 5, numVisits=6, meanQ=1.998333, numObservations: 5
action -1, numVisits=8, meanQ=-1.133750, numObservations: 8
action 0, numVisits=8, meanQ=-1.133750, numObservations: 8
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 1 0.217356 0.152143 0.324484 0.556888 0.787936 0.233646 0.622531 0.799705 0.267618 0.0380297 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 36
Initial state: 0 0.516636 0.507258 0.549038 0.553123 0.726337 0.221609 0.412733 0.59882 0.635242 0.696793 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89919 episodes
GETTING ACTION FROM:
action 3, numVisits=89899, meanQ=8.750658, numObservations: 9
action 5, numVisits=10, meanQ=-0.189000, numObservations: 7
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 2, numVisits=2, meanQ=-4.000000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.516636 0.507258 0.549038 0.553123 0.726337 0.221609 0.412733 0.59882 0.635242 0.696793 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 37
Initial state: 0 0.110006 0.856768 0.32908 0.749928 0.922272 0.439961 0.408412 0.535706 0.892412 0.112066 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 94780 episodes
GETTING ACTION FROM:
action 3, numVisits=94772, meanQ=8.633751, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.110006 0.856768 0.32908 0.749928 0.922272 0.439961 0.408412 0.535706 0.892412 0.112066 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 38
Initial state: 0 0.484329 0.258723 0.253528 0.43657 0.386708 0.574946 0.0116297 0.85211 0.241015 0.283742 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 94374 episodes
GETTING ACTION FROM:
action 3, numVisits=94368, meanQ=8.585941, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.484329 0.258723 0.253528 0.43657 0.386708 0.574946 0.0116297 0.85211 0.241015 0.283742 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 39
Initial state: 0 0.336405 0.573557 0.682859 0.471477 0.23063 0.207404 0.488888 0.732841 0.239827 0.206189 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 93593 episodes
GETTING ACTION FROM:
action 3, numVisits=93583, meanQ=8.697206, numObservations: 9
action 1, numVisits=5, meanQ=4.598000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.336405 0.573557 0.682859 0.471477 0.23063 0.207404 0.488888 0.732841 0.239827 0.206189 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=9998, meanQ=9.671685, numObservations: 9
action 2, numVisits=25, meanQ=7.083604, numObservations: 9
action 4, numVisits=8, meanQ=6.120000, numObservations: 7
action 1, numVisits=9, meanQ=4.972222, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 27346 episodes
GETTING ACTION FROM:
action 2, numVisits=1574, meanQ=8.839664, numObservations: 9
action 5, numVisits=35687, meanQ=8.177782, numObservations: 9
action 4, numVisits=14, meanQ=3.478591, numObservations: 8
action 1, numVisits=99, meanQ=-0.204598, numObservations: 9
action -1, numVisits=11, meanQ=-1.550900, numObservations: 10
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=3, meanQ=-352.528616, numObservations: 2
action: 2
Next state: 2 0.336405 0.573557 0.682859 0.471477 0.23063 0.207404 0.488888 0.732841 0.239827 0.206189 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 40
Initial state: 0 0.378228 0.274593 0.384651 0.575315 0.957811 0.641135 0.82902 0.296859 0.985527 0.327467 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 93800 episodes
GETTING ACTION FROM:
action 4, numVisits=93792, meanQ=8.759539, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.378228 0.274593 0.384651 0.575315 0.957811 0.641135 0.82902 0.296859 0.985527 0.327467 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 41
Initial state: 0 0.374893 0.966452 0.231294 0.749081 0.426992 0.5038 0.638038 0.767477 0.394419 0.0461861 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 94632 episodes
GETTING ACTION FROM:
action 3, numVisits=94624, meanQ=8.585041, numObservations: 9
action 4, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.374893 0.966452 0.231294 0.749081 0.426992 0.5038 0.638038 0.767477 0.394419 0.0461861 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 42
Initial state: 0 0.894281 0.760874 0.391727 0.542966 0.530771 0.198894 0.64967 0.782134 0.368716 0.349495 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 93136 episodes
GETTING ACTION FROM:
action 4, numVisits=93130, meanQ=8.563698, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.894281 0.760874 0.391727 0.542966 0.530771 0.198894 0.64967 0.782134 0.368716 0.349495 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 43
Initial state: 0 0.761712 0.190205 0.0726595 0.214986 0.00384879 0.511949 0.853332 0.829223 0.43198 0.502828 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92873 episodes
GETTING ACTION FROM:
action 5, numVisits=92839, meanQ=8.715017, numObservations: 9
action 3, numVisits=15, meanQ=6.931333, numObservations: 5
action 2, numVisits=13, meanQ=6.083846, numObservations: 8
action 4, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.761712 0.190205 0.0726595 0.214986 0.00384879 0.511949 0.853332 0.829223 0.43198 0.502828 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 44
Initial state: 0 0.850098 0.142557 0.79093 0.0223585 0.249887 0.271488 0.372868 0.566348 0.121456 0.0399629 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 93425 episodes
GETTING ACTION FROM:
action 1, numVisits=93397, meanQ=8.602692, numObservations: 9
action 5, numVisits=23, meanQ=6.346535, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.850098 0.142557 0.79093 0.0223585 0.249887 0.271488 0.372868 0.566348 0.121456 0.0399629 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 45
Initial state: 0 0.283833 0.348443 0.842035 0.766775 0.217704 0.382564 0.434138 0.602371 0.69636 0.633131 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92885 episodes
GETTING ACTION FROM:
action 1, numVisits=92858, meanQ=8.479046, numObservations: 9
action 5, numVisits=15, meanQ=5.134013, numObservations: 6
action 3, numVisits=8, meanQ=4.343750, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.283833 0.348443 0.842035 0.766775 0.217704 0.382564 0.434138 0.602371 0.69636 0.633131 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 46
Initial state: 0 0.558277 0.276021 0.652701 0.990169 0.709336 0.964222 0.308182 0.149528 0.386238 0.591848 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 94628 episodes
GETTING ACTION FROM:
action 4, numVisits=94611, meanQ=8.592888, numObservations: 9
action 5, numVisits=10, meanQ=4.499000, numObservations: 6
action 3, numVisits=3, meanQ=1.703333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.558277 0.276021 0.652701 0.990169 0.709336 0.964222 0.308182 0.149528 0.386238 0.591848 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=10234, meanQ=9.546719, numObservations: 9
action 3, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 29372 episodes
GETTING ACTION FROM:
action 2, numVisits=39588, meanQ=8.919257, numObservations: 9
action 3, numVisits=3, meanQ=0.666667, numObservations: 2
action 5, numVisits=4, meanQ=-0.252500, numObservations: 3
action 0, numVisits=9, meanQ=-1.120000, numObservations: 8
action -1, numVisits=8, meanQ=-1.257500, numObservations: 7
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.558277 0.276021 0.652701 0.990169 0.709336 0.964222 0.308182 0.149528 0.386238 0.591848 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 47
Initial state: 0 0.396526 0.540027 0.244821 0.345515 0.793341 0.155919 0.588632 0.656119 0.0545239 0.609102 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 94794 episodes
GETTING ACTION FROM:
action 3, numVisits=94767, meanQ=8.703942, numObservations: 9
action 5, numVisits=19, meanQ=1.157895, numObservations: 7
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=2, meanQ=-4.000000, numObservations: 2
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.396526 0.540027 0.244821 0.345515 0.793341 0.155919 0.588632 0.656119 0.0545239 0.609102 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 48
Initial state: 0 0.122581 0.673436 0.563802 0.00468626 0.954889 0.651552 0.519338 0.694834 0.370991 0.502257 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 94835 episodes
GETTING ACTION FROM:
action 1, numVisits=94822, meanQ=8.758899, numObservations: 9
action 2, numVisits=6, meanQ=5.496683, numObservations: 4
action 3, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.122581 0.673436 0.563802 0.00468626 0.954889 0.651552 0.519338 0.694834 0.370991 0.502257 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 49
Initial state: 0 0.191494 0.124435 0.35819 0.592858 0.248239 0.470503 0.717597 0.488408 0.214458 0.670599 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92968 episodes
GETTING ACTION FROM:
action 5, numVisits=92957, meanQ=8.668234, numObservations: 9
action 1, numVisits=6, meanQ=3.330000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.191494 0.124435 0.35819 0.592858 0.248239 0.470503 0.717597 0.488408 0.214458 0.670599 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=6316, meanQ=10.002534, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 27390 episodes
GETTING ACTION FROM:
action 3, numVisits=33696, meanQ=11.767556, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=7, meanQ=-1.010000, numObservations: 7
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.191494 0.124435 0.35819 0.592858 0.248239 0.470503 0.717597 0.488408 0.214458 0.670599 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=1972, meanQ=18.173840, numObservations: 9
action 1, numVisits=670, meanQ=10.401782, numObservations: 9
action 4, numVisits=71, meanQ=8.598744, numObservations: 9
action 5, numVisits=3, meanQ=5.330033, numObservations: 1
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 27675 episodes
GETTING ACTION FROM:
action 2, numVisits=29647, meanQ=15.469587, numObservations: 9
action 1, numVisits=670, meanQ=10.401782, numObservations: 9
action 4, numVisits=71, meanQ=8.598744, numObservations: 9
action 5, numVisits=3, meanQ=5.330033, numObservations: 1
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.191494 0.124435 0.35819 0.592858 0.248239 0.470503 0.717597 0.488408 0.214458 0.670599 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 50
Initial state: 0 0.406269 0.58716 0.930901 0.131797 0.650277 0.0203635 0.686924 0.364051 0.834024 0.256027 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92748 episodes
GETTING ACTION FROM:
action 1, numVisits=92740, meanQ=8.453081, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.406269 0.58716 0.930901 0.131797 0.650277 0.0203635 0.686924 0.364051 0.834024 0.256027 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
[32m ProblemEnvironment.hpp 351: Done.[39m
