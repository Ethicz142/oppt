Run # 1
Initial state: 0 0.0943235 0.058787 0.188797 0.314847 0.0125298 0.0845533 0.796082 0.487467 0.493561 0.419505 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 84292 episodes
GETTING ACTION FROM:
action 3, numVisits=84282, meanQ=11.987234, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.0943235 0.058787 0.188797 0.314847 0.0125298 0.0845533 0.796082 0.487467 0.493561 0.419505 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 2
Initial state: 0 0.792726 0.837786 0.106861 0.212643 0.501122 0.396141 0.799028 0.570192 0.418613 0.23922 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 86922 episodes
GETTING ACTION FROM:
action 1, numVisits=86903, meanQ=11.979444, numObservations: 9
action 5, numVisits=8, meanQ=0.375000, numObservations: 6
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=5, meanQ=-1.200000, numObservations: 4
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.792726 0.837786 0.106861 0.212643 0.501122 0.396141 0.799028 0.570192 0.418613 0.23922 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 3
Initial state: 0 0.943362 0.0547162 0.652454 0.226016 0.152523 0.919873 0.565009 0.42038 0.681999 0.238983 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 82868 episodes
GETTING ACTION FROM:
action 2, numVisits=82853, meanQ=12.011797, numObservations: 9
action 1, numVisits=8, meanQ=6.845000, numObservations: 5
action 5, numVisits=3, meanQ=4.340033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 2 0.943362 0.0547162 0.652454 0.226016 0.152523 0.919873 0.565009 0.42038 0.681999 0.238983 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 4
Initial state: 0 0.797571 0.310624 0.904289 0.3739 0.12955 0.654163 0.548856 0.454335 0.00844065 0.423774 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 86502 episodes
GETTING ACTION FROM:
action 5, numVisits=86493, meanQ=11.876550, numObservations: 9
action 3, numVisits=4, meanQ=6.500000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.797571 0.310624 0.904289 0.3739 0.12955 0.654163 0.548856 0.454335 0.00844065 0.423774 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=2470, meanQ=12.220412, numObservations: 9
action 1, numVisits=7, meanQ=7.997171, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 25932 episodes
GETTING ACTION FROM:
action 2, numVisits=28341, meanQ=12.518530, numObservations: 9
action 1, numVisits=34, meanQ=7.446942, numObservations: 7
action -1, numVisits=21, meanQ=-1.292857, numObservations: 19
action 0, numVisits=15, meanQ=-1.538000, numObservations: 15
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.797571 0.310624 0.904289 0.3739 0.12955 0.654163 0.548856 0.454335 0.00844065 0.423774 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 5
Initial state: 0 0.365015 0.092518 0.246615 0.431177 0.65103 0.257893 0.587343 0.475272 0.399974 0.141365 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87809 episodes
GETTING ACTION FROM:
action 2, numVisits=87791, meanQ=11.990224, numObservations: 9
action 1, numVisits=6, meanQ=8.998333, numObservations: 4
action 4, numVisits=6, meanQ=7.666667, numObservations: 4
action 5, numVisits=3, meanQ=5.663333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.365015 0.092518 0.246615 0.431177 0.65103 0.257893 0.587343 0.475272 0.399974 0.141365 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=2567, meanQ=12.743468, numObservations: 9
action 3, numVisits=4, meanQ=8.497500, numObservations: 4
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 26698 episodes
GETTING ACTION FROM:
action 4, numVisits=29173, meanQ=13.020416, numObservations: 9
action 3, numVisits=66, meanQ=9.262991, numObservations: 9
action 1, numVisits=16, meanQ=6.331271, numObservations: 8
action -1, numVisits=9, meanQ=-1.230000, numObservations: 8
action 0, numVisits=9, meanQ=-1.230000, numObservations: 8
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.365015 0.092518 0.246615 0.431177 0.65103 0.257893 0.587343 0.475272 0.399974 0.141365 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 6
Initial state: 0 0.908748 0.789708 0.289231 0.594158 0.383747 0.566229 0.0424838 0.456465 0.465634 0.420063 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 84023 episodes
GETTING ACTION FROM:
action 2, numVisits=84011, meanQ=11.926228, numObservations: 9
action 5, numVisits=6, meanQ=7.666667, numObservations: 3
action 4, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.908748 0.789708 0.289231 0.594158 0.383747 0.566229 0.0424838 0.456465 0.465634 0.420063 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=2399, meanQ=12.573740, numObservations: 9
action 3, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 30705 episodes
GETTING ACTION FROM:
action 4, numVisits=33083, meanQ=11.942940, numObservations: 9
action 3, numVisits=3, meanQ=0.666667, numObservations: 3
action 0, numVisits=13, meanQ=-1.086154, numObservations: 13
action -1, numVisits=10, meanQ=-1.307000, numObservations: 10
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 0 0.908748 0.789708 0.289231 0.594158 0.383747 0.566229 0.0424838 0.456465 0.465634 0.420063 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=2330, meanQ=14.073352, numObservations: 9
action 1, numVisits=6, meanQ=-1.264986, numObservations: 4
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=2, meanQ=-4.004950, numObservations: 1
action 5, numVisits=2, meanQ=-7.005000, numObservations: 2
action -1, numVisits=37, meanQ=-27.394642, numObservations: 22
action 0, numVisits=25, meanQ=-42.643386, numObservations: 22
Sampled 38340 episodes
GETTING ACTION FROM:
action 3, numVisits=40670, meanQ=15.179497, numObservations: 9
action 1, numVisits=6, meanQ=-1.264986, numObservations: 4
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=2, meanQ=-4.004950, numObservations: 1
action 5, numVisits=2, meanQ=-7.005000, numObservations: 2
action -1, numVisits=37, meanQ=-27.394642, numObservations: 22
action 0, numVisits=25, meanQ=-42.643386, numObservations: 22
action: 3
Next state: 0 0.908748 0.789708 0.289231 0.594158 0.383747 0.566229 0.0424838 0.456465 0.465634 0.420063 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=995, meanQ=20.550965, numObservations: 9
action 2, numVisits=18, meanQ=14.404444, numObservations: 6
action 5, numVisits=15, meanQ=2.410170, numObservations: 4
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=10, meanQ=-4.003087, numObservations: 8
action -1, numVisits=87, meanQ=-5.190051, numObservations: 35
action 3, numVisits=2, meanQ=-8.241578, numObservations: 2
Sampled 61056 episodes
GETTING ACTION FROM:
action 1, numVisits=62051, meanQ=19.861929, numObservations: 9
action 2, numVisits=18, meanQ=14.404444, numObservations: 6
action 5, numVisits=15, meanQ=2.410170, numObservations: 4
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=10, meanQ=-4.003087, numObservations: 8
action -1, numVisits=87, meanQ=-5.190051, numObservations: 35
action 3, numVisits=2, meanQ=-8.241578, numObservations: 2
action: 1
Next state: 1 0.908748 0.789708 0.289231 0.594158 0.383747 0.566229 0.0424838 0.456465 0.465634 0.420063 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 11.4068
Run # 7
Initial state: 0 0.37407 0.00146859 0.445619 0.452758 0.511232 0.565735 0.343797 0.0484285 0.633401 0.90112 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87517 episodes
GETTING ACTION FROM:
action 2, numVisits=87509, meanQ=12.003275, numObservations: 9
action 5, numVisits=3, meanQ=5.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.37407 0.00146859 0.445619 0.452758 0.511232 0.565735 0.343797 0.0484285 0.633401 0.90112 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 8
Initial state: 0 0.799021 0.613729 0.0302914 0.964189 0.572083 0.467954 0.353986 0.745389 0.347654 0.692259 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88099 episodes
GETTING ACTION FROM:
action 2, numVisits=88089, meanQ=11.966246, numObservations: 9
action 1, numVisits=3, meanQ=5.333333, numObservations: 3
action 4, numVisits=3, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.799021 0.613729 0.0302914 0.964189 0.572083 0.467954 0.353986 0.745389 0.347654 0.692259 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=11024, meanQ=12.528555, numObservations: 9
action 1, numVisits=12, meanQ=4.266667, numObservations: 5
action 3, numVisits=7, meanQ=2.424286, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 31648 episodes
GETTING ACTION FROM:
action 5, numVisits=42670, meanQ=13.701147, numObservations: 9
action 1, numVisits=12, meanQ=4.266667, numObservations: 5
action 3, numVisits=7, meanQ=2.424286, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.799021 0.613729 0.0302914 0.964189 0.572083 0.467954 0.353986 0.745389 0.347654 0.692259 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=3989, meanQ=14.641782, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 27656 episodes
GETTING ACTION FROM:
action 1, numVisits=31645, meanQ=15.730347, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.799021 0.613729 0.0302914 0.964189 0.572083 0.467954 0.353986 0.745389 0.347654 0.692259 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 9
Initial state: 0 0.528544 0.467402 0.961128 0.976175 0.987824 0.140872 0.24332 0.716728 0.737485 0.555946 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 83561 episodes
GETTING ACTION FROM:
action 4, numVisits=83555, meanQ=12.001986, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.528544 0.467402 0.961128 0.976175 0.987824 0.140872 0.24332 0.716728 0.737485 0.555946 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=10494, meanQ=12.854320, numObservations: 9
action 5, numVisits=5, meanQ=10.000000, numObservations: 4
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 30812 episodes
GETTING ACTION FROM:
action 1, numVisits=30563, meanQ=14.879470, numObservations: 9
action 4, numVisits=10497, meanQ=12.856039, numObservations: 9
action 3, numVisits=110, meanQ=5.092227, numObservations: 9
action 0, numVisits=21, meanQ=-1.293329, numObservations: 19
action -1, numVisits=14, meanQ=-1.505000, numObservations: 12
action 5, numVisits=79, meanQ=-1.775142, numObservations: 9
action 2, numVisits=33, meanQ=-23.238403, numObservations: 9
action: 1
Next state: 1 0.528544 0.467402 0.961128 0.976175 0.987824 0.140872 0.24332 0.716728 0.737485 0.555946 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 10
Initial state: 0 0.00597232 0.520393 0.78053 0.999074 0.587019 0.698718 0.485522 0.44655 0.944505 0.200125 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 86969 episodes
GETTING ACTION FROM:
action 4, numVisits=86958, meanQ=11.928241, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 2, numVisits=2, meanQ=-4.000000, numObservations: 2
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.00597232 0.520393 0.78053 0.999074 0.587019 0.698718 0.485522 0.44655 0.944505 0.200125 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=2422, meanQ=12.487786, numObservations: 9
action 3, numVisits=4, meanQ=1.745000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 22072 episodes
GETTING ACTION FROM:
action 5, numVisits=24482, meanQ=13.073484, numObservations: 9
action 3, numVisits=4, meanQ=1.745000, numObservations: 3
action 0, numVisits=8, meanQ=-1.133750, numObservations: 8
action -1, numVisits=6, meanQ=-1.505000, numObservations: 6
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.00597232 0.520393 0.78053 0.999074 0.587019 0.698718 0.485522 0.44655 0.944505 0.200125 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 11
Initial state: 0 0.574839 0.462819 0.880063 0.129891 0.320453 0.913839 0.984621 0.583109 0.0302283 0.792236 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 84338 episodes
GETTING ACTION FROM:
action 4, numVisits=84332, meanQ=11.936778, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.574839 0.462819 0.880063 0.129891 0.320453 0.913839 0.984621 0.583109 0.0302283 0.792236 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 12
Initial state: 0 0.536076 0.543685 0.562907 0.403479 0.26956 0.74665 0.473736 0.491104 0.0763769 0.146551 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88218 episodes
GETTING ACTION FROM:
action 2, numVisits=88192, meanQ=11.771277, numObservations: 9
action 3, numVisits=15, meanQ=2.538000, numObservations: 8
action 1, numVisits=7, meanQ=1.714314, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.536076 0.543685 0.562907 0.403479 0.26956 0.74665 0.473736 0.491104 0.0763769 0.146551 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 13
Initial state: 0 0.190601 0.840351 0.344588 0.761616 0.261605 0.16413 0.555762 0.419716 0.253357 0.228709 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87766 episodes
GETTING ACTION FROM:
action 5, numVisits=87749, meanQ=12.016424, numObservations: 9
action 3, numVisits=6, meanQ=8.998333, numObservations: 5
action 1, numVisits=3, meanQ=3.000000, numObservations: 2
action 2, numVisits=3, meanQ=3.000000, numObservations: 3
action 4, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 5
Next state: 0 0.190601 0.840351 0.344588 0.761616 0.261605 0.16413 0.555762 0.419716 0.253357 0.228709 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=9282, meanQ=12.861419, numObservations: 9
action 3, numVisits=20, meanQ=8.287515, numObservations: 7
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 28873 episodes
GETTING ACTION FROM:
action 1, numVisits=38149, meanQ=11.852572, numObservations: 9
action 3, numVisits=21, meanQ=7.369062, numObservations: 7
action 2, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.190601 0.840351 0.344588 0.761616 0.261605 0.16413 0.555762 0.419716 0.253357 0.228709 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=3406, meanQ=14.760056, numObservations: 9
action 4, numVisits=7, meanQ=7.424286, numObservations: 6
action 1, numVisits=5, meanQ=6.998040, numObservations: 1
action 5, numVisits=3, meanQ=5.330033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 28919 episodes
GETTING ACTION FROM:
action 2, numVisits=32323, meanQ=13.368227, numObservations: 9
action 4, numVisits=7, meanQ=7.424286, numObservations: 6
action 1, numVisits=5, meanQ=6.998040, numObservations: 1
action 5, numVisits=3, meanQ=5.330033, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.190601 0.840351 0.344588 0.761616 0.261605 0.16413 0.555762 0.419716 0.253357 0.228709 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 14
Initial state: 0 0.569048 0.37541 0.718273 0.801323 0.019183 0.253373 0.601969 0.794705 0.977606 0.074516 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87393 episodes
GETTING ACTION FROM:
action 1, numVisits=87378, meanQ=11.713995, numObservations: 9
action 5, numVisits=6, meanQ=7.018333, numObservations: 3
action 3, numVisits=5, meanQ=6.196000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.569048 0.37541 0.718273 0.801323 0.019183 0.253373 0.601969 0.794705 0.977606 0.074516 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 15
Initial state: 0 0.641823 0.869359 0.326457 0.446675 0.488213 0.480578 0.552064 0.255073 0.100138 0.685141 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88264 episodes
GETTING ACTION FROM:
action 1, numVisits=88143, meanQ=11.946992, numObservations: 9
action 3, numVisits=107, meanQ=11.125211, numObservations: 9
action 5, numVisits=10, meanQ=8.508000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.641823 0.869359 0.326457 0.446675 0.488213 0.480578 0.552064 0.255073 0.100138 0.685141 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 16
Initial state: 0 0.181683 0.201456 0.231575 0.807557 0.472414 0.475226 0.626426 0.0610371 0.47763 0.692352 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88071 episodes
GETTING ACTION FROM:
action 3, numVisits=88065, meanQ=12.001393, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.181683 0.201456 0.231575 0.807557 0.472414 0.475226 0.626426 0.0610371 0.47763 0.692352 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 17
Initial state: 0 0.659751 0.612054 0.542469 0.92417 0.308992 0.713484 0.413732 0.808791 0.434784 0.382444 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88034 episodes
GETTING ACTION FROM:
action 3, numVisits=88026, meanQ=11.904698, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.659751 0.612054 0.542469 0.92417 0.308992 0.713484 0.413732 0.808791 0.434784 0.382444 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=10974, meanQ=12.715912, numObservations: 9
action 2, numVisits=7, meanQ=5.715729, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 32075 episodes
GETTING ACTION FROM:
action 1, numVisits=43042, meanQ=14.596892, numObservations: 9
action 2, numVisits=9, meanQ=5.995826, numObservations: 7
action -1, numVisits=4, meanQ=-1.505000, numObservations: 4
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=3, meanQ=-5.099858, numObservations: 2
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.659751 0.612054 0.542469 0.92417 0.308992 0.713484 0.413732 0.808791 0.434784 0.382444 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 18
Initial state: 0 0.204093 0.201245 0.866315 0.411462 0.092175 0.949324 0.0752538 0.0785486 0.450406 0.423773 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88230 episodes
GETTING ACTION FROM:
action 4, numVisits=88224, meanQ=11.937511, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.204093 0.201245 0.866315 0.411462 0.092175 0.949324 0.0752538 0.0785486 0.450406 0.423773 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=1269, meanQ=12.603413, numObservations: 9
action 3, numVisits=48, meanQ=7.209602, numObservations: 9
action 1, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 84892 episodes
GETTING ACTION FROM:
action 5, numVisits=86127, meanQ=6.794754, numObservations: 9
action 3, numVisits=60, meanQ=5.317682, numObservations: 9
action 1, numVisits=9, meanQ=1.667683, numObservations: 6
action 0, numVisits=9, meanQ=-1.780000, numObservations: 9
action -1, numVisits=8, meanQ=-1.876250, numObservations: 8
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.204093 0.201245 0.866315 0.411462 0.092175 0.949324 0.0752538 0.0785486 0.450406 0.423773 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 19
Initial state: 0 0.213858 0.489688 0.559098 0.478136 0.26876 0.0833145 0.382117 0.523804 0.309271 0.0197029 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88326 episodes
GETTING ACTION FROM:
action 5, numVisits=88320, meanQ=12.027384, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.213858 0.489688 0.559098 0.478136 0.26876 0.0833145 0.382117 0.523804 0.309271 0.0197029 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=9387, meanQ=12.686661, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 24791 episodes
GETTING ACTION FROM:
action 4, numVisits=34176, meanQ=12.354326, numObservations: 9
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action -1, numVisits=3, meanQ=-1.340000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 1 0.213858 0.489688 0.559098 0.478136 0.26876 0.0833145 0.382117 0.523804 0.309271 0.0197029 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 20
Initial state: 0 0.707278 0.290932 0.300794 0.773252 0.0872743 0.96769 0.473425 0.464948 0.656404 0.695271 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87340 episodes
GETTING ACTION FROM:
action 3, numVisits=87334, meanQ=11.854417, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.707278 0.290932 0.300794 0.773252 0.0872743 0.96769 0.473425 0.464948 0.656404 0.695271 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 21
Initial state: 0 0.513595 0.399808 0.969204 0.249492 0.341255 0.712297 0.407252 0.848306 0.808986 0.139348 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 85041 episodes
GETTING ACTION FROM:
action 4, numVisits=85033, meanQ=11.933673, numObservations: 9
action 2, numVisits=3, meanQ=5.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.513595 0.399808 0.969204 0.249492 0.341255 0.712297 0.407252 0.848306 0.808986 0.139348 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=10550, meanQ=12.995396, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 1, numVisits=2, meanQ=-4.004950, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 28198 episodes
GETTING ACTION FROM:
action 3, numVisits=28022, meanQ=15.172858, numObservations: 9
action 4, numVisits=10551, meanQ=12.995012, numObservations: 9
action 1, numVisits=4, meanQ=-6.002450, numObservations: 2
action 2, numVisits=42, meanQ=-10.259306, numObservations: 8
action 5, numVisits=2, meanQ=-11.000000, numObservations: 2
action 0, numVisits=76, meanQ=-13.595636, numObservations: 51
action -1, numVisits=70, meanQ=-16.179098, numObservations: 52
action: 3
Next state: 0 0.513595 0.399808 0.969204 0.249492 0.341255 0.712297 0.407252 0.848306 0.808986 0.139348 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=2141, meanQ=16.274003, numObservations: 9
action 1, numVisits=2, meanQ=6.584349, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-9.941696, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-1068.537207, numObservations: 1
Sampled 34843 episodes
GETTING ACTION FROM:
action 5, numVisits=36984, meanQ=17.242489, numObservations: 9
action 1, numVisits=2, meanQ=6.584349, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-9.941696, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-1068.537207, numObservations: 1
action: 5
Next state: 2 0.513595 0.399808 0.969204 0.249492 0.341255 0.712297 0.407252 0.848306 0.808986 0.139348 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -18.7411
Run # 22
Initial state: 0 0.475408 0.47441 0.187534 0.944805 0.209205 0.0961269 0.21991 0.105741 0.918345 0.52751 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87543 episodes
GETTING ACTION FROM:
action 1, numVisits=87537, meanQ=12.018322, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.475408 0.47441 0.187534 0.944805 0.209205 0.0961269 0.21991 0.105741 0.918345 0.52751 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 23
Initial state: 0 0.69633 0.878694 0.428246 0.413387 0.940709 0.924377 0.687618 0.643015 0.840254 0.631142 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87059 episodes
GETTING ACTION FROM:
action 2, numVisits=87052, meanQ=11.790060, numObservations: 9
action 4, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.69633 0.878694 0.428246 0.413387 0.940709 0.924377 0.687618 0.643015 0.840254 0.631142 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 24
Initial state: 0 0.970292 0.293245 0.273552 0.904274 0.129372 0.684626 0.825863 0.583422 0.480523 0.379401 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88361 episodes
GETTING ACTION FROM:
action 5, numVisits=88351, meanQ=12.030464, numObservations: 9
action 2, numVisits=5, meanQ=5.800000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 1 0.970292 0.293245 0.273552 0.904274 0.129372 0.684626 0.825863 0.583422 0.480523 0.379401 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 25
Initial state: 0 0.698723 0.334747 0.786058 0.780188 0.454538 0.418259 0.719883 0.0812657 0.878212 0.289541 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87966 episodes
GETTING ACTION FROM:
action 1, numVisits=87941, meanQ=11.798144, numObservations: 9
action 2, numVisits=20, meanQ=7.825505, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.698723 0.334747 0.786058 0.780188 0.454538 0.418259 0.719883 0.0812657 0.878212 0.289541 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 26
Initial state: 0 0.168335 0.899813 0.174878 0.081065 0.506483 0.377458 0.846228 0.658543 0.419828 0.127798 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88398 episodes
GETTING ACTION FROM:
action 2, numVisits=88392, meanQ=11.948776, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.168335 0.899813 0.174878 0.081065 0.506483 0.377458 0.846228 0.658543 0.419828 0.127798 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=9334, meanQ=12.518822, numObservations: 9
action 1, numVisits=5, meanQ=6.196000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 28511 episodes
GETTING ACTION FROM:
action 3, numVisits=37689, meanQ=11.821791, numObservations: 9
action 1, numVisits=157, meanQ=9.925169, numObservations: 9
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action -1, numVisits=3, meanQ=-1.340000, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.168335 0.899813 0.174878 0.081065 0.506483 0.377458 0.846228 0.658543 0.419828 0.127798 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 27
Initial state: 0 0.420443 0.441847 0.586577 0.413984 0.953789 0.402421 0.257887 0.41404 0.396014 0.349583 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 84749 episodes
GETTING ACTION FROM:
action 2, numVisits=84743, meanQ=11.997965, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.420443 0.441847 0.586577 0.413984 0.953789 0.402421 0.257887 0.41404 0.396014 0.349583 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 28
Initial state: 0 0.729054 0.234312 0.550273 0.382897 0.488147 0.626219 0.757192 0.235987 0.0814445 0.00980601 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 86903 episodes
GETTING ACTION FROM:
action 5, numVisits=86876, meanQ=11.920211, numObservations: 9
action 3, numVisits=18, meanQ=6.798889, numObservations: 9
action 4, numVisits=5, meanQ=5.998000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 0 0.729054 0.234312 0.550273 0.382897 0.488147 0.626219 0.757192 0.235987 0.0814445 0.00980601 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=8846, meanQ=11.959749, numObservations: 9
action 2, numVisits=304, meanQ=10.320238, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 25510 episodes
GETTING ACTION FROM:
action 3, numVisits=34351, meanQ=11.447137, numObservations: 9
action 2, numVisits=304, meanQ=10.320238, numObservations: 9
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action -1, numVisits=3, meanQ=-1.340000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.729054 0.234312 0.550273 0.382897 0.488147 0.626219 0.757192 0.235987 0.0814445 0.00980601 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 29
Initial state: 0 0.28556 0.0843834 0.918988 0.179357 0.337662 0.976425 0.541014 0.426498 0.574931 0.603069 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88002 episodes
GETTING ACTION FROM:
action 1, numVisits=87996, meanQ=11.891788, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.28556 0.0843834 0.918988 0.179357 0.337662 0.976425 0.541014 0.426498 0.574931 0.603069 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=9287, meanQ=12.539341, numObservations: 9
action 4, numVisits=13, meanQ=2.997715, numObservations: 7
action 5, numVisits=8, meanQ=2.247513, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 29862 episodes
GETTING ACTION FROM:
action 3, numVisits=39143, meanQ=11.528069, numObservations: 9
action 4, numVisits=13, meanQ=2.997715, numObservations: 7
action 5, numVisits=8, meanQ=2.247513, numObservations: 5
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action -1, numVisits=4, meanQ=-1.257500, numObservations: 4
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.28556 0.0843834 0.918988 0.179357 0.337662 0.976425 0.541014 0.426498 0.574931 0.603069 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=3341, meanQ=14.938387, numObservations: 9
action 3, numVisits=3, meanQ=5.330033, numObservations: 1
action 5, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 18130 episodes
GETTING ACTION FROM:
action 2, numVisits=21469, meanQ=15.513406, numObservations: 9
action 3, numVisits=3, meanQ=5.330033, numObservations: 1
action 5, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.28556 0.0843834 0.918988 0.179357 0.337662 0.976425 0.541014 0.426498 0.574931 0.603069 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -18.7411
Run # 30
Initial state: 0 0.922457 0.0910839 0.536084 0.411834 0.811889 0.968393 0.338201 0.0807137 0.720293 0.0767616 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88083 episodes
GETTING ACTION FROM:
action 4, numVisits=88069, meanQ=11.956798, numObservations: 9
action 1, numVisits=8, meanQ=8.876262, numObservations: 6
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.922457 0.0910839 0.536084 0.411834 0.811889 0.968393 0.338201 0.0807137 0.720293 0.0767616 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=9500, meanQ=12.820522, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 22882 episodes
GETTING ACTION FROM:
action 3, numVisits=32378, meanQ=12.187406, numObservations: 9
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action -1, numVisits=3, meanQ=-1.340000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.922457 0.0910839 0.536084 0.411834 0.811889 0.968393 0.338201 0.0807137 0.720293 0.0767616 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 31
Initial state: 0 0.455674 0.359056 0.249212 0.123912 0.804177 0.612228 0.0930914 0.34902 0.0986778 0.173107 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88202 episodes
GETTING ACTION FROM:
action 5, numVisits=88190, meanQ=12.038579, numObservations: 9
action 3, numVisits=5, meanQ=3.000000, numObservations: 4
action 4, numVisits=3, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.455674 0.359056 0.249212 0.123912 0.804177 0.612228 0.0930914 0.34902 0.0986778 0.173107 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=9216, meanQ=13.137408, numObservations: 9
action 3, numVisits=26, meanQ=8.337319, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 24247 episodes
GETTING ACTION FROM:
action 2, numVisits=33459, meanQ=12.371333, numObservations: 9
action 3, numVisits=26, meanQ=8.337319, numObservations: 9
action -1, numVisits=3, meanQ=-1.340000, numObservations: 3
action 0, numVisits=3, meanQ=-1.340000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.455674 0.359056 0.249212 0.123912 0.804177 0.612228 0.0930914 0.34902 0.0986778 0.173107 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=2968, meanQ=15.376926, numObservations: 9
action 4, numVisits=22, meanQ=11.761818, numObservations: 8
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 13990 episodes
GETTING ACTION FROM:
action 3, numVisits=16924, meanQ=13.846904, numObservations: 9
action 4, numVisits=56, meanQ=11.164485, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.455674 0.359056 0.249212 0.123912 0.804177 0.612228 0.0930914 0.34902 0.0986778 0.173107 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 32
Initial state: 0 0.333816 0.84778 0.064164 0.839253 0.758917 0.483519 0.805484 0.730913 0.4296 0.39047 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88427 episodes
GETTING ACTION FROM:
action 2, numVisits=88369, meanQ=11.893357, numObservations: 9
action 1, numVisits=28, meanQ=10.466789, numObservations: 9
action 4, numVisits=21, meanQ=9.359062, numObservations: 9
action 5, numVisits=6, meanQ=7.831667, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.333816 0.84778 0.064164 0.839253 0.758917 0.483519 0.805484 0.730913 0.4296 0.39047 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1264, meanQ=12.230550, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 50199 episodes
GETTING ACTION FROM:
action 1, numVisits=51463, meanQ=14.304134, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.333816 0.84778 0.064164 0.839253 0.758917 0.483519 0.805484 0.730913 0.4296 0.39047 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 33
Initial state: 0 0.419777 0.0615139 0.572496 0.355291 0.589906 0.0413109 0.074044 0.929667 0.741886 0.153663 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87602 episodes
GETTING ACTION FROM:
action 3, numVisits=87596, meanQ=11.964689, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.419777 0.0615139 0.572496 0.355291 0.589906 0.0413109 0.074044 0.929667 0.741886 0.153663 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=9197, meanQ=12.766279, numObservations: 9
action 1, numVisits=9, meanQ=3.330000, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 22310 episodes
GETTING ACTION FROM:
action 2, numVisits=31501, meanQ=12.130034, numObservations: 9
action 1, numVisits=9, meanQ=3.330000, numObservations: 8
action -1, numVisits=4, meanQ=-1.257500, numObservations: 4
action 0, numVisits=4, meanQ=-1.257500, numObservations: 4
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.419777 0.0615139 0.572496 0.355291 0.589906 0.0413109 0.074044 0.929667 0.741886 0.153663 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 34
Initial state: 0 0.495112 0.878527 0.525565 0.402351 0.951719 0.164711 0.988845 0.835856 0.254946 0.992958 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87808 episodes
GETTING ACTION FROM:
action 1, numVisits=76416, meanQ=11.994106, numObservations: 9
action 3, numVisits=11373, meanQ=11.911688, numObservations: 9
action 2, numVisits=15, meanQ=9.866020, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.495112 0.878527 0.525565 0.402351 0.951719 0.164711 0.988845 0.835856 0.254946 0.992958 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 35
Initial state: 0 0.227964 0.678386 0.762782 0.898802 0.436805 0.434818 0.183683 0.592115 0.811013 0.80665 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87845 episodes
GETTING ACTION FROM:
action 1, numVisits=87837, meanQ=11.885608, numObservations: 9
action 2, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.227964 0.678386 0.762782 0.898802 0.436805 0.434818 0.183683 0.592115 0.811013 0.80665 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 36
Initial state: 0 0.460103 0.184457 0.529722 0.474393 0.916097 0.844458 0.776824 0.61243 0.775133 0.00303605 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 86619 episodes
GETTING ACTION FROM:
action 1, numVisits=86613, meanQ=11.903773, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.460103 0.184457 0.529722 0.474393 0.916097 0.844458 0.776824 0.61243 0.775133 0.00303605 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 37
Initial state: 0 0.0508789 0.925493 0.467929 0.422476 0.00324058 0.171982 0.104545 0.524303 0.723527 0.950658 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88128 episodes
GETTING ACTION FROM:
action 3, numVisits=88120, meanQ=11.969084, numObservations: 9
action 5, numVisits=3, meanQ=5.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.0508789 0.925493 0.467929 0.422476 0.00324058 0.171982 0.104545 0.524303 0.723527 0.950658 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=10992, meanQ=12.916118, numObservations: 9
action 4, numVisits=9, meanQ=8.106667, numObservations: 5
action 3, numVisits=4, meanQ=7.525000, numObservations: 1
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 36881 episodes
GETTING ACTION FROM:
action 5, numVisits=47856, meanQ=14.344471, numObservations: 9
action 3, numVisits=8, meanQ=10.901250, numObservations: 1
action 1, numVisits=10, meanQ=6.987044, numObservations: 5
action 4, numVisits=10, meanQ=6.462514, numObservations: 6
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action -1, numVisits=3, meanQ=-1.340000, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 1 0.0508789 0.925493 0.467929 0.422476 0.00324058 0.171982 0.104545 0.524303 0.723527 0.950658 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 38
Initial state: 0 0.0752228 0.521927 0.379868 0.314853 0.758675 0.562721 0.222268 0.887696 0.427791 0.365111 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88140 episodes
GETTING ACTION FROM:
action 2, numVisits=88124, meanQ=12.039149, numObservations: 9
action 5, numVisits=7, meanQ=7.141429, numObservations: 6
action 1, numVisits=3, meanQ=4.340033, numObservations: 2
action 4, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.0752228 0.521927 0.379868 0.314853 0.758675 0.562721 0.222268 0.887696 0.427791 0.365111 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=9412, meanQ=12.774583, numObservations: 9
action 5, numVisits=3, meanQ=5.330033, numObservations: 2
action 3, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 27400 episodes
GETTING ACTION FROM:
action 4, numVisits=36803, meanQ=11.245964, numObservations: 9
action 5, numVisits=4, meanQ=1.451256, numObservations: 3
action 3, numVisits=4, meanQ=-0.252500, numObservations: 4
action -1, numVisits=5, meanQ=-1.010000, numObservations: 5
action 0, numVisits=4, meanQ=-1.257500, numObservations: 4
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.0752228 0.521927 0.379868 0.314853 0.758675 0.562721 0.222268 0.887696 0.427791 0.365111 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=3112, meanQ=15.594936, numObservations: 9
action 1, numVisits=17, meanQ=12.393660, numObservations: 8
action 3, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 28007 episodes
GETTING ACTION FROM:
action 5, numVisits=31118, meanQ=15.091222, numObservations: 9
action 1, numVisits=18, meanQ=10.919293, numObservations: 8
action 3, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 1 0.0752228 0.521927 0.379868 0.314853 0.758675 0.562721 0.222268 0.887696 0.427791 0.365111 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 39
Initial state: 0 0.594861 0.521404 0.977754 0.794215 0.286766 0.338574 0.692194 0.997152 0.474946 0.375293 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87741 episodes
GETTING ACTION FROM:
action 4, numVisits=87735, meanQ=11.730812, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.594861 0.521404 0.977754 0.794215 0.286766 0.338574 0.692194 0.997152 0.474946 0.375293 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 40
Initial state: 0 0.276128 0.707028 0.463302 0.352942 0.685926 0.156574 0.084775 0.74812 0.512257 0.167104 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87091 episodes
GETTING ACTION FROM:
action 4, numVisits=87076, meanQ=11.919744, numObservations: 9
action 3, numVisits=8, meanQ=8.250000, numObservations: 5
action 2, numVisits=3, meanQ=5.663333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.276128 0.707028 0.463302 0.352942 0.685926 0.156574 0.084775 0.74812 0.512257 0.167104 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 41
Initial state: 0 0.0898871 0.934861 0.811513 0.758512 0.903969 0.0368314 0.902676 0.371232 0.506408 0.479415 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87290 episodes
GETTING ACTION FROM:
action 2, numVisits=87254, meanQ=12.067041, numObservations: 9
action 4, numVisits=24, meanQ=9.533346, numObservations: 9
action 5, numVisits=8, meanQ=7.877512, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.0898871 0.934861 0.811513 0.758512 0.903969 0.0368314 0.902676 0.371232 0.506408 0.479415 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 42
Initial state: 0 0.759926 0.572327 0.716874 0.487481 0.00321381 0.0645998 0.582601 0.399396 0.475031 0.946555 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 86871 episodes
GETTING ACTION FROM:
action 3, numVisits=86810, meanQ=11.819465, numObservations: 9
action 1, numVisits=56, meanQ=8.627693, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.759926 0.572327 0.716874 0.487481 0.00321381 0.0645998 0.582601 0.399396 0.475031 0.946555 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=9341, meanQ=12.283900, numObservations: 9
action 4, numVisits=3, meanQ=3.330000, numObservations: 3
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 25774 episodes
GETTING ACTION FROM:
action 1, numVisits=35112, meanQ=12.358587, numObservations: 9
action 4, numVisits=3, meanQ=3.330000, numObservations: 3
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.759926 0.572327 0.716874 0.487481 0.00321381 0.0645998 0.582601 0.399396 0.475031 0.946555 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 43
Initial state: 0 0.481605 0.777351 0.0519425 0.145995 0.577776 0.415426 0.527361 0.691312 0.654333 0.72433 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88315 episodes
GETTING ACTION FROM:
action 3, numVisits=88300, meanQ=11.962492, numObservations: 9
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 5, numVisits=4, meanQ=-1.472500, numObservations: 3
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.481605 0.777351 0.0519425 0.145995 0.577776 0.415426 0.527361 0.691312 0.654333 0.72433 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 44
Initial state: 0 0.143252 0.824843 0.225605 0.649166 0.481384 0.396726 0.989421 0.550072 0.0870986 0.247744 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87957 episodes
GETTING ACTION FROM:
action 3, numVisits=87938, meanQ=12.010822, numObservations: 9
action 2, numVisits=7, meanQ=4.394286, numObservations: 5
action 4, numVisits=3, meanQ=3.000000, numObservations: 3
action 5, numVisits=3, meanQ=3.000000, numObservations: 3
action 1, numVisits=4, meanQ=1.000025, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.143252 0.824843 0.225605 0.649166 0.481384 0.396726 0.989421 0.550072 0.0870986 0.247744 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 45
Initial state: 0 0.769491 0.504044 0.471487 0.417615 0.895688 0.706704 0.38501 0.684956 0.0823546 0.197542 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87396 episodes
GETTING ACTION FROM:
action 1, numVisits=87382, meanQ=12.038734, numObservations: 9
action 4, numVisits=9, meanQ=6.747778, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.769491 0.504044 0.471487 0.417615 0.895688 0.706704 0.38501 0.684956 0.0823546 0.197542 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 46
Initial state: 0 0.541095 0.367636 0.632274 0.293981 0.80114 0.720101 0.586554 0.0424071 0.601152 0.335288 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 83262 episodes
GETTING ACTION FROM:
action 5, numVisits=83254, meanQ=11.649823, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.541095 0.367636 0.632274 0.293981 0.80114 0.720101 0.586554 0.0424071 0.601152 0.335288 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 47
Initial state: 0 0.254901 0.426569 0.512601 0.45916 0.472807 0.237544 0.613279 0.42407 0.525622 0.0607347 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87131 episodes
GETTING ACTION FROM:
action 2, numVisits=87125, meanQ=11.980024, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.254901 0.426569 0.512601 0.45916 0.472807 0.237544 0.613279 0.42407 0.525622 0.0607347 w: 1
Observation: 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=1503, meanQ=12.324479, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.671650, numObservations: 5
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 47876 episodes
GETTING ACTION FROM:
action 3, numVisits=49369, meanQ=9.598363, numObservations: 9
action -1, numVisits=14, meanQ=-1.292857, numObservations: 14
action 0, numVisits=9, meanQ=-1.671100, numObservations: 8
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.254901 0.426569 0.512601 0.45916 0.472807 0.237544 0.613279 0.42407 0.525622 0.0607347 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=149, meanQ=15.792087, numObservations: 9
action 0, numVisits=11, meanQ=-1.010000, numObservations: 11
action -1, numVisits=8, meanQ=-1.258738, numObservations: 7
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 67042 episodes
GETTING ACTION FROM:
action 5, numVisits=67191, meanQ=14.239120, numObservations: 9
action 0, numVisits=11, meanQ=-1.010000, numObservations: 11
action -1, numVisits=8, meanQ=-1.258738, numObservations: 7
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.254901 0.426569 0.512601 0.45916 0.472807 0.237544 0.613279 0.42407 0.525622 0.0607347 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -18.7411
Run # 48
Initial state: 0 0.690429 0.91837 0.80498 0.0109241 0.466342 0.35895 0.118578 0.96868 0.306125 0.736053 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87728 episodes
GETTING ACTION FROM:
action 5, numVisits=87717, meanQ=11.669531, numObservations: 9
action 3, numVisits=3, meanQ=3.000000, numObservations: 2
action 1, numVisits=4, meanQ=1.250000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 0 0.690429 0.91837 0.80498 0.0109241 0.466342 0.35895 0.118578 0.96868 0.306125 0.736053 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=2362, meanQ=12.720588, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 23698 episodes
GETTING ACTION FROM:
action 3, numVisits=26050, meanQ=13.159516, numObservations: 9
action 0, numVisits=6, meanQ=-1.505000, numObservations: 6
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=5, meanQ=-3.386000, numObservations: 4
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 3
Next state: 0 0.690429 0.91837 0.80498 0.0109241 0.466342 0.35895 0.118578 0.96868 0.306125 0.736053 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action -1, numVisits=55, meanQ=3.852047, numObservations: 32
action 4, numVisits=136, meanQ=3.685697, numObservations: 9
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=123, meanQ=-5.001636, numObservations: 60
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=19, meanQ=-49.792066, numObservations: 7
Sampled 81876 episodes
GETTING ACTION FROM:
action 3, numVisits=163, meanQ=22.777607, numObservations: 8
action 4, numVisits=81426, meanQ=17.201609, numObservations: 9
action -1, numVisits=479, meanQ=-1.793906, numObservations: 101
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=123, meanQ=-5.001636, numObservations: 60
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=19, meanQ=-49.792066, numObservations: 7
action: 3
Next state: 1 0.690429 0.91837 0.80498 0.0109241 0.466342 0.35895 0.118578 0.96868 0.306125 0.736053 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 49
Initial state: 0 0.242173 0.752796 0.316737 0.293 0.264344 0.987816 0.439455 0.399329 0.661961 0.558699 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 84003 episodes
GETTING ACTION FROM:
action 4, numVisits=83993, meanQ=11.814431, numObservations: 9
action 5, numVisits=3, meanQ=5.333333, numObservations: 3
action 1, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.242173 0.752796 0.316737 0.293 0.264344 0.987816 0.439455 0.399329 0.661961 0.558699 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 50
Initial state: 0 0.62446 0.813349 0.689561 0.234417 0.506468 0.366122 0.134166 0.885332 0.904561 0.143025 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87732 episodes
GETTING ACTION FROM:
action 5, numVisits=87717, meanQ=11.854804, numObservations: 9
action 3, numVisits=8, meanQ=8.752512, numObservations: 4
action 4, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 2 0.62446 0.813349 0.689561 0.234417 0.506468 0.366122 0.134166 0.885332 0.904561 0.143025 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
[32m ProblemEnvironment.hpp 351: Done.[39m
