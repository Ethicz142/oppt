Run # 1
Initial state: 0 0.335581 0.118257 0.950801 0.741319 0.643406 0.568632 0.727544 0.547185 0.520927 0.609526 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 77159 episodes
GETTING ACTION FROM:
action 4, numVisits=77153, meanQ=8.266600, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.335581 0.118257 0.950801 0.741319 0.643406 0.568632 0.727544 0.547185 0.520927 0.609526 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 2
Initial state: 0 0.403505 0.565647 0.954878 0.842195 0.311874 0.213504 0.0978788 0.0689145 0.550461 0.591572 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80781 episodes
GETTING ACTION FROM:
action 5, numVisits=80768, meanQ=7.778214, numObservations: 9
action 2, numVisits=8, meanQ=3.875000, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.403505 0.565647 0.954878 0.842195 0.311874 0.213504 0.0978788 0.0689145 0.550461 0.591572 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 3
Initial state: 0 0.149986 0.0695107 0.78889 0.874702 0.514968 0.649957 0.739692 0.243407 0.520865 0.200056 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79277 episodes
GETTING ACTION FROM:
action 4, numVisits=79271, meanQ=8.047915, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.149986 0.0695107 0.78889 0.874702 0.514968 0.649957 0.739692 0.243407 0.520865 0.200056 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 4
Initial state: 0 0.889422 0.760797 0.965507 0.241278 0.424415 0.269162 0.747693 0.590281 0.590862 0.65295 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 82397 episodes
GETTING ACTION FROM:
action 1, numVisits=82374, meanQ=8.079586, numObservations: 9
action 4, numVisits=16, meanQ=5.536875, numObservations: 8
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.889422 0.760797 0.965507 0.241278 0.424415 0.269162 0.747693 0.590281 0.590862 0.65295 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 5
Initial state: 0 0.643643 0.846158 0.34633 0.366614 0.21147 0.0183226 0.4885 0.601545 0.734674 0.117453 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 78544 episodes
GETTING ACTION FROM:
action 4, numVisits=78520, meanQ=8.034693, numObservations: 9
action 1, numVisits=8, meanQ=1.000025, numObservations: 4
action 5, numVisits=7, meanQ=0.857157, numObservations: 5
action 3, numVisits=4, meanQ=-0.500000, numObservations: 3
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.643643 0.846158 0.34633 0.366614 0.21147 0.0183226 0.4885 0.601545 0.734674 0.117453 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 6
Initial state: 0 0.00612109 0.869114 0.752281 0.0626505 0.587657 0.614289 0.202267 0.980444 0.192352 0.67233 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 81964 episodes
GETTING ACTION FROM:
action 4, numVisits=81928, meanQ=7.969284, numObservations: 9
action 5, numVisits=28, meanQ=4.288943, numObservations: 7
action 2, numVisits=4, meanQ=1.497500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 1 0.00612109 0.869114 0.752281 0.0626505 0.587657 0.614289 0.202267 0.980444 0.192352 0.67233 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 7
Initial state: 0 0.695595 0.364526 0.940455 0.00594987 0.949456 0.0445514 0.320589 0.887131 0.625561 0.665695 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 50326 episodes
GETTING ACTION FROM:
action -1, numVisits=50305, meanQ=13.013241, numObservations: 243
action 3, numVisits=9, meanQ=-1.753333, numObservations: 5
action 0, numVisits=8, meanQ=-2.495000, numObservations: 7
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.695595 0.364526 0.940455 0.00594987 0.949456 0.0445514 0.320589 0.887131 0.625561 0.665695 w: 1
Observation: 0 3 0 3 0 3 0 1 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=220, meanQ=19.377945, numObservations: 9
action 3, numVisits=18, meanQ=6.943889, numObservations: 6
action 1, numVisits=5, meanQ=4.598000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 113435 episodes
GETTING ACTION FROM:
action 5, numVisits=113655, meanQ=21.390309, numObservations: 9
action 3, numVisits=18, meanQ=6.943889, numObservations: 6
action 1, numVisits=5, meanQ=4.598000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 1 0.695595 0.364526 0.940455 0.00594987 0.949456 0.0445514 0.320589 0.887131 0.625561 0.665695 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 8
Initial state: 0 0.514402 0.190464 0.690786 0.436012 0.778333 0.93141 0.546261 0.575654 0.12483 0.291738 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80080 episodes
GETTING ACTION FROM:
action 5, numVisits=79558, meanQ=8.053506, numObservations: 9
action 4, numVisits=517, meanQ=7.765631, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.514402 0.190464 0.690786 0.436012 0.778333 0.93141 0.546261 0.575654 0.12483 0.291738 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=2004, meanQ=9.270664, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 74329 episodes
GETTING ACTION FROM:
action 3, numVisits=76215, meanQ=3.992289, numObservations: 9
action -1, numVisits=63, meanQ=-1.827143, numObservations: 53
action 0, numVisits=54, meanQ=-1.890000, numObservations: 38
action 1, numVisits=2, meanQ=-6.781910, numObservations: 2
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action 4, numVisits=2, meanQ=-7.005000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.514402 0.190464 0.690786 0.436012 0.778333 0.93141 0.546261 0.575654 0.12483 0.291738 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 9
Initial state: 0 0.10168 0.0588368 0.420149 0.156128 0.735799 0.302059 0.203405 0.775803 0.532176 0.586238 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79832 episodes
GETTING ACTION FROM:
action 4, numVisits=79820, meanQ=8.061412, numObservations: 9
action 1, numVisits=4, meanQ=2.750025, numObservations: 3
action 5, numVisits=4, meanQ=-0.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.10168 0.0588368 0.420149 0.156128 0.735799 0.302059 0.203405 0.775803 0.532176 0.586238 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=7247, meanQ=9.585949, numObservations: 9
action 3, numVisits=64, meanQ=8.649952, numObservations: 9
action 1, numVisits=5, meanQ=6.196000, numObservations: 4
action 5, numVisits=5, meanQ=4.598000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 29243 episodes
GETTING ACTION FROM:
action 3, numVisits=29063, meanQ=10.349589, numObservations: 9
action 4, numVisits=7247, meanQ=9.585949, numObservations: 9
action 1, numVisits=197, meanQ=6.186237, numObservations: 9
action 5, numVisits=21, meanQ=4.348064, numObservations: 8
action -1, numVisits=26, meanQ=-0.819615, numObservations: 23
action 0, numVisits=11, meanQ=-1.550900, numObservations: 10
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 3
Next state: 2 0.10168 0.0588368 0.420149 0.156128 0.735799 0.302059 0.203405 0.775803 0.532176 0.586238 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 10
Initial state: 0 0.090349 0.964834 0.586557 0.617536 0.729894 0.137858 0.94518 0.68704 0.0688077 0.673878 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 82622 episodes
GETTING ACTION FROM:
action 1, numVisits=82554, meanQ=8.260042, numObservations: 9
action 4, numVisits=18, meanQ=6.333900, numObservations: 7
action 5, numVisits=28, meanQ=6.203582, numObservations: 8
action 2, numVisits=17, meanQ=5.939424, numObservations: 8
action 3, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.090349 0.964834 0.586557 0.617536 0.729894 0.137858 0.94518 0.68704 0.0688077 0.673878 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 11
Initial state: 0 0.540564 0.625148 0.896985 0.822814 0.37835 0.694707 0.111984 0.984858 0.673816 0.960885 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 82401 episodes
GETTING ACTION FROM:
action 2, numVisits=82395, meanQ=8.039013, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.540564 0.625148 0.896985 0.822814 0.37835 0.694707 0.111984 0.984858 0.673816 0.960885 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 12
Initial state: 0 0.340301 0.0776224 0.995249 0.189789 0.794839 0.0813502 0.652859 0.328871 0.62169 0.665281 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 81439 episodes
GETTING ACTION FROM:
action 1, numVisits=81433, meanQ=7.919449, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.340301 0.0776224 0.995249 0.189789 0.794839 0.0813502 0.652859 0.328871 0.62169 0.665281 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=482, meanQ=7.283725, numObservations: 9
action 5, numVisits=6, meanQ=4.330017, numObservations: 4
action 4, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 101408 episodes
GETTING ACTION FROM:
action 2, numVisits=101330, meanQ=13.416375, numObservations: 9
action 1, numVisits=543, meanQ=8.223874, numObservations: 9
action 5, numVisits=7, meanQ=2.140014, numObservations: 4
action 3, numVisits=6, meanQ=2.133107, numObservations: 5
action 0, numVisits=7, meanQ=-1.717143, numObservations: 7
action -1, numVisits=6, meanQ=-1.835000, numObservations: 6
action 4, numVisits=4, meanQ=-2.250000, numObservations: 2
action: 2
Next state: 2 0.340301 0.0776224 0.995249 0.189789 0.794839 0.0813502 0.652859 0.328871 0.62169 0.665281 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 13
Initial state: 0 0.952247 0.992798 0.46259 0.110452 0.827091 0.172249 0.664245 0.698781 0.619639 0.618826 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 81783 episodes
GETTING ACTION FROM:
action 1, numVisits=81775, meanQ=8.113979, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.952247 0.992798 0.46259 0.110452 0.827091 0.172249 0.664245 0.698781 0.619639 0.618826 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 14
Initial state: 0 0.842596 0.297295 0.672653 0.817086 0.216827 0.819577 0.649761 0.916767 0.570163 0.612008 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80934 episodes
GETTING ACTION FROM:
action 4, numVisits=80922, meanQ=8.005958, numObservations: 9
action 1, numVisits=3, meanQ=3.330000, numObservations: 2
action 5, numVisits=3, meanQ=3.000000, numObservations: 2
action 2, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 2 0.842596 0.297295 0.672653 0.817086 0.216827 0.819577 0.649761 0.916767 0.570163 0.612008 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 15
Initial state: 0 0.358835 0.371053 0.57776 0.629062 0.411977 0.0740763 0.931275 0.292354 0.663595 0.144987 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 82311 episodes
GETTING ACTION FROM:
action 4, numVisits=82305, meanQ=8.129890, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.358835 0.371053 0.57776 0.629062 0.411977 0.0740763 0.931275 0.292354 0.663595 0.144987 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 16
Initial state: 0 0.703131 0.163635 0.475512 0.631769 0.674021 0.208601 0.699971 0.809959 0.644927 0.749674 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80839 episodes
GETTING ACTION FROM:
action 3, numVisits=80833, meanQ=7.857237, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.703131 0.163635 0.475512 0.631769 0.674021 0.208601 0.699971 0.809959 0.644927 0.749674 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 17
Initial state: 0 0.655223 0.124228 0.0715192 0.0431678 0.951999 0.697177 0.518765 0.640099 0.770057 0.398008 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79596 episodes
GETTING ACTION FROM:
action 4, numVisits=79586, meanQ=8.110177, numObservations: 9
action 2, numVisits=3, meanQ=3.000000, numObservations: 3
action 3, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 1 0.655223 0.124228 0.0715192 0.0431678 0.951999 0.697177 0.518765 0.640099 0.770057 0.398008 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 18
Initial state: 0 0.666946 0.238483 0.983413 0.232352 0.493266 0.569836 0.928392 0.100289 0.0174554 0.80087 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79808 episodes
GETTING ACTION FROM:
action 2, numVisits=79796, meanQ=7.714729, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=5, meanQ=-2.600000, numObservations: 3
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.666946 0.238483 0.983413 0.232352 0.493266 0.569836 0.928392 0.100289 0.0174554 0.80087 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=2063, meanQ=7.457080, numObservations: 9
action -1, numVisits=6, meanQ=-1.010000, numObservations: 6
action 0, numVisits=5, meanQ=-1.407980, numObservations: 4
action 3, numVisits=7, meanQ=-2.285686, numObservations: 4
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 71465 episodes
GETTING ACTION FROM:
action 5, numVisits=73483, meanQ=4.333273, numObservations: 9
action -1, numVisits=30, meanQ=-1.736000, numObservations: 30
action 0, numVisits=26, meanQ=-1.809996, numObservations: 23
action 3, numVisits=7, meanQ=-2.285686, numObservations: 4
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.666946 0.238483 0.983413 0.232352 0.493266 0.569836 0.928392 0.100289 0.0174554 0.80087 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=1166, meanQ=12.729672, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.618737, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 58944 episodes
GETTING ACTION FROM:
action 3, numVisits=60108, meanQ=10.423625, numObservations: 9
action -1, numVisits=4, meanQ=-1.505000, numObservations: 4
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.618737, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.666946 0.238483 0.983413 0.232352 0.493266 0.569836 0.928392 0.100289 0.0174554 0.80087 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 19
Initial state: 0 0.587343 0.608544 0.0538676 0.371082 0.304535 0.938926 0.993774 0.317534 0.127327 0.218632 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 82235 episodes
GETTING ACTION FROM:
action 3, numVisits=82229, meanQ=7.962385, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.587343 0.608544 0.0538676 0.371082 0.304535 0.938926 0.993774 0.317534 0.127327 0.218632 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=15509, meanQ=9.100713, numObservations: 9
action 2, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 22987 episodes
GETTING ACTION FROM:
action 4, numVisits=38475, meanQ=9.609157, numObservations: 9
action 2, numVisits=4, meanQ=-0.252500, numObservations: 2
action -1, numVisits=8, meanQ=-1.381250, numObservations: 8
action 0, numVisits=12, meanQ=-1.979077, numObservations: 11
action 3, numVisits=2, meanQ=-4.004950, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.587343 0.608544 0.0538676 0.371082 0.304535 0.938926 0.993774 0.317534 0.127327 0.218632 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 20
Initial state: 0 0.422709 0.305358 0.571977 0.798377 0.522291 0.54255 0.0120305 0.74795 0.302765 0.221195 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 82001 episodes
GETTING ACTION FROM:
action 1, numVisits=81995, meanQ=7.877056, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.422709 0.305358 0.571977 0.798377 0.522291 0.54255 0.0120305 0.74795 0.302765 0.221195 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=15298, meanQ=9.382141, numObservations: 9
action 3, numVisits=7, meanQ=6.282857, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 23852 episodes
GETTING ACTION FROM:
action 5, numVisits=39120, meanQ=9.243858, numObservations: 9
action 3, numVisits=9, meanQ=2.442222, numObservations: 6
action -1, numVisits=20, meanQ=-0.614000, numObservations: 18
action 0, numVisits=9, meanQ=-1.120000, numObservations: 9
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=2, meanQ=-7.005000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.422709 0.305358 0.571977 0.798377 0.522291 0.54255 0.0120305 0.74795 0.302765 0.221195 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=6120, meanQ=10.712333, numObservations: 9
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 14544 episodes
GETTING ACTION FROM:
action 2, numVisits=20644, meanQ=9.945476, numObservations: 9
action 4, numVisits=8, meanQ=2.905844, numObservations: 4
action 3, numVisits=6, meanQ=1.998333, numObservations: 4
action -1, numVisits=9, meanQ=-1.120000, numObservations: 9
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=7, meanQ=-77.585688, numObservations: 6
action: 2
Next state: 2 0.422709 0.305358 0.571977 0.798377 0.522291 0.54255 0.0120305 0.74795 0.302765 0.221195 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -18.7411
Run # 21
Initial state: 0 0.10337 0.316513 0.520031 0.5818 0.797091 0.334911 0.662469 0.18749 0.432696 0.876096 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80599 episodes
GETTING ACTION FROM:
action 5, numVisits=80591, meanQ=7.761338, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.10337 0.316513 0.520031 0.5818 0.797091 0.334911 0.662469 0.18749 0.432696 0.876096 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 22
Initial state: 0 0.79978 0.214087 0.725553 0.0492929 0.496548 0.518325 0.502959 0.612169 0.345324 0.73805 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80249 episodes
GETTING ACTION FROM:
action 2, numVisits=80237, meanQ=8.025105, numObservations: 9
action 4, numVisits=7, meanQ=3.572886, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 2 0.79978 0.214087 0.725553 0.0492929 0.496548 0.518325 0.502959 0.612169 0.345324 0.73805 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 23
Initial state: 0 0.600582 0.665693 0.958621 0.731418 0.338005 0.762066 0.47056 0.208578 0.290072 0.345749 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80117 episodes
GETTING ACTION FROM:
action 1, numVisits=79827, meanQ=8.007599, numObservations: 9
action 3, numVisits=224, meanQ=7.372546, numObservations: 9
action 4, numVisits=44, meanQ=6.872957, numObservations: 9
action 5, numVisits=19, meanQ=6.105284, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.600582 0.665693 0.958621 0.731418 0.338005 0.762066 0.47056 0.208578 0.290072 0.345749 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 24
Initial state: 0 0.549306 0.670373 0.335112 0.897094 0.524561 0.728296 0.659252 0.392248 0.0716633 0.000602466 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 81231 episodes
GETTING ACTION FROM:
action 2, numVisits=81222, meanQ=8.002075, numObservations: 9
action 4, numVisits=4, meanQ=1.497500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.549306 0.670373 0.335112 0.897094 0.524561 0.728296 0.659252 0.392248 0.0716633 0.000602466 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=2548, meanQ=11.753010, numObservations: 207
action 0, numVisits=13, meanQ=-1.315377, numObservations: 12
action 2, numVisits=2, meanQ=-4.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 9250 episodes
GETTING ACTION FROM:
action -1, numVisits=11798, meanQ=7.708299, numObservations: 242
action 0, numVisits=13, meanQ=-1.315377, numObservations: 12
action 2, numVisits=2, meanQ=-4.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.549306 0.670373 0.335112 0.897094 0.524561 0.728296 0.659252 0.392248 0.0716633 0.000602466 w: 1
Observation: 0 1 0 1 0 1 0 3 0 1 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=11, meanQ=4.219205, numObservations: 4
action 0, numVisits=60, meanQ=1.148974, numObservations: 45
action -1, numVisits=7, meanQ=-2.991414, numObservations: 5
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 59707 episodes
GETTING ACTION FROM:
action 4, numVisits=59513, meanQ=9.944569, numObservations: 9
action 5, numVisits=91, meanQ=-0.874319, numObservations: 8
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=93, meanQ=-4.391397, numObservations: 8
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action 0, numVisits=61, meanQ=-16.189218, numObservations: 45
action -1, numVisits=28, meanQ=-37.383944, numObservations: 17
action: 4
Next state: 2 0.549306 0.670373 0.335112 0.897094 0.524561 0.728296 0.659252 0.392248 0.0716633 0.000602466 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -16.7611
Run # 25
Initial state: 0 0.216674 0.68722 0.442288 0.378874 0.634992 0.637127 0.707451 0.413838 0.838903 0.032947 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79660 episodes
GETTING ACTION FROM:
action 3, numVisits=79643, meanQ=8.078319, numObservations: 9
action 5, numVisits=12, meanQ=2.168342, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.216674 0.68722 0.442288 0.378874 0.634992 0.637127 0.707451 0.413838 0.838903 0.032947 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 26
Initial state: 0 0.478273 0.190892 0.567456 0.661465 0.546749 0.898156 0.155983 0.852794 0.351835 0.679301 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 82109 episodes
GETTING ACTION FROM:
action 1, numVisits=82090, meanQ=7.725429, numObservations: 9
action -1, numVisits=6, meanQ=-1.010000, numObservations: 6
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 4, numVisits=2, meanQ=-4.000000, numObservations: 2
action 5, numVisits=2, meanQ=-4.000000, numObservations: 2
action 3, numVisits=2, meanQ=-7.500000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.478273 0.190892 0.567456 0.661465 0.546749 0.898156 0.155983 0.852794 0.351835 0.679301 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 27
Initial state: 0 0.0574221 0.440558 0.779419 0.509574 0.497142 0.671306 0.26729 0.415899 0.559533 0.379624 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 81778 episodes
GETTING ACTION FROM:
action 1, numVisits=81769, meanQ=7.889653, numObservations: 9
action 5, numVisits=4, meanQ=-0.252500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.0574221 0.440558 0.779419 0.509574 0.497142 0.671306 0.26729 0.415899 0.559533 0.379624 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=15177, meanQ=9.441176, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 23919 episodes
GETTING ACTION FROM:
action 4, numVisits=39078, meanQ=9.242409, numObservations: 9
action 5, numVisits=8, meanQ=3.825715, numObservations: 7
action 0, numVisits=13, meanQ=-1.010000, numObservations: 13
action -1, numVisits=11, meanQ=-1.190900, numObservations: 10
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.0574221 0.440558 0.779419 0.509574 0.497142 0.671306 0.26729 0.415899 0.559533 0.379624 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=6423, meanQ=11.327986, numObservations: 9
action 2, numVisits=12, meanQ=3.785389, numObservations: 7
action 3, numVisits=14, meanQ=2.618462, numObservations: 7
action -1, numVisits=14, meanQ=-1.010000, numObservations: 14
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=67, meanQ=-10.378519, numObservations: 29
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 23627 episodes
GETTING ACTION FROM:
action 5, numVisits=30050, meanQ=10.674742, numObservations: 9
action 2, numVisits=12, meanQ=3.785389, numObservations: 7
action 3, numVisits=14, meanQ=2.618462, numObservations: 7
action -1, numVisits=14, meanQ=-1.010000, numObservations: 14
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=67, meanQ=-10.378519, numObservations: 29
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.0574221 0.440558 0.779419 0.509574 0.497142 0.671306 0.26729 0.415899 0.559533 0.379624 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=457, meanQ=10.307758, numObservations: 9
action 0, numVisits=9, meanQ=-2.330000, numObservations: 8
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=6, meanQ=-177.168678, numObservations: 5
Sampled 39554 episodes
GETTING ACTION FROM:
action 3, numVisits=40011, meanQ=13.500210, numObservations: 9
action 0, numVisits=9, meanQ=-2.330000, numObservations: 8
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=6, meanQ=-177.168678, numObservations: 5
action: 3
Next state: 1 0.0574221 0.440558 0.779419 0.509574 0.497142 0.671306 0.26729 0.415899 0.559533 0.379624 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 11.4068
Run # 28
Initial state: 0 0.521841 0.240943 0.267905 0.174131 0.517787 0.576975 0.171923 0.399313 0.146528 0.117344 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 82073 episodes
GETTING ACTION FROM:
action 4, numVisits=79978, meanQ=8.087556, numObservations: 9
action 2, numVisits=1364, meanQ=7.466998, numObservations: 9
action 1, numVisits=727, meanQ=7.396625, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.521841 0.240943 0.267905 0.174131 0.517787 0.576975 0.171923 0.399313 0.146528 0.117344 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 29
Initial state: 0 0.52103 0.652114 0.258286 0.772604 0.191018 0.265536 0.00784364 0.0903594 0.977271 0.270204 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79651 episodes
GETTING ACTION FROM:
action 2, numVisits=74738, meanQ=7.886940, numObservations: 9
action 4, numVisits=4891, meanQ=7.436639, numObservations: 9
action 1, numVisits=15, meanQ=5.332013, numObservations: 6
action 3, numVisits=4, meanQ=2.502525, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.52103 0.652114 0.258286 0.772604 0.191018 0.265536 0.00784364 0.0903594 0.977271 0.270204 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 30
Initial state: 0 0.72135 0.853849 0.940565 0.0596286 0.562553 0.571801 0.468754 0.967719 0.369694 0.256216 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 81896 episodes
GETTING ACTION FROM:
action 3, numVisits=81868, meanQ=7.982558, numObservations: 9
action -1, numVisits=13, meanQ=-1.923846, numObservations: 12
action 0, numVisits=9, meanQ=-2.330000, numObservations: 8
action 5, numVisits=2, meanQ=-4.000000, numObservations: 2
action 2, numVisits=2, meanQ=-7.500000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.72135 0.853849 0.940565 0.0596286 0.562553 0.571801 0.468754 0.967719 0.369694 0.256216 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 31
Initial state: 0 0.58529 0.587128 0.426037 0.492803 0.795597 0.00521682 0.472812 0.855093 0.197015 0.654103 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 82366 episodes
GETTING ACTION FROM:
action 1, numVisits=82355, meanQ=7.970387, numObservations: 9
action 3, numVisits=6, meanQ=3.000000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.58529 0.587128 0.426037 0.492803 0.795597 0.00521682 0.472812 0.855093 0.197015 0.654103 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 32
Initial state: 0 0.277137 0.715714 0.345348 0.596546 0.867613 0.0228017 0.627369 0.616799 0.729669 0.687769 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 81936 episodes
GETTING ACTION FROM:
action 2, numVisits=81927, meanQ=8.149905, numObservations: 9
action 1, numVisits=4, meanQ=-0.500000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.277137 0.715714 0.345348 0.596546 0.867613 0.0228017 0.627369 0.616799 0.729669 0.687769 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 33
Initial state: 0 0.215395 0.257292 0.318168 0.0767711 0.571142 0.549636 0.877062 0.351132 0.209634 0.753005 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 81986 episodes
GETTING ACTION FROM:
action 1, numVisits=81977, meanQ=8.088928, numObservations: 9
action 2, numVisits=4, meanQ=1.000025, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.215395 0.257292 0.318168 0.0767711 0.571142 0.549636 0.877062 0.351132 0.209634 0.753005 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=15338, meanQ=9.523561, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 22907 episodes
GETTING ACTION FROM:
action 5, numVisits=38220, meanQ=9.116494, numObservations: 9
action 4, numVisits=10, meanQ=3.412336, numObservations: 7
action 0, numVisits=8, meanQ=-1.257500, numObservations: 8
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=9, meanQ=-118.495905, numObservations: 8
action: 5
Next state: 1 0.215395 0.257292 0.318168 0.0767711 0.571142 0.549636 0.877062 0.351132 0.209634 0.753005 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 34
Initial state: 0 0.292008 0.467213 0.452381 0.723244 0.472199 0.311709 0.723791 0.73385 0.531601 0.549283 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 50357 episodes
GETTING ACTION FROM:
action -1, numVisits=50339, meanQ=12.906637, numObservations: 243
action 0, numVisits=10, meanQ=-2.198000, numObservations: 9
action 3, numVisits=2, meanQ=-4.000000, numObservations: 2
action 5, numVisits=2, meanQ=-5.489950, numObservations: 1
action 4, numVisits=2, meanQ=-7.500000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.292008 0.467213 0.452381 0.723244 0.472199 0.311709 0.723791 0.73385 0.531601 0.549283 w: 1
Observation: 0 1 0 1 0 1 0 3 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=452, meanQ=19.340924, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 115412 episodes
GETTING ACTION FROM:
action 5, numVisits=115864, meanQ=22.148647, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.292008 0.467213 0.452381 0.723244 0.472199 0.311709 0.723791 0.73385 0.531601 0.549283 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 35
Initial state: 0 0.68478 0.932866 0.816048 0.906071 0.315894 0.64323 0.891183 0.269802 0.617529 0.601505 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 82103 episodes
GETTING ACTION FROM:
action 3, numVisits=82094, meanQ=8.060903, numObservations: 9
action 2, numVisits=4, meanQ=1.250000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.68478 0.932866 0.816048 0.906071 0.315894 0.64323 0.891183 0.269802 0.617529 0.601505 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=2682, meanQ=8.791666, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 23262 episodes
GETTING ACTION FROM:
action 2, numVisits=25746, meanQ=8.456706, numObservations: 9
action 1, numVisits=17, meanQ=4.946986, numObservations: 8
action -1, numVisits=37, meanQ=-2.403719, numObservations: 30
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=2, meanQ=-5.271466, numObservations: 2
action 0, numVisits=146, meanQ=-8.271742, numObservations: 100
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.68478 0.932866 0.816048 0.906071 0.315894 0.64323 0.891183 0.269802 0.617529 0.601505 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 36
Initial state: 0 0.657708 0.203138 0.834198 0.479186 0.0119356 0.824598 0.631005 0.583042 0.0205054 0.0889992 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 81773 episodes
GETTING ACTION FROM:
action 3, numVisits=81728, meanQ=7.976718, numObservations: 9
action 4, numVisits=38, meanQ=4.310506, numObservations: 9
action 5, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.657708 0.203138 0.834198 0.479186 0.0119356 0.824598 0.631005 0.583042 0.0205054 0.0889992 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 37
Initial state: 0 0.968782 0.0564988 0.9345 0.607646 0.82221 0.217916 0.94053 0.253668 0.633432 0.561838 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 81787 episodes
GETTING ACTION FROM:
action 2, numVisits=81772, meanQ=7.950664, numObservations: 9
action 3, numVisits=10, meanQ=5.509010, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.968782 0.0564988 0.9345 0.607646 0.82221 0.217916 0.94053 0.253668 0.633432 0.561838 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 38
Initial state: 0 0.997662 0.135156 0.426207 0.373891 0.503283 0.607825 0.524095 0.367817 0.0572836 0.935677 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 75856 episodes
GETTING ACTION FROM:
action 1, numVisits=75848, meanQ=6.992249, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.997662 0.135156 0.426207 0.373891 0.503283 0.607825 0.524095 0.367817 0.0572836 0.935677 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 39
Initial state: 0 0.00683882 0.135219 0.348413 0.788129 0.344351 0.733116 0.609258 0.628163 0.831569 0.10455 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 82392 episodes
GETTING ACTION FROM:
action 5, numVisits=82380, meanQ=8.082217, numObservations: 9
action 1, numVisits=4, meanQ=-0.500000, numObservations: 3
action 4, numVisits=4, meanQ=-0.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 2 0.00683882 0.135219 0.348413 0.788129 0.344351 0.733116 0.609258 0.628163 0.831569 0.10455 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 40
Initial state: 0 0.0476764 0.144082 0.355049 0.823255 0.128801 0.726392 0.521916 0.63945 0.795993 0.538201 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 81872 episodes
GETTING ACTION FROM:
action 3, numVisits=81852, meanQ=7.778672, numObservations: 9
action 1, numVisits=6, meanQ=0.168367, numObservations: 4
action 2, numVisits=4, meanQ=-0.252500, numObservations: 4
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 5, numVisits=5, meanQ=-1.780000, numObservations: 3
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.0476764 0.144082 0.355049 0.823255 0.128801 0.726392 0.521916 0.63945 0.795993 0.538201 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=7291, meanQ=9.132578, numObservations: 9
action 2, numVisits=10, meanQ=4.598000, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 26960 episodes
GETTING ACTION FROM:
action 1, numVisits=34244, meanQ=10.695399, numObservations: 9
action 2, numVisits=10, meanQ=4.598000, numObservations: 7
action 0, numVisits=5, meanQ=-1.208000, numObservations: 5
action -1, numVisits=4, meanQ=-1.752500, numObservations: 4
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.0476764 0.144082 0.355049 0.823255 0.128801 0.726392 0.521916 0.63945 0.795993 0.538201 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=3964, meanQ=11.002109, numObservations: 9
action 5, numVisits=6, meanQ=4.330017, numObservations: 3
action 2, numVisits=4, meanQ=3.742500, numObservations: 4
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 19368 episodes
GETTING ACTION FROM:
action 4, numVisits=23332, meanQ=12.969725, numObservations: 9
action 5, numVisits=6, meanQ=4.330017, numObservations: 3
action 2, numVisits=4, meanQ=3.742500, numObservations: 4
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 0 0.0476764 0.144082 0.355049 0.823255 0.128801 0.726392 0.521916 0.63945 0.795993 0.538201 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action -1, numVisits=172, meanQ=1.228957, numObservations: 53
action 3, numVisits=6, meanQ=1.160017, numObservations: 4
action 5, numVisits=24, meanQ=1.117167, numObservations: 7
action 0, numVisits=15, meanQ=-2.822255, numObservations: 11
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 12968 episodes
GETTING ACTION FROM:
action 3, numVisits=9, meanQ=5.551133, numObservations: 4
action -1, numVisits=13128, meanQ=1.400526, numObservations: 221
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=28, meanQ=-11.950216, numObservations: 8
action 0, numVisits=20, meanQ=-20.479031, numObservations: 14
action: 3
Next state: 0 0.0476764 0.144082 0.355049 0.823255 0.128801 0.726392 0.521916 0.63945 0.795993 0.538201 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-361.662255, numObservations: 1
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 42999 episodes
GETTING ACTION FROM:
action 2, numVisits=42994, meanQ=18.078457, numObservations: 9
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action -1, numVisits=1, meanQ=-2.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-361.662255, numObservations: 1
action: 2
Next state: 0 0.0476764 0.144082 0.355049 0.823255 0.128801 0.726392 0.521916 0.63945 0.795993 0.538201 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 5
Improving policy...
PLANNING FROM:
action 3, numVisits=1, meanQ=24.000000, numObservations: 1
action 2, numVisits=26, meanQ=17.126469, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.787576, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-362.979681, numObservations: 1
Sampled 77475 episodes
GETTING ACTION FROM:
action 3, numVisits=306, meanQ=19.685490, numObservations: 8
action 2, numVisits=26, meanQ=17.126469, numObservations: 7
action -1, numVisits=77106, meanQ=-1.857980, numObservations: 231
action 0, numVisits=66, meanQ=-6.077026, numObservations: 28
action 5, numVisits=1, meanQ=-10.787576, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-362.979681, numObservations: 1
action: 3
Next state: 0 0.0476764 0.144082 0.355049 0.823255 0.128801 0.726392 0.521916 0.63945 0.795993 0.538201 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: -4
Updated belief

t = 6
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 84801 episodes
GETTING ACTION FROM:
action 2, numVisits=268, meanQ=17.805971, numObservations: 9
action 5, numVisits=84509, meanQ=16.744678, numObservations: 9
action 1, numVisits=15, meanQ=14.666667, numObservations: 4
action 3, numVisits=3, meanQ=12.333333, numObservations: 1
action 4, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=2, meanQ=-2.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.000000, numObservations: 2
action: 2
Next state: 0 0.0476764 0.144082 0.355049 0.823255 0.128801 0.726392 0.521916 0.63945 0.795993 0.538201 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 7
Improving policy...
PLANNING FROM:
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52510 episodes
GETTING ACTION FROM:
action 3, numVisits=32, meanQ=22.992500, numObservations: 3
action 4, numVisits=46, meanQ=22.478261, numObservations: 7
action 2, numVisits=19, meanQ=22.157895, numObservations: 5
action -1, numVisits=52356, meanQ=-1.303721, numObservations: 214
action 0, numVisits=54, meanQ=-7.014068, numObservations: 25
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=3, meanQ=-85.219807, numObservations: 2
action: 3
Next state: 1 0.0476764 0.144082 0.355049 0.823255 0.128801 0.726392 0.521916 0.63945 0.795993 0.538201 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -4.80429
Run # 41
Initial state: 0 0.2103 0.915807 0.374705 0.649998 0.676007 0.0587643 0.389925 0.935429 0.566357 0.640755 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 81551 episodes
GETTING ACTION FROM:
action 5, numVisits=81545, meanQ=7.703661, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.2103 0.915807 0.374705 0.649998 0.676007 0.0587643 0.389925 0.935429 0.566357 0.640755 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 42
Initial state: 0 0.930839 0.762055 0.466034 0.907219 0.234881 0.457544 0.626417 0.602922 0.302905 0.928656 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80122 episodes
GETTING ACTION FROM:
action 2, numVisits=80105, meanQ=7.909941, numObservations: 9
action 5, numVisits=12, meanQ=3.081675, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.930839 0.762055 0.466034 0.907219 0.234881 0.457544 0.626417 0.602922 0.302905 0.928656 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=597, meanQ=6.958587, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 36538 episodes
GETTING ACTION FROM:
action 3, numVisits=36474, meanQ=11.116867, numObservations: 9
action 2, numVisits=611, meanQ=7.140589, numObservations: 9
action -1, numVisits=38, meanQ=-1.140263, numObservations: 31
action 0, numVisits=15, meanQ=-1.670000, numObservations: 14
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.930839 0.762055 0.466034 0.907219 0.234881 0.457544 0.626417 0.602922 0.302905 0.928656 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=1378, meanQ=12.213666, numObservations: 9
action 0, numVisits=161, meanQ=-10.379717, numObservations: 68
action 3, numVisits=1, meanQ=-11.396260, numObservations: 1
action 4, numVisits=2, meanQ=-11.617241, numObservations: 2
action 1, numVisits=32, meanQ=-25.588124, numObservations: 7
action -1, numVisits=9, meanQ=-117.716940, numObservations: 8
action 2, numVisits=1, meanQ=-1063.524119, numObservations: 1
Sampled 20135 episodes
GETTING ACTION FROM:
action 5, numVisits=18653, meanQ=9.796616, numObservations: 9
action 4, numVisits=2862, meanQ=9.668739, numObservations: 9
action 0, numVisits=161, meanQ=-10.379717, numObservations: 68
action 3, numVisits=1, meanQ=-11.396260, numObservations: 1
action 1, numVisits=32, meanQ=-25.588124, numObservations: 7
action -1, numVisits=9, meanQ=-117.716940, numObservations: 8
action 2, numVisits=1, meanQ=-1063.524119, numObservations: 1
action: 5
Next state: 0 0.930839 0.762055 0.466034 0.907219 0.234881 0.457544 0.626417 0.602922 0.302905 0.928656 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=1, meanQ=24.000000, numObservations: 1
action -1, numVisits=398, meanQ=4.717931, numObservations: 78
action 4, numVisits=7, meanQ=3.275256, numObservations: 4
action 0, numVisits=8, meanQ=-2.807526, numObservations: 7
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-12.590488, numObservations: 1
action 5, numVisits=3, meanQ=-346.048416, numObservations: 2
Sampled 57221 episodes
GETTING ACTION FROM:
action 2, numVisits=178, meanQ=17.135449, numObservations: 9
action 4, numVisits=46723, meanQ=12.082624, numObservations: 9
action -1, numVisits=10721, meanQ=-0.859591, numObservations: 210
action 0, numVisits=13, meanQ=-3.258478, numObservations: 11
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-12.590488, numObservations: 1
action 5, numVisits=3, meanQ=-346.048416, numObservations: 2
action: 2
Next state: 0 0.930839 0.762055 0.466034 0.907219 0.234881 0.457544 0.626417 0.602922 0.302905 0.928656 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 62501 episodes
GETTING ACTION FROM:
action 4, numVisits=62431, meanQ=19.827940, numObservations: 9
action 5, numVisits=60, meanQ=18.329333, numObservations: 6
action 2, numVisits=5, meanQ=11.400000, numObservations: 2
action 3, numVisits=2, meanQ=10.000000, numObservations: 2
action -1, numVisits=1, meanQ=-2.000000, numObservations: 1
action 0, numVisits=1, meanQ=-2.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.930839 0.762055 0.466034 0.907219 0.234881 0.457544 0.626417 0.602922 0.302905 0.928656 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.29271
Run # 43
Initial state: 0 0.629048 0.315557 0.0816536 0.676356 0.556522 0.551061 0.144731 0.158056 0.243081 0.463435 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 82192 episodes
GETTING ACTION FROM:
action 1, numVisits=82181, meanQ=7.889408, numObservations: 9
action 5, numVisits=6, meanQ=0.666667, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.629048 0.315557 0.0816536 0.676356 0.556522 0.551061 0.144731 0.158056 0.243081 0.463435 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 44
Initial state: 0 0.607918 0.370935 0.775084 0.200194 0.623178 0.604107 0.985443 0.722431 0.12041 0.684501 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 82050 episodes
GETTING ACTION FROM:
action 5, numVisits=82028, meanQ=7.889623, numObservations: 9
action -1, numVisits=14, meanQ=-0.232143, numObservations: 12
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.607918 0.370935 0.775084 0.200194 0.623178 0.604107 0.985443 0.722431 0.12041 0.684501 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=7238, meanQ=9.411335, numObservations: 9
action 3, numVisits=16, meanQ=0.246875, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 21194 episodes
GETTING ACTION FROM:
action 4, numVisits=28425, meanQ=9.859017, numObservations: 9
action 3, numVisits=16, meanQ=0.246875, numObservations: 9
action -1, numVisits=6, meanQ=-1.175000, numObservations: 6
action 0, numVisits=5, meanQ=-1.406000, numObservations: 5
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.607918 0.370935 0.775084 0.200194 0.623178 0.604107 0.985443 0.722431 0.12041 0.684501 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 45
Initial state: 0 0.338987 0.448809 0.850317 0.388867 0.424612 0.483969 0.334075 0.34522 0.523664 0.624199 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 81759 episodes
GETTING ACTION FROM:
action 1, numVisits=81753, meanQ=7.868182, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.338987 0.448809 0.850317 0.388867 0.424612 0.483969 0.334075 0.34522 0.523664 0.624199 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=15214, meanQ=9.381728, numObservations: 9
action 2, numVisits=21, meanQ=7.382395, numObservations: 7
action 5, numVisits=5, meanQ=5.798020, numObservations: 4
action 3, numVisits=6, meanQ=4.661667, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 25008 episodes
GETTING ACTION FROM:
action 4, numVisits=40061, meanQ=8.108913, numObservations: 9
action 2, numVisits=144, meanQ=6.264449, numObservations: 9
action 5, numVisits=18, meanQ=3.888065, numObservations: 9
action 3, numVisits=8, meanQ=0.746250, numObservations: 6
action -1, numVisits=17, meanQ=-1.243524, numObservations: 16
action 0, numVisits=8, meanQ=-2.495949, numObservations: 7
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 0 0.338987 0.448809 0.850317 0.388867 0.424612 0.483969 0.334075 0.34522 0.523664 0.624199 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=6173, meanQ=11.790792, numObservations: 9
action 0, numVisits=5, meanQ=-1.010000, numObservations: 5
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=4, meanQ=-264.657452, numObservations: 3
Sampled 19050 episodes
GETTING ACTION FROM:
action 5, numVisits=25222, meanQ=10.866581, numObservations: 9
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=6, meanQ=-3.370719, numObservations: 5
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=4, meanQ=-264.657452, numObservations: 3
action: 5
Next state: 1 0.338987 0.448809 0.850317 0.388867 0.424612 0.483969 0.334075 0.34522 0.523664 0.624199 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 46
Initial state: 0 0.775226 0.696462 0.566684 0.616296 0.984167 0.0992993 0.070215 0.37802 0.816205 0.840774 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79708 episodes
GETTING ACTION FROM:
action 3, numVisits=79692, meanQ=8.130039, numObservations: 9
action 1, numVisits=11, meanQ=4.907291, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.775226 0.696462 0.566684 0.616296 0.984167 0.0992993 0.070215 0.37802 0.816205 0.840774 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 47
Initial state: 0 0.593771 0.768481 0.680492 0.0222294 0.751378 0.819869 0.187971 0.81375 0.544447 0.634241 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80446 episodes
GETTING ACTION FROM:
action 4, numVisits=80438, meanQ=7.753145, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.593771 0.768481 0.680492 0.0222294 0.751378 0.819869 0.187971 0.81375 0.544447 0.634241 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=7215, meanQ=8.932560, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 26363 episodes
GETTING ACTION FROM:
action 3, numVisits=33565, meanQ=10.799520, numObservations: 9
action -1, numVisits=8, meanQ=-1.133750, numObservations: 8
action 0, numVisits=6, meanQ=-1.505000, numObservations: 6
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.593771 0.768481 0.680492 0.0222294 0.751378 0.819869 0.187971 0.81375 0.544447 0.634241 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 48
Initial state: 0 0.0181036 0.156001 0.18949 0.757485 0.580735 0.647527 0.401491 0.29227 0.327685 0.423151 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 78580 episodes
GETTING ACTION FROM:
action 5, numVisits=78570, meanQ=8.270926, numObservations: 9
action 1, numVisits=3, meanQ=3.330000, numObservations: 3
action 3, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.0181036 0.156001 0.18949 0.757485 0.580735 0.647527 0.401491 0.29227 0.327685 0.423151 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=14582, meanQ=9.390200, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 21259 episodes
GETTING ACTION FROM:
action 2, numVisits=35602, meanQ=9.422119, numObservations: 9
action 3, numVisits=218, meanQ=5.260038, numObservations: 9
action -1, numVisits=22, meanQ=-0.603922, numObservations: 20
action 0, numVisits=12, meanQ=-1.175825, numObservations: 11
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=2, meanQ=-7.005000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.0181036 0.156001 0.18949 0.757485 0.580735 0.647527 0.401491 0.29227 0.327685 0.423151 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 49
Initial state: 0 0.758245 0.131482 0.927764 0.150038 0.479257 0.646938 0.408329 0.823903 0.979696 0.249117 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 50234 episodes
GETTING ACTION FROM:
action -1, numVisits=50201, meanQ=12.507661, numObservations: 243
action 0, numVisits=28, meanQ=-1.576068, numObservations: 26
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.758245 0.131482 0.927764 0.150038 0.479257 0.646938 0.408329 0.823903 0.979696 0.249117 w: 1
Observation: 0 3 0 3 0 1 0 1 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=105, meanQ=10.507727, numObservations: 9
action 5, numVisits=20, meanQ=4.498505, numObservations: 5
action 1, numVisits=3, meanQ=3.330000, numObservations: 3
action 2, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 74218 episodes
GETTING ACTION FROM:
action 3, numVisits=74323, meanQ=9.354259, numObservations: 9
action 5, numVisits=20, meanQ=4.498505, numObservations: 5
action 1, numVisits=3, meanQ=3.330000, numObservations: 3
action 2, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.758245 0.131482 0.927764 0.150038 0.479257 0.646938 0.408329 0.823903 0.979696 0.249117 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 50
Initial state: 0 0.255999 0.798322 0.930842 0.186447 0.830022 0.519319 0.631992 0.577851 0.711495 0.446711 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 81957 episodes
GETTING ACTION FROM:
action 5, numVisits=81906, meanQ=7.984155, numObservations: 9
action -1, numVisits=17, meanQ=-1.010000, numObservations: 17
action 0, numVisits=17, meanQ=-1.010000, numObservations: 17
action 2, numVisits=8, meanQ=-1.502463, numObservations: 5
action 1, numVisits=6, meanQ=-3.316667, numObservations: 4
action 3, numVisits=2, meanQ=-7.500000, numObservations: 2
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.255999 0.798322 0.930842 0.186447 0.830022 0.519319 0.631992 0.577851 0.711495 0.446711 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
[32m ProblemEnvironment.hpp 351: Done.[39m
