Run # 1
Initial state: 0 0.27465 0.789714 0.524713 0.106543 0.856578 0.427629 0.64352 0.917026 0.410651 0.489257 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 50331 episodes
GETTING ACTION FROM:
action -1, numVisits=50317, meanQ=14.589607, numObservations: 243
action 2, numVisits=6, meanQ=-4.000000, numObservations: 4
action 4, numVisits=3, meanQ=-6.003333, numObservations: 3
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.27465 0.789714 0.524713 0.106543 0.856578 0.427629 0.64352 0.917026 0.410651 0.489257 w: 1
Observation: 0 1 0 3 0 3 0 3 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=502, meanQ=21.072256, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 117718 episodes
GETTING ACTION FROM:
action 5, numVisits=118220, meanQ=21.818277, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.27465 0.789714 0.524713 0.106543 0.856578 0.427629 0.64352 0.917026 0.410651 0.489257 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 2
Initial state: 0 0.0940122 0.19115 0.0848654 0.86762 0.475889 0.465034 0.0650942 0.60536 0.916728 0.542576 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92284 episodes
GETTING ACTION FROM:
action 4, numVisits=92266, meanQ=10.337666, numObservations: 9
action 1, numVisits=11, meanQ=4.271827, numObservations: 7
action 2, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.0940122 0.19115 0.0848654 0.86762 0.475889 0.465034 0.0650942 0.60536 0.916728 0.542576 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=7689, meanQ=11.824397, numObservations: 9
action 2, numVisits=41, meanQ=9.694637, numObservations: 9
action 1, numVisits=7, meanQ=6.282857, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 42430 episodes
GETTING ACTION FROM:
action 5, numVisits=49942, meanQ=12.755329, numObservations: 9
action 1, numVisits=182, meanQ=11.351054, numObservations: 9
action 2, numVisits=41, meanQ=9.694637, numObservations: 9
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 1 0.0940122 0.19115 0.0848654 0.86762 0.475889 0.465034 0.0650942 0.60536 0.916728 0.542576 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 3
Initial state: 0 0.114585 0.352368 0.474764 0.66274 0.45536 0.446375 0.227182 0.041567 0.8805 0.412147 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87535 episodes
GETTING ACTION FROM:
action 3, numVisits=87524, meanQ=10.416827, numObservations: 9
action 4, numVisits=3, meanQ=3.000000, numObservations: 3
action 5, numVisits=4, meanQ=3.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.114585 0.352368 0.474764 0.66274 0.45536 0.446375 0.227182 0.041567 0.8805 0.412147 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 4
Initial state: 0 0.148004 0.755166 0.862856 0.0348814 0.455154 0.547297 0.811154 0.84978 0.920498 0.138879 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92430 episodes
GETTING ACTION FROM:
action 3, numVisits=92424, meanQ=10.417245, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.148004 0.755166 0.862856 0.0348814 0.455154 0.547297 0.811154 0.84978 0.920498 0.138879 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 5
Initial state: 0 0.130851 0.321256 0.072527 0.696135 0.153233 0.545921 0.0356572 0.446509 0.425034 0.406711 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92703 episodes
GETTING ACTION FROM:
action 3, numVisits=92687, meanQ=10.367421, numObservations: 9
action 2, numVisits=9, meanQ=6.998889, numObservations: 5
action 4, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.130851 0.321256 0.072527 0.696135 0.153233 0.545921 0.0356572 0.446509 0.425034 0.406711 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=9644, meanQ=10.949162, numObservations: 9
action 2, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 25608 episodes
GETTING ACTION FROM:
action 5, numVisits=35247, meanQ=10.969739, numObservations: 9
action 2, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=4, meanQ=-1.257500, numObservations: 4
action 0, numVisits=3, meanQ=-1.670000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.130851 0.321256 0.072527 0.696135 0.153233 0.545921 0.0356572 0.446509 0.425034 0.406711 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 6
Initial state: 0 0.964806 0.5369 0.660758 0.110496 0.646863 0.719637 0.990016 0.993445 0.401492 0.486507 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92792 episodes
GETTING ACTION FROM:
action 3, numVisits=92780, meanQ=10.389069, numObservations: 9
action 1, numVisits=7, meanQ=1.727143, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.964806 0.5369 0.660758 0.110496 0.646863 0.719637 0.990016 0.993445 0.401492 0.486507 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 7
Initial state: 0 0.571235 0.362775 0.371592 0.480189 0.869369 0.908038 0.218609 0.91602 0.516157 0.00615695 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92221 episodes
GETTING ACTION FROM:
action 1, numVisits=92183, meanQ=10.078526, numObservations: 9
action 3, numVisits=25, meanQ=8.333212, numObservations: 6
action 2, numVisits=7, meanQ=6.585714, numObservations: 5
action 5, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.571235 0.362775 0.371592 0.480189 0.869369 0.908038 0.218609 0.91602 0.516157 0.00615695 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 8
Initial state: 0 0.542614 0.350038 0.474584 0.55326 0.100068 0.868509 0.546363 0.899519 0.872398 0.0750044 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92653 episodes
GETTING ACTION FROM:
action 3, numVisits=92640, meanQ=10.324993, numObservations: 9
action 2, numVisits=8, meanQ=4.005025, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.542614 0.350038 0.474584 0.55326 0.100068 0.868509 0.546363 0.899519 0.872398 0.0750044 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=7968, meanQ=11.575715, numObservations: 9
action 1, numVisits=21, meanQ=9.767148, numObservations: 7
action 3, numVisits=7, meanQ=8.281443, numObservations: 3
action 4, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 42609 episodes
GETTING ACTION FROM:
action 1, numVisits=42535, meanQ=13.739110, numObservations: 9
action 2, numVisits=8050, meanQ=11.584633, numObservations: 9
action 3, numVisits=8, meanQ=9.716262, numObservations: 3
action 4, numVisits=3, meanQ=3.000000, numObservations: 3
action 5, numVisits=6, meanQ=2.574495, numObservations: 6
action -1, numVisits=4, meanQ=-1.257500, numObservations: 4
action 0, numVisits=4, meanQ=-1.505000, numObservations: 4
action: 1
Next state: 2 0.542614 0.350038 0.474584 0.55326 0.100068 0.868509 0.546363 0.899519 0.872398 0.0750044 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 9
Initial state: 0 0.949867 0.71162 0.184211 0.284736 0.935903 0.217272 0.410759 0.41526 0.831085 0.386742 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92196 episodes
GETTING ACTION FROM:
action 4, numVisits=92175, meanQ=10.095456, numObservations: 9
action 2, numVisits=12, meanQ=7.666667, numObservations: 6
action 5, numVisits=5, meanQ=5.998000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.949867 0.71162 0.184211 0.284736 0.935903 0.217272 0.410759 0.41526 0.831085 0.386742 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 10
Initial state: 0 0.00352053 0.739363 0.47546 0.936789 0.711024 0.776644 0.155087 0.317745 0.454938 0.478154 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92936 episodes
GETTING ACTION FROM:
action 5, numVisits=92926, meanQ=10.275190, numObservations: 9
action 3, numVisits=5, meanQ=3.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 1 0.00352053 0.739363 0.47546 0.936789 0.711024 0.776644 0.155087 0.317745 0.454938 0.478154 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 11
Initial state: 0 0.80274 0.80186 0.529351 0.995636 0.408904 0.478263 0.105989 0.90492 0.886426 0.158504 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92833 episodes
GETTING ACTION FROM:
action 2, numVisits=92827, meanQ=10.257135, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.80274 0.80186 0.529351 0.995636 0.408904 0.478263 0.105989 0.90492 0.886426 0.158504 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 12
Initial state: 0 0.138964 0.0971425 0.493825 0.45161 0.238662 0.612358 0.426917 0.552689 0.26746 0.3222 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89690 episodes
GETTING ACTION FROM:
action 2, numVisits=89632, meanQ=10.291523, numObservations: 9
action -1, numVisits=42, meanQ=-0.609993, numObservations: 38
action 0, numVisits=11, meanQ=-1.370900, numObservations: 10
action 1, numVisits=2, meanQ=-7.500000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.138964 0.0971425 0.493825 0.45161 0.238662 0.612358 0.426917 0.552689 0.26746 0.3222 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 13
Initial state: 0 0.567429 0.511682 0.389595 0.567659 0.0137204 0.0874066 0.19465 0.37938 0.766168 0.952262 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92386 episodes
GETTING ACTION FROM:
action 4, numVisits=92372, meanQ=10.242699, numObservations: 9
action 2, numVisits=7, meanQ=2.000000, numObservations: 6
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.567429 0.511682 0.389595 0.567659 0.0137204 0.0874066 0.19465 0.37938 0.766168 0.952262 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=9596, meanQ=10.458371, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 27200 episodes
GETTING ACTION FROM:
action 2, numVisits=36788, meanQ=10.526825, numObservations: 9
action -1, numVisits=5, meanQ=-1.010000, numObservations: 5
action 0, numVisits=5, meanQ=-1.010000, numObservations: 5
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.567429 0.511682 0.389595 0.567659 0.0137204 0.0874066 0.19465 0.37938 0.766168 0.952262 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 14
Initial state: 0 0.387252 0.526744 0.391371 0.871253 0.203112 0.40552 0.503766 0.52071 0.703703 0.32652 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92374 episodes
GETTING ACTION FROM:
action 1, numVisits=92334, meanQ=10.386654, numObservations: 9
action 2, numVisits=27, meanQ=7.147415, numObservations: 9
action 5, numVisits=7, meanQ=4.000000, numObservations: 4
action 3, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.387252 0.526744 0.391371 0.871253 0.203112 0.40552 0.503766 0.52071 0.703703 0.32652 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 15
Initial state: 0 0.370593 0.674321 0.400888 0.515296 0.528333 0.337787 0.998387 0.079956 0.158554 0.943789 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92293 episodes
GETTING ACTION FROM:
action 1, numVisits=92281, meanQ=10.357534, numObservations: 9
action 2, numVisits=7, meanQ=6.282857, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.370593 0.674321 0.400888 0.515296 0.528333 0.337787 0.998387 0.079956 0.158554 0.943789 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=2809, meanQ=11.357113, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 40865 episodes
GETTING ACTION FROM:
action 4, numVisits=43661, meanQ=11.616426, numObservations: 9
action -1, numVisits=8, meanQ=-1.133750, numObservations: 8
action 0, numVisits=7, meanQ=-1.292857, numObservations: 7
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.370593 0.674321 0.400888 0.515296 0.528333 0.337787 0.998387 0.079956 0.158554 0.943789 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 16
Initial state: 0 0.593961 0.668033 0.611499 0.957126 0.399994 0.481042 0.666105 0.59942 0.981537 0.863203 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88187 episodes
GETTING ACTION FROM:
action 2, numVisits=88147, meanQ=10.417707, numObservations: 9
action 5, numVisits=31, meanQ=8.906461, numObservations: 8
action 1, numVisits=5, meanQ=5.998000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.593961 0.668033 0.611499 0.957126 0.399994 0.481042 0.666105 0.59942 0.981537 0.863203 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 17
Initial state: 0 0.947583 0.947711 0.384411 0.424502 0.686831 0.340349 0.649715 0.376611 0.614376 0.627229 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92341 episodes
GETTING ACTION FROM:
action 2, numVisits=92329, meanQ=10.269804, numObservations: 9
action 1, numVisits=7, meanQ=5.000000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.947583 0.947711 0.384411 0.424502 0.686831 0.340349 0.649715 0.376611 0.614376 0.627229 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 18
Initial state: 0 0.916964 0.671043 0.740225 0.741248 0.166247 0.472433 0.475965 0.471903 0.333045 0.908262 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 93269 episodes
GETTING ACTION FROM:
action 4, numVisits=86253, meanQ=10.311362, numObservations: 9
action 2, numVisits=7011, meanQ=10.045769, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.916964 0.671043 0.740225 0.741248 0.166247 0.472433 0.475965 0.471903 0.333045 0.908262 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 19
Initial state: 0 0.640169 0.681555 0.312623 0.968996 0.488723 0.00903476 0.275 0.365906 0.424786 0.547117 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88695 episodes
GETTING ACTION FROM:
action 5, numVisits=88689, meanQ=10.148380, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.640169 0.681555 0.312623 0.968996 0.488723 0.00903476 0.275 0.365906 0.424786 0.547117 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 20
Initial state: 0 0.448556 0.423709 0.821237 0.997594 0.917782 0.513914 0.635616 0.907721 0.743632 0.114884 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91790 episodes
GETTING ACTION FROM:
action 3, numVisits=91733, meanQ=10.129744, numObservations: 9
action 2, numVisits=36, meanQ=7.721117, numObservations: 9
action 4, numVisits=11, meanQ=6.727282, numObservations: 6
action 5, numVisits=7, meanQ=5.141429, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 2 0.448556 0.423709 0.821237 0.997594 0.917782 0.513914 0.635616 0.907721 0.743632 0.114884 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 21
Initial state: 0 0.396524 0.262129 0.460374 0.556817 0.0732035 0.119165 0.319678 0.86938 0.139651 0.3881 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89558 episodes
GETTING ACTION FROM:
action 5, numVisits=89526, meanQ=10.064144, numObservations: 9
action 3, numVisits=25, meanQ=7.944000, numObservations: 7
action 2, numVisits=3, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.396524 0.262129 0.460374 0.556817 0.0732035 0.119165 0.319678 0.86938 0.139651 0.3881 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=9203, meanQ=10.897824, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 26480 episodes
GETTING ACTION FROM:
action 3, numVisits=35454, meanQ=10.263807, numObservations: 9
action 2, numVisits=223, meanQ=6.245350, numObservations: 9
action -1, numVisits=5, meanQ=-1.208000, numObservations: 5
action 0, numVisits=4, meanQ=-1.505000, numObservations: 4
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.396524 0.262129 0.460374 0.556817 0.0732035 0.119165 0.319678 0.86938 0.139651 0.3881 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=2949, meanQ=11.910514, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 27442 episodes
GETTING ACTION FROM:
action 4, numVisits=30391, meanQ=14.268960, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.396524 0.262129 0.460374 0.556817 0.0732035 0.119165 0.319678 0.86938 0.139651 0.3881 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 22
Initial state: 0 0.924462 0.742127 0.968542 0.593755 0.546985 0.550462 0.393342 0.555282 0.719522 0.845129 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92805 episodes
GETTING ACTION FROM:
action 5, numVisits=92799, meanQ=10.332807, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 1 0.924462 0.742127 0.968542 0.593755 0.546985 0.550462 0.393342 0.555282 0.719522 0.845129 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 23
Initial state: 0 0.475556 0.532886 0.874265 0.611347 0.639588 0.459223 0.584448 0.85181 0.201123 0.329781 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87888 episodes
GETTING ACTION FROM:
action 2, numVisits=87874, meanQ=10.368910, numObservations: 9
action 1, numVisits=9, meanQ=7.004467, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.475556 0.532886 0.874265 0.611347 0.639588 0.459223 0.584448 0.85181 0.201123 0.329781 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 24
Initial state: 0 0.53475 0.788559 0.987554 0.20332 0.717545 0.0212124 0.449065 0.584821 0.78484 0.8277 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91962 episodes
GETTING ACTION FROM:
action 2, numVisits=91954, meanQ=10.383344, numObservations: 9
action 3, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.53475 0.788559 0.987554 0.20332 0.717545 0.0212124 0.449065 0.584821 0.78484 0.8277 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 25
Initial state: 0 0.20428 0.634025 0.196605 0.74018 0.425673 0.439134 0.585538 0.0708461 0.706349 0.680721 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91856 episodes
GETTING ACTION FROM:
action 5, numVisits=91756, meanQ=10.147834, numObservations: 9
action 3, numVisits=48, meanQ=8.135842, numObservations: 8
action 1, numVisits=33, meanQ=8.105761, numObservations: 8
action 2, numVisits=13, meanQ=6.921538, numObservations: 5
action 4, numVisits=4, meanQ=6.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 5
Next state: 1 0.20428 0.634025 0.196605 0.74018 0.425673 0.439134 0.585538 0.0708461 0.706349 0.680721 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 26
Initial state: 0 0.391675 0.431767 0.484806 0.926841 0.220207 0.931097 0.0048964 0.800987 0.257195 0.458362 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92652 episodes
GETTING ACTION FROM:
action 1, numVisits=92605, meanQ=10.459259, numObservations: 9
action 3, numVisits=15, meanQ=8.600000, numObservations: 7
action 5, numVisits=15, meanQ=8.532020, numObservations: 6
action 2, numVisits=14, meanQ=7.928579, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.391675 0.431767 0.484806 0.926841 0.220207 0.931097 0.0048964 0.800987 0.257195 0.458362 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 27
Initial state: 0 0.301261 0.374913 0.492293 0.800091 0.660874 0.560488 0.968675 0.00258708 0.371039 0.585225 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87870 episodes
GETTING ACTION FROM:
action 3, numVisits=87855, meanQ=10.295403, numObservations: 9
action 2, numVisits=4, meanQ=6.500000, numObservations: 3
action 4, numVisits=7, meanQ=6.000000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.301261 0.374913 0.492293 0.800091 0.660874 0.560488 0.968675 0.00258708 0.371039 0.585225 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 28
Initial state: 0 0.468381 0.459158 0.0655029 0.512248 0.512134 0.807938 0.143197 0.0550378 0.259104 0.653188 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92733 episodes
GETTING ACTION FROM:
action 3, numVisits=92332, meanQ=10.381882, numObservations: 9
action 1, numVisits=392, meanQ=9.996044, numObservations: 9
action 2, numVisits=3, meanQ=3.000000, numObservations: 2
action 5, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.468381 0.459158 0.0655029 0.512248 0.512134 0.807938 0.143197 0.0550378 0.259104 0.653188 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 29
Initial state: 0 0.387909 0.818404 0.0091319 0.0502572 0.0848343 0.757654 0.404482 0.504863 0.024363 0.158287 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92005 episodes
GETTING ACTION FROM:
action 2, numVisits=91990, meanQ=10.068121, numObservations: 9
action 4, numVisits=4, meanQ=6.500000, numObservations: 4
action 5, numVisits=7, meanQ=6.141429, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.387909 0.818404 0.0091319 0.0502572 0.0848343 0.757654 0.404482 0.504863 0.024363 0.158287 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=9399, meanQ=11.041742, numObservations: 9
action 1, numVisits=4, meanQ=1.745000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 25926 episodes
GETTING ACTION FROM:
action 3, numVisits=35316, meanQ=10.639175, numObservations: 9
action 1, numVisits=4, meanQ=1.745000, numObservations: 4
action -1, numVisits=5, meanQ=-1.010000, numObservations: 5
action 0, numVisits=5, meanQ=-1.208000, numObservations: 5
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 3
Next state: 1 0.387909 0.818404 0.0091319 0.0502572 0.0848343 0.757654 0.404482 0.504863 0.024363 0.158287 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 30
Initial state: 0 0.576331 0.386973 0.565399 0.0643178 0.911293 0.656649 0.669539 0.992833 0.403544 0.442372 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92844 episodes
GETTING ACTION FROM:
action 3, numVisits=92826, meanQ=10.328761, numObservations: 9
action 2, numVisits=11, meanQ=6.907282, numObservations: 5
action 5, numVisits=3, meanQ=5.663333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.576331 0.386973 0.565399 0.0643178 0.911293 0.656649 0.669539 0.992833 0.403544 0.442372 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 31
Initial state: 0 0.917477 0.37758 0.961494 0.175186 0.410755 0.139884 0.407965 0.453786 0.623741 0.807939 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92477 episodes
GETTING ACTION FROM:
action 4, numVisits=92463, meanQ=10.013104, numObservations: 9
action 1, numVisits=5, meanQ=3.000000, numObservations: 3
action 5, numVisits=3, meanQ=3.000000, numObservations: 3
action 3, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.917477 0.37758 0.961494 0.175186 0.410755 0.139884 0.407965 0.453786 0.623741 0.807939 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 32
Initial state: 0 0.799399 0.375159 0.136373 0.40373 0.258175 0.803153 0.4167 0.524787 0.044992 0.736719 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89775 episodes
GETTING ACTION FROM:
action 2, numVisits=89760, meanQ=10.348648, numObservations: 9
action 3, numVisits=5, meanQ=4.400000, numObservations: 3
action 5, numVisits=6, meanQ=4.165017, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.799399 0.375159 0.136373 0.40373 0.258175 0.803153 0.4167 0.524787 0.044992 0.736719 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=446, meanQ=13.611693, numObservations: 9
action 0, numVisits=21, meanQ=-0.114757, numObservations: 19
action -1, numVisits=6, meanQ=-1.671650, numObservations: 5
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 61434 episodes
GETTING ACTION FROM:
action 2, numVisits=460, meanQ=13.662262, numObservations: 9
action 3, numVisits=61361, meanQ=12.506435, numObservations: 9
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=63, meanQ=-17.520845, numObservations: 52
action -1, numVisits=24, meanQ=-45.353228, numObservations: 21
action: 2
Next state: 0 0.799399 0.375159 0.136373 0.40373 0.258175 0.803153 0.4167 0.524787 0.044992 0.736719 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=9, meanQ=10.934806, numObservations: 6
action 4, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 47806 episodes
GETTING ACTION FROM:
action 3, numVisits=47799, meanQ=11.322431, numObservations: 9
action 4, numVisits=3, meanQ=1.221798, numObservations: 3
action 0, numVisits=9, meanQ=-1.450000, numObservations: 9
action -1, numVisits=8, meanQ=-1.505000, numObservations: 7
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.799399 0.375159 0.136373 0.40373 0.258175 0.803153 0.4167 0.524787 0.044992 0.736719 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 33
Initial state: 0 0.74529 0.331819 0.76483 0.351021 0.220494 0.85935 0.44477 0.506441 0.0602816 0.138669 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92313 episodes
GETTING ACTION FROM:
action 4, numVisits=92307, meanQ=10.151784, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 1 0.74529 0.331819 0.76483 0.351021 0.220494 0.85935 0.44477 0.506441 0.0602816 0.138669 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 34
Initial state: 0 0.849772 0.351943 0.426483 0.339336 0.421262 0.540346 0.496716 0.184845 0.840042 0.137793 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89079 episodes
GETTING ACTION FROM:
action 1, numVisits=89069, meanQ=10.452102, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.849772 0.351943 0.426483 0.339336 0.421262 0.540346 0.496716 0.184845 0.840042 0.137793 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 35
Initial state: 0 0.289515 0.861177 0.790624 0.872578 0.395981 0.526807 0.289367 0.123715 0.796187 0.233376 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89905 episodes
GETTING ACTION FROM:
action 3, numVisits=89875, meanQ=10.244752, numObservations: 9
action 4, numVisits=19, meanQ=8.671058, numObservations: 8
action 5, numVisits=5, meanQ=5.998000, numObservations: 5
action 2, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.289515 0.861177 0.790624 0.872578 0.395981 0.526807 0.289367 0.123715 0.796187 0.233376 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 36
Initial state: 0 0.105249 0.332285 0.462238 0.540401 0.444435 0.60848 0.978631 0.490882 0.676722 0.127457 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91969 episodes
GETTING ACTION FROM:
action 2, numVisits=91959, meanQ=10.247858, numObservations: 9
action 4, numVisits=5, meanQ=5.998000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.105249 0.332285 0.462238 0.540401 0.444435 0.60848 0.978631 0.490882 0.676722 0.127457 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 37
Initial state: 0 0.351944 0.645318 0.571149 0.310305 0.035542 0.297261 0.0716747 0.627194 0.418994 0.520053 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91836 episodes
GETTING ACTION FROM:
action 2, numVisits=91830, meanQ=10.119472, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 2 0.351944 0.645318 0.571149 0.310305 0.035542 0.297261 0.0716747 0.627194 0.418994 0.520053 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 38
Initial state: 0 0.395265 0.420934 0.87825 0.530974 0.7506 0.45028 0.323996 0.187428 0.563149 0.698348 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 90972 episodes
GETTING ACTION FROM:
action 5, numVisits=90936, meanQ=10.259867, numObservations: 9
action 3, numVisits=27, meanQ=8.355189, numObservations: 8
action 2, numVisits=3, meanQ=5.663333, numObservations: 3
action 1, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.395265 0.420934 0.87825 0.530974 0.7506 0.45028 0.323996 0.187428 0.563149 0.698348 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 39
Initial state: 0 0.81161 0.822185 0.478057 0.143883 0.923426 0.965246 0.445115 0.571081 0.0225343 0.312289 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91253 episodes
GETTING ACTION FROM:
action 5, numVisits=91243, meanQ=10.192810, numObservations: 9
action 4, numVisits=3, meanQ=3.330000, numObservations: 3
action 1, numVisits=3, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.81161 0.822185 0.478057 0.143883 0.923426 0.965246 0.445115 0.571081 0.0225343 0.312289 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=9588, meanQ=10.951109, numObservations: 9
action 3, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 27679 episodes
GETTING ACTION FROM:
action 4, numVisits=37261, meanQ=10.318752, numObservations: 9
action 3, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=4, meanQ=-1.257500, numObservations: 4
action 0, numVisits=4, meanQ=-1.257500, numObservations: 4
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.81161 0.822185 0.478057 0.143883 0.923426 0.965246 0.445115 0.571081 0.0225343 0.312289 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 40
Initial state: 0 0.0522806 0.932499 0.409477 0.574454 0.0563855 0.454487 0.642651 0.319076 0.750824 0.528862 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88608 episodes
GETTING ACTION FROM:
action 4, numVisits=88600, meanQ=10.281651, numObservations: 9
action 1, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.0522806 0.932499 0.409477 0.574454 0.0563855 0.454487 0.642651 0.319076 0.750824 0.528862 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 41
Initial state: 0 0.00601142 0.111607 0.370863 0.513308 0.438799 0.482302 0.888696 0.0918896 0.856746 0.783409 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91882 episodes
GETTING ACTION FROM:
action 2, numVisits=91872, meanQ=10.230001, numObservations: 9
action 1, numVisits=3, meanQ=3.000000, numObservations: 2
action 3, numVisits=3, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.00601142 0.111607 0.370863 0.513308 0.438799 0.482302 0.888696 0.0918896 0.856746 0.783409 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=7875, meanQ=11.221035, numObservations: 9
action 3, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 41806 episodes
GETTING ACTION FROM:
action 4, numVisits=41801, meanQ=13.723963, numObservations: 9
action 1, numVisits=7877, meanQ=11.221806, numObservations: 9
action 3, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=3, meanQ=-1.340000, numObservations: 3
action 0, numVisits=3, meanQ=-1.670000, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 2 0.00601142 0.111607 0.370863 0.513308 0.438799 0.482302 0.888696 0.0918896 0.856746 0.783409 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 42
Initial state: 0 0.158235 0.815264 0.360841 0.944765 0.873082 0.486403 0.606985 0.753281 0.418654 0.482882 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92743 episodes
GETTING ACTION FROM:
action 2, numVisits=92737, meanQ=10.327519, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.158235 0.815264 0.360841 0.944765 0.873082 0.486403 0.606985 0.753281 0.418654 0.482882 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=7842, meanQ=11.177724, numObservations: 9
action 1, numVisits=41, meanQ=9.903176, numObservations: 8
action 4, numVisits=42, meanQ=9.902383, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 36357 episodes
GETTING ACTION FROM:
action 3, numVisits=43837, meanQ=12.471223, numObservations: 9
action 4, numVisits=255, meanQ=8.952325, numObservations: 9
action 1, numVisits=186, meanQ=6.984712, numObservations: 9
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action -1, numVisits=3, meanQ=-1.340000, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.158235 0.815264 0.360841 0.944765 0.873082 0.486403 0.606985 0.753281 0.418654 0.482882 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 43
Initial state: 0 0.0566167 0.284858 0.5046 0.197597 0.446849 0.440184 0.508315 0.040761 0.46247 0.884744 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92241 episodes
GETTING ACTION FROM:
action 2, numVisits=92233, meanQ=10.286373, numObservations: 9
action 4, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.0566167 0.284858 0.5046 0.197597 0.446849 0.440184 0.508315 0.040761 0.46247 0.884744 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 44
Initial state: 0 0.351242 0.704779 0.458601 0.433452 0.756575 0.412895 0.978081 0.199934 0.818818 0.334963 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91354 episodes
GETTING ACTION FROM:
action 2, numVisits=91341, meanQ=10.365122, numObservations: 9
action 3, numVisits=8, meanQ=7.357500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.351242 0.704779 0.458601 0.433452 0.756575 0.412895 0.978081 0.199934 0.818818 0.334963 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 45
Initial state: 0 0.92715 0.0895632 0.448225 0.557545 0.207655 0.961962 0.731894 0.0762015 0.31851 0.0222541 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89172 episodes
GETTING ACTION FROM:
action 5, numVisits=89151, meanQ=10.382978, numObservations: 9
action 1, numVisits=16, meanQ=7.375000, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.92715 0.0895632 0.448225 0.557545 0.207655 0.961962 0.731894 0.0762015 0.31851 0.0222541 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=9314, meanQ=11.037880, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 31126 episodes
GETTING ACTION FROM:
action 1, numVisits=40429, meanQ=10.588255, numObservations: 9
action 2, numVisits=4, meanQ=-0.252500, numObservations: 3
action 0, numVisits=5, meanQ=-1.406000, numObservations: 5
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=4, meanQ=-3.783789, numObservations: 3
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.92715 0.0895632 0.448225 0.557545 0.207655 0.961962 0.731894 0.0762015 0.31851 0.0222541 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 46
Initial state: 0 0.37281 0.577734 0.695176 0.24328 0.0323828 0.902582 0.0495709 0.959968 0.250244 0.400258 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92338 episodes
GETTING ACTION FROM:
action 2, numVisits=92324, meanQ=10.391451, numObservations: 9
action 5, numVisits=7, meanQ=6.000000, numObservations: 4
action 4, numVisits=3, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 2 0.37281 0.577734 0.695176 0.24328 0.0323828 0.902582 0.0495709 0.959968 0.250244 0.400258 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 47
Initial state: 0 0.734918 0.0360386 0.949219 0.539406 0.419766 0.583819 0.45988 0.797528 0.217908 0.81947 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89842 episodes
GETTING ACTION FROM:
action 1, numVisits=89832, meanQ=10.432380, numObservations: 9
action 4, numVisits=3, meanQ=5.663333, numObservations: 2
action 5, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.734918 0.0360386 0.949219 0.539406 0.419766 0.583819 0.45988 0.797528 0.217908 0.81947 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 48
Initial state: 0 0.435332 0.461339 0.855446 0.824598 0.0257835 0.583891 0.511042 0.470764 0.837284 0.671101 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 93149 episodes
GETTING ACTION FROM:
action 1, numVisits=84130, meanQ=10.150717, numObservations: 9
action 2, numVisits=9001, meanQ=10.069674, numObservations: 9
action 4, numVisits=14, meanQ=7.267857, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.435332 0.461339 0.855446 0.824598 0.0257835 0.583891 0.511042 0.470764 0.837284 0.671101 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=1442, meanQ=9.954939, numObservations: 9
action 3, numVisits=10, meanQ=3.799000, numObservations: 5
action 1, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 95384 episodes
GETTING ACTION FROM:
action 4, numVisits=96820, meanQ=12.242331, numObservations: 9
action 3, numVisits=10, meanQ=3.799000, numObservations: 5
action 1, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=4, meanQ=-1.752500, numObservations: 3
action 0, numVisits=4, meanQ=-1.752500, numObservations: 4
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 1 0.435332 0.461339 0.855446 0.824598 0.0257835 0.583891 0.511042 0.470764 0.837284 0.671101 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 49
Initial state: 0 0.537216 0.0226127 0.358011 0.0918268 0.264819 0.67767 0.3762 0.482301 0.553104 0.775962 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91954 episodes
GETTING ACTION FROM:
action 4, numVisits=91931, meanQ=10.360548, numObservations: 9
action 1, numVisits=12, meanQ=6.499175, numObservations: 8
action 3, numVisits=7, meanQ=6.000000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 0 0.537216 0.0226127 0.358011 0.0918268 0.264819 0.67767 0.3762 0.482301 0.553104 0.775962 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=344, meanQ=9.949685, numObservations: 9
action 4, numVisits=3, meanQ=5.993333, numObservations: 3
action 1, numVisits=7, meanQ=5.141429, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 85296 episodes
GETTING ACTION FROM:
action 1, numVisits=85252, meanQ=10.252394, numObservations: 9
action 2, numVisits=363, meanQ=9.861479, numObservations: 9
action 4, numVisits=15, meanQ=6.865333, numObservations: 6
action -1, numVisits=11, meanQ=-1.910000, numObservations: 10
action 0, numVisits=11, meanQ=-1.910000, numObservations: 11
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.537216 0.0226127 0.358011 0.0918268 0.264819 0.67767 0.3762 0.482301 0.553104 0.775962 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 50
Initial state: 0 0.805349 0.665048 0.398665 0.501378 0.350846 0.91838 0.548132 0.206501 0.543621 0.102312 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92837 episodes
GETTING ACTION FROM:
action 1, numVisits=92831, meanQ=10.207070, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.805349 0.665048 0.398665 0.501378 0.350846 0.91838 0.548132 0.206501 0.543621 0.102312 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
[32m ProblemEnvironment.hpp 351: Done.[39m
