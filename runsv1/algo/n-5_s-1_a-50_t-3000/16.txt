Run # 1
Initial state: 0 0.874958 0.686467 0.820761 0.62794 0.769709 0.0239533 0.895794 0.47766 0.55429 0.489442 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79149 episodes
GETTING ACTION FROM:
action 5, numVisits=79138, meanQ=9.789646, numObservations: 9
action 1, numVisits=6, meanQ=4.670033, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.874958 0.686467 0.820761 0.62794 0.769709 0.0239533 0.895794 0.47766 0.55429 0.489442 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 2
Initial state: 0 0.55575 0.486448 0.571605 0.840004 0.039561 0.879459 0.0292829 0.858592 0.179382 0.8192 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79166 episodes
GETTING ACTION FROM:
action 4, numVisits=79153, meanQ=9.679752, numObservations: 9
action 3, numVisits=8, meanQ=3.875000, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.55575 0.486448 0.571605 0.840004 0.039561 0.879459 0.0292829 0.858592 0.179382 0.8192 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 3
Initial state: 0 0.526494 0.908412 0.580692 0.443868 0.787006 0.976454 0.202468 0.00116397 0.698508 0.917248 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80244 episodes
GETTING ACTION FROM:
action 3, numVisits=80238, meanQ=9.830479, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.526494 0.908412 0.580692 0.443868 0.787006 0.976454 0.202468 0.00116397 0.698508 0.917248 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 4
Initial state: 0 0.0816856 0.618472 0.71509 0.297022 0.708291 0.0747415 0.510975 0.790374 0.5196 0.487246 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 75998 episodes
GETTING ACTION FROM:
action 3, numVisits=75968, meanQ=9.839036, numObservations: 9
action 5, numVisits=18, meanQ=7.389467, numObservations: 8
action 1, numVisits=8, meanQ=5.121250, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.0816856 0.618472 0.71509 0.297022 0.708291 0.0747415 0.510975 0.790374 0.5196 0.487246 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 5
Initial state: 0 0.841509 0.651473 0.621568 0.506971 0.740872 0.911692 0.0664549 0.152572 0.926759 0.787796 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79355 episodes
GETTING ACTION FROM:
action 1, numVisits=79345, meanQ=9.806628, numObservations: 9
action 3, numVisits=5, meanQ=5.600020, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.841509 0.651473 0.621568 0.506971 0.740872 0.911692 0.0664549 0.152572 0.926759 0.787796 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 6
Initial state: 0 0.661742 0.592463 0.706506 0.623789 0.738899 0.838355 0.223458 0.21878 0.983593 0.902898 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79405 episodes
GETTING ACTION FROM:
action 5, numVisits=79399, meanQ=9.610438, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 1 0.661742 0.592463 0.706506 0.623789 0.738899 0.838355 0.223458 0.21878 0.983593 0.902898 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 7
Initial state: 0 0.100559 0.795866 0.166199 0.793012 0.617781 0.55445 0.346259 0.12553 0.311183 0.891071 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80327 episodes
GETTING ACTION FROM:
action 5, numVisits=80304, meanQ=10.045929, numObservations: 9
action 3, numVisits=13, meanQ=4.315392, numObservations: 7
action 4, numVisits=6, meanQ=3.518333, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.100559 0.795866 0.166199 0.793012 0.617781 0.55445 0.346259 0.12553 0.311183 0.891071 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=9411, meanQ=10.818149, numObservations: 9
action 4, numVisits=13, meanQ=7.768477, numObservations: 5
action 5, numVisits=5, meanQ=6.196000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 22086 episodes
GETTING ACTION FROM:
action 2, numVisits=31410, meanQ=12.465355, numObservations: 9
action 4, numVisits=93, meanQ=9.336853, numObservations: 9
action 5, numVisits=7, meanQ=7.140014, numObservations: 4
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=3, meanQ=-1.340000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.100559 0.795866 0.166199 0.793012 0.617781 0.55445 0.346259 0.12553 0.311183 0.891071 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 8
Initial state: 0 0.54028 0.494957 0.297477 0.687444 0.293585 0.749674 0.40682 0.069904 0.491632 0.153168 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80071 episodes
GETTING ACTION FROM:
action 1, numVisits=80063, meanQ=9.780674, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.54028 0.494957 0.297477 0.687444 0.293585 0.749674 0.40682 0.069904 0.491632 0.153168 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 9
Initial state: 0 0.10937 0.175092 0.0962763 0.180096 0.347072 0.0859599 0.516157 0.563887 0.0629767 0.895704 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80472 episodes
GETTING ACTION FROM:
action 5, numVisits=80466, meanQ=9.777754, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.10937 0.175092 0.0962763 0.180096 0.347072 0.0859599 0.516157 0.563887 0.0629767 0.895704 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=559, meanQ=11.616303, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 89191 episodes
GETTING ACTION FROM:
action 1, numVisits=89750, meanQ=14.810141, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.10937 0.175092 0.0962763 0.180096 0.347072 0.0859599 0.516157 0.563887 0.0629767 0.895704 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=1201, meanQ=14.655288, numObservations: 9
action 4, numVisits=28, meanQ=5.713936, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 73268 episodes
GETTING ACTION FROM:
action 3, numVisits=74467, meanQ=14.601888, numObservations: 9
action 4, numVisits=28, meanQ=5.713936, numObservations: 8
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.10937 0.175092 0.0962763 0.180096 0.347072 0.0859599 0.516157 0.563887 0.0629767 0.895704 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=972, meanQ=19.533639, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 83379 episodes
GETTING ACTION FROM:
action 2, numVisits=84351, meanQ=18.098910, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.10937 0.175092 0.0962763 0.180096 0.347072 0.0859599 0.516157 0.563887 0.0629767 0.895704 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 5, numVisits=1, meanQ=24.000000, numObservations: 1
action 4, numVisits=650, meanQ=22.781722, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-9.487303, numObservations: 1
action 3, numVisits=1, meanQ=-9.835309, numObservations: 1
action 2, numVisits=1, meanQ=-9.967697, numObservations: 1
Sampled 109979 episodes
GETTING ACTION FROM:
action 4, numVisits=110628, meanQ=21.711795, numObservations: 9
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-9.487303, numObservations: 1
action 3, numVisits=1, meanQ=-9.835309, numObservations: 1
action 2, numVisits=1, meanQ=-9.967697, numObservations: 1
action: 4
Next state: 1 0.10937 0.175092 0.0962763 0.180096 0.347072 0.0859599 0.516157 0.563887 0.0629767 0.895704 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.29271
Run # 10
Initial state: 0 0.300401 0.111464 0.714146 0.413703 0.670431 0.457121 0.116985 0.301032 0.421044 0.194864 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80111 episodes
GETTING ACTION FROM:
action 2, numVisits=80089, meanQ=9.904833, numObservations: 9
action 3, numVisits=17, meanQ=7.411776, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.300401 0.111464 0.714146 0.413703 0.670431 0.457121 0.116985 0.301032 0.421044 0.194864 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 11
Initial state: 0 0.938072 0.687257 0.606034 0.594525 0.896199 0.870827 0.998177 0.415884 0.670222 0.262639 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80337 episodes
GETTING ACTION FROM:
action 4, numVisits=80304, meanQ=9.693878, numObservations: 9
action 3, numVisits=28, meanQ=4.795007, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.938072 0.687257 0.606034 0.594525 0.896199 0.870827 0.998177 0.415884 0.670222 0.262639 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 12
Initial state: 0 0.140976 0.729022 0.525385 0.885896 0.731687 0.426827 0.601444 0.48315 0.282991 0.689807 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80498 episodes
GETTING ACTION FROM:
action 3, numVisits=80471, meanQ=9.685645, numObservations: 9
action 5, numVisits=18, meanQ=7.513889, numObservations: 7
action 4, numVisits=3, meanQ=3.330000, numObservations: 3
action 1, numVisits=3, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.140976 0.729022 0.525385 0.885896 0.731687 0.426827 0.601444 0.48315 0.282991 0.689807 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=1604, meanQ=10.414861, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 77320 episodes
GETTING ACTION FROM:
action 4, numVisits=78861, meanQ=5.912563, numObservations: 9
action 5, numVisits=18, meanQ=3.055000, numObservations: 8
action -1, numVisits=24, meanQ=-1.628750, numObservations: 24
action 0, numVisits=23, meanQ=-1.698696, numObservations: 20
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.140976 0.729022 0.525385 0.885896 0.731687 0.426827 0.601444 0.48315 0.282991 0.689807 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 13
Initial state: 0 0.657752 0.554754 0.720759 0.789374 0.696623 0.978095 0.0461644 0.64838 0.0734041 0.0264168 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80832 episodes
GETTING ACTION FROM:
action 5, numVisits=80808, meanQ=9.755050, numObservations: 9
action 1, numVisits=15, meanQ=-0.131320, numObservations: 8
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.657752 0.554754 0.720759 0.789374 0.696623 0.978095 0.0461644 0.64838 0.0734041 0.0264168 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=13299, meanQ=11.186736, numObservations: 9
action 2, numVisits=8, meanQ=4.625013, numObservations: 7
action 3, numVisits=3, meanQ=3.330000, numObservations: 3
action 1, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 18777 episodes
GETTING ACTION FROM:
action 4, numVisits=31926, meanQ=10.124153, numObservations: 9
action 2, numVisits=126, meanQ=1.627241, numObservations: 9
action 1, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=8, meanQ=-1.133750, numObservations: 8
action 0, numVisits=6, meanQ=-2.679362, numObservations: 5
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=23, meanQ=-38.088825, numObservations: 8
action: 4
Next state: 1 0.657752 0.554754 0.720759 0.789374 0.696623 0.978095 0.0461644 0.64838 0.0734041 0.0264168 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 14
Initial state: 0 0.821157 0.535394 0.32005 0.636844 0.919483 0.872675 0.669452 0.578302 0.247839 0.016932 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 77274 episodes
GETTING ACTION FROM:
action 1, numVisits=77268, meanQ=9.894286, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.821157 0.535394 0.32005 0.636844 0.919483 0.872675 0.669452 0.578302 0.247839 0.016932 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 15
Initial state: 0 0.135556 0.438933 0.600732 0.525744 0.827935 0.990259 0.480605 0.55663 0.670517 0.325904 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80919 episodes
GETTING ACTION FROM:
action 4, numVisits=80905, meanQ=9.862900, numObservations: 9
action 2, numVisits=9, meanQ=3.892256, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.135556 0.438933 0.600732 0.525744 0.827935 0.990259 0.480605 0.55663 0.670517 0.325904 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=3218, meanQ=11.221429, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=2, meanQ=-4.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 19239 episodes
GETTING ACTION FROM:
action 2, numVisits=22407, meanQ=10.494744, numObservations: 9
action 0, numVisits=30, meanQ=-1.670330, numObservations: 28
action -1, numVisits=32, meanQ=-1.784366, numObservations: 26
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=2, meanQ=-4.004950, numObservations: 1
action 1, numVisits=2, meanQ=-4.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.135556 0.438933 0.600732 0.525744 0.827935 0.990259 0.480605 0.55663 0.670517 0.325904 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 16
Initial state: 0 0.539437 0.527459 0.218302 0.775356 0.838668 0.760004 0.755207 0.424317 0.346311 0.292095 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79650 episodes
GETTING ACTION FROM:
action 4, numVisits=79644, meanQ=9.841367, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.539437 0.527459 0.218302 0.775356 0.838668 0.760004 0.755207 0.424317 0.346311 0.292095 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 17
Initial state: 0 0.675938 0.237385 0.193806 0.72756 0.610644 0.505408 0.18499 0.907884 0.283137 0.183184 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 74976 episodes
GETTING ACTION FROM:
action 2, numVisits=74968, meanQ=9.745972, numObservations: 9
action 3, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.675938 0.237385 0.193806 0.72756 0.610644 0.505408 0.18499 0.907884 0.283137 0.183184 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=8969, meanQ=12.604185, numObservations: 9
action 4, numVisits=8, meanQ=10.495000, numObservations: 8
action 3, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 30527 episodes
GETTING ACTION FROM:
action 1, numVisits=30203, meanQ=15.088831, numObservations: 9
action 2, numVisits=8969, meanQ=12.604185, numObservations: 9
action -1, numVisits=299, meanQ=-3.826408, numObservations: 105
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=19, meanQ=-57.339903, numObservations: 17
action 4, numVisits=11, meanQ=-90.726714, numObservations: 8
action 3, numVisits=9, meanQ=-111.479051, numObservations: 8
action: 1
Next state: 0 0.675938 0.237385 0.193806 0.72756 0.610644 0.505408 0.18499 0.907884 0.283137 0.183184 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=1, meanQ=24.000000, numObservations: 1
action 5, numVisits=344, meanQ=14.753322, numObservations: 9
action 4, numVisits=3, meanQ=1.297867, numObservations: 3
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=1, meanQ=-9.415062, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 65013 episodes
GETTING ACTION FROM:
action 5, numVisits=65350, meanQ=9.195111, numObservations: 9
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action 4, numVisits=3, meanQ=1.297867, numObservations: 3
action -1, numVisits=5, meanQ=-1.604000, numObservations: 5
action 0, numVisits=5, meanQ=-1.604000, numObservations: 5
action 3, numVisits=1, meanQ=-9.415062, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.675938 0.237385 0.193806 0.72756 0.610644 0.505408 0.18499 0.907884 0.283137 0.183184 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=1, meanQ=24.000000, numObservations: 1
action 4, numVisits=918, meanQ=15.120307, numObservations: 9
action 3, numVisits=37, meanQ=-9.573779, numObservations: 9
action 1, numVisits=1, meanQ=-9.581186, numObservations: 1
action 5, numVisits=2, meanQ=-9.829112, numObservations: 2
action -1, numVisits=39, meanQ=-16.098942, numObservations: 25
action 0, numVisits=16, meanQ=-35.324782, numObservations: 13
Sampled 77059 episodes
GETTING ACTION FROM:
action 4, numVisits=77969, meanQ=14.479792, numObservations: 9
action 3, numVisits=37, meanQ=-9.573779, numObservations: 9
action 1, numVisits=1, meanQ=-9.581186, numObservations: 1
action 5, numVisits=2, meanQ=-9.829112, numObservations: 2
action 2, numVisits=9, meanQ=-10.427419, numObservations: 3
action -1, numVisits=39, meanQ=-16.098942, numObservations: 25
action 0, numVisits=16, meanQ=-35.324782, numObservations: 13
action: 4
Next state: 0 0.675938 0.237385 0.193806 0.72756 0.610644 0.505408 0.18499 0.907884 0.283137 0.183184 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: -4
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 3, numVisits=91, meanQ=14.028809, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.041862, numObservations: 1
action 4, numVisits=1, meanQ=-10.142328, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-539.456578, numObservations: 1
Sampled 109042 episodes
GETTING ACTION FROM:
action 3, numVisits=109131, meanQ=16.914255, numObservations: 9
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 5, numVisits=1, meanQ=-10.041862, numObservations: 1
action 4, numVisits=1, meanQ=-10.142328, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-539.456578, numObservations: 1
action: 3
Next state: 0 0.675938 0.237385 0.193806 0.72756 0.610644 0.505408 0.18499 0.907884 0.283137 0.183184 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: -4
Updated belief

t = 5
Improving policy...
PLANNING FROM:
action 3, numVisits=199, meanQ=17.880970, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-274.075769, numObservations: 1
action 2, numVisits=1, meanQ=-274.184510, numObservations: 1
action 5, numVisits=1, meanQ=-274.370293, numObservations: 1
action 4, numVisits=1, meanQ=-275.218412, numObservations: 1
Sampled 69959 episodes
GETTING ACTION FROM:
action 3, numVisits=750, meanQ=21.670711, numObservations: 9
action -1, numVisits=68954, meanQ=-1.726404, numObservations: 195
action 0, numVisits=458, meanQ=-2.313143, numObservations: 65
action 1, numVisits=1, meanQ=-274.075769, numObservations: 1
action 2, numVisits=1, meanQ=-274.184510, numObservations: 1
action 5, numVisits=1, meanQ=-274.370293, numObservations: 1
action 4, numVisits=1, meanQ=-275.218412, numObservations: 1
action: 3
Next state: 1 0.675938 0.237385 0.193806 0.72756 0.610644 0.505408 0.18499 0.907884 0.283137 0.183184 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 3.21978
Run # 18
Initial state: 0 0.169848 0.0584836 0.812402 0.0493483 0.518604 0.47754 0.521581 0.953849 0.479048 0.956365 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80482 episodes
GETTING ACTION FROM:
action 1, numVisits=80463, meanQ=9.647337, numObservations: 9
action 3, numVisits=10, meanQ=5.100000, numObservations: 6
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action 4, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.169848 0.0584836 0.812402 0.0493483 0.518604 0.47754 0.521581 0.953849 0.479048 0.956365 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=13449, meanQ=11.081213, numObservations: 9
action 3, numVisits=4, meanQ=1.745000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 21194 episodes
GETTING ACTION FROM:
action 4, numVisits=34620, meanQ=10.616849, numObservations: 9
action 3, numVisits=4, meanQ=1.745000, numObservations: 4
action 0, numVisits=18, meanQ=0.145000, numObservations: 16
action -1, numVisits=6, meanQ=-1.010000, numObservations: 6
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=2, meanQ=-7.005000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.169848 0.0584836 0.812402 0.0493483 0.518604 0.47754 0.521581 0.953849 0.479048 0.956365 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 19
Initial state: 0 0.791705 0.732466 0.295992 0.355731 0.806119 0.54136 0.667752 0.467884 0.915959 0.883921 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80947 episodes
GETTING ACTION FROM:
action 3, numVisits=80934, meanQ=9.778721, numObservations: 9
action 2, numVisits=8, meanQ=3.875000, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.791705 0.732466 0.295992 0.355731 0.806119 0.54136 0.667752 0.467884 0.915959 0.883921 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 20
Initial state: 0 0.991375 0.104247 0.115896 0.721506 0.576266 0.553293 0.802878 0.405905 0.193414 0.400252 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80389 episodes
GETTING ACTION FROM:
action 2, numVisits=80381, meanQ=9.943455, numObservations: 9
action 1, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.991375 0.104247 0.115896 0.721506 0.576266 0.553293 0.802878 0.405905 0.193414 0.400252 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=9572, meanQ=11.472549, numObservations: 9
action -1, numVisits=6, meanQ=-1.010000, numObservations: 6
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 5, numVisits=4, meanQ=-2.250000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 29246 episodes
GETTING ACTION FROM:
action 1, numVisits=38818, meanQ=12.721781, numObservations: 9
action -1, numVisits=6, meanQ=-1.010000, numObservations: 6
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 5, numVisits=4, meanQ=-2.250000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.991375 0.104247 0.115896 0.721506 0.576266 0.553293 0.802878 0.405905 0.193414 0.400252 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 21
Initial state: 0 0.546686 0.510364 0.345419 0.9214 0.676913 0.796736 0.483713 0.830904 0.0887114 0.859497 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80193 episodes
GETTING ACTION FROM:
action 4, numVisits=80180, meanQ=9.603521, numObservations: 9
action 1, numVisits=6, meanQ=4.165017, numObservations: 4
action 3, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 1 0.546686 0.510364 0.345419 0.9214 0.676913 0.796736 0.483713 0.830904 0.0887114 0.859497 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 22
Initial state: 0 0.210703 0.0437303 0.720785 0.0818737 0.540851 0.491865 0.885901 0.720976 0.732945 0.185326 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80794 episodes
GETTING ACTION FROM:
action 1, numVisits=80776, meanQ=9.932367, numObservations: 9
action 4, numVisits=13, meanQ=2.085392, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.210703 0.0437303 0.720785 0.0818737 0.540851 0.491865 0.885901 0.720976 0.732945 0.185326 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=13375, meanQ=10.882215, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 25265 episodes
GETTING ACTION FROM:
action 5, numVisits=38628, meanQ=10.097959, numObservations: 9
action -1, numVisits=6, meanQ=-1.010000, numObservations: 6
action 0, numVisits=6, meanQ=-1.175000, numObservations: 5
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=2, meanQ=-5.519533, numObservations: 2
action 3, numVisits=2, meanQ=-6.420766, numObservations: 2
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.210703 0.0437303 0.720785 0.0818737 0.540851 0.491865 0.885901 0.720976 0.732945 0.185326 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 23
Initial state: 0 0.578338 0.580507 0.219056 0.647549 0.0540292 0.0703546 0.260852 0.00172755 0.495767 0.619709 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79993 episodes
GETTING ACTION FROM:
action 4, numVisits=79980, meanQ=9.819394, numObservations: 9
action 1, numVisits=6, meanQ=1.833333, numObservations: 4
action 5, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 0 0.578338 0.580507 0.219056 0.647549 0.0540292 0.0703546 0.260852 0.00172755 0.495767 0.619709 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=13152, meanQ=11.027943, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 21208 episodes
GETTING ACTION FROM:
action 3, numVisits=34360, meanQ=11.203287, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.578338 0.580507 0.219056 0.647549 0.0540292 0.0703546 0.260852 0.00172755 0.495767 0.619709 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=213, meanQ=8.288053, numObservations: 9
action 4, numVisits=265, meanQ=6.384004, numObservations: 9
action 3, numVisits=2, meanQ=-11.000000, numObservations: 2
action 5, numVisits=2, meanQ=-11.000000, numObservations: 2
action -1, numVisits=40, meanQ=-28.452420, numObservations: 31
action 1, numVisits=28, meanQ=-34.055341, numObservations: 9
action 0, numVisits=18, meanQ=-60.468706, numObservations: 16
Sampled 40603 episodes
GETTING ACTION FROM:
action 4, numVisits=265, meanQ=6.384004, numObservations: 9
action 2, numVisits=40816, meanQ=4.941184, numObservations: 9
action 3, numVisits=2, meanQ=-11.000000, numObservations: 2
action 5, numVisits=2, meanQ=-11.000000, numObservations: 2
action -1, numVisits=40, meanQ=-28.452420, numObservations: 31
action 1, numVisits=28, meanQ=-34.055341, numObservations: 9
action 0, numVisits=18, meanQ=-60.468706, numObservations: 16
action: 4
Next state: 0 0.578338 0.580507 0.219056 0.647549 0.0540292 0.0703546 0.260852 0.00172755 0.495767 0.619709 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=1, meanQ=24.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 50656 episodes
GETTING ACTION FROM:
action 1, numVisits=50638, meanQ=10.566442, numObservations: 9
action 2, numVisits=9, meanQ=0.666667, numObservations: 5
action 0, numVisits=7, meanQ=-1.575714, numObservations: 6
action -1, numVisits=6, meanQ=-1.670000, numObservations: 5
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.578338 0.580507 0.219056 0.647549 0.0540292 0.0703546 0.260852 0.00172755 0.495767 0.619709 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 11.4068
Run # 24
Initial state: 0 0.0307502 0.200331 0.0663663 0.751465 0.495062 0.692716 0.625833 0.437431 0.661419 0.863994 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80909 episodes
GETTING ACTION FROM:
action 5, numVisits=80894, meanQ=9.919302, numObservations: 9
action 3, numVisits=8, meanQ=2.998762, numObservations: 7
action 2, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 1 0.0307502 0.200331 0.0663663 0.751465 0.495062 0.692716 0.625833 0.437431 0.661419 0.863994 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 25
Initial state: 0 0.253069 0.656185 0.0334735 0.00870761 0.451579 0.413678 0.787284 0.075748 0.576425 0.510112 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79556 episodes
GETTING ACTION FROM:
action 3, numVisits=79541, meanQ=9.887631, numObservations: 9
action 5, numVisits=8, meanQ=3.875000, numObservations: 5
action 4, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.253069 0.656185 0.0334735 0.00870761 0.451579 0.413678 0.787284 0.075748 0.576425 0.510112 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=12647, meanQ=10.850246, numObservations: 9
action 2, numVisits=418, meanQ=9.327988, numObservations: 9
action 5, numVisits=3, meanQ=5.993333, numObservations: 3
action 1, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 22469 episodes
GETTING ACTION FROM:
action 1, numVisits=11384, meanQ=10.330039, numObservations: 9
action 4, numVisits=22454, meanQ=9.943242, numObservations: 9
action 2, numVisits=1687, meanQ=8.689436, numObservations: 9
action 5, numVisits=4, meanQ=1.745000, numObservations: 4
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.175000, numObservations: 6
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.253069 0.656185 0.0334735 0.00870761 0.451579 0.413678 0.787284 0.075748 0.576425 0.510112 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=942, meanQ=11.166675, numObservations: 9
action 1, numVisits=1, meanQ=-9.083431, numObservations: 1
action 0, numVisits=85, meanQ=-10.561315, numObservations: 49
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=29, meanQ=-34.129575, numObservations: 20
action 3, numVisits=1, meanQ=-1066.802259, numObservations: 1
Sampled 15091 episodes
GETTING ACTION FROM:
action 4, numVisits=16033, meanQ=13.172063, numObservations: 9
action 1, numVisits=1, meanQ=-9.083431, numObservations: 1
action 0, numVisits=85, meanQ=-10.561315, numObservations: 49
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=29, meanQ=-34.129575, numObservations: 20
action 3, numVisits=1, meanQ=-1066.802259, numObservations: 1
action: 4
Next state: 0 0.253069 0.656185 0.0334735 0.00870761 0.451579 0.413678 0.787284 0.075748 0.576425 0.510112 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 5, numVisits=12, meanQ=6.877235, numObservations: 7
action 2, numVisits=3, meanQ=0.904591, numObservations: 3
action 4, numVisits=3, meanQ=0.868061, numObservations: 3
action -1, numVisits=18, meanQ=0.749450, numObservations: 14
action 1, numVisits=1, meanQ=-9.993019, numObservations: 1
action 0, numVisits=9, meanQ=-57.872444, numObservations: 7
action 3, numVisits=1, meanQ=-1068.160779, numObservations: 1
Sampled 55152 episodes
GETTING ACTION FROM:
action 5, numVisits=55164, meanQ=16.185345, numObservations: 9
action 2, numVisits=3, meanQ=0.904591, numObservations: 3
action 4, numVisits=3, meanQ=0.868061, numObservations: 3
action -1, numVisits=18, meanQ=0.749450, numObservations: 14
action 1, numVisits=1, meanQ=-9.993019, numObservations: 1
action 0, numVisits=9, meanQ=-57.872444, numObservations: 7
action 3, numVisits=1, meanQ=-1068.160779, numObservations: 1
action: 5
Next state: 1 0.253069 0.656185 0.0334735 0.00870761 0.451579 0.413678 0.787284 0.075748 0.576425 0.510112 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 11.4068
Run # 26
Initial state: 0 0.872304 0.433145 0.655803 0.133508 0.84585 0.285896 0.789457 0.914463 0.551383 0.441812 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79666 episodes
GETTING ACTION FROM:
action 1, numVisits=79658, meanQ=9.846469, numObservations: 9
action 2, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.872304 0.433145 0.655803 0.133508 0.84585 0.285896 0.789457 0.914463 0.551383 0.441812 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 27
Initial state: 0 0.235814 0.161009 0.510065 0.438628 0.300873 0.62867 0.105883 0.131286 0.660163 0.746899 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 77834 episodes
GETTING ACTION FROM:
action 1, numVisits=77814, meanQ=9.577651, numObservations: 9
action -1, numVisits=8, meanQ=-1.010000, numObservations: 8
action 0, numVisits=8, meanQ=-1.010000, numObservations: 8
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.235814 0.161009 0.510065 0.438628 0.300873 0.62867 0.105883 0.131286 0.660163 0.746899 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=12822, meanQ=10.949466, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 23689 episodes
GETTING ACTION FROM:
action 2, numVisits=36505, meanQ=10.790248, numObservations: 9
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.235814 0.161009 0.510065 0.438628 0.300873 0.62867 0.105883 0.131286 0.660163 0.746899 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 28
Initial state: 0 0.118784 0.28413 0.669742 0.588661 0.118609 0.847129 0.282895 0.0520273 0.397187 0.726901 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79919 episodes
GETTING ACTION FROM:
action 1, numVisits=79907, meanQ=9.728928, numObservations: 9
action 5, numVisits=5, meanQ=4.400000, numObservations: 5
action 4, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.118784 0.28413 0.669742 0.588661 0.118609 0.847129 0.282895 0.0520273 0.397187 0.726901 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=1370, meanQ=10.546516, numObservations: 9
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action 3, numVisits=6, meanQ=2.668350, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 33306 episodes
GETTING ACTION FROM:
action 5, numVisits=34639, meanQ=9.666619, numObservations: 9
action 3, numVisits=6, meanQ=2.668350, numObservations: 4
action 2, numVisits=6, meanQ=2.326719, numObservations: 4
action 0, numVisits=25, meanQ=-1.203007, numObservations: 22
action -1, numVisits=11, meanQ=-1.820000, numObservations: 11
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.118784 0.28413 0.669742 0.588661 0.118609 0.847129 0.282895 0.0520273 0.397187 0.726901 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 29
Initial state: 0 0.0780289 0.671233 0.864184 0.178168 0.713549 0.98969 0.188158 0.891529 0.525484 0.473607 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80713 episodes
GETTING ACTION FROM:
action 3, numVisits=80698, meanQ=9.940869, numObservations: 9
action 1, numVisits=8, meanQ=4.005025, numObservations: 4
action 4, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.0780289 0.671233 0.864184 0.178168 0.713549 0.98969 0.188158 0.891529 0.525484 0.473607 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 30
Initial state: 0 0.199209 0.487886 0.670585 0.524449 0.466169 0.256561 0.693938 0.0148004 0.0250675 0.8164 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79340 episodes
GETTING ACTION FROM:
action 5, numVisits=79322, meanQ=9.896257, numObservations: 9
action 2, numVisits=7, meanQ=2.282857, numObservations: 5
action 4, numVisits=7, meanQ=1.998586, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.199209 0.487886 0.670585 0.524449 0.466169 0.256561 0.693938 0.0148004 0.0250675 0.8164 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=691, meanQ=12.202876, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 36381 episodes
GETTING ACTION FROM:
action 2, numVisits=37066, meanQ=13.643548, numObservations: 9
action -1, numVisits=4, meanQ=-1.505000, numObservations: 3
action 0, numVisits=4, meanQ=-1.505000, numObservations: 4
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.199209 0.487886 0.670585 0.524449 0.466169 0.256561 0.693938 0.0148004 0.0250675 0.8164 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 31
Initial state: 0 0.942322 0.739548 0.275878 0.121376 0.523513 0.565741 0.29514 0.49663 0.025718 0.820065 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79755 episodes
GETTING ACTION FROM:
action 4, numVisits=79747, meanQ=9.779581, numObservations: 9
action 5, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 0 0.942322 0.739548 0.275878 0.121376 0.523513 0.565741 0.29514 0.49663 0.025718 0.820065 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=3225, meanQ=11.727686, numObservations: 9
action 1, numVisits=7, meanQ=6.282857, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 26243 episodes
GETTING ACTION FROM:
action 5, numVisits=29410, meanQ=11.109907, numObservations: 9
action 1, numVisits=33, meanQ=8.399557, numObservations: 9
action 0, numVisits=27, meanQ=-1.962153, numObservations: 25
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=7, meanQ=-3.068489, numObservations: 6
action: 5
Next state: 0 0.942322 0.739548 0.275878 0.121376 0.523513 0.565741 0.29514 0.49663 0.025718 0.820065 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=2028, meanQ=10.267669, numObservations: 9
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=42, meanQ=-25.094517, numObservations: 36
action -1, numVisits=16, meanQ=-64.636996, numObservations: 13
Sampled 21283 episodes
GETTING ACTION FROM:
action 1, numVisits=23311, meanQ=12.045125, numObservations: 9
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=42, meanQ=-25.094517, numObservations: 36
action -1, numVisits=16, meanQ=-64.636996, numObservations: 13
action: 1
Next state: 1 0.942322 0.739548 0.275878 0.121376 0.523513 0.565741 0.29514 0.49663 0.025718 0.820065 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 32
Initial state: 0 0.577355 0.825728 0.791194 0.211304 0.402725 0.295974 0.510995 0.438334 0.77013 0.795942 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79824 episodes
GETTING ACTION FROM:
action 3, numVisits=79812, meanQ=9.625965, numObservations: 9
action 4, numVisits=5, meanQ=0.200000, numObservations: 3
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.577355 0.825728 0.791194 0.211304 0.402725 0.295974 0.510995 0.438334 0.77013 0.795942 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=13147, meanQ=10.870367, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 21444 episodes
GETTING ACTION FROM:
action 4, numVisits=34583, meanQ=10.410060, numObservations: 9
action 0, numVisits=5, meanQ=-1.208000, numObservations: 5
action -1, numVisits=5, meanQ=-1.406000, numObservations: 5
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.577355 0.825728 0.791194 0.211304 0.402725 0.295974 0.510995 0.438334 0.77013 0.795942 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 33
Initial state: 0 0.826109 0.885244 0.112816 0.366602 0.813363 0.646642 0.600642 0.575605 0.345021 0.220056 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80046 episodes
GETTING ACTION FROM:
action 5, numVisits=80008, meanQ=9.712399, numObservations: 9
action 4, numVisits=33, meanQ=3.792448, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.826109 0.885244 0.112816 0.366602 0.813363 0.646642 0.600642 0.575605 0.345021 0.220056 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=3254, meanQ=10.551830, numObservations: 9
action 3, numVisits=8, meanQ=6.092513, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 21019 episodes
GETTING ACTION FROM:
action 2, numVisits=24251, meanQ=10.522410, numObservations: 9
action 3, numVisits=9, meanQ=4.193344, numObservations: 5
action 0, numVisits=18, meanQ=-2.041305, numObservations: 16
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=5, meanQ=-212.595833, numObservations: 4
action: 2
Next state: 0 0.826109 0.885244 0.112816 0.366602 0.813363 0.646642 0.600642 0.575605 0.345021 0.220056 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=2879, meanQ=10.637953, numObservations: 9
action 0, numVisits=13, meanQ=-1.163069, numObservations: 12
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=7, meanQ=-150.404224, numObservations: 5
Sampled 18926 episodes
GETTING ACTION FROM:
action 4, numVisits=21804, meanQ=11.260154, numObservations: 9
action 0, numVisits=13, meanQ=-1.163069, numObservations: 12
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=7, meanQ=-150.404224, numObservations: 5
action: 4
Next state: 1 0.826109 0.885244 0.112816 0.366602 0.813363 0.646642 0.600642 0.575605 0.345021 0.220056 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 34
Initial state: 0 0.269385 0.634756 0.278929 0.679269 0.517189 0.452899 0.848875 0.068803 0.112943 0.773565 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 75093 episodes
GETTING ACTION FROM:
action 3, numVisits=75080, meanQ=9.774181, numObservations: 9
action 1, numVisits=6, meanQ=1.833333, numObservations: 5
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.269385 0.634756 0.278929 0.679269 0.517189 0.452899 0.848875 0.068803 0.112943 0.773565 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 35
Initial state: 0 0.453963 0.949625 0.61023 0.454581 0.134987 0.330295 0.0968193 0.0169975 0.831705 0.359491 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 76246 episodes
GETTING ACTION FROM:
action 4, numVisits=76240, meanQ=9.748647, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.453963 0.949625 0.61023 0.454581 0.134987 0.330295 0.0968193 0.0169975 0.831705 0.359491 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=12593, meanQ=10.923878, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 21019 episodes
GETTING ACTION FROM:
action 1, numVisits=33595, meanQ=10.591868, numObservations: 9
action 5, numVisits=4, meanQ=0.525928, numObservations: 3
action 3, numVisits=4, meanQ=-0.930717, numObservations: 3
action -1, numVisits=6, meanQ=-1.010000, numObservations: 6
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=2, meanQ=-5.475682, numObservations: 2
action: 1
Next state: 0 0.453963 0.949625 0.61023 0.454581 0.134987 0.330295 0.0968193 0.0169975 0.831705 0.359491 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=196, meanQ=14.333323, numObservations: 9
action 2, numVisits=11, meanQ=4.451827, numObservations: 5
action 5, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 49775 episodes
GETTING ACTION FROM:
action 3, numVisits=49967, meanQ=14.184023, numObservations: 9
action 2, numVisits=11, meanQ=4.451827, numObservations: 5
action 5, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=3, meanQ=-1.340000, numObservations: 3
action 0, numVisits=3, meanQ=-1.340000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.453963 0.949625 0.61023 0.454581 0.134987 0.330295 0.0968193 0.0169975 0.831705 0.359491 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -18.7411
Run # 36
Initial state: 0 0.508546 0.289753 0.4722 0.807627 0.354778 0.22402 0.705943 0.672162 0.618115 0.600364 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80047 episodes
GETTING ACTION FROM:
action 3, numVisits=80025, meanQ=9.782977, numObservations: 9
action -1, numVisits=9, meanQ=-1.010000, numObservations: 9
action 0, numVisits=9, meanQ=-1.010000, numObservations: 9
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.508546 0.289753 0.4722 0.807627 0.354778 0.22402 0.705943 0.672162 0.618115 0.600364 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=12997, meanQ=10.879943, numObservations: 9
action 5, numVisits=14, meanQ=5.292150, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 21589 episodes
GETTING ACTION FROM:
action 4, numVisits=33049, meanQ=10.923858, numObservations: 9
action 1, numVisits=1331, meanQ=9.966692, numObservations: 9
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=111, meanQ=-8.738829, numObservations: 73
action 5, numVisits=52, meanQ=-12.406314, numObservations: 9
action 0, numVisits=45, meanQ=-24.603123, numObservations: 34
action 2, numVisits=16, meanQ=-60.382337, numObservations: 6
action: 4
Next state: 1 0.508546 0.289753 0.4722 0.807627 0.354778 0.22402 0.705943 0.672162 0.618115 0.600364 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 37
Initial state: 0 0.438769 0.322243 0.841096 0.0863765 0.717513 0.309657 0.0467751 0.0677812 0.510121 0.440242 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80209 episodes
GETTING ACTION FROM:
action 5, numVisits=80201, meanQ=9.954257, numObservations: 9
action 2, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.438769 0.322243 0.841096 0.0863765 0.717513 0.309657 0.0467751 0.0677812 0.510121 0.440242 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 38
Initial state: 0 0.209514 0.146936 0.561504 0.483497 0.0964472 0.686183 0.261914 0.323108 0.291333 0.775324 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79776 episodes
GETTING ACTION FROM:
action 5, numVisits=79770, meanQ=9.746567, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 0 0.209514 0.146936 0.561504 0.483497 0.0964472 0.686183 0.261914 0.323108 0.291333 0.775324 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=9541, meanQ=11.172332, numObservations: 9
action 4, numVisits=9, meanQ=6.777789, numObservations: 6
action 1, numVisits=5, meanQ=4.598000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 26912 episodes
GETTING ACTION FROM:
action 2, numVisits=36446, meanQ=11.901583, numObservations: 9
action 4, numVisits=9, meanQ=6.777789, numObservations: 6
action 1, numVisits=6, meanQ=2.249120, numObservations: 5
action -1, numVisits=4, meanQ=-1.257500, numObservations: 4
action 0, numVisits=4, meanQ=-1.257500, numObservations: 4
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.209514 0.146936 0.561504 0.483497 0.0964472 0.686183 0.261914 0.323108 0.291333 0.775324 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 39
Initial state: 0 0.0389167 0.625333 0.370319 0.0847174 0.490568 0.264656 0.163974 0.0999168 0.540307 0.493341 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79963 episodes
GETTING ACTION FROM:
action 4, numVisits=79934, meanQ=9.694033, numObservations: 9
action 2, numVisits=22, meanQ=8.068186, numObservations: 9
action 1, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.0389167 0.625333 0.370319 0.0847174 0.490568 0.264656 0.163974 0.0999168 0.540307 0.493341 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=13144, meanQ=10.967087, numObservations: 9
action 1, numVisits=4, meanQ=3.742500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 20641 episodes
GETTING ACTION FROM:
action 5, numVisits=33763, meanQ=11.189655, numObservations: 9
action 1, numVisits=16, meanQ=6.026895, numObservations: 8
action 3, numVisits=4, meanQ=0.438169, numObservations: 4
action -1, numVisits=5, meanQ=-1.010000, numObservations: 5
action 0, numVisits=4, meanQ=-1.257500, numObservations: 4
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.0389167 0.625333 0.370319 0.0847174 0.490568 0.264656 0.163974 0.0999168 0.540307 0.493341 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 40
Initial state: 0 0.559953 0.462335 0.825126 0.338268 0.467147 0.316615 0.774454 0.550313 0.469712 0.343805 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80495 episodes
GETTING ACTION FROM:
action 2, numVisits=80485, meanQ=10.019772, numObservations: 9
action 3, numVisits=3, meanQ=3.330000, numObservations: 3
action 5, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 2 0.559953 0.462335 0.825126 0.338268 0.467147 0.316615 0.774454 0.550313 0.469712 0.343805 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 41
Initial state: 0 0.176967 0.0254114 0.199459 0.0248684 0.492285 0.95436 0.440109 0.617861 0.58548 0.571068 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80318 episodes
GETTING ACTION FROM:
action 4, numVisits=80300, meanQ=9.949515, numObservations: 9
action 5, numVisits=9, meanQ=6.888889, numObservations: 5
action 3, numVisits=5, meanQ=4.400000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.176967 0.0254114 0.199459 0.0248684 0.492285 0.95436 0.440109 0.617861 0.58548 0.571068 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=9634, meanQ=11.303424, numObservations: 9
action 3, numVisits=47, meanQ=4.873640, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 29351 episodes
GETTING ACTION FROM:
action 5, numVisits=38980, meanQ=12.300920, numObservations: 9
action 3, numVisits=47, meanQ=4.873640, numObservations: 9
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=3, meanQ=-1.340000, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.176967 0.0254114 0.199459 0.0248684 0.492285 0.95436 0.440109 0.617861 0.58548 0.571068 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 42
Initial state: 0 0.739971 0.216584 0.214345 0.00437484 0.617768 0.460187 0.786243 0.238027 0.696671 0.635748 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79811 episodes
GETTING ACTION FROM:
action 4, numVisits=79800, meanQ=9.815070, numObservations: 9
action 1, numVisits=3, meanQ=3.000000, numObservations: 3
action 2, numVisits=4, meanQ=3.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.739971 0.216584 0.214345 0.00437484 0.617768 0.460187 0.786243 0.238027 0.696671 0.635748 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 43
Initial state: 0 0.638721 0.512227 0.295908 0.888908 0.671721 0.58171 0.338184 0.682838 0.750985 0.132488 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80047 episodes
GETTING ACTION FROM:
action 3, numVisits=79867, meanQ=9.661786, numObservations: 9
action 2, numVisits=170, meanQ=6.449158, numObservations: 9
action 5, numVisits=6, meanQ=3.835017, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.638721 0.512227 0.295908 0.888908 0.671721 0.58171 0.338184 0.682838 0.750985 0.132488 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 44
Initial state: 0 0.0375906 0.918422 0.538369 0.444829 0.979514 0.302358 0.458714 0.399049 0.0982884 0.937359 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80588 episodes
GETTING ACTION FROM:
action 4, numVisits=80571, meanQ=9.818761, numObservations: 9
action 3, numVisits=12, meanQ=7.083333, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.0375906 0.918422 0.538369 0.444829 0.979514 0.302358 0.458714 0.399049 0.0982884 0.937359 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=13372, meanQ=11.261905, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 19898 episodes
GETTING ACTION FROM:
action 2, numVisits=33150, meanQ=10.950599, numObservations: 9
action 0, numVisits=20, meanQ=0.519242, numObservations: 17
action -1, numVisits=4, meanQ=-1.257500, numObservations: 4
action 5, numVisits=99, meanQ=-1.437840, numObservations: 9
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.0375906 0.918422 0.538369 0.444829 0.979514 0.302358 0.458714 0.399049 0.0982884 0.937359 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 45
Initial state: 0 0.598883 0.549363 0.209156 0.358362 0.461825 0.143652 0.834965 0.828132 0.2794 0.204387 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80059 episodes
GETTING ACTION FROM:
action 3, numVisits=80048, meanQ=9.607008, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=2, meanQ=-7.500000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.598883 0.549363 0.209156 0.358362 0.461825 0.143652 0.834965 0.828132 0.2794 0.204387 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 46
Initial state: 0 0.646776 0.496821 0.222143 0.898207 0.345552 0.504198 0.361597 0.12737 0.00463345 0.0436555 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79400 episodes
GETTING ACTION FROM:
action 1, numVisits=79389, meanQ=9.944050, numObservations: 9
action 4, numVisits=3, meanQ=3.000000, numObservations: 2
action 3, numVisits=4, meanQ=2.255025, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.646776 0.496821 0.222143 0.898207 0.345552 0.504198 0.361597 0.12737 0.00463345 0.0436555 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 47
Initial state: 0 0.906716 0.339087 0.393005 0.518802 0.514438 0.155734 0.232217 0.143689 0.589857 0.457488 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 76452 episodes
GETTING ACTION FROM:
action 4, numVisits=76446, meanQ=10.069454, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.906716 0.339087 0.393005 0.518802 0.514438 0.155734 0.232217 0.143689 0.589857 0.457488 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1523, meanQ=9.355282, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 63146 episodes
GETTING ACTION FROM:
action 1, numVisits=64632, meanQ=6.270602, numObservations: 9
action -1, numVisits=34, meanQ=-0.980882, numObservations: 30
action 0, numVisits=15, meanQ=-1.538000, numObservations: 14
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=2, meanQ=-7.005000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.906716 0.339087 0.393005 0.518802 0.514438 0.155734 0.232217 0.143689 0.589857 0.457488 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 48
Initial state: 0 0.110265 0.428179 0.567932 0.440266 0.899968 0.838185 0.840026 0.339832 0.085662 0.937709 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49671 episodes
GETTING ACTION FROM:
action -1, numVisits=49635, meanQ=13.812837, numObservations: 243
action 0, numVisits=21, meanQ=-1.104757, numObservations: 20
action 2, numVisits=9, meanQ=-1.668867, numObservations: 6
action 3, numVisits=2, meanQ=-7.500000, numObservations: 1
action 4, numVisits=2, meanQ=-7.500000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.110265 0.428179 0.567932 0.440266 0.899968 0.838185 0.840026 0.339832 0.085662 0.937709 w: 1
Observation: 0 1 0 2 0 3 0 3 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=294, meanQ=20.258478, numObservations: 9
action 3, numVisits=14, meanQ=14.000000, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 113937 episodes
GETTING ACTION FROM:
action 2, numVisits=114231, meanQ=21.377164, numObservations: 9
action 3, numVisits=14, meanQ=14.000000, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.110265 0.428179 0.567932 0.440266 0.899968 0.838185 0.840026 0.339832 0.085662 0.937709 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 49
Initial state: 0 0.612959 0.57341 0.568646 0.613766 0.425031 0.084814 0.567055 0.0510259 0.6626 0.406895 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 75374 episodes
GETTING ACTION FROM:
action 3, numVisits=75363, meanQ=9.586815, numObservations: 9
action 1, numVisits=4, meanQ=-0.252500, numObservations: 3
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.612959 0.57341 0.568646 0.613766 0.425031 0.084814 0.567055 0.0510259 0.6626 0.406895 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=8903, meanQ=12.120432, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 30684 episodes
GETTING ACTION FROM:
action 1, numVisits=30566, meanQ=12.344653, numObservations: 9
action 3, numVisits=8906, meanQ=12.122662, numObservations: 9
action 4, numVisits=2, meanQ=-7.005000, numObservations: 1
action 5, numVisits=42, meanQ=-12.718547, numObservations: 9
action -1, numVisits=43, meanQ=-24.566954, numObservations: 34
action 0, numVisits=19, meanQ=-57.052033, numObservations: 16
action 2, numVisits=15, meanQ=-61.580480, numObservations: 6
action: 1
Next state: 1 0.612959 0.57341 0.568646 0.613766 0.425031 0.084814 0.567055 0.0510259 0.6626 0.406895 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 50
Initial state: 0 0.47131 0.610769 0.117564 0.16168 0.0360898 0.751578 0.190888 0.656906 0.669285 0.497048 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80641 episodes
GETTING ACTION FROM:
action 1, numVisits=80633, meanQ=9.801870, numObservations: 9
action 4, numVisits=3, meanQ=5.663333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.47131 0.610769 0.117564 0.16168 0.0360898 0.751578 0.190888 0.656906 0.669285 0.497048 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
[32m ProblemEnvironment.hpp 351: Done.[39m
