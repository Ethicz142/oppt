Run # 1
Initial state: 0 0.172899 0.286131 0.667882 0.301676 0.936514 0.135601 0.861216 0.87439 0.452404 0.658072 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87919 episodes
GETTING ACTION FROM:
action 1, numVisits=87910, meanQ=8.281634, numObservations: 9
action 2, numVisits=4, meanQ=1.745000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.172899 0.286131 0.667882 0.301676 0.936514 0.135601 0.861216 0.87439 0.452404 0.658072 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=1731, meanQ=8.928657, numObservations: 9
action 4, numVisits=6, meanQ=5.661683, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 34449 episodes
GETTING ACTION FROM:
action 5, numVisits=35988, meanQ=6.155337, numObservations: 9
action 4, numVisits=9, meanQ=0.885567, numObservations: 7
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=114, meanQ=-10.841583, numObservations: 90
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=77, meanQ=-15.554622, numObservations: 50
action: 5
Next state: 1 0.172899 0.286131 0.667882 0.301676 0.936514 0.135601 0.861216 0.87439 0.452404 0.658072 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 2
Initial state: 0 0.405447 0.531675 0.338635 0.739742 0.654988 0.414013 0.0591484 0.795763 0.317001 0.191064 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 90779 episodes
GETTING ACTION FROM:
action 1, numVisits=90773, meanQ=8.271736, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.405447 0.531675 0.338635 0.739742 0.654988 0.414013 0.0591484 0.795763 0.317001 0.191064 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 3
Initial state: 0 0.21117 0.200516 0.507624 0.859729 0.40704 0.622985 0.0607971 0.0739097 0.38632 0.311761 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 90051 episodes
GETTING ACTION FROM:
action 1, numVisits=90045, meanQ=8.172445, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.21117 0.200516 0.507624 0.859729 0.40704 0.622985 0.0607971 0.0739097 0.38632 0.311761 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 4
Initial state: 0 0.427054 0.645376 0.272211 0.17641 0.376998 0.0319537 0.225623 0.187743 0.12144 0.00516261 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87969 episodes
GETTING ACTION FROM:
action 5, numVisits=87956, meanQ=8.238782, numObservations: 9
action 4, numVisits=8, meanQ=4.500025, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.427054 0.645376 0.272211 0.17641 0.376998 0.0319537 0.225623 0.187743 0.12144 0.00516261 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 5
Initial state: 0 0.192028 0.167875 0.728294 0.897675 0.343069 0.295281 0.0368553 0.128762 0.459344 0.661175 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 85713 episodes
GETTING ACTION FROM:
action 3, numVisits=85691, meanQ=8.142365, numObservations: 9
action 1, numVisits=15, meanQ=4.400000, numObservations: 8
action 4, numVisits=3, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.192028 0.167875 0.728294 0.897675 0.343069 0.295281 0.0368553 0.128762 0.459344 0.661175 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=2471, meanQ=8.697648, numObservations: 9
action 5, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 85157 episodes
GETTING ACTION FROM:
action 2, numVisits=86679, meanQ=6.245422, numObservations: 9
action 5, numVisits=915, meanQ=6.145155, numObservations: 9
action 1, numVisits=7, meanQ=0.141429, numObservations: 5
action -1, numVisits=18, meanQ=-1.725000, numObservations: 17
action 0, numVisits=15, meanQ=-1.868000, numObservations: 13
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.192028 0.167875 0.728294 0.897675 0.343069 0.295281 0.0368553 0.128762 0.459344 0.661175 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 6
Initial state: 0 0.922623 0.0580238 0.463554 0.572513 0.92502 0.299406 0.232607 0.52723 0.12123 0.442774 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 90423 episodes
GETTING ACTION FROM:
action 4, numVisits=90417, meanQ=8.132855, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.922623 0.0580238 0.463554 0.572513 0.92502 0.299406 0.232607 0.52723 0.12123 0.442774 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 7
Initial state: 0 0.993085 0.97719 0.885239 0.452926 0.421932 0.520005 0.306664 0.897038 0.061096 0.357854 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 90607 episodes
GETTING ACTION FROM:
action 4, numVisits=90587, meanQ=8.225853, numObservations: 9
action 2, numVisits=8, meanQ=5.376263, numObservations: 5
action 1, numVisits=6, meanQ=4.166667, numObservations: 5
action 3, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 0 0.993085 0.97719 0.885239 0.452926 0.421932 0.520005 0.306664 0.897038 0.061096 0.357854 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=6339, meanQ=9.828456, numObservations: 9
action 3, numVisits=5, meanQ=4.598000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 33258 episodes
GETTING ACTION FROM:
action 5, numVisits=39582, meanQ=13.049447, numObservations: 9
action 3, numVisits=10, meanQ=4.264705, numObservations: 7
action 0, numVisits=5, meanQ=-1.208000, numObservations: 5
action -1, numVisits=5, meanQ=-1.406000, numObservations: 5
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=2, meanQ=-5.522834, numObservations: 2
action 1, numVisits=2, meanQ=-6.217087, numObservations: 2
action: 5
Next state: 0 0.993085 0.97719 0.885239 0.452926 0.421932 0.520005 0.306664 0.897038 0.061096 0.357854 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=2212, meanQ=12.074106, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 46098 episodes
GETTING ACTION FROM:
action 2, numVisits=48310, meanQ=15.217294, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.993085 0.97719 0.885239 0.452926 0.421932 0.520005 0.306664 0.897038 0.061096 0.357854 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -18.7411
Run # 8
Initial state: 0 0.447448 0.660927 0.339811 0.308387 0.765809 0.879247 0.725634 0.447854 0.214145 0.451336 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 90069 episodes
GETTING ACTION FROM:
action 2, numVisits=90057, meanQ=7.888627, numObservations: 9
action 3, numVisits=7, meanQ=5.000000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.447448 0.660927 0.339811 0.308387 0.765809 0.879247 0.725634 0.447854 0.214145 0.451336 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=11481, meanQ=9.101062, numObservations: 9
action 4, numVisits=8, meanQ=3.123750, numObservations: 6
action 1, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 26393 episodes
GETTING ACTION FROM:
action 5, numVisits=37843, meanQ=8.706643, numObservations: 9
action 3, numVisits=15, meanQ=3.835192, numObservations: 7
action 4, numVisits=8, meanQ=3.123750, numObservations: 6
action 1, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=8, meanQ=-1.506237, numObservations: 7
action 0, numVisits=10, meanQ=-2.260417, numObservations: 9
action 2, numVisits=2, meanQ=-4.004950, numObservations: 1
action: 5
Next state: 0 0.447448 0.660927 0.339811 0.308387 0.765809 0.879247 0.725634 0.447854 0.214145 0.451336 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=3870, meanQ=11.874779, numObservations: 9
action 4, numVisits=4, meanQ=1.745000, numObservations: 3
action 1, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 19027 episodes
GETTING ACTION FROM:
action 3, numVisits=22897, meanQ=12.076852, numObservations: 9
action 4, numVisits=4, meanQ=1.745000, numObservations: 3
action 1, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.447448 0.660927 0.339811 0.308387 0.765809 0.879247 0.725634 0.447854 0.214145 0.451336 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 9
Initial state: 0 0.382364 0.644529 0.864408 0.71885 0.780923 0.837684 0.836001 0.149525 0.437452 0.236357 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 86734 episodes
GETTING ACTION FROM:
action 5, numVisits=86708, meanQ=8.399235, numObservations: 9
action -1, numVisits=11, meanQ=-1.010000, numObservations: 11
action 0, numVisits=11, meanQ=-1.010000, numObservations: 11
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.382364 0.644529 0.864408 0.71885 0.780923 0.837684 0.836001 0.149525 0.437452 0.236357 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 10
Initial state: 0 0.893501 0.258892 0.0187538 0.195182 0.386454 0.57108 0.906408 0.110087 0.248029 0.759902 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87458 episodes
GETTING ACTION FROM:
action 2, numVisits=87434, meanQ=8.225556, numObservations: 9
action 4, numVisits=14, meanQ=5.000000, numObservations: 8
action 5, numVisits=6, meanQ=3.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.893501 0.258892 0.0187538 0.195182 0.386454 0.57108 0.906408 0.110087 0.248029 0.759902 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=11266, meanQ=9.065853, numObservations: 9
action 3, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 31447 episodes
GETTING ACTION FROM:
action 4, numVisits=42694, meanQ=9.144704, numObservations: 9
action 1, numVisits=6, meanQ=2.998350, numObservations: 5
action 3, numVisits=3, meanQ=0.666667, numObservations: 2
action 0, numVisits=8, meanQ=-1.010000, numObservations: 8
action -1, numVisits=7, meanQ=-1.151429, numObservations: 7
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 4
Next state: 2 0.893501 0.258892 0.0187538 0.195182 0.386454 0.57108 0.906408 0.110087 0.248029 0.759902 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 11
Initial state: 0 0.574042 0.285951 0.653369 0.18024 0.405345 0.602181 0.684032 0.256696 0.257908 0.580233 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 86780 episodes
GETTING ACTION FROM:
action 4, numVisits=86745, meanQ=8.207096, numObservations: 9
action 1, numVisits=30, meanQ=5.366003, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.574042 0.285951 0.653369 0.18024 0.405345 0.602181 0.684032 0.256696 0.257908 0.580233 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 12
Initial state: 0 0.171949 0.976641 0.155607 0.400519 0.381847 0.580735 0.0497672 0.435188 0.900328 0.450991 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89525 episodes
GETTING ACTION FROM:
action 1, numVisits=89513, meanQ=8.206757, numObservations: 9
action 2, numVisits=5, meanQ=4.400000, numObservations: 5
action 4, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.171949 0.976641 0.155607 0.400519 0.381847 0.580735 0.0497672 0.435188 0.900328 0.450991 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=6254, meanQ=9.768709, numObservations: 9
action 3, numVisits=5, meanQ=0.794000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 33824 episodes
GETTING ACTION FROM:
action 5, numVisits=40072, meanQ=10.376459, numObservations: 9
action 3, numVisits=5, meanQ=0.794000, numObservations: 5
action 0, numVisits=4, meanQ=-1.257500, numObservations: 4
action -1, numVisits=4, meanQ=-1.505000, numObservations: 4
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.171949 0.976641 0.155607 0.400519 0.381847 0.580735 0.0497672 0.435188 0.900328 0.450991 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 13
Initial state: 0 0.437168 0.516062 0.198042 0.393471 0.96505 0.543277 0.346173 0.300985 0.473802 0.398842 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89737 episodes
GETTING ACTION FROM:
action 3, numVisits=89716, meanQ=8.072011, numObservations: 9
action 2, numVisits=8, meanQ=2.125000, numObservations: 6
action 5, numVisits=4, meanQ=1.250000, numObservations: 4
action 4, numVisits=4, meanQ=-0.500000, numObservations: 4
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.437168 0.516062 0.198042 0.393471 0.96505 0.543277 0.346173 0.300985 0.473802 0.398842 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 14
Initial state: 0 0.214 0.341782 0.44947 0.61498 0.732491 0.4421 0.261286 0.678386 0.754443 0.136783 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89672 episodes
GETTING ACTION FROM:
action 5, numVisits=89663, meanQ=8.080024, numObservations: 9
action 4, numVisits=4, meanQ=-0.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.214 0.341782 0.44947 0.61498 0.732491 0.4421 0.261286 0.678386 0.754443 0.136783 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 15
Initial state: 0 0.469934 0.587972 0.760868 0.965942 0.303749 0.209781 0.266171 0.0268514 0.716668 0.410298 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89626 episodes
GETTING ACTION FROM:
action 3, numVisits=89614, meanQ=8.127796, numObservations: 9
action 4, numVisits=7, meanQ=5.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.469934 0.587972 0.760868 0.965942 0.303749 0.209781 0.266171 0.0268514 0.716668 0.410298 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=2321, meanQ=9.294749, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 27776 episodes
GETTING ACTION FROM:
action 1, numVisits=30014, meanQ=8.747798, numObservations: 9
action 4, numVisits=37, meanQ=5.515904, numObservations: 9
action 0, numVisits=30, meanQ=-1.406000, numObservations: 27
action -1, numVisits=19, meanQ=-2.204808, numObservations: 16
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.469934 0.587972 0.760868 0.965942 0.303749 0.209781 0.266171 0.0268514 0.716668 0.410298 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=289, meanQ=6.274276, numObservations: 9
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=36, meanQ=-11.577131, numObservations: 7
action -1, numVisits=23, meanQ=-44.937625, numObservations: 17
action 5, numVisits=20, meanQ=-50.590717, numObservations: 7
action 2, numVisits=12, meanQ=-86.352774, numObservations: 8
action 0, numVisits=12, meanQ=-88.662333, numObservations: 10
Sampled 74455 episodes
GETTING ACTION FROM:
action 4, numVisits=74744, meanQ=10.500627, numObservations: 9
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=36, meanQ=-11.577131, numObservations: 7
action -1, numVisits=23, meanQ=-44.937625, numObservations: 17
action 5, numVisits=20, meanQ=-50.590717, numObservations: 7
action 2, numVisits=12, meanQ=-86.352774, numObservations: 8
action 0, numVisits=12, meanQ=-88.662333, numObservations: 10
action: 4
Next state: 0 0.469934 0.587972 0.760868 0.965942 0.303749 0.209781 0.266171 0.0268514 0.716668 0.410298 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=14, meanQ=24.000000, numObservations: 5
action 2, numVisits=145, meanQ=7.296760, numObservations: 9
action 0, numVisits=150, meanQ=-4.669201, numObservations: 57
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-12.340297, numObservations: 1
action -1, numVisits=13, meanQ=-42.052261, numObservations: 12
action 3, numVisits=1, meanQ=-1059.406452, numObservations: 1
Sampled 46331 episodes
GETTING ACTION FROM:
action 1, numVisits=113, meanQ=20.620442, numObservations: 9
action 2, numVisits=46377, meanQ=8.734055, numObservations: 9
action 0, numVisits=150, meanQ=-4.669201, numObservations: 57
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-12.340297, numObservations: 1
action -1, numVisits=13, meanQ=-42.052261, numObservations: 12
action 3, numVisits=1, meanQ=-1059.406452, numObservations: 1
action: 1
Next state: 1 0.469934 0.587972 0.760868 0.965942 0.303749 0.209781 0.266171 0.0268514 0.716668 0.410298 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 11.4068
Run # 16
Initial state: 0 0.150033 0.702582 0.378815 0.561791 0.0149305 0.937989 0.845736 0.0946623 0.68521 0.758735 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87718 episodes
GETTING ACTION FROM:
action 2, numVisits=87705, meanQ=8.247267, numObservations: 9
action 5, numVisits=6, meanQ=3.000000, numObservations: 5
action 4, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.150033 0.702582 0.378815 0.561791 0.0149305 0.937989 0.845736 0.0946623 0.68521 0.758735 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1431, meanQ=20.035595, numObservations: 9
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 92737 episodes
GETTING ACTION FROM:
action 2, numVisits=1525, meanQ=20.162424, numObservations: 9
action 3, numVisits=92597, meanQ=9.213067, numObservations: 9
action 4, numVisits=28, meanQ=5.042312, numObservations: 8
action -1, numVisits=11, meanQ=-1.820000, numObservations: 10
action 0, numVisits=11, meanQ=-1.820000, numObservations: 10
action 1, numVisits=2, meanQ=-7.005000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.150033 0.702582 0.378815 0.561791 0.0149305 0.937989 0.845736 0.0946623 0.68521 0.758735 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 17
Initial state: 0 0.972984 0.141639 0.468195 0.576782 0.149404 0.963057 0.57693 0.861456 0.57229 0.659344 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87424 episodes
GETTING ACTION FROM:
action 3, numVisits=87187, meanQ=8.057816, numObservations: 9
action 5, numVisits=225, meanQ=7.422949, numObservations: 9
action 1, numVisits=3, meanQ=3.000000, numObservations: 3
action 2, numVisits=6, meanQ=3.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.972984 0.141639 0.468195 0.576782 0.149404 0.963057 0.57693 0.861456 0.57229 0.659344 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=6083, meanQ=9.388366, numObservations: 9
action 2, numVisits=11, meanQ=3.906364, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 25906 episodes
GETTING ACTION FROM:
action 4, numVisits=31982, meanQ=10.837986, numObservations: 9
action 2, numVisits=11, meanQ=3.906364, numObservations: 7
action -1, numVisits=5, meanQ=-1.208000, numObservations: 5
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=4, meanQ=-3.519801, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.972984 0.141639 0.468195 0.576782 0.149404 0.963057 0.57693 0.861456 0.57229 0.659344 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 18
Initial state: 0 0.323675 0.387689 0.785143 0.846713 0.439949 0.574509 0.789714 0.0893739 0.306832 0.209336 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 84013 episodes
GETTING ACTION FROM:
action 1, numVisits=83991, meanQ=7.448178, numObservations: 9
action 5, numVisits=17, meanQ=1.887665, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.323675 0.387689 0.785143 0.846713 0.439949 0.574509 0.789714 0.0893739 0.306832 0.209336 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=10716, meanQ=3.269236, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 33385 episodes
GETTING ACTION FROM:
action 4, numVisits=33274, meanQ=7.585565, numObservations: 9
action 1, numVisits=10717, meanQ=3.269402, numObservations: 9
action 3, numVisits=3, meanQ=-8.336667, numObservations: 3
action 2, numVisits=2, meanQ=-11.000000, numObservations: 1
action 5, numVisits=2, meanQ=-11.000000, numObservations: 2
action 0, numVisits=88, meanQ=-13.334148, numObservations: 60
action -1, numVisits=32, meanQ=-35.428637, numObservations: 27
action: 4
Next state: 2 0.323675 0.387689 0.785143 0.846713 0.439949 0.574509 0.789714 0.0893739 0.306832 0.209336 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 19
Initial state: 0 0.438251 0.646208 0.357995 0.390956 0.157914 0.743595 0.932438 0.798833 0.447275 0.27419 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89261 episodes
GETTING ACTION FROM:
action 5, numVisits=89253, meanQ=8.072114, numObservations: 9
action 3, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.438251 0.646208 0.357995 0.390956 0.157914 0.743595 0.932438 0.798833 0.447275 0.27419 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=1447, meanQ=19.307131, numObservations: 9
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action 4, numVisits=2, meanQ=10.495000, numObservations: 2
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 79626 episodes
GETTING ACTION FROM:
action 5, numVisits=1503, meanQ=19.445906, numObservations: 9
action 1, numVisits=79533, meanQ=10.532264, numObservations: 9
action 2, numVisits=21, meanQ=5.666667, numObservations: 7
action 4, numVisits=6, meanQ=1.912385, numObservations: 3
action 3, numVisits=4, meanQ=-0.252500, numObservations: 2
action 0, numVisits=8, meanQ=-1.628750, numObservations: 7
action -1, numVisits=7, meanQ=-1.717143, numObservations: 7
action: 5
Next state: 2 0.438251 0.646208 0.357995 0.390956 0.157914 0.743595 0.932438 0.798833 0.447275 0.27419 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 20
Initial state: 0 0.897859 0.780483 0.65604 0.0090481 7.07905e-05 0.361487 0.613424 0.925326 0.442581 0.508826 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 86342 episodes
GETTING ACTION FROM:
action 1, numVisits=86325, meanQ=8.489588, numObservations: 9
action 3, numVisits=9, meanQ=3.000000, numObservations: 6
action 5, numVisits=4, meanQ=3.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.897859 0.780483 0.65604 0.0090481 7.07905e-05 0.361487 0.613424 0.925326 0.442581 0.508826 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 21
Initial state: 0 0.310529 0.10086 0.424297 0.630485 0.857087 0.424109 0.548543 0.70404 0.693888 0.890577 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89855 episodes
GETTING ACTION FROM:
action 2, numVisits=89818, meanQ=8.219517, numObservations: 9
action 3, numVisits=32, meanQ=5.788128, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.310529 0.10086 0.424297 0.630485 0.857087 0.424109 0.548543 0.70404 0.693888 0.890577 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 22
Initial state: 0 0.499125 0.19789 0.378699 0.616029 0.952928 0.0069377 0.600795 0.226618 0.0508524 0.653108 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89873 episodes
GETTING ACTION FROM:
action 1, numVisits=89859, meanQ=8.396995, numObservations: 9
action 5, numVisits=9, meanQ=4.555556, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.499125 0.19789 0.378699 0.616029 0.952928 0.0069377 0.600795 0.226618 0.0508524 0.653108 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 23
Initial state: 0 0.942257 0.84798 0.580673 0.487821 0.797982 0.13609 0.528286 0.755233 0.437139 0.587313 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 90227 episodes
GETTING ACTION FROM:
action 4, numVisits=90221, meanQ=8.172087, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.942257 0.84798 0.580673 0.487821 0.797982 0.13609 0.528286 0.755233 0.437139 0.587313 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 24
Initial state: 0 0.433917 0.645164 0.828725 0.0710323 0.640618 0.619346 0.258535 0.764712 0.728161 0.821153 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89877 episodes
GETTING ACTION FROM:
action 2, numVisits=89871, meanQ=8.307325, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.433917 0.645164 0.828725 0.0710323 0.640618 0.619346 0.258535 0.764712 0.728161 0.821153 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 25
Initial state: 0 0.370078 0.651097 0.1464 0.365545 0.952673 0.891528 0.748728 0.707345 0.173166 0.421033 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 90304 episodes
GETTING ACTION FROM:
action 4, numVisits=90296, meanQ=7.976332, numObservations: 9
action 3, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.370078 0.651097 0.1464 0.365545 0.952673 0.891528 0.748728 0.707345 0.173166 0.421033 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 26
Initial state: 0 0.896285 0.255826 0.483738 0.29777 0.488677 0.256726 0.406948 0.553611 0.0111659 0.538894 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87981 episodes
GETTING ACTION FROM:
action 4, numVisits=87915, meanQ=8.228733, numObservations: 9
action 3, numVisits=46, meanQ=6.761535, numObservations: 9
action 2, numVisits=9, meanQ=5.333333, numObservations: 6
action 1, numVisits=5, meanQ=4.400000, numObservations: 4
action 5, numVisits=4, meanQ=1.497500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 4
Next state: 1 0.896285 0.255826 0.483738 0.29777 0.488677 0.256726 0.406948 0.553611 0.0111659 0.538894 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 27
Initial state: 0 0.702821 0.398619 0.464499 0.57301 0.843733 0.486784 0.583947 0.700345 0.0528602 0.293492 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 90933 episodes
GETTING ACTION FROM:
action 3, numVisits=90916, meanQ=8.253347, numObservations: 9
action 5, numVisits=7, meanQ=0.000000, numObservations: 4
action 4, numVisits=4, meanQ=-0.500000, numObservations: 3
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.702821 0.398619 0.464499 0.57301 0.843733 0.486784 0.583947 0.700345 0.0528602 0.293492 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 28
Initial state: 0 0.435016 0.521607 0.744616 0.862158 0.122666 0.159647 0.84258 0.664286 0.834591 0.0920337 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89059 episodes
GETTING ACTION FROM:
action 2, numVisits=89044, meanQ=7.992432, numObservations: 9
action 4, numVisits=10, meanQ=3.799000, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.435016 0.521607 0.744616 0.862158 0.122666 0.159647 0.84258 0.664286 0.834591 0.0920337 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 29
Initial state: 0 0.419515 0.633615 0.971412 0.0155884 0.645095 0.945661 0.670677 0.177724 0.38 0.053258 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 83064 episodes
GETTING ACTION FROM:
action 4, numVisits=83058, meanQ=8.611998, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.419515 0.633615 0.971412 0.0155884 0.645095 0.945661 0.670677 0.177724 0.38 0.053258 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 30
Initial state: 0 0.822261 0.152179 0.335752 0.00934554 0.658062 0.990746 0.626919 0.70904 0.423282 0.542609 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 83261 episodes
GETTING ACTION FROM:
action 5, numVisits=83252, meanQ=8.663365, numObservations: 9
action 2, numVisits=4, meanQ=-0.500000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.822261 0.152179 0.335752 0.00934554 0.658062 0.990746 0.626919 0.70904 0.423282 0.542609 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 31
Initial state: 0 0.437176 0.516402 0.0445544 0.00106924 0.270912 0.179988 0.0572411 0.790935 0.0520743 0.694562 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 90345 episodes
GETTING ACTION FROM:
action 4, numVisits=90332, meanQ=8.176712, numObservations: 9
action 3, numVisits=8, meanQ=5.747513, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.437176 0.516402 0.0445544 0.00106924 0.270912 0.179988 0.0572411 0.790935 0.0520743 0.694562 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 32
Initial state: 0 0.503888 0.783989 0.294206 0.430838 0.544205 0.311872 0.604765 0.907727 0.420786 0.635596 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 90080 episodes
GETTING ACTION FROM:
action 5, numVisits=90067, meanQ=8.177987, numObservations: 9
action 3, numVisits=8, meanQ=2.513750, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.503888 0.783989 0.294206 0.430838 0.544205 0.311872 0.604765 0.907727 0.420786 0.635596 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 33
Initial state: 0 0.420643 0.618967 0.194546 0.862034 0.0283467 0.560752 0.828568 0.583099 0.322609 0.620798 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87459 episodes
GETTING ACTION FROM:
action 2, numVisits=87453, meanQ=8.234333, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.420643 0.618967 0.194546 0.862034 0.0283467 0.560752 0.828568 0.583099 0.322609 0.620798 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=2276, meanQ=9.398659, numObservations: 9
action 5, numVisits=9, meanQ=6.777789, numObservations: 5
action 4, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 30698 episodes
GETTING ACTION FROM:
action 3, numVisits=32898, meanQ=8.109646, numObservations: 9
action 5, numVisits=34, meanQ=5.015796, numObservations: 9
action 4, numVisits=3, meanQ=0.666667, numObservations: 3
action 0, numVisits=49, meanQ=-1.373876, numObservations: 44
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=3, meanQ=-4.970000, numObservations: 2
action 1, numVisits=2, meanQ=-8.102205, numObservations: 2
action: 3
Next state: 2 0.420643 0.618967 0.194546 0.862034 0.0283467 0.560752 0.828568 0.583099 0.322609 0.620798 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 34
Initial state: 0 0.386247 0.395605 0.42726 0.529342 0.149523 0.928593 0.939201 0.0182118 0.625138 0.983943 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79725 episodes
GETTING ACTION FROM:
action 2, numVisits=79696, meanQ=8.629269, numObservations: 9
action 1, numVisits=20, meanQ=5.299520, numObservations: 7
action 3, numVisits=5, meanQ=4.598000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.386247 0.395605 0.42726 0.529342 0.149523 0.928593 0.939201 0.0182118 0.625138 0.983943 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 35
Initial state: 0 0.854009 0.688609 0.612188 0.124502 0.413065 0.507557 0.0198779 0.47945 0.154792 0.0876941 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89693 episodes
GETTING ACTION FROM:
action 3, numVisits=89682, meanQ=8.232296, numObservations: 9
action 1, numVisits=3, meanQ=3.000000, numObservations: 3
action 5, numVisits=4, meanQ=2.500050, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.854009 0.688609 0.612188 0.124502 0.413065 0.507557 0.0198779 0.47945 0.154792 0.0876941 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 36
Initial state: 0 0.562849 0.252234 0.550142 0.184534 0.526984 0.639453 0.248734 0.29536 0.422595 0.644522 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 85198 episodes
GETTING ACTION FROM:
action 4, numVisits=85169, meanQ=7.459023, numObservations: 9
action 2, numVisits=16, meanQ=-0.562494, numObservations: 6
action -1, numVisits=5, meanQ=-1.010000, numObservations: 5
action 0, numVisits=5, meanQ=-1.010000, numObservations: 5
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.562849 0.252234 0.550142 0.184534 0.526984 0.639453 0.248734 0.29536 0.422595 0.644522 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=10683, meanQ=4.000903, numObservations: 9
action -1, numVisits=6, meanQ=-1.010000, numObservations: 6
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 2, numVisits=6, meanQ=-2.503333, numObservations: 4
action 3, numVisits=2, meanQ=-3.010000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 27993 episodes
GETTING ACTION FROM:
action 3, numVisits=27861, meanQ=8.055668, numObservations: 9
action 4, numVisits=10683, meanQ=4.000903, numObservations: 9
action 2, numVisits=74, meanQ=-6.269885, numObservations: 9
action 1, numVisits=2, meanQ=-11.000000, numObservations: 2
action 5, numVisits=2, meanQ=-11.000000, numObservations: 2
action -1, numVisits=57, meanQ=-20.769107, numObservations: 46
action 0, numVisits=19, meanQ=-56.677250, numObservations: 16
action: 3
Next state: 1 0.562849 0.252234 0.550142 0.184534 0.526984 0.639453 0.248734 0.29536 0.422595 0.644522 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 37
Initial state: 0 0.424883 0.509467 0.26663 0.664732 0.819791 0.362708 0.54063 0.755873 0.529038 0.154211 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89929 episodes
GETTING ACTION FROM:
action 5, numVisits=89915, meanQ=8.197535, numObservations: 9
action 2, numVisits=9, meanQ=2.332222, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.424883 0.509467 0.26663 0.664732 0.819791 0.362708 0.54063 0.755873 0.529038 0.154211 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 38
Initial state: 0 0.377859 0.850226 0.379388 0.568071 0.745045 0.535234 0.301238 0.768521 0.354946 0.157637 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 81367 episodes
GETTING ACTION FROM:
action 2, numVisits=81359, meanQ=8.332593, numObservations: 9
action 5, numVisits=3, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.377859 0.850226 0.379388 0.568071 0.745045 0.535234 0.301238 0.768521 0.354946 0.157637 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 39
Initial state: 0 0.770795 0.91485 0.963253 0.832501 0.335271 0.148639 0.947272 0.71471 0.438488 0.586067 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 90223 episodes
GETTING ACTION FROM:
action 3, numVisits=90217, meanQ=8.154120, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.770795 0.91485 0.963253 0.832501 0.335271 0.148639 0.947272 0.71471 0.438488 0.586067 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=11410, meanQ=9.361222, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 29196 episodes
GETTING ACTION FROM:
action 2, numVisits=40591, meanQ=8.495997, numObservations: 9
action 0, numVisits=8, meanQ=-1.257500, numObservations: 8
action -1, numVisits=8, meanQ=-1.257500, numObservations: 8
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=2, meanQ=-6.485400, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.770795 0.91485 0.963253 0.832501 0.335271 0.148639 0.947272 0.71471 0.438488 0.586067 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 40
Initial state: 0 0.364257 0.720914 0.0918115 0.554816 0.656074 0.784664 0.851098 0.438537 0.373282 0.628202 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 90000 episodes
GETTING ACTION FROM:
action 2, numVisits=89991, meanQ=8.202267, numObservations: 9
action 5, numVisits=4, meanQ=1.497500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.364257 0.720914 0.0918115 0.554816 0.656074 0.784664 0.851098 0.438537 0.373282 0.628202 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=2459, meanQ=9.379834, numObservations: 9
action 5, numVisits=6, meanQ=1.998333, numObservations: 4
action 3, numVisits=4, meanQ=-0.252500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 39190 episodes
GETTING ACTION FROM:
action 1, numVisits=41602, meanQ=9.383332, numObservations: 9
action 5, numVisits=6, meanQ=1.998333, numObservations: 4
action 3, numVisits=4, meanQ=-0.252500, numObservations: 3
action 0, numVisits=25, meanQ=-1.524800, numObservations: 24
action -1, numVisits=24, meanQ=-1.547075, numObservations: 22
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.364257 0.720914 0.0918115 0.554816 0.656074 0.784664 0.851098 0.438537 0.373282 0.628202 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 41
Initial state: 0 0.0409492 0.924989 0.276362 0.939197 0.402314 0.571527 0.236075 0.344913 0.307744 0.483607 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 85697 episodes
GETTING ACTION FROM:
action 4, numVisits=85691, meanQ=8.342949, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.0409492 0.924989 0.276362 0.939197 0.402314 0.571527 0.236075 0.344913 0.307744 0.483607 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=10798, meanQ=9.720961, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 28633 episodes
GETTING ACTION FROM:
action 1, numVisits=39417, meanQ=8.869399, numObservations: 9
action -1, numVisits=9, meanQ=-1.120000, numObservations: 9
action 0, numVisits=7, meanQ=-1.434286, numObservations: 5
action 5, numVisits=2, meanQ=-5.797296, numObservations: 2
action 2, numVisits=2, meanQ=-7.005000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.0409492 0.924989 0.276362 0.939197 0.402314 0.571527 0.236075 0.344913 0.307744 0.483607 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=2136, meanQ=11.575316, numObservations: 9
action 1, numVisits=13, meanQ=3.813637, numObservations: 5
action 0, numVisits=12, meanQ=-1.175825, numObservations: 11
action -1, numVisits=14, meanQ=-1.858571, numObservations: 13
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 24729 episodes
GETTING ACTION FROM:
action 2, numVisits=26865, meanQ=12.936051, numObservations: 9
action 1, numVisits=13, meanQ=3.813637, numObservations: 5
action 0, numVisits=12, meanQ=-1.175825, numObservations: 11
action -1, numVisits=14, meanQ=-1.858571, numObservations: 13
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.0409492 0.924989 0.276362 0.939197 0.402314 0.571527 0.236075 0.344913 0.307744 0.483607 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 42
Initial state: 0 0.381007 0.582496 0.634443 0.269691 0.483571 0.699279 0.49011 0.0985436 0.740181 0.933731 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 90024 episodes
GETTING ACTION FROM:
action 4, numVisits=90009, meanQ=8.250414, numObservations: 9
action 1, numVisits=6, meanQ=3.670017, numObservations: 4
action 3, numVisits=3, meanQ=3.000000, numObservations: 3
action 5, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.381007 0.582496 0.634443 0.269691 0.483571 0.699279 0.49011 0.0985436 0.740181 0.933731 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 43
Initial state: 0 0.222616 0.826016 0.138076 0.509361 0.425809 0.536296 0.0117898 0.470324 0.0596286 0.307265 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 90680 episodes
GETTING ACTION FROM:
action 1, numVisits=90665, meanQ=8.395896, numObservations: 9
action 4, numVisits=8, meanQ=3.388750, numObservations: 4
action 2, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.222616 0.826016 0.138076 0.509361 0.425809 0.536296 0.0117898 0.470324 0.0596286 0.307265 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=634, meanQ=10.166340, numObservations: 9
action 4, numVisits=5, meanQ=3.000000, numObservations: 4
action 2, numVisits=6, meanQ=1.998333, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 53997 episodes
GETTING ACTION FROM:
action 2, numVisits=53977, meanQ=11.835155, numObservations: 9
action 3, numVisits=641, meanQ=10.186872, numObservations: 9
action 4, numVisits=6, meanQ=0.666667, numObservations: 4
action -1, numVisits=10, meanQ=-1.802000, numObservations: 10
action 0, numVisits=10, meanQ=-1.802000, numObservations: 9
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.222616 0.826016 0.138076 0.509361 0.425809 0.536296 0.0117898 0.470324 0.0596286 0.307265 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=4, meanQ=-4.014190, numObservations: 4
action -1, numVisits=247, meanQ=-4.739071, numObservations: 82
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-12.139485, numObservations: 1
action 0, numVisits=22, meanQ=-48.019780, numObservations: 19
action 1, numVisits=1, meanQ=-1056.784582, numObservations: 1
Sampled 59078 episodes
GETTING ACTION FROM:
action 3, numVisits=59082, meanQ=13.665683, numObservations: 9
action -1, numVisits=247, meanQ=-4.739071, numObservations: 82
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-12.139485, numObservations: 1
action 0, numVisits=22, meanQ=-48.019780, numObservations: 19
action 1, numVisits=1, meanQ=-1056.784582, numObservations: 1
action: 3
Next state: 1 0.222616 0.826016 0.138076 0.509361 0.425809 0.536296 0.0117898 0.470324 0.0596286 0.307265 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 44
Initial state: 0 0.0520621 0.408982 0.262528 0.986018 0.448836 0.567236 0.0712643 0.875587 0.749546 0.123514 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 50195 episodes
GETTING ACTION FROM:
action -1, numVisits=50147, meanQ=13.737968, numObservations: 243
action 0, numVisits=41, meanQ=-1.348290, numObservations: 39
action 3, numVisits=2, meanQ=-5.489950, numObservations: 1
action 5, numVisits=2, meanQ=-9.445000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.0520621 0.408982 0.262528 0.986018 0.448836 0.567236 0.0712643 0.875587 0.749546 0.123514 w: 1
Observation: 0 1 0 1 0 1 0 1 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=43, meanQ=10.412818, numObservations: 7
action 5, numVisits=19, meanQ=4.577895, numObservations: 5
action 1, numVisits=12, meanQ=4.504208, numObservations: 6
action 3, numVisits=15, meanQ=4.401367, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 63924 episodes
GETTING ACTION FROM:
action 4, numVisits=63967, meanQ=9.808747, numObservations: 9
action 5, numVisits=19, meanQ=4.577895, numObservations: 5
action 1, numVisits=12, meanQ=4.504208, numObservations: 6
action 3, numVisits=15, meanQ=4.401367, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 0 0.0520621 0.408982 0.262528 0.986018 0.448836 0.567236 0.0712643 0.875587 0.749546 0.123514 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=10969, meanQ=12.938377, numObservations: 9
action 4, numVisits=4, meanQ=3.742500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 28684 episodes
GETTING ACTION FROM:
action 3, numVisits=39646, meanQ=15.271596, numObservations: 9
action 4, numVisits=4, meanQ=3.742500, numObservations: 4
action -1, numVisits=4, meanQ=-1.257500, numObservations: 3
action 0, numVisits=4, meanQ=-1.257500, numObservations: 4
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=2, meanQ=-5.271466, numObservations: 2
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.0520621 0.408982 0.262528 0.986018 0.448836 0.567236 0.0712643 0.875587 0.749546 0.123514 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 17.5624
Run # 45
Initial state: 0 0.905934 0.232088 0.645606 0.569344 0.626748 0.458566 0.405959 0.526391 0.860406 0.200506 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89880 episodes
GETTING ACTION FROM:
action 4, numVisits=89869, meanQ=8.128612, numObservations: 9
action 3, numVisits=4, meanQ=1.250000, numObservations: 4
action 5, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.905934 0.232088 0.645606 0.569344 0.626748 0.458566 0.405959 0.526391 0.860406 0.200506 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 46
Initial state: 0 0.461878 0.629006 0.014075 0.430224 0.614286 0.306396 0.718363 0.470895 0.570029 0.664187 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 90321 episodes
GETTING ACTION FROM:
action 1, numVisits=90311, meanQ=8.160660, numObservations: 9
action 2, numVisits=3, meanQ=3.330000, numObservations: 2
action 5, numVisits=3, meanQ=1.703333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.461878 0.629006 0.014075 0.430224 0.614286 0.306396 0.718363 0.470895 0.570029 0.664187 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 47
Initial state: 0 0.891113 0.393542 0.699732 0.310332 0.872697 0.402736 0.431292 0.567443 0.880658 0.815962 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89536 episodes
GETTING ACTION FROM:
action 4, numVisits=89509, meanQ=8.157504, numObservations: 9
action 2, numVisits=11, meanQ=2.908200, numObservations: 7
action 5, numVisits=10, meanQ=1.897000, numObservations: 6
action 3, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.891113 0.393542 0.699732 0.310332 0.872697 0.402736 0.431292 0.567443 0.880658 0.815962 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 48
Initial state: 0 0.0163275 0.512156 0.770714 0.151843 0.226632 0.371174 0.558311 0.763486 0.460761 0.588749 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 90387 episodes
GETTING ACTION FROM:
action 5, numVisits=89705, meanQ=8.230838, numObservations: 9
action 2, numVisits=653, meanQ=7.571541, numObservations: 9
action 1, numVisits=20, meanQ=6.036505, numObservations: 4
action 3, numVisits=6, meanQ=4.496667, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.0163275 0.512156 0.770714 0.151843 0.226632 0.371174 0.558311 0.763486 0.460761 0.588749 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 49
Initial state: 0 0.367453 0.859141 0.395364 0.657502 0.620936 0.304321 0.843208 0.0807385 0.504556 0.463454 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 90020 episodes
GETTING ACTION FROM:
action 2, numVisits=90012, meanQ=8.164767, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.367453 0.859141 0.395364 0.657502 0.620936 0.304321 0.843208 0.0807385 0.504556 0.463454 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 50
Initial state: 0 0.703333 0.877225 0.617733 0.183545 0.502135 0.2553 0.397709 0.56804 0.070525 0.203861 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 90028 episodes
GETTING ACTION FROM:
action 2, numVisits=90019, meanQ=8.325148, numObservations: 9
action 4, numVisits=4, meanQ=3.247500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.703333 0.877225 0.617733 0.183545 0.502135 0.2553 0.397709 0.56804 0.070525 0.203861 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
[32m ProblemEnvironment.hpp 351: Done.[39m
