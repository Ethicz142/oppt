Run # 1
Initial state: 0 0.472946 0.442018 0.194857 0.460904 0.867535 0.302805 0.0719744 0.917657 0.607767 0.523058 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 73360 episodes
GETTING ACTION FROM:
action 1, numVisits=73350, meanQ=10.533871, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.472946 0.442018 0.194857 0.460904 0.867535 0.302805 0.0719744 0.917657 0.607767 0.523058 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=12673, meanQ=12.063614, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 15876 episodes
GETTING ACTION FROM:
action 4, numVisits=28542, meanQ=11.136673, numObservations: 9
action -1, numVisits=5, meanQ=-1.208000, numObservations: 5
action 0, numVisits=4, meanQ=-1.505000, numObservations: 4
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 1 0.472946 0.442018 0.194857 0.460904 0.867535 0.302805 0.0719744 0.917657 0.607767 0.523058 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 2
Initial state: 0 0.755995 0.687604 0.61306 0.496456 0.135571 0.0569924 0.693919 0.578763 0.645167 0.743679 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79232 episodes
GETTING ACTION FROM:
action 2, numVisits=79210, meanQ=10.470060, numObservations: 9
action 3, numVisits=12, meanQ=2.340000, numObservations: 6
action 5, numVisits=6, meanQ=1.350000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.755995 0.687604 0.61306 0.496456 0.135571 0.0569924 0.693919 0.578763 0.645167 0.743679 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=286, meanQ=7.655308, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 64562 episodes
GETTING ACTION FROM:
action 5, numVisits=64848, meanQ=11.810206, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.755995 0.687604 0.61306 0.496456 0.135571 0.0569924 0.693919 0.578763 0.645167 0.743679 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 3
Initial state: 0 0.159347 0.438288 0.956644 0.844288 0.907229 0.575367 0.630451 0.539225 0.331319 0.293739 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 77651 episodes
GETTING ACTION FROM:
action 1, numVisits=77639, meanQ=10.769155, numObservations: 9
action 2, numVisits=7, meanQ=1.574300, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.159347 0.438288 0.956644 0.844288 0.907229 0.575367 0.630451 0.539225 0.331319 0.293739 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=13531, meanQ=12.123073, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 15971 episodes
GETTING ACTION FROM:
action 2, numVisits=29496, meanQ=11.364299, numObservations: 9
action -1, numVisits=4, meanQ=-1.257500, numObservations: 4
action 0, numVisits=4, meanQ=-1.257500, numObservations: 4
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.159347 0.438288 0.956644 0.844288 0.907229 0.575367 0.630451 0.539225 0.331319 0.293739 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 4
Initial state: 0 0.761617 0.205679 0.156952 0.169119 0.605327 0.505203 0.0530663 0.04373 0.170534 0.280559 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 78706 episodes
GETTING ACTION FROM:
action 2, numVisits=78650, meanQ=10.522278, numObservations: 9
action 0, numVisits=39, meanQ=-0.681015, numObservations: 34
action -1, numVisits=12, meanQ=-1.175825, numObservations: 11
action 1, numVisits=2, meanQ=-3.505000, numObservations: 2
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.761617 0.205679 0.156952 0.169119 0.605327 0.505203 0.0530663 0.04373 0.170534 0.280559 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=13740, meanQ=11.723144, numObservations: 9
action 3, numVisits=8, meanQ=5.121250, numObservations: 5
action 4, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 18428 episodes
GETTING ACTION FROM:
action 1, numVisits=32132, meanQ=11.130553, numObservations: 9
action 5, numVisits=28, meanQ=7.102498, numObservations: 8
action 3, numVisits=8, meanQ=5.121250, numObservations: 5
action 4, numVisits=4, meanQ=-0.252500, numObservations: 3
action -1, numVisits=5, meanQ=-1.010000, numObservations: 5
action 0, numVisits=5, meanQ=-1.406000, numObservations: 5
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.761617 0.205679 0.156952 0.169119 0.605327 0.505203 0.0530663 0.04373 0.170534 0.280559 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 5
Initial state: 0 0.913513 0.519897 0.176702 0.0682952 0.359293 0.22056 0.114652 0.152067 0.678122 0.538511 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 77709 episodes
GETTING ACTION FROM:
action 4, numVisits=77700, meanQ=10.371831, numObservations: 9
action 3, numVisits=4, meanQ=3.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 0 0.913513 0.519897 0.176702 0.0682952 0.359293 0.22056 0.114652 0.152067 0.678122 0.538511 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=13285, meanQ=11.947598, numObservations: 9
action 1, numVisits=118, meanQ=9.026210, numObservations: 9
action 5, numVisits=7, meanQ=6.282857, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 17196 episodes
GETTING ACTION FROM:
action 3, numVisits=30477, meanQ=11.948260, numObservations: 9
action 1, numVisits=118, meanQ=9.026210, numObservations: 9
action 5, numVisits=7, meanQ=6.282857, numObservations: 6
action -1, numVisits=3, meanQ=-1.340000, numObservations: 3
action 0, numVisits=3, meanQ=-1.340000, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.913513 0.519897 0.176702 0.0682952 0.359293 0.22056 0.114652 0.152067 0.678122 0.538511 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 6
Initial state: 0 0.619616 0.465987 0.980807 0.843197 0.893661 0.363952 0.871487 0.0187384 0.512517 0.265316 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79481 episodes
GETTING ACTION FROM:
action 4, numVisits=79449, meanQ=10.599218, numObservations: 9
action 2, numVisits=16, meanQ=8.111888, numObservations: 7
action 3, numVisits=8, meanQ=7.012500, numObservations: 4
action 1, numVisits=5, meanQ=5.998000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 2 0.619616 0.465987 0.980807 0.843197 0.893661 0.363952 0.871487 0.0187384 0.512517 0.265316 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 7
Initial state: 0 0.589138 0.477565 0.0324099 0.266499 0.450724 0.179225 0.834124 0.810803 0.208758 0.065547 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79473 episodes
GETTING ACTION FROM:
action 3, numVisits=79465, meanQ=10.630027, numObservations: 9
action 2, numVisits=3, meanQ=5.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.589138 0.477565 0.0324099 0.266499 0.450724 0.179225 0.834124 0.810803 0.208758 0.065547 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=13620, meanQ=11.743151, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 20460 episodes
GETTING ACTION FROM:
action 1, numVisits=34007, meanQ=11.084655, numObservations: 9
action -1, numVisits=53, meanQ=0.546230, numObservations: 39
action 4, numVisits=5, meanQ=-0.771314, numObservations: 4
action 0, numVisits=16, meanQ=-1.382488, numObservations: 13
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action 5, numVisits=2, meanQ=-8.950000, numObservations: 1
action: 1
Next state: 1 0.589138 0.477565 0.0324099 0.266499 0.450724 0.179225 0.834124 0.810803 0.208758 0.065547 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 8
Initial state: 0 0.71176 0.404628 0.509796 0.863477 0.810568 0.31965 0.638925 0.467069 0.2169 0.458901 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79786 episodes
GETTING ACTION FROM:
action 5, numVisits=79772, meanQ=10.829816, numObservations: 9
action 3, numVisits=5, meanQ=7.000020, numObservations: 3
action 1, numVisits=3, meanQ=5.333333, numObservations: 3
action 4, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 0 0.71176 0.404628 0.509796 0.863477 0.810568 0.31965 0.638925 0.467069 0.2169 0.458901 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=2595, meanQ=11.475880, numObservations: 9
action 3, numVisits=27, meanQ=10.213348, numObservations: 9
action 1, numVisits=5, meanQ=7.794000, numObservations: 4
action 5, numVisits=3, meanQ=4.670033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 18621 episodes
GETTING ACTION FROM:
action 2, numVisits=21130, meanQ=12.831318, numObservations: 9
action 3, numVisits=71, meanQ=7.704202, numObservations: 9
action 5, numVisits=3, meanQ=4.670033, numObservations: 2
action 1, numVisits=7, meanQ=2.525561, numObservations: 5
action 0, numVisits=21, meanQ=-1.576186, numObservations: 19
action -1, numVisits=21, meanQ=-1.953800, numObservations: 17
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.71176 0.404628 0.509796 0.863477 0.810568 0.31965 0.638925 0.467069 0.2169 0.458901 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 9
Initial state: 0 0.486867 0.516217 0.919705 0.366746 0.187667 0.899082 0.630604 0.533041 0.269815 0.587847 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79858 episodes
GETTING ACTION FROM:
action 3, numVisits=79843, meanQ=10.683826, numObservations: 9
action 2, numVisits=7, meanQ=2.141429, numObservations: 5
action 1, numVisits=4, meanQ=-0.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.486867 0.516217 0.919705 0.366746 0.187667 0.899082 0.630604 0.533041 0.269815 0.587847 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=11352, meanQ=11.948750, numObservations: 9
action 5, numVisits=7, meanQ=6.857157, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 24189 episodes
GETTING ACTION FROM:
action 4, numVisits=35532, meanQ=13.393705, numObservations: 9
action 5, numVisits=8, meanQ=4.625013, numObservations: 4
action 0, numVisits=5, meanQ=-1.010000, numObservations: 5
action -1, numVisits=5, meanQ=-1.406000, numObservations: 5
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.486867 0.516217 0.919705 0.366746 0.187667 0.899082 0.630604 0.533041 0.269815 0.587847 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 10
Initial state: 0 0.64545 0.524535 0.124431 0.870842 0.190735 0.205716 0.739012 0.495615 0.29888 0.0309694 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79869 episodes
GETTING ACTION FROM:
action 5, numVisits=79863, meanQ=10.739167, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 0 0.64545 0.524535 0.124431 0.870842 0.190735 0.205716 0.739012 0.495615 0.29888 0.0309694 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=13922, meanQ=11.900780, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 18192 episodes
GETTING ACTION FROM:
action 1, numVisits=32109, meanQ=11.958147, numObservations: 9
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action -1, numVisits=3, meanQ=-1.340000, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.64545 0.524535 0.124431 0.870842 0.190735 0.205716 0.739012 0.495615 0.29888 0.0309694 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 11
Initial state: 0 0.719123 0.0701612 0.66375 0.466493 0.826418 0.549689 0.0382791 0.137359 0.0016206 0.0590317 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 75901 episodes
GETTING ACTION FROM:
action 3, numVisits=75885, meanQ=10.545647, numObservations: 9
action 5, numVisits=8, meanQ=7.843750, numObservations: 5
action 1, numVisits=4, meanQ=7.190000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.719123 0.0701612 0.66375 0.466493 0.826418 0.549689 0.0382791 0.137359 0.0016206 0.0590317 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 12
Initial state: 0 0.765706 0.463371 0.612565 0.460277 0.799666 0.584258 0.694607 0.594589 0.0222217 0.862399 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 76020 episodes
GETTING ACTION FROM:
action 4, numVisits=76014, meanQ=10.682745, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.765706 0.463371 0.612565 0.460277 0.799666 0.584258 0.694607 0.594589 0.0222217 0.862399 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 13
Initial state: 0 0.793486 0.0371575 0.9611 0.279744 0.0304863 0.587594 0.0150605 0.889827 0.648743 0.497204 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79165 episodes
GETTING ACTION FROM:
action 4, numVisits=79159, meanQ=10.409212, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.793486 0.0371575 0.9611 0.279744 0.0304863 0.587594 0.0150605 0.889827 0.648743 0.497204 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=11003, meanQ=11.707427, numObservations: 9
action 3, numVisits=4, meanQ=-0.252500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 21514 episodes
GETTING ACTION FROM:
action 1, numVisits=32513, meanQ=13.201688, numObservations: 9
action 3, numVisits=4, meanQ=-0.252500, numObservations: 4
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action -1, numVisits=3, meanQ=-1.340000, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.793486 0.0371575 0.9611 0.279744 0.0304863 0.587594 0.0150605 0.889827 0.648743 0.497204 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 14
Initial state: 0 0.963994 0.774602 0.0446063 0.35639 0.197266 0.951129 0.595091 0.535399 0.477017 0.596848 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79606 episodes
GETTING ACTION FROM:
action 1, numVisits=79596, meanQ=10.555500, numObservations: 9
action 4, numVisits=3, meanQ=5.333333, numObservations: 2
action 5, numVisits=3, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.963994 0.774602 0.0446063 0.35639 0.197266 0.951129 0.595091 0.535399 0.477017 0.596848 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 15
Initial state: 0 0.879433 0.189161 0.618982 0.481749 0.279216 0.909073 0.420259 0.242604 0.00746994 0.724763 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79152 episodes
GETTING ACTION FROM:
action 1, numVisits=79142, meanQ=10.453170, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.879433 0.189161 0.618982 0.481749 0.279216 0.909073 0.420259 0.242604 0.00746994 0.724763 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 16
Initial state: 0 0.42789 0.150724 0.895398 0.295527 0.314319 0.128221 0.460464 0.5471 0.58164 0.475165 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 76344 episodes
GETTING ACTION FROM:
action 4, numVisits=76332, meanQ=10.499527, numObservations: 9
action 1, numVisits=5, meanQ=4.400000, numObservations: 4
action 2, numVisits=3, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 1 0.42789 0.150724 0.895398 0.295527 0.314319 0.128221 0.460464 0.5471 0.58164 0.475165 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 17
Initial state: 0 0.930754 0.125437 0.55872 0.488456 0.153712 0.120488 0.982861 0.354218 0.0156345 0.79127 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 76676 episodes
GETTING ACTION FROM:
action 1, numVisits=76670, meanQ=10.843369, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.930754 0.125437 0.55872 0.488456 0.153712 0.120488 0.982861 0.354218 0.0156345 0.79127 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 18
Initial state: 0 0.589041 0.530172 0.975629 0.159639 0.939999 0.0181093 0.155329 0.860196 0.381606 0.0652646 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79563 episodes
GETTING ACTION FROM:
action 4, numVisits=79555, meanQ=10.624361, numObservations: 9
action 5, numVisits=3, meanQ=5.663333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.589041 0.530172 0.975629 0.159639 0.939999 0.0181093 0.155329 0.860196 0.381606 0.0652646 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=11106, meanQ=11.524738, numObservations: 9
action 1, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 22798 episodes
GETTING ACTION FROM:
action 5, numVisits=33884, meanQ=13.605074, numObservations: 9
action 0, numVisits=16, meanQ=0.351250, numObservations: 15
action -1, numVisits=5, meanQ=-1.208000, numObservations: 5
action 1, numVisits=4, meanQ=-1.225000, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 2 0.589041 0.530172 0.975629 0.159639 0.939999 0.0181093 0.155329 0.860196 0.381606 0.0652646 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 19
Initial state: 0 0.603756 0.48004 0.41348 0.213634 0.904386 0.0588913 0.729283 0.953826 0.159571 0.468284 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79528 episodes
GETTING ACTION FROM:
action 4, numVisits=79516, meanQ=10.646913, numObservations: 9
action 2, numVisits=7, meanQ=6.282857, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.603756 0.48004 0.41348 0.213634 0.904386 0.0588913 0.729283 0.953826 0.159571 0.468284 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 20
Initial state: 0 0.637954 0.460249 0.940743 0.884117 0.802334 0.401657 0.410176 0.94734 0.117313 0.559545 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 50621 episodes
GETTING ACTION FROM:
action -1, numVisits=50597, meanQ=13.781668, numObservations: 243
action 0, numVisits=18, meanQ=-1.010000, numObservations: 18
action 5, numVisits=2, meanQ=-7.500000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.637954 0.460249 0.940743 0.884117 0.802334 0.401657 0.410176 0.94734 0.117313 0.559545 w: 1
Observation: 0 2 0 1 0 3 0 1 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=494, meanQ=20.834599, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 113222 episodes
GETTING ACTION FROM:
action 1, numVisits=113716, meanQ=21.608598, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.637954 0.460249 0.940743 0.884117 0.802334 0.401657 0.410176 0.94734 0.117313 0.559545 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 21
Initial state: 0 0.999943 0.140114 0.679589 0.542332 0.300713 0.711861 0.161788 0.723555 0.885195 0.572186 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79423 episodes
GETTING ACTION FROM:
action 2, numVisits=79417, meanQ=10.515893, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.999943 0.140114 0.679589 0.542332 0.300713 0.711861 0.161788 0.723555 0.885195 0.572186 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 22
Initial state: 0 0.430477 0.143978 0.572798 0.473374 0.176432 0.990562 0.611855 0.0928437 0.487772 0.961955 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 78999 episodes
GETTING ACTION FROM:
action 3, numVisits=78991, meanQ=10.549528, numObservations: 9
action 1, numVisits=3, meanQ=1.703333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.430477 0.143978 0.572798 0.473374 0.176432 0.990562 0.611855 0.0928437 0.487772 0.961955 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=727, meanQ=12.778204, numObservations: 9
action 2, numVisits=4, meanQ=8.497500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 74592 episodes
GETTING ACTION FROM:
action 1, numVisits=75313, meanQ=15.511074, numObservations: 9
action 2, numVisits=8, meanQ=7.498750, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.430477 0.143978 0.572798 0.473374 0.176432 0.990562 0.611855 0.0928437 0.487772 0.961955 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=1404, meanQ=15.259994, numObservations: 9
action 4, numVisits=9, meanQ=11.107778, numObservations: 7
action 5, numVisits=5, meanQ=6.523254, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 68196 episodes
GETTING ACTION FROM:
action 4, numVisits=66409, meanQ=15.948868, numObservations: 9
action 2, numVisits=3198, meanQ=14.054837, numObservations: 9
action 5, numVisits=5, meanQ=6.523254, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 0 0.430477 0.143978 0.572798 0.473374 0.176432 0.990562 0.611855 0.0928437 0.487772 0.961955 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 5, numVisits=40, meanQ=17.235876, numObservations: 6
action 2, numVisits=49, meanQ=6.589119, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-10.284506, numObservations: 1
action 3, numVisits=1, meanQ=-538.940041, numObservations: 1
action 1, numVisits=1, meanQ=-538.983377, numObservations: 1
Sampled 94858 episodes
GETTING ACTION FROM:
action 5, numVisits=94890, meanQ=12.111950, numObservations: 9
action 2, numVisits=49, meanQ=6.589119, numObservations: 8
action -1, numVisits=5, meanQ=-1.802000, numObservations: 5
action 0, numVisits=5, meanQ=-1.802000, numObservations: 5
action 4, numVisits=1, meanQ=-10.284506, numObservations: 1
action 3, numVisits=1, meanQ=-538.940041, numObservations: 1
action 1, numVisits=1, meanQ=-538.983377, numObservations: 1
action: 5
Next state: 0 0.430477 0.143978 0.572798 0.473374 0.176432 0.990562 0.611855 0.0928437 0.487772 0.961955 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 2, numVisits=44, meanQ=10.587059, numObservations: 6
action -1, numVisits=32, meanQ=-5.480093, numObservations: 12
action 5, numVisits=1, meanQ=-12.621155, numObservations: 1
action 0, numVisits=4, meanQ=-90.841575, numObservations: 3
action 3, numVisits=1, meanQ=-360.463861, numObservations: 1
action 1, numVisits=1, meanQ=-361.541972, numObservations: 1
action 4, numVisits=1, meanQ=-362.224017, numObservations: 1
Sampled 124419 episodes
GETTING ACTION FROM:
action 2, numVisits=124463, meanQ=19.843332, numObservations: 9
action -1, numVisits=32, meanQ=-5.480093, numObservations: 12
action 5, numVisits=1, meanQ=-12.621155, numObservations: 1
action 0, numVisits=4, meanQ=-90.841575, numObservations: 3
action 3, numVisits=1, meanQ=-360.463861, numObservations: 1
action 1, numVisits=1, meanQ=-361.541972, numObservations: 1
action 4, numVisits=1, meanQ=-362.224017, numObservations: 1
action: 2
Next state: 1 0.430477 0.143978 0.572798 0.473374 0.176432 0.990562 0.611855 0.0928437 0.487772 0.961955 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.29271
Run # 23
Initial state: 0 0.648604 0.505531 0.928036 0.965634 0.43892 0.151127 0.815475 0.738345 0.939711 0.966212 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 78856 episodes
GETTING ACTION FROM:
action 4, numVisits=78845, meanQ=10.735102, numObservations: 9
action 2, numVisits=6, meanQ=3.173367, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.648604 0.505531 0.928036 0.965634 0.43892 0.151127 0.815475 0.738345 0.939711 0.966212 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 24
Initial state: 0 0.372243 0.848015 0.726732 0.146053 0.373408 0.194983 0.679816 0.777346 0.556267 0.521234 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 78762 episodes
GETTING ACTION FROM:
action 1, numVisits=78754, meanQ=10.488777, numObservations: 9
action 3, numVisits=3, meanQ=1.703333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.372243 0.848015 0.726732 0.146053 0.373408 0.194983 0.679816 0.777346 0.556267 0.521234 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 25
Initial state: 0 0.67133 0.448549 0.411841 0.899797 0.729273 0.942503 0.994975 0.95761 0.226018 0.0228106 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79851 episodes
GETTING ACTION FROM:
action 2, numVisits=79840, meanQ=10.551175, numObservations: 9
action 3, numVisits=6, meanQ=3.670017, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.67133 0.448549 0.411841 0.899797 0.729273 0.942503 0.994975 0.95761 0.226018 0.0228106 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=11105, meanQ=11.867635, numObservations: 9
action 4, numVisits=21, meanQ=8.143348, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 26591 episodes
GETTING ACTION FROM:
action 5, numVisits=37694, meanQ=12.664902, numObservations: 9
action 4, numVisits=21, meanQ=8.143348, numObservations: 9
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.67133 0.448549 0.411841 0.899797 0.729273 0.942503 0.994975 0.95761 0.226018 0.0228106 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 26
Initial state: 0 0.549526 0.488512 0.513637 0.776004 0.00979402 0.594031 0.777061 0.962282 0.923185 0.0653823 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79817 episodes
GETTING ACTION FROM:
action 5, numVisits=79801, meanQ=10.704179, numObservations: 9
action 1, numVisits=6, meanQ=3.000000, numObservations: 5
action 3, numVisits=4, meanQ=3.000000, numObservations: 4
action 4, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 2 0.549526 0.488512 0.513637 0.776004 0.00979402 0.594031 0.777061 0.962282 0.923185 0.0653823 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 27
Initial state: 0 0.548949 0.531551 0.39849 0.772415 0.397734 0.15205 0.612199 0.799237 0.32473 0.71805 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79029 episodes
GETTING ACTION FROM:
action 1, numVisits=79019, meanQ=10.481751, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.548949 0.531551 0.39849 0.772415 0.397734 0.15205 0.612199 0.799237 0.32473 0.71805 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 28
Initial state: 0 0.579362 0.476006 0.917974 0.301858 0.397286 0.0623226 0.749277 0.853912 0.911056 0.859215 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 77121 episodes
GETTING ACTION FROM:
action 2, numVisits=77107, meanQ=10.697982, numObservations: 9
action 1, numVisits=9, meanQ=5.443333, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 2 0.579362 0.476006 0.917974 0.301858 0.397286 0.0623226 0.749277 0.853912 0.911056 0.859215 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 29
Initial state: 0 0.921702 0.635602 0.171543 0.604426 0.587065 0.438667 0.515613 0.196368 0.667571 0.465692 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79380 episodes
GETTING ACTION FROM:
action 2, numVisits=79361, meanQ=10.655430, numObservations: 9
action 4, numVisits=12, meanQ=5.750842, numObservations: 7
action 1, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.921702 0.635602 0.171543 0.604426 0.587065 0.438667 0.515613 0.196368 0.667571 0.465692 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=10861, meanQ=11.835609, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
Sampled 22077 episodes
GETTING ACTION FROM:
action 4, numVisits=32938, meanQ=12.382570, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 4
Next state: 0 0.921702 0.635602 0.171543 0.604426 0.587065 0.438667 0.515613 0.196368 0.667571 0.465692 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=3820, meanQ=13.886780, numObservations: 9
action 4, numVisits=39, meanQ=4.788852, numObservations: 4
action 3, numVisits=4, meanQ=1.745000, numObservations: 3
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 15400 episodes
GETTING ACTION FROM:
action 1, numVisits=19220, meanQ=13.876058, numObservations: 9
action 4, numVisits=39, meanQ=4.788852, numObservations: 4
action 3, numVisits=4, meanQ=1.745000, numObservations: 3
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.921702 0.635602 0.171543 0.604426 0.587065 0.438667 0.515613 0.196368 0.667571 0.465692 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 30
Initial state: 0 0.887523 0.765357 0.969964 0.551288 0.579842 0.895026 0.571787 0.525735 0.808542 0.742859 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 75817 episodes
GETTING ACTION FROM:
action 1, numVisits=75809, meanQ=10.577442, numObservations: 9
action 3, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.887523 0.765357 0.969964 0.551288 0.579842 0.895026 0.571787 0.525735 0.808542 0.742859 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 31
Initial state: 0 0.827812 0.935535 0.682666 0.528291 0.751165 0.547076 0.96031 0.871852 0.926718 0.282035 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79758 episodes
GETTING ACTION FROM:
action 2, numVisits=79741, meanQ=10.572177, numObservations: 9
action 5, numVisits=7, meanQ=6.677143, numObservations: 4
action 1, numVisits=6, meanQ=5.331683, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.827812 0.935535 0.682666 0.528291 0.751165 0.547076 0.96031 0.871852 0.926718 0.282035 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 32
Initial state: 0 0.743066 0.0044952 0.664195 0.456565 0.787715 0.836234 0.207598 0.385938 0.244074 0.232055 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 78295 episodes
GETTING ACTION FROM:
action 1, numVisits=78285, meanQ=10.604788, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.743066 0.0044952 0.664195 0.456565 0.787715 0.836234 0.207598 0.385938 0.244074 0.232055 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 33
Initial state: 0 0.888381 0.717379 0.139077 0.889258 0.569757 0.516727 0.00160542 0.815962 0.706804 0.536826 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 77560 episodes
GETTING ACTION FROM:
action 5, numVisits=77529, meanQ=10.356866, numObservations: 9
action -1, numVisits=22, meanQ=-0.020000, numObservations: 18
action 0, numVisits=5, meanQ=-1.010000, numObservations: 5
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.888381 0.717379 0.139077 0.889258 0.569757 0.516727 0.00160542 0.815962 0.706804 0.536826 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 34
Initial state: 0 0.951838 0.669686 0.0600418 0.136102 0.73412 0.667046 0.714796 0.334022 0.685088 0.485451 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79062 episodes
GETTING ACTION FROM:
action 4, numVisits=72611, meanQ=10.574363, numObservations: 9
action 2, numVisits=6446, meanQ=10.467238, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 2 0.951838 0.669686 0.0600418 0.136102 0.73412 0.667046 0.714796 0.334022 0.685088 0.485451 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 35
Initial state: 0 0.309546 0.000881618 0.341822 0.888067 0.654405 0.471848 0.763179 0.675724 0.128445 0.992959 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79130 episodes
GETTING ACTION FROM:
action 3, numVisits=79122, meanQ=10.586201, numObservations: 9
action 2, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.309546 0.000881618 0.341822 0.888067 0.654405 0.471848 0.763179 0.675724 0.128445 0.992959 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 36
Initial state: 0 0.0233955 0.333844 0.300213 0.846997 0.653257 0.639414 0.669952 0.446469 0.49324 0.902127 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 76358 episodes
GETTING ACTION FROM:
action 1, numVisits=76337, meanQ=10.604344, numObservations: 9
action 5, numVisits=16, meanQ=6.631263, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.0233955 0.333844 0.300213 0.846997 0.653257 0.639414 0.669952 0.446469 0.49324 0.902127 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=10671, meanQ=11.701563, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 22466 episodes
GETTING ACTION FROM:
action 4, numVisits=22453, meanQ=16.397487, numObservations: 9
action 1, numVisits=10672, meanQ=11.700455, numObservations: 9
action 2, numVisits=4, meanQ=-0.070371, numObservations: 3
action -1, numVisits=6, meanQ=-1.010000, numObservations: 6
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.0233955 0.333844 0.300213 0.846997 0.653257 0.639414 0.669952 0.446469 0.49324 0.902127 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 37
Initial state: 0 0.902121 0.249431 0.592618 0.185586 0.75276 0.431176 0.337811 0.807109 0.679143 0.502871 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 78372 episodes
GETTING ACTION FROM:
action 2, numVisits=78348, meanQ=10.632021, numObservations: 9
action -1, numVisits=10, meanQ=-1.010000, numObservations: 10
action 0, numVisits=10, meanQ=-1.010000, numObservations: 10
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.902121 0.249431 0.592618 0.185586 0.75276 0.431176 0.337811 0.807109 0.679143 0.502871 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=637, meanQ=10.269239, numObservations: 9
action 3, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 33605 episodes
GETTING ACTION FROM:
action 1, numVisits=34224, meanQ=15.102000, numObservations: 9
action 3, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=11, meanQ=-1.730000, numObservations: 11
action 0, numVisits=9, meanQ=-1.890000, numObservations: 9
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.902121 0.249431 0.592618 0.185586 0.75276 0.431176 0.337811 0.807109 0.679143 0.502871 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 38
Initial state: 0 0.682856 0.531371 0.116037 0.627759 0.17527 0.319873 0.00336136 0.406336 0.209931 0.353739 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79159 episodes
GETTING ACTION FROM:
action 5, numVisits=79153, meanQ=10.667881, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 0 0.682856 0.531371 0.116037 0.627759 0.17527 0.319873 0.00336136 0.406336 0.209931 0.353739 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=11101, meanQ=11.556411, numObservations: 9
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 21474 episodes
GETTING ACTION FROM:
action 3, numVisits=32570, meanQ=12.912068, numObservations: 9
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action 0, numVisits=4, meanQ=-1.257500, numObservations: 4
action -1, numVisits=3, meanQ=-1.670000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.682856 0.531371 0.116037 0.627759 0.17527 0.319873 0.00336136 0.406336 0.209931 0.353739 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=4560, meanQ=12.659694, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 12458 episodes
GETTING ACTION FROM:
action 4, numVisits=17016, meanQ=12.788967, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 0 0.682856 0.531371 0.116037 0.627759 0.17527 0.319873 0.00336136 0.406336 0.209931 0.353739 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=2998, meanQ=13.324245, numObservations: 9
action 5, numVisits=7, meanQ=6.572886, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 22813 episodes
GETTING ACTION FROM:
action 1, numVisits=25809, meanQ=11.882897, numObservations: 9
action 5, numVisits=7, meanQ=6.572886, numObservations: 2
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action -1, numVisits=3, meanQ=-1.340000, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.682856 0.531371 0.116037 0.627759 0.17527 0.319873 0.00336136 0.406336 0.209931 0.353739 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 11.4068
Run # 39
Initial state: 0 0.473682 0.711463 0.940629 0.579568 0.21952 0.0457664 0.697305 0.473133 0.143822 0.338061 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 78099 episodes
GETTING ACTION FROM:
action 1, numVisits=78090, meanQ=10.514720, numObservations: 9
action 4, numVisits=4, meanQ=1.497500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.473682 0.711463 0.940629 0.579568 0.21952 0.0457664 0.697305 0.473133 0.143822 0.338061 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=11054, meanQ=12.006349, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 22982 episodes
GETTING ACTION FROM:
action 5, numVisits=34032, meanQ=13.222646, numObservations: 9
action 0, numVisits=3, meanQ=-1.340000, numObservations: 3
action -1, numVisits=3, meanQ=-1.670000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.473682 0.711463 0.940629 0.579568 0.21952 0.0457664 0.697305 0.473133 0.143822 0.338061 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 40
Initial state: 0 0.679617 0.463898 0.927168 0.671117 0.73964 0.628193 0.29253 0.918399 0.944047 0.988549 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 76545 episodes
GETTING ACTION FROM:
action 5, numVisits=76500, meanQ=10.766663, numObservations: 9
action 4, numVisits=20, meanQ=7.875005, numObservations: 8
action 1, numVisits=21, meanQ=7.596667, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 1 0.679617 0.463898 0.927168 0.671117 0.73964 0.628193 0.29253 0.918399 0.944047 0.988549 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 41
Initial state: 0 0.356067 0.596845 0.646591 0.459341 0.237762 0.800196 0.308522 0.67363 0.735627 0.607475 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79556 episodes
GETTING ACTION FROM:
action 2, numVisits=79515, meanQ=10.689804, numObservations: 9
action 1, numVisits=21, meanQ=9.049067, numObservations: 6
action 5, numVisits=8, meanQ=8.125013, numObservations: 6
action 4, numVisits=5, meanQ=7.596000, numObservations: 3
action 3, numVisits=5, meanQ=7.198020, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.356067 0.596845 0.646591 0.459341 0.237762 0.800196 0.308522 0.67363 0.735627 0.607475 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 42
Initial state: 0 0.670817 0.492215 0.0867519 0.210762 0.731 0.641085 0.826947 0.86151 0.476384 0.49614 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 78732 episodes
GETTING ACTION FROM:
action 5, numVisits=78726, meanQ=10.571651, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 0 0.670817 0.492215 0.0867519 0.210762 0.731 0.641085 0.826947 0.86151 0.476384 0.49614 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=2571, meanQ=11.138762, numObservations: 9
action 1, numVisits=32, meanQ=9.642831, numObservations: 8
action 4, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 18180 episodes
GETTING ACTION FROM:
action 4, numVisits=18003, meanQ=12.710450, numObservations: 9
action 2, numVisits=2669, meanQ=11.212330, numObservations: 9
action 1, numVisits=46, meanQ=6.903720, numObservations: 8
action 0, numVisits=46, meanQ=-1.168032, numObservations: 42
action -1, numVisits=24, meanQ=-1.464163, numObservations: 23
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 1 0.670817 0.492215 0.0867519 0.210762 0.731 0.641085 0.826947 0.86151 0.476384 0.49614 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 43
Initial state: 0 0.412005 0.948981 0.558737 0.514228 0.50187 0.771513 0.395512 0.683254 0.491861 0.59225 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 78698 episodes
GETTING ACTION FROM:
action 2, numVisits=78665, meanQ=10.574617, numObservations: 9
action 5, numVisits=10, meanQ=8.098000, numObservations: 6
action 4, numVisits=7, meanQ=6.998586, numObservations: 4
action 1, numVisits=7, meanQ=6.715729, numObservations: 4
action 3, numVisits=7, meanQ=5.715729, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.412005 0.948981 0.558737 0.514228 0.50187 0.771513 0.395512 0.683254 0.491861 0.59225 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 44
Initial state: 0 0.145013 0.858077 0.0824226 0.00280717 0.552426 0.459829 0.88072 0.239556 0.383837 0.437828 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 78867 episodes
GETTING ACTION FROM:
action 3, numVisits=78857, meanQ=10.503542, numObservations: 9
action 1, numVisits=5, meanQ=5.998000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.145013 0.858077 0.0824226 0.00280717 0.552426 0.459829 0.88072 0.239556 0.383837 0.437828 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 45
Initial state: 0 0.758734 0.599202 0.444029 0.887882 0.359178 0.0738236 0.640123 0.518897 0.434224 0.846773 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 77673 episodes
GETTING ACTION FROM:
action 5, numVisits=77651, meanQ=10.348671, numObservations: 9
action 3, numVisits=15, meanQ=7.010013, numObservations: 8
action 2, numVisits=3, meanQ=5.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.758734 0.599202 0.444029 0.887882 0.359178 0.0738236 0.640123 0.518897 0.434224 0.846773 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=623, meanQ=13.182902, numObservations: 9
action 4, numVisits=5, meanQ=7.000020, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 38685 episodes
GETTING ACTION FROM:
action 1, numVisits=39296, meanQ=13.320540, numObservations: 9
action 4, numVisits=6, meanQ=5.000033, numObservations: 4
action -1, numVisits=7, meanQ=-1.717143, numObservations: 7
action 0, numVisits=6, meanQ=-1.835000, numObservations: 6
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.758734 0.599202 0.444029 0.887882 0.359178 0.0738236 0.640123 0.518897 0.434224 0.846773 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 46
Initial state: 0 0.446734 0.96865 0.563209 0.753379 0.743797 0.885557 0.646745 0.508398 0.26062 0.952968 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79480 episodes
GETTING ACTION FROM:
action 2, numVisits=79460, meanQ=10.465566, numObservations: 9
action 3, numVisits=11, meanQ=6.817282, numObservations: 8
action 5, numVisits=5, meanQ=4.400000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.446734 0.96865 0.563209 0.753379 0.743797 0.885557 0.646745 0.508398 0.26062 0.952968 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 47
Initial state: 0 0.543275 0.182805 0.302826 0.359508 0.590815 0.482637 0.746618 0.174643 0.503924 0.249096 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 78157 episodes
GETTING ACTION FROM:
action 5, numVisits=78149, meanQ=10.257748, numObservations: 9
action 3, numVisits=3, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 0 0.543275 0.182805 0.302826 0.359508 0.590815 0.482637 0.746618 0.174643 0.503924 0.249096 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=2610, meanQ=9.884646, numObservations: 9
action 2, numVisits=4, meanQ=-0.252500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 15888 episodes
GETTING ACTION FROM:
action 3, numVisits=18417, meanQ=11.310876, numObservations: 9
action 2, numVisits=4, meanQ=-0.252500, numObservations: 4
action 0, numVisits=55, meanQ=-1.574368, numObservations: 46
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=2, meanQ=-8.565973, numObservations: 2
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=27, meanQ=-39.610162, numObservations: 22
action: 3
Next state: 1 0.543275 0.182805 0.302826 0.359508 0.590815 0.482637 0.746618 0.174643 0.503924 0.249096 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 48
Initial state: 0 0.10156 0.753749 0.900894 0.147746 0.584571 0.482599 0.945411 0.32149 0.33249 0.976738 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79316 episodes
GETTING ACTION FROM:
action 5, numVisits=79310, meanQ=10.575680, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.10156 0.753749 0.900894 0.147746 0.584571 0.482599 0.945411 0.32149 0.33249 0.976738 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=548, meanQ=12.464783, numObservations: 9
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 34665 episodes
GETTING ACTION FROM:
action 3, numVisits=35192, meanQ=14.306625, numObservations: 9
action 5, numVisits=17, meanQ=10.000000, numObservations: 6
action 0, numVisits=4, meanQ=-1.505000, numObservations: 4
action -1, numVisits=4, meanQ=-1.752500, numObservations: 4
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.10156 0.753749 0.900894 0.147746 0.584571 0.482599 0.945411 0.32149 0.33249 0.976738 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 49
Initial state: 0 0.99629 0.698772 0.659261 0.542421 0.0625704 0.934793 0.490455 0.967237 0.279493 0.774635 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79188 episodes
GETTING ACTION FROM:
action 5, numVisits=79178, meanQ=10.595113, numObservations: 9
action 2, numVisits=3, meanQ=5.333333, numObservations: 3
action 1, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.99629 0.698772 0.659261 0.542421 0.0625704 0.934793 0.490455 0.967237 0.279493 0.774635 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=11084, meanQ=11.899355, numObservations: 9
action -1, numVisits=7, meanQ=-1.010000, numObservations: 7
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=2, meanQ=-4.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 21411 episodes
GETTING ACTION FROM:
action 4, numVisits=32492, meanQ=12.382172, numObservations: 9
action -1, numVisits=8, meanQ=-1.010000, numObservations: 8
action 0, numVisits=8, meanQ=-1.133750, numObservations: 8
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=2, meanQ=-4.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.99629 0.698772 0.659261 0.542421 0.0625704 0.934793 0.490455 0.967237 0.279493 0.774635 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=3787, meanQ=15.017678, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 19553 episodes
GETTING ACTION FROM:
action 3, numVisits=23340, meanQ=18.562995, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.99629 0.698772 0.659261 0.542421 0.0625704 0.934793 0.490455 0.967237 0.279493 0.774635 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=1370, meanQ=14.441713, numObservations: 9
action 4, numVisits=35, meanQ=12.012271, numObservations: 6
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 54949 episodes
GETTING ACTION FROM:
action 1, numVisits=54945, meanQ=22.271858, numObservations: 9
action 2, numVisits=1371, meanQ=14.441331, numObservations: 9
action 4, numVisits=35, meanQ=12.012271, numObservations: 6
action 0, numVisits=4, meanQ=-1.257500, numObservations: 4
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=4, meanQ=-78.972077, numObservations: 3
action: 1
Next state: 1 0.99629 0.698772 0.659261 0.542421 0.0625704 0.934793 0.490455 0.967237 0.279493 0.774635 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 11.4068
Run # 50
Initial state: 0 0.22585 0.943151 0.651554 0.00383182 0.483509 0.0943691 0.606894 0.966289 0.62757 0.468665 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 78483 episodes
GETTING ACTION FROM:
action 2, numVisits=78459, meanQ=10.569126, numObservations: 9
action 3, numVisits=14, meanQ=4.714314, numObservations: 7
action 1, numVisits=6, meanQ=3.790000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 2 0.22585 0.943151 0.651554 0.00383182 0.483509 0.0943691 0.606894 0.966289 0.62757 0.468665 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
[32m ProblemEnvironment.hpp 351: Done.[39m
