Run # 1
Initial state: 0 0.259849 0.958458 0.305535 0.719263 0.739177 0.564126 0.130663 0.121167 0.441434 0.459042 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89462 episodes
GETTING ACTION FROM:
action 3, numVisits=89443, meanQ=11.699003, numObservations: 9
action 1, numVisits=14, meanQ=4.195729, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.259849 0.958458 0.305535 0.719263 0.739177 0.564126 0.130663 0.121167 0.441434 0.459042 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 2
Initial state: 0 0.319401 0.597137 0.400561 0.37155 0.66033 0.287775 0.985767 0.923763 0.371802 0.869578 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 90879 episodes
GETTING ACTION FROM:
action 3, numVisits=90870, meanQ=11.813345, numObservations: 9
action 4, numVisits=4, meanQ=6.500000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.319401 0.597137 0.400561 0.37155 0.66033 0.287775 0.985767 0.923763 0.371802 0.869578 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 3
Initial state: 0 0.696274 0.323919 0.71902 0.133317 0.964649 0.311557 0.391472 0.433415 0.794043 0.557726 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91035 episodes
GETTING ACTION FROM:
action 1, numVisits=91018, meanQ=11.844110, numObservations: 9
action 2, numVisits=8, meanQ=3.875000, numObservations: 6
action 4, numVisits=5, meanQ=3.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.696274 0.323919 0.71902 0.133317 0.964649 0.311557 0.391472 0.433415 0.794043 0.557726 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 4
Initial state: 0 0.143594 0.470634 0.960159 0.565479 0.102296 0.539616 0.5782 0.269992 0.468043 0.371205 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91569 episodes
GETTING ACTION FROM:
action 2, numVisits=91559, meanQ=11.854834, numObservations: 9
action 3, numVisits=5, meanQ=5.800000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.143594 0.470634 0.960159 0.565479 0.102296 0.539616 0.5782 0.269992 0.468043 0.371205 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 5
Initial state: 0 0.28558 0.746354 0.604007 0.393106 0.403686 0.437217 0.336286 0.534509 0.107792 0.372678 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 86112 episodes
GETTING ACTION FROM:
action 4, numVisits=86106, meanQ=11.817002, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 0 0.28558 0.746354 0.604007 0.393106 0.403686 0.437217 0.336286 0.534509 0.107792 0.372678 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=9348, meanQ=12.821116, numObservations: 9
action 2, numVisits=6, meanQ=7.831667, numObservations: 5
action 5, numVisits=4, meanQ=6.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 36909 episodes
GETTING ACTION FROM:
action 5, numVisits=36733, meanQ=13.324821, numObservations: 9
action 4, numVisits=9349, meanQ=12.820735, numObservations: 9
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=40, meanQ=-11.960639, numObservations: 8
action -1, numVisits=61, meanQ=-17.762705, numObservations: 48
action 0, numVisits=55, meanQ=-20.203028, numObservations: 38
action 1, numVisits=32, meanQ=-24.945974, numObservations: 9
action: 5
Next state: 2 0.28558 0.746354 0.604007 0.393106 0.403686 0.437217 0.336286 0.534509 0.107792 0.372678 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 6
Initial state: 0 0.681098 0.594901 0.406792 0.361463 0.708835 0.51062 0.862199 0.543709 0.840923 0.539521 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91302 episodes
GETTING ACTION FROM:
action 4, numVisits=91282, meanQ=11.756504, numObservations: 9
action 3, numVisits=8, meanQ=4.880025, numObservations: 6
action 2, numVisits=8, meanQ=4.873750, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.681098 0.594901 0.406792 0.361463 0.708835 0.51062 0.862199 0.543709 0.840923 0.539521 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 7
Initial state: 0 0.419607 0.419625 0.568383 0.309708 0.827669 0.0991919 0.908979 0.192373 0.264805 0.818642 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91272 episodes
GETTING ACTION FROM:
action 2, numVisits=91258, meanQ=11.756925, numObservations: 9
action 4, numVisits=9, meanQ=8.442244, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 2 0.419607 0.419625 0.568383 0.309708 0.827669 0.0991919 0.908979 0.192373 0.264805 0.818642 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 8
Initial state: 0 0.0434122 0.958461 0.421525 0.370712 0.0653558 0.0940122 0.982965 0.093445 0.49403 0.521276 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 90860 episodes
GETTING ACTION FROM:
action 3, numVisits=90824, meanQ=11.832291, numObservations: 9
action 1, numVisits=22, meanQ=7.454545, numObservations: 7
action 4, numVisits=5, meanQ=4.400000, numObservations: 3
action 2, numVisits=4, meanQ=3.000000, numObservations: 3
action 5, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.0434122 0.958461 0.421525 0.370712 0.0653558 0.0940122 0.982965 0.093445 0.49403 0.521276 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=8537, meanQ=12.395209, numObservations: 9
action 5, numVisits=30, meanQ=4.533343, numObservations: 8
action 4, numVisits=4, meanQ=0.752525, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 24883 episodes
GETTING ACTION FROM:
action 2, numVisits=33413, meanQ=12.559004, numObservations: 9
action 5, numVisits=30, meanQ=4.533343, numObservations: 8
action 4, numVisits=4, meanQ=0.752525, numObservations: 3
action 0, numVisits=5, meanQ=-1.010000, numObservations: 5
action -1, numVisits=4, meanQ=-1.257500, numObservations: 4
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.0434122 0.958461 0.421525 0.370712 0.0653558 0.0940122 0.982965 0.093445 0.49403 0.521276 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 9
Initial state: 0 0.164195 0.619668 0.338748 0.601479 0.348346 0.634631 0.621016 0.294681 0.543049 0.432454 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87942 episodes
GETTING ACTION FROM:
action 3, numVisits=87928, meanQ=11.800874, numObservations: 9
action 2, numVisits=7, meanQ=5.857157, numObservations: 5
action 4, numVisits=3, meanQ=5.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.164195 0.619668 0.338748 0.601479 0.348346 0.634631 0.621016 0.294681 0.543049 0.432454 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=9645, meanQ=12.447703, numObservations: 9
action 1, numVisits=5, meanQ=4.598000, numObservations: 4
action 2, numVisits=4, meanQ=1.745000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 34816 episodes
GETTING ACTION FROM:
action 2, numVisits=34787, meanQ=14.269979, numObservations: 9
action 3, numVisits=9646, meanQ=12.447280, numObservations: 9
action 1, numVisits=6, meanQ=1.998333, numObservations: 5
action 0, numVisits=18, meanQ=-1.395000, numObservations: 17
action -1, numVisits=15, meanQ=-1.472000, numObservations: 15
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.164195 0.619668 0.338748 0.601479 0.348346 0.634631 0.621016 0.294681 0.543049 0.432454 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=1631, meanQ=15.595685, numObservations: 9
action -1, numVisits=11, meanQ=-2.131889, numObservations: 10
action 0, numVisits=248, meanQ=-3.954236, numObservations: 83
action 2, numVisits=1, meanQ=-9.561493, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-13.330572, numObservations: 1
action 3, numVisits=1, meanQ=-1069.701800, numObservations: 1
Sampled 32083 episodes
GETTING ACTION FROM:
action 5, numVisits=33714, meanQ=15.760315, numObservations: 9
action -1, numVisits=11, meanQ=-2.131889, numObservations: 10
action 0, numVisits=248, meanQ=-3.954236, numObservations: 83
action 2, numVisits=1, meanQ=-9.561493, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-13.330572, numObservations: 1
action 3, numVisits=1, meanQ=-1069.701800, numObservations: 1
action: 5
Next state: 1 0.164195 0.619668 0.338748 0.601479 0.348346 0.634631 0.621016 0.294681 0.543049 0.432454 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 10
Initial state: 0 0.751952 0.446058 0.738069 0.533409 0.0335928 0.137206 0.468791 0.360134 0.997976 0.0240646 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88469 episodes
GETTING ACTION FROM:
action 2, numVisits=88445, meanQ=11.776421, numObservations: 9
action 5, numVisits=13, meanQ=8.286162, numObservations: 8
action 1, numVisits=7, meanQ=6.857157, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.751952 0.446058 0.738069 0.533409 0.0335928 0.137206 0.468791 0.360134 0.997976 0.0240646 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 11
Initial state: 0 0.955756 0.963564 0.617969 0.00626299 0.462339 0.462065 0.64158 0.585107 0.637958 0.00255299 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 90619 episodes
GETTING ACTION FROM:
action 4, numVisits=90601, meanQ=11.839513, numObservations: 9
action 1, numVisits=13, meanQ=7.463100, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.955756 0.963564 0.617969 0.00626299 0.462339 0.462065 0.64158 0.585107 0.637958 0.00255299 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 12
Initial state: 0 0.544884 0.533239 0.0700487 0.24268 0.494824 0.440527 0.822176 0.780019 0.92329 0.583881 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91237 episodes
GETTING ACTION FROM:
action 4, numVisits=91231, meanQ=11.773171, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.544884 0.533239 0.0700487 0.24268 0.494824 0.440527 0.822176 0.780019 0.92329 0.583881 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 13
Initial state: 0 0.0869635 0.566021 0.469815 0.434362 0.919108 0.636066 0.95226 0.895413 0.756188 0.542846 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89770 episodes
GETTING ACTION FROM:
action 4, numVisits=89761, meanQ=11.754011, numObservations: 9
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.0869635 0.566021 0.469815 0.434362 0.919108 0.636066 0.95226 0.895413 0.756188 0.542846 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 14
Initial state: 0 0.78724 0.587089 0.757191 0.106686 0.328049 0.197334 0.482385 0.358613 0.883913 0.231926 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91274 episodes
GETTING ACTION FROM:
action 4, numVisits=91266, meanQ=11.727252, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.78724 0.587089 0.757191 0.106686 0.328049 0.197334 0.482385 0.358613 0.883913 0.231926 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 15
Initial state: 0 0.0204569 0.650751 0.217679 0.190673 0.0570802 0.224951 0.762971 0.197821 0.438911 0.41061 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 90448 episodes
GETTING ACTION FROM:
action 4, numVisits=90440, meanQ=11.747432, numObservations: 9
action 3, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.0204569 0.650751 0.217679 0.190673 0.0570802 0.224951 0.762971 0.197821 0.438911 0.41061 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 16
Initial state: 0 0.311597 0.456751 0.504798 0.413478 0.946239 0.393803 0.371752 0.0331746 0.455593 0.569751 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91319 episodes
GETTING ACTION FROM:
action 3, numVisits=91306, meanQ=11.904137, numObservations: 9
action 5, numVisits=8, meanQ=7.843750, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.311597 0.456751 0.504798 0.413478 0.946239 0.393803 0.371752 0.0331746 0.455593 0.569751 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 17
Initial state: 0 0.427373 0.418795 0.892411 0.518683 0.118364 0.188909 0.320142 0.887945 0.341925 0.569138 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 90845 episodes
GETTING ACTION FROM:
action 2, numVisits=90835, meanQ=11.668214, numObservations: 9
action 5, numVisits=5, meanQ=4.400000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.427373 0.418795 0.892411 0.518683 0.118364 0.188909 0.320142 0.887945 0.341925 0.569138 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 18
Initial state: 0 0.910331 0.34239 0.497763 0.407951 0.806155 0.0976764 0.762336 0.995442 0.734411 0.0124019 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91459 episodes
GETTING ACTION FROM:
action 5, numVisits=91453, meanQ=11.889070, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.910331 0.34239 0.497763 0.407951 0.806155 0.0976764 0.762336 0.995442 0.734411 0.0124019 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 19
Initial state: 0 0.971479 0.348711 0.807245 0.0376014 0.548417 0.437189 0.0112494 0.909809 0.0680222 0.0459874 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 90818 episodes
GETTING ACTION FROM:
action 3, numVisits=90806, meanQ=11.608255, numObservations: 9
action 1, numVisits=5, meanQ=4.400000, numObservations: 4
action 5, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.971479 0.348711 0.807245 0.0376014 0.548417 0.437189 0.0112494 0.909809 0.0680222 0.0459874 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 20
Initial state: 0 0.619856 0.577691 0.375395 0.410547 0.268538 0.492011 0.667834 0.693632 0.262312 0.591615 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91369 episodes
GETTING ACTION FROM:
action 5, numVisits=91362, meanQ=11.563621, numObservations: 9
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.619856 0.577691 0.375395 0.410547 0.268538 0.492011 0.667834 0.693632 0.262312 0.591615 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=9771, meanQ=12.361431, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 36168 episodes
GETTING ACTION FROM:
action 4, numVisits=45936, meanQ=13.889172, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.619856 0.577691 0.375395 0.410547 0.268538 0.492011 0.667834 0.693632 0.262312 0.591615 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 21
Initial state: 0 0.573501 0.942154 0.774691 0.440947 0.498164 0.377869 0.710089 0.128784 0.053332 0.270279 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 90542 episodes
GETTING ACTION FROM:
action 1, numVisits=90532, meanQ=11.896770, numObservations: 9
action 3, numVisits=5, meanQ=5.998000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.573501 0.942154 0.774691 0.440947 0.498164 0.377869 0.710089 0.128784 0.053332 0.270279 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 22
Initial state: 0 0.587643 0.218877 0.739091 0.739771 0.494372 0.396533 0.76643 0.855753 0.126037 0.311207 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 90738 episodes
GETTING ACTION FROM:
action 1, numVisits=90666, meanQ=11.944416, numObservations: 9
action 2, numVisits=64, meanQ=10.252198, numObservations: 9
action 4, numVisits=4, meanQ=8.250000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.587643 0.218877 0.739091 0.739771 0.494372 0.396533 0.76643 0.855753 0.126037 0.311207 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 23
Initial state: 0 0.452808 0.536224 0.583755 0.930535 0.398291 0.430644 0.996726 0.349578 0.340328 0.46043 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87302 episodes
GETTING ACTION FROM:
action 1, numVisits=87293, meanQ=11.842987, numObservations: 9
action 4, numVisits=4, meanQ=1.250000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.452808 0.536224 0.583755 0.930535 0.398291 0.430644 0.996726 0.349578 0.340328 0.46043 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 24
Initial state: 0 0.4897 0.388629 0.360501 0.656643 0.620376 0.340944 0.254311 0.325353 0.645442 0.625865 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91559 episodes
GETTING ACTION FROM:
action 4, numVisits=91550, meanQ=11.822876, numObservations: 9
action 3, numVisits=4, meanQ=6.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.4897 0.388629 0.360501 0.656643 0.620376 0.340944 0.254311 0.325353 0.645442 0.625865 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=8575, meanQ=12.359317, numObservations: 9
action 5, numVisits=31, meanQ=10.861619, numObservations: 9
action 3, numVisits=22, meanQ=10.771364, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 35938 episodes
GETTING ACTION FROM:
action 2, numVisits=44388, meanQ=11.922460, numObservations: 9
action 3, numVisits=84, meanQ=9.803636, numObservations: 9
action 5, numVisits=90, meanQ=0.191294, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.670000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.4897 0.388629 0.360501 0.656643 0.620376 0.340944 0.254311 0.325353 0.645442 0.625865 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=3302, meanQ=13.278968, numObservations: 9
action 2, numVisits=7, meanQ=9.465714, numObservations: 3
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 37986 episodes
GETTING ACTION FROM:
action 3, numVisits=41284, meanQ=13.535832, numObservations: 9
action 2, numVisits=11, meanQ=8.387273, numObservations: 4
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.4897 0.388629 0.360501 0.656643 0.620376 0.340944 0.254311 0.325353 0.645442 0.625865 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=74, meanQ=6.372661, numObservations: 9
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=286, meanQ=-4.032569, numObservations: 53
action 3, numVisits=3, meanQ=-7.908520, numObservations: 3
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=6, meanQ=-177.825431, numObservations: 4
Sampled 65628 episodes
GETTING ACTION FROM:
action 1, numVisits=65702, meanQ=6.443946, numObservations: 9
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=286, meanQ=-4.032569, numObservations: 53
action 3, numVisits=3, meanQ=-7.908520, numObservations: 3
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=6, meanQ=-177.825431, numObservations: 4
action: 1
Next state: 1 0.4897 0.388629 0.360501 0.656643 0.620376 0.340944 0.254311 0.325353 0.645442 0.625865 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 11.4068
Run # 25
Initial state: 0 0.553257 0.0991668 0.167124 0.253683 0.750098 0.320933 0.217187 0.906321 0.398634 0.38761 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91012 episodes
GETTING ACTION FROM:
action 5, numVisits=90983, meanQ=11.750323, numObservations: 9
action 1, numVisits=24, meanQ=5.422933, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.553257 0.0991668 0.167124 0.253683 0.750098 0.320933 0.217187 0.906321 0.398634 0.38761 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 26
Initial state: 0 0.36537 0.580643 0.804051 0.180537 0.465686 0.436181 0.368586 0.475215 0.115399 0.416087 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89008 episodes
GETTING ACTION FROM:
action 3, numVisits=88979, meanQ=11.824853, numObservations: 9
action 2, numVisits=24, meanQ=9.374592, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.36537 0.580643 0.804051 0.180537 0.465686 0.436181 0.368586 0.475215 0.115399 0.416087 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 27
Initial state: 0 0.0315193 0.707508 0.542353 0.378433 0.432278 0.496753 0.500351 0.237979 0.857174 0.636338 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91059 episodes
GETTING ACTION FROM:
action 3, numVisits=91045, meanQ=11.813371, numObservations: 9
action 5, numVisits=9, meanQ=7.665567, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.0315193 0.707508 0.542353 0.378433 0.432278 0.496753 0.500351 0.237979 0.857174 0.636338 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 28
Initial state: 0 0.810539 0.536036 0.471559 0.386381 0.427751 0.119962 0.837275 0.751461 0.0328153 0.409855 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91264 episodes
GETTING ACTION FROM:
action 4, numVisits=91242, meanQ=11.914187, numObservations: 9
action 2, numVisits=13, meanQ=8.700000, numObservations: 6
action 1, numVisits=3, meanQ=3.000000, numObservations: 3
action 5, numVisits=3, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 1 0.810539 0.536036 0.471559 0.386381 0.427751 0.119962 0.837275 0.751461 0.0328153 0.409855 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 29
Initial state: 0 0.762321 0.346873 0.50955 0.46033 0.761217 0.490842 0.666721 0.0884169 0.661838 0.149366 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87102 episodes
GETTING ACTION FROM:
action 3, numVisits=87094, meanQ=11.893283, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.762321 0.346873 0.50955 0.46033 0.761217 0.490842 0.666721 0.0884169 0.661838 0.149366 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 30
Initial state: 0 0.975088 0.749505 0.239716 0.084145 0.82611 0.253344 0.502471 0.385541 0.881848 0.212305 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91198 episodes
GETTING ACTION FROM:
action 4, numVisits=91192, meanQ=11.873877, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.975088 0.749505 0.239716 0.084145 0.82611 0.253344 0.502471 0.385541 0.881848 0.212305 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 31
Initial state: 0 0.641837 0.503837 0.250994 0.784646 0.440691 0.387093 0.406718 0.0639769 0.0888648 0.8423 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 90613 episodes
GETTING ACTION FROM:
action 5, numVisits=90605, meanQ=11.663580, numObservations: 9
action 3, numVisits=3, meanQ=5.663333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 5
Next state: 0 0.641837 0.503837 0.250994 0.784646 0.440691 0.387093 0.406718 0.0639769 0.0888648 0.8423 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=9899, meanQ=12.653317, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 34723 episodes
GETTING ACTION FROM:
action 4, numVisits=44620, meanQ=13.096908, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.641837 0.503837 0.250994 0.784646 0.440691 0.387093 0.406718 0.0639769 0.0888648 0.8423 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=453, meanQ=8.580758, numObservations: 9
action 3, numVisits=6, meanQ=2.210787, numObservations: 5
action -1, numVisits=12, meanQ=-1.341650, numObservations: 10
action 0, numVisits=10, meanQ=-2.076005, numObservations: 9
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 41319 episodes
GETTING ACTION FROM:
action 1, numVisits=41771, meanQ=9.680277, numObservations: 9
action 3, numVisits=6, meanQ=2.210787, numObservations: 5
action -1, numVisits=12, meanQ=-1.341650, numObservations: 10
action 0, numVisits=10, meanQ=-2.076005, numObservations: 9
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.641837 0.503837 0.250994 0.784646 0.440691 0.387093 0.406718 0.0639769 0.0888648 0.8423 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 32
Initial state: 0 0.511188 0.47932 0.866218 0.622891 0.152212 0.324661 0.747582 0.0994277 0.161815 0.755425 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 90475 episodes
GETTING ACTION FROM:
action 2, numVisits=90467, meanQ=11.798068, numObservations: 9
action 1, numVisits=3, meanQ=5.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.511188 0.47932 0.866218 0.622891 0.152212 0.324661 0.747582 0.0994277 0.161815 0.755425 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 33
Initial state: 0 0.692445 0.0389443 0.368032 0.235264 0.423406 0.374654 0.884809 0.210357 0.331071 0.362194 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87398 episodes
GETTING ACTION FROM:
action 5, numVisits=87390, meanQ=11.758342, numObservations: 9
action 4, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.692445 0.0389443 0.368032 0.235264 0.423406 0.374654 0.884809 0.210357 0.331071 0.362194 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=2119, meanQ=12.696301, numObservations: 9
action 3, numVisits=23, meanQ=8.911309, numObservations: 8
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action 4, numVisits=5, meanQ=4.598000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 27317 episodes
GETTING ACTION FROM:
action 2, numVisits=29421, meanQ=13.627808, numObservations: 9
action 3, numVisits=23, meanQ=8.911309, numObservations: 8
action 4, numVisits=5, meanQ=4.598000, numObservations: 3
action 1, numVisits=5, meanQ=3.000000, numObservations: 3
action 0, numVisits=7, meanQ=-1.292857, numObservations: 7
action -1, numVisits=7, meanQ=-1.434286, numObservations: 7
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.692445 0.0389443 0.368032 0.235264 0.423406 0.374654 0.884809 0.210357 0.331071 0.362194 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=1644, meanQ=15.408729, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 22363 episodes
GETTING ACTION FROM:
action 4, numVisits=24005, meanQ=14.536068, numObservations: 9
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action -1, numVisits=3, meanQ=-1.340000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 2 0.692445 0.0389443 0.368032 0.235264 0.423406 0.374654 0.884809 0.210357 0.331071 0.362194 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -18.7411
Run # 34
Initial state: 0 0.651077 0.166473 0.0860159 0.773708 0.417386 0.413985 0.551904 0.0655249 0.235698 0.299119 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91557 episodes
GETTING ACTION FROM:
action 2, numVisits=91550, meanQ=11.766031, numObservations: 9
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.651077 0.166473 0.0860159 0.773708 0.417386 0.413985 0.551904 0.0655249 0.235698 0.299119 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=9856, meanQ=12.971037, numObservations: 9
action 4, numVisits=19, meanQ=4.775263, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 29420 episodes
GETTING ACTION FROM:
action 1, numVisits=39216, meanQ=13.756684, numObservations: 9
action 4, numVisits=19, meanQ=4.775263, numObservations: 9
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=58, meanQ=-5.477502, numObservations: 8
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.651077 0.166473 0.0860159 0.773708 0.417386 0.413985 0.551904 0.0655249 0.235698 0.299119 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 35
Initial state: 0 0.426155 0.0696733 0.265346 0.737638 0.535804 0.441708 0.1819 0.479375 0.587434 0.530102 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87044 episodes
GETTING ACTION FROM:
action 2, numVisits=87007, meanQ=11.711374, numObservations: 9
action 1, numVisits=32, meanQ=8.882188, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.426155 0.0696733 0.265346 0.737638 0.535804 0.441708 0.1819 0.479375 0.587434 0.530102 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=9403, meanQ=12.832854, numObservations: 9
action 3, numVisits=12, meanQ=6.250850, numObservations: 7
action 1, numVisits=3, meanQ=4.670033, numObservations: 2
action 4, numVisits=5, meanQ=3.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 35736 episodes
GETTING ACTION FROM:
action 3, numVisits=35631, meanQ=13.515098, numObservations: 9
action 2, numVisits=9404, meanQ=12.832423, numObservations: 9
action 4, numVisits=5, meanQ=3.000000, numObservations: 4
action -1, numVisits=26, meanQ=-0.286538, numObservations: 24
action 1, numVisits=60, meanQ=-4.716932, numObservations: 9
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=35, meanQ=-30.252964, numObservations: 31
action: 3
Next state: 1 0.426155 0.0696733 0.265346 0.737638 0.535804 0.441708 0.1819 0.479375 0.587434 0.530102 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 36
Initial state: 0 0.430978 0.321732 0.0671573 0.56549 0.381306 0.460464 0.664068 0.71256 0.823812 0.056996 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91091 episodes
GETTING ACTION FROM:
action 3, numVisits=89711, meanQ=11.815895, numObservations: 9
action 4, numVisits=1375, meanQ=11.573787, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.430978 0.321732 0.0671573 0.56549 0.381306 0.460464 0.664068 0.71256 0.823812 0.056996 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 37
Initial state: 0 0.750167 0.0211359 0.541645 0.464006 0.175775 0.194686 0.228329 0.733694 0.70614 0.13385 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 90649 episodes
GETTING ACTION FROM:
action 3, numVisits=90643, meanQ=11.754385, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.750167 0.0211359 0.541645 0.464006 0.175775 0.194686 0.228329 0.733694 0.70614 0.13385 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=8402, meanQ=12.669809, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 25962 episodes
GETTING ACTION FROM:
action 5, numVisits=34346, meanQ=12.513922, numObservations: 9
action 1, numVisits=4, meanQ=-0.252500, numObservations: 3
action -1, numVisits=4, meanQ=-1.257500, numObservations: 4
action 0, numVisits=4, meanQ=-1.505000, numObservations: 4
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=10, meanQ=-98.365717, numObservations: 7
action: 5
Next state: 2 0.750167 0.0211359 0.541645 0.464006 0.175775 0.194686 0.228329 0.733694 0.70614 0.13385 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 38
Initial state: 0 0.430677 0.44017 0.353985 0.448086 0.0569044 0.943999 0.349791 0.307958 0.344968 0.752163 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91055 episodes
GETTING ACTION FROM:
action 3, numVisits=91041, meanQ=11.947082, numObservations: 9
action 5, numVisits=5, meanQ=5.800000, numObservations: 3
action 4, numVisits=3, meanQ=5.333333, numObservations: 3
action 2, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.430677 0.44017 0.353985 0.448086 0.0569044 0.943999 0.349791 0.307958 0.344968 0.752163 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=10110, meanQ=13.085668, numObservations: 9
action 4, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 37222 episodes
GETTING ACTION FROM:
action 2, numVisits=47320, meanQ=13.569637, numObservations: 9
action 4, numVisits=10, meanQ=7.146492, numObservations: 5
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.430677 0.44017 0.353985 0.448086 0.0569044 0.943999 0.349791 0.307958 0.344968 0.752163 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 39
Initial state: 0 0.473081 0.463423 0.596839 0.256655 0.613578 0.578595 0.998876 0.0838537 0.851778 0.188347 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 85138 episodes
GETTING ACTION FROM:
action 2, numVisits=85116, meanQ=11.783608, numObservations: 9
action 3, numVisits=17, meanQ=7.704118, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.473081 0.463423 0.596839 0.256655 0.613578 0.578595 0.998876 0.0838537 0.851778 0.188347 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 40
Initial state: 0 0.826765 0.870222 0.604575 0.956218 0.674299 0.567411 0.548664 0.405632 0.788347 0.451375 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91014 episodes
GETTING ACTION FROM:
action 2, numVisits=91006, meanQ=11.891732, numObservations: 9
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.826765 0.870222 0.604575 0.956218 0.674299 0.567411 0.548664 0.405632 0.788347 0.451375 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 41
Initial state: 0 0.474808 0.474847 0.300679 0.165883 0.261659 0.853242 0.0419797 0.999214 0.412969 0.951741 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 90263 episodes
GETTING ACTION FROM:
action 4, numVisits=90255, meanQ=11.821291, numObservations: 9
action 1, numVisits=3, meanQ=5.663333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.474808 0.474847 0.300679 0.165883 0.261659 0.853242 0.0419797 0.999214 0.412969 0.951741 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=9828, meanQ=12.894405, numObservations: 9
action 3, numVisits=21, meanQ=9.760952, numObservations: 8
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 30728 episodes
GETTING ACTION FROM:
action 5, numVisits=40471, meanQ=13.858585, numObservations: 9
action 2, numVisits=65, meanQ=11.244792, numObservations: 9
action 3, numVisits=21, meanQ=9.760952, numObservations: 8
action 1, numVisits=20, meanQ=9.600005, numObservations: 8
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.340000, numObservations: 3
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 1 0.474808 0.474847 0.300679 0.165883 0.261659 0.853242 0.0419797 0.999214 0.412969 0.951741 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 42
Initial state: 0 0.78322 0.350022 0.447334 0.281161 0.49858 0.36499 0.951309 0.568072 0.905399 0.711832 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 90679 episodes
GETTING ACTION FROM:
action 2, numVisits=90665, meanQ=11.859508, numObservations: 9
action 3, numVisits=8, meanQ=9.372500, numObservations: 7
action 4, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.78322 0.350022 0.447334 0.281161 0.49858 0.36499 0.951309 0.568072 0.905399 0.711832 w: 1
Observation: 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 43
Initial state: 0 0.0989324 0.0843061 0.570262 0.634863 0.940761 0.327493 0.951653 0.180906 0.44889 0.425318 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 90327 episodes
GETTING ACTION FROM:
action 3, numVisits=90307, meanQ=11.749615, numObservations: 9
action 5, numVisits=10, meanQ=8.098000, numObservations: 7
action 1, numVisits=6, meanQ=6.500000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.0989324 0.0843061 0.570262 0.634863 0.940761 0.327493 0.951653 0.180906 0.44889 0.425318 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 44
Initial state: 0 0.543301 0.370598 0.986983 0.322568 0.386489 0.899038 0.384808 0.130228 0.780172 0.107392 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91433 episodes
GETTING ACTION FROM:
action 1, numVisits=91427, meanQ=11.683549, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.543301 0.370598 0.986983 0.322568 0.386489 0.899038 0.384808 0.130228 0.780172 0.107392 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 45
Initial state: 0 0.245308 0.192615 0.285346 0.876972 0.51251 0.451169 0.406936 0.663807 0.232134 0.536329 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 90483 episodes
GETTING ACTION FROM:
action 4, numVisits=90466, meanQ=11.808222, numObservations: 9
action 5, numVisits=9, meanQ=3.000000, numObservations: 7
action 1, numVisits=4, meanQ=1.250000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 2 0.245308 0.192615 0.285346 0.876972 0.51251 0.451169 0.406936 0.663807 0.232134 0.536329 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 46
Initial state: 0 0.408608 0.410683 0.365153 0.935994 0.328919 0.373751 0.470744 0.845943 0.889892 0.525332 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 85944 episodes
GETTING ACTION FROM:
action 5, numVisits=85934, meanQ=11.900871, numObservations: 9
action 4, numVisits=5, meanQ=4.400000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.408608 0.410683 0.365153 0.935994 0.328919 0.373751 0.470744 0.845943 0.889892 0.525332 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 47
Initial state: 0 0.727054 0.350289 0.94575 0.678981 0.94676 0.276416 0.6757 0.875574 0.515938 0.429349 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 90553 episodes
GETTING ACTION FROM:
action 1, numVisits=90531, meanQ=11.744285, numObservations: 9
action 3, numVisits=14, meanQ=9.681436, numObservations: 7
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action 5, numVisits=3, meanQ=5.663333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.727054 0.350289 0.94575 0.678981 0.94676 0.276416 0.6757 0.875574 0.515938 0.429349 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 48
Initial state: 0 0.420592 0.416746 0.637712 0.333344 0.0758286 0.241232 0.676591 0.810434 0.413673 0.917768 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91536 episodes
GETTING ACTION FROM:
action 1, numVisits=91510, meanQ=11.825354, numObservations: 9
action 2, numVisits=15, meanQ=8.784000, numObservations: 8
action 3, numVisits=6, meanQ=7.666667, numObservations: 5
action 4, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.420592 0.416746 0.637712 0.333344 0.0758286 0.241232 0.676591 0.810434 0.413673 0.917768 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 49
Initial state: 0 0.471273 0.3474 0.862049 0.0107114 0.607305 0.579431 0.418978 0.480148 0.725117 0.298141 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89959 episodes
GETTING ACTION FROM:
action 5, numVisits=89949, meanQ=11.971647, numObservations: 9
action 3, numVisits=3, meanQ=3.000000, numObservations: 3
action 4, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.471273 0.3474 0.862049 0.0107114 0.607305 0.579431 0.418978 0.480148 0.725117 0.298141 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 50
Initial state: 0 0.751644 0.0113704 0.213962 0.271245 0.46546 0.437175 0.631935 0.987086 0.0772431 0.536364 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91486 episodes
GETTING ACTION FROM:
action 4, numVisits=91478, meanQ=11.893854, numObservations: 9
action 1, numVisits=3, meanQ=5.663333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 1 0.751644 0.0113704 0.213962 0.271245 0.46546 0.437175 0.631935 0.987086 0.0772431 0.536364 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
[32m ProblemEnvironment.hpp 351: Done.[39m
