Run # 1
Initial state: 0 0.805779 0.210652 0.820676 0.606671 0.661444 0.49874 0.380627 0.900736 0.375536 0.561477 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 93579 episodes
GETTING ACTION FROM:
action 3, numVisits=93570, meanQ=6.881396, numObservations: 9
action 5, numVisits=4, meanQ=1.250000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.805779 0.210652 0.820676 0.606671 0.661444 0.49874 0.380627 0.900736 0.375536 0.561477 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=3150, meanQ=8.524100, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 90334 episodes
GETTING ACTION FROM:
action 4, numVisits=92914, meanQ=4.110136, numObservations: 9
action -1, numVisits=302, meanQ=-1.950926, numObservations: 103
action 0, numVisits=269, meanQ=-5.636123, numObservations: 107
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.805779 0.210652 0.820676 0.606671 0.661444 0.49874 0.380627 0.900736 0.375536 0.561477 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 2
Initial state: 0 0.395435 0.619632 0.924617 0.443613 0.578192 0.404312 0.723478 0.235401 0.99086 0.944597 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 90128 episodes
GETTING ACTION FROM:
action 1, numVisits=90117, meanQ=6.416710, numObservations: 9
action 4, numVisits=6, meanQ=3.000000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.395435 0.619632 0.924617 0.443613 0.578192 0.404312 0.723478 0.235401 0.99086 0.944597 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 3
Initial state: 0 0.74126 0.728505 0.583185 0.0625788 0.462074 0.868603 0.536417 0.337879 0.33338 0.573787 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95499 episodes
GETTING ACTION FROM:
action 2, numVisits=95490, meanQ=6.885685, numObservations: 9
action 3, numVisits=4, meanQ=-0.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.74126 0.728505 0.583185 0.0625788 0.462074 0.868603 0.536417 0.337879 0.33338 0.573787 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 4
Initial state: 0 0.593387 0.109093 0.0351202 0.430645 0.334042 0.621782 0.530178 0.805607 0.411896 0.906128 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95837 episodes
GETTING ACTION FROM:
action 5, numVisits=95708, meanQ=6.998534, numObservations: 9
action 1, numVisits=120, meanQ=5.635431, numObservations: 9
action 2, numVisits=5, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.593387 0.109093 0.0351202 0.430645 0.334042 0.621782 0.530178 0.805607 0.411896 0.906128 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 5
Initial state: 0 0.516265 0.0127709 0.593935 0.291396 0.474441 0.181645 0.52049 0.971527 0.413124 0.580399 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87540 episodes
GETTING ACTION FROM:
action 1, numVisits=87534, meanQ=6.432139, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.516265 0.0127709 0.593935 0.291396 0.474441 0.181645 0.52049 0.971527 0.413124 0.580399 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=2764, meanQ=7.513089, numObservations: 9
action 4, numVisits=4, meanQ=-0.252500, numObservations: 3
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 91130 episodes
GETTING ACTION FROM:
action 3, numVisits=93770, meanQ=4.215525, numObservations: 9
action 2, numVisits=18, meanQ=1.110556, numObservations: 6
action 0, numVisits=55, meanQ=-1.838000, numObservations: 33
action -1, numVisits=54, meanQ=-1.966982, numObservations: 39
action 4, numVisits=5, meanQ=-2.402000, numObservations: 4
action 1, numVisits=2, meanQ=-7.005000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.516265 0.0127709 0.593935 0.291396 0.474441 0.181645 0.52049 0.971527 0.413124 0.580399 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 6
Initial state: 0 0.329665 0.538371 0.884295 0.296665 0.441539 0.669685 0.156054 0.754711 0.752223 0.993178 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 93860 episodes
GETTING ACTION FROM:
action 1, numVisits=93842, meanQ=6.814119, numObservations: 9
action 2, numVisits=9, meanQ=3.454456, numObservations: 5
action 3, numVisits=5, meanQ=3.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.329665 0.538371 0.884295 0.296665 0.441539 0.669685 0.156054 0.754711 0.752223 0.993178 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 7
Initial state: 0 0.636793 0.100875 0.334323 0.890907 0.256769 0.0335934 0.372122 0.603207 0.128063 0.857172 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 93456 episodes
GETTING ACTION FROM:
action 5, numVisits=93377, meanQ=6.795920, numObservations: 9
action 0, numVisits=46, meanQ=-1.376300, numObservations: 40
action -1, numVisits=22, meanQ=-1.550000, numObservations: 21
action 2, numVisits=5, meanQ=-3.448000, numObservations: 4
action 1, numVisits=2, meanQ=-4.000000, numObservations: 2
action 3, numVisits=2, meanQ=-7.500000, numObservations: 2
action 4, numVisits=2, meanQ=-7.500000, numObservations: 2
action: 5
Next state: 0 0.636793 0.100875 0.334323 0.890907 0.256769 0.0335934 0.372122 0.603207 0.128063 0.857172 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=4355, meanQ=7.998824, numObservations: 9
action 4, numVisits=6, meanQ=3.330000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 38371 episodes
GETTING ACTION FROM:
action 2, numVisits=42702, meanQ=9.433005, numObservations: 9
action 5, numVisits=9, meanQ=4.233333, numObservations: 6
action 4, numVisits=7, meanQ=1.614442, numObservations: 5
action 1, numVisits=5, meanQ=0.398000, numObservations: 5
action -1, numVisits=7, meanQ=-1.292857, numObservations: 7
action 0, numVisits=6, meanQ=-1.505000, numObservations: 6
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.636793 0.100875 0.334323 0.890907 0.256769 0.0335934 0.372122 0.603207 0.128063 0.857172 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 8
Initial state: 0 0.0860431 0.106946 0.746569 0.384232 0.826161 0.56754 0.364117 0.589617 0.237098 0.595167 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95221 episodes
GETTING ACTION FROM:
action 1, numVisits=95215, meanQ=6.912444, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.0860431 0.106946 0.746569 0.384232 0.826161 0.56754 0.364117 0.589617 0.237098 0.595167 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=9875, meanQ=8.029487, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 22404 episodes
GETTING ACTION FROM:
action 4, numVisits=32246, meanQ=7.457694, numObservations: 9
action -1, numVisits=28, meanQ=-1.230702, numObservations: 24
action 0, numVisits=6, meanQ=-2.990000, numObservations: 5
action 3, numVisits=2, meanQ=-7.005000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.0860431 0.106946 0.746569 0.384232 0.826161 0.56754 0.364117 0.589617 0.237098 0.595167 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 9
Initial state: 0 0.226247 0.210604 0.58031 0.938254 0.274178 0.996656 0.795568 0.862536 0.428643 0.676769 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95480 episodes
GETTING ACTION FROM:
action 1, numVisits=95474, meanQ=6.752186, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.226247 0.210604 0.58031 0.938254 0.274178 0.996656 0.795568 0.862536 0.428643 0.676769 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=613, meanQ=11.645652, numObservations: 9
action 4, numVisits=11, meanQ=4.909091, numObservations: 5
action 2, numVisits=11, meanQ=4.632727, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 79546 episodes
GETTING ACTION FROM:
action 1, numVisits=627, meanQ=11.834710, numObservations: 9
action 3, numVisits=79516, meanQ=8.904033, numObservations: 9
action 4, numVisits=11, meanQ=4.909091, numObservations: 5
action 2, numVisits=11, meanQ=4.632727, numObservations: 5
action 0, numVisits=10, meanQ=-1.703000, numObservations: 9
action -1, numVisits=9, meanQ=-1.890000, numObservations: 9
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.226247 0.210604 0.58031 0.938254 0.274178 0.996656 0.795568 0.862536 0.428643 0.676769 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 10
Initial state: 0 0.620397 0.950859 0.452682 0.99373 0.415032 0.568195 0.0344912 0.98697 0.14597 0.25134 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95395 episodes
GETTING ACTION FROM:
action 4, numVisits=95356, meanQ=6.942309, numObservations: 9
action 2, numVisits=25, meanQ=5.319600, numObservations: 8
action 5, numVisits=10, meanQ=3.700000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.620397 0.950859 0.452682 0.99373 0.415032 0.568195 0.0344912 0.98697 0.14597 0.25134 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=4392, meanQ=8.442948, numObservations: 9
action 2, numVisits=4, meanQ=3.742500, numObservations: 4
action 3, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 39417 episodes
GETTING ACTION FROM:
action 5, numVisits=43776, meanQ=9.116350, numObservations: 9
action 2, numVisits=16, meanQ=3.623125, numObservations: 7
action 3, numVisits=3, meanQ=0.666667, numObservations: 3
action 0, numVisits=13, meanQ=-1.162308, numObservations: 12
action -1, numVisits=9, meanQ=-1.671100, numObservations: 7
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 5
Next state: 0 0.620397 0.950859 0.452682 0.99373 0.415032 0.568195 0.0344912 0.98697 0.14597 0.25134 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=2770, meanQ=10.495918, numObservations: 9
action 2, numVisits=4, meanQ=0.752525, numObservations: 3
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 50938 episodes
GETTING ACTION FROM:
action 1, numVisits=53699, meanQ=8.459683, numObservations: 9
action 2, numVisits=4, meanQ=0.752525, numObservations: 3
action -1, numVisits=8, meanQ=-1.133750, numObservations: 8
action 0, numVisits=7, meanQ=-1.292857, numObservations: 6
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.620397 0.950859 0.452682 0.99373 0.415032 0.568195 0.0344912 0.98697 0.14597 0.25134 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 11
Initial state: 0 0.412322 0.578871 0.326751 0.506733 0.963021 0.684094 0.225648 0.160475 0.837153 0.779713 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95800 episodes
GETTING ACTION FROM:
action 5, numVisits=95716, meanQ=7.001063, numObservations: 9
action 2, numVisits=79, meanQ=3.614319, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.412322 0.578871 0.326751 0.506733 0.963021 0.684094 0.225648 0.160475 0.837153 0.779713 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 12
Initial state: 0 0.316571 0.657386 0.0447262 0.78058 0.131851 0.273394 0.592384 0.184057 0.724816 0.0906227 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 94906 episodes
GETTING ACTION FROM:
action 4, numVisits=94898, meanQ=6.829913, numObservations: 9
action 3, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.316571 0.657386 0.0447262 0.78058 0.131851 0.273394 0.592384 0.184057 0.724816 0.0906227 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 13
Initial state: 0 0.278087 0.24878 0.586645 0.820358 0.423054 0.639416 0.2873 0.267969 0.900101 0.0160906 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95662 episodes
GETTING ACTION FROM:
action 3, numVisits=95656, meanQ=6.900170, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.278087 0.24878 0.586645 0.820358 0.423054 0.639416 0.2873 0.267969 0.900101 0.0160906 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 14
Initial state: 0 0.430578 0.661994 0.121317 0.763355 0.322192 0.564159 0.00836696 0.910241 0.0695196 0.506184 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88879 episodes
GETTING ACTION FROM:
action 4, numVisits=88873, meanQ=6.155637, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.430578 0.661994 0.121317 0.763355 0.322192 0.564159 0.00836696 0.910241 0.0695196 0.506184 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=4122, meanQ=9.686781, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 36064 episodes
GETTING ACTION FROM:
action 2, numVisits=35958, meanQ=10.277002, numObservations: 9
action 4, numVisits=4124, meanQ=9.689135, numObservations: 9
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=70, meanQ=-14.312961, numObservations: 50
action 0, numVisits=37, meanQ=-28.183417, numObservations: 30
action: 2
Next state: 0 0.430578 0.661994 0.121317 0.763355 0.322192 0.564159 0.00836696 0.910241 0.0695196 0.506184 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action -1, numVisits=1360, meanQ=4.773912, numObservations: 141
action 5, numVisits=23, meanQ=1.061587, numObservations: 6
action 2, numVisits=1, meanQ=-10.060861, numObservations: 1
action 0, numVisits=73, meanQ=-12.603450, numObservations: 37
action 1, numVisits=41, meanQ=-14.897151, numObservations: 9
action 3, numVisits=18, meanQ=-45.661692, numObservations: 6
action 4, numVisits=1, meanQ=-1068.554012, numObservations: 1
Sampled 9279 episodes
GETTING ACTION FROM:
action -1, numVisits=10639, meanQ=4.172591, numObservations: 227
action 5, numVisits=23, meanQ=1.061587, numObservations: 6
action 2, numVisits=1, meanQ=-10.060861, numObservations: 1
action 0, numVisits=73, meanQ=-12.603450, numObservations: 37
action 1, numVisits=41, meanQ=-14.897151, numObservations: 9
action 3, numVisits=18, meanQ=-45.661692, numObservations: 6
action 4, numVisits=1, meanQ=-1068.554012, numObservations: 1
action: -1
Next state: 0 0.430578 0.661994 0.121317 0.763355 0.322192 0.564159 0.00836696 0.910241 0.0695196 0.506184 w: 1
Observation: 0 3 0 3 0 2 0 1 0 1 0 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=1, meanQ=24.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-8.636829, numObservations: 1
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 125984 episodes
GETTING ACTION FROM:
action 3, numVisits=125928, meanQ=23.354934, numObservations: 9
action 4, numVisits=30, meanQ=21.900000, numObservations: 6
action 2, numVisits=24, meanQ=21.375000, numObservations: 5
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-2.000000, numObservations: 1
action 5, numVisits=1, meanQ=-8.636829, numObservations: 1
action: 3
Next state: 1 0.430578 0.661994 0.121317 0.763355 0.322192 0.564159 0.00836696 0.910241 0.0695196 0.506184 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 13.367
Run # 15
Initial state: 0 0.888248 0.803573 0.0972095 0.677258 0.250351 0.512006 0.342111 0.690034 0.789848 0.300279 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95357 episodes
GETTING ACTION FROM:
action 4, numVisits=95348, meanQ=7.013902, numObservations: 9
action 5, numVisits=4, meanQ=1.250000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 1 0.888248 0.803573 0.0972095 0.677258 0.250351 0.512006 0.342111 0.690034 0.789848 0.300279 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 16
Initial state: 0 0.0903271 0.171813 0.979484 0.134295 0.408102 0.565256 0.116027 0.235797 0.608317 0.189118 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95565 episodes
GETTING ACTION FROM:
action 5, numVisits=95554, meanQ=6.879658, numObservations: 9
action 1, numVisits=6, meanQ=1.833333, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.0903271 0.171813 0.979484 0.134295 0.408102 0.565256 0.116027 0.235797 0.608317 0.189118 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 17
Initial state: 0 0.705445 0.0451042 0.217168 0.275732 0.161026 0.16629 0.180396 0.984286 0.299046 0.607405 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95915 episodes
GETTING ACTION FROM:
action 2, numVisits=95856, meanQ=6.943348, numObservations: 9
action 1, numVisits=52, meanQ=3.432310, numObservations: 8
action 4, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.705445 0.0451042 0.217168 0.275732 0.161026 0.16629 0.180396 0.984286 0.299046 0.607405 w: 1
Observation: 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=1798, meanQ=8.740365, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 54813 episodes
GETTING ACTION FROM:
action 1, numVisits=46114, meanQ=6.804737, numObservations: 9
action 3, numVisits=10060, meanQ=5.957811, numObservations: 9
action 0, numVisits=299, meanQ=-5.484178, numObservations: 115
action -1, numVisits=141, meanQ=-8.528928, numObservations: 95
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.705445 0.0451042 0.217168 0.275732 0.161026 0.16629 0.180396 0.984286 0.299046 0.607405 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 18
Initial state: 0 0.617716 0.0202489 0.717386 0.749761 0.0322551 0.532427 0.915338 0.895187 0.416003 0.692068 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 93452 episodes
GETTING ACTION FROM:
action 3, numVisits=93443, meanQ=6.820090, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=4, meanQ=-1.225000, numObservations: 2
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.617716 0.0202489 0.717386 0.749761 0.0322551 0.532427 0.915338 0.895187 0.416003 0.692068 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=2172, meanQ=8.210261, numObservations: 9
action 1, numVisits=3, meanQ=0.666667, numObservations: 2
action 5, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 29677 episodes
GETTING ACTION FROM:
action 2, numVisits=31744, meanQ=7.906475, numObservations: 9
action 1, numVisits=6, meanQ=0.666667, numObservations: 4
action 5, numVisits=4, meanQ=-2.250000, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=2, meanQ=-7.005000, numObservations: 2
action 0, numVisits=69, meanQ=-16.968586, numObservations: 56
action -1, numVisits=33, meanQ=-31.905209, numObservations: 28
action: 2
Next state: 1 0.617716 0.0202489 0.717386 0.749761 0.0322551 0.532427 0.915338 0.895187 0.416003 0.692068 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 19
Initial state: 0 0.169517 0.0247161 0.0294313 0.375846 0.397145 0.543096 0.647982 0.730782 0.786415 0.518519 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 50199 episodes
GETTING ACTION FROM:
action -1, numVisits=50108, meanQ=12.539709, numObservations: 243
action 0, numVisits=85, meanQ=-0.580340, numObservations: 65
action 3, numVisits=2, meanQ=-7.500000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.169517 0.0247161 0.0294313 0.375846 0.397145 0.543096 0.647982 0.730782 0.786415 0.518519 w: 1
Observation: 0 1 0 1 0 2 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=289, meanQ=19.892580, numObservations: 9
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action 5, numVisits=5, meanQ=10.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 114406 episodes
GETTING ACTION FROM:
action 3, numVisits=114695, meanQ=21.777035, numObservations: 9
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action 5, numVisits=5, meanQ=10.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.169517 0.0247161 0.0294313 0.375846 0.397145 0.543096 0.647982 0.730782 0.786415 0.518519 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=7271, meanQ=22.950605, numObservations: 9
action 2, numVisits=3, meanQ=12.333333, numObservations: 3
action 5, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 84298 episodes
GETTING ACTION FROM:
action 3, numVisits=7375, meanQ=22.959829, numObservations: 9
action 2, numVisits=84188, meanQ=17.640266, numObservations: 9
action 5, numVisits=5, meanQ=3.000000, numObservations: 3
action -1, numVisits=4, meanQ=-1.752500, numObservations: 4
action 0, numVisits=4, meanQ=-1.752500, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.169517 0.0247161 0.0294313 0.375846 0.397145 0.543096 0.647982 0.730782 0.786415 0.518519 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 17.5624
Run # 20
Initial state: 0 0.353836 0.683933 0.58394 0.039012 0.582418 0.781369 0.173998 0.157404 0.0185518 0.247988 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 94864 episodes
GETTING ACTION FROM:
action 4, numVisits=94819, meanQ=6.875009, numObservations: 9
action 0, numVisits=15, meanQ=-1.142660, numObservations: 14
action 5, numVisits=9, meanQ=-1.551089, numObservations: 4
action -1, numVisits=17, meanQ=-1.708824, numObservations: 16
action 1, numVisits=2, meanQ=-7.500000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.353836 0.683933 0.58394 0.039012 0.582418 0.781369 0.173998 0.157404 0.0185518 0.247988 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=3025, meanQ=8.400106, numObservations: 9
action 1, numVisits=11, meanQ=-0.355455, numObservations: 7
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 92498 episodes
GETTING ACTION FROM:
action 5, numVisits=95389, meanQ=4.814424, numObservations: 9
action 3, numVisits=46, meanQ=2.869348, numObservations: 9
action 1, numVisits=11, meanQ=-0.355455, numObservations: 7
action 0, numVisits=48, meanQ=-1.835000, numObservations: 32
action -1, numVisits=45, meanQ=-1.868000, numObservations: 32
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.353836 0.683933 0.58394 0.039012 0.582418 0.781369 0.173998 0.157404 0.0185518 0.247988 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=580, meanQ=9.322029, numObservations: 9
action -1, numVisits=6, meanQ=-1.010000, numObservations: 6
action 0, numVisits=6, meanQ=-1.010000, numObservations: 6
action 3, numVisits=4, meanQ=-2.250000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 34859 episodes
GETTING ACTION FROM:
action 5, numVisits=584, meanQ=9.201356, numObservations: 9
action 0, numVisits=34837, meanQ=-0.736655, numObservations: 241
action 3, numVisits=5, meanQ=-4.000000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=29, meanQ=-20.079582, numObservations: 23
action: 5
Next state: 0 0.353836 0.683933 0.58394 0.039012 0.582418 0.781369 0.173998 0.157404 0.0185518 0.247988 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=52, meanQ=5.671018, numObservations: 9
action 5, numVisits=6, meanQ=0.828367, numObservations: 3
action -1, numVisits=6, meanQ=-2.990000, numObservations: 5
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=8, meanQ=-133.132408, numObservations: 7
Sampled 96661 episodes
GETTING ACTION FROM:
action 3, numVisits=96713, meanQ=6.873411, numObservations: 9
action 5, numVisits=6, meanQ=0.828367, numObservations: 3
action -1, numVisits=6, meanQ=-2.990000, numObservations: 5
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=8, meanQ=-133.132408, numObservations: 7
action: 3
Next state: 1 0.353836 0.683933 0.58394 0.039012 0.582418 0.781369 0.173998 0.157404 0.0185518 0.247988 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 11.4068
Run # 21
Initial state: 0 0.73529 0.49705 0.327767 0.57896 0.0137224 0.44198 0.198046 0.269677 0.822528 0.588342 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95352 episodes
GETTING ACTION FROM:
action 4, numVisits=95338, meanQ=6.790996, numObservations: 9
action 2, numVisits=7, meanQ=0.000000, numObservations: 6
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.73529 0.49705 0.327767 0.57896 0.0137224 0.44198 0.198046 0.269677 0.822528 0.588342 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=10191, meanQ=8.185775, numObservations: 9
action 1, numVisits=12, meanQ=0.251692, numObservations: 5
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 32658 episodes
GETTING ACTION FROM:
action 3, numVisits=42838, meanQ=7.849154, numObservations: 9
action 1, numVisits=12, meanQ=0.251692, numObservations: 5
action -1, numVisits=8, meanQ=-2.495000, numObservations: 7
action 5, numVisits=2, meanQ=-3.505000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=8, meanQ=-132.679139, numObservations: 7
action: 3
Next state: 0 0.73529 0.49705 0.327767 0.57896 0.0137224 0.44198 0.198046 0.269677 0.822528 0.588342 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=3053, meanQ=11.700819, numObservations: 9
action 2, numVisits=333, meanQ=7.820161, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 22749 episodes
GETTING ACTION FROM:
action 2, numVisits=7255, meanQ=10.896249, numObservations: 9
action 1, numVisits=18842, meanQ=9.583084, numObservations: 9
action -1, numVisits=37, meanQ=0.434330, numObservations: 25
action 0, numVisits=6, meanQ=-1.340000, numObservations: 6
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 2
Next state: 1 0.73529 0.49705 0.327767 0.57896 0.0137224 0.44198 0.198046 0.269677 0.822528 0.588342 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 22
Initial state: 0 0.699414 0.836359 0.862736 0.54753 0.665433 0.825252 0.394735 0.530772 0.245722 0.242259 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91735 episodes
GETTING ACTION FROM:
action 3, numVisits=91729, meanQ=6.898062, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.699414 0.836359 0.862736 0.54753 0.665433 0.825252 0.394735 0.530772 0.245722 0.242259 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 23
Initial state: 0 0.9509 0.847464 0.658 0.546666 0.933879 0.852074 0.306395 0.586476 0.00328944 0.909874 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 90110 episodes
GETTING ACTION FROM:
action 4, numVisits=90099, meanQ=6.389669, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 2, numVisits=2, meanQ=-4.000000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.9509 0.847464 0.658 0.546666 0.933879 0.852074 0.306395 0.586476 0.00328944 0.909874 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 24
Initial state: 0 0.608727 0.465681 0.825357 0.646305 0.763654 0.728468 0.129929 0.176975 0.330266 0.562847 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49637 episodes
GETTING ACTION FROM:
action -1, numVisits=49564, meanQ=12.590030, numObservations: 243
action 0, numVisits=58, meanQ=-1.369984, numObservations: 46
action 1, numVisits=10, meanQ=-2.324990, numObservations: 4
action 4, numVisits=2, meanQ=-7.500000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.608727 0.465681 0.825357 0.646305 0.763654 0.728468 0.129929 0.176975 0.330266 0.562847 w: 1
Observation: 0 3 0 3 0 3 0 1 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=483, meanQ=13.922569, numObservations: 69
action 1, numVisits=77, meanQ=2.648964, numObservations: 8
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 52924 episodes
GETTING ACTION FROM:
action -1, numVisits=53407, meanQ=18.593966, numObservations: 196
action 1, numVisits=77, meanQ=2.648964, numObservations: 8
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.608727 0.465681 0.825357 0.646305 0.763654 0.728468 0.129929 0.176975 0.330266 0.562847 w: 1
Observation: 0 3 0 3 0 3 0 1 0 2 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=21769, meanQ=22.119578, numObservations: 9
action 2, numVisits=3, meanQ=12.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 115408 episodes
GETTING ACTION FROM:
action 5, numVisits=137177, meanQ=22.061335, numObservations: 9
action 2, numVisits=3, meanQ=12.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.608727 0.465681 0.825357 0.646305 0.763654 0.728468 0.129929 0.176975 0.330266 0.562847 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.5424
Run # 25
Initial state: 0 0.922961 0.464868 0.303063 0.489654 0.991385 0.279383 0.45508 0.044654 0.337184 0.626932 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95938 episodes
GETTING ACTION FROM:
action 1, numVisits=95900, meanQ=6.776826, numObservations: 9
action 5, numVisits=28, meanQ=5.421079, numObservations: 8
action 2, numVisits=4, meanQ=1.250000, numObservations: 4
action 4, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.922961 0.464868 0.303063 0.489654 0.991385 0.279383 0.45508 0.044654 0.337184 0.626932 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 26
Initial state: 0 0.77052 0.728661 0.448173 0.184918 0.0208645 0.151658 0.640556 0.0845388 0.333294 0.60262 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95261 episodes
GETTING ACTION FROM:
action 3, numVisits=95247, meanQ=6.909135, numObservations: 9
action 1, numVisits=7, meanQ=4.000000, numObservations: 4
action 2, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.77052 0.728661 0.448173 0.184918 0.0208645 0.151658 0.640556 0.0845388 0.333294 0.60262 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=9793, meanQ=8.439168, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 32439 episodes
GETTING ACTION FROM:
action 4, numVisits=42120, meanQ=7.118087, numObservations: 9
action -1, numVisits=14, meanQ=-1.577129, numObservations: 12
action 3, numVisits=2, meanQ=-4.004950, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 1
action 0, numVisits=98, meanQ=-8.639889, numObservations: 54
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.77052 0.728661 0.448173 0.184918 0.0208645 0.151658 0.640556 0.0845388 0.333294 0.60262 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 27
Initial state: 0 0.13918 0.267217 0.696279 0.871762 0.204196 0.00806573 0.405709 0.610593 0.856057 0.456571 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 94096 episodes
GETTING ACTION FROM:
action 4, numVisits=94077, meanQ=6.993211, numObservations: 9
action 5, numVisits=9, meanQ=2.222222, numObservations: 6
action 2, numVisits=4, meanQ=-0.500000, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.13918 0.267217 0.696279 0.871762 0.204196 0.00806573 0.405709 0.610593 0.856057 0.456571 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 28
Initial state: 0 0.480067 0.289798 0.17995 0.169772 0.307605 0.524371 0.0293002 0.710836 0.58324 0.268834 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95564 episodes
GETTING ACTION FROM:
action 1, numVisits=95554, meanQ=6.988251, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.480067 0.289798 0.17995 0.169772 0.307605 0.524371 0.0293002 0.710836 0.58324 0.268834 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=2996, meanQ=8.205630, numObservations: 9
action 3, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 86604 episodes
GETTING ACTION FROM:
action 5, numVisits=89522, meanQ=4.934913, numObservations: 9
action -1, numVisits=35, meanQ=-2.084857, numObservations: 29
action 0, numVisits=44, meanQ=-2.135000, numObservations: 35
action 3, numVisits=4, meanQ=-2.250000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.480067 0.289798 0.17995 0.169772 0.307605 0.524371 0.0293002 0.710836 0.58324 0.268834 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 29
Initial state: 0 0.218196 0.879757 0.378062 0.673477 0.540991 0.64212 0.647897 0.422942 0.776854 0.955462 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95262 episodes
GETTING ACTION FROM:
action 3, numVisits=95256, meanQ=6.817573, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.218196 0.879757 0.378062 0.673477 0.540991 0.64212 0.647897 0.422942 0.776854 0.955462 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 30
Initial state: 0 0.758532 0.464263 0.0105274 0.331906 0.609272 0.945055 0.636466 0.737598 0.390202 0.563785 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92868 episodes
GETTING ACTION FROM:
action 1, numVisits=91037, meanQ=6.764513, numObservations: 9
action 4, numVisits=1734, meanQ=6.396313, numObservations: 9
action 3, numVisits=93, meanQ=5.915275, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.758532 0.464263 0.0105274 0.331906 0.609272 0.945055 0.636466 0.737598 0.390202 0.563785 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 31
Initial state: 0 0.541297 0.823607 0.0645277 0.945289 0.998862 0.927346 0.364046 0.524261 0.744712 0.0989063 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95265 episodes
GETTING ACTION FROM:
action 4, numVisits=95216, meanQ=6.821232, numObservations: 9
action 1, numVisits=32, meanQ=5.154375, numObservations: 9
action 2, numVisits=13, meanQ=4.538469, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.541297 0.823607 0.0645277 0.945289 0.998862 0.927346 0.364046 0.524261 0.744712 0.0989063 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=534, meanQ=6.536939, numObservations: 9
action 1, numVisits=32, meanQ=4.343128, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 78098 episodes
GETTING ACTION FROM:
action 4, numVisits=17, meanQ=16.005882, numObservations: 5
action 5, numVisits=66878, meanQ=9.693861, numObservations: 9
action 3, numVisits=11713, meanQ=9.669287, numObservations: 9
action 1, numVisits=32, meanQ=4.343128, numObservations: 9
action -1, numVisits=15, meanQ=-1.736000, numObservations: 14
action 0, numVisits=13, meanQ=-1.847692, numObservations: 13
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.541297 0.823607 0.0645277 0.945289 0.998862 0.927346 0.364046 0.524261 0.744712 0.0989063 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 32
Initial state: 0 0.269362 0.516302 0.613941 0.892054 0.805369 0.442466 0.295897 0.587608 0.800868 0.950903 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 93828 episodes
GETTING ACTION FROM:
action 2, numVisits=93806, meanQ=7.011932, numObservations: 9
action 3, numVisits=14, meanQ=3.837864, numObservations: 7
action 4, numVisits=4, meanQ=2.502525, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.269362 0.516302 0.613941 0.892054 0.805369 0.442466 0.295897 0.587608 0.800868 0.950903 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 33
Initial state: 0 0.354797 0.524894 0.827255 0.45302 0.537304 0.416007 0.235014 0.00430506 0.0928482 0.154037 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 93174 episodes
GETTING ACTION FROM:
action 2, numVisits=93164, meanQ=7.011266, numObservations: 9
action 3, numVisits=5, meanQ=-0.804000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.354797 0.524894 0.827255 0.45302 0.537304 0.416007 0.235014 0.00430506 0.0928482 0.154037 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 34
Initial state: 0 0.166364 0.683335 0.436172 0.420258 0.331941 0.592461 0.685809 0.261642 0.95845 0.109616 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95546 episodes
GETTING ACTION FROM:
action 5, numVisits=95536, meanQ=6.858133, numObservations: 9
action 1, numVisits=3, meanQ=0.666667, numObservations: 3
action 4, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.166364 0.683335 0.436172 0.420258 0.331941 0.592461 0.685809 0.261642 0.95845 0.109616 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 35
Initial state: 0 0.903371 0.451547 0.453001 0.510094 0.391422 0.64083 0.781867 0.0716018 0.868967 0.10401 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 94204 episodes
GETTING ACTION FROM:
action 2, numVisits=94190, meanQ=6.653207, numObservations: 9
action 3, numVisits=9, meanQ=2.222222, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.903371 0.451547 0.453001 0.510094 0.391422 0.64083 0.781867 0.0716018 0.868967 0.10401 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 36
Initial state: 0 0.930828 0.476288 0.322985 0.570639 0.19212 0.268404 0.522314 0.229494 0.193017 0.177679 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 93983 episodes
GETTING ACTION FROM:
action 1, numVisits=93923, meanQ=7.000300, numObservations: 9
action 4, numVisits=55, meanQ=5.985644, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.930828 0.476288 0.322985 0.570639 0.19212 0.268404 0.522314 0.229494 0.193017 0.177679 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=2990, meanQ=8.259530, numObservations: 9
action 4, numVisits=16, meanQ=0.248775, numObservations: 5
action 2, numVisits=7, meanQ=0.141429, numObservations: 3
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 99438 episodes
GETTING ACTION FROM:
action 3, numVisits=102330, meanQ=5.026243, numObservations: 9
action 2, numVisits=39, meanQ=2.676512, numObservations: 8
action 4, numVisits=16, meanQ=0.248775, numObservations: 5
action 0, numVisits=44, meanQ=-1.842500, numObservations: 32
action -1, numVisits=27, meanQ=-2.257033, numObservations: 22
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 3
Next state: 0 0.930828 0.476288 0.322985 0.570639 0.19212 0.268404 0.522314 0.229494 0.193017 0.177679 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=369, meanQ=13.720141, numObservations: 9
action 4, numVisits=90, meanQ=10.934560, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 123960 episodes
GETTING ACTION FROM:
action 5, numVisits=2036, meanQ=6.560163, numObservations: 9
action 4, numVisits=122361, meanQ=5.984916, numObservations: 9
action -1, numVisits=13, meanQ=-1.847692, numObservations: 12
action 0, numVisits=13, meanQ=-1.847692, numObservations: 12
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.930828 0.476288 0.322985 0.570639 0.19212 0.268404 0.522314 0.229494 0.193017 0.177679 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 4, numVisits=3, meanQ=24.000000, numObservations: 2
action 2, numVisits=3, meanQ=12.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-10.347758, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 227278 episodes
GETTING ACTION FROM:
action 4, numVisits=227270, meanQ=9.005148, numObservations: 9
action 2, numVisits=12, meanQ=3.583333, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 5, numVisits=1, meanQ=-10.347758, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.930828 0.476288 0.322985 0.570639 0.19212 0.268404 0.522314 0.229494 0.193017 0.177679 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -22.5537
Run # 37
Initial state: 0 0.137571 0.157784 0.0835572 0.450158 0.405267 0.701475 0.0145805 0.326249 0.484516 0.258993 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91795 episodes
GETTING ACTION FROM:
action 3, numVisits=91787, meanQ=6.966223, numObservations: 9
action 5, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.137571 0.157784 0.0835572 0.450158 0.405267 0.701475 0.0145805 0.326249 0.484516 0.258993 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 38
Initial state: 0 0.27332 0.0505666 0.0845877 0.224104 0.123435 0.618605 0.314233 0.541995 0.176236 0.859626 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95324 episodes
GETTING ACTION FROM:
action 3, numVisits=95311, meanQ=6.906497, numObservations: 9
action 2, numVisits=8, meanQ=3.123750, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.27332 0.0505666 0.0845877 0.224104 0.123435 0.618605 0.314233 0.541995 0.176236 0.859626 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=2305, meanQ=7.871639, numObservations: 9
action 1, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 44761 episodes
GETTING ACTION FROM:
action 5, numVisits=46888, meanQ=7.504198, numObservations: 9
action 1, numVisits=4, meanQ=-2.250000, numObservations: 3
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action 4, numVisits=2, meanQ=-7.005000, numObservations: 2
action 0, numVisits=80, meanQ=-14.243487, numObservations: 58
action -1, numVisits=72, meanQ=-16.105636, numObservations: 55
action 2, numVisits=26, meanQ=-35.881262, numObservations: 8
action: 5
Next state: 0 0.27332 0.0505666 0.0845877 0.224104 0.123435 0.618605 0.314233 0.541995 0.176236 0.859626 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=1743, meanQ=12.437924, numObservations: 9
action -1, numVisits=10, meanQ=-1.010000, numObservations: 10
action 0, numVisits=8, meanQ=-1.258738, numObservations: 7
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 40481 episodes
GETTING ACTION FROM:
action 4, numVisits=42223, meanQ=10.700864, numObservations: 9
action -1, numVisits=10, meanQ=-1.010000, numObservations: 10
action 0, numVisits=8, meanQ=-1.258738, numObservations: 7
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.27332 0.0505666 0.0845877 0.224104 0.123435 0.618605 0.314233 0.541995 0.176236 0.859626 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 39
Initial state: 0 0.604807 0.880589 0.52495 0.387574 0.345407 0.690429 0.0848529 0.346339 0.644279 0.35623 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 94295 episodes
GETTING ACTION FROM:
action 2, numVisits=94279, meanQ=6.985534, numObservations: 9
action 1, numVisits=6, meanQ=2.833350, numObservations: 4
action 5, numVisits=6, meanQ=1.833333, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.604807 0.880589 0.52495 0.387574 0.345407 0.690429 0.0848529 0.346339 0.644279 0.35623 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 40
Initial state: 0 0.0915072 0.859359 0.0139052 0.876436 0.37328 0.596217 0.262712 0.727845 0.101183 0.00186571 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 94816 episodes
GETTING ACTION FROM:
action 1, numVisits=88876, meanQ=6.980529, numObservations: 9
action 5, numVisits=5868, meanQ=6.795078, numObservations: 9
action 4, numVisits=66, meanQ=5.999397, numObservations: 9
action 3, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.0915072 0.859359 0.0139052 0.876436 0.37328 0.596217 0.262712 0.727845 0.101183 0.00186571 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=2033, meanQ=7.539771, numObservations: 9
action 4, numVisits=5, meanQ=4.598000, numObservations: 4
action 3, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 39522 episodes
GETTING ACTION FROM:
action 4, numVisits=38790, meanQ=8.787055, numObservations: 9
action 5, numVisits=2639, meanQ=7.654661, numObservations: 9
action 0, numVisits=78, meanQ=-1.587862, numObservations: 58
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=51, meanQ=-14.326316, numObservations: 9
action -1, numVisits=7, meanQ=-151.470171, numObservations: 6
action: 4
Next state: 1 0.0915072 0.859359 0.0139052 0.876436 0.37328 0.596217 0.262712 0.727845 0.101183 0.00186571 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 41
Initial state: 0 0.933059 0.614056 0.841071 0.468032 0.576996 0.39646 0.138732 0.127678 0.320479 0.640263 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95454 episodes
GETTING ACTION FROM:
action 2, numVisits=95429, meanQ=6.883223, numObservations: 9
action 4, numVisits=20, meanQ=4.092500, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.933059 0.614056 0.841071 0.468032 0.576996 0.39646 0.138732 0.127678 0.320479 0.640263 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 42
Initial state: 0 0.949541 0.885201 0.751131 0.371538 0.0933199 0.370502 0.906204 0.487387 0.366796 0.665143 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95099 episodes
GETTING ACTION FROM:
action 4, numVisits=95091, meanQ=6.562750, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.949541 0.885201 0.751131 0.371538 0.0933199 0.370502 0.906204 0.487387 0.366796 0.665143 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 43
Initial state: 0 0.39223 0.638532 0.161875 0.382963 0.0989083 0.0376075 0.558983 0.355042 0.0948303 0.056733 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 94556 episodes
GETTING ACTION FROM:
action 3, numVisits=94548, meanQ=6.838065, numObservations: 9
action 1, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.39223 0.638532 0.161875 0.382963 0.0989083 0.0376075 0.558983 0.355042 0.0948303 0.056733 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=2149, meanQ=7.236863, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 46393 episodes
GETTING ACTION FROM:
action 1, numVisits=48442, meanQ=7.898045, numObservations: 9
action 0, numVisits=53, meanQ=-1.776223, numObservations: 44
action -1, numVisits=45, meanQ=-2.128252, numObservations: 39
action 5, numVisits=5, meanQ=-2.402000, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.39223 0.638532 0.161875 0.382963 0.0989083 0.0376075 0.558983 0.355042 0.0948303 0.056733 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 44
Initial state: 0 0.673172 0.974453 0.148216 0.550462 0.418129 0.617548 0.111197 0.286864 0.538672 0.216213 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 94433 episodes
GETTING ACTION FROM:
action 1, numVisits=94386, meanQ=6.705535, numObservations: 9
action 4, numVisits=20, meanQ=2.536505, numObservations: 8
action 5, numVisits=18, meanQ=2.502800, numObservations: 7
action 2, numVisits=6, meanQ=1.833333, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.673172 0.974453 0.148216 0.550462 0.418129 0.617548 0.111197 0.286864 0.538672 0.216213 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 45
Initial state: 0 0.196735 0.729902 0.946174 0.378332 0.227578 0.405521 0.392546 0.683677 0.0730839 0.982512 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95253 episodes
GETTING ACTION FROM:
action 3, numVisits=95235, meanQ=6.816244, numObservations: 9
action 4, numVisits=9, meanQ=3.225578, numObservations: 4
action 1, numVisits=5, meanQ=3.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.196735 0.729902 0.946174 0.378332 0.227578 0.405521 0.392546 0.683677 0.0730839 0.982512 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=10016, meanQ=8.129510, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 25370 episodes
GETTING ACTION FROM:
action 3, numVisits=2, meanQ=8.375000, numObservations: 1
action 1, numVisits=35357, meanQ=7.681608, numObservations: 9
action 0, numVisits=16, meanQ=-1.133750, numObservations: 16
action -1, numVisits=12, meanQ=-1.340825, numObservations: 11
action 2, numVisits=5, meanQ=-1.566479, numObservations: 3
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.196735 0.729902 0.946174 0.378332 0.227578 0.405521 0.392546 0.683677 0.0730839 0.982512 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 39209 episodes
GETTING ACTION FROM:
action 4, numVisits=39075, meanQ=6.027032, numObservations: 9
action 1, numVisits=14, meanQ=-3.500000, numObservations: 7
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=61, meanQ=-19.885000, numObservations: 35
action -1, numVisits=56, meanQ=-20.055463, numObservations: 43
action: 4
Next state: 1 0.196735 0.729902 0.946174 0.378332 0.227578 0.405521 0.392546 0.683677 0.0730839 0.982512 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 46
Initial state: 0 0.00397874 0.892234 0.922896 0.137262 0.310405 0.558672 0.280906 0.980535 0.796633 0.988382 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95523 episodes
GETTING ACTION FROM:
action 1, numVisits=95509, meanQ=6.864810, numObservations: 9
action 4, numVisits=9, meanQ=4.555556, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.00397874 0.892234 0.922896 0.137262 0.310405 0.558672 0.280906 0.980535 0.796633 0.988382 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 47
Initial state: 0 0.135725 0.12952 0.0895979 0.221116 0.472987 0.137732 0.33163 0.633023 0.251933 0.733455 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 94973 episodes
GETTING ACTION FROM:
action 1, numVisits=94950, meanQ=6.873950, numObservations: 9
action 3, numVisits=15, meanQ=4.866007, numObservations: 5
action 2, numVisits=4, meanQ=-0.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.135725 0.12952 0.0895979 0.221116 0.472987 0.137732 0.33163 0.633023 0.251933 0.733455 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=10166, meanQ=8.169191, numObservations: 9
action 5, numVisits=17, meanQ=4.102353, numObservations: 7
action 2, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 27814 episodes
GETTING ACTION FROM:
action 3, numVisits=37890, meanQ=6.762262, numObservations: 9
action 4, numVisits=29, meanQ=2.804368, numObservations: 9
action 5, numVisits=19, meanQ=2.581287, numObservations: 8
action 2, numVisits=9, meanQ=0.666667, numObservations: 6
action -1, numVisits=23, meanQ=-1.784783, numObservations: 21
action 1, numVisits=2, meanQ=-3.505000, numObservations: 2
action 0, numVisits=32, meanQ=-33.039423, numObservations: 27
action: 3
Next state: 2 0.135725 0.12952 0.0895979 0.221116 0.472987 0.137732 0.33163 0.633023 0.251933 0.733455 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 48
Initial state: 0 0.353382 0.942326 0.730504 0.795836 0.49573 0.277097 0.813603 0.93442 0.360886 0.651041 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95588 episodes
GETTING ACTION FROM:
action 2, numVisits=95582, meanQ=6.925603, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.353382 0.942326 0.730504 0.795836 0.49573 0.277097 0.813603 0.93442 0.360886 0.651041 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 49
Initial state: 0 0.276226 0.359617 0.911621 0.300903 0.793883 0.195944 0.408545 0.62173 0.240593 0.724309 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95433 episodes
GETTING ACTION FROM:
action 2, numVisits=95404, meanQ=6.832447, numObservations: 9
action 1, numVisits=24, meanQ=4.837508, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.276226 0.359617 0.911621 0.300903 0.793883 0.195944 0.408545 0.62173 0.240593 0.724309 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 50
Initial state: 0 0.232667 0.119261 0.307111 0.59227 0.729375 0.722399 0.100288 0.580322 0.788573 0.328072 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95326 episodes
GETTING ACTION FROM:
action 4, numVisits=95311, meanQ=6.895618, numObservations: 9
action 3, numVisits=4, meanQ=-0.252500, numObservations: 3
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=5, meanQ=-1.780000, numObservations: 3
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 0 0.232667 0.119261 0.307111 0.59227 0.729375 0.722399 0.100288 0.580322 0.788573 0.328072 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=2223, meanQ=6.481044, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 28636 episodes
GETTING ACTION FROM:
action 2, numVisits=30774, meanQ=6.964541, numObservations: 9
action 4, numVisits=2, meanQ=-3.505000, numObservations: 2
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=66, meanQ=-17.283739, numObservations: 50
action -1, numVisits=23, meanQ=-47.631453, numObservations: 18
action: 2
Next state: 1 0.232667 0.119261 0.307111 0.59227 0.729375 0.722399 0.100288 0.580322 0.788573 0.328072 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
[32m ProblemEnvironment.hpp 351: Done.[39m
