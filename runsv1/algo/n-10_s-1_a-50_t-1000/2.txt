Run # 1
Initial state: 0 0.868303 0.559248 0.268184 0.74675 0.495625 0.120627 0.840197 0.279587 0.566712 0.373312 0.812039 0.923437 0.745677 0.315738 0.625987 0.108172 0.253844 0.54307 0.655424 0.532611 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18901 episodes
GETTING ACTION FROM:
action 7, numVisits=18761, meanQ=11.912552, numObservations: 9
action 2, numVisits=82, meanQ=11.098051, numObservations: 9
action 8, numVisits=21, meanQ=10.291914, numObservations: 7
action 6, numVisits=15, meanQ=9.731333, numObservations: 7
action 10, numVisits=11, meanQ=9.555464, numObservations: 5
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action 4, numVisits=4, meanQ=6.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 7
Next state: 1 0.868303 0.559248 0.268184 0.74675 0.495625 0.120627 0.840197 0.279587 0.566712 0.373312 0.812039 0.923437 0.745677 0.315738 0.625987 0.108172 0.253844 0.54307 0.655424 0.532611 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 2
Initial state: 0 0.948144 0.111304 0.767312 0.596079 0.612358 0.681731 0.248447 0.201697 0.505557 0.0257815 0.654752 0.461349 0.358751 0.675726 0.373533 0.613432 0.850003 0.42417 0.559271 0.309717 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19120 episodes
GETTING ACTION FROM:
action 7, numVisits=19096, meanQ=11.829272, numObservations: 9
action 4, numVisits=9, meanQ=8.332244, numObservations: 7
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action 9, numVisits=2, meanQ=6.500000, numObservations: 2
action 5, numVisits=3, meanQ=5.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 10, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 7
Next state: 1 0.948144 0.111304 0.767312 0.596079 0.612358 0.681731 0.248447 0.201697 0.505557 0.0257815 0.654752 0.461349 0.358751 0.675726 0.373533 0.613432 0.850003 0.42417 0.559271 0.309717 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 3
Initial state: 0 0.692085 0.734857 0.640193 0.210263 0.947517 0.0559446 0.561295 0.307045 0.777472 0.569267 0.25465 0.537455 0.746125 0.745195 0.992232 0.186958 0.0855913 0.804524 0.802417 0.800364 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18729 episodes
GETTING ACTION FROM:
action 1, numVisits=18714, meanQ=11.829811, numObservations: 9
action 5, numVisits=5, meanQ=5.800000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action 9, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.692085 0.734857 0.640193 0.210263 0.947517 0.0559446 0.561295 0.307045 0.777472 0.569267 0.25465 0.537455 0.746125 0.745195 0.992232 0.186958 0.0855913 0.804524 0.802417 0.800364 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 4
Initial state: 0 0.131343 0.0711096 0.725545 0.307325 0.860559 0.530676 0.69001 0.525728 0.0882928 0.132234 0.937683 0.467087 0.0309981 0.84948 0.280063 0.765975 0.752241 0.932112 0.537259 0.333109 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18723 episodes
GETTING ACTION FROM:
action 10, numVisits=18700, meanQ=11.672189, numObservations: 9
action 6, numVisits=4, meanQ=8.250000, numObservations: 3
action 4, numVisits=6, meanQ=7.831667, numObservations: 5
action 2, numVisits=5, meanQ=7.398000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action 9, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 10
Next state: 1 0.131343 0.0711096 0.725545 0.307325 0.860559 0.530676 0.69001 0.525728 0.0882928 0.132234 0.937683 0.467087 0.0309981 0.84948 0.280063 0.765975 0.752241 0.932112 0.537259 0.333109 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 5
Initial state: 0 0.595443 0.343604 0.681564 0.191181 0.125472 0.936365 0.600632 0.119869 0.221851 0.875271 0.131609 0.253084 0.756076 0.989584 0.00706518 0.0324996 0.210681 0.784694 0.129424 0.802997 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19172 episodes
GETTING ACTION FROM:
action 9, numVisits=18917, meanQ=11.791664, numObservations: 9
action 7, numVisits=228, meanQ=11.357251, numObservations: 9
action 10, numVisits=10, meanQ=8.577020, numObservations: 5
action 1, numVisits=4, meanQ=8.250000, numObservations: 4
action 4, numVisits=2, meanQ=6.500000, numObservations: 2
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action 6, numVisits=4, meanQ=6.500000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 9
Next state: 0 0.595443 0.343604 0.681564 0.191181 0.125472 0.936365 0.600632 0.119869 0.221851 0.875271 0.131609 0.253084 0.756076 0.989584 0.00706518 0.0324996 0.210681 0.784694 0.129424 0.802997 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=3512, meanQ=12.261498, numObservations: 9
action 8, numVisits=3, meanQ=3.330000, numObservations: 3
action 6, numVisits=5, meanQ=3.000000, numObservations: 4
action 1, numVisits=4, meanQ=1.745000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 7, numVisits=1, meanQ=-3.010000, numObservations: 1
action 9, numVisits=1, meanQ=-3.010000, numObservations: 1
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 4584 episodes
GETTING ACTION FROM:
action 2, numVisits=8093, meanQ=13.127262, numObservations: 9
action 8, numVisits=3, meanQ=3.330000, numObservations: 3
action 6, numVisits=5, meanQ=3.000000, numObservations: 4
action 1, numVisits=4, meanQ=1.745000, numObservations: 3
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 7, numVisits=1, meanQ=-3.010000, numObservations: 1
action 9, numVisits=1, meanQ=-3.010000, numObservations: 1
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.595443 0.343604 0.681564 0.191181 0.125472 0.936365 0.600632 0.119869 0.221851 0.875271 0.131609 0.253084 0.756076 0.989584 0.00706518 0.0324996 0.210681 0.784694 0.129424 0.802997 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 6
Initial state: 0 0.801155 0.304484 0.16326 0.956448 0.722745 0.551024 0.10313 0.0784798 0.104078 0.842455 0.877124 0.830571 0.621307 0.381458 0.319491 0.106981 0.0824448 0.165568 0.174739 0.546494 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18935 episodes
GETTING ACTION FROM:
action 6, numVisits=18916, meanQ=11.615626, numObservations: 9
action 4, numVisits=9, meanQ=3.777778, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 7, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action 9, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 6
Next state: 1 0.801155 0.304484 0.16326 0.956448 0.722745 0.551024 0.10313 0.0784798 0.104078 0.842455 0.877124 0.830571 0.621307 0.381458 0.319491 0.106981 0.0824448 0.165568 0.174739 0.546494 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 7
Initial state: 0 0.52168 0.320724 0.859618 0.144022 0.103277 0.213376 0.99573 0.461086 0.902639 0.653458 0.0532534 0.998504 0.904595 0.133666 0.424734 0.01765 0.0100263 0.070253 0.221879 0.425239 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19156 episodes
GETTING ACTION FROM:
action 6, numVisits=19130, meanQ=11.535566, numObservations: 9
action 1, numVisits=12, meanQ=6.746675, numObservations: 6
action 10, numVisits=5, meanQ=6.196000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 7, numVisits=1, meanQ=-4.000000, numObservations: 1
action 9, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 6
Next state: 0 0.52168 0.320724 0.859618 0.144022 0.103277 0.213376 0.99573 0.461086 0.902639 0.653458 0.0532534 0.998504 0.904595 0.133666 0.424734 0.01765 0.0100263 0.070253 0.221879 0.425239 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 9, numVisits=3639, meanQ=11.635624, numObservations: 9
action 8, numVisits=7, meanQ=4.707143, numObservations: 6
action 6, numVisits=4, meanQ=3.742500, numObservations: 3
action 5, numVisits=4, meanQ=1.745000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 7, numVisits=1, meanQ=-3.010000, numObservations: 1
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 4337 episodes
GETTING ACTION FROM:
action 9, numVisits=7972, meanQ=12.566973, numObservations: 9
action 8, numVisits=7, meanQ=4.707143, numObservations: 6
action 6, numVisits=4, meanQ=3.742500, numObservations: 3
action 5, numVisits=4, meanQ=1.745000, numObservations: 2
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.340000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 7, numVisits=1, meanQ=-3.010000, numObservations: 1
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 9
Next state: 0 0.52168 0.320724 0.859618 0.144022 0.103277 0.213376 0.99573 0.461086 0.902639 0.653458 0.0532534 0.998504 0.904595 0.133666 0.424734 0.01765 0.0100263 0.070253 0.221879 0.425239 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=810, meanQ=12.662962, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 6, numVisits=1, meanQ=-3.010000, numObservations: 1
action 7, numVisits=1, meanQ=-3.010000, numObservations: 1
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 3066 episodes
GETTING ACTION FROM:
action 5, numVisits=3875, meanQ=13.579477, numObservations: 9
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 6, numVisits=1, meanQ=-3.010000, numObservations: 1
action 7, numVisits=1, meanQ=-3.010000, numObservations: 1
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.52168 0.320724 0.859618 0.144022 0.103277 0.213376 0.99573 0.461086 0.902639 0.653458 0.0532534 0.998504 0.904595 0.133666 0.424734 0.01765 0.0100263 0.070253 0.221879 0.425239 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 8
Initial state: 0 0.563354 0.303292 0.815913 0.511471 0.233715 0.116198 0.179905 0.918792 0.85614 0.887062 0.922369 0.444411 0.878893 0.412374 0.385657 0.840838 0.510373 0.843563 0.228942 0.979101 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19337 episodes
GETTING ACTION FROM:
action 4, numVisits=19304, meanQ=11.796781, numObservations: 9
action 1, numVisits=7, meanQ=7.282857, numObservations: 4
action 9, numVisits=7, meanQ=6.998586, numObservations: 4
action 10, numVisits=9, meanQ=6.792244, numObservations: 2
action 6, numVisits=3, meanQ=1.703333, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.563354 0.303292 0.815913 0.511471 0.233715 0.116198 0.179905 0.918792 0.85614 0.887062 0.922369 0.444411 0.878893 0.412374 0.385657 0.840838 0.510373 0.843563 0.228942 0.979101 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 9
Initial state: 0 0.606358 0.737196 0.124942 0.61313 0.380858 0.635428 0.79286 0.41377 0.593285 0.309602 0.060041 0.842928 0.849218 0.742714 0.988671 0.58305 0.727579 0.676403 0.103261 0.768702 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19192 episodes
GETTING ACTION FROM:
action 7, numVisits=19171, meanQ=11.818157, numObservations: 9
action 4, numVisits=7, meanQ=5.585714, numObservations: 3
action 10, numVisits=3, meanQ=4.340033, numObservations: 2
action 1, numVisits=3, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action 9, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 7
Next state: 1 0.606358 0.737196 0.124942 0.61313 0.380858 0.635428 0.79286 0.41377 0.593285 0.309602 0.060041 0.842928 0.849218 0.742714 0.988671 0.58305 0.727579 0.676403 0.103261 0.768702 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 10
Initial state: 0 0.523973 0.363819 0.339651 0.0684961 0.0611936 0.420525 0.778828 0.924993 0.209214 0.426707 0.363606 0.886246 0.834225 0.0194948 0.964304 0.981707 0.572183 0.017413 0.0414888 0.742291 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19368 episodes
GETTING ACTION FROM:
action 10, numVisits=19338, meanQ=11.784532, numObservations: 9
action 9, numVisits=20, meanQ=6.474510, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 10
Next state: 1 0.523973 0.363819 0.339651 0.0684961 0.0611936 0.420525 0.778828 0.924993 0.209214 0.426707 0.363606 0.886246 0.834225 0.0194948 0.964304 0.981707 0.572183 0.017413 0.0414888 0.742291 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 11
Initial state: 0 0.000135104 0.573671 0.723525 0.510967 0.110781 0.86911 0.577792 0.352177 0.821209 0.192398 0.800758 0.933119 0.104783 0.237198 0.480637 0.227291 0.502749 0.747066 0.735664 0.0961114 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18576 episodes
GETTING ACTION FROM:
action 5, numVisits=18565, meanQ=11.933821, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-4.000000, numObservations: 1
action 7, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.000135104 0.573671 0.723525 0.510967 0.110781 0.86911 0.577792 0.352177 0.821209 0.192398 0.800758 0.933119 0.104783 0.237198 0.480637 0.227291 0.502749 0.747066 0.735664 0.0961114 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 12
Initial state: 0 0.421899 0.265874 0.510039 0.210699 0.582749 0.320815 0.791351 0.751827 0.110316 0.041388 0.164494 0.827863 0.192945 0.0323551 0.798909 0.617345 0.53859 0.678002 0.890204 0.0292231 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19321 episodes
GETTING ACTION FROM:
action 1, numVisits=19288, meanQ=11.683510, numObservations: 9
action 10, numVisits=15, meanQ=6.884007, numObservations: 7
action 4, numVisits=3, meanQ=5.333333, numObservations: 3
action 3, numVisits=3, meanQ=3.330000, numObservations: 2
action 8, numVisits=3, meanQ=3.330000, numObservations: 3
action 5, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-4.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.421899 0.265874 0.510039 0.210699 0.582749 0.320815 0.791351 0.751827 0.110316 0.041388 0.164494 0.827863 0.192945 0.0323551 0.798909 0.617345 0.53859 0.678002 0.890204 0.0292231 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 13
Initial state: 0 0.723078 0.124857 0.37867 0.39811 0.874873 0.45213 0.520131 0.360786 0.310221 0.270337 0.992836 0.844982 0.913326 0.60189 0.13139 0.781792 0.543165 0.714381 0.210064 0.873694 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19105 episodes
GETTING ACTION FROM:
action 7, numVisits=19085, meanQ=11.806714, numObservations: 9
action 9, numVisits=6, meanQ=8.666683, numObservations: 4
action 6, numVisits=3, meanQ=4.340033, numObservations: 1
action 3, numVisits=3, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 7
Next state: 1 0.723078 0.124857 0.37867 0.39811 0.874873 0.45213 0.520131 0.360786 0.310221 0.270337 0.992836 0.844982 0.913326 0.60189 0.13139 0.781792 0.543165 0.714381 0.210064 0.873694 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 14
Initial state: 0 0.573997 0.344949 0.45021 0.769781 0.989047 0.748355 0.418759 0.10066 0.935412 0.201277 0.110431 0.110023 0.53158 0.560119 0.695473 0.459446 0.0896739 0.820923 0.240032 0.803842 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19501 episodes
GETTING ACTION FROM:
action 8, numVisits=19469, meanQ=11.568798, numObservations: 9
action 6, numVisits=18, meanQ=9.943900, numObservations: 6
action 9, numVisits=5, meanQ=5.204020, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 8
Next state: 1 0.573997 0.344949 0.45021 0.769781 0.989047 0.748355 0.418759 0.10066 0.935412 0.201277 0.110431 0.110023 0.53158 0.560119 0.695473 0.459446 0.0896739 0.820923 0.240032 0.803842 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 15
Initial state: 0 0.857735 0.295136 0.200378 0.864053 0.571478 0.328651 0.670227 0.148076 0.603246 0.0476294 0.839008 0.444793 0.727495 0.0912584 0.419924 0.285768 0.313193 0.72235 0.914986 0.0830678 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19136 episodes
GETTING ACTION FROM:
action 3, numVisits=19098, meanQ=11.950278, numObservations: 9
action 7, numVisits=16, meanQ=8.249381, numObservations: 7
action 8, numVisits=5, meanQ=7.596000, numObservations: 3
action 9, numVisits=3, meanQ=5.663333, numObservations: 3
action 5, numVisits=3, meanQ=4.340033, numObservations: 2
action 6, numVisits=5, meanQ=3.622000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.857735 0.295136 0.200378 0.864053 0.571478 0.328651 0.670227 0.148076 0.603246 0.0476294 0.839008 0.444793 0.727495 0.0912584 0.419924 0.285768 0.313193 0.72235 0.914986 0.0830678 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=33, meanQ=9.979709, numObservations: 6
action 4, numVisits=20, meanQ=5.388020, numObservations: 8
action 7, numVisits=5, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 6, numVisits=1, meanQ=-3.010000, numObservations: 1
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 15099 episodes
GETTING ACTION FROM:
action 1, numVisits=15128, meanQ=13.596939, numObservations: 9
action 4, numVisits=20, meanQ=5.388020, numObservations: 8
action 7, numVisits=5, meanQ=3.000000, numObservations: 3
action -1, numVisits=3, meanQ=-1.340000, numObservations: 3
action 0, numVisits=3, meanQ=-1.340000, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 6, numVisits=1, meanQ=-3.010000, numObservations: 1
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.857735 0.295136 0.200378 0.864053 0.571478 0.328651 0.670227 0.148076 0.603246 0.0476294 0.839008 0.444793 0.727495 0.0912584 0.419924 0.285768 0.313193 0.72235 0.914986 0.0830678 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 16
Initial state: 0 0.896098 0.506919 0.495882 0.118077 0.880535 0.925306 0.727722 0.995205 0.734951 0.20027 0.442183 0.608839 0.80496 0.914387 0.2049 0.51659 0.571835 0.38075 0.628521 0.411305 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18448 episodes
GETTING ACTION FROM:
action 3, numVisits=18409, meanQ=11.742182, numObservations: 9
action 8, numVisits=20, meanQ=8.238510, numObservations: 8
action 7, numVisits=4, meanQ=6.500000, numObservations: 2
action 10, numVisits=5, meanQ=4.426020, numObservations: 3
action 9, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.896098 0.506919 0.495882 0.118077 0.880535 0.925306 0.727722 0.995205 0.734951 0.20027 0.442183 0.608839 0.80496 0.914387 0.2049 0.51659 0.571835 0.38075 0.628521 0.411305 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 17
Initial state: 0 0.358353 0.126432 0.148543 0.0265148 0.439882 0.547604 0.992326 0.842938 0.216311 0.793537 0.514482 0.528666 0.478651 0.616644 0.657529 0.513285 0.911788 0.808351 0.530362 0.339312 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19287 episodes
GETTING ACTION FROM:
action 10, numVisits=19272, meanQ=11.817339, numObservations: 9
action 3, numVisits=3, meanQ=3.330000, numObservations: 2
action 2, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action 9, numVisits=1, meanQ=-4.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 10
Next state: 1 0.358353 0.126432 0.148543 0.0265148 0.439882 0.547604 0.992326 0.842938 0.216311 0.793537 0.514482 0.528666 0.478651 0.616644 0.657529 0.513285 0.911788 0.808351 0.530362 0.339312 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 18
Initial state: 0 0.270362 0.736494 0.578791 0.345007 0.922077 0.174111 0.541339 0.436086 0.476921 0.0147101 0.417657 0.980604 0.756105 0.857696 0.750982 0.0991744 0.726061 0.122033 0.861078 0.796077 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19315 episodes
GETTING ACTION FROM:
action 3, numVisits=19292, meanQ=11.964843, numObservations: 9
action 5, numVisits=4, meanQ=8.497500, numObservations: 4
action 8, numVisits=4, meanQ=8.250000, numObservations: 3
action 2, numVisits=3, meanQ=5.663333, numObservations: 2
action 1, numVisits=3, meanQ=3.000000, numObservations: 3
action 6, numVisits=3, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 7, numVisits=1, meanQ=-4.000000, numObservations: 1
action 9, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.270362 0.736494 0.578791 0.345007 0.922077 0.174111 0.541339 0.436086 0.476921 0.0147101 0.417657 0.980604 0.756105 0.857696 0.750982 0.0991744 0.726061 0.122033 0.861078 0.796077 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 19
Initial state: 0 0.269817 0.980157 0.0866281 0.693209 0.802165 0.291172 0.979493 0.740269 0.526096 0.602926 0.91843 0.845433 0.866218 0.914583 0.601778 0.396111 0.0121741 0.800668 0.393125 0.716722 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19665 episodes
GETTING ACTION FROM:
action 6, numVisits=19639, meanQ=11.839109, numObservations: 9
action 4, numVisits=6, meanQ=8.336683, numObservations: 4
action 2, numVisits=10, meanQ=7.900000, numObservations: 6
action 7, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action 9, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 6
Next state: 1 0.269817 0.980157 0.0866281 0.693209 0.802165 0.291172 0.979493 0.740269 0.526096 0.602926 0.91843 0.845433 0.866218 0.914583 0.601778 0.396111 0.0121741 0.800668 0.393125 0.716722 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 20
Initial state: 0 0.857587 0.347845 0.32357 0.20705 0.262865 0.366759 0.547927 0.349876 0.868426 0.722302 0.144626 0.321704 0.915567 0.998152 0.643993 0.0275327 0.916485 0.896085 0.0053586 0.797628 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19574 episodes
GETTING ACTION FROM:
action 1, numVisits=19556, meanQ=11.836875, numObservations: 9
action 4, numVisits=3, meanQ=3.000000, numObservations: 2
action 8, numVisits=6, meanQ=1.833333, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 7, numVisits=1, meanQ=-4.000000, numObservations: 1
action 9, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.857587 0.347845 0.32357 0.20705 0.262865 0.366759 0.547927 0.349876 0.868426 0.722302 0.144626 0.321704 0.915567 0.998152 0.643993 0.0275327 0.916485 0.896085 0.0053586 0.797628 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 21
Initial state: 0 0.0771728 0.8423 0.0311126 0.531269 0.0238066 0.414345 0.58063 0.399693 0.648938 0.289424 0.923668 0.890994 0.77244 0.0656038 0.128367 0.869615 0.0966343 0.824461 0.0730611 0.919011 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18502 episodes
GETTING ACTION FROM:
action 10, numVisits=18489, meanQ=12.137206, numObservations: 9
action 3, numVisits=3, meanQ=5.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-4.000000, numObservations: 1
action 7, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 10
Next state: 0 0.0771728 0.8423 0.0311126 0.531269 0.0238066 0.414345 0.58063 0.399693 0.648938 0.289424 0.923668 0.890994 0.77244 0.0656038 0.128367 0.869615 0.0966343 0.824461 0.0730611 0.919011 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 10, numVisits=3528, meanQ=13.595246, numObservations: 9
action 8, numVisits=4, meanQ=9.997525, numObservations: 3
action 6, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 4778 episodes
GETTING ACTION FROM:
action 6, numVisits=4768, meanQ=15.535855, numObservations: 9
action 10, numVisits=3528, meanQ=13.595246, numObservations: 9
action 8, numVisits=15, meanQ=11.338799, numObservations: 7
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 6
Next state: 1 0.0771728 0.8423 0.0311126 0.531269 0.0238066 0.414345 0.58063 0.399693 0.648938 0.289424 0.923668 0.890994 0.77244 0.0656038 0.128367 0.869615 0.0966343 0.824461 0.0730611 0.919011 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 22
Initial state: 0 0.180571 0.672165 0.138832 0.904523 0.765445 0.782952 0.676405 0.730371 0.690806 0.79973 0.530104 0.893041 0.217037 0.940706 0.182736 0.259221 0.604327 0.998899 0.523988 0.310323 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19344 episodes
GETTING ACTION FROM:
action 3, numVisits=19312, meanQ=11.691779, numObservations: 9
action 10, numVisits=13, meanQ=8.623846, numObservations: 6
action 8, numVisits=6, meanQ=8.336683, numObservations: 5
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action 4, numVisits=2, meanQ=6.500000, numObservations: 2
action 6, numVisits=3, meanQ=5.663333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 7, numVisits=1, meanQ=-4.000000, numObservations: 1
action 9, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.180571 0.672165 0.138832 0.904523 0.765445 0.782952 0.676405 0.730371 0.690806 0.79973 0.530104 0.893041 0.217037 0.940706 0.182736 0.259221 0.604327 0.998899 0.523988 0.310323 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 23
Initial state: 0 0.617349 0.326605 0.870259 0.580523 0.431829 0.207264 0.282614 0.154814 0.631659 0.645289 0.0377274 0.655356 0.944626 0.588355 0.28157 0.957338 0.287561 0.441019 0.662359 0.531591 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19231 episodes
GETTING ACTION FROM:
action 1, numVisits=19172, meanQ=11.872146, numObservations: 9
action 4, numVisits=41, meanQ=8.633422, numObservations: 9
action 8, numVisits=6, meanQ=7.688350, numObservations: 4
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action 9, numVisits=3, meanQ=5.663333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-4.000000, numObservations: 1
action 7, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.617349 0.326605 0.870259 0.580523 0.431829 0.207264 0.282614 0.154814 0.631659 0.645289 0.0377274 0.655356 0.944626 0.588355 0.28157 0.957338 0.287561 0.441019 0.662359 0.531591 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 24
Initial state: 0 0.125723 0.182798 0.290125 0.759146 0.558687 0.116409 0.148633 0.203939 0.29193 0.642398 0.795039 0.517531 0.52573 0.927796 0.528858 0.33895 0.918876 0.120077 0.897705 0.861512 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19166 episodes
GETTING ACTION FROM:
action 4, numVisits=19148, meanQ=11.817614, numObservations: 9
action 3, numVisits=6, meanQ=8.998333, numObservations: 4
action 8, numVisits=3, meanQ=5.663333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 7, numVisits=1, meanQ=-4.000000, numObservations: 1
action 9, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.125723 0.182798 0.290125 0.759146 0.558687 0.116409 0.148633 0.203939 0.29193 0.642398 0.795039 0.517531 0.52573 0.927796 0.528858 0.33895 0.918876 0.120077 0.897705 0.861512 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=2265, meanQ=12.704188, numObservations: 9
action 9, numVisits=12, meanQ=10.707500, numObservations: 6
action 1, numVisits=4, meanQ=8.497500, numObservations: 4
action 2, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 7, numVisits=1, meanQ=-3.010000, numObservations: 1
action 8, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 4105 episodes
GETTING ACTION FROM:
action 5, numVisits=6325, meanQ=11.233028, numObservations: 9
action 9, numVisits=41, meanQ=8.380535, numObservations: 8
action 1, numVisits=6, meanQ=3.141792, numObservations: 5
action 2, numVisits=4, meanQ=2.038843, numObservations: 3
action 7, numVisits=6, meanQ=1.600058, numObservations: 5
action 0, numVisits=5, meanQ=-1.208000, numObservations: 5
action -1, numVisits=4, meanQ=-1.257500, numObservations: 4
action 8, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=2, meanQ=-516.430835, numObservations: 1
action: 5
Next state: 0 0.125723 0.182798 0.290125 0.759146 0.558687 0.116409 0.148633 0.203939 0.29193 0.642398 0.795039 0.517531 0.52573 0.927796 0.528858 0.33895 0.918876 0.120077 0.897705 0.861512 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=963, meanQ=12.054037, numObservations: 9
action 10, numVisits=11, meanQ=7.814545, numObservations: 8
action 5, numVisits=3, meanQ=5.993333, numObservations: 2
action 6, numVisits=3, meanQ=4.670033, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 8, numVisits=1, meanQ=-3.010000, numObservations: 1
action 9, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2980 episodes
GETTING ACTION FROM:
action 1, numVisits=3943, meanQ=12.994510, numObservations: 9
action 10, numVisits=11, meanQ=7.814545, numObservations: 8
action 5, numVisits=3, meanQ=5.993333, numObservations: 2
action 6, numVisits=3, meanQ=4.670033, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 8, numVisits=1, meanQ=-3.010000, numObservations: 1
action 9, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.125723 0.182798 0.290125 0.759146 0.558687 0.116409 0.148633 0.203939 0.29193 0.642398 0.795039 0.517531 0.52573 0.927796 0.528858 0.33895 0.918876 0.120077 0.897705 0.861512 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 5, numVisits=67, meanQ=14.980921, numObservations: 5
action 6, numVisits=285, meanQ=13.740198, numObservations: 9
action 8, numVisits=10, meanQ=10.799000, numObservations: 6
action 9, numVisits=6, meanQ=9.163333, numObservations: 5
action 2, numVisits=5, meanQ=5.651714, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 7, numVisits=1, meanQ=-3.010000, numObservations: 1
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 3851 episodes
GETTING ACTION FROM:
action 5, numVisits=71, meanQ=14.723499, numObservations: 5
action 6, numVisits=4116, meanQ=13.062471, numObservations: 9
action 9, numVisits=19, meanQ=10.380834, numObservations: 8
action 8, numVisits=11, meanQ=9.126302, numObservations: 7
action 2, numVisits=5, meanQ=5.651714, numObservations: 3
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 7, numVisits=1, meanQ=-3.010000, numObservations: 1
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.125723 0.182798 0.290125 0.759146 0.558687 0.116409 0.148633 0.203939 0.29193 0.642398 0.795039 0.517531 0.52573 0.927796 0.528858 0.33895 0.918876 0.120077 0.897705 0.861512 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 9, numVisits=4, meanQ=8.734072, numObservations: 3
action 6, numVisits=16, meanQ=7.189210, numObservations: 6
action 3, numVisits=3, meanQ=3.880213, numObservations: 3
action 10, numVisits=5, meanQ=3.209850, numObservations: 5
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 8, numVisits=1, meanQ=-3.010000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 6517 episodes
GETTING ACTION FROM:
action 6, numVisits=6531, meanQ=15.151301, numObservations: 9
action 9, numVisits=5, meanQ=4.787258, numObservations: 3
action 10, numVisits=5, meanQ=3.209850, numObservations: 5
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 8, numVisits=1, meanQ=-3.010000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=4, meanQ=-86.387463, numObservations: 3
action: 6
Next state: 1 0.125723 0.182798 0.290125 0.759146 0.558687 0.116409 0.148633 0.203939 0.29193 0.642398 0.795039 0.517531 0.52573 0.927796 0.528858 0.33895 0.918876 0.120077 0.897705 0.861512 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.29271
Run # 25
Initial state: 0 0.314848 0.413252 0.79738 0.416118 0.840608 0.284751 0.174384 0.848283 0.41591 0.206691 0.568235 0.359181 0.841354 0.613618 0.104637 0.0849373 0.351242 0.0814547 0.822591 0.836591 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19095 episodes
GETTING ACTION FROM:
action 5, numVisits=19049, meanQ=11.899726, numObservations: 9
action 4, numVisits=19, meanQ=10.267895, numObservations: 5
action 6, numVisits=10, meanQ=9.200010, numObservations: 7
action 10, numVisits=4, meanQ=8.250000, numObservations: 4
action 9, numVisits=2, meanQ=6.500000, numObservations: 2
action 1, numVisits=5, meanQ=5.022000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 7, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.314848 0.413252 0.79738 0.416118 0.840608 0.284751 0.174384 0.848283 0.41591 0.206691 0.568235 0.359181 0.841354 0.613618 0.104637 0.0849373 0.351242 0.0814547 0.822591 0.836591 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 10, numVisits=2308, meanQ=12.858455, numObservations: 9
action 2, numVisits=7, meanQ=7.140014, numObservations: 5
action 7, numVisits=4, meanQ=6.500000, numObservations: 4
action 3, numVisits=3, meanQ=5.993333, numObservations: 3
action 6, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 8, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 3218 episodes
GETTING ACTION FROM:
action 10, numVisits=5516, meanQ=11.548343, numObservations: 9
action 2, numVisits=8, meanQ=5.622525, numObservations: 5
action 3, numVisits=6, meanQ=3.945671, numObservations: 6
action 7, numVisits=5, meanQ=3.907174, numObservations: 5
action 6, numVisits=4, meanQ=2.770117, numObservations: 4
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.340000, numObservations: 3
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 8, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 10
Next state: 1 0.314848 0.413252 0.79738 0.416118 0.840608 0.284751 0.174384 0.848283 0.41591 0.206691 0.568235 0.359181 0.841354 0.613618 0.104637 0.0849373 0.351242 0.0814547 0.822591 0.836591 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 26
Initial state: 0 0.972077 0.0799383 0.493211 0.148043 0.228506 0.0184564 0.367314 0.392369 0.228841 0.17784 0.30662 0.959283 0.613101 0.301662 0.928735 0.922279 0.273777 0.403164 0.0818156 0.884941 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19106 episodes
GETTING ACTION FROM:
action 1, numVisits=19077, meanQ=11.841668, numObservations: 9
action 2, numVisits=4, meanQ=8.497500, numObservations: 4
action 9, numVisits=4, meanQ=8.250000, numObservations: 3
action 10, numVisits=9, meanQ=7.665567, numObservations: 5
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action 5, numVisits=2, meanQ=6.500000, numObservations: 1
action 7, numVisits=3, meanQ=5.663333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.972077 0.0799383 0.493211 0.148043 0.228506 0.0184564 0.367314 0.392369 0.228841 0.17784 0.30662 0.959283 0.613101 0.301662 0.928735 0.922279 0.273777 0.403164 0.0818156 0.884941 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 27
Initial state: 0 0.424321 0.651879 0.37481 0.584707 0.48704 0.154372 0.589495 0.357539 0.674185 0.783227 0.663028 0.418698 0.384877 0.145126 0.140798 0.117511 0.746591 0.664198 0.732425 0.690112 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19690 episodes
GETTING ACTION FROM:
action 4, numVisits=19640, meanQ=11.868952, numObservations: 9
action 3, numVisits=25, meanQ=9.118816, numObservations: 8
action 1, numVisits=13, meanQ=8.306177, numObservations: 6
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action 7, numVisits=3, meanQ=5.663333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action 9, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 4
Next state: 1 0.424321 0.651879 0.37481 0.584707 0.48704 0.154372 0.589495 0.357539 0.674185 0.783227 0.663028 0.418698 0.384877 0.145126 0.140798 0.117511 0.746591 0.664198 0.732425 0.690112 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 28
Initial state: 0 0.588783 0.399933 0.628464 0.588027 0.748263 0.956606 0.389805 0.907409 0.791887 0.527589 0.953364 0.792104 0.148339 0.633511 0.387267 0.107826 0.0201856 0.00406417 0.359155 0.99519 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19244 episodes
GETTING ACTION FROM:
action 8, numVisits=19218, meanQ=11.817433, numObservations: 9
action 3, numVisits=6, meanQ=4.331667, numObservations: 4
action 2, numVisits=11, meanQ=4.271827, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 9, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 8
Next state: 0 0.588783 0.399933 0.628464 0.588027 0.748263 0.956606 0.389805 0.907409 0.791887 0.527589 0.953364 0.792104 0.148339 0.633511 0.387267 0.107826 0.0201856 0.00406417 0.359155 0.99519 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 6, numVisits=2298, meanQ=12.744345, numObservations: 9
action 7, numVisits=6, meanQ=9.163333, numObservations: 5
action 5, numVisits=8, meanQ=8.497500, numObservations: 4
action 9, numVisits=4, meanQ=8.497500, numObservations: 3
action 1, numVisits=8, meanQ=8.497500, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 8, numVisits=1, meanQ=-3.010000, numObservations: 1
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 3352 episodes
GETTING ACTION FROM:
action 6, numVisits=5636, meanQ=11.653813, numObservations: 9
action 1, numVisits=14, meanQ=7.139747, numObservations: 7
action 5, numVisits=9, meanQ=6.331111, numObservations: 5
action 9, numVisits=6, meanQ=2.591453, numObservations: 4
action -1, numVisits=3, meanQ=-1.340000, numObservations: 3
action 0, numVisits=3, meanQ=-1.340000, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 8, numVisits=1, meanQ=-3.010000, numObservations: 1
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
action 7, numVisits=7, meanQ=-68.666740, numObservations: 5
action: 6
Next state: 1 0.588783 0.399933 0.628464 0.588027 0.748263 0.956606 0.389805 0.907409 0.791887 0.527589 0.953364 0.792104 0.148339 0.633511 0.387267 0.107826 0.0201856 0.00406417 0.359155 0.99519 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 29
Initial state: 0 0.595755 0.373561 0.714545 0.176822 0.848486 0.153269 0.156829 0.649808 0.839148 0.553904 0.510377 0.688407 0.265842 0.739973 0.0566267 0.0825503 0.386142 0.553289 0.561238 0.138207 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19634 episodes
GETTING ACTION FROM:
action 9, numVisits=19613, meanQ=11.976976, numObservations: 9
action 1, numVisits=6, meanQ=7.666667, numObservations: 5
action 8, numVisits=2, meanQ=6.500000, numObservations: 2
action 10, numVisits=3, meanQ=5.663333, numObservations: 3
action 6, numVisits=3, meanQ=4.340033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 9
Next state: 0 0.595755 0.373561 0.714545 0.176822 0.848486 0.153269 0.156829 0.649808 0.839148 0.553904 0.510377 0.688407 0.265842 0.739973 0.0566267 0.0825503 0.386142 0.553289 0.561238 0.138207 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=2280, meanQ=13.399486, numObservations: 9
action 6, numVisits=4, meanQ=8.497500, numObservations: 4
action 7, numVisits=5, meanQ=6.196000, numObservations: 5
action 8, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 9, numVisits=1, meanQ=-3.010000, numObservations: 1
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 3852 episodes
GETTING ACTION FROM:
action 5, numVisits=3265, meanQ=12.690253, numObservations: 9
action 8, numVisits=2864, meanQ=12.602070, numObservations: 9
action 6, numVisits=5, meanQ=4.598000, numObservations: 5
action 7, numVisits=6, meanQ=3.330000, numObservations: 5
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.340000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 9, numVisits=1, meanQ=-3.010000, numObservations: 1
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 1 0.595755 0.373561 0.714545 0.176822 0.848486 0.153269 0.156829 0.649808 0.839148 0.553904 0.510377 0.688407 0.265842 0.739973 0.0566267 0.0825503 0.386142 0.553289 0.561238 0.138207 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 30
Initial state: 0 0.560858 0.307501 0.879307 0.826295 0.969769 0.97387 0.51357 0.609543 0.891715 0.758027 0.790256 0.641756 0.324635 0.509126 0.63726 0.440504 0.533531 0.577599 0.770161 0.470242 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18632 episodes
GETTING ACTION FROM:
action 10, numVisits=18601, meanQ=12.142129, numObservations: 9
action 8, numVisits=11, meanQ=10.000000, numObservations: 7
action 9, numVisits=4, meanQ=8.250000, numObservations: 4
action 7, numVisits=7, meanQ=7.574300, numObservations: 5
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 10
Next state: 2 0.560858 0.307501 0.879307 0.826295 0.969769 0.97387 0.51357 0.609543 0.891715 0.758027 0.790256 0.641756 0.324635 0.509126 0.63726 0.440504 0.533531 0.577599 0.770161 0.470242 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
[32m ProblemEnvironment.hpp 351: Done.[39m
