Run # 1
Initial state: 0 0.420378 0.778741 0.52896 0.188187 0.694377 0.169478 0.6883 0.98527 0.359536 0.353027 0.718329 0.271172 0.214761 0.469849 0.875527 0.620673 0.199114 0.471186 0.859931 0.769403 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18771 episodes
GETTING ACTION FROM:
action 2, numVisits=18744, meanQ=11.323121, numObservations: 9
action 7, numVisits=16, meanQ=8.130625, numObservations: 8
action 4, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action 9, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.420378 0.778741 0.52896 0.188187 0.694377 0.169478 0.6883 0.98527 0.359536 0.353027 0.718329 0.271172 0.214761 0.469849 0.875527 0.620673 0.199114 0.471186 0.859931 0.769403 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 2
Initial state: 0 0.377853 0.378623 0.270927 0.59376 0.49625 0.035625 0.650692 0.309485 0.852903 0.128924 0.0288 0.58013 0.924019 0.613673 0.168441 0.846537 0.930488 0.403098 0.59482 0.551756 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18627 episodes
GETTING ACTION FROM:
action 7, numVisits=18601, meanQ=11.517484, numObservations: 9
action 3, numVisits=11, meanQ=8.727273, numObservations: 6
action 1, numVisits=4, meanQ=8.250000, numObservations: 3
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action 6, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 7
Next state: 1 0.377853 0.378623 0.270927 0.59376 0.49625 0.035625 0.650692 0.309485 0.852903 0.128924 0.0288 0.58013 0.924019 0.613673 0.168441 0.846537 0.930488 0.403098 0.59482 0.551756 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 3
Initial state: 0 0.828609 0.0986084 0.512557 0.568455 0.0566927 0.196757 0.169678 0.50838 0.656844 0.953352 0.107726 0.701268 0.818363 0.835836 0.35796 0.229437 0.359662 0.346289 0.926514 0.717189 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19315 episodes
GETTING ACTION FROM:
action 1, numVisits=19226, meanQ=11.514285, numObservations: 9
action 4, numVisits=57, meanQ=10.172112, numObservations: 9
action 3, numVisits=17, meanQ=8.939412, numObservations: 7
action 6, numVisits=4, meanQ=6.500000, numObservations: 3
action 8, numVisits=2, meanQ=6.500000, numObservations: 2
action 5, numVisits=3, meanQ=5.663333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 10, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.828609 0.0986084 0.512557 0.568455 0.0566927 0.196757 0.169678 0.50838 0.656844 0.953352 0.107726 0.701268 0.818363 0.835836 0.35796 0.229437 0.359662 0.346289 0.926514 0.717189 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 4
Initial state: 0 0.471058 0.337822 0.0625749 0.871296 0.706142 0.433555 0.215043 0.296615 0.807313 0.167327 0.683601 0.592812 0.787208 0.892567 0.587802 0.494185 0.739571 0.150247 0.378155 0.429032 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19229 episodes
GETTING ACTION FROM:
action 10, numVisits=19033, meanQ=11.327406, numObservations: 9
action 4, numVisits=138, meanQ=10.709709, numObservations: 9
action 1, numVisits=28, meanQ=9.999646, numObservations: 8
action 3, numVisits=13, meanQ=9.075385, numObservations: 5
action 9, numVisits=8, meanQ=7.498750, numObservations: 4
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 10
Next state: 2 0.471058 0.337822 0.0625749 0.871296 0.706142 0.433555 0.215043 0.296615 0.807313 0.167327 0.683601 0.592812 0.787208 0.892567 0.587802 0.494185 0.739571 0.150247 0.378155 0.429032 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 5
Initial state: 0 0.0560552 0.511394 0.154077 0.521741 0.381806 0.116276 0.8194 0.962713 0.413977 0.876116 0.470956 0.406096 0.151022 0.622834 0.885443 0.724564 0.27149 0.157671 0.476575 0.970254 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18375 episodes
GETTING ACTION FROM:
action 3, numVisits=18358, meanQ=11.065715, numObservations: 9
action 7, numVisits=2, meanQ=6.500000, numObservations: 2
action 10, numVisits=2, meanQ=6.500000, numObservations: 2
action 2, numVisits=3, meanQ=4.340033, numObservations: 2
action 5, numVisits=3, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-4.000000, numObservations: 1
action 9, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.0560552 0.511394 0.154077 0.521741 0.381806 0.116276 0.8194 0.962713 0.413977 0.876116 0.470956 0.406096 0.151022 0.622834 0.885443 0.724564 0.27149 0.157671 0.476575 0.970254 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 6
Initial state: 0 0.87655 0.517254 0.0730564 0.0173482 0.401143 0.190898 0.456947 0.348249 0.538951 0.0804958 0.880711 0.263071 0.465068 0.00837539 0.193696 0.98871 0.992344 0.832376 0.757292 0.618556 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19074 episodes
GETTING ACTION FROM:
action 7, numVisits=19047, meanQ=11.327718, numObservations: 9
action 3, numVisits=10, meanQ=7.553010, numObservations: 5
action 10, numVisits=4, meanQ=6.500000, numObservations: 3
action 8, numVisits=3, meanQ=3.000000, numObservations: 2
action 9, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 7
Next state: 2 0.87655 0.517254 0.0730564 0.0173482 0.401143 0.190898 0.456947 0.348249 0.538951 0.0804958 0.880711 0.263071 0.465068 0.00837539 0.193696 0.98871 0.992344 0.832376 0.757292 0.618556 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 7
Initial state: 0 0.810552 0.00721703 0.162391 0.679188 0.0395741 0.970087 0.174964 0.18281 0.542123 0.143613 0.34679 0.360616 0.731306 0.649455 0.58246 0.247734 0.697472 0.630833 0.0867674 0.736956 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19289 episodes
GETTING ACTION FROM:
action 4, numVisits=19272, meanQ=11.594174, numObservations: 9
action 5, numVisits=4, meanQ=6.500000, numObservations: 3
action 8, numVisits=2, meanQ=6.500000, numObservations: 2
action 9, numVisits=2, meanQ=6.500000, numObservations: 2
action 10, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.810552 0.00721703 0.162391 0.679188 0.0395741 0.970087 0.174964 0.18281 0.542123 0.143613 0.34679 0.360616 0.731306 0.649455 0.58246 0.247734 0.697472 0.630833 0.0867674 0.736956 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 9, numVisits=1269, meanQ=13.051774, numObservations: 9
action 8, numVisits=10, meanQ=8.897000, numObservations: 5
action 5, numVisits=4, meanQ=8.497500, numObservations: 3
action 7, numVisits=4, meanQ=8.497500, numObservations: 2
action 3, numVisits=6, meanQ=7.831667, numObservations: 3
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 6322 episodes
GETTING ACTION FROM:
action 9, numVisits=7478, meanQ=10.759922, numObservations: 9
action 8, numVisits=26, meanQ=7.652696, numObservations: 8
action 3, numVisits=15, meanQ=6.266007, numObservations: 7
action 7, numVisits=5, meanQ=4.598000, numObservations: 2
action 2, numVisits=3, meanQ=0.666667, numObservations: 2
action 5, numVisits=86, meanQ=-0.831474, numObservations: 9
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action -1, numVisits=3, meanQ=-1.340000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 9
Next state: 1 0.810552 0.00721703 0.162391 0.679188 0.0395741 0.970087 0.174964 0.18281 0.542123 0.143613 0.34679 0.360616 0.731306 0.649455 0.58246 0.247734 0.697472 0.630833 0.0867674 0.736956 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 8
Initial state: 0 0.0188125 0.624555 0.725006 0.104699 0.921839 0.424942 0.750384 0.268947 0.0442252 0.0866787 0.366291 0.338678 0.81833 0.196666 0.276078 0.677369 0.500638 0.674619 0.601185 0.887329 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18556 episodes
GETTING ACTION FROM:
action 4, numVisits=18511, meanQ=11.555023, numObservations: 9
action 10, numVisits=23, meanQ=10.076526, numObservations: 8
action 9, numVisits=10, meanQ=7.999000, numObservations: 6
action 6, numVisits=2, meanQ=6.500000, numObservations: 2
action 3, numVisits=3, meanQ=5.663333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 7, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.0188125 0.624555 0.725006 0.104699 0.921839 0.424942 0.750384 0.268947 0.0442252 0.0866787 0.366291 0.338678 0.81833 0.196666 0.276078 0.677369 0.500638 0.674619 0.601185 0.887329 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 9
Initial state: 0 0.632095 0.0181352 0.512222 0.0215884 0.542172 0.729419 0.231506 0.512267 0.202591 0.948127 0.357794 0.440481 0.456992 0.328569 0.0590228 0.0605608 0.163692 0.588311 0.607213 0.0911444 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19622 episodes
GETTING ACTION FROM:
action 2, numVisits=19585, meanQ=11.538241, numObservations: 9
action 9, numVisits=22, meanQ=8.778186, numObservations: 5
action 8, numVisits=5, meanQ=7.596000, numObservations: 4
action 6, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 7, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.632095 0.0181352 0.512222 0.0215884 0.542172 0.729419 0.231506 0.512267 0.202591 0.948127 0.357794 0.440481 0.456992 0.328569 0.0590228 0.0605608 0.163692 0.588311 0.607213 0.0911444 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 10
Initial state: 0 0.455989 0.59867 0.0818269 0.872845 0.803516 0.583473 0.912098 0.798415 0.946832 0.92191 0.671939 0.29184 0.820459 0.178666 0.172224 0.9454 0.783378 0.717271 0.344574 0.40873 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 16859 episodes
GETTING ACTION FROM:
action 6, numVisits=13308, meanQ=11.541233, numObservations: 9
action 10, numVisits=3530, meanQ=11.371852, numObservations: 9
action 1, numVisits=8, meanQ=9.125000, numObservations: 6
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action 5, numVisits=3, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 6
Next state: 2 0.455989 0.59867 0.0818269 0.872845 0.803516 0.583473 0.912098 0.798415 0.946832 0.92191 0.671939 0.29184 0.820459 0.178666 0.172224 0.9454 0.783378 0.717271 0.344574 0.40873 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 11
Initial state: 0 0.00403075 0.120981 0.472562 0.361121 0.514088 0.611795 0.0827655 0.299691 0.107015 0.769181 0.554557 0.58451 0.670403 0.927292 0.0285914 0.731162 0.902563 0.101109 0.462088 0.764485 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19838 episodes
GETTING ACTION FROM:
action 4, numVisits=5594, meanQ=11.618575, numObservations: 9
action 1, numVisits=14216, meanQ=11.584049, numObservations: 9
action 6, numVisits=15, meanQ=9.207340, numObservations: 8
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action 8, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 9, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-4.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.00403075 0.120981 0.472562 0.361121 0.514088 0.611795 0.0827655 0.299691 0.107015 0.769181 0.554557 0.58451 0.670403 0.927292 0.0285914 0.731162 0.902563 0.101109 0.462088 0.764485 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 7, numVisits=343, meanQ=11.599993, numObservations: 9
action 2, numVisits=34, meanQ=8.352359, numObservations: 9
action 9, numVisits=6, meanQ=7.183333, numObservations: 5
action 1, numVisits=9, meanQ=6.345567, numObservations: 6
action 6, numVisits=5, meanQ=4.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 8, numVisits=1, meanQ=-3.010000, numObservations: 1
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 7344 episodes
GETTING ACTION FROM:
action 7, numVisits=7679, meanQ=11.021246, numObservations: 9
action 2, numVisits=34, meanQ=8.352359, numObservations: 9
action 9, numVisits=10, meanQ=6.910000, numObservations: 5
action 1, numVisits=9, meanQ=6.345567, numObservations: 6
action 6, numVisits=5, meanQ=4.598000, numObservations: 2
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 8, numVisits=1, meanQ=-3.010000, numObservations: 1
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 7
Next state: 1 0.00403075 0.120981 0.472562 0.361121 0.514088 0.611795 0.0827655 0.299691 0.107015 0.769181 0.554557 0.58451 0.670403 0.927292 0.0285914 0.731162 0.902563 0.101109 0.462088 0.764485 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 12
Initial state: 0 0.236175 0.79594 0.753824 0.300824 0.714936 0.137571 0.558853 0.712919 0.602058 0.434177 0.55885 0.154381 0.456633 0.397594 0.091435 0.658296 0.628274 0.107987 0.755913 0.142022 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19429 episodes
GETTING ACTION FROM:
action 8, numVisits=19388, meanQ=11.373764, numObservations: 9
action 1, numVisits=19, meanQ=9.803158, numObservations: 9
action 7, numVisits=4, meanQ=8.250000, numObservations: 3
action 2, numVisits=6, meanQ=6.500000, numObservations: 2
action 6, numVisits=2, meanQ=6.500000, numObservations: 2
action 9, numVisits=2, meanQ=6.500000, numObservations: 2
action 4, numVisits=3, meanQ=5.000033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 8
Next state: 0 0.236175 0.79594 0.753824 0.300824 0.714936 0.137571 0.558853 0.712919 0.602058 0.434177 0.55885 0.154381 0.456633 0.397594 0.091435 0.658296 0.628274 0.107987 0.755913 0.142022 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 10, numVisits=1930, meanQ=11.925664, numObservations: 9
action 4, numVisits=44, meanQ=8.510230, numObservations: 9
action 1, numVisits=10, meanQ=7.299000, numObservations: 4
action 6, numVisits=15, meanQ=6.931333, numObservations: 7
action 3, numVisits=3, meanQ=5.993333, numObservations: 3
action 7, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 8, numVisits=1, meanQ=-3.010000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 6930 episodes
GETTING ACTION FROM:
action 10, numVisits=8833, meanQ=13.370562, numObservations: 9
action 3, numVisits=27, meanQ=10.318199, numObservations: 8
action 4, numVisits=44, meanQ=8.510230, numObservations: 9
action 1, numVisits=10, meanQ=7.299000, numObservations: 4
action 6, numVisits=15, meanQ=6.931333, numObservations: 7
action 7, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=3, meanQ=-1.340000, numObservations: 3
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 8, numVisits=1, meanQ=-3.010000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 10
Next state: 2 0.236175 0.79594 0.753824 0.300824 0.714936 0.137571 0.558853 0.712919 0.602058 0.434177 0.55885 0.154381 0.456633 0.397594 0.091435 0.658296 0.628274 0.107987 0.755913 0.142022 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 13
Initial state: 0 0.781599 0.629049 0.478482 0.299279 0.0520349 0.211028 0.497353 0.0773451 0.813244 0.511057 0.00526987 0.286012 0.667063 0.954242 0.422536 0.752804 0.301047 0.380625 0.538813 0.175994 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18285 episodes
GETTING ACTION FROM:
action 8, numVisits=18264, meanQ=11.433961, numObservations: 9
action 2, numVisits=4, meanQ=8.250000, numObservations: 2
action 10, numVisits=4, meanQ=8.250000, numObservations: 3
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action 4, numVisits=2, meanQ=6.500000, numObservations: 2
action 6, numVisits=3, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 9, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 8
Next state: 1 0.781599 0.629049 0.478482 0.299279 0.0520349 0.211028 0.497353 0.0773451 0.813244 0.511057 0.00526987 0.286012 0.667063 0.954242 0.422536 0.752804 0.301047 0.380625 0.538813 0.175994 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 14
Initial state: 0 0.701126 0.662823 0.817673 0.707159 0.247295 0.273028 0.839482 0.226512 0.711856 0.859251 0.579074 0.0838554 0.136485 0.477283 0.195739 0.866902 0.346853 0.410543 0.509064 0.960549 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18968 episodes
GETTING ACTION FROM:
action 1, numVisits=18949, meanQ=11.271224, numObservations: 9
action 7, numVisits=3, meanQ=5.333333, numObservations: 3
action 9, numVisits=5, meanQ=4.400000, numObservations: 2
action 5, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.701126 0.662823 0.817673 0.707159 0.247295 0.273028 0.839482 0.226512 0.711856 0.859251 0.579074 0.0838554 0.136485 0.477283 0.195739 0.866902 0.346853 0.410543 0.509064 0.960549 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 15
Initial state: 0 0.539317 0.888841 0.80174 0.797134 0.671319 0.253152 0.84652 0.399394 0.0378248 0.04689 0.856589 0.864723 0.67343 0.123532 0.445516 0.332572 0.86363 0.605327 0.11175 0.923425 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19145 episodes
GETTING ACTION FROM:
action 7, numVisits=19108, meanQ=11.643426, numObservations: 9
action 4, numVisits=13, meanQ=7.824615, numObservations: 8
action 1, numVisits=8, meanQ=7.498750, numObservations: 5
action 10, numVisits=2, meanQ=6.500000, numObservations: 2
action 8, numVisits=3, meanQ=5.333333, numObservations: 3
action 9, numVisits=3, meanQ=5.000033, numObservations: 2
action 3, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 7
Next state: 2 0.539317 0.888841 0.80174 0.797134 0.671319 0.253152 0.84652 0.399394 0.0378248 0.04689 0.856589 0.864723 0.67343 0.123532 0.445516 0.332572 0.86363 0.605327 0.11175 0.923425 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 16
Initial state: 0 0.58917 0.330328 0.987244 0.313691 0.664785 0.807913 0.392453 0.78374 0.257513 0.741766 0.915571 0.336424 0.100729 0.674315 0.906004 0.456006 0.429391 0.314968 0.559618 0.468295 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19932 episodes
GETTING ACTION FROM:
action 6, numVisits=19890, meanQ=11.432257, numObservations: 9
action 1, numVisits=9, meanQ=7.108889, numObservations: 6
action 8, numVisits=8, meanQ=6.622513, numObservations: 6
action 7, numVisits=6, meanQ=5.166683, numObservations: 4
action 5, numVisits=8, meanQ=4.748763, numObservations: 5
action 2, numVisits=5, meanQ=4.400000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 6
Next state: 2 0.58917 0.330328 0.987244 0.313691 0.664785 0.807913 0.392453 0.78374 0.257513 0.741766 0.915571 0.336424 0.100729 0.674315 0.906004 0.456006 0.429391 0.314968 0.559618 0.468295 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 17
Initial state: 0 0.275907 0.545328 0.370354 0.449415 0.809485 0.9344 0.048786 0.643951 0.389199 0.3758 0.577123 0.489401 0.638084 0.493856 0.57678 0.29944 0.719938 0.21622 0.293966 0.574071 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19085 episodes
GETTING ACTION FROM:
action 10, numVisits=19036, meanQ=11.387121, numObservations: 9
action 1, numVisits=13, meanQ=8.384615, numObservations: 6
action 2, numVisits=11, meanQ=8.270909, numObservations: 7
action 8, numVisits=6, meanQ=7.666667, numObservations: 5
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action 4, numVisits=2, meanQ=6.500000, numObservations: 2
action 5, numVisits=8, meanQ=6.500000, numObservations: 6
action 9, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 7, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 10
Next state: 2 0.275907 0.545328 0.370354 0.449415 0.809485 0.9344 0.048786 0.643951 0.389199 0.3758 0.577123 0.489401 0.638084 0.493856 0.57678 0.29944 0.719938 0.21622 0.293966 0.574071 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 18
Initial state: 0 0.686293 0.429967 0.57642 0.159469 0.747557 0.633622 0.88399 0.68549 0.769666 0.417976 0.553278 0.664512 0.276444 0.719045 0.459903 0.393093 0.533251 0.791357 0.364677 0.277411 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18911 episodes
GETTING ACTION FROM:
action 3, numVisits=18875, meanQ=11.639072, numObservations: 9
action 10, numVisits=12, meanQ=8.331675, numObservations: 7
action 8, numVisits=7, meanQ=7.141429, numObservations: 6
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action 7, numVisits=2, meanQ=6.500000, numObservations: 2
action 6, numVisits=5, meanQ=5.204020, numObservations: 3
action 4, numVisits=3, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 9, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.686293 0.429967 0.57642 0.159469 0.747557 0.633622 0.88399 0.68549 0.769666 0.417976 0.553278 0.664512 0.276444 0.719045 0.459903 0.393093 0.533251 0.791357 0.364677 0.277411 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 19
Initial state: 0 0.546186 0.618569 0.157299 0.752572 0.95437 0.251228 0.332989 0.349157 0.997587 0.423346 0.62117 0.877143 0.100588 0.689681 0.508663 0.250958 0.748733 0.406618 0.927722 0.102879 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17762 episodes
GETTING ACTION FROM:
action 5, numVisits=17745, meanQ=11.535965, numObservations: 9
action 3, numVisits=6, meanQ=7.018333, numObservations: 4
action 7, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.546186 0.618569 0.157299 0.752572 0.95437 0.251228 0.332989 0.349157 0.997587 0.423346 0.62117 0.877143 0.100588 0.689681 0.508663 0.250958 0.748733 0.406618 0.927722 0.102879 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 20
Initial state: 0 0.951308 0.549453 0.756748 0.773754 0.830687 0.430666 0.317504 0.316711 0.18666 0.155999 0.988478 0.875311 0.122831 0.423449 0.235639 0.840108 0.237804 0.531722 0.132376 0.304109 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19184 episodes
GETTING ACTION FROM:
action 4, numVisits=19161, meanQ=11.476943, numObservations: 9
action 3, numVisits=4, meanQ=8.250000, numObservations: 3
action 2, numVisits=5, meanQ=7.200000, numObservations: 5
action 9, numVisits=4, meanQ=6.500000, numObservations: 3
action 8, numVisits=3, meanQ=5.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.951308 0.549453 0.756748 0.773754 0.830687 0.430666 0.317504 0.316711 0.18666 0.155999 0.988478 0.875311 0.122831 0.423449 0.235639 0.840108 0.237804 0.531722 0.132376 0.304109 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 21
Initial state: 0 0.22595 0.463502 0.023934 0.526455 0.812026 0.481537 0.667157 0.161247 0.693394 0.749201 0.288827 0.780807 0.403293 0.671945 0.273852 0.666884 0.411512 0.333501 0.692496 0.130844 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19375 episodes
GETTING ACTION FROM:
action 1, numVisits=11490, meanQ=11.401608, numObservations: 9
action 6, numVisits=7850, meanQ=11.352798, numObservations: 9
action 8, numVisits=20, meanQ=9.299505, numObservations: 7
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action 9, numVisits=4, meanQ=6.500000, numObservations: 4
action 5, numVisits=3, meanQ=5.663333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 7, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.22595 0.463502 0.023934 0.526455 0.812026 0.481537 0.667157 0.161247 0.693394 0.749201 0.288827 0.780807 0.403293 0.671945 0.273852 0.666884 0.411512 0.333501 0.692496 0.130844 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 9, numVisits=1194, meanQ=12.520897, numObservations: 9
action 8, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 6301 episodes
GETTING ACTION FROM:
action 9, numVisits=7493, meanQ=13.990362, numObservations: 9
action 8, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 9
Next state: 1 0.22595 0.463502 0.023934 0.526455 0.812026 0.481537 0.667157 0.161247 0.693394 0.749201 0.288827 0.780807 0.403293 0.671945 0.273852 0.666884 0.411512 0.333501 0.692496 0.130844 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 22
Initial state: 0 0.27423 0.584583 0.543954 0.310358 0.100948 0.396255 0.868542 0.885524 0.429615 0.368026 0.283791 0.547093 0.553297 0.981722 0.784388 0.178474 0.169687 0.4325 0.0616932 0.941106 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19469 episodes
GETTING ACTION FROM:
action 7, numVisits=19455, meanQ=11.386966, numObservations: 9
action 6, numVisits=4, meanQ=6.500000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 7
Next state: 1 0.27423 0.584583 0.543954 0.310358 0.100948 0.396255 0.868542 0.885524 0.429615 0.368026 0.283791 0.547093 0.553297 0.981722 0.784388 0.178474 0.169687 0.4325 0.0616932 0.941106 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 23
Initial state: 0 0.00471206 0.742863 0.135943 0.990475 0.186351 0.683713 0.508238 0.932403 0.384433 0.362717 0.812098 0.74545 0.0953086 0.89181 0.0723716 0.712522 0.0176749 0.781286 0.385229 0.646029 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19508 episodes
GETTING ACTION FROM:
action 6, numVisits=19393, meanQ=11.376469, numObservations: 9
action 5, numVisits=51, meanQ=7.231969, numObservations: 9
action 7, numVisits=33, meanQ=6.696682, numObservations: 8
action 10, numVisits=19, meanQ=6.394211, numObservations: 8
action 2, numVisits=3, meanQ=5.333333, numObservations: 3
action 3, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 6
Next state: 1 0.00471206 0.742863 0.135943 0.990475 0.186351 0.683713 0.508238 0.932403 0.384433 0.362717 0.812098 0.74545 0.0953086 0.89181 0.0723716 0.712522 0.0176749 0.781286 0.385229 0.646029 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 24
Initial state: 0 0.858986 0.160792 0.493554 0.577911 0.269062 0.0214474 0.540624 0.700552 0.54751 0.954044 0.471901 0.335557 0.18719 0.639795 0.0840344 0.17988 0.847152 0.735351 0.714754 0.361646 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19985 episodes
GETTING ACTION FROM:
action 8, numVisits=19903, meanQ=11.547074, numObservations: 9
action 10, numVisits=56, meanQ=10.346970, numObservations: 9
action 6, numVisits=9, meanQ=9.332222, numObservations: 5
action 5, numVisits=6, meanQ=8.833333, numObservations: 4
action 3, numVisits=4, meanQ=8.250000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 7, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 8
Next state: 0 0.858986 0.160792 0.493554 0.577911 0.269062 0.0214474 0.540624 0.700552 0.54751 0.954044 0.471901 0.335557 0.18719 0.639795 0.0840344 0.17988 0.847152 0.735351 0.714754 0.361646 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 10, numVisits=371, meanQ=12.955591, numObservations: 9
action 3, numVisits=3, meanQ=5.993333, numObservations: 3
action 4, numVisits=8, meanQ=5.871263, numObservations: 5
action 2, numVisits=5, meanQ=4.598000, numObservations: 5
action 5, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 6, numVisits=1, meanQ=-3.010000, numObservations: 1
action 7, numVisits=1, meanQ=-3.010000, numObservations: 1
action 9, numVisits=1, meanQ=-3.010000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 18638 episodes
GETTING ACTION FROM:
action 2, numVisits=17169, meanQ=9.594927, numObservations: 9
action 10, numVisits=1833, meanQ=9.060327, numObservations: 9
action 4, numVisits=13, meanQ=4.766931, numObservations: 5
action 3, numVisits=4, meanQ=1.745000, numObservations: 3
action 5, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=4, meanQ=-1.505000, numObservations: 4
action 0, numVisits=4, meanQ=-1.752500, numObservations: 4
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 6, numVisits=1, meanQ=-3.010000, numObservations: 1
action 7, numVisits=1, meanQ=-3.010000, numObservations: 1
action 9, numVisits=1, meanQ=-3.010000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.858986 0.160792 0.493554 0.577911 0.269062 0.0214474 0.540624 0.700552 0.54751 0.954044 0.471901 0.335557 0.18719 0.639795 0.0840344 0.17988 0.847152 0.735351 0.714754 0.361646 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 25
Initial state: 0 0.102123 0.269006 0.529451 0.765128 0.897622 0.71812 0.873039 0.483856 0.796678 0.259846 0.442257 0.134453 0.154444 0.140146 0.413156 0.387854 0.0704175 0.212813 0.30229 0.545534 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18624 episodes
GETTING ACTION FROM:
action 9, numVisits=18603, meanQ=11.360179, numObservations: 9
action 1, numVisits=10, meanQ=7.476000, numObservations: 5
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 6, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 9
Next state: 0 0.102123 0.269006 0.529451 0.765128 0.897622 0.71812 0.873039 0.483856 0.796678 0.259846 0.442257 0.134453 0.154444 0.140146 0.413156 0.387854 0.0704175 0.212813 0.30229 0.545534 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 6, numVisits=1250, meanQ=12.295901, numObservations: 9
action 7, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 9, numVisits=1, meanQ=-3.010000, numObservations: 1
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 6442 episodes
GETTING ACTION FROM:
action 6, numVisits=7690, meanQ=10.878619, numObservations: 9
action 7, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 9, numVisits=1, meanQ=-3.010000, numObservations: 1
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 6
Next state: 0 0.102123 0.269006 0.529451 0.765128 0.897622 0.71812 0.873039 0.483856 0.796678 0.259846 0.442257 0.134453 0.154444 0.140146 0.413156 0.387854 0.0704175 0.212813 0.30229 0.545534 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=55, meanQ=10.737943, numObservations: 9
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 6, numVisits=1, meanQ=-3.010000, numObservations: 1
action 9, numVisits=1, meanQ=-3.010000, numObservations: 1
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 10278 episodes
GETTING ACTION FROM:
action 1, numVisits=10323, meanQ=9.194146, numObservations: 9
action 0, numVisits=7, meanQ=-1.575714, numObservations: 7
action -1, numVisits=7, meanQ=-1.717143, numObservations: 7
action 6, numVisits=1, meanQ=-3.010000, numObservations: 1
action 9, numVisits=1, meanQ=-3.010000, numObservations: 1
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.102123 0.269006 0.529451 0.765128 0.897622 0.71812 0.873039 0.483856 0.796678 0.259846 0.442257 0.134453 0.154444 0.140146 0.413156 0.387854 0.0704175 0.212813 0.30229 0.545534 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=45, meanQ=13.888889, numObservations: 8
action 7, numVisits=15, meanQ=9.646208, numObservations: 5
action 4, numVisits=2, meanQ=5.361192, numObservations: 1
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action -1, numVisits=2, meanQ=-6.890631, numObservations: 1
action 1, numVisits=1, meanQ=-9.684896, numObservations: 1
action 2, numVisits=1, meanQ=-10.377030, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.613123, numObservations: 1
action 6, numVisits=1, meanQ=-518.638439, numObservations: 1
Sampled 10539 episodes
GETTING ACTION FROM:
action 7, numVisits=10112, meanQ=9.166593, numObservations: 9
action 3, numVisits=475, meanQ=7.785264, numObservations: 9
action 4, numVisits=3, meanQ=-0.092538, numObservations: 2
action 0, numVisits=13, meanQ=-1.771538, numObservations: 13
action -1, numVisits=2, meanQ=-6.890631, numObservations: 1
action 1, numVisits=1, meanQ=-9.684896, numObservations: 1
action 2, numVisits=1, meanQ=-10.377030, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.613123, numObservations: 1
action 6, numVisits=1, meanQ=-518.638439, numObservations: 1
action: 7
Next state: 2 0.102123 0.269006 0.529451 0.765128 0.897622 0.71812 0.873039 0.483856 0.796678 0.259846 0.442257 0.134453 0.154444 0.140146 0.413156 0.387854 0.0704175 0.212813 0.30229 0.545534 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -22.5537
Run # 26
Initial state: 0 0.354048 0.888046 0.55909 0.861445 0.536066 0.581398 0.915736 0.038124 0.711866 0.143068 0.359983 0.321313 0.185604 0.89803 0.528756 0.569293 0.0213534 0.291061 0.659677 0.638125 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19786 episodes
GETTING ACTION FROM:
action 5, numVisits=19739, meanQ=11.347823, numObservations: 9
action 7, numVisits=24, meanQ=9.713754, numObservations: 8
action 3, numVisits=8, meanQ=8.373750, numObservations: 6
action 6, numVisits=4, meanQ=7.277500, numObservations: 2
action 9, numVisits=2, meanQ=6.500000, numObservations: 1
action 8, numVisits=3, meanQ=5.663333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.354048 0.888046 0.55909 0.861445 0.536066 0.581398 0.915736 0.038124 0.711866 0.143068 0.359983 0.321313 0.185604 0.89803 0.528756 0.569293 0.0213534 0.291061 0.659677 0.638125 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 27
Initial state: 0 0.554783 0.293746 0.268701 0.0739508 0.895187 0.138792 0.510201 0.629122 0.274654 0.602855 0.189999 0.277443 0.379409 0.402704 0.627023 0.516299 0.802032 0.98024 0.377743 0.835054 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19304 episodes
GETTING ACTION FROM:
action 6, numVisits=19263, meanQ=11.542165, numObservations: 9
action 1, numVisits=23, meanQ=8.244352, numObservations: 9
action 9, numVisits=5, meanQ=7.198020, numObservations: 4
action 2, numVisits=5, meanQ=5.998000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 7, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 6
Next state: 0 0.554783 0.293746 0.268701 0.0739508 0.895187 0.138792 0.510201 0.629122 0.274654 0.602855 0.189999 0.277443 0.379409 0.402704 0.627023 0.516299 0.802032 0.98024 0.377743 0.835054 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=274, meanQ=12.949020, numObservations: 9
action 4, numVisits=6, meanQ=7.831667, numObservations: 3
action 7, numVisits=12, meanQ=7.831667, numObservations: 7
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 6, numVisits=1, meanQ=-3.010000, numObservations: 1
action 9, numVisits=1, meanQ=-3.010000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 7296 episodes
GETTING ACTION FROM:
action 1, numVisits=7426, meanQ=9.781887, numObservations: 9
action 4, numVisits=92, meanQ=9.207095, numObservations: 9
action 7, numVisits=16, meanQ=7.498750, numObservations: 8
action -1, numVisits=5, meanQ=-1.406000, numObservations: 5
action 0, numVisits=5, meanQ=-1.604000, numObservations: 5
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 6, numVisits=1, meanQ=-3.010000, numObservations: 1
action 9, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=48, meanQ=-10.819145, numObservations: 9
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.554783 0.293746 0.268701 0.0739508 0.895187 0.138792 0.510201 0.629122 0.274654 0.602855 0.189999 0.277443 0.379409 0.402704 0.627023 0.516299 0.802032 0.98024 0.377743 0.835054 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 28
Initial state: 0 0.150386 0.453049 0.869008 0.165501 0.760673 0.908515 0.299184 0.657008 0.00959312 0.417543 0.0867697 0.602588 0.40804 0.38182 0.756951 0.857613 0.28422 0.49757 0.117114 0.00788329 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18192 episodes
GETTING ACTION FROM:
action 8, numVisits=18152, meanQ=11.147696, numObservations: 9
action 10, numVisits=23, meanQ=8.093052, numObservations: 8
action 9, numVisits=2, meanQ=6.500000, numObservations: 2
action 7, numVisits=5, meanQ=5.600020, numObservations: 3
action 2, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 8
Next state: 1 0.150386 0.453049 0.869008 0.165501 0.760673 0.908515 0.299184 0.657008 0.00959312 0.417543 0.0867697 0.602588 0.40804 0.38182 0.756951 0.857613 0.28422 0.49757 0.117114 0.00788329 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 29
Initial state: 0 0.698205 0.238202 0.754499 0.888508 0.258595 0.656253 0.500266 0.491932 0.589816 0.0621003 0.327325 0.600316 0.14943 0.719508 0.525038 0.0939012 0.403338 0.374125 0.556379 0.498865 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18888 episodes
GETTING ACTION FROM:
action 5, numVisits=18870, meanQ=11.256822, numObservations: 9
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action 4, numVisits=5, meanQ=5.800000, numObservations: 4
action 9, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 7, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.698205 0.238202 0.754499 0.888508 0.258595 0.656253 0.500266 0.491932 0.589816 0.0621003 0.327325 0.600316 0.14943 0.719508 0.525038 0.0939012 0.403338 0.374125 0.556379 0.498865 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 30
Initial state: 0 0.999145 0.266156 0.449573 0.816061 0.0606212 0.466087 0.168995 0.862301 0.899827 0.520333 0.306548 0.0412235 0.201921 0.592286 0.300982 0.355667 0.860275 0.374361 0.159876 0.89317 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19697 episodes
GETTING ACTION FROM:
action 6, numVisits=19608, meanQ=11.430636, numObservations: 9
action 2, numVisits=40, meanQ=10.029505, numObservations: 8
action 5, numVisits=31, meanQ=9.664839, numObservations: 6
action 10, numVisits=4, meanQ=8.250000, numObservations: 4
action 1, numVisits=5, meanQ=7.596000, numObservations: 5
action 4, numVisits=2, meanQ=6.500000, numObservations: 2
action 7, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action 9, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 6
Next state: 2 0.999145 0.266156 0.449573 0.816061 0.0606212 0.466087 0.168995 0.862301 0.899827 0.520333 0.306548 0.0412235 0.201921 0.592286 0.300982 0.355667 0.860275 0.374361 0.159876 0.89317 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 31
Initial state: 0 0.492696 0.1169 0.748497 0.544785 0.97025 0.800382 0.315213 0.352488 0.720782 0.768208 0.734226 0.245155 0.668462 0.585702 0.637539 0.589411 0.242406 0.934986 0.118965 0.42981 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18589 episodes
GETTING ACTION FROM:
action 8, numVisits=18535, meanQ=11.442232, numObservations: 9
action 7, numVisits=36, meanQ=10.368894, numObservations: 8
action 2, numVisits=4, meanQ=8.250000, numObservations: 3
action 10, numVisits=5, meanQ=6.802020, numObservations: 3
action 9, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 8
Next state: 1 0.492696 0.1169 0.748497 0.544785 0.97025 0.800382 0.315213 0.352488 0.720782 0.768208 0.734226 0.245155 0.668462 0.585702 0.637539 0.589411 0.242406 0.934986 0.118965 0.42981 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 32
Initial state: 0 0.166596 0.0821278 0.295012 0.361126 0.757221 0.0357614 0.994758 0.864785 0.887767 0.0757223 0.10684 0.159375 0.963985 0.670081 0.658951 0.0468959 0.281375 0.199335 0.70811 0.196155 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18917 episodes
GETTING ACTION FROM:
action 9, numVisits=5251, meanQ=11.471934, numObservations: 9
action 3, numVisits=13654, meanQ=11.396653, numObservations: 9
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action 8, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-4.000000, numObservations: 1
action 7, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 9
Next state: 2 0.166596 0.0821278 0.295012 0.361126 0.757221 0.0357614 0.994758 0.864785 0.887767 0.0757223 0.10684 0.159375 0.963985 0.670081 0.658951 0.0468959 0.281375 0.199335 0.70811 0.196155 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 33
Initial state: 0 0.118343 0.69951 0.733929 0.729938 0.135333 0.252667 0.548799 0.950556 0.738417 0.85791 0.232619 0.458721 0.940689 0.103669 0.87639 0.491821 0.627085 0.681782 0.42356 0.390787 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18824 episodes
GETTING ACTION FROM:
action 3, numVisits=18712, meanQ=11.448251, numObservations: 9
action 10, numVisits=70, meanQ=10.650290, numObservations: 9
action 2, numVisits=9, meanQ=9.332222, numObservations: 6
action 9, numVisits=11, meanQ=8.682727, numObservations: 4
action 6, numVisits=8, meanQ=8.373750, numObservations: 4
action 7, numVisits=4, meanQ=8.250000, numObservations: 3
action 8, numVisits=4, meanQ=7.277500, numObservations: 2
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.118343 0.69951 0.733929 0.729938 0.135333 0.252667 0.548799 0.950556 0.738417 0.85791 0.232619 0.458721 0.940689 0.103669 0.87639 0.491821 0.627085 0.681782 0.42356 0.390787 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=323, meanQ=11.770043, numObservations: 9
action 4, numVisits=33, meanQ=9.241215, numObservations: 9
action 8, numVisits=10, meanQ=8.309010, numObservations: 4
action 10, numVisits=2, meanQ=6.500000, numObservations: 2
action 7, numVisits=5, meanQ=6.196000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 9, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 16280 episodes
GETTING ACTION FROM:
action 4, numVisits=14828, meanQ=8.767144, numObservations: 9
action 2, numVisits=1705, meanQ=8.277568, numObservations: 9
action 7, numVisits=63, meanQ=6.532114, numObservations: 8
action 10, numVisits=34, meanQ=5.676471, numObservations: 9
action 8, numVisits=12, meanQ=5.090842, numObservations: 5
action 9, numVisits=6, meanQ=1.998333, numObservations: 4
action -1, numVisits=4, meanQ=-1.752500, numObservations: 4
action 0, numVisits=4, meanQ=-1.752500, numObservations: 4
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.118343 0.69951 0.733929 0.729938 0.135333 0.252667 0.548799 0.950556 0.738417 0.85791 0.232619 0.458721 0.940689 0.103669 0.87639 0.491821 0.627085 0.681782 0.42356 0.390787 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 34
Initial state: 0 0.874218 0.245869 0.452924 0.200962 0.973571 0.30217 0.756313 0.907661 0.265627 0.119434 0.500621 0.929764 0.429961 0.337017 0.388206 0.27749 0.0806509 0.9387 0.0629424 0.420688 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19012 episodes
GETTING ACTION FROM:
action 7, numVisits=18988, meanQ=11.362361, numObservations: 9
action 6, numVisits=4, meanQ=8.250000, numObservations: 3
action 10, numVisits=4, meanQ=8.250000, numObservations: 3
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action 4, numVisits=5, meanQ=5.800000, numObservations: 4
action 3, numVisits=3, meanQ=5.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 7
Next state: 1 0.874218 0.245869 0.452924 0.200962 0.973571 0.30217 0.756313 0.907661 0.265627 0.119434 0.500621 0.929764 0.429961 0.337017 0.388206 0.27749 0.0806509 0.9387 0.0629424 0.420688 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 35
Initial state: 0 0.249382 0.286661 0.784215 0.766713 0.416202 0.318942 0.935077 0.831013 0.82279 0.439197 0.23941 0.290015 0.794746 0.246426 0.874905 0.65251 0.710352 0.670127 0.607291 0.495579 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19453 episodes
GETTING ACTION FROM:
action 9, numVisits=19421, meanQ=11.383626, numObservations: 9
action 10, numVisits=9, meanQ=7.886667, numObservations: 7
action 1, numVisits=11, meanQ=6.998182, numObservations: 6
action 7, numVisits=4, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 9
Next state: 2 0.249382 0.286661 0.784215 0.766713 0.416202 0.318942 0.935077 0.831013 0.82279 0.439197 0.23941 0.290015 0.794746 0.246426 0.874905 0.65251 0.710352 0.670127 0.607291 0.495579 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 36
Initial state: 0 0.904512 0.916935 0.323363 0.754882 0.27584 0.542231 0.211623 0.628392 0.313536 0.355449 0.629486 0.230469 0.977237 0.919928 0.47692 0.420356 0.901938 0.62428 0.54244 0.746669 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19252 episodes
GETTING ACTION FROM:
action 7, numVisits=19203, meanQ=11.369215, numObservations: 9
action 1, numVisits=19, meanQ=9.251063, numObservations: 7
action 9, numVisits=10, meanQ=8.699000, numObservations: 7
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action 6, numVisits=7, meanQ=6.141429, numObservations: 6
action 4, numVisits=3, meanQ=3.000000, numObservations: 2
action 5, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 7
Next state: 1 0.904512 0.916935 0.323363 0.754882 0.27584 0.542231 0.211623 0.628392 0.313536 0.355449 0.629486 0.230469 0.977237 0.919928 0.47692 0.420356 0.901938 0.62428 0.54244 0.746669 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 37
Initial state: 0 0.155518 0.93531 0.706357 0.58863 0.395305 0.364071 0.406666 0.595303 0.173709 0.00224242 0.5142 0.470945 0.0821686 0.793847 0.174903 0.728444 0.718663 0.504946 0.173579 0.747696 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19254 episodes
GETTING ACTION FROM:
action 9, numVisits=19143, meanQ=11.922624, numObservations: 9
action 6, numVisits=88, meanQ=10.756933, numObservations: 8
action 5, numVisits=8, meanQ=9.372500, numObservations: 5
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action 7, numVisits=2, meanQ=6.500000, numObservations: 1
action 8, numVisits=2, meanQ=6.500000, numObservations: 2
action 4, numVisits=3, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 9
Next state: 1 0.155518 0.93531 0.706357 0.58863 0.395305 0.364071 0.406666 0.595303 0.173709 0.00224242 0.5142 0.470945 0.0821686 0.793847 0.174903 0.728444 0.718663 0.504946 0.173579 0.747696 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 38
Initial state: 0 0.465856 0.41363 0.0238586 0.315298 0.744035 0.64103 0.592036 0.383806 0.0258571 0.364025 0.00449656 0.820235 0.058764 0.898204 0.626627 0.792463 0.530684 0.974206 0.844604 0.188833 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19079 episodes
GETTING ACTION FROM:
action 4, numVisits=19025, meanQ=11.444051, numObservations: 9
action 3, numVisits=26, meanQ=10.067696, numObservations: 7
action 7, numVisits=11, meanQ=9.363636, numObservations: 5
action 5, numVisits=9, meanQ=9.222222, numObservations: 7
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 9, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.465856 0.41363 0.0238586 0.315298 0.744035 0.64103 0.592036 0.383806 0.0258571 0.364025 0.00449656 0.820235 0.058764 0.898204 0.626627 0.792463 0.530684 0.974206 0.844604 0.188833 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 39
Initial state: 0 0.556714 0.789437 0.840333 0.10198 0.689425 0.232974 0.119024 0.185404 0.942861 0.248302 0.188531 0.303565 0.684291 0.64644 0.046192 0.203872 0.153386 0.166932 0.471485 0.360077 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19739 episodes
GETTING ACTION FROM:
action 7, numVisits=19681, meanQ=11.429412, numObservations: 9
action 6, numVisits=11, meanQ=9.272736, numObservations: 5
action 8, numVisits=13, meanQ=8.999231, numObservations: 5
action 5, numVisits=12, meanQ=8.008333, numObservations: 7
action 9, numVisits=7, meanQ=7.282857, numObservations: 6
action 4, numVisits=7, meanQ=6.677143, numObservations: 5
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 7
Next state: 1 0.556714 0.789437 0.840333 0.10198 0.689425 0.232974 0.119024 0.185404 0.942861 0.248302 0.188531 0.303565 0.684291 0.64644 0.046192 0.203872 0.153386 0.166932 0.471485 0.360077 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 40
Initial state: 0 0.114712 0.991788 0.0679715 0.104534 0.0644331 0.879446 0.0485558 0.366052 0.370575 0.395567 0.267029 0.70914 0.852246 0.199478 0.732386 0.907958 0.679966 0.0786574 0.424297 0.090352 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19714 episodes
GETTING ACTION FROM:
action 6, numVisits=19688, meanQ=11.393965, numObservations: 9
action 8, numVisits=5, meanQ=7.596000, numObservations: 4
action 2, numVisits=6, meanQ=6.500000, numObservations: 4
action 7, numVisits=4, meanQ=6.500000, numObservations: 3
action 9, numVisits=4, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 6
Next state: 0 0.114712 0.991788 0.0679715 0.104534 0.0644331 0.879446 0.0485558 0.366052 0.370575 0.395567 0.267029 0.70914 0.852246 0.199478 0.732386 0.907958 0.679966 0.0786574 0.424297 0.090352 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 7, numVisits=26, meanQ=14.076158, numObservations: 8
action 9, numVisits=40, meanQ=8.625000, numObservations: 9
action 10, numVisits=34, meanQ=8.327653, numObservations: 8
action 2, numVisits=4, meanQ=6.500000, numObservations: 4
action 5, numVisits=9, meanQ=6.331111, numObservations: 5
action 8, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 6, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 24020 episodes
GETTING ACTION FROM:
action 7, numVisits=24044, meanQ=14.050798, numObservations: 9
action 9, numVisits=40, meanQ=8.625000, numObservations: 9
action 10, numVisits=34, meanQ=8.327653, numObservations: 8
action 2, numVisits=4, meanQ=6.500000, numObservations: 4
action 5, numVisits=9, meanQ=6.331111, numObservations: 5
action 8, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 6, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 7
Next state: 2 0.114712 0.991788 0.0679715 0.104534 0.0644331 0.879446 0.0485558 0.366052 0.370575 0.395567 0.267029 0.70914 0.852246 0.199478 0.732386 0.907958 0.679966 0.0786574 0.424297 0.090352 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 41
Initial state: 0 0.517528 0.0284208 0.244831 0.984612 0.305463 0.329263 0.840668 0.577612 0.253414 0.896251 0.0694878 0.987676 0.413682 0.0873312 0.576174 0.680238 0.55046 0.0573788 0.982873 0.0104001 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19258 episodes
GETTING ACTION FROM:
action 7, numVisits=19224, meanQ=11.287889, numObservations: 9
action 1, numVisits=19, meanQ=8.387905, numObservations: 8
action 4, numVisits=5, meanQ=7.198020, numObservations: 3
action 8, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 7
Next state: 2 0.517528 0.0284208 0.244831 0.984612 0.305463 0.329263 0.840668 0.577612 0.253414 0.896251 0.0694878 0.987676 0.413682 0.0873312 0.576174 0.680238 0.55046 0.0573788 0.982873 0.0104001 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 42
Initial state: 0 0.84985 0.231897 0.0376805 0.965659 0.300171 0.327429 0.545563 0.822612 0.668976 0.713741 0.199402 0.758337 0.548311 0.445193 0.981529 0.695991 0.811632 0.54486 0.830064 0.505832 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19937 episodes
GETTING ACTION FROM:
action 3, numVisits=19862, meanQ=11.429634, numObservations: 9
action 4, numVisits=65, meanQ=10.565389, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 7, numVisits=1, meanQ=-4.000000, numObservations: 1
action 9, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.84985 0.231897 0.0376805 0.965659 0.300171 0.327429 0.545563 0.822612 0.668976 0.713741 0.199402 0.758337 0.548311 0.445193 0.981529 0.695991 0.811632 0.54486 0.830064 0.505832 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 43
Initial state: 0 0.628812 0.109757 0.789759 0.068638 0.780285 0.40459 0.427148 0.350954 0.676641 0.0445119 0.46671 0.0135294 0.921595 0.672663 0.188117 0.889128 0.76884 0.832838 0.621311 0.654927 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18862 episodes
GETTING ACTION FROM:
action 6, numVisits=18847, meanQ=11.237426, numObservations: 9
action 10, numVisits=5, meanQ=-0.595960, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action 9, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 6
Next state: 0 0.628812 0.109757 0.789759 0.068638 0.780285 0.40459 0.427148 0.350954 0.676641 0.0445119 0.46671 0.0135294 0.921595 0.672663 0.188117 0.889128 0.76884 0.832838 0.621311 0.654927 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=167, meanQ=13.238025, numObservations: 9
action 9, numVisits=29, meanQ=8.188621, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 6, numVisits=1, meanQ=-3.010000, numObservations: 1
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 13381 episodes
GETTING ACTION FROM:
action 5, numVisits=13542, meanQ=14.168865, numObservations: 9
action 9, numVisits=29, meanQ=8.188621, numObservations: 8
action -1, numVisits=4, meanQ=-1.505000, numObservations: 4
action 0, numVisits=4, meanQ=-1.505000, numObservations: 4
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 6, numVisits=1, meanQ=-3.010000, numObservations: 1
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.628812 0.109757 0.789759 0.068638 0.780285 0.40459 0.427148 0.350954 0.676641 0.0445119 0.46671 0.0135294 0.921595 0.672663 0.188117 0.889128 0.76884 0.832838 0.621311 0.654927 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 44
Initial state: 0 0.531355 0.646911 0.07654 0.741292 0.399754 0.389481 0.109178 0.799011 0.133432 0.190988 0.000704126 0.612144 0.102521 0.808666 0.923876 0.770663 0.34583 0.796161 0.116583 0.673841 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18767 episodes
GETTING ACTION FROM:
action 1, numVisits=18688, meanQ=11.216058, numObservations: 9
action 5, numVisits=38, meanQ=9.783953, numObservations: 8
action 10, numVisits=21, meanQ=9.760952, numObservations: 6
action 7, numVisits=10, meanQ=8.599010, numObservations: 5
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action 9, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.531355 0.646911 0.07654 0.741292 0.399754 0.389481 0.109178 0.799011 0.133432 0.190988 0.000704126 0.612144 0.102521 0.808666 0.923876 0.770663 0.34583 0.796161 0.116583 0.673841 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 45
Initial state: 0 0.923122 0.278163 0.319961 0.947963 0.159162 0.899019 0.611733 0.784212 0.220779 0.00309169 0.30449 0.375471 0.128722 0.132505 0.0310625 0.968017 0.821368 0.402144 0.175607 0.152308 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19063 episodes
GETTING ACTION FROM:
action 4, numVisits=19044, meanQ=11.660521, numObservations: 9
action 9, numVisits=8, meanQ=7.375000, numObservations: 4
action 7, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.923122 0.278163 0.319961 0.947963 0.159162 0.899019 0.611733 0.784212 0.220779 0.00309169 0.30449 0.375471 0.128722 0.132505 0.0310625 0.968017 0.821368 0.402144 0.175607 0.152308 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 46
Initial state: 0 0.732624 0.830131 0.364997 0.117583 0.688902 0.556372 0.918087 0.613761 0.7774 0.00246412 0.638146 0.567925 0.00795287 0.839417 0.184046 0.290932 0.450799 0.318204 0.220999 0.835354 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19457 episodes
GETTING ACTION FROM:
action 10, numVisits=19414, meanQ=11.530288, numObservations: 9
action 3, numVisits=16, meanQ=9.443125, numObservations: 8
action 8, numVisits=6, meanQ=8.998333, numObservations: 4
action 5, numVisits=4, meanQ=8.250000, numObservations: 3
action 9, numVisits=4, meanQ=8.250000, numObservations: 4
action 7, numVisits=6, meanQ=7.666667, numObservations: 5
action 4, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 10
Next state: 1 0.732624 0.830131 0.364997 0.117583 0.688902 0.556372 0.918087 0.613761 0.7774 0.00246412 0.638146 0.567925 0.00795287 0.839417 0.184046 0.290932 0.450799 0.318204 0.220999 0.835354 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 47
Initial state: 0 0.642313 0.6492 0.426324 0.414171 0.840547 0.609812 0.577287 0.568832 0.145584 0.604391 0.888442 0.019447 0.0989239 0.755804 0.651512 0.913921 0.986592 0.691805 0.50175 0.756484 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18519 episodes
GETTING ACTION FROM:
action 4, numVisits=18486, meanQ=11.495221, numObservations: 9
action 9, numVisits=18, meanQ=9.222222, numObservations: 8
action 10, numVisits=5, meanQ=7.200000, numObservations: 5
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 7, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.642313 0.6492 0.426324 0.414171 0.840547 0.609812 0.577287 0.568832 0.145584 0.604391 0.888442 0.019447 0.0989239 0.755804 0.651512 0.913921 0.986592 0.691805 0.50175 0.756484 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 48
Initial state: 0 0.108991 0.141209 0.157121 0.835395 0.281693 0.859729 0.764923 0.775564 0.676245 0.969004 0.948566 0.188973 0.0166167 0.656968 0.645095 0.434702 0.33343 0.345464 0.55481 0.464261 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18928 episodes
GETTING ACTION FROM:
action 5, numVisits=18910, meanQ=11.571646, numObservations: 9
action 1, numVisits=5, meanQ=7.198020, numObservations: 3
action 7, numVisits=2, meanQ=6.500000, numObservations: 2
action 8, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.108991 0.141209 0.157121 0.835395 0.281693 0.859729 0.764923 0.775564 0.676245 0.969004 0.948566 0.188973 0.0166167 0.656968 0.645095 0.434702 0.33343 0.345464 0.55481 0.464261 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 49
Initial state: 0 0.75177 0.024527 0.107695 0.500249 0.0752878 0.661392 0.560862 0.86332 0.746569 0.7648 0.341114 0.375854 0.43173 0.0842113 0.157348 0.595187 0.655783 0.236677 0.500714 0.303319 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19399 episodes
GETTING ACTION FROM:
action 1, numVisits=19386, meanQ=11.407900, numObservations: 9
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action 7, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 9, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.75177 0.024527 0.107695 0.500249 0.0752878 0.661392 0.560862 0.86332 0.746569 0.7648 0.341114 0.375854 0.43173 0.0842113 0.157348 0.595187 0.655783 0.236677 0.500714 0.303319 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 50
Initial state: 0 0.173329 0.855901 0.669507 0.06037 0.724032 0.685789 0.713672 0.129449 0.312145 0.9775 0.449517 0.374701 0.109458 0.131962 0.558751 0.834887 0.87912 0.0631601 0.0141355 0.0566738 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 20055 episodes
GETTING ACTION FROM:
action 5, numVisits=19949, meanQ=11.299125, numObservations: 9
action 3, numVisits=60, meanQ=10.376177, numObservations: 8
action 4, numVisits=27, meanQ=9.410741, numObservations: 8
action 6, numVisits=9, meanQ=9.222222, numObservations: 5
action 2, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-4.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.173329 0.855901 0.669507 0.06037 0.724032 0.685789 0.713672 0.129449 0.312145 0.9775 0.449517 0.374701 0.109458 0.131962 0.558751 0.834887 0.87912 0.0631601 0.0141355 0.0566738 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
[32m ProblemEnvironment.hpp 351: Done.[39m
