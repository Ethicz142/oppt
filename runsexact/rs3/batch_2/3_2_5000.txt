Run # 1
Initial state: 0 0.571458 0.82606 0.270458 0.738497 0.602814 0.82159 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1025817 episodes
GETTING ACTION FROM:
action 3, numVisits=1025811, meanQ=17.879719, numObservations: 5
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.571458 0.82606 0.270458 0.738497 0.602814 0.82159 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 2
Initial state: 0 0.533175 0.806894 0.616352 0.842881 0.872308 0.721672 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1095901 episodes
GETTING ACTION FROM:
action 2, numVisits=1095870, meanQ=17.851961, numObservations: 4
action 1, numVisits=28, meanQ=12.350364, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.533175 0.806894 0.616352 0.842881 0.872308 0.721672 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 3
Initial state: 0 0.670234 0.834876 0.665223 0.802173 0.644395 0.789959 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1100256 episodes
GETTING ACTION FROM:
action 1, numVisits=1100252, meanQ=17.783877, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.670234 0.834876 0.665223 0.802173 0.644395 0.789959 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 4
Initial state: 0 0.890753 0.938607 0.690485 0.853745 0.612827 0.807862 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 753018 episodes
GETTING ACTION FROM:
action -1, numVisits=753014, meanQ=15.547506, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: -1
Next state: 0 0.890753 0.938607 0.690485 0.853745 0.612827 0.807862 w: 1
Observation: 0 0.908419 0 0.63582 0 0.538729 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=752993, meanQ=17.762073, numObservations: 5
action 2, numVisits=17, meanQ=10.985300, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1194055 episodes
GETTING ACTION FROM:
action 3, numVisits=1947048, meanQ=17.825028, numObservations: 5
action 2, numVisits=17, meanQ=10.985300, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.890753 0.938607 0.690485 0.853745 0.612827 0.807862 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 5
Initial state: 0 0.598932 0.842821 0.636914 0.285559 0.529771 0.889319 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1105341 episodes
GETTING ACTION FROM:
action 2, numVisits=1105335, meanQ=17.852101, numObservations: 4
action 1, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.598932 0.842821 0.636914 0.285559 0.529771 0.889319 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 6
Initial state: 0 0.903544 0.136842 0.682122 0.855484 0.563302 0.838839 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1091105 episodes
GETTING ACTION FROM:
action 3, numVisits=1091101, meanQ=17.877995, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.903544 0.136842 0.682122 0.855484 0.563302 0.838839 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 7
Initial state: 0 0.688973 0.859803 0.562258 0.811347 0.889613 0.68899 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1117209 episodes
GETTING ACTION FROM:
action 1, numVisits=1117203, meanQ=17.890248, numObservations: 3
action 2, numVisits=3, meanQ=4.670033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.688973 0.859803 0.562258 0.811347 0.889613 0.68899 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=82220, meanQ=18.710872, numObservations: 3
action 2, numVisits=7, meanQ=11.857157, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1306709 episodes
GETTING ACTION FROM:
action 1, numVisits=1388929, meanQ=17.339229, numObservations: 3
action 2, numVisits=7, meanQ=11.857157, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.688973 0.859803 0.562258 0.811347 0.889613 0.68899 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 8
Initial state: 0 0.627103 0.872731 0.49502 0.907141 0.580315 0.884876 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1107558 episodes
GETTING ACTION FROM:
action 2, numVisits=1107548, meanQ=17.733319, numObservations: 4
action 3, numVisits=7, meanQ=5.998586, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.627103 0.872731 0.49502 0.907141 0.580315 0.884876 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 9
Initial state: 0 0.376657 0.339311 0.556761 0.894257 0.559002 0.857987 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1092043 episodes
GETTING ACTION FROM:
action 2, numVisits=1092038, meanQ=17.723777, numObservations: 4
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.376657 0.339311 0.556761 0.894257 0.559002 0.857987 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 10
Initial state: 0 0.603227 0.839965 0.582454 0.879915 0.975125 0.547216 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1102396 episodes
GETTING ACTION FROM:
action 3, numVisits=1102383, meanQ=17.756387, numObservations: 4
action 1, numVisits=10, meanQ=11.774010, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.603227 0.839965 0.582454 0.879915 0.975125 0.547216 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 11
Initial state: 0 0.532732 0.849067 0.133851 0.0629677 0.633487 0.804828 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1084092 episodes
GETTING ACTION FROM:
action 3, numVisits=1084087, meanQ=17.739379, numObservations: 5
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.532732 0.849067 0.133851 0.0629677 0.633487 0.804828 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 12
Initial state: 0 0.571043 0.834967 0.674755 0.863249 0.194225 0.439662 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1083519 episodes
GETTING ACTION FROM:
action 3, numVisits=1083514, meanQ=17.764780, numObservations: 5
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.571043 0.834967 0.674755 0.863249 0.194225 0.439662 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=124699, meanQ=23.504998, numObservations: 3
action 2, numVisits=13, meanQ=19.844615, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1410495 episodes
GETTING ACTION FROM:
action 1, numVisits=1535191, meanQ=19.233922, numObservations: 4
action 2, numVisits=16, meanQ=16.623756, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.571043 0.834967 0.674755 0.863249 0.194225 0.439662 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 13
Initial state: 0 0.53565 0.870335 0.560574 0.881942 0.781581 0.577329 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1110195 episodes
GETTING ACTION FROM:
action 1, numVisits=1110162, meanQ=18.099943, numObservations: 4
action 3, numVisits=30, meanQ=14.066680, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.53565 0.870335 0.560574 0.881942 0.781581 0.577329 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 14
Initial state: 0 0.573053 0.878301 0.555094 0.88702 0.807684 0.238053 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1101313 episodes
GETTING ACTION FROM:
action 1, numVisits=1101309, meanQ=17.756146, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.573053 0.878301 0.555094 0.88702 0.807684 0.238053 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 15
Initial state: 0 0.5571 0.871523 0.887846 0.0501211 0.626877 0.865991 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 757928 episodes
GETTING ACTION FROM:
action 0, numVisits=757923, meanQ=15.580149, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.5571 0.871523 0.887846 0.0501211 0.626877 0.865991 w: 1
Observation: 0 0 0.916159 0 0.0433861 0 0.856738 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=757895, meanQ=17.753620, numObservations: 4
action 3, numVisits=24, meanQ=14.604588, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1225205 episodes
GETTING ACTION FROM:
action 2, numVisits=1983100, meanQ=17.776357, numObservations: 4
action 3, numVisits=24, meanQ=14.604588, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.5571 0.871523 0.887846 0.0501211 0.626877 0.865991 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 16
Initial state: 0 0.69464 0.882358 0.350219 0.97915 0.607529 0.814552 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1100653 episodes
GETTING ACTION FROM:
action 2, numVisits=1100645, meanQ=17.827580, numObservations: 4
action 1, numVisits=5, meanQ=10.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.69464 0.882358 0.350219 0.97915 0.607529 0.814552 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=27320, meanQ=22.237108, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1372986 episodes
GETTING ACTION FROM:
action 3, numVisits=1400306, meanQ=19.132694, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.69464 0.882358 0.350219 0.97915 0.607529 0.814552 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 17
Initial state: 0 0.763632 0.08458 0.550715 0.895441 0.691402 0.898752 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1080801 episodes
GETTING ACTION FROM:
action 1, numVisits=1080789, meanQ=17.728564, numObservations: 5
action 3, numVisits=9, meanQ=14.996667, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.763632 0.08458 0.550715 0.895441 0.691402 0.898752 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 18
Initial state: 0 0.676268 0.543679 0.605347 0.823169 0.540394 0.826541 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1084801 episodes
GETTING ACTION FROM:
action 3, numVisits=1084785, meanQ=17.784877, numObservations: 5
action 2, numVisits=13, meanQ=13.845385, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.676268 0.543679 0.605347 0.823169 0.540394 0.826541 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 19
Initial state: 0 0.603371 0.844009 0.533432 0.898261 0.486699 0.992163 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1088921 episodes
GETTING ACTION FROM:
action 3, numVisits=1088893, meanQ=17.847796, numObservations: 5
action 1, numVisits=20, meanQ=13.687500, numObservations: 5
action 2, numVisits=6, meanQ=12.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.603371 0.844009 0.533432 0.898261 0.486699 0.992163 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=80733, meanQ=18.592111, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1305825 episodes
GETTING ACTION FROM:
action 3, numVisits=1386558, meanQ=17.606584, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.603371 0.844009 0.533432 0.898261 0.486699 0.992163 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=26919, meanQ=19.393381, numObservations: 4
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1320974 episodes
GETTING ACTION FROM:
action 3, numVisits=1347893, meanQ=17.526431, numObservations: 5
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.603371 0.844009 0.533432 0.898261 0.486699 0.992163 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=13473, meanQ=22.339380, numObservations: 4
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1439031 episodes
GETTING ACTION FROM:
action 2, numVisits=1452504, meanQ=18.647255, numObservations: 4
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.603371 0.844009 0.533432 0.898261 0.486699 0.992163 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 1, numVisits=14392, meanQ=23.325681, numObservations: 4
action 2, numVisits=6, meanQ=19.498333, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1455088 episodes
GETTING ACTION FROM:
action 1, numVisits=1469452, meanQ=19.368625, numObservations: 4
action 2, numVisits=34, meanQ=18.058529, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.603371 0.844009 0.533432 0.898261 0.486699 0.992163 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.29271
Run # 20
Initial state: 0 0.577482 0.810822 0.504508 0.893531 0.0703585 0.615511 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1105422 episodes
GETTING ACTION FROM:
action 1, numVisits=1105413, meanQ=17.739087, numObservations: 4
action 2, numVisits=3, meanQ=12.333333, numObservations: 3
action 3, numVisits=4, meanQ=9.997525, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.577482 0.810822 0.504508 0.893531 0.0703585 0.615511 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 21
Initial state: 0 0.557224 0.891768 0.618118 0.589388 0.57914 0.877436 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1088058 episodes
GETTING ACTION FROM:
action 3, numVisits=1088054, meanQ=17.872172, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.557224 0.891768 0.618118 0.589388 0.57914 0.877436 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 22
Initial state: 0 0.601374 0.82302 0.847274 0.94362 0.679256 0.893486 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1063281 episodes
GETTING ACTION FROM:
action 1, numVisits=1063269, meanQ=17.627310, numObservations: 4
action 2, numVisits=9, meanQ=13.221111, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.601374 0.82302 0.847274 0.94362 0.679256 0.893486 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 23
Initial state: 0 0.954324 0.416885 0.624257 0.895015 0.681981 0.861293 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1083534 episodes
GETTING ACTION FROM:
action 3, numVisits=1083528, meanQ=17.765939, numObservations: 5
action 2, numVisits=3, meanQ=5.330033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.954324 0.416885 0.624257 0.895015 0.681981 0.861293 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 24
Initial state: 0 0.549045 0.883908 0.569634 0.800251 0.368937 0.328209 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1081659 episodes
GETTING ACTION FROM:
action 1, numVisits=1081654, meanQ=17.754667, numObservations: 5
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.549045 0.883908 0.569634 0.800251 0.368937 0.328209 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 25
Initial state: 0 0.6119 0.819592 0.366825 0.578384 0.654772 0.835742 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1104507 episodes
GETTING ACTION FROM:
action 2, numVisits=1104492, meanQ=17.816703, numObservations: 4
action 1, numVisits=12, meanQ=8.313350, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.6119 0.819592 0.366825 0.578384 0.654772 0.835742 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=181883, meanQ=23.099597, numObservations: 3
action 3, numVisits=3, meanQ=14.996667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1431063 episodes
GETTING ACTION FROM:
action 1, numVisits=1612943, meanQ=19.227308, numObservations: 3
action 3, numVisits=6, meanQ=13.665000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.6119 0.819592 0.366825 0.578384 0.654772 0.835742 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 26
Initial state: 0 0.192625 0.466391 0.678686 0.828632 0.621311 0.889593 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1104318 episodes
GETTING ACTION FROM:
action 3, numVisits=1104313, meanQ=17.846590, numObservations: 4
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.192625 0.466391 0.678686 0.828632 0.621311 0.889593 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 27
Initial state: 0 0.454694 0.231397 0.659176 0.872204 0.582569 0.847714 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1065934 episodes
GETTING ACTION FROM:
action 3, numVisits=1065930, meanQ=17.593532, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.454694 0.231397 0.659176 0.872204 0.582569 0.847714 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 28
Initial state: 0 0.365095 0.911443 0.65196 0.842586 0.649453 0.819942 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1100556 episodes
GETTING ACTION FROM:
action 2, numVisits=1100545, meanQ=17.734129, numObservations: 4
action 3, numVisits=5, meanQ=10.000000, numObservations: 2
action 1, numVisits=4, meanQ=8.497500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.365095 0.911443 0.65196 0.842586 0.649453 0.819942 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 29
Initial state: 0 0.260317 0.0890172 0.669594 0.879498 0.601646 0.889994 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1090607 episodes
GETTING ACTION FROM:
action 2, numVisits=1090600, meanQ=17.768590, numObservations: 5
action 3, numVisits=4, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.260317 0.0890172 0.669594 0.879498 0.601646 0.889994 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=81063, meanQ=17.535127, numObservations: 5
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1372063 episodes
GETTING ACTION FROM:
action 3, numVisits=1453126, meanQ=18.200380, numObservations: 5
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.260317 0.0890172 0.669594 0.879498 0.601646 0.889994 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 30
Initial state: 0 0.580356 0.850695 0.961845 0.585229 0.637006 0.807944 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1077336 episodes
GETTING ACTION FROM:
action 3, numVisits=1077332, meanQ=17.877891, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.580356 0.850695 0.961845 0.585229 0.637006 0.807944 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 31
Initial state: 0 0.532918 0.832259 0.560737 0.839471 0.434216 0.0987541 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1096483 episodes
GETTING ACTION FROM:
action 1, numVisits=1096479, meanQ=17.875740, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.532918 0.832259 0.560737 0.839471 0.434216 0.0987541 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 32
Initial state: 0 0.324578 0.279949 0.563501 0.829086 0.566267 0.859646 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1104565 episodes
GETTING ACTION FROM:
action 2, numVisits=1104561, meanQ=17.876588, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.324578 0.279949 0.563501 0.829086 0.566267 0.859646 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=81448, meanQ=18.620655, numObservations: 4
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1325332 episodes
GETTING ACTION FROM:
action 2, numVisits=1406780, meanQ=17.337807, numObservations: 4
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.324578 0.279949 0.563501 0.829086 0.566267 0.859646 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 33
Initial state: 0 0.65104 0.817663 0.275648 0.599857 0.544474 0.832333 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1102783 episodes
GETTING ACTION FROM:
action 2, numVisits=1102778, meanQ=17.872178, numObservations: 4
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.65104 0.817663 0.275648 0.599857 0.544474 0.832333 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=154686, meanQ=23.312679, numObservations: 5
action 1, numVisits=24, meanQ=21.254167, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1401422 episodes
GETTING ACTION FROM:
action 3, numVisits=1556033, meanQ=19.412077, numObservations: 5
action 1, numVisits=99, meanQ=18.483334, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.65104 0.817663 0.275648 0.599857 0.544474 0.832333 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 34
Initial state: 0 0.554762 0.84172 0.60142 0.477434 0.656685 0.800792 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1111352 episodes
GETTING ACTION FROM:
action 2, numVisits=1111346, meanQ=17.814767, numObservations: 3
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.554762 0.84172 0.60142 0.477434 0.656685 0.800792 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=183581, meanQ=23.154529, numObservations: 4
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1412062 episodes
GETTING ACTION FROM:
action 3, numVisits=1595643, meanQ=19.243094, numObservations: 4
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.554762 0.84172 0.60142 0.477434 0.656685 0.800792 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 35
Initial state: 0 0.484356 0.451734 0.55628 0.819974 0.64726 0.818836 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1102046 episodes
GETTING ACTION FROM:
action 2, numVisits=1102034, meanQ=17.861229, numObservations: 4
action 1, numVisits=8, meanQ=11.873750, numObservations: 3
action 3, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.484356 0.451734 0.55628 0.819974 0.64726 0.818836 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 36
Initial state: 0 0.654719 0.837038 0.558066 0.865716 0.896695 0.722397 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1110867 episodes
GETTING ACTION FROM:
action 2, numVisits=1110863, meanQ=17.876955, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.654719 0.837038 0.558066 0.865716 0.896695 0.722397 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 37
Initial state: 0 0.61556 0.818771 0.685444 0.830382 0.455193 0.261645 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1120297 episodes
GETTING ACTION FROM:
action 2, numVisits=1120289, meanQ=17.854770, numObservations: 3
action 1, numVisits=5, meanQ=11.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.61556 0.818771 0.685444 0.830382 0.455193 0.261645 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 38
Initial state: 0 0.526494 0.0101065 0.676287 0.818607 0.505753 0.833708 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1116962 episodes
GETTING ACTION FROM:
action 3, numVisits=1116957, meanQ=17.857559, numObservations: 4
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.526494 0.0101065 0.676287 0.818607 0.505753 0.833708 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 39
Initial state: 0 0.679922 0.821612 0.606492 0.863061 0.23212 0.227315 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1125017 episodes
GETTING ACTION FROM:
action 3, numVisits=1125013, meanQ=17.847251, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.679922 0.821612 0.606492 0.863061 0.23212 0.227315 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 40
Initial state: 0 0.911246 0.875136 0.629795 0.886493 0.581918 0.871474 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1109281 episodes
GETTING ACTION FROM:
action 2, numVisits=1109270, meanQ=17.731264, numObservations: 5
action 1, numVisits=7, meanQ=11.282857, numObservations: 3
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.911246 0.875136 0.629795 0.886493 0.581918 0.871474 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 41
Initial state: 0 0.6268 0.866356 0.694182 0.826925 0.798745 0.174573 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1126124 episodes
GETTING ACTION FROM:
action 2, numVisits=1126107, meanQ=17.860348, numObservations: 4
action 1, numVisits=13, meanQ=13.230769, numObservations: 3
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.6268 0.866356 0.694182 0.826925 0.798745 0.174573 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 42
Initial state: 0 0.613773 0.803984 0.680908 0.841745 0.485974 0.456755 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1086142 episodes
GETTING ACTION FROM:
action 3, numVisits=1086105, meanQ=17.774836, numObservations: 5
action 2, numVisits=32, meanQ=11.467828, numObservations: 4
action 1, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.613773 0.803984 0.680908 0.841745 0.485974 0.456755 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=27402, meanQ=22.271578, numObservations: 5
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1429649 episodes
GETTING ACTION FROM:
action 1, numVisits=1457051, meanQ=18.460253, numObservations: 5
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.613773 0.803984 0.680908 0.841745 0.485974 0.456755 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 43
Initial state: 0 0.554812 0.897295 0.503798 0.811168 0.826938 0.523187 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1115412 episodes
GETTING ACTION FROM:
action 2, numVisits=1115399, meanQ=17.855249, numObservations: 5
action 1, numVisits=10, meanQ=8.098000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.554812 0.897295 0.503798 0.811168 0.826938 0.523187 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 44
Initial state: 0 0.516262 0.808914 0.548808 0.316451 0.634801 0.817122 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1118547 episodes
GETTING ACTION FROM:
action 3, numVisits=1118540, meanQ=17.805201, numObservations: 4
action 2, numVisits=4, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.516262 0.808914 0.548808 0.316451 0.634801 0.817122 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 45
Initial state: 0 0.556472 0.82824 0.501869 0.816704 0.194349 0.396194 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1119964 episodes
GETTING ACTION FROM:
action 3, numVisits=1119960, meanQ=17.734425, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.556472 0.82824 0.501869 0.816704 0.194349 0.396194 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=183060, meanQ=23.142304, numObservations: 5
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1425905 episodes
GETTING ACTION FROM:
action 1, numVisits=1608965, meanQ=19.808634, numObservations: 5
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.556472 0.82824 0.501869 0.816704 0.194349 0.396194 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 46
Initial state: 0 0.612211 0.882551 0.582693 0.889018 0.987362 0.262138 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1119977 episodes
GETTING ACTION FROM:
action 3, numVisits=1119971, meanQ=17.820291, numObservations: 4
action 2, numVisits=3, meanQ=12.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.612211 0.882551 0.582693 0.889018 0.987362 0.262138 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 47
Initial state: 0 0.720286 0.283401 0.575359 0.813315 0.529454 0.811671 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1136203 episodes
GETTING ACTION FROM:
action 2, numVisits=1136199, meanQ=17.839958, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.720286 0.283401 0.575359 0.813315 0.529454 0.811671 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 48
Initial state: 0 0.733439 0.243396 0.506501 0.894495 0.622102 0.898047 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1133537 episodes
GETTING ACTION FROM:
action 2, numVisits=1133530, meanQ=17.746804, numObservations: 4
action 3, numVisits=4, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.733439 0.243396 0.506501 0.894495 0.622102 0.898047 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 49
Initial state: 0 0.348187 0.819863 0.679169 0.891056 0.543619 0.802505 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1119285 episodes
GETTING ACTION FROM:
action 1, numVisits=1119280, meanQ=17.869260, numObservations: 4
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.348187 0.819863 0.679169 0.891056 0.543619 0.802505 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=183907, meanQ=23.137803, numObservations: 3
action 2, numVisits=5, meanQ=18.598000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1431044 episodes
GETTING ACTION FROM:
action 3, numVisits=1614946, meanQ=18.882969, numObservations: 3
action 2, numVisits=10, meanQ=14.299000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.348187 0.819863 0.679169 0.891056 0.543619 0.802505 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=42647, meanQ=21.957835, numObservations: 3
action 2, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1466273 episodes
GETTING ACTION FROM:
action 3, numVisits=1508920, meanQ=17.411034, numObservations: 3
action 2, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.348187 0.819863 0.679169 0.891056 0.543619 0.802505 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 50
Initial state: 0 0.537474 0.853836 0.52907 0.882595 0.873941 0.90435 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1128457 episodes
GETTING ACTION FROM:
action 2, numVisits=1128452, meanQ=17.865271, numObservations: 4
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.537474 0.853836 0.52907 0.882595 0.873941 0.90435 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 51
Initial state: 0 0.579641 0.846656 0.898868 0.547668 0.563645 0.891584 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1147149 episodes
GETTING ACTION FROM:
action 2, numVisits=1147145, meanQ=17.873597, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.579641 0.846656 0.898868 0.547668 0.563645 0.891584 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 52
Initial state: 0 0.323128 0.560384 0.674496 0.821584 0.533335 0.888177 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1126433 episodes
GETTING ACTION FROM:
action 3, numVisits=1126429, meanQ=17.827655, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.323128 0.560384 0.674496 0.821584 0.533335 0.888177 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 53
Initial state: 0 0.226456 0.609801 0.672445 0.887302 0.638295 0.859575 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1121760 episodes
GETTING ACTION FROM:
action 1, numVisits=1121755, meanQ=17.857037, numObservations: 5
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.226456 0.609801 0.672445 0.887302 0.638295 0.859575 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=157386, meanQ=23.303238, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1457307 episodes
GETTING ACTION FROM:
action 2, numVisits=1614693, meanQ=18.821970, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.226456 0.609801 0.672445 0.887302 0.638295 0.859575 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 54
Initial state: 0 0.606458 0.901144 0.51223 0.889761 0.636855 0.866786 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1116314 episodes
GETTING ACTION FROM:
action 1, numVisits=1116305, meanQ=17.822889, numObservations: 5
action 2, numVisits=5, meanQ=11.598000, numObservations: 3
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.606458 0.901144 0.51223 0.889761 0.636855 0.866786 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 55
Initial state: 0 0.583137 0.848318 0.439714 0.661388 0.655485 0.89851 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1116650 episodes
GETTING ACTION FROM:
action 1, numVisits=1116644, meanQ=17.744745, numObservations: 5
action 2, numVisits=3, meanQ=4.670033, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.583137 0.848318 0.439714 0.661388 0.655485 0.89851 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 56
Initial state: 0 0.689364 0.804031 0.792792 0.715403 0.699843 0.844591 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1127927 episodes
GETTING ACTION FROM:
action 1, numVisits=1127896, meanQ=17.733365, numObservations: 4
action 2, numVisits=27, meanQ=15.175941, numObservations: 5
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.689364 0.804031 0.792792 0.715403 0.699843 0.844591 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 57
Initial state: 0 0.53297 0.935848 0.563381 0.873215 0.561878 0.878304 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1111696 episodes
GETTING ACTION FROM:
action 1, numVisits=1111691, meanQ=17.841283, numObservations: 5
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.53297 0.935848 0.563381 0.873215 0.561878 0.878304 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 58
Initial state: 0 0.556726 0.822788 0.238387 0.171919 0.557107 0.839202 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1106383 episodes
GETTING ACTION FROM:
action 3, numVisits=1106378, meanQ=17.857273, numObservations: 5
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.556726 0.822788 0.238387 0.171919 0.557107 0.839202 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=82025, meanQ=18.648322, numObservations: 4
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1324587 episodes
GETTING ACTION FROM:
action 3, numVisits=1406612, meanQ=17.156103, numObservations: 5
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.556726 0.822788 0.238387 0.171919 0.557107 0.839202 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 59
Initial state: 0 0.516482 0.857932 0.143312 0.497982 0.563505 0.867932 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1124144 episodes
GETTING ACTION FROM:
action 2, numVisits=1124139, meanQ=17.798718, numObservations: 4
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.516482 0.857932 0.143312 0.497982 0.563505 0.867932 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=185668, meanQ=23.176150, numObservations: 5
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1423424 episodes
GETTING ACTION FROM:
action 3, numVisits=1609092, meanQ=19.125980, numObservations: 5
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.516482 0.857932 0.143312 0.497982 0.563505 0.867932 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 60
Initial state: 0 0.731019 0.262484 0.595596 0.813458 0.527003 0.800144 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1115846 episodes
GETTING ACTION FROM:
action 2, numVisits=1115842, meanQ=17.700395, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.731019 0.262484 0.595596 0.813458 0.527003 0.800144 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 61
Initial state: 0 0.505765 0.879049 0.63196 0.808847 0.377566 0.102998 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1103558 episodes
GETTING ACTION FROM:
action 3, numVisits=1103552, meanQ=17.779636, numObservations: 5
action 1, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.505765 0.879049 0.63196 0.808847 0.377566 0.102998 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=154648, meanQ=23.325442, numObservations: 5
action 1, numVisits=5, meanQ=18.598000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1416309 episodes
GETTING ACTION FROM:
action 2, numVisits=1570955, meanQ=19.213958, numObservations: 5
action 1, numVisits=7, meanQ=15.141429, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.505765 0.879049 0.63196 0.808847 0.377566 0.102998 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 62
Initial state: 0 0.534191 0.831553 0.610303 0.807881 0.394711 0.246753 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1106668 episodes
GETTING ACTION FROM:
action 3, numVisits=1106662, meanQ=17.830235, numObservations: 5
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.534191 0.831553 0.610303 0.807881 0.394711 0.246753 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=154966, meanQ=23.327792, numObservations: 5
action 1, numVisits=4, meanQ=15.250000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1417972 episodes
GETTING ACTION FROM:
action 2, numVisits=1572938, meanQ=19.093044, numObservations: 5
action 1, numVisits=4, meanQ=15.250000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.534191 0.831553 0.610303 0.807881 0.394711 0.246753 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 63
Initial state: 0 0.68429 0.874261 0.572845 0.88715 0.2699 0.149304 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1117970 episodes
GETTING ACTION FROM:
action 1, numVisits=1117959, meanQ=17.851336, numObservations: 5
action 2, numVisits=6, meanQ=7.183333, numObservations: 2
action 3, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.68429 0.874261 0.572845 0.88715 0.2699 0.149304 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 64
Initial state: 0 0.538051 0.823804 0.508474 0.815236 0.711281 0.523216 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1118068 episodes
GETTING ACTION FROM:
action 1, numVisits=1118063, meanQ=17.821258, numObservations: 4
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.538051 0.823804 0.508474 0.815236 0.711281 0.523216 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 65
Initial state: 0 0.50918 0.859115 0.70338 0.13583 0.58606 0.85366 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1113329 episodes
GETTING ACTION FROM:
action 1, numVisits=1113325, meanQ=17.797698, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.50918 0.859115 0.70338 0.13583 0.58606 0.85366 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 66
Initial state: 0 0.673345 0.870556 0.611028 0.813678 0.75876 0.15409 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1114345 episodes
GETTING ACTION FROM:
action 2, numVisits=1114336, meanQ=17.763895, numObservations: 5
action 1, numVisits=6, meanQ=9.163333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.673345 0.870556 0.611028 0.813678 0.75876 0.15409 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 67
Initial state: 0 0.588462 0.873452 0.524055 0.814259 0.494147 0.666631 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1071451 episodes
GETTING ACTION FROM:
action 1, numVisits=1071447, meanQ=17.604678, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.588462 0.873452 0.524055 0.814259 0.494147 0.666631 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 68
Initial state: 0 0.695171 0.833518 0.415435 0.136184 0.588628 0.807574 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1121023 episodes
GETTING ACTION FROM:
action 2, numVisits=1121016, meanQ=17.717882, numObservations: 4
action 1, numVisits=4, meanQ=8.497500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.695171 0.833518 0.415435 0.136184 0.588628 0.807574 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=184439, meanQ=23.157600, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1414067 episodes
GETTING ACTION FROM:
action 3, numVisits=1598506, meanQ=18.913438, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.695171 0.833518 0.415435 0.136184 0.588628 0.807574 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=43848, meanQ=22.057442, numObservations: 3
action 1, numVisits=5, meanQ=18.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1471958 episodes
GETTING ACTION FROM:
action 3, numVisits=1515789, meanQ=18.705180, numObservations: 4
action 1, numVisits=22, meanQ=16.408636, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.695171 0.833518 0.415435 0.136184 0.588628 0.807574 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 69
Initial state: 0 0.662319 0.89932 0.864209 0.146638 0.566454 0.829327 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1134943 episodes
GETTING ACTION FROM:
action 1, numVisits=1134937, meanQ=17.911402, numObservations: 4
action 3, numVisits=3, meanQ=3.330000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.662319 0.89932 0.864209 0.146638 0.566454 0.829327 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 70
Initial state: 0 0.497957 0.927684 0.655921 0.893891 0.540949 0.821184 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1125529 episodes
GETTING ACTION FROM:
action 2, numVisits=1125523, meanQ=17.796545, numObservations: 4
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.497957 0.927684 0.655921 0.893891 0.540949 0.821184 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 71
Initial state: 0 0.603205 0.813149 0.499334 0.428892 0.639379 0.869961 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1135566 episodes
GETTING ACTION FROM:
action 3, numVisits=1135562, meanQ=17.768813, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.603205 0.813149 0.499334 0.428892 0.639379 0.869961 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 72
Initial state: 0 0.695508 0.870255 0.590503 0.821675 0.317422 0.228797 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1136529 episodes
GETTING ACTION FROM:
action 2, numVisits=1136525, meanQ=17.857529, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.695508 0.870255 0.590503 0.821675 0.317422 0.228797 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 73
Initial state: 0 0.134516 0.921147 0.594643 0.854814 0.692064 0.819379 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1079672 episodes
GETTING ACTION FROM:
action 3, numVisits=1079662, meanQ=17.630083, numObservations: 4
action 2, numVisits=7, meanQ=9.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.134516 0.921147 0.594643 0.854814 0.692064 0.819379 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 74
Initial state: 0 0.572631 0.85756 0.570095 0.848094 0.1153 0.325107 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1145785 episodes
GETTING ACTION FROM:
action 2, numVisits=1145781, meanQ=17.771818, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.572631 0.85756 0.570095 0.848094 0.1153 0.325107 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=10921, meanQ=18.543789, numObservations: 3
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1335046 episodes
GETTING ACTION FROM:
action 2, numVisits=1345967, meanQ=17.842101, numObservations: 4
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.572631 0.85756 0.570095 0.848094 0.1153 0.325107 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 75
Initial state: 0 0.620224 0.848291 0.563327 0.817993 0.879158 0.429485 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1140673 episodes
GETTING ACTION FROM:
action 2, numVisits=1140668, meanQ=17.747499, numObservations: 3
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.620224 0.848291 0.563327 0.817993 0.879158 0.429485 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 76
Initial state: 0 0.892443 0.555178 0.544124 0.8614 0.553984 0.843219 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1079127 episodes
GETTING ACTION FROM:
action 3, numVisits=1079123, meanQ=17.582448, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.892443 0.555178 0.544124 0.8614 0.553984 0.843219 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 77
Initial state: 0 0.414302 0.37511 0.567488 0.883319 0.513091 0.843484 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1122173 episodes
GETTING ACTION FROM:
action 1, numVisits=1122167, meanQ=17.883027, numObservations: 5
action 3, numVisits=2, meanQ=10.495000, numObservations: 1
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 0 0.414302 0.37511 0.567488 0.883319 0.513091 0.843484 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=156676, meanQ=23.290429, numObservations: 3
action 2, numVisits=35, meanQ=20.799434, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1439103 episodes
GETTING ACTION FROM:
action 3, numVisits=1595109, meanQ=19.408046, numObservations: 3
action 2, numVisits=705, meanQ=19.108370, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.414302 0.37511 0.567488 0.883319 0.513091 0.843484 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 78
Initial state: 0 0.532317 0.829974 0.6997 0.839306 0.0591174 0.200602 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1130980 episodes
GETTING ACTION FROM:
action 2, numVisits=1130975, meanQ=17.876457, numObservations: 4
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.532317 0.829974 0.6997 0.839306 0.0591174 0.200602 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 79
Initial state: 0 0.469589 0.49985 0.692305 0.846773 0.660541 0.843821 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1122043 episodes
GETTING ACTION FROM:
action 3, numVisits=1122038, meanQ=17.699947, numObservations: 4
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.469589 0.49985 0.692305 0.846773 0.660541 0.843821 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 80
Initial state: 0 0.875411 0.695857 0.550011 0.880739 0.672099 0.871532 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1096006 episodes
GETTING ACTION FROM:
action 1, numVisits=1096002, meanQ=17.681500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.875411 0.695857 0.550011 0.880739 0.672099 0.871532 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 81
Initial state: 0 0.917957 0.099349 0.649122 0.896989 0.696998 0.823223 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 767204 episodes
GETTING ACTION FROM:
action 0, numVisits=767199, meanQ=15.568326, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.917957 0.099349 0.649122 0.896989 0.696998 0.823223 w: 1
Observation: 0 0 0.135266 0 0.871144 0 0.896788 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=767193, meanQ=17.770073, numObservations: 5
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1219053 episodes
GETTING ACTION FROM:
action 1, numVisits=1986246, meanQ=17.817216, numObservations: 5
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.917957 0.099349 0.649122 0.896989 0.696998 0.823223 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 82
Initial state: 0 0.695327 0.80269 0.163439 0.545003 0.654056 0.883592 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1133440 episodes
GETTING ACTION FROM:
action 3, numVisits=1133423, meanQ=17.768848, numObservations: 3
action 2, numVisits=14, meanQ=14.570714, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.695327 0.80269 0.163439 0.545003 0.654056 0.883592 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 83
Initial state: 0 0.591477 0.837925 0.557944 0.814406 0.0829136 0.985118 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1139573 episodes
GETTING ACTION FROM:
action 2, numVisits=1139569, meanQ=17.921721, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.591477 0.837925 0.557944 0.814406 0.0829136 0.985118 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 84
Initial state: 0 0.562277 0.840919 0.556006 0.873392 0.263697 0.000622454 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1120937 episodes
GETTING ACTION FROM:
action 2, numVisits=1120917, meanQ=17.867463, numObservations: 5
action 3, numVisits=13, meanQ=6.844623, numObservations: 3
action 1, numVisits=5, meanQ=5.418000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.562277 0.840919 0.556006 0.873392 0.263697 0.000622454 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=156802, meanQ=23.301970, numObservations: 4
action 3, numVisits=9, meanQ=20.998889, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1450194 episodes
GETTING ACTION FROM:
action 1, numVisits=1606913, meanQ=19.457720, numObservations: 4
action 3, numVisits=92, meanQ=18.662829, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.562277 0.840919 0.556006 0.873392 0.263697 0.000622454 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 85
Initial state: 0 0.542232 0.82305 0.406787 0.585005 0.672668 0.857291 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1123367 episodes
GETTING ACTION FROM:
action 3, numVisits=1123357, meanQ=17.921895, numObservations: 5
action 1, numVisits=7, meanQ=15.071429, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.542232 0.82305 0.406787 0.585005 0.672668 0.857291 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 86
Initial state: 0 0.528932 0.813374 0.529847 0.984586 0.616845 0.826136 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1129289 episodes
GETTING ACTION FROM:
action 1, numVisits=1129285, meanQ=17.835364, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.528932 0.813374 0.529847 0.984586 0.616845 0.826136 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 87
Initial state: 0 0.746662 0.07558 0.600182 0.828859 0.502887 0.888892 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1122069 episodes
GETTING ACTION FROM:
action 2, numVisits=1122065, meanQ=17.849695, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.746662 0.07558 0.600182 0.828859 0.502887 0.888892 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 88
Initial state: 0 0.520299 0.827344 0.610567 0.815079 0.322356 0.498612 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1132052 episodes
GETTING ACTION FROM:
action 1, numVisits=1132046, meanQ=17.765270, numObservations: 4
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.520299 0.827344 0.610567 0.815079 0.322356 0.498612 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 89
Initial state: 0 0.704255 0.179676 0.501873 0.842053 0.510863 0.850282 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1129428 episodes
GETTING ACTION FROM:
action 1, numVisits=1129424, meanQ=17.791005, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.704255 0.179676 0.501873 0.842053 0.510863 0.850282 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 90
Initial state: 0 0.612272 0.899263 0.0936147 0.548871 0.635179 0.802011 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1078852 episodes
GETTING ACTION FROM:
action 3, numVisits=1078848, meanQ=17.677603, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.612272 0.899263 0.0936147 0.548871 0.635179 0.802011 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=80599, meanQ=16.458400, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1245552 episodes
GETTING ACTION FROM:
action -1, numVisits=1326148, meanQ=2.907778, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.612272 0.899263 0.0936147 0.548871 0.635179 0.802011 w: 1
Observation: 0 0.567152 0 0.0631249 0 0.702316 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=371298, meanQ=17.041718, numObservations: 3
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1340753 episodes
GETTING ACTION FROM:
action 3, numVisits=1712051, meanQ=17.171212, numObservations: 4
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.612272 0.899263 0.0936147 0.548871 0.635179 0.802011 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 17.5424
Run # 91
Initial state: 0 0.326468 0.630134 0.532712 0.86318 0.613608 0.879762 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1114958 episodes
GETTING ACTION FROM:
action 2, numVisits=1114949, meanQ=17.751598, numObservations: 5
action 1, numVisits=6, meanQ=13.665000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.326468 0.630134 0.532712 0.86318 0.613608 0.879762 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 92
Initial state: 0 0.632371 0.812617 0.467947 0.720212 0.681469 0.867491 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1141080 episodes
GETTING ACTION FROM:
action 2, numVisits=1141053, meanQ=17.846665, numObservations: 3
action 3, numVisits=18, meanQ=15.282783, numObservations: 2
action 1, numVisits=7, meanQ=14.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.632371 0.812617 0.467947 0.720212 0.681469 0.867491 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=188164, meanQ=23.157700, numObservations: 3
action 1, numVisits=82, meanQ=22.353904, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1463806 episodes
GETTING ACTION FROM:
action 3, numVisits=1651641, meanQ=19.659107, numObservations: 3
action 1, numVisits=411, meanQ=19.287620, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.632371 0.812617 0.467947 0.720212 0.681469 0.867491 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 93
Initial state: 0 0.974313 0.136007 0.58087 0.897607 0.528806 0.826279 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1128491 episodes
GETTING ACTION FROM:
action 2, numVisits=1128486, meanQ=17.876775, numObservations: 4
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.974313 0.136007 0.58087 0.897607 0.528806 0.826279 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 94
Initial state: 0 0.651183 0.894589 0.515239 0.86235 0.198103 0.174081 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1122310 episodes
GETTING ACTION FROM:
action 1, numVisits=1122306, meanQ=18.168303, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.651183 0.894589 0.515239 0.86235 0.198103 0.174081 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 95
Initial state: 0 0.205412 0.55728 0.566053 0.848888 0.669758 0.836414 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1117630 episodes
GETTING ACTION FROM:
action 2, numVisits=1117625, meanQ=17.854550, numObservations: 5
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.205412 0.55728 0.566053 0.848888 0.669758 0.836414 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 96
Initial state: 0 0.536251 0.864918 0.692656 0.842527 0.305366 0.176349 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1127213 episodes
GETTING ACTION FROM:
action 1, numVisits=1127208, meanQ=17.736723, numObservations: 4
action 2, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.536251 0.864918 0.692656 0.842527 0.305366 0.176349 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 97
Initial state: 0 0.651164 0.870642 0.175965 0.73784 0.646007 0.853302 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1138292 episodes
GETTING ACTION FROM:
action 2, numVisits=1138288, meanQ=17.859380, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.651164 0.870642 0.175965 0.73784 0.646007 0.853302 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=187019, meanQ=23.147352, numObservations: 4
action 1, numVisits=11, meanQ=19.089091, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1431301 episodes
GETTING ACTION FROM:
action 3, numVisits=1618313, meanQ=19.489817, numObservations: 4
action 1, numVisits=18, meanQ=17.110000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.651164 0.870642 0.175965 0.73784 0.646007 0.853302 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 98
Initial state: 0 0.361619 0.00819609 0.61661 0.855151 0.670618 0.886039 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1117833 episodes
GETTING ACTION FROM:
action 2, numVisits=1117815, meanQ=17.852577, numObservations: 4
action 1, numVisits=15, meanQ=13.666013, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.361619 0.00819609 0.61661 0.855151 0.670618 0.886039 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 99
Initial state: 0 0.521167 0.867111 0.647034 0.800087 0.855841 0.971798 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1125329 episodes
GETTING ACTION FROM:
action 2, numVisits=1125324, meanQ=17.817656, numObservations: 4
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.521167 0.867111 0.647034 0.800087 0.855841 0.971798 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 100
Initial state: 0 0.184327 0.900677 0.536051 0.813641 0.634071 0.839817 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1127220 episodes
GETTING ACTION FROM:
action 3, numVisits=1127215, meanQ=17.768505, numObservations: 4
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.184327 0.900677 0.536051 0.813641 0.634071 0.839817 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 101
Initial state: 0 0.713887 0.614102 0.678294 0.801111 0.662169 0.825507 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1128755 episodes
GETTING ACTION FROM:
action 3, numVisits=1128751, meanQ=18.081408, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.713887 0.614102 0.678294 0.801111 0.662169 0.825507 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 102
Initial state: 0 0.592315 0.827027 0.60689 0.885542 0.86129 0.929269 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1121195 episodes
GETTING ACTION FROM:
action 3, numVisits=1121191, meanQ=17.816212, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.592315 0.827027 0.60689 0.885542 0.86129 0.929269 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 103
Initial state: 0 0.531814 0.867992 0.511124 0.850388 0.730997 0.928342 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1113399 episodes
GETTING ACTION FROM:
action 1, numVisits=1113381, meanQ=17.737907, numObservations: 5
action 3, numVisits=12, meanQ=8.997508, numObservations: 4
action 2, numVisits=4, meanQ=8.497500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.531814 0.867992 0.511124 0.850388 0.730997 0.928342 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 104
Initial state: 0 0.592517 0.850912 0.63665 0.85515 0.203998 0.109246 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1134852 episodes
GETTING ACTION FROM:
action 1, numVisits=1134847, meanQ=17.862513, numObservations: 4
action 2, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.592517 0.850912 0.63665 0.85515 0.203998 0.109246 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 105
Initial state: 0 0.678324 0.80823 0.621952 0.803404 0.293367 0.451285 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1126856 episodes
GETTING ACTION FROM:
action 3, numVisits=1126852, meanQ=18.068792, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.678324 0.80823 0.621952 0.803404 0.293367 0.451285 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=156718, meanQ=23.304717, numObservations: 5
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1419743 episodes
GETTING ACTION FROM:
action 1, numVisits=1576461, meanQ=19.132134, numObservations: 5
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.678324 0.80823 0.621952 0.803404 0.293367 0.451285 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 106
Initial state: 0 0.648707 0.847676 0.828089 0.382206 0.614824 0.816479 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1131504 episodes
GETTING ACTION FROM:
action 2, numVisits=1131492, meanQ=17.852456, numObservations: 4
action 1, numVisits=9, meanQ=9.277778, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.648707 0.847676 0.828089 0.382206 0.614824 0.816479 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 107
Initial state: 0 0.308227 0.172259 0.505352 0.854557 0.53495 0.898481 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1110741 episodes
GETTING ACTION FROM:
action 2, numVisits=1110737, meanQ=17.766603, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.308227 0.172259 0.505352 0.854557 0.53495 0.898481 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 108
Initial state: 0 0.0855361 0.671438 0.585202 0.85262 0.558949 0.880849 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1138819 episodes
GETTING ACTION FROM:
action 1, numVisits=1138811, meanQ=17.757444, numObservations: 3
action 2, numVisits=5, meanQ=5.798020, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.0855361 0.671438 0.585202 0.85262 0.558949 0.880849 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 109
Initial state: 0 0.618848 0.850046 0.953585 0.0904977 0.695938 0.834911 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1119269 episodes
GETTING ACTION FROM:
action 2, numVisits=1119264, meanQ=17.752966, numObservations: 5
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.618848 0.850046 0.953585 0.0904977 0.695938 0.834911 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 110
Initial state: 0 0.596627 0.834075 0.89061 0.403907 0.687926 0.871594 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1134253 episodes
GETTING ACTION FROM:
action 2, numVisits=1134247, meanQ=17.757165, numObservations: 3
action 1, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.596627 0.834075 0.89061 0.403907 0.687926 0.871594 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 111
Initial state: 0 0.572276 0.899326 0.644488 0.830416 0.117552 0.408809 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1127138 episodes
GETTING ACTION FROM:
action 1, numVisits=1127132, meanQ=17.762211, numObservations: 4
action 2, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.572276 0.899326 0.644488 0.830416 0.117552 0.408809 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 112
Initial state: 0 0.600806 0.812734 0.642622 0.820573 0.854575 0.476448 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1130876 episodes
GETTING ACTION FROM:
action 2, numVisits=1130866, meanQ=17.836310, numObservations: 4
action 3, numVisits=7, meanQ=10.141429, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.600806 0.812734 0.642622 0.820573 0.854575 0.476448 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 113
Initial state: 0 0.679351 0.817308 0.55526 0.898016 0.0658475 0.979158 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 771751 episodes
GETTING ACTION FROM:
action 0, numVisits=771746, meanQ=15.684418, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.679351 0.817308 0.55526 0.898016 0.0658475 0.979158 w: 1
Observation: 0 0 0.789225 0 0.989293 0 0.968378 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=771726, meanQ=17.866301, numObservations: 5
action 2, numVisits=7, meanQ=11.282857, numObservations: 3
action 3, numVisits=10, meanQ=10.799000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1232265 episodes
GETTING ACTION FROM:
action 1, numVisits=2003991, meanQ=17.783538, numObservations: 5
action 2, numVisits=7, meanQ=11.282857, numObservations: 3
action 3, numVisits=10, meanQ=10.799000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.679351 0.817308 0.55526 0.898016 0.0658475 0.979158 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 114
Initial state: 0 0.779008 0.546908 0.660135 0.893093 0.569481 0.856171 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1125971 episodes
GETTING ACTION FROM:
action 3, numVisits=1125953, meanQ=17.744401, numObservations: 4
action 1, numVisits=8, meanQ=13.373775, numObservations: 3
action 2, numVisits=8, meanQ=12.872500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.779008 0.546908 0.660135 0.893093 0.569481 0.856171 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 115
Initial state: 0 0.686238 0.811143 0.151551 0.257151 0.618366 0.841419 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1123515 episodes
GETTING ACTION FROM:
action 2, numVisits=1123505, meanQ=17.733379, numObservations: 5
action 3, numVisits=7, meanQ=2.997171, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.686238 0.811143 0.151551 0.257151 0.618366 0.841419 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=128103, meanQ=23.511627, numObservations: 3
action 3, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1426894 episodes
GETTING ACTION FROM:
action 1, numVisits=1554997, meanQ=19.664071, numObservations: 5
action 3, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.686238 0.811143 0.151551 0.257151 0.618366 0.841419 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 116
Initial state: 0 0.670701 0.827953 0.765744 0.941172 0.669911 0.875143 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1120985 episodes
GETTING ACTION FROM:
action 3, numVisits=1120980, meanQ=17.816157, numObservations: 4
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.670701 0.827953 0.765744 0.941172 0.669911 0.875143 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 117
Initial state: 0 0.683705 0.837817 0.571729 0.832788 0.836087 0.75567 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1109310 episodes
GETTING ACTION FROM:
action 3, numVisits=1109305, meanQ=17.739925, numObservations: 5
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.683705 0.837817 0.571729 0.832788 0.836087 0.75567 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 118
Initial state: 0 0.535931 0.807792 0.693175 0.862736 0.771428 0.68989 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1120883 episodes
GETTING ACTION FROM:
action 2, numVisits=1120875, meanQ=17.762138, numObservations: 5
action 3, numVisits=5, meanQ=6.196000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.535931 0.807792 0.693175 0.862736 0.771428 0.68989 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 119
Initial state: 0 0.685215 0.867703 0.0474601 0.522146 0.655484 0.806418 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1116235 episodes
GETTING ACTION FROM:
action 1, numVisits=1116228, meanQ=17.753639, numObservations: 5
action 3, numVisits=3, meanQ=12.333333, numObservations: 1
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.685215 0.867703 0.0474601 0.522146 0.655484 0.806418 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 120
Initial state: 0 0.0616629 0.0369584 0.581504 0.889615 0.655896 0.884206 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1120792 episodes
GETTING ACTION FROM:
action 1, numVisits=1120788, meanQ=17.869691, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.0616629 0.0369584 0.581504 0.889615 0.655896 0.884206 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=156975, meanQ=23.315036, numObservations: 3
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1450092 episodes
GETTING ACTION FROM:
action 3, numVisits=1607067, meanQ=19.262622, numObservations: 3
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.0616629 0.0369584 0.581504 0.889615 0.655896 0.884206 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 121
Initial state: 0 0.558309 0.83572 0.607623 0.862223 0.339806 0.869332 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 750843 episodes
GETTING ACTION FROM:
action -1, numVisits=750839, meanQ=15.472630, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.558309 0.83572 0.607623 0.862223 0.339806 0.869332 w: 1
Observation: 0 0.641168 0 0.565556 0 0.361984 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=750826, meanQ=17.676763, numObservations: 5
action 2, numVisits=4, meanQ=10.495000, numObservations: 2
action 1, numVisits=6, meanQ=9.163333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1165708 episodes
GETTING ACTION FROM:
action 3, numVisits=1916534, meanQ=17.567143, numObservations: 5
action 2, numVisits=4, meanQ=10.495000, numObservations: 2
action 1, numVisits=6, meanQ=9.163333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 2 0.558309 0.83572 0.607623 0.862223 0.339806 0.869332 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 122
Initial state: 0 0.97998 0.535898 0.668194 0.865866 0.616972 0.807842 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1126540 episodes
GETTING ACTION FROM:
action 2, numVisits=1126533, meanQ=17.783076, numObservations: 4
action 1, numVisits=4, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.97998 0.535898 0.668194 0.865866 0.616972 0.807842 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 123
Initial state: 0 0.610742 0.812997 0.616284 0.831766 0.551787 0.95435 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1121517 episodes
GETTING ACTION FROM:
action 2, numVisits=1121501, meanQ=17.751160, numObservations: 4
action 3, numVisits=12, meanQ=14.477508, numObservations: 4
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.610742 0.812997 0.616284 0.831766 0.551787 0.95435 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 124
Initial state: 0 0.686307 0.803068 0.166472 0.335234 0.650966 0.815808 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1052001 episodes
GETTING ACTION FROM:
action 3, numVisits=1051993, meanQ=17.602444, numObservations: 5
action 2, numVisits=5, meanQ=13.196000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.686307 0.803068 0.166472 0.335234 0.650966 0.815808 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 125
Initial state: 0 0.673813 0.843571 0.957357 0.913744 0.506487 0.809601 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1119803 episodes
GETTING ACTION FROM:
action 2, numVisits=1119797, meanQ=17.863809, numObservations: 4
action 1, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.673813 0.843571 0.957357 0.913744 0.506487 0.809601 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 126
Initial state: 0 0.887886 0.599014 0.504716 0.842199 0.578948 0.815423 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1112803 episodes
GETTING ACTION FROM:
action 2, numVisits=1112786, meanQ=17.863733, numObservations: 5
action 1, numVisits=14, meanQ=15.712143, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.887886 0.599014 0.504716 0.842199 0.578948 0.815423 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=81748, meanQ=18.701149, numObservations: 3
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1359843 episodes
GETTING ACTION FROM:
action 2, numVisits=1441591, meanQ=17.932985, numObservations: 3
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.887886 0.599014 0.504716 0.842199 0.578948 0.815423 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 127
Initial state: 0 0.500628 0.868514 0.377884 0.0433881 0.657504 0.887115 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1126245 episodes
GETTING ACTION FROM:
action 3, numVisits=1126240, meanQ=17.748815, numObservations: 4
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.500628 0.868514 0.377884 0.0433881 0.657504 0.887115 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 128
Initial state: 0 0.617716 0.878271 0.186965 0.191528 0.689364 0.882153 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1128509 episodes
GETTING ACTION FROM:
action 3, numVisits=1128500, meanQ=17.833009, numObservations: 4
action 2, numVisits=5, meanQ=11.598000, numObservations: 2
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.617716 0.878271 0.186965 0.191528 0.689364 0.882153 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 129
Initial state: 0 0.692693 0.821489 0.579908 0.278019 0.699791 0.818392 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1092972 episodes
GETTING ACTION FROM:
action 2, numVisits=1092967, meanQ=17.974352, numObservations: 5
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.692693 0.821489 0.579908 0.278019 0.699791 0.818392 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=125171, meanQ=23.506772, numObservations: 3
action 1, numVisits=7, meanQ=20.141429, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1431697 episodes
GETTING ACTION FROM:
action 3, numVisits=1556836, meanQ=19.574806, numObservations: 4
action 1, numVisits=39, meanQ=18.281541, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.692693 0.821489 0.579908 0.278019 0.699791 0.818392 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 130
Initial state: 0 0.583026 0.811615 0.591414 0.368283 0.69082 0.821387 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1138546 episodes
GETTING ACTION FROM:
action 2, numVisits=1138533, meanQ=17.830142, numObservations: 3
action 1, numVisits=7, meanQ=11.282857, numObservations: 3
action 3, numVisits=4, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.583026 0.811615 0.591414 0.368283 0.69082 0.821387 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=187297, meanQ=23.166983, numObservations: 5
action 3, numVisits=5, meanQ=18.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1423707 episodes
GETTING ACTION FROM:
action 1, numVisits=1611002, meanQ=19.544939, numObservations: 5
action 3, numVisits=7, meanQ=15.141429, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.583026 0.811615 0.591414 0.368283 0.69082 0.821387 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=7002, meanQ=22.481324, numObservations: 4
action 1, numVisits=5, meanQ=18.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1482083 episodes
GETTING ACTION FROM:
action 3, numVisits=1489083, meanQ=19.411461, numObservations: 4
action 1, numVisits=7, meanQ=15.141429, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.583026 0.811615 0.591414 0.368283 0.69082 0.821387 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 131
Initial state: 0 0.693485 0.815657 0.395044 0.302229 0.596221 0.808435 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1120224 episodes
GETTING ACTION FROM:
action 3, numVisits=1120212, meanQ=17.849071, numObservations: 5
action 1, numVisits=9, meanQ=11.107778, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.693485 0.815657 0.395044 0.302229 0.596221 0.808435 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 132
Initial state: 0 0.674509 0.843667 0.555083 0.89905 0.319612 0.690147 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1109805 episodes
GETTING ACTION FROM:
action 2, numVisits=1109797, meanQ=17.741984, numObservations: 5
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.674509 0.843667 0.555083 0.89905 0.319612 0.690147 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 133
Initial state: 0 0.698989 0.871283 0.262548 0.910902 0.504337 0.873962 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1127264 episodes
GETTING ACTION FROM:
action 2, numVisits=1127255, meanQ=17.791467, numObservations: 4
action 1, numVisits=6, meanQ=7.831667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.698989 0.871283 0.262548 0.910902 0.504337 0.873962 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=65717, meanQ=22.274604, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1446277 episodes
GETTING ACTION FROM:
action 3, numVisits=1511994, meanQ=19.447914, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.698989 0.871283 0.262548 0.910902 0.504337 0.873962 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action -1, numVisits=31894, meanQ=19.502121, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1485204 episodes
GETTING ACTION FROM:
action 1, numVisits=1386128, meanQ=19.135243, numObservations: 4
action -1, numVisits=130970, meanQ=3.836199, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.698989 0.871283 0.262548 0.910902 0.504337 0.873962 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 134
Initial state: 0 0.428076 0.330947 0.660928 0.841538 0.525082 0.84739 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1123210 episodes
GETTING ACTION FROM:
action 1, numVisits=1123206, meanQ=17.847317, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.428076 0.330947 0.660928 0.841538 0.525082 0.84739 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=157395, meanQ=23.301320, numObservations: 3
action 2, numVisits=6, meanQ=19.498333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1446125 episodes
GETTING ACTION FROM:
action 3, numVisits=1603519, meanQ=19.038052, numObservations: 3
action 2, numVisits=7, meanQ=15.141429, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.428076 0.330947 0.660928 0.841538 0.525082 0.84739 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=4510, meanQ=22.040067, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1467847 episodes
GETTING ACTION FROM:
action 2, numVisits=1472357, meanQ=19.320096, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.428076 0.330947 0.660928 0.841538 0.525082 0.84739 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 135
Initial state: 0 0.522029 0.866617 0.500367 0.840136 0.890791 0.61513 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1115776 episodes
GETTING ACTION FROM:
action 3, numVisits=1115772, meanQ=17.873073, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.522029 0.866617 0.500367 0.840136 0.890791 0.61513 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 136
Initial state: 0 0.632209 0.894455 0.574059 0.863239 0.700742 0.0404394 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1107291 episodes
GETTING ACTION FROM:
action 3, numVisits=1107283, meanQ=17.829319, numObservations: 5
action 2, numVisits=5, meanQ=13.196000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.632209 0.894455 0.574059 0.863239 0.700742 0.0404394 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 137
Initial state: 0 0.635089 0.810754 0.438251 0.324075 0.606209 0.880033 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1123479 episodes
GETTING ACTION FROM:
action 1, numVisits=1123461, meanQ=18.114451, numObservations: 4
action 2, numVisits=10, meanQ=15.098000, numObservations: 2
action 3, numVisits=6, meanQ=14.335017, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.635089 0.810754 0.438251 0.324075 0.606209 0.880033 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 138
Initial state: 0 0.533546 0.825113 0.713733 0.111422 0.615173 0.805037 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1128928 episodes
GETTING ACTION FROM:
action 2, numVisits=1128922, meanQ=17.757801, numObservations: 4
action 3, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.533546 0.825113 0.713733 0.111422 0.615173 0.805037 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 139
Initial state: 0 0.236089 0.366768 0.596464 0.808115 0.597903 0.892638 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1109448 episodes
GETTING ACTION FROM:
action 1, numVisits=1109436, meanQ=17.851047, numObservations: 5
action 2, numVisits=9, meanQ=10.220000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.236089 0.366768 0.596464 0.808115 0.597903 0.892638 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=155728, meanQ=23.316487, numObservations: 3
action 3, numVisits=6, meanQ=19.498333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1469985 episodes
GETTING ACTION FROM:
action 2, numVisits=1625712, meanQ=19.512137, numObservations: 3
action 3, numVisits=7, meanQ=16.282857, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.236089 0.366768 0.596464 0.808115 0.597903 0.892638 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 140
Initial state: 0 0.611877 0.891859 0.561139 0.845774 0.603207 0.632118 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1120579 episodes
GETTING ACTION FROM:
action 3, numVisits=1120540, meanQ=17.846595, numObservations: 4
action 2, numVisits=20, meanQ=14.599005, numObservations: 2
action 1, numVisits=17, meanQ=13.630594, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 2 0.611877 0.891859 0.561139 0.845774 0.603207 0.632118 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 141
Initial state: 0 0.634034 0.827644 0.265997 0.107824 0.684837 0.800558 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1090778 episodes
GETTING ACTION FROM:
action 2, numVisits=1090772, meanQ=17.935621, numObservations: 5
action 3, numVisits=3, meanQ=12.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.634034 0.827644 0.265997 0.107824 0.684837 0.800558 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=124698, meanQ=23.505423, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1437559 episodes
GETTING ACTION FROM:
action 1, numVisits=1562257, meanQ=19.635335, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.634034 0.827644 0.265997 0.107824 0.684837 0.800558 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 142
Initial state: 0 0.504309 0.898444 0.296893 0.00744845 0.632404 0.867018 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1135138 episodes
GETTING ACTION FROM:
action 3, numVisits=1135127, meanQ=17.792158, numObservations: 3
action 2, numVisits=8, meanQ=8.497500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.504309 0.898444 0.296893 0.00744845 0.632404 0.867018 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 143
Initial state: 0 0.5355 0.8172 0.691317 0.804617 0.274634 0.588316 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1128139 episodes
GETTING ACTION FROM:
action 2, numVisits=1128129, meanQ=17.835325, numObservations: 4
action 3, numVisits=6, meanQ=9.163333, numObservations: 2
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.5355 0.8172 0.691317 0.804617 0.274634 0.588316 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 144
Initial state: 0 0.564448 0.356144 0.648517 0.84755 0.514563 0.898979 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1108581 episodes
GETTING ACTION FROM:
action 3, numVisits=1108573, meanQ=17.756591, numObservations: 5
action 2, numVisits=5, meanQ=4.598000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.564448 0.356144 0.648517 0.84755 0.514563 0.898979 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 145
Initial state: 0 0.511239 0.82653 0.669292 0.819754 0.61711 0.78401 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1134246 episodes
GETTING ACTION FROM:
action 1, numVisits=1134241, meanQ=17.860484, numObservations: 4
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.511239 0.82653 0.669292 0.819754 0.61711 0.78401 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 146
Initial state: 0 0.580506 0.832519 0.629049 0.814211 0.716785 0.675707 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1129356 episodes
GETTING ACTION FROM:
action 2, numVisits=1129344, meanQ=17.758414, numObservations: 4
action 1, numVisits=8, meanQ=12.872500, numObservations: 3
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.580506 0.832519 0.629049 0.814211 0.716785 0.675707 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 147
Initial state: 0 0.168753 0.782753 0.605937 0.864664 0.669125 0.882957 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1124228 episodes
GETTING ACTION FROM:
action 1, numVisits=1124224, meanQ=17.897366, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.168753 0.782753 0.605937 0.864664 0.669125 0.882957 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=56673, meanQ=22.346508, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1418154 episodes
GETTING ACTION FROM:
action 3, numVisits=1474827, meanQ=18.640381, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.168753 0.782753 0.605937 0.864664 0.669125 0.882957 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 148
Initial state: 0 0.560809 0.816034 0.619562 0.837446 0.322087 0.796279 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1137004 episodes
GETTING ACTION FROM:
action 1, numVisits=1137000, meanQ=17.906242, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.560809 0.816034 0.619562 0.837446 0.322087 0.796279 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 149
Initial state: 0 0.0981072 0.711947 0.674122 0.821713 0.690637 0.87514 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1126757 episodes
GETTING ACTION FROM:
action 3, numVisits=1126747, meanQ=17.736041, numObservations: 4
action 2, numVisits=6, meanQ=7.831667, numObservations: 3
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.0981072 0.711947 0.674122 0.821713 0.690637 0.87514 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 150
Initial state: 0 0.596583 0.938341 0.628484 0.859691 0.502827 0.866663 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1119427 episodes
GETTING ACTION FROM:
action 3, numVisits=1119417, meanQ=17.765668, numObservations: 4
action 2, numVisits=6, meanQ=13.665000, numObservations: 2
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.596583 0.938341 0.628484 0.859691 0.502827 0.866663 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 151
Initial state: 0 0.588947 0.81668 0.666964 0.808822 0.155081 0.260945 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1089432 episodes
GETTING ACTION FROM:
action 2, numVisits=1089426, meanQ=17.939768, numObservations: 4
action 1, numVisits=3, meanQ=3.330000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.588947 0.81668 0.666964 0.808822 0.155081 0.260945 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 152
Initial state: 0 0.0981173 0.806907 0.690837 0.803798 0.64257 0.857906 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 772092 episodes
GETTING ACTION FROM:
action 0, numVisits=772087, meanQ=15.902990, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.0981173 0.806907 0.690837 0.803798 0.64257 0.857906 w: 1
Observation: 0 0 0.871366 0 0.845249 0 0.8534 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=772081, meanQ=18.092901, numObservations: 4
action 2, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1229542 episodes
GETTING ACTION FROM:
action 3, numVisits=2001623, meanQ=18.043215, numObservations: 4
action 2, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.0981173 0.806907 0.690837 0.803798 0.64257 0.857906 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 153
Initial state: 0 0.688599 0.825367 0.633019 0.856345 0.354295 0.509046 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1130927 episodes
GETTING ACTION FROM:
action 2, numVisits=1130923, meanQ=17.731803, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.688599 0.825367 0.633019 0.856345 0.354295 0.509046 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 154
Initial state: 0 0.518911 0.816622 0.507885 0.821925 0.926786 0.105614 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1124969 episodes
GETTING ACTION FROM:
action 3, numVisits=1124964, meanQ=18.081129, numObservations: 4
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.518911 0.816622 0.507885 0.821925 0.926786 0.105614 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 155
Initial state: 0 0.613547 0.895555 0.756702 0.279414 0.626143 0.819656 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1130965 episodes
GETTING ACTION FROM:
action 2, numVisits=1130950, meanQ=17.882312, numObservations: 4
action 1, numVisits=9, meanQ=10.886678, numObservations: 3
action 3, numVisits=4, meanQ=8.497500, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 2 0.613547 0.895555 0.756702 0.279414 0.626143 0.819656 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 156
Initial state: 0 0.574913 0.891855 0.0785415 0.609742 0.63917 0.816278 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1118524 episodes
GETTING ACTION FROM:
action 2, numVisits=1118515, meanQ=17.750242, numObservations: 4
action 1, numVisits=6, meanQ=9.163333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.574913 0.891855 0.0785415 0.609742 0.63917 0.816278 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 157
Initial state: 0 0.951223 0.206784 0.552613 0.869954 0.52755 0.856968 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1117290 episodes
GETTING ACTION FROM:
action 2, numVisits=1117283, meanQ=17.865522, numObservations: 5
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action 3, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.951223 0.206784 0.552613 0.869954 0.52755 0.856968 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 158
Initial state: 0 0.650492 0.861748 0.648979 0.831044 0.74942 0.395328 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 777407 episodes
GETTING ACTION FROM:
action -1, numVisits=777403, meanQ=15.662812, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.650492 0.861748 0.648979 0.831044 0.74942 0.395328 w: 1
Observation: 0 0.606378 0 0.708258 0 0.843093 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=777397, meanQ=17.859784, numObservations: 5
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1217585 episodes
GETTING ACTION FROM:
action 3, numVisits=1994982, meanQ=17.749706, numObservations: 5
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.650492 0.861748 0.648979 0.831044 0.74942 0.395328 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=151466, meanQ=18.634276, numObservations: 4
action 1, numVisits=11, meanQ=6.726382, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1321449 episodes
GETTING ACTION FROM:
action 3, numVisits=1472915, meanQ=17.099560, numObservations: 4
action 1, numVisits=11, meanQ=6.726382, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.650492 0.861748 0.648979 0.831044 0.74942 0.395328 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -16.7411
Run # 159
Initial state: 0 0.5678 0.842091 0.635979 0.842963 0.913912 0.551384 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1128953 episodes
GETTING ACTION FROM:
action 2, numVisits=1128948, meanQ=17.775216, numObservations: 4
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.5678 0.842091 0.635979 0.842963 0.913912 0.551384 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=82266, meanQ=17.340168, numObservations: 3
action 2, numVisits=5, meanQ=6.196000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1452736 episodes
GETTING ACTION FROM:
action 1, numVisits=1535002, meanQ=18.926023, numObservations: 3
action 2, numVisits=5, meanQ=6.196000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.5678 0.842091 0.635979 0.842963 0.913912 0.551384 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 160
Initial state: 0 0.82725 0.0725082 0.658317 0.891227 0.611496 0.89531 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1124876 episodes
GETTING ACTION FROM:
action 3, numVisits=1124857, meanQ=17.757818, numObservations: 4
action 1, numVisits=15, meanQ=15.472667, numObservations: 3
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.82725 0.0725082 0.658317 0.891227 0.611496 0.89531 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 161
Initial state: 0 0.548916 0.812463 0.57561 0.868491 0.235989 0.07216 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1128506 episodes
GETTING ACTION FROM:
action 2, numVisits=1128497, meanQ=17.862568, numObservations: 4
action 3, numVisits=3, meanQ=12.333333, numObservations: 1
action 1, numVisits=4, meanQ=8.497500, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.548916 0.812463 0.57561 0.868491 0.235989 0.07216 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 162
Initial state: 0 0.806172 0.0141554 0.529412 0.83856 0.622258 0.890667 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1118566 episodes
GETTING ACTION FROM:
action 1, numVisits=1118546, meanQ=18.095752, numObservations: 5
action 3, numVisits=16, meanQ=11.873750, numObservations: 3
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 2 0.806172 0.0141554 0.529412 0.83856 0.622258 0.890667 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 163
Initial state: 0 0.656372 0.877634 0.601003 0.894998 0.421053 0.515064 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1052192 episodes
GETTING ACTION FROM:
action 1, numVisits=1052149, meanQ=17.463354, numObservations: 5
action 3, numVisits=39, meanQ=13.024628, numObservations: 5
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.656372 0.877634 0.601003 0.894998 0.421053 0.515064 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 164
Initial state: 0 0.696708 0.878946 0.715841 0.453304 0.673989 0.801464 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1117923 episodes
GETTING ACTION FROM:
action 3, numVisits=1117906, meanQ=17.742563, numObservations: 4
action 1, numVisits=10, meanQ=7.674000, numObservations: 3
action 2, numVisits=5, meanQ=6.196000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.696708 0.878946 0.715841 0.453304 0.673989 0.801464 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 165
Initial state: 0 0.45862 0.0966966 0.595531 0.855497 0.552219 0.823761 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1116870 episodes
GETTING ACTION FROM:
action 2, numVisits=1116866, meanQ=17.784427, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.45862 0.0966966 0.595531 0.855497 0.552219 0.823761 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 166
Initial state: 0 0.98798 0.573994 0.618366 0.855389 0.636 0.89857 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1118489 episodes
GETTING ACTION FROM:
action 1, numVisits=1118480, meanQ=17.858410, numObservations: 5
action 3, numVisits=5, meanQ=11.598000, numObservations: 3
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 2 0.98798 0.573994 0.618366 0.855389 0.636 0.89857 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 167
Initial state: 0 0.243119 0.645941 0.588349 0.857073 0.509454 0.80266 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1131712 episodes
GETTING ACTION FROM:
action 1, numVisits=1131708, meanQ=17.843237, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.243119 0.645941 0.588349 0.857073 0.509454 0.80266 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=185694, meanQ=23.162701, numObservations: 3
action 3, numVisits=7, meanQ=20.141429, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1471489 episodes
GETTING ACTION FROM:
action 2, numVisits=1657112, meanQ=18.865049, numObservations: 3
action 3, numVisits=78, meanQ=17.788591, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.243119 0.645941 0.588349 0.857073 0.509454 0.80266 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 168
Initial state: 0 0.624435 0.816564 0.662882 0.580535 0.582095 0.890735 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1116876 episodes
GETTING ACTION FROM:
action 3, numVisits=1116860, meanQ=17.776764, numObservations: 5
action 1, numVisits=7, meanQ=10.998586, numObservations: 1
action 2, numVisits=7, meanQ=10.715729, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.624435 0.816564 0.662882 0.580535 0.582095 0.890735 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 169
Initial state: 0 0.668883 0.856391 0.776319 0.954233 0.604574 0.804903 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1132013 episodes
GETTING ACTION FROM:
action 1, numVisits=1132007, meanQ=17.851182, numObservations: 4
action 2, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.668883 0.856391 0.776319 0.954233 0.604574 0.804903 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 170
Initial state: 0 0.686333 0.824834 0.986914 0.622245 0.545873 0.877471 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 772946 episodes
GETTING ACTION FROM:
action 0, numVisits=772940, meanQ=15.747693, numObservations: 1
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.686333 0.824834 0.986914 0.622245 0.545873 0.877471 w: 1
Observation: 0 0 0.848009 0 0.527935 0 0.882758 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=772935, meanQ=17.919508, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1220688 episodes
GETTING ACTION FROM:
action 3, numVisits=1993623, meanQ=17.488531, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.686333 0.824834 0.986914 0.622245 0.545873 0.877471 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 171
Initial state: 0 0.69391 0.875929 0.57912 0.807606 0.768841 0.819179 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1127320 episodes
GETTING ACTION FROM:
action 2, numVisits=1127316, meanQ=18.151898, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.69391 0.875929 0.57912 0.807606 0.768841 0.819179 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 172
Initial state: 0 0.504836 0.834631 0.622822 0.886022 0.942396 0.755827 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1128384 episodes
GETTING ACTION FROM:
action 2, numVisits=1128379, meanQ=17.855943, numObservations: 5
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.504836 0.834631 0.622822 0.886022 0.942396 0.755827 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 173
Initial state: 0 0.54313 0.168984 0.589981 0.822714 0.522427 0.829498 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1102104 episodes
GETTING ACTION FROM:
action 3, numVisits=1102100, meanQ=17.757019, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.54313 0.168984 0.589981 0.822714 0.522427 0.829498 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 174
Initial state: 0 0.670646 0.869295 0.632576 0.899841 0.502193 0.251002 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1128881 episodes
GETTING ACTION FROM:
action 2, numVisits=1128869, meanQ=17.755389, numObservations: 4
action 3, numVisits=9, meanQ=9.778900, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.670646 0.869295 0.632576 0.899841 0.502193 0.251002 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 175
Initial state: 0 0.0579626 0.181385 0.587232 0.814705 0.546999 0.835624 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1125077 episodes
GETTING ACTION FROM:
action 1, numVisits=1125073, meanQ=17.735800, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.0579626 0.181385 0.587232 0.814705 0.546999 0.835624 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 176
Initial state: 0 0.59361 0.868828 0.26341 0.647367 0.635379 0.82587 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1127812 episodes
GETTING ACTION FROM:
action 3, numVisits=1127804, meanQ=17.860480, numObservations: 4
action 1, numVisits=5, meanQ=4.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.59361 0.868828 0.26341 0.647367 0.635379 0.82587 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 177
Initial state: 0 0.552834 0.839727 0.505932 0.834799 0.238826 0.539862 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1108903 episodes
GETTING ACTION FROM:
action 3, numVisits=1108899, meanQ=17.746709, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.552834 0.839727 0.505932 0.834799 0.238826 0.539862 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=27420, meanQ=22.004998, numObservations: 5
action 2, numVisits=29, meanQ=19.313793, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1409605 episodes
GETTING ACTION FROM:
action 1, numVisits=1437008, meanQ=18.527034, numObservations: 5
action 2, numVisits=46, meanQ=17.371741, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.552834 0.839727 0.505932 0.834799 0.238826 0.539862 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 0, numVisits=28312, meanQ=19.157980, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1468304 episodes
GETTING ACTION FROM:
action 1, numVisits=1384640, meanQ=17.793129, numObservations: 4
action 0, numVisits=111977, meanQ=3.789013, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.552834 0.839727 0.505932 0.834799 0.238826 0.539862 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 178
Initial state: 0 0.578205 0.886602 0.956811 0.135789 0.622914 0.883561 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1133335 episodes
GETTING ACTION FROM:
action 2, numVisits=1133331, meanQ=17.780290, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.578205 0.886602 0.956811 0.135789 0.622914 0.883561 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 179
Initial state: 0 0.634472 0.807775 0.559196 0.817587 0.687382 0.171103 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1120038 episodes
GETTING ACTION FROM:
action 1, numVisits=1120033, meanQ=17.764073, numObservations: 5
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.634472 0.807775 0.559196 0.817587 0.687382 0.171103 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 180
Initial state: 0 0.0861922 0.933428 0.537734 0.842042 0.632245 0.877893 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1137430 episodes
GETTING ACTION FROM:
action 2, numVisits=1137421, meanQ=17.790885, numObservations: 3
action 1, numVisits=6, meanQ=13.665000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.0861922 0.933428 0.537734 0.842042 0.632245 0.877893 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 181
Initial state: 0 0.545133 0.824235 0.570444 0.80772 0.137603 0.977309 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1122351 episodes
GETTING ACTION FROM:
action 3, numVisits=1122346, meanQ=18.180583, numObservations: 5
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.545133 0.824235 0.570444 0.80772 0.137603 0.977309 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=23457, meanQ=20.578590, numObservations: 5
action 2, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1413010 episodes
GETTING ACTION FROM:
action 1, numVisits=1436467, meanQ=19.068220, numObservations: 5
action 2, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.545133 0.824235 0.570444 0.80772 0.137603 0.977309 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 182
Initial state: 0 0.692837 0.849622 0.310741 0.943363 0.594503 0.813845 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1125937 episodes
GETTING ACTION FROM:
action 1, numVisits=1125933, meanQ=17.770649, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.692837 0.849622 0.310741 0.943363 0.594503 0.813845 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 183
Initial state: 0 0.669009 0.886513 0.687784 0.836698 0.114002 0.209661 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1119698 episodes
GETTING ACTION FROM:
action 2, numVisits=1119694, meanQ=17.750447, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.669009 0.886513 0.687784 0.836698 0.114002 0.209661 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=10834, meanQ=16.983024, numObservations: 4
action 3, numVisits=11, meanQ=7.272745, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1439042 episodes
GETTING ACTION FROM:
action 1, numVisits=1449876, meanQ=18.828212, numObservations: 4
action 3, numVisits=11, meanQ=7.272745, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.669009 0.886513 0.687784 0.836698 0.114002 0.209661 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 184
Initial state: 0 0.437537 0.344759 0.662256 0.870248 0.541869 0.829706 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1133633 episodes
GETTING ACTION FROM:
action 1, numVisits=1133103, meanQ=17.846312, numObservations: 4
action 2, numVisits=527, meanQ=17.452568, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.437537 0.344759 0.662256 0.870248 0.541869 0.829706 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=129864, meanQ=23.514059, numObservations: 3
action 3, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1475286 episodes
GETTING ACTION FROM:
action 2, numVisits=1605150, meanQ=19.243806, numObservations: 3
action 3, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.437537 0.344759 0.662256 0.870248 0.541869 0.829706 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 185
Initial state: 0 0.13096 0.102757 0.662222 0.888691 0.544112 0.892411 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1116894 episodes
GETTING ACTION FROM:
action 3, numVisits=1116888, meanQ=17.816497, numObservations: 4
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.13096 0.102757 0.662222 0.888691 0.544112 0.892411 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 186
Initial state: 0 0.506932 0.849974 0.857153 0.742461 0.695571 0.800562 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1140903 episodes
GETTING ACTION FROM:
action 1, numVisits=1140899, meanQ=17.875142, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.506932 0.849974 0.857153 0.742461 0.695571 0.800562 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=10649, meanQ=19.082513, numObservations: 3
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1338820 episodes
GETTING ACTION FROM:
action 1, numVisits=1349469, meanQ=17.649870, numObservations: 4
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.506932 0.849974 0.857153 0.742461 0.695571 0.800562 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 187
Initial state: 0 0.86606 0.237811 0.570114 0.889417 0.69046 0.859426 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1120053 episodes
GETTING ACTION FROM:
action 1, numVisits=1120049, meanQ=17.845194, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.86606 0.237811 0.570114 0.889417 0.69046 0.859426 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 188
Initial state: 0 0.563581 0.840687 0.594672 0.854137 0.456833 0.954443 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1135394 episodes
GETTING ACTION FROM:
action 2, numVisits=1135390, meanQ=17.765025, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.563581 0.840687 0.594672 0.854137 0.456833 0.954443 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 189
Initial state: 0 0.52036 0.814257 0.445783 0.535182 0.616731 0.819737 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1117451 episodes
GETTING ACTION FROM:
action 1, numVisits=1117446, meanQ=17.739319, numObservations: 4
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.52036 0.814257 0.445783 0.535182 0.616731 0.819737 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 190
Initial state: 0 0.628782 0.896711 0.730227 0.093967 0.545706 0.886935 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1119426 episodes
GETTING ACTION FROM:
action 1, numVisits=1119418, meanQ=17.854615, numObservations: 5
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action 2, numVisits=4, meanQ=8.497500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.628782 0.896711 0.730227 0.093967 0.545706 0.886935 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 191
Initial state: 0 0.0362071 0.548648 0.564428 0.833078 0.64373 0.878703 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1107868 episodes
GETTING ACTION FROM:
action 3, numVisits=1107862, meanQ=17.779183, numObservations: 5
action 2, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.0362071 0.548648 0.564428 0.833078 0.64373 0.878703 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 192
Initial state: 0 0.599195 0.875167 0.596418 0.838915 0.386001 0.0363613 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1141479 episodes
GETTING ACTION FROM:
action 1, numVisits=1141444, meanQ=17.856005, numObservations: 3
action 2, numVisits=32, meanQ=13.468134, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.599195 0.875167 0.596418 0.838915 0.386001 0.0363613 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 193
Initial state: 0 0.543472 0.814949 0.269152 0.136391 0.560148 0.839171 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1125080 episodes
GETTING ACTION FROM:
action 3, numVisits=1125070, meanQ=17.769840, numObservations: 4
action 1, numVisits=7, meanQ=14.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.543472 0.814949 0.269152 0.136391 0.560148 0.839171 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 194
Initial state: 0 0.611712 0.835383 0.47707 0.118082 0.659068 0.813075 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1121466 episodes
GETTING ACTION FROM:
action 3, numVisits=1121460, meanQ=17.862318, numObservations: 4
action 2, numVisits=3, meanQ=4.670033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.611712 0.835383 0.47707 0.118082 0.659068 0.813075 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 195
Initial state: 0 0.623791 0.877229 0.449062 0.504195 0.63516 0.843849 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1104831 episodes
GETTING ACTION FROM:
action 3, numVisits=1104827, meanQ=17.728244, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.623791 0.877229 0.449062 0.504195 0.63516 0.843849 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 196
Initial state: 0 0.531872 0.845802 0.718456 0.887324 0.539894 0.822217 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1122794 episodes
GETTING ACTION FROM:
action 2, numVisits=1122790, meanQ=17.753273, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.531872 0.845802 0.718456 0.887324 0.539894 0.822217 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 197
Initial state: 0 0.628012 0.836482 0.679539 0.844382 0.528852 0.320806 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1124504 episodes
GETTING ACTION FROM:
action 3, numVisits=1124491, meanQ=18.102954, numObservations: 4
action 2, numVisits=10, meanQ=9.898030, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.628012 0.836482 0.679539 0.844382 0.528852 0.320806 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 198
Initial state: 0 0.666724 0.801182 0.571311 0.893659 0.405876 0.403945 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1108801 episodes
GETTING ACTION FROM:
action 3, numVisits=1108796, meanQ=17.842095, numObservations: 5
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.666724 0.801182 0.571311 0.893659 0.405876 0.403945 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 199
Initial state: 0 0.671969 0.809705 0.4688 0.666999 0.590133 0.803484 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1139413 episodes
GETTING ACTION FROM:
action 2, numVisits=1139408, meanQ=17.734673, numObservations: 3
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.671969 0.809705 0.4688 0.666999 0.590133 0.803484 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=187524, meanQ=22.981252, numObservations: 3
action 3, numVisits=5, meanQ=18.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1427976 episodes
GETTING ACTION FROM:
action 1, numVisits=1615432, meanQ=19.265372, numObservations: 3
action 3, numVisits=73, meanQ=18.297945, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.671969 0.809705 0.4688 0.666999 0.590133 0.803484 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 200
Initial state: 0 0.863164 0.928741 0.672363 0.86665 0.643122 0.814511 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1100675 episodes
GETTING ACTION FROM:
action 3, numVisits=1100671, meanQ=17.766341, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.863164 0.928741 0.672363 0.86665 0.643122 0.814511 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=82249, meanQ=17.416126, numObservations: 4
action 1, numVisits=3, meanQ=5.330033, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1413690 episodes
GETTING ACTION FROM:
action 2, numVisits=1495939, meanQ=18.550838, numObservations: 4
action 1, numVisits=3, meanQ=5.330033, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.863164 0.928741 0.672363 0.86665 0.643122 0.814511 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 201
Initial state: 0 0.557428 0.83717 0.760517 0.246674 0.5151 0.87235 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1103566 episodes
GETTING ACTION FROM:
action 2, numVisits=1103545, meanQ=17.743520, numObservations: 4
action 1, numVisits=16, meanQ=10.061256, numObservations: 3
action 3, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 2 0.557428 0.83717 0.760517 0.246674 0.5151 0.87235 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 202
Initial state: 0 0.268578 0.211043 0.524515 0.822246 0.56969 0.812891 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1111026 episodes
GETTING ACTION FROM:
action 1, numVisits=1111022, meanQ=17.869041, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.268578 0.211043 0.524515 0.822246 0.56969 0.812891 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 203
Initial state: 0 0.696614 0.863404 0.805809 0.226212 0.665507 0.883006 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1096361 episodes
GETTING ACTION FROM:
action 1, numVisits=1096357, meanQ=17.735739, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.696614 0.863404 0.805809 0.226212 0.665507 0.883006 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 204
Initial state: 0 0.658219 0.8952 0.35621 0.780126 0.524909 0.885137 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1104654 episodes
GETTING ACTION FROM:
action 1, numVisits=1104650, meanQ=17.865309, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.658219 0.8952 0.35621 0.780126 0.524909 0.885137 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=81625, meanQ=18.567478, numObservations: 4
action 3, numVisits=3, meanQ=12.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1319514 episodes
GETTING ACTION FROM:
action 1, numVisits=1401139, meanQ=17.362761, numObservations: 4
action 3, numVisits=3, meanQ=12.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.658219 0.8952 0.35621 0.780126 0.524909 0.885137 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 205
Initial state: 0 0.585675 0.877268 0.140656 0.117955 0.641693 0.859214 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1115764 episodes
GETTING ACTION FROM:
action 1, numVisits=1115743, meanQ=17.757857, numObservations: 3
action 2, numVisits=16, meanQ=11.860006, numObservations: 3
action 3, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.585675 0.877268 0.140656 0.117955 0.641693 0.859214 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 206
Initial state: 0 0.520287 0.860791 0.64757 0.800814 0.685599 0.055897 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1094031 episodes
GETTING ACTION FROM:
action 2, numVisits=1094025, meanQ=18.097216, numObservations: 5
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.520287 0.860791 0.64757 0.800814 0.685599 0.055897 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 207
Initial state: 0 0.18363 0.919671 0.501017 0.871515 0.683761 0.816623 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1091201 episodes
GETTING ACTION FROM:
action 3, numVisits=1091197, meanQ=17.843492, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.18363 0.919671 0.501017 0.871515 0.683761 0.816623 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 208
Initial state: 0 0.745296 0.00692119 0.543355 0.875618 0.698211 0.851219 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1097450 episodes
GETTING ACTION FROM:
action 1, numVisits=1097445, meanQ=18.102895, numObservations: 5
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.745296 0.00692119 0.543355 0.875618 0.698211 0.851219 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=10013, meanQ=19.372514, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1314929 episodes
GETTING ACTION FROM:
action 1, numVisits=1324942, meanQ=16.981317, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.745296 0.00692119 0.543355 0.875618 0.698211 0.851219 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 209
Initial state: 0 0.645688 0.847553 0.504808 0.859474 0.00417037 0.550702 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1113788 episodes
GETTING ACTION FROM:
action 1, numVisits=1113781, meanQ=17.746575, numObservations: 3
action 2, numVisits=4, meanQ=-0.252500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.645688 0.847553 0.504808 0.859474 0.00417037 0.550702 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 210
Initial state: 0 0.553846 0.860374 0.0866766 0.530603 0.566989 0.814454 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1088993 episodes
GETTING ACTION FROM:
action 3, numVisits=1088956, meanQ=17.746647, numObservations: 5
action 2, numVisits=34, meanQ=13.322944, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.553846 0.860374 0.0866766 0.530603 0.566989 0.814454 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=79884, meanQ=17.441569, numObservations: 3
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1422474 episodes
GETTING ACTION FROM:
action 1, numVisits=1502358, meanQ=18.692633, numObservations: 3
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.553846 0.860374 0.0866766 0.530603 0.566989 0.814454 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 211
Initial state: 0 0.679739 0.848466 0.0708651 0.327456 0.547728 0.860264 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1109413 episodes
GETTING ACTION FROM:
action 3, numVisits=1109399, meanQ=17.845050, numObservations: 4
action 1, numVisits=11, meanQ=9.908200, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.679739 0.848466 0.0708651 0.327456 0.547728 0.860264 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 212
Initial state: 0 0.675803 0.88269 0.675894 0.884942 0.45382 0.130838 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1114344 episodes
GETTING ACTION FROM:
action 1, numVisits=1114340, meanQ=17.771429, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.675803 0.88269 0.675894 0.884942 0.45382 0.130838 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 213
Initial state: 0 0.422277 0.300112 0.603157 0.809471 0.529168 0.855944 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1090075 episodes
GETTING ACTION FROM:
action 1, numVisits=1090069, meanQ=17.671201, numObservations: 4
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 0 0.422277 0.300112 0.603157 0.809471 0.529168 0.855944 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=152218, meanQ=23.111952, numObservations: 4
action 2, numVisits=5, meanQ=18.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1396581 episodes
GETTING ACTION FROM:
action 3, numVisits=1548790, meanQ=19.309883, numObservations: 4
action 2, numVisits=14, meanQ=17.070714, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.422277 0.300112 0.603157 0.809471 0.529168 0.855944 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action -1, numVisits=39234, meanQ=20.343372, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1445171 episodes
GETTING ACTION FROM:
action 3, numVisits=1318378, meanQ=18.123091, numObservations: 4
action -1, numVisits=166023, meanQ=3.906928, numObservations: 1
action 2, numVisits=4, meanQ=-0.252500, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 3
Next state: 1 0.422277 0.300112 0.603157 0.809471 0.529168 0.855944 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 214
Initial state: 0 0.653622 0.633693 0.590401 0.813837 0.619134 0.806643 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1111408 episodes
GETTING ACTION FROM:
action 1, numVisits=1111401, meanQ=17.847183, numObservations: 4
action 3, numVisits=4, meanQ=8.497500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.653622 0.633693 0.590401 0.813837 0.619134 0.806643 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=182312, meanQ=23.174761, numObservations: 4
action 3, numVisits=13, meanQ=19.844615, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1420051 episodes
GETTING ACTION FROM:
action 2, numVisits=1602348, meanQ=18.957691, numObservations: 4
action 3, numVisits=28, meanQ=17.214289, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.653622 0.633693 0.590401 0.813837 0.619134 0.806643 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 215
Initial state: 0 0.51162 0.871266 0.301402 0.325626 0.632481 0.898739 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1094117 episodes
GETTING ACTION FROM:
action 3, numVisits=1094107, meanQ=17.849789, numObservations: 5
action 1, numVisits=7, meanQ=11.282857, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.51162 0.871266 0.301402 0.325626 0.632481 0.898739 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 216
Initial state: 0 0.590809 0.836372 0.129763 0.208031 0.628038 0.885269 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1116554 episodes
GETTING ACTION FROM:
action 3, numVisits=1116546, meanQ=17.876190, numObservations: 3
action 2, numVisits=5, meanQ=11.598000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.590809 0.836372 0.129763 0.208031 0.628038 0.885269 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 217
Initial state: 0 0.628092 0.843445 0.681764 0.804321 0.505395 0.080253 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1104042 episodes
GETTING ACTION FROM:
action 3, numVisits=1104032, meanQ=17.874270, numObservations: 4
action 1, numVisits=7, meanQ=11.282857, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.628092 0.843445 0.681764 0.804321 0.505395 0.080253 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=154102, meanQ=23.324538, numObservations: 4
action 1, numVisits=23, meanQ=21.303913, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1417704 episodes
GETTING ACTION FROM:
action 2, numVisits=1571737, meanQ=19.171919, numObservations: 4
action 1, numVisits=92, meanQ=18.260873, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.628092 0.843445 0.681764 0.804321 0.505395 0.080253 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=39837, meanQ=22.304342, numObservations: 3
action 1, numVisits=11, meanQ=18.362727, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1443637 episodes
GETTING ACTION FROM:
action 1, numVisits=1259927, meanQ=19.208172, numObservations: 5
action 2, numVisits=223558, meanQ=18.469633, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.628092 0.843445 0.681764 0.804321 0.505395 0.080253 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=4140, meanQ=23.203622, numObservations: 4
action 2, numVisits=4, meanQ=17.247500, numObservations: 2
action 3, numVisits=3, meanQ=14.996667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1443447 episodes
GETTING ACTION FROM:
action 1, numVisits=1447583, meanQ=18.994978, numObservations: 5
action 2, numVisits=6, meanQ=13.665000, numObservations: 2
action 3, numVisits=5, meanQ=11.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.628092 0.843445 0.681764 0.804321 0.505395 0.080253 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 11.4068
Run # 218
Initial state: 0 0.677038 0.889752 0.667503 0.822403 0.655152 0.617827 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1094599 episodes
GETTING ACTION FROM:
action 3, numVisits=1094592, meanQ=17.728727, numObservations: 5
action 1, numVisits=4, meanQ=8.497500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.677038 0.889752 0.667503 0.822403 0.655152 0.617827 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 219
Initial state: 0 0.686876 0.817949 0.683309 0.825103 0.224462 0.911672 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1112457 episodes
GETTING ACTION FROM:
action 3, numVisits=1112448, meanQ=17.846604, numObservations: 3
action 1, numVisits=5, meanQ=13.196000, numObservations: 2
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.686876 0.817949 0.683309 0.825103 0.224462 0.911672 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=81632, meanQ=18.719502, numObservations: 4
action 1, numVisits=4, meanQ=15.250000, numObservations: 3
action 2, numVisits=3, meanQ=12.333333, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1295075 episodes
GETTING ACTION FROM:
action 3, numVisits=1376706, meanQ=17.588649, numObservations: 4
action 2, numVisits=3, meanQ=12.333333, numObservations: 1
action 1, numVisits=5, meanQ=10.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.686876 0.817949 0.683309 0.825103 0.224462 0.911672 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=32427, meanQ=20.053577, numObservations: 5
action 3, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1418611 episodes
GETTING ACTION FROM:
action 1, numVisits=1451038, meanQ=18.893314, numObservations: 5
action 3, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.686876 0.817949 0.683309 0.825103 0.224462 0.911672 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 220
Initial state: 0 0.892098 0.365969 0.658437 0.841257 0.521696 0.865302 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1078385 episodes
GETTING ACTION FROM:
action 3, numVisits=1078377, meanQ=18.074087, numObservations: 5
action 2, numVisits=5, meanQ=6.196000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.892098 0.365969 0.658437 0.841257 0.521696 0.865302 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 221
Initial state: 0 0.560871 0.822042 0.664981 0.820543 0.467543 0.895092 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1110449 episodes
GETTING ACTION FROM:
action 1, numVisits=1110435, meanQ=17.761067, numObservations: 4
action 2, numVisits=7, meanQ=11.857157, numObservations: 3
action 3, numVisits=5, meanQ=11.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 0 0.560871 0.822042 0.664981 0.820543 0.467543 0.895092 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=182231, meanQ=23.164727, numObservations: 4
action 3, numVisits=4, meanQ=17.247500, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1422267 episodes
GETTING ACTION FROM:
action 2, numVisits=1604496, meanQ=19.278723, numObservations: 4
action 3, numVisits=6, meanQ=13.665000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.560871 0.822042 0.664981 0.820543 0.467543 0.895092 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 222
Initial state: 0 0.621926 0.867021 0.671058 0.852554 0.287777 0.236709 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1096488 episodes
GETTING ACTION FROM:
action 1, numVisits=1096483, meanQ=17.850950, numObservations: 5
action 3, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.621926 0.867021 0.671058 0.852554 0.287777 0.236709 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 223
Initial state: 0 0.659572 0.806918 0.33486 0.206112 0.517684 0.883988 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1088945 episodes
GETTING ACTION FROM:
action 3, numVisits=1088940, meanQ=17.868148, numObservations: 5
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.659572 0.806918 0.33486 0.206112 0.517684 0.883988 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 224
Initial state: 0 0.605749 0.864417 0.561736 0.882554 0.401154 0.462491 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1104819 episodes
GETTING ACTION FROM:
action 2, numVisits=1104811, meanQ=17.833983, numObservations: 5
action 3, numVisits=5, meanQ=10.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.605749 0.864417 0.561736 0.882554 0.401154 0.462491 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 225
Initial state: 0 0.0508552 0.893984 0.565246 0.816301 0.616092 0.840492 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1100533 episodes
GETTING ACTION FROM:
action 2, numVisits=1100528, meanQ=17.772625, numObservations: 5
action 3, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.0508552 0.893984 0.565246 0.816301 0.616092 0.840492 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 226
Initial state: 0 0.629782 0.858641 0.8631 0.669092 0.510425 0.895038 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1103944 episodes
GETTING ACTION FROM:
action 1, numVisits=1103940, meanQ=17.774415, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.629782 0.858641 0.8631 0.669092 0.510425 0.895038 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 227
Initial state: 0 0.539169 0.804242 0.62757 0.816891 0.336056 0.356651 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1112010 episodes
GETTING ACTION FROM:
action 2, numVisits=1112006, meanQ=17.877645, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.539169 0.804242 0.62757 0.816891 0.336056 0.356651 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 228
Initial state: 0 0.693708 0.801375 0.685152 0.880868 0.344582 0.273006 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1108939 episodes
GETTING ACTION FROM:
action 2, numVisits=1108921, meanQ=17.857677, numObservations: 4
action 1, numVisits=12, meanQ=11.248342, numObservations: 3
action 3, numVisits=4, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.693708 0.801375 0.685152 0.880868 0.344582 0.273006 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 229
Initial state: 0 0.634211 0.883486 0.195248 0.920934 0.599986 0.861849 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 750336 episodes
GETTING ACTION FROM:
action 0, numVisits=750330, meanQ=15.656622, numObservations: 1
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.634211 0.883486 0.195248 0.920934 0.599986 0.861849 w: 1
Observation: 0 0 0.872527 0 0.999911 0 0.883011 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=750324, meanQ=17.849624, numObservations: 4
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1201294 episodes
GETTING ACTION FROM:
action 3, numVisits=1951618, meanQ=17.441838, numObservations: 4
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.634211 0.883486 0.195248 0.920934 0.599986 0.861849 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 230
Initial state: 0 0.667857 0.800316 0.539635 0.834612 0.360626 0.485745 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1101265 episodes
GETTING ACTION FROM:
action 1, numVisits=1101258, meanQ=17.836721, numObservations: 5
action 2, numVisits=4, meanQ=8.497500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.667857 0.800316 0.539635 0.834612 0.360626 0.485745 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 231
Initial state: 0 0.638831 0.84838 0.738561 0.05365 0.54083 0.856346 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1097777 episodes
GETTING ACTION FROM:
action 1, numVisits=1097771, meanQ=17.752534, numObservations: 5
action 2, numVisits=2, meanQ=10.495000, numObservations: 1
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.638831 0.84838 0.738561 0.05365 0.54083 0.856346 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 232
Initial state: 0 0.0568305 0.0489902 0.630674 0.877823 0.544325 0.802615 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1103090 episodes
GETTING ACTION FROM:
action 3, numVisits=1103086, meanQ=17.774753, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.0568305 0.0489902 0.630674 0.877823 0.544325 0.802615 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 233
Initial state: 0 0.845276 0.629479 0.562924 0.801269 0.549597 0.833891 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1095664 episodes
GETTING ACTION FROM:
action 2, numVisits=1095651, meanQ=17.743324, numObservations: 4
action 3, numVisits=8, meanQ=9.247513, numObservations: 2
action 1, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.845276 0.629479 0.562924 0.801269 0.549597 0.833891 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 234
Initial state: 0 0.971622 0.182294 0.504733 0.842819 0.53162 0.897182 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1092942 episodes
GETTING ACTION FROM:
action 3, numVisits=1092930, meanQ=17.839041, numObservations: 5
action 2, numVisits=8, meanQ=11.873750, numObservations: 3
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.971622 0.182294 0.504733 0.842819 0.53162 0.897182 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 235
Initial state: 0 0.606809 0.824074 0.562941 0.823661 0.527293 0.918197 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1100093 episodes
GETTING ACTION FROM:
action 3, numVisits=1100088, meanQ=17.712598, numObservations: 4
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.606809 0.824074 0.562941 0.823661 0.527293 0.918197 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 236
Initial state: 0 0.69085 0.825738 0.56807 0.807325 0.600014 0.207883 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1105070 episodes
GETTING ACTION FROM:
action 1, numVisits=1105066, meanQ=17.736668, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.69085 0.825738 0.56807 0.807325 0.600014 0.207883 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 237
Initial state: 0 0.167169 0.528411 0.657252 0.869755 0.592926 0.810334 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 792612 episodes
GETTING ACTION FROM:
action 0, numVisits=792606, meanQ=19.912075, numObservations: 2
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.167169 0.528411 0.657252 0.869755 0.592926 0.810334 w: 1
Observation: 0 0 0.591286 0 0.883027 0 0.740704 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=213045, meanQ=22.990098, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1223110 episodes
GETTING ACTION FROM:
action 2, numVisits=1436155, meanQ=18.740826, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.167169 0.528411 0.657252 0.869755 0.592926 0.810334 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 238
Initial state: 0 0.631075 0.880362 0.77808 0.124085 0.563634 0.80464 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1099605 episodes
GETTING ACTION FROM:
action 3, numVisits=1099592, meanQ=17.756226, numObservations: 4
action 2, numVisits=9, meanQ=10.886678, numObservations: 3
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.631075 0.880362 0.77808 0.124085 0.563634 0.80464 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 239
Initial state: 0 0.959379 0.29086 0.660967 0.887561 0.557985 0.837226 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1100605 episodes
GETTING ACTION FROM:
action 1, numVisits=1100597, meanQ=17.869542, numObservations: 4
action 3, numVisits=5, meanQ=10.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.959379 0.29086 0.660967 0.887561 0.557985 0.837226 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 240
Initial state: 0 0.597031 0.848934 0.862711 0.189477 0.571019 0.812282 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1106950 episodes
GETTING ACTION FROM:
action 1, numVisits=1106924, meanQ=17.795567, numObservations: 4
action 2, numVisits=23, meanQ=15.988265, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.597031 0.848934 0.862711 0.189477 0.571019 0.812282 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 241
Initial state: 0 0.35076 0.41466 0.627054 0.874614 0.68843 0.891659 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1108551 episodes
GETTING ACTION FROM:
action 2, numVisits=1108545, meanQ=17.740732, numObservations: 4
action 3, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.35076 0.41466 0.627054 0.874614 0.68843 0.891659 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 242
Initial state: 0 0.532098 0.819077 0.945608 0.074599 0.633852 0.8563 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1094601 episodes
GETTING ACTION FROM:
action 1, numVisits=1094593, meanQ=17.732838, numObservations: 5
action 3, numVisits=5, meanQ=5.402020, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.532098 0.819077 0.945608 0.074599 0.633852 0.8563 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=80151, meanQ=17.369685, numObservations: 5
action 1, numVisits=4, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1384696 episodes
GETTING ACTION FROM:
action 3, numVisits=1464847, meanQ=18.804393, numObservations: 5
action 1, numVisits=4, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.532098 0.819077 0.945608 0.074599 0.633852 0.8563 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 243
Initial state: 0 0.520377 0.887962 0.872505 0.312539 0.565161 0.855007 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1114818 episodes
GETTING ACTION FROM:
action 3, numVisits=1114814, meanQ=17.884837, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.520377 0.887962 0.872505 0.312539 0.565161 0.855007 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 244
Initial state: 0 0.699053 0.879778 0.189615 0.0502233 0.589745 0.875418 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1103913 episodes
GETTING ACTION FROM:
action 2, numVisits=1103902, meanQ=17.750137, numObservations: 4
action 1, numVisits=7, meanQ=10.141429, numObservations: 4
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.699053 0.879778 0.189615 0.0502233 0.589745 0.875418 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=27654, meanQ=22.264995, numObservations: 4
action 1, numVisits=6, meanQ=14.996667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1420235 episodes
GETTING ACTION FROM:
action 3, numVisits=1447889, meanQ=18.923506, numObservations: 4
action 1, numVisits=6, meanQ=14.996667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.699053 0.879778 0.189615 0.0502233 0.589745 0.875418 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 245
Initial state: 0 0.502621 0.888538 0.560351 0.873217 0.198316 0.7962 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1097552 episodes
GETTING ACTION FROM:
action 2, numVisits=1097540, meanQ=17.735025, numObservations: 4
action 1, numVisits=7, meanQ=10.141429, numObservations: 3
action 3, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.502621 0.888538 0.560351 0.873217 0.198316 0.7962 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 246
Initial state: 0 0.632249 0.860509 0.669772 0.812289 0.384135 0.372883 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1104889 episodes
GETTING ACTION FROM:
action 1, numVisits=1104885, meanQ=18.121191, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.632249 0.860509 0.669772 0.812289 0.384135 0.372883 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 247
Initial state: 0 0.616751 0.883624 0.504609 0.87399 0.964025 0.462084 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1104993 episodes
GETTING ACTION FROM:
action 3, numVisits=1104978, meanQ=17.828487, numObservations: 3
action 2, numVisits=11, meanQ=13.066364, numObservations: 3
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 2 0.616751 0.883624 0.504609 0.87399 0.964025 0.462084 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 248
Initial state: 0 0.566946 0.893804 0.0876354 0.389813 0.607729 0.864112 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1115791 episodes
GETTING ACTION FROM:
action 2, numVisits=1115787, meanQ=17.741481, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.566946 0.893804 0.0876354 0.389813 0.607729 0.864112 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=184322, meanQ=23.146937, numObservations: 5
action 3, numVisits=3, meanQ=14.996667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1395024 episodes
GETTING ACTION FROM:
action 1, numVisits=1579346, meanQ=19.720965, numObservations: 5
action 3, numVisits=3, meanQ=14.996667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.566946 0.893804 0.0876354 0.389813 0.607729 0.864112 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 249
Initial state: 0 0.556211 0.82433 0.698074 0.985172 0.561279 0.873852 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1082013 episodes
GETTING ACTION FROM:
action 3, numVisits=1082009, meanQ=17.786897, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.556211 0.82433 0.698074 0.985172 0.561279 0.873852 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 250
Initial state: 0 0.0106869 0.295793 0.584982 0.800946 0.545764 0.82832 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1122318 episodes
GETTING ACTION FROM:
action 2, numVisits=1122313, meanQ=17.883267, numObservations: 3
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.0106869 0.295793 0.584982 0.800946 0.545764 0.82832 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 251
Initial state: 0 0.550511 0.802858 0.0579675 0.353034 0.561043 0.875004 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1093729 episodes
GETTING ACTION FROM:
action 3, numVisits=1093721, meanQ=17.853120, numObservations: 5
action 1, numVisits=5, meanQ=10.820000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.550511 0.802858 0.0579675 0.353034 0.561043 0.875004 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 252
Initial state: 0 0.301109 0.677324 0.552555 0.805612 0.552991 0.895571 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1097317 episodes
GETTING ACTION FROM:
action 3, numVisits=1097312, meanQ=17.817018, numObservations: 4
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.301109 0.677324 0.552555 0.805612 0.552991 0.895571 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 253
Initial state: 0 0.684735 0.82886 0.478331 0.256468 0.627218 0.856434 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1102408 episodes
GETTING ACTION FROM:
action 2, numVisits=1102400, meanQ=17.872002, numObservations: 4
action 3, numVisits=4, meanQ=8.497500, numObservations: 2
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.684735 0.82886 0.478331 0.256468 0.627218 0.856434 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=182414, meanQ=23.144473, numObservations: 5
action 3, numVisits=5, meanQ=18.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1391772 episodes
GETTING ACTION FROM:
action 1, numVisits=1574177, meanQ=19.604041, numObservations: 5
action 3, numVisits=14, meanQ=17.070714, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.684735 0.82886 0.478331 0.256468 0.627218 0.856434 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 254
Initial state: 0 0.92699 0.154532 0.623263 0.861985 0.626931 0.846114 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1091030 episodes
GETTING ACTION FROM:
action 1, numVisits=1091021, meanQ=17.736259, numObservations: 5
action 2, numVisits=5, meanQ=13.196000, numObservations: 2
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 2 0.92699 0.154532 0.623263 0.861985 0.626931 0.846114 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 255
Initial state: 0 0.652732 0.807029 0.67498 0.859588 0.390244 0.903497 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1094906 episodes
GETTING ACTION FROM:
action 2, numVisits=1094860, meanQ=17.765473, numObservations: 5
action 3, numVisits=32, meanQ=13.932506, numObservations: 4
action 1, numVisits=12, meanQ=12.675000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.652732 0.807029 0.67498 0.859588 0.390244 0.903497 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 256
Initial state: 0 0.381621 0.0980041 0.562663 0.804514 0.697429 0.858926 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 757576 episodes
GETTING ACTION FROM:
action -1, numVisits=757572, meanQ=15.575921, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: -1
Next state: 0 0.381621 0.0980041 0.562663 0.804514 0.697429 0.858926 w: 1
Observation: 0 0.435329 0 0.644601 0 0.627213 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=757560, meanQ=17.755758, numObservations: 4
action 2, numVisits=8, meanQ=12.342500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1214281 episodes
GETTING ACTION FROM:
action 1, numVisits=1971841, meanQ=17.780927, numObservations: 4
action 2, numVisits=8, meanQ=12.342500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.381621 0.0980041 0.562663 0.804514 0.697429 0.858926 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=48865, meanQ=22.101383, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1432385 episodes
GETTING ACTION FROM:
action 2, numVisits=1481250, meanQ=19.077579, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.381621 0.0980041 0.562663 0.804514 0.697429 0.858926 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 17.5624
Run # 257
Initial state: 0 0.661847 0.845248 0.658522 0.8899 0.884107 0.693184 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1079921 episodes
GETTING ACTION FROM:
action 3, numVisits=1079917, meanQ=17.836632, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.661847 0.845248 0.658522 0.8899 0.884107 0.693184 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 258
Initial state: 0 0.617287 0.875489 0.628028 0.876825 0.457625 0.58655 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1097263 episodes
GETTING ACTION FROM:
action 1, numVisits=1097254, meanQ=18.100679, numObservations: 5
action 2, numVisits=6, meanQ=9.163333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.617287 0.875489 0.628028 0.876825 0.457625 0.58655 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 259
Initial state: 0 0.68699 0.821409 0.658712 0.810725 0.175983 0.575132 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1117097 episodes
GETTING ACTION FROM:
action 3, numVisits=1117076, meanQ=17.808557, numObservations: 3
action 1, numVisits=12, meanQ=12.999167, numObservations: 2
action 2, numVisits=7, meanQ=10.141429, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.68699 0.821409 0.658712 0.810725 0.175983 0.575132 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=184573, meanQ=23.162712, numObservations: 4
action 2, numVisits=4, meanQ=15.250000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1420601 episodes
GETTING ACTION FROM:
action 1, numVisits=1605174, meanQ=19.469364, numObservations: 4
action 2, numVisits=4, meanQ=15.250000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.68699 0.821409 0.658712 0.810725 0.175983 0.575132 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 260
Initial state: 0 0.660659 0.863576 0.344793 0.00497086 0.601975 0.847177 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1095896 episodes
GETTING ACTION FROM:
action 1, numVisits=1095888, meanQ=17.754816, numObservations: 5
action 2, numVisits=5, meanQ=7.794000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.660659 0.863576 0.344793 0.00497086 0.601975 0.847177 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 261
Initial state: 0 0.628694 0.845113 0.534549 0.841781 0.454954 0.646972 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 765968 episodes
GETTING ACTION FROM:
action -1, numVisits=765957, meanQ=15.532384, numObservations: 1
action 2, numVisits=4, meanQ=-0.252500, numObservations: 2
action 3, numVisits=5, meanQ=-0.804000, numObservations: 3
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.628694 0.845113 0.534549 0.841781 0.454954 0.646972 w: 1
Observation: 0 0.605469 0 0.49859 0 0.509084 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=765945, meanQ=17.724331, numObservations: 3
action 2, numVisits=7, meanQ=10.141429, numObservations: 2
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1230513 episodes
GETTING ACTION FROM:
action 1, numVisits=1996458, meanQ=17.673645, numObservations: 3
action 2, numVisits=7, meanQ=10.141429, numObservations: 2
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.628694 0.845113 0.534549 0.841781 0.454954 0.646972 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 262
Initial state: 0 0.126753 0.453594 0.606604 0.839753 0.687307 0.869515 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1103555 episodes
GETTING ACTION FROM:
action 2, numVisits=1103551, meanQ=18.139227, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.126753 0.453594 0.606604 0.839753 0.687307 0.869515 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 263
Initial state: 0 0.341913 0.279118 0.516406 0.842916 0.639002 0.863151 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1087949 episodes
GETTING ACTION FROM:
action 2, numVisits=1087945, meanQ=17.726003, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.341913 0.279118 0.516406 0.842916 0.639002 0.863151 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 264
Initial state: 0 0.325407 0.469866 0.680664 0.87044 0.654363 0.807811 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1100285 episodes
GETTING ACTION FROM:
action 3, numVisits=1100272, meanQ=18.072480, numObservations: 4
action 2, numVisits=10, meanQ=15.098000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.325407 0.469866 0.680664 0.87044 0.654363 0.807811 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 265
Initial state: 0 0.516001 0.833361 0.618329 0.866343 0.14464 0.76033 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1070435 episodes
GETTING ACTION FROM:
action 1, numVisits=1070431, meanQ=17.608709, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.516001 0.833361 0.618329 0.866343 0.14464 0.76033 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 266
Initial state: 0 0.193967 0.614833 0.606258 0.853459 0.606017 0.865161 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1110059 episodes
GETTING ACTION FROM:
action 3, numVisits=1110055, meanQ=18.074768, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.193967 0.614833 0.606258 0.853459 0.606017 0.865161 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 267
Initial state: 0 0.600489 0.881535 0.300637 0.318859 0.598153 0.871272 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1121275 episodes
GETTING ACTION FROM:
action 2, numVisits=1121269, meanQ=17.845476, numObservations: 3
action 1, numVisits=3, meanQ=12.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.600489 0.881535 0.300637 0.318859 0.598153 0.871272 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=184006, meanQ=23.159974, numObservations: 3
action 3, numVisits=4, meanQ=17.247500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1427394 episodes
GETTING ACTION FROM:
action 1, numVisits=1611399, meanQ=19.487019, numObservations: 3
action 3, numVisits=5, meanQ=11.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.600489 0.881535 0.300637 0.318859 0.598153 0.871272 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 268
Initial state: 0 0.646487 0.857008 0.418815 0.791753 0.63127 0.888007 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1088585 episodes
GETTING ACTION FROM:
action 3, numVisits=1088576, meanQ=17.782741, numObservations: 5
action 1, numVisits=6, meanQ=12.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.646487 0.857008 0.418815 0.791753 0.63127 0.888007 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=79454, meanQ=17.396652, numObservations: 5
action 3, numVisits=4, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1403909 episodes
GETTING ACTION FROM:
action 2, numVisits=1483363, meanQ=18.732503, numObservations: 5
action 3, numVisits=4, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.646487 0.857008 0.418815 0.791753 0.63127 0.888007 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=32088, meanQ=23.036220, numObservations: 3
action 1, numVisits=3, meanQ=14.996667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1438765 episodes
GETTING ACTION FROM:
action 3, numVisits=1470849, meanQ=19.214015, numObservations: 4
action 1, numVisits=7, meanQ=15.141429, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.646487 0.857008 0.418815 0.791753 0.63127 0.888007 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 269
Initial state: 0 0.248512 0.149567 0.587688 0.844256 0.627425 0.848789 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 757684 episodes
GETTING ACTION FROM:
action 0, numVisits=757679, meanQ=15.645434, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.248512 0.149567 0.587688 0.844256 0.627425 0.848789 w: 1
Observation: 0 0 0.174791 0 0.938202 0 0.930556 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=757666, meanQ=17.838125, numObservations: 5
action 1, numVisits=6, meanQ=9.163333, numObservations: 2
action 3, numVisits=4, meanQ=8.497500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1204220 episodes
GETTING ACTION FROM:
action 2, numVisits=1961886, meanQ=17.773173, numObservations: 5
action 1, numVisits=6, meanQ=9.163333, numObservations: 2
action 3, numVisits=4, meanQ=8.497500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.248512 0.149567 0.587688 0.844256 0.627425 0.848789 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 270
Initial state: 0 0.630124 0.832918 0.654642 0.80467 0.45887 0.220459 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1075906 episodes
GETTING ACTION FROM:
action 1, numVisits=1075893, meanQ=17.700163, numObservations: 3
action 3, numVisits=6, meanQ=13.665000, numObservations: 3
action 2, numVisits=5, meanQ=13.196000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.630124 0.832918 0.654642 0.80467 0.45887 0.220459 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 271
Initial state: 0 0.376427 0.784366 0.64268 0.857479 0.590625 0.820261 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1107211 episodes
GETTING ACTION FROM:
action 2, numVisits=1107204, meanQ=17.872130, numObservations: 4
action 1, numVisits=4, meanQ=8.497500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.376427 0.784366 0.64268 0.857479 0.590625 0.820261 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 272
Initial state: 0 0.685545 0.874905 0.715968 0.332898 0.698556 0.835125 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1096818 episodes
GETTING ACTION FROM:
action 3, numVisits=1096813, meanQ=17.856409, numObservations: 5
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.685545 0.874905 0.715968 0.332898 0.698556 0.835125 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 273
Initial state: 0 0.325125 0.755196 0.610871 0.86508 0.610182 0.8548 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1094702 episodes
GETTING ACTION FROM:
action 1, numVisits=1094687, meanQ=17.860791, numObservations: 5
action 3, numVisits=9, meanQ=9.277778, numObservations: 2
action 2, numVisits=4, meanQ=8.497500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 2 0.325125 0.755196 0.610871 0.86508 0.610182 0.8548 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 274
Initial state: 0 0.507282 0.810912 0.574025 0.839549 0.453147 0.0921008 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1109216 episodes
GETTING ACTION FROM:
action 1, numVisits=1109187, meanQ=17.863040, numObservations: 4
action 2, numVisits=26, meanQ=12.383477, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.507282 0.810912 0.574025 0.839549 0.453147 0.0921008 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 275
Initial state: 0 0.673049 0.82237 0.622152 0.87081 0.270491 0.0400276 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1094496 episodes
GETTING ACTION FROM:
action 3, numVisits=1094492, meanQ=18.113937, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.673049 0.82237 0.622152 0.87081 0.270491 0.0400276 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=152577, meanQ=23.329256, numObservations: 5
action 1, numVisits=44, meanQ=21.229320, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1405422 episodes
GETTING ACTION FROM:
action 1, numVisits=670350, meanQ=19.385867, numObservations: 4
action 2, numVisits=887693, meanQ=19.358236, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.673049 0.82237 0.622152 0.87081 0.270491 0.0400276 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 276
Initial state: 0 0.624985 0.826477 0.506345 0.857501 0.680706 0.348417 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1108615 episodes
GETTING ACTION FROM:
action 3, numVisits=1108605, meanQ=17.839619, numObservations: 4
action 1, numVisits=6, meanQ=10.163350, numObservations: 2
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 2 0.624985 0.826477 0.506345 0.857501 0.680706 0.348417 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 277
Initial state: 0 0.0957392 0.922569 0.548412 0.88371 0.626613 0.818309 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1095403 episodes
GETTING ACTION FROM:
action 3, numVisits=1095396, meanQ=17.868475, numObservations: 5
action 1, numVisits=4, meanQ=10.495000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.0957392 0.922569 0.548412 0.88371 0.626613 0.818309 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 278
Initial state: 0 0.500487 0.891577 0.200303 0.910368 0.507943 0.812312 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1097557 episodes
GETTING ACTION FROM:
action 2, numVisits=1097553, meanQ=17.766278, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.500487 0.891577 0.200303 0.910368 0.507943 0.812312 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=81353, meanQ=17.370698, numObservations: 4
action 2, numVisits=17, meanQ=13.947059, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1420652 episodes
GETTING ACTION FROM:
action 1, numVisits=1502005, meanQ=19.349283, numObservations: 4
action 2, numVisits=17, meanQ=13.947059, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.500487 0.891577 0.200303 0.910368 0.507943 0.812312 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 279
Initial state: 0 0.00132665 0.574131 0.605087 0.81331 0.663378 0.879416 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1087544 episodes
GETTING ACTION FROM:
action 2, numVisits=1087537, meanQ=17.837084, numObservations: 5
action 1, numVisits=4, meanQ=10.495000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.00132665 0.574131 0.605087 0.81331 0.663378 0.879416 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 280
Initial state: 0 0.148663 0.380683 0.634942 0.819184 0.624283 0.84186 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1102429 episodes
GETTING ACTION FROM:
action 2, numVisits=1102422, meanQ=17.758428, numObservations: 5
action 3, numVisits=4, meanQ=8.497500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.148663 0.380683 0.634942 0.819184 0.624283 0.84186 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 281
Initial state: 0 0.968537 0.170498 0.506302 0.809706 0.643049 0.858646 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1098439 episodes
GETTING ACTION FROM:
action 1, numVisits=1098422, meanQ=17.826145, numObservations: 5
action 3, numVisits=14, meanQ=12.070714, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.968537 0.170498 0.506302 0.809706 0.643049 0.858646 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 282
Initial state: 0 0.681014 0.837844 0.604871 0.330404 0.500292 0.863099 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1108428 episodes
GETTING ACTION FROM:
action 1, numVisits=1108424, meanQ=17.738067, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.681014 0.837844 0.604871 0.330404 0.500292 0.863099 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 283
Initial state: 0 0.678156 0.848712 0.702756 0.259891 0.563303 0.860382 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1109906 episodes
GETTING ACTION FROM:
action 3, numVisits=1109860, meanQ=17.851663, numObservations: 3
action 1, numVisits=43, meanQ=16.319302, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.678156 0.848712 0.702756 0.259891 0.563303 0.860382 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 284
Initial state: 0 0.569756 0.854808 0.654767 0.644708 0.519567 0.80741 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1104486 episodes
GETTING ACTION FROM:
action 2, numVisits=1104480, meanQ=17.857948, numObservations: 4
action 1, numVisits=3, meanQ=12.333333, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.569756 0.854808 0.654767 0.644708 0.519567 0.80741 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 285
Initial state: 0 0.633597 0.865599 0.596336 0.810553 0.935916 0.747925 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1100116 episodes
GETTING ACTION FROM:
action 1, numVisits=1100111, meanQ=17.850258, numObservations: 5
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.633597 0.865599 0.596336 0.810553 0.935916 0.747925 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 286
Initial state: 0 0.524005 0.855819 0.310967 0.578948 0.597987 0.825231 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1105210 episodes
GETTING ACTION FROM:
action 1, numVisits=1105201, meanQ=17.768636, numObservations: 4
action 2, numVisits=5, meanQ=12.348000, numObservations: 3
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.524005 0.855819 0.310967 0.578948 0.597987 0.825231 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 287
Initial state: 0 0.785295 0.615591 0.660548 0.864338 0.649415 0.839021 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1118020 episodes
GETTING ACTION FROM:
action 2, numVisits=1118015, meanQ=17.846331, numObservations: 4
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.785295 0.615591 0.660548 0.864338 0.649415 0.839021 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 288
Initial state: 0 0.889786 0.875341 0.632397 0.846792 0.582575 0.832892 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1109764 episodes
GETTING ACTION FROM:
action 2, numVisits=1109760, meanQ=17.758463, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.889786 0.875341 0.632397 0.846792 0.582575 0.832892 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 289
Initial state: 0 0.534091 0.812999 0.604589 0.855509 0.772111 0.292049 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1106042 episodes
GETTING ACTION FROM:
action 3, numVisits=1106036, meanQ=17.851423, numObservations: 4
action 1, numVisits=3, meanQ=12.333333, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.534091 0.812999 0.604589 0.855509 0.772111 0.292049 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 290
Initial state: 0 0.653869 0.860219 0.697926 0.891714 0.0394696 0.37818 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1101413 episodes
GETTING ACTION FROM:
action 1, numVisits=1101407, meanQ=17.884472, numObservations: 5
action 3, numVisits=3, meanQ=12.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.653869 0.860219 0.697926 0.891714 0.0394696 0.37818 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 291
Initial state: 0 0.577242 0.872289 0.964968 0.610131 0.680958 0.874885 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 765470 episodes
GETTING ACTION FROM:
action -1, numVisits=765465, meanQ=15.616135, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.577242 0.872289 0.964968 0.610131 0.680958 0.874885 w: 1
Observation: 0 0.488548 0 0.867322 0 0.775403 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=765456, meanQ=17.815640, numObservations: 4
action 3, numVisits=5, meanQ=11.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1236110 episodes
GETTING ACTION FROM:
action 2, numVisits=2001566, meanQ=17.924890, numObservations: 4
action 3, numVisits=5, meanQ=11.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.577242 0.872289 0.964968 0.610131 0.680958 0.874885 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 292
Initial state: 0 0.601327 0.811513 0.594616 0.857729 0.429002 0.1496 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1110765 episodes
GETTING ACTION FROM:
action 2, numVisits=1110759, meanQ=17.766474, numObservations: 4
action 3, numVisits=3, meanQ=12.333333, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.601327 0.811513 0.594616 0.857729 0.429002 0.1496 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 293
Initial state: 0 0.165049 0.160739 0.503203 0.866018 0.587934 0.847346 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1101236 episodes
GETTING ACTION FROM:
action 3, numVisits=1101232, meanQ=17.727306, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.165049 0.160739 0.503203 0.866018 0.587934 0.847346 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 294
Initial state: 0 0.582754 0.847015 0.668132 0.818173 0.448008 0.700843 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1026344 episodes
GETTING ACTION FROM:
action 2, numVisits=1026339, meanQ=17.344415, numObservations: 4
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.582754 0.847015 0.668132 0.818173 0.448008 0.700843 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 295
Initial state: 0 0.11158 0.789921 0.671627 0.830371 0.506984 0.878776 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1096017 episodes
GETTING ACTION FROM:
action 1, numVisits=1096013, meanQ=17.857909, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.11158 0.789921 0.671627 0.830371 0.506984 0.878776 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=153626, meanQ=23.300380, numObservations: 4
action 2, numVisits=27, meanQ=21.925559, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1410439 episodes
GETTING ACTION FROM:
action 3, numVisits=1564038, meanQ=18.990742, numObservations: 4
action 2, numVisits=54, meanQ=17.925557, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.11158 0.789921 0.671627 0.830371 0.506984 0.878776 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 296
Initial state: 0 0.580788 0.843928 0.548235 0.827127 0.570719 0.74985 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1102127 episodes
GETTING ACTION FROM:
action 1, numVisits=1102119, meanQ=17.870608, numObservations: 5
action 2, numVisits=4, meanQ=8.497500, numObservations: 3
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.580788 0.843928 0.548235 0.827127 0.570719 0.74985 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 297
Initial state: 0 0.545807 0.814461 0.122943 0.848202 0.535761 0.899219 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1113562 episodes
GETTING ACTION FROM:
action 2, numVisits=1113554, meanQ=18.083518, numObservations: 4
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=2, meanQ=-4.004950, numObservations: 1
action: 2
Next state: 0 0.545807 0.814461 0.122943 0.848202 0.535761 0.899219 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=36473, meanQ=22.582301, numObservations: 5
action 3, numVisits=4, meanQ=17.247500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1389064 episodes
GETTING ACTION FROM:
action 1, numVisits=1425533, meanQ=18.916268, numObservations: 5
action 3, numVisits=8, meanQ=16.248750, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.545807 0.814461 0.122943 0.848202 0.535761 0.899219 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 298
Initial state: 0 0.6968 0.882266 0.421418 0.00540165 0.526033 0.872765 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 746410 episodes
GETTING ACTION FROM:
action 0, numVisits=746402, meanQ=15.545503, numObservations: 1
action 1, numVisits=4, meanQ=-2.250000, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.6968 0.882266 0.421418 0.00540165 0.526033 0.872765 w: 1
Observation: 0 0 0.895715 0 0 0 0.883668 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=746391, meanQ=17.744506, numObservations: 5
action 2, numVisits=6, meanQ=9.163333, numObservations: 2
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1195583 episodes
GETTING ACTION FROM:
action 3, numVisits=1941974, meanQ=17.885670, numObservations: 5
action 2, numVisits=6, meanQ=9.163333, numObservations: 2
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.6968 0.882266 0.421418 0.00540165 0.526033 0.872765 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=147213, meanQ=16.953598, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1400284 episodes
GETTING ACTION FROM:
action 2, numVisits=1547497, meanQ=18.742977, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.6968 0.882266 0.421418 0.00540165 0.526033 0.872765 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action -1, numVisits=41363, meanQ=21.035909, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1462024 episodes
GETTING ACTION FROM:
action 1, numVisits=1323112, meanQ=18.378526, numObservations: 4
action -1, numVisits=180275, meanQ=3.931244, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.6968 0.882266 0.421418 0.00540165 0.526033 0.872765 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 13.4068
Run # 299
Initial state: 0 0.606215 0.827573 0.640056 0.886267 0.206277 0.409044 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1094080 episodes
GETTING ACTION FROM:
action 3, numVisits=1094066, meanQ=17.829889, numObservations: 4
action 2, numVisits=5, meanQ=6.998040, numObservations: 2
action 1, numVisits=7, meanQ=5.141429, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.606215 0.827573 0.640056 0.886267 0.206277 0.409044 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=178794, meanQ=23.144017, numObservations: 5
action 1, numVisits=7, meanQ=16.282857, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1396850 episodes
GETTING ACTION FROM:
action 2, numVisits=1575644, meanQ=19.560842, numObservations: 5
action 1, numVisits=7, meanQ=16.282857, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.606215 0.827573 0.640056 0.886267 0.206277 0.409044 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 300
Initial state: 0 0.634044 0.804446 0.77771 0.927427 0.539586 0.816738 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1095011 episodes
GETTING ACTION FROM:
action 1, numVisits=1095006, meanQ=17.766110, numObservations: 5
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.634044 0.804446 0.77771 0.927427 0.539586 0.816738 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 301
Initial state: 0 0.653828 0.812828 0.78136 0.371475 0.569987 0.854609 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1109309 episodes
GETTING ACTION FROM:
action 2, numVisits=1109286, meanQ=17.729500, numObservations: 4
action 3, numVisits=19, meanQ=15.210000, numObservations: 4
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 2 0.653828 0.812828 0.78136 0.371475 0.569987 0.854609 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 302
Initial state: 0 0.476462 0.121162 0.581777 0.837715 0.655531 0.877179 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1101773 episodes
GETTING ACTION FROM:
action 3, numVisits=1101769, meanQ=17.855637, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.476462 0.121162 0.581777 0.837715 0.655531 0.877179 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 303
Initial state: 0 0.666736 0.829546 0.536792 0.805562 0.294459 0.416089 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1082073 episodes
GETTING ACTION FROM:
action 2, numVisits=1082063, meanQ=17.694544, numObservations: 3
action 3, numVisits=4, meanQ=10.495000, numObservations: 2
action 1, numVisits=4, meanQ=8.497500, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.666736 0.829546 0.536792 0.805562 0.294459 0.416089 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 304
Initial state: 0 0.665273 0.850347 0.292265 0.938805 0.507552 0.830744 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1028681 episodes
GETTING ACTION FROM:
action 2, numVisits=1028676, meanQ=17.392237, numObservations: 5
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.665273 0.850347 0.292265 0.938805 0.507552 0.830744 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 305
Initial state: 0 0.550194 0.877502 0.540283 0.856703 0.125379 0.664339 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1092714 episodes
GETTING ACTION FROM:
action 1, numVisits=1092710, meanQ=17.731353, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.550194 0.877502 0.540283 0.856703 0.125379 0.664339 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 306
Initial state: 0 0.550708 0.8389 0.0758222 0.0829671 0.648807 0.81836 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1093591 episodes
GETTING ACTION FROM:
action 1, numVisits=1093587, meanQ=17.746166, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.550708 0.8389 0.0758222 0.0829671 0.648807 0.81836 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 307
Initial state: 0 0.59994 0.828007 0.122195 0.222269 0.677489 0.811255 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1097247 episodes
GETTING ACTION FROM:
action 3, numVisits=1097237, meanQ=17.742436, numObservations: 4
action 2, numVisits=7, meanQ=10.715729, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.59994 0.828007 0.122195 0.222269 0.677489 0.811255 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 308
Initial state: 0 0.511574 0.868715 0.659988 0.895524 0.606163 0.0527456 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1097654 episodes
GETTING ACTION FROM:
action 3, numVisits=1097644, meanQ=17.736854, numObservations: 4
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action 1, numVisits=6, meanQ=10.495000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.511574 0.868715 0.659988 0.895524 0.606163 0.0527456 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=54893, meanQ=22.360731, numObservations: 4
action 2, numVisits=3, meanQ=14.996667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1415908 episodes
GETTING ACTION FROM:
action 1, numVisits=1469123, meanQ=18.643606, numObservations: 4
action 2, numVisits=1681, meanQ=18.454929, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.511574 0.868715 0.659988 0.895524 0.606163 0.0527456 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 309
Initial state: 0 0.588718 0.803592 0.306972 0.117136 0.653637 0.896826 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1117126 episodes
GETTING ACTION FROM:
action 1, numVisits=1117101, meanQ=17.770523, numObservations: 3
action 3, numVisits=22, meanQ=14.817727, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.588718 0.803592 0.306972 0.117136 0.653637 0.896826 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 310
Initial state: 0 0.570174 0.856335 0.64654 0.846464 0.94186 0.305757 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1105036 episodes
GETTING ACTION FROM:
action 1, numVisits=1105028, meanQ=17.847458, numObservations: 4
action 2, numVisits=5, meanQ=11.598000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.570174 0.856335 0.64654 0.846464 0.94186 0.305757 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 311
Initial state: 0 0.581479 0.835117 0.298837 0.463492 0.607699 0.820335 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1095220 episodes
GETTING ACTION FROM:
action 3, numVisits=1095216, meanQ=17.750071, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.581479 0.835117 0.298837 0.463492 0.607699 0.820335 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=81188, meanQ=17.241899, numObservations: 4
action 2, numVisits=39, meanQ=11.058469, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1398588 episodes
GETTING ACTION FROM:
action 1, numVisits=1479776, meanQ=19.045588, numObservations: 4
action 2, numVisits=39, meanQ=11.058469, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.581479 0.835117 0.298837 0.463492 0.607699 0.820335 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 312
Initial state: 0 0.765469 0.546799 0.659825 0.8556 0.65531 0.851835 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1103273 episodes
GETTING ACTION FROM:
action 3, numVisits=1103269, meanQ=17.763721, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.765469 0.546799 0.659825 0.8556 0.65531 0.851835 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 313
Initial state: 0 0.0421424 0.925121 0.668048 0.829355 0.641321 0.891492 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1090830 episodes
GETTING ACTION FROM:
action 3, numVisits=1090780, meanQ=18.160720, numObservations: 5
action 1, numVisits=44, meanQ=15.484325, numObservations: 4
action 2, numVisits=4, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.0421424 0.925121 0.668048 0.829355 0.641321 0.891492 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 314
Initial state: 0 0.527411 0.892895 0.516998 0.811347 0.411501 0.869408 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1104172 episodes
GETTING ACTION FROM:
action 1, numVisits=1104168, meanQ=17.875818, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.527411 0.892895 0.516998 0.811347 0.411501 0.869408 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 315
Initial state: 0 0.408026 0.929469 0.577427 0.8726 0.682829 0.842074 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1114357 episodes
GETTING ACTION FROM:
action 3, numVisits=1114348, meanQ=17.765977, numObservations: 3
action 1, numVisits=3, meanQ=3.330000, numObservations: 3
action 2, numVisits=4, meanQ=3.245025, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.408026 0.929469 0.577427 0.8726 0.682829 0.842074 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 316
Initial state: 0 0.57349 0.809468 0.512393 0.872312 0.761393 0.700877 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1115562 episodes
GETTING ACTION FROM:
action 1, numVisits=1115557, meanQ=17.887279, numObservations: 4
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.57349 0.809468 0.512393 0.872312 0.761393 0.700877 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 317
Initial state: 0 0.588238 0.813644 0.540927 0.881533 0.907284 0.404868 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1104085 episodes
GETTING ACTION FROM:
action 2, numVisits=1104081, meanQ=17.864455, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.588238 0.813644 0.540927 0.881533 0.907284 0.404868 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 318
Initial state: 0 0.0144352 0.217224 0.666854 0.866834 0.588877 0.874189 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1093252 episodes
GETTING ACTION FROM:
action 2, numVisits=1093246, meanQ=17.856962, numObservations: 5
action 1, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.0144352 0.217224 0.666854 0.866834 0.588877 0.874189 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 319
Initial state: 0 0.647772 0.853353 0.317882 0.747629 0.691027 0.874226 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1097240 episodes
GETTING ACTION FROM:
action 1, numVisits=1097236, meanQ=18.102111, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.647772 0.853353 0.317882 0.747629 0.691027 0.874226 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 320
Initial state: 0 0.66993 0.841469 0.417202 0.11712 0.606408 0.89594 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1091957 episodes
GETTING ACTION FROM:
action 2, numVisits=1091950, meanQ=17.727955, numObservations: 5
action 1, numVisits=4, meanQ=8.497500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.66993 0.841469 0.417202 0.11712 0.606408 0.89594 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=152974, meanQ=23.318838, numObservations: 5
action 3, numVisits=3, meanQ=14.996667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1396726 episodes
GETTING ACTION FROM:
action 1, numVisits=1549700, meanQ=19.538081, numObservations: 5
action 3, numVisits=3, meanQ=14.996667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.66993 0.841469 0.417202 0.11712 0.606408 0.89594 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 321
Initial state: 0 0.541667 0.876716 0.598201 0.854261 0.2878 0.914947 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1104656 episodes
GETTING ACTION FROM:
action 1, numVisits=1104649, meanQ=17.917775, numObservations: 5
action 3, numVisits=3, meanQ=12.333333, numObservations: 2
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.541667 0.876716 0.598201 0.854261 0.2878 0.914947 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 322
Initial state: 0 0.466057 0.862175 0.602818 0.832117 0.511565 0.816065 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1097230 episodes
GETTING ACTION FROM:
action 3, numVisits=1097223, meanQ=17.759030, numObservations: 4
action 1, numVisits=4, meanQ=8.497500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.466057 0.862175 0.602818 0.832117 0.511565 0.816065 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 323
Initial state: 0 0.186151 0.0560307 0.537416 0.865723 0.680769 0.800244 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1085150 episodes
GETTING ACTION FROM:
action 1, numVisits=1085132, meanQ=17.782739, numObservations: 4
action 3, numVisits=13, meanQ=8.922315, numObservations: 4
action 2, numVisits=3, meanQ=5.330033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 0 0.186151 0.0560307 0.537416 0.865723 0.680769 0.800244 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=151370, meanQ=23.317727, numObservations: 5
action 3, numVisits=5, meanQ=18.598000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1398372 episodes
GETTING ACTION FROM:
action 2, numVisits=1549739, meanQ=19.317461, numObservations: 5
action 3, numVisits=8, meanQ=16.248750, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.186151 0.0560307 0.537416 0.865723 0.680769 0.800244 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 324
Initial state: 0 0.670401 0.87162 0.0841899 0.517209 0.513808 0.805203 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1094139 episodes
GETTING ACTION FROM:
action 3, numVisits=1094135, meanQ=17.851815, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.670401 0.87162 0.0841899 0.517209 0.513808 0.805203 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 325
Initial state: 0 0.620035 0.836447 0.535798 0.834268 0.0197168 0.682103 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1113790 episodes
GETTING ACTION FROM:
action 2, numVisits=1113779, meanQ=17.734166, numObservations: 3
action 1, numVisits=7, meanQ=11.282857, numObservations: 3
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.620035 0.836447 0.535798 0.834268 0.0197168 0.682103 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 326
Initial state: 0 0.630032 0.812084 0.430755 0.790678 0.678347 0.88195 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1100950 episodes
GETTING ACTION FROM:
action 2, numVisits=1100930, meanQ=17.737304, numObservations: 3
action 3, numVisits=17, meanQ=10.631771, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.630032 0.812084 0.430755 0.790678 0.678347 0.88195 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=180762, meanQ=23.184598, numObservations: 5
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1395298 episodes
GETTING ACTION FROM:
action 3, numVisits=1576060, meanQ=19.834650, numObservations: 5
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.630032 0.812084 0.430755 0.790678 0.678347 0.88195 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 327
Initial state: 0 0.54617 0.894604 0.59466 0.866276 0.0563246 0.578913 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1105712 episodes
GETTING ACTION FROM:
action 2, numVisits=1105702, meanQ=17.849045, numObservations: 4
action 3, numVisits=6, meanQ=14.665017, numObservations: 2
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.54617 0.894604 0.59466 0.866276 0.0563246 0.578913 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 328
Initial state: 0 0.545128 0.806891 0.205686 0.729878 0.6244 0.829908 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1092089 episodes
GETTING ACTION FROM:
action 3, numVisits=1092083, meanQ=17.680960, numObservations: 4
action 1, numVisits=3, meanQ=5.330033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.545128 0.806891 0.205686 0.729878 0.6244 0.829908 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 329
Initial state: 0 0.64458 0.804804 0.841406 0.020066 0.517486 0.874212 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1102251 episodes
GETTING ACTION FROM:
action 1, numVisits=1102245, meanQ=17.729002, numObservations: 4
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.64458 0.804804 0.841406 0.020066 0.517486 0.874212 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 330
Initial state: 0 0.725505 0.998497 0.584516 0.898031 0.558069 0.883354 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1105874 episodes
GETTING ACTION FROM:
action 1, numVisits=1105864, meanQ=17.758320, numObservations: 4
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action 3, numVisits=6, meanQ=9.833350, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 2 0.725505 0.998497 0.584516 0.898031 0.558069 0.883354 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 331
Initial state: 0 0.57823 0.840991 0.0987662 0.488913 0.697582 0.807942 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1103415 episodes
GETTING ACTION FROM:
action 2, numVisits=1103406, meanQ=17.849474, numObservations: 4
action 1, numVisits=6, meanQ=13.665000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.57823 0.840991 0.0987662 0.488913 0.697582 0.807942 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=154126, meanQ=23.290007, numObservations: 4
action 1, numVisits=4, meanQ=17.247500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1387643 episodes
GETTING ACTION FROM:
action 3, numVisits=1541760, meanQ=19.350801, numObservations: 4
action 1, numVisits=13, meanQ=16.537692, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.57823 0.840991 0.0987662 0.488913 0.697582 0.807942 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 332
Initial state: 0 0.583937 0.886959 0.079824 0.38061 0.567588 0.852664 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1098066 episodes
GETTING ACTION FROM:
action 1, numVisits=1098061, meanQ=17.731518, numObservations: 5
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.583937 0.886959 0.079824 0.38061 0.567588 0.852664 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 333
Initial state: 0 0.638513 0.832859 0.636416 0.991219 0.580836 0.881891 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1099189 episodes
GETTING ACTION FROM:
action 1, numVisits=1099174, meanQ=18.131655, numObservations: 5
action 3, numVisits=12, meanQ=8.144167, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.638513 0.832859 0.636416 0.991219 0.580836 0.881891 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 334
Initial state: 0 0.624342 0.800203 0.578669 0.850186 0.97552 0.569336 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1111808 episodes
GETTING ACTION FROM:
action 1, numVisits=1111804, meanQ=17.862193, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.624342 0.800203 0.578669 0.850186 0.97552 0.569336 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 335
Initial state: 0 0.55046 0.53948 0.650909 0.860375 0.576828 0.835432 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1108180 episodes
GETTING ACTION FROM:
action 1, numVisits=1108176, meanQ=17.826170, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.55046 0.53948 0.650909 0.860375 0.576828 0.835432 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=154281, meanQ=23.308022, numObservations: 4
action 3, numVisits=17, meanQ=20.352353, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1419063 episodes
GETTING ACTION FROM:
action 2, numVisits=1573326, meanQ=18.897873, numObservations: 4
action 3, numVisits=35, meanQ=17.399717, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.55046 0.53948 0.650909 0.860375 0.576828 0.835432 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 336
Initial state: 0 0.966052 0.830978 0.673519 0.855968 0.506842 0.801497 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 758465 episodes
GETTING ACTION FROM:
action 0, numVisits=758460, meanQ=15.605156, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.966052 0.830978 0.673519 0.855968 0.506842 0.801497 w: 1
Observation: 0 0 0.756848 0 0.787273 0 0.767518 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=758443, meanQ=17.765637, numObservations: 5
action 3, numVisits=12, meanQ=11.914175, numObservations: 4
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1203680 episodes
GETTING ACTION FROM:
action 1, numVisits=1962123, meanQ=17.765927, numObservations: 5
action 3, numVisits=12, meanQ=11.914175, numObservations: 4
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.966052 0.830978 0.673519 0.855968 0.506842 0.801497 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 337
Initial state: 0 0.518841 0.867444 0.589162 0.837589 0.0345349 0.065978 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1099319 episodes
GETTING ACTION FROM:
action 2, numVisits=1099314, meanQ=17.748071, numObservations: 5
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.518841 0.867444 0.589162 0.837589 0.0345349 0.065978 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 338
Initial state: 0 0.536483 0.832568 0.266233 0.42851 0.57601 0.863977 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1104919 episodes
GETTING ACTION FROM:
action 3, numVisits=1104897, meanQ=17.844058, numObservations: 4
action 1, numVisits=19, meanQ=10.420005, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.536483 0.832568 0.266233 0.42851 0.57601 0.863977 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 339
Initial state: 0 0.76877 0.701645 0.563054 0.835362 0.510012 0.853101 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1092887 episodes
GETTING ACTION FROM:
action 3, numVisits=1092872, meanQ=17.861744, numObservations: 5
action 1, numVisits=10, meanQ=14.674000, numObservations: 3
action 2, numVisits=3, meanQ=12.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.76877 0.701645 0.563054 0.835362 0.510012 0.853101 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 340
Initial state: 0 0.629425 0.85416 0.292935 0.322241 0.673486 0.89632 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1087095 episodes
GETTING ACTION FROM:
action 3, numVisits=1087087, meanQ=17.765805, numObservations: 4
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action 1, numVisits=4, meanQ=8.497500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.629425 0.85416 0.292935 0.322241 0.673486 0.89632 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 341
Initial state: 0 0.649445 0.804279 0.959794 0.176138 0.66458 0.813261 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1106054 episodes
GETTING ACTION FROM:
action 1, numVisits=1106045, meanQ=17.835020, numObservations: 4
action 2, numVisits=4, meanQ=8.497500, numObservations: 2
action 3, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.649445 0.804279 0.959794 0.176138 0.66458 0.813261 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 342
Initial state: 0 0.545309 0.870195 0.400317 0.53504 0.584589 0.825868 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1105599 episodes
GETTING ACTION FROM:
action 2, numVisits=1105591, meanQ=17.778029, numObservations: 4
action 3, numVisits=4, meanQ=8.497500, numObservations: 2
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.545309 0.870195 0.400317 0.53504 0.584589 0.825868 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=27513, meanQ=22.213502, numObservations: 4
action 3, numVisits=9, meanQ=17.556678, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1410283 episodes
GETTING ACTION FROM:
action 1, numVisits=1437651, meanQ=18.506940, numObservations: 4
action 3, numVisits=154, meanQ=17.750131, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.545309 0.870195 0.400317 0.53504 0.584589 0.825868 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 343
Initial state: 0 0.384943 0.946081 0.638293 0.80629 0.579625 0.806119 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 762403 episodes
GETTING ACTION FROM:
action -1, numVisits=762399, meanQ=15.557316, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: -1
Next state: 0 0.384943 0.946081 0.638293 0.80629 0.579625 0.806119 w: 1
Observation: 0 0.461799 0 0.598565 0 0.528506 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=762392, meanQ=17.761959, numObservations: 4
action 1, numVisits=3, meanQ=5.330033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1227625 episodes
GETTING ACTION FROM:
action 2, numVisits=1990017, meanQ=18.264223, numObservations: 4
action 1, numVisits=3, meanQ=5.330033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.384943 0.946081 0.638293 0.80629 0.579625 0.806119 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 344
Initial state: 0 0.502777 0.816128 0.190162 0.496798 0.514256 0.864824 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1028626 episodes
GETTING ACTION FROM:
action 3, numVisits=1028618, meanQ=17.448323, numObservations: 5
action 1, numVisits=5, meanQ=11.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.502777 0.816128 0.190162 0.496798 0.514256 0.864824 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 345
Initial state: 0 0.22715 0.0946782 0.66054 0.871839 0.615851 0.864568 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1110531 episodes
GETTING ACTION FROM:
action 3, numVisits=1110527, meanQ=17.855499, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.22715 0.0946782 0.66054 0.871839 0.615851 0.864568 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 346
Initial state: 0 0.605372 0.823764 0.570205 0.948588 0.538879 0.846902 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1111964 episodes
GETTING ACTION FROM:
action 3, numVisits=1111922, meanQ=17.842437, numObservations: 3
action 2, numVisits=38, meanQ=13.776587, numObservations: 3
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.605372 0.823764 0.570205 0.948588 0.538879 0.846902 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 347
Initial state: 0 0.501009 0.815034 0.609922 0.867201 0.381084 0.608699 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1114843 episodes
GETTING ACTION FROM:
action 3, numVisits=1114808, meanQ=17.780750, numObservations: 3
action 1, numVisits=31, meanQ=14.935168, numObservations: 5
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.501009 0.815034 0.609922 0.867201 0.381084 0.608699 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=183632, meanQ=23.166422, numObservations: 4
action 1, numVisits=5, meanQ=18.598000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1416129 episodes
GETTING ACTION FROM:
action 2, numVisits=1599760, meanQ=19.563168, numObservations: 4
action 1, numVisits=6, meanQ=13.665000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.501009 0.815034 0.609922 0.867201 0.381084 0.608699 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 348
Initial state: 0 0.290178 0.331838 0.640206 0.895299 0.67535 0.803041 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1105257 episodes
GETTING ACTION FROM:
action 2, numVisits=1105248, meanQ=17.722331, numObservations: 3
action 1, numVisits=5, meanQ=7.000020, numObservations: 3
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.290178 0.331838 0.640206 0.895299 0.67535 0.803041 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 349
Initial state: 0 0.678542 0.818523 0.546163 0.867706 0.198086 0.401118 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1101106 episodes
GETTING ACTION FROM:
action 2, numVisits=1101096, meanQ=17.748340, numObservations: 5
action 3, numVisits=7, meanQ=11.857157, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.678542 0.818523 0.546163 0.867706 0.198086 0.401118 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 350
Initial state: 0 0.610134 0.87442 0.354928 0.591577 0.549232 0.886829 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1117134 episodes
GETTING ACTION FROM:
action 1, numVisits=1117122, meanQ=17.862361, numObservations: 3
action 3, numVisits=9, meanQ=7.218889, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.610134 0.87442 0.354928 0.591577 0.549232 0.886829 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 351
Initial state: 0 0.763437 0.503995 0.57146 0.821274 0.636667 0.894692 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1107911 episodes
GETTING ACTION FROM:
action 1, numVisits=1107907, meanQ=17.835516, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.763437 0.503995 0.57146 0.821274 0.636667 0.894692 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 352
Initial state: 0 0.218506 0.912579 0.682329 0.845985 0.563026 0.897739 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1101977 episodes
GETTING ACTION FROM:
action 3, numVisits=1101969, meanQ=17.753585, numObservations: 4
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action 2, numVisits=4, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.218506 0.912579 0.682329 0.845985 0.563026 0.897739 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 353
Initial state: 0 0.547404 0.802417 0.920407 0.756122 0.527133 0.836254 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1105456 episodes
GETTING ACTION FROM:
action 3, numVisits=1105449, meanQ=17.853268, numObservations: 4
action 1, numVisits=4, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.547404 0.802417 0.920407 0.756122 0.527133 0.836254 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=81190, meanQ=18.434079, numObservations: 4
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1260428 episodes
GETTING ACTION FROM:
action 3, numVisits=1341618, meanQ=17.955806, numObservations: 5
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.547404 0.802417 0.920407 0.756122 0.527133 0.836254 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 354
Initial state: 0 0.538668 0.870051 0.64171 0.405905 0.669947 0.85884 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1105699 episodes
GETTING ACTION FROM:
action 2, numVisits=1105683, meanQ=17.861141, numObservations: 4
action 1, numVisits=13, meanQ=13.845385, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.538668 0.870051 0.64171 0.405905 0.669947 0.85884 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 355
Initial state: 0 0.977989 0.295819 0.549747 0.84011 0.525726 0.820124 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1109431 episodes
GETTING ACTION FROM:
action 2, numVisits=1109328, meanQ=17.820683, numObservations: 4
action 3, numVisits=99, meanQ=15.880606, numObservations: 4
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.977989 0.295819 0.549747 0.84011 0.525726 0.820124 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 356
Initial state: 0 0.69377 0.878885 0.540845 0.851015 0.177222 0.494855 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1101492 episodes
GETTING ACTION FROM:
action 3, numVisits=1101482, meanQ=18.179540, numObservations: 5
action 1, numVisits=4, meanQ=9.502525, numObservations: 2
action 2, numVisits=4, meanQ=8.497500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.69377 0.878885 0.540845 0.851015 0.177222 0.494855 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=126316, meanQ=23.518981, numObservations: 3
action 1, numVisits=3, meanQ=14.996667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1412392 episodes
GETTING ACTION FROM:
action 2, numVisits=1538603, meanQ=19.345542, numObservations: 3
action 1, numVisits=108, meanQ=18.421670, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.69377 0.878885 0.540845 0.851015 0.177222 0.494855 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=36587, meanQ=22.423933, numObservations: 4
action 1, numVisits=4, meanQ=17.247500, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1419643 episodes
GETTING ACTION FROM:
action 2, numVisits=1455039, meanQ=19.127676, numObservations: 5
action 1, numVisits=1195, meanQ=18.915063, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.69377 0.878885 0.540845 0.851015 0.177222 0.494855 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=6670, meanQ=21.932387, numObservations: 3
action 1, numVisits=112, meanQ=21.277145, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1446439 episodes
GETTING ACTION FROM:
action 2, numVisits=1452287, meanQ=18.690203, numObservations: 4
action 1, numVisits=934, meanQ=18.433662, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.69377 0.878885 0.540845 0.851015 0.177222 0.494855 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 11.4068
Run # 357
Initial state: 0 0.620215 0.853157 0.540207 0.897881 0.934203 0.082951 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1113312 episodes
GETTING ACTION FROM:
action 3, numVisits=1113304, meanQ=17.848062, numObservations: 3
action 2, numVisits=5, meanQ=11.598000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.620215 0.853157 0.540207 0.897881 0.934203 0.082951 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=84033, meanQ=18.772264, numObservations: 3
action 1, numVisits=15, meanQ=15.732000, numObservations: 3
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1314909 episodes
GETTING ACTION FROM:
action 3, numVisits=1398942, meanQ=18.220926, numObservations: 4
action 1, numVisits=15, meanQ=15.732000, numObservations: 3
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 2 0.620215 0.853157 0.540207 0.897881 0.934203 0.082951 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 358
Initial state: 0 0.665563 0.805691 0.544135 0.800056 0.266119 0.152845 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1109874 episodes
GETTING ACTION FROM:
action 2, numVisits=1109868, meanQ=17.746982, numObservations: 3
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.665563 0.805691 0.544135 0.800056 0.266119 0.152845 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 359
Initial state: 0 0.761959 0.13162 0.611288 0.895663 0.507682 0.817177 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1099955 episodes
GETTING ACTION FROM:
action 1, numVisits=1099949, meanQ=18.099134, numObservations: 5
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 2 0.761959 0.13162 0.611288 0.895663 0.507682 0.817177 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 360
Initial state: 0 0.550977 0.833663 0.686928 0.886003 0.195441 0.561037 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1099076 episodes
GETTING ACTION FROM:
action 2, numVisits=1099065, meanQ=17.750722, numObservations: 4
action 1, numVisits=8, meanQ=9.000013, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.550977 0.833663 0.686928 0.886003 0.195441 0.561037 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 361
Initial state: 0 0.836119 0.161669 0.52418 0.875821 0.594052 0.82713 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1122577 episodes
GETTING ACTION FROM:
action 2, numVisits=1122573, meanQ=17.737645, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.836119 0.161669 0.52418 0.875821 0.594052 0.82713 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 362
Initial state: 0 0.238865 0.400322 0.558166 0.895475 0.607251 0.876852 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1099805 episodes
GETTING ACTION FROM:
action 3, numVisits=1099794, meanQ=17.834641, numObservations: 4
action 2, numVisits=8, meanQ=5.622525, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.238865 0.400322 0.558166 0.895475 0.607251 0.876852 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 363
Initial state: 0 0.502828 0.800976 0.664353 0.841537 0.795961 0.938478 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1096989 episodes
GETTING ACTION FROM:
action 3, numVisits=1096972, meanQ=18.130456, numObservations: 5
action 1, numVisits=9, meanQ=9.748889, numObservations: 3
action 2, numVisits=6, meanQ=8.831683, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 2 0.502828 0.800976 0.664353 0.841537 0.795961 0.938478 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 364
Initial state: 0 0.662945 0.878422 0.888368 0.02816 0.611647 0.896384 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1092128 episodes
GETTING ACTION FROM:
action 2, numVisits=1092120, meanQ=17.853089, numObservations: 5
action 3, numVisits=4, meanQ=8.497500, numObservations: 2
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 2 0.662945 0.878422 0.888368 0.02816 0.611647 0.896384 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 365
Initial state: 0 0.527238 0.849842 0.523142 0.822992 0.55395 0.559791 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1097351 episodes
GETTING ACTION FROM:
action 3, numVisits=1097347, meanQ=17.832832, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.527238 0.849842 0.523142 0.822992 0.55395 0.559791 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 366
Initial state: 0 0.565288 0.897667 0.657907 0.859651 0.0769904 0.542102 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1103044 episodes
GETTING ACTION FROM:
action 3, numVisits=1103035, meanQ=17.713104, numObservations: 4
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 2, numVisits=2, meanQ=-4.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 1
action: 3
Next state: 0 0.565288 0.897667 0.657907 0.859651 0.0769904 0.542102 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=153242, meanQ=23.294939, numObservations: 3
action 2, numVisits=13, meanQ=19.230000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1435365 episodes
GETTING ACTION FROM:
action 1, numVisits=1588604, meanQ=19.930505, numObservations: 3
action 2, numVisits=16, meanQ=17.936875, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.565288 0.897667 0.657907 0.859651 0.0769904 0.542102 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 367
Initial state: 0 0.553898 0.833439 0.00878441 0.919479 0.678341 0.875554 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1102983 episodes
GETTING ACTION FROM:
action 2, numVisits=1102963, meanQ=17.829293, numObservations: 4
action 1, numVisits=17, meanQ=15.118835, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.553898 0.833439 0.00878441 0.919479 0.678341 0.875554 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=81618, meanQ=18.663760, numObservations: 4
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1305800 episodes
GETTING ACTION FROM:
action 2, numVisits=1387418, meanQ=17.727120, numObservations: 4
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.553898 0.833439 0.00878441 0.919479 0.678341 0.875554 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=29016, meanQ=18.938753, numObservations: 4
action 3, numVisits=6, meanQ=10.163350, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1330725 episodes
GETTING ACTION FROM:
action 2, numVisits=1359741, meanQ=17.330542, numObservations: 4
action 3, numVisits=6, meanQ=10.163350, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.553898 0.833439 0.00878441 0.919479 0.678341 0.875554 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=13334, meanQ=22.231219, numObservations: 4
action 2, numVisits=6, meanQ=19.498333, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1432931 episodes
GETTING ACTION FROM:
action 3, numVisits=1446264, meanQ=18.980276, numObservations: 4
action 2, numVisits=7, meanQ=15.141429, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.553898 0.833439 0.00878441 0.919479 0.678341 0.875554 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 11.4068
Run # 368
Initial state: 0 0.664547 0.807339 0.508931 0.882315 0.716796 0.55688 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1067385 episodes
GETTING ACTION FROM:
action 1, numVisits=1067378, meanQ=17.678724, numObservations: 4
action 2, numVisits=4, meanQ=8.497500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.664547 0.807339 0.508931 0.882315 0.716796 0.55688 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 369
Initial state: 0 0.539733 0.861214 0.809119 0.681831 0.557773 0.840035 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 785126 episodes
GETTING ACTION FROM:
action 0, numVisits=785121, meanQ=20.491407, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.539733 0.861214 0.809119 0.681831 0.557773 0.840035 w: 1
Observation: 0 0 0.843396 0 0.74577 0 0.935944 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=245316, meanQ=22.960357, numObservations: 4
action 1, numVisits=3, meanQ=14.996667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1212876 episodes
GETTING ACTION FROM:
action 3, numVisits=1458166, meanQ=18.636642, numObservations: 4
action 1, numVisits=29, meanQ=17.162993, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.539733 0.861214 0.809119 0.681831 0.557773 0.840035 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 370
Initial state: 0 0.527338 0.836126 0.694973 0.879185 0.827212 0.245734 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1098276 episodes
GETTING ACTION FROM:
action 3, numVisits=1098270, meanQ=17.774723, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.527338 0.836126 0.694973 0.879185 0.827212 0.245734 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 371
Initial state: 0 0.633285 0.842385 0.410352 0.310786 0.613476 0.898866 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1109706 episodes
GETTING ACTION FROM:
action 2, numVisits=1109701, meanQ=17.798908, numObservations: 3
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.633285 0.842385 0.410352 0.310786 0.613476 0.898866 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=182385, meanQ=23.152845, numObservations: 5
action 3, numVisits=8, meanQ=20.623750, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1391619 episodes
GETTING ACTION FROM:
action 1, numVisits=1574002, meanQ=18.706916, numObservations: 5
action 3, numVisits=10, meanQ=14.299000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.633285 0.842385 0.410352 0.310786 0.613476 0.898866 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 372
Initial state: 0 0.647632 0.897591 0.631346 0.882311 0.275798 0.214145 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1101961 episodes
GETTING ACTION FROM:
action 2, numVisits=1101948, meanQ=17.852631, numObservations: 5
action 3, numVisits=10, meanQ=11.598000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.647632 0.897591 0.631346 0.882311 0.275798 0.214145 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=80913, meanQ=18.597299, numObservations: 3
action 1, numVisits=11, meanQ=15.907273, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1313935 episodes
GETTING ACTION FROM:
action 2, numVisits=1394847, meanQ=18.031713, numObservations: 4
action 1, numVisits=12, meanQ=13.665000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.647632 0.897591 0.631346 0.882311 0.275798 0.214145 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 373
Initial state: 0 0.551879 0.231722 0.54543 0.824114 0.53466 0.84411 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1097848 episodes
GETTING ACTION FROM:
action 1, numVisits=1097841, meanQ=17.772756, numObservations: 4
action 2, numVisits=4, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.551879 0.231722 0.54543 0.824114 0.53466 0.84411 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 374
Initial state: 0 0.565133 0.895821 0.7971 0.998539 0.694026 0.81196 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1104507 episodes
GETTING ACTION FROM:
action 2, numVisits=1104502, meanQ=17.857973, numObservations: 4
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.565133 0.895821 0.7971 0.998539 0.694026 0.81196 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 375
Initial state: 0 0.382533 0.121773 0.524254 0.871908 0.500757 0.823743 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1112428 episodes
GETTING ACTION FROM:
action 1, numVisits=1112424, meanQ=17.837012, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.382533 0.121773 0.524254 0.871908 0.500757 0.823743 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=128012, meanQ=23.495569, numObservations: 3
action 3, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1425002 episodes
GETTING ACTION FROM:
action 2, numVisits=1553014, meanQ=19.070758, numObservations: 4
action 3, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.382533 0.121773 0.524254 0.871908 0.500757 0.823743 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 376
Initial state: 0 0.589316 0.392295 0.690212 0.836067 0.508323 0.866051 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1117405 episodes
GETTING ACTION FROM:
action 1, numVisits=1117397, meanQ=17.753989, numObservations: 3
action 2, numVisits=4, meanQ=10.495000, numObservations: 3
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 0 0.589316 0.392295 0.690212 0.836067 0.508323 0.866051 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=81881, meanQ=17.376615, numObservations: 4
action 1, numVisits=13, meanQ=14.460000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1403643 episodes
GETTING ACTION FROM:
action 2, numVisits=1485524, meanQ=18.786341, numObservations: 4
action 1, numVisits=13, meanQ=14.460000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.589316 0.392295 0.690212 0.836067 0.508323 0.866051 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 377
Initial state: 0 0.936142 0.205756 0.571574 0.851686 0.634069 0.832321 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1085695 episodes
GETTING ACTION FROM:
action 2, numVisits=1085691, meanQ=17.747884, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.936142 0.205756 0.571574 0.851686 0.634069 0.832321 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 378
Initial state: 0 0.678157 0.894421 0.626459 0.844848 0.499671 0.852449 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1084311 episodes
GETTING ACTION FROM:
action 3, numVisits=1084306, meanQ=17.730335, numObservations: 5
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.678157 0.894421 0.626459 0.844848 0.499671 0.852449 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=27055, meanQ=22.256267, numObservations: 3
action 2, numVisits=9, meanQ=17.997778, numObservations: 4
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1433778 episodes
GETTING ACTION FROM:
action 1, numVisits=1460831, meanQ=18.713647, numObservations: 3
action 2, numVisits=11, meanQ=15.907273, numObservations: 4
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.678157 0.894421 0.626459 0.844848 0.499671 0.852449 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 379
Initial state: 0 0.51491 0.825653 0.965175 0.365958 0.583331 0.874365 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1084416 episodes
GETTING ACTION FROM:
action 3, numVisits=1084412, meanQ=17.761426, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.51491 0.825653 0.965175 0.365958 0.583331 0.874365 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 380
Initial state: 0 0.95395 0.835794 0.598799 0.884641 0.646428 0.835504 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1094142 episodes
GETTING ACTION FROM:
action 1, numVisits=1094137, meanQ=17.778826, numObservations: 5
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.95395 0.835794 0.598799 0.884641 0.646428 0.835504 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 381
Initial state: 0 0.608542 0.892347 0.542429 0.831305 0.765657 0.240534 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1123026 episodes
GETTING ACTION FROM:
action 2, numVisits=1123022, meanQ=17.787452, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.608542 0.892347 0.542429 0.831305 0.765657 0.240534 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 382
Initial state: 0 0.829457 0.278189 0.563623 0.885307 0.649701 0.841946 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1124240 episodes
GETTING ACTION FROM:
action 2, numVisits=1124233, meanQ=17.846158, numObservations: 3
action 1, numVisits=4, meanQ=-0.252500, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.829457 0.278189 0.563623 0.885307 0.649701 0.841946 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 383
Initial state: 0 0.820228 0.0914862 0.674046 0.84934 0.583142 0.846672 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1092031 episodes
GETTING ACTION FROM:
action 3, numVisits=1092016, meanQ=17.766860, numObservations: 5
action 1, numVisits=12, meanQ=14.165008, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.820228 0.0914862 0.674046 0.84934 0.583142 0.846672 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 384
Initial state: 0 0.558261 0.866648 0.698445 0.81425 0.720239 0.577181 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1104893 episodes
GETTING ACTION FROM:
action 3, numVisits=1104885, meanQ=17.840273, numObservations: 4
action 1, numVisits=5, meanQ=10.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.558261 0.866648 0.698445 0.81425 0.720239 0.577181 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 385
Initial state: 0 0.106627 0.533776 0.683615 0.821992 0.575905 0.896873 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1117404 episodes
GETTING ACTION FROM:
action 3, numVisits=1117400, meanQ=17.864285, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.106627 0.533776 0.683615 0.821992 0.575905 0.896873 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 386
Initial state: 0 0.635185 0.827658 0.88005 0.203316 0.69167 0.839636 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1088466 episodes
GETTING ACTION FROM:
action 3, numVisits=1088458, meanQ=17.835839, numObservations: 5
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.635185 0.827658 0.88005 0.203316 0.69167 0.839636 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 387
Initial state: 0 0.83032 0.608777 0.501689 0.879789 0.633696 0.848567 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1111637 episodes
GETTING ACTION FROM:
action 3, numVisits=1111633, meanQ=17.895207, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.83032 0.608777 0.501689 0.879789 0.633696 0.848567 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 388
Initial state: 0 0.6011 0.853427 0.16671 0.908534 0.574071 0.802532 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1091243 episodes
GETTING ACTION FROM:
action 1, numVisits=1091239, meanQ=17.778679, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.6011 0.853427 0.16671 0.908534 0.574071 0.802532 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 389
Initial state: 0 0.671619 0.8725 0.655509 0.856587 0.568126 0.335987 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1108426 episodes
GETTING ACTION FROM:
action 2, numVisits=1108419, meanQ=17.836730, numObservations: 4
action 1, numVisits=4, meanQ=8.497500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.671619 0.8725 0.655509 0.856587 0.568126 0.335987 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=81808, meanQ=18.669431, numObservations: 3
action 3, numVisits=32, meanQ=10.699697, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1302067 episodes
GETTING ACTION FROM:
action 2, numVisits=1383875, meanQ=17.759132, numObservations: 4
action 3, numVisits=32, meanQ=10.699697, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.671619 0.8725 0.655509 0.856587 0.568126 0.335987 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 390
Initial state: 0 0.328605 0.783571 0.667265 0.867611 0.579627 0.80866 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1125998 episodes
GETTING ACTION FROM:
action 2, numVisits=1125994, meanQ=17.855471, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.328605 0.783571 0.667265 0.867611 0.579627 0.80866 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 391
Initial state: 0 0.231936 0.0819622 0.586165 0.838491 0.509176 0.808159 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1103302 episodes
GETTING ACTION FROM:
action 2, numVisits=1103291, meanQ=17.742375, numObservations: 4
action 1, numVisits=7, meanQ=11.282857, numObservations: 4
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.231936 0.0819622 0.586165 0.838491 0.509176 0.808159 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 392
Initial state: 0 0.685351 0.882304 0.051582 0.172518 0.547509 0.876665 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1109428 episodes
GETTING ACTION FROM:
action 2, numVisits=1109424, meanQ=17.741280, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.685351 0.882304 0.051582 0.172518 0.547509 0.876665 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=155100, meanQ=23.322691, numObservations: 5
action 1, numVisits=9, meanQ=17.997778, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1395696 episodes
GETTING ACTION FROM:
action 3, numVisits=1550793, meanQ=18.963090, numObservations: 5
action 1, numVisits=12, meanQ=16.581667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.685351 0.882304 0.051582 0.172518 0.547509 0.876665 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 393
Initial state: 0 0.512876 0.846777 0.796369 0.989396 0.630354 0.896529 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1098918 episodes
GETTING ACTION FROM:
action 1, numVisits=1098913, meanQ=17.761599, numObservations: 4
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.512876 0.846777 0.796369 0.989396 0.630354 0.896529 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 394
Initial state: 0 0.607512 0.843874 0.605465 0.828035 0.085514 0.900584 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1090655 episodes
GETTING ACTION FROM:
action 1, numVisits=1090648, meanQ=17.756866, numObservations: 5
action 2, numVisits=4, meanQ=8.497500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.607512 0.843874 0.605465 0.828035 0.085514 0.900584 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 395
Initial state: 0 0.461855 0.3248 0.628695 0.806081 0.669751 0.838745 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1104705 episodes
GETTING ACTION FROM:
action 3, numVisits=1104701, meanQ=17.852784, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.461855 0.3248 0.628695 0.806081 0.669751 0.838745 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 396
Initial state: 0 0.94159 0.114856 0.675512 0.891944 0.61204 0.830015 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 734870 episodes
GETTING ACTION FROM:
action 0, numVisits=734865, meanQ=15.490814, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.94159 0.114856 0.675512 0.891944 0.61204 0.830015 w: 1
Observation: 0 0 0.205358 0 0.954847 0 0.913559 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=734822, meanQ=17.706838, numObservations: 5
action 1, numVisits=21, meanQ=13.463819, numObservations: 4
action 2, numVisits=19, meanQ=13.163158, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1162849 episodes
GETTING ACTION FROM:
action 3, numVisits=1897671, meanQ=17.874042, numObservations: 5
action 1, numVisits=21, meanQ=13.463819, numObservations: 4
action 2, numVisits=19, meanQ=13.163158, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.94159 0.114856 0.675512 0.891944 0.61204 0.830015 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 0, numVisits=137981, meanQ=16.545331, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1198112 episodes
GETTING ACTION FROM:
action 0, numVisits=1336092, meanQ=3.762583, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.94159 0.114856 0.675512 0.891944 0.61204 0.830015 w: 1
Observation: 0 0 0.146234 0 0.863073 0 0.731452 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=433233, meanQ=17.048822, numObservations: 4
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1292895 episodes
GETTING ACTION FROM:
action 3, numVisits=1726128, meanQ=18.216114, numObservations: 4
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.94159 0.114856 0.675512 0.891944 0.61204 0.830015 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.367
Run # 397
Initial state: 0 0.478968 0.0732525 0.68986 0.827281 0.609625 0.854119 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1105779 episodes
GETTING ACTION FROM:
action 1, numVisits=1105740, meanQ=18.084713, numObservations: 4
action 2, numVisits=35, meanQ=12.249440, numObservations: 4
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 0 0.478968 0.0732525 0.68986 0.827281 0.609625 0.854119 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=36420, meanQ=22.552818, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1405793 episodes
GETTING ACTION FROM:
action 2, numVisits=1442213, meanQ=18.886261, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.478968 0.0732525 0.68986 0.827281 0.609625 0.854119 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 398
Initial state: 0 0.598453 0.813719 0.564509 0.893334 0.750506 0.0100034 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1110154 episodes
GETTING ACTION FROM:
action 2, numVisits=1110148, meanQ=17.874301, numObservations: 4
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.598453 0.813719 0.564509 0.893334 0.750506 0.0100034 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=81951, meanQ=18.640940, numObservations: 3
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1301866 episodes
GETTING ACTION FROM:
action 2, numVisits=1383817, meanQ=17.909650, numObservations: 4
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.598453 0.813719 0.564509 0.893334 0.750506 0.0100034 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 399
Initial state: 0 0.514779 0.808574 0.5955 0.845935 0.306077 0.202143 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1087763 episodes
GETTING ACTION FROM:
action 3, numVisits=1087749, meanQ=17.902329, numObservations: 5
action 2, numVisits=9, meanQ=11.554456, numObservations: 3
action 1, numVisits=3, meanQ=4.670033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.514779 0.808574 0.5955 0.845935 0.306077 0.202143 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=55261, meanQ=22.318716, numObservations: 5
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1391357 episodes
GETTING ACTION FROM:
action 1, numVisits=1446618, meanQ=19.031258, numObservations: 5
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.514779 0.808574 0.5955 0.845935 0.306077 0.202143 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 400
Initial state: 0 0.60842 0.891515 0.625053 0.0974888 0.632614 0.884741 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1103077 episodes
GETTING ACTION FROM:
action 3, numVisits=1103073, meanQ=17.752684, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.60842 0.891515 0.625053 0.0974888 0.632614 0.884741 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 401
Initial state: 0 0.579181 0.886317 0.29829 0.324097 0.595313 0.814273 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1089993 episodes
GETTING ACTION FROM:
action 2, numVisits=1089989, meanQ=17.734675, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.579181 0.886317 0.29829 0.324097 0.595313 0.814273 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 402
Initial state: 0 0.668621 0.809998 0.554723 0.804318 0.496134 0.418488 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 765906 episodes
GETTING ACTION FROM:
action -1, numVisits=765902, meanQ=15.582434, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.668621 0.809998 0.554723 0.804318 0.496134 0.418488 w: 1
Observation: 0 0.68407 0 0.469193 0 0.541725 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=765895, meanQ=17.807078, numObservations: 3
action 2, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1221970 episodes
GETTING ACTION FROM:
action 3, numVisits=1987865, meanQ=18.122339, numObservations: 3
action 2, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.668621 0.809998 0.554723 0.804318 0.496134 0.418488 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=327971, meanQ=23.163648, numObservations: 5
action 2, numVisits=26, meanQ=19.768081, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1393887 episodes
GETTING ACTION FROM:
action 1, numVisits=1721809, meanQ=19.800584, numObservations: 5
action 2, numVisits=75, meanQ=18.766536, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.668621 0.809998 0.554723 0.804318 0.496134 0.418488 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 17.5624
Run # 403
Initial state: 0 0.491266 0.632219 0.589749 0.865021 0.632753 0.852843 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1083925 episodes
GETTING ACTION FROM:
action 3, numVisits=1083921, meanQ=17.764997, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.491266 0.632219 0.589749 0.865021 0.632753 0.852843 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 404
Initial state: 0 0.502769 0.833777 0.626421 0.775845 0.667702 0.845924 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1098545 episodes
GETTING ACTION FROM:
action 1, numVisits=1098541, meanQ=17.844217, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.502769 0.833777 0.626421 0.775845 0.667702 0.845924 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 405
Initial state: 0 0.548024 0.842405 0.0531422 0.633779 0.556792 0.851257 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1092011 episodes
GETTING ACTION FROM:
action 3, numVisits=1092004, meanQ=17.873772, numObservations: 5
action 2, numVisits=4, meanQ=-0.252500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.548024 0.842405 0.0531422 0.633779 0.556792 0.851257 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 406
Initial state: 0 0.604012 0.860442 0.312978 0.7742 0.619442 0.876314 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1085183 episodes
GETTING ACTION FROM:
action 1, numVisits=1085170, meanQ=17.798262, numObservations: 5
action 3, numVisits=10, meanQ=7.709000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.604012 0.860442 0.312978 0.7742 0.619442 0.876314 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 407
Initial state: 0 0.518276 0.844968 0.101447 0.0734091 0.603553 0.864201 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1097131 episodes
GETTING ACTION FROM:
action 1, numVisits=1097127, meanQ=17.849497, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.518276 0.844968 0.101447 0.0734091 0.603553 0.864201 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 408
Initial state: 0 0.69618 0.889455 0.683717 0.868383 0.651327 0.239659 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1101966 episodes
GETTING ACTION FROM:
action 1, numVisits=1101962, meanQ=17.762841, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.69618 0.889455 0.683717 0.868383 0.651327 0.239659 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 409
Initial state: 0 0.996166 0.180339 0.567737 0.886098 0.571174 0.852409 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1100666 episodes
GETTING ACTION FROM:
action 3, numVisits=1100650, meanQ=17.841158, numObservations: 4
action 1, numVisits=5, meanQ=11.598000, numObservations: 2
action 2, numVisits=9, meanQ=11.553356, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.996166 0.180339 0.567737 0.886098 0.571174 0.852409 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=81348, meanQ=18.596478, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1277851 episodes
GETTING ACTION FROM:
action 3, numVisits=1359199, meanQ=17.234849, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.996166 0.180339 0.567737 0.886098 0.571174 0.852409 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 410
Initial state: 0 0.402147 0.373154 0.618607 0.859858 0.639125 0.857668 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1110306 episodes
GETTING ACTION FROM:
action 2, numVisits=1110302, meanQ=17.864502, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.402147 0.373154 0.618607 0.859858 0.639125 0.857668 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 411
Initial state: 0 0.658555 0.856827 0.549625 0.886009 0.0373859 0.888611 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1095126 episodes
GETTING ACTION FROM:
action 2, numVisits=1095121, meanQ=17.871985, numObservations: 5
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.658555 0.856827 0.549625 0.886009 0.0373859 0.888611 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 412
Initial state: 0 0.732434 0.670303 0.506343 0.859005 0.505377 0.804451 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1111542 episodes
GETTING ACTION FROM:
action 1, numVisits=1111538, meanQ=17.840681, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.732434 0.670303 0.506343 0.859005 0.505377 0.804451 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 413
Initial state: 0 0.278521 0.06038 0.64075 0.86627 0.547185 0.828406 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1103703 episodes
GETTING ACTION FROM:
action 2, numVisits=1103685, meanQ=17.765000, numObservations: 4
action 1, numVisits=15, meanQ=14.916667, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.278521 0.06038 0.64075 0.86627 0.547185 0.828406 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 414
Initial state: 0 0.518777 0.895441 0.985729 0.777583 0.64219 0.841611 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1111674 episodes
GETTING ACTION FROM:
action 1, numVisits=1111662, meanQ=17.874250, numObservations: 4
action 2, numVisits=7, meanQ=14.535714, numObservations: 2
action 3, numVisits=3, meanQ=12.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.518777 0.895441 0.985729 0.777583 0.64219 0.841611 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 415
Initial state: 0 0.477931 0.157943 0.616198 0.827576 0.574222 0.830828 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1099411 episodes
GETTING ACTION FROM:
action 3, numVisits=1099406, meanQ=17.764485, numObservations: 4
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.477931 0.157943 0.616198 0.827576 0.574222 0.830828 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 416
Initial state: 0 0.504376 0.8815 0.634887 0.940757 0.531008 0.823525 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1100494 episodes
GETTING ACTION FROM:
action 3, numVisits=1100490, meanQ=17.749837, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.504376 0.8815 0.634887 0.940757 0.531008 0.823525 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 417
Initial state: 0 0.643462 0.802491 0.849693 0.298438 0.566793 0.887462 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1093236 episodes
GETTING ACTION FROM:
action 3, numVisits=1093229, meanQ=17.840691, numObservations: 5
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.643462 0.802491 0.849693 0.298438 0.566793 0.887462 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=80604, meanQ=18.527970, numObservations: 3
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1299550 episodes
GETTING ACTION FROM:
action 3, numVisits=1380154, meanQ=17.689261, numObservations: 4
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.643462 0.802491 0.849693 0.298438 0.566793 0.887462 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 418
Initial state: 0 0.17105 0.271181 0.555221 0.868306 0.597977 0.863059 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1105294 episodes
GETTING ACTION FROM:
action 2, numVisits=1105287, meanQ=17.863672, numObservations: 4
action 1, numVisits=4, meanQ=8.497500, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.17105 0.271181 0.555221 0.868306 0.597977 0.863059 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=10129, meanQ=18.709569, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1287506 episodes
GETTING ACTION FROM:
action 2, numVisits=1297635, meanQ=17.943658, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.17105 0.271181 0.555221 0.868306 0.597977 0.863059 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 419
Initial state: 0 0.573917 0.784276 0.568753 0.857132 0.609758 0.893149 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1111172 episodes
GETTING ACTION FROM:
action 3, numVisits=1111164, meanQ=17.773457, numObservations: 3
action 1, numVisits=3, meanQ=3.330000, numObservations: 1
action 2, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.573917 0.784276 0.568753 0.857132 0.609758 0.893149 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 420
Initial state: 0 0.224302 0.180077 0.659487 0.884166 0.697892 0.88714 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1113028 episodes
GETTING ACTION FROM:
action 3, numVisits=1113023, meanQ=17.867697, numObservations: 3
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.224302 0.180077 0.659487 0.884166 0.697892 0.88714 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 421
Initial state: 0 0.241989 0.968148 0.578847 0.899988 0.54347 0.847243 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1117445 episodes
GETTING ACTION FROM:
action 1, numVisits=1117435, meanQ=17.848648, numObservations: 3
action 2, numVisits=7, meanQ=9.585714, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.241989 0.968148 0.578847 0.899988 0.54347 0.847243 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=82811, meanQ=18.682076, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1310285 episodes
GETTING ACTION FROM:
action 1, numVisits=1393096, meanQ=17.548508, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.241989 0.968148 0.578847 0.899988 0.54347 0.847243 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 422
Initial state: 0 0.772892 0.681938 0.652748 0.833627 0.545609 0.813303 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1100853 episodes
GETTING ACTION FROM:
action 3, numVisits=1100841, meanQ=17.742373, numObservations: 4
action 1, numVisits=9, meanQ=10.220000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.772892 0.681938 0.652748 0.833627 0.545609 0.813303 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 423
Initial state: 0 0.2123 0.0334893 0.573885 0.850516 0.673982 0.859889 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1060807 episodes
GETTING ACTION FROM:
action 3, numVisits=1060800, meanQ=17.581530, numObservations: 4
action 2, numVisits=4, meanQ=8.497500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.2123 0.0334893 0.573885 0.850516 0.673982 0.859889 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 424
Initial state: 0 0.512876 0.805908 0.652971 0.89036 0.253062 0.411649 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1099904 episodes
GETTING ACTION FROM:
action 3, numVisits=1099897, meanQ=17.761938, numObservations: 4
action 2, numVisits=4, meanQ=8.497500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.512876 0.805908 0.652971 0.89036 0.253062 0.411649 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=153513, meanQ=23.298906, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1432839 episodes
GETTING ACTION FROM:
action 1, numVisits=1586352, meanQ=19.680063, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.512876 0.805908 0.652971 0.89036 0.253062 0.411649 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 425
Initial state: 0 0.57666 0.877582 0.57979 0.845878 0.866146 0.44784 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1090408 episodes
GETTING ACTION FROM:
action 2, numVisits=1090395, meanQ=17.763761, numObservations: 5
action 1, numVisits=9, meanQ=14.108889, numObservations: 2
action 3, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.57666 0.877582 0.57979 0.845878 0.866146 0.44784 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 426
Initial state: 0 0.5795 0.860369 0.4294 0.388298 0.515417 0.810412 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1110506 episodes
GETTING ACTION FROM:
action 1, numVisits=1110492, meanQ=17.878612, numObservations: 4
action 2, numVisits=11, meanQ=9.543636, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.5795 0.860369 0.4294 0.388298 0.515417 0.810412 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 427
Initial state: 0 0.983996 0.738548 0.593677 0.802047 0.596823 0.8938 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1100429 episodes
GETTING ACTION FROM:
action 2, numVisits=1100422, meanQ=17.735380, numObservations: 4
action 3, numVisits=3, meanQ=12.333333, numObservations: 2
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.983996 0.738548 0.593677 0.802047 0.596823 0.8938 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 428
Initial state: 0 0.613665 0.890517 0.353754 0.167923 0.669309 0.851962 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1099439 episodes
GETTING ACTION FROM:
action 3, numVisits=1099431, meanQ=17.749946, numObservations: 4
action 2, numVisits=5, meanQ=12.798020, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.613665 0.890517 0.353754 0.167923 0.669309 0.851962 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 429
Initial state: 0 0.473317 0.283387 0.686414 0.820244 0.573567 0.832386 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1117346 episodes
GETTING ACTION FROM:
action 3, numVisits=1117338, meanQ=17.869279, numObservations: 3
action 1, numVisits=5, meanQ=4.598000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.473317 0.283387 0.686414 0.820244 0.573567 0.832386 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 430
Initial state: 0 0.677491 0.824538 0.860918 0.337277 0.679958 0.80413 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1084779 episodes
GETTING ACTION FROM:
action 3, numVisits=1084774, meanQ=17.736495, numObservations: 5
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.677491 0.824538 0.860918 0.337277 0.679958 0.80413 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=150916, meanQ=23.302451, numObservations: 3
action 1, numVisits=3, meanQ=14.996667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1432106 episodes
GETTING ACTION FROM:
action 2, numVisits=1583019, meanQ=18.824829, numObservations: 3
action 1, numVisits=6, meanQ=13.665000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.677491 0.824538 0.860918 0.337277 0.679958 0.80413 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 431
Initial state: 0 0.138007 0.223151 0.657848 0.89422 0.658513 0.847586 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1103413 episodes
GETTING ACTION FROM:
action 2, numVisits=1103407, meanQ=18.122713, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.138007 0.223151 0.657848 0.89422 0.658513 0.847586 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 432
Initial state: 0 0.57524 0.888526 0.0360515 0.188783 0.528377 0.85654 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1129358 episodes
GETTING ACTION FROM:
action 1, numVisits=1129353, meanQ=17.855954, numObservations: 4
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.57524 0.888526 0.0360515 0.188783 0.528377 0.85654 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 433
Initial state: 0 0.544248 0.802323 0.957946 0.453594 0.515207 0.885007 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1128258 episodes
GETTING ACTION FROM:
action 1, numVisits=1128244, meanQ=17.869055, numObservations: 5
action 3, numVisits=11, meanQ=11.999091, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.544248 0.802323 0.957946 0.453594 0.515207 0.885007 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 434
Initial state: 0 0.614053 0.866732 0.488804 0.463818 0.606835 0.800336 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1136828 episodes
GETTING ACTION FROM:
action 2, numVisits=1136824, meanQ=17.768573, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.614053 0.866732 0.488804 0.463818 0.606835 0.800336 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=28622, meanQ=22.234141, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1439135 episodes
GETTING ACTION FROM:
action 3, numVisits=1467757, meanQ=18.478001, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.614053 0.866732 0.488804 0.463818 0.606835 0.800336 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 435
Initial state: 0 0.589733 0.808237 0.495314 0.138897 0.510138 0.883795 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1084552 episodes
GETTING ACTION FROM:
action 2, numVisits=1084547, meanQ=17.602630, numObservations: 5
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.589733 0.808237 0.495314 0.138897 0.510138 0.883795 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=124363, meanQ=23.513945, numObservations: 3
action 3, numVisits=5, meanQ=18.598000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1439878 episodes
GETTING ACTION FROM:
action 1, numVisits=1564222, meanQ=19.543531, numObservations: 4
action 3, numVisits=24, meanQ=17.374167, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.589733 0.808237 0.495314 0.138897 0.510138 0.883795 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 436
Initial state: 0 0.785887 0.381597 0.504609 0.884588 0.661562 0.830434 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1145521 episodes
GETTING ACTION FROM:
action 1, numVisits=1145463, meanQ=17.849211, numObservations: 3
action 2, numVisits=54, meanQ=12.243581, numObservations: 4
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 2 0.785887 0.381597 0.504609 0.884588 0.661562 0.830434 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 437
Initial state: 0 0.61281 0.822426 0.333392 0.523055 0.641093 0.841721 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1093287 episodes
GETTING ACTION FROM:
action 2, numVisits=1093282, meanQ=17.581479, numObservations: 4
action 3, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.61281 0.822426 0.333392 0.523055 0.641093 0.841721 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 438
Initial state: 0 0.586756 0.165872 0.636641 0.820618 0.621315 0.831777 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1137462 episodes
GETTING ACTION FROM:
action 1, numVisits=1137457, meanQ=17.862935, numObservations: 4
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.586756 0.165872 0.636641 0.820618 0.621315 0.831777 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 439
Initial state: 0 0.509603 0.813368 0.256355 0.0775422 0.65447 0.848461 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1133223 episodes
GETTING ACTION FROM:
action 2, numVisits=1133218, meanQ=17.764851, numObservations: 4
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.509603 0.813368 0.256355 0.0775422 0.65447 0.848461 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=187040, meanQ=23.166745, numObservations: 3
action 1, numVisits=3, meanQ=14.996667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1470796 episodes
GETTING ACTION FROM:
action 3, numVisits=1657836, meanQ=19.753650, numObservations: 3
action 1, numVisits=3, meanQ=14.996667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.509603 0.813368 0.256355 0.0775422 0.65447 0.848461 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 440
Initial state: 0 0.431115 0.112968 0.698678 0.805752 0.548452 0.824551 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1141139 episodes
GETTING ACTION FROM:
action 2, numVisits=1141129, meanQ=17.772607, numObservations: 3
action 1, numVisits=7, meanQ=5.715729, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.431115 0.112968 0.698678 0.805752 0.548452 0.824551 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 441
Initial state: 0 0.653046 0.802081 0.686912 0.801975 0.303066 0.441078 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1142732 episodes
GETTING ACTION FROM:
action 1, numVisits=1142726, meanQ=17.747649, numObservations: 3
action 2, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.653046 0.802081 0.686912 0.801975 0.303066 0.441078 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 442
Initial state: 0 0.508103 0.866036 0.486538 0.383058 0.557499 0.813814 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1127346 episodes
GETTING ACTION FROM:
action 2, numVisits=1127338, meanQ=17.733821, numObservations: 4
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action 1, numVisits=4, meanQ=6.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.508103 0.866036 0.486538 0.383058 0.557499 0.813814 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=185285, meanQ=23.142871, numObservations: 5
action 3, numVisits=10, meanQ=20.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1419455 episodes
GETTING ACTION FROM:
action 1, numVisits=1604645, meanQ=18.818954, numObservations: 5
action 3, numVisits=105, meanQ=17.890286, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.508103 0.866036 0.486538 0.383058 0.557499 0.813814 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 443
Initial state: 0 0.66784 0.854905 0.514584 0.833602 0.771796 0.0750619 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1123117 episodes
GETTING ACTION FROM:
action 3, numVisits=1123113, meanQ=17.892803, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.66784 0.854905 0.514584 0.833602 0.771796 0.0750619 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 444
Initial state: 0 0.553087 0.890509 0.0747632 0.0121379 0.572473 0.804056 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1116023 episodes
GETTING ACTION FROM:
action 2, numVisits=1116016, meanQ=17.861490, numObservations: 5
action 1, numVisits=4, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.553087 0.890509 0.0747632 0.0121379 0.572473 0.804056 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=128731, meanQ=23.502566, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1438063 episodes
GETTING ACTION FROM:
action 3, numVisits=1566794, meanQ=19.025560, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.553087 0.890509 0.0747632 0.0121379 0.572473 0.804056 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 445
Initial state: 0 0.731137 0.169128 0.545094 0.806396 0.601029 0.845367 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1128004 episodes
GETTING ACTION FROM:
action 2, numVisits=1127988, meanQ=17.757215, numObservations: 4
action 3, numVisits=12, meanQ=13.145842, numObservations: 3
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.731137 0.169128 0.545094 0.806396 0.601029 0.845367 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 446
Initial state: 0 0.603703 0.819977 0.592355 0.845821 0.974248 0.209042 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1113538 episodes
GETTING ACTION FROM:
action 3, numVisits=1113534, meanQ=17.765213, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.603703 0.819977 0.592355 0.845821 0.974248 0.209042 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 447
Initial state: 0 0.591275 0.888355 0.566456 0.843114 0.616522 0.0333847 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1128958 episodes
GETTING ACTION FROM:
action 2, numVisits=1128953, meanQ=17.744347, numObservations: 4
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.591275 0.888355 0.566456 0.843114 0.616522 0.0333847 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 448
Initial state: 0 0.666401 0.835506 0.650875 0.888468 0.183773 0.127796 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1125059 episodes
GETTING ACTION FROM:
action 3, numVisits=1125054, meanQ=17.753201, numObservations: 4
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.666401 0.835506 0.650875 0.888468 0.183773 0.127796 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=184808, meanQ=23.154146, numObservations: 5
action 2, numVisits=3, meanQ=14.996667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1426034 episodes
GETTING ACTION FROM:
action 1, numVisits=1610814, meanQ=19.082924, numObservations: 5
action 2, numVisits=31, meanQ=17.604516, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.666401 0.835506 0.650875 0.888468 0.183773 0.127796 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 449
Initial state: 0 0.709414 0.707245 0.646676 0.816549 0.693419 0.896626 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1082674 episodes
GETTING ACTION FROM:
action 2, numVisits=1082669, meanQ=17.683023, numObservations: 5
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.709414 0.707245 0.646676 0.816549 0.693419 0.896626 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 450
Initial state: 0 0.543452 0.805344 0.579604 0.856295 0.453964 0.0219243 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 782477 episodes
GETTING ACTION FROM:
action -1, numVisits=782472, meanQ=15.542375, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: -1
Next state: 0 0.543452 0.805344 0.579604 0.856295 0.453964 0.0219243 w: 1
Observation: 0 0.612527 0 0.634456 0 0.361007 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=782464, meanQ=17.746588, numObservations: 4
action 3, numVisits=4, meanQ=10.495000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1253257 episodes
GETTING ACTION FROM:
action 2, numVisits=2035721, meanQ=17.858820, numObservations: 4
action 3, numVisits=4, meanQ=10.495000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.543452 0.805344 0.579604 0.856295 0.453964 0.0219243 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=152015, meanQ=17.114891, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1415038 episodes
GETTING ACTION FROM:
action 3, numVisits=1567053, meanQ=17.591983, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.543452 0.805344 0.579604 0.856295 0.453964 0.0219243 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=44535, meanQ=23.282164, numObservations: 4
action 2, numVisits=14, meanQ=20.141429, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1460951 episodes
GETTING ACTION FROM:
action 2, numVisits=651278, meanQ=18.885647, numObservations: 5
action 1, numVisits=854222, meanQ=18.815109, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.543452 0.805344 0.579604 0.856295 0.453964 0.0219243 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 3, numVisits=2755, meanQ=22.788756, numObservations: 4
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1457602 episodes
GETTING ACTION FROM:
action 3, numVisits=1460357, meanQ=18.112531, numObservations: 5
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.543452 0.805344 0.579604 0.856295 0.453964 0.0219243 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -24.3282
Run # 451
Initial state: 0 0.608553 0.806622 0.617277 0.895439 0.415383 0.100265 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1109964 episodes
GETTING ACTION FROM:
action 1, numVisits=1109960, meanQ=17.977840, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.608553 0.806622 0.617277 0.895439 0.415383 0.100265 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 452
Initial state: 0 0.121676 0.375647 0.609617 0.804397 0.542033 0.896279 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1116599 episodes
GETTING ACTION FROM:
action 1, numVisits=1116579, meanQ=17.763888, numObservations: 5
action 3, numVisits=14, meanQ=12.070714, numObservations: 2
action 2, numVisits=4, meanQ=10.495000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 0 0.121676 0.375647 0.609617 0.804397 0.542033 0.896279 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=128135, meanQ=23.513488, numObservations: 3
action 2, numVisits=6, meanQ=19.498333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1410573 episodes
GETTING ACTION FROM:
action 3, numVisits=1538702, meanQ=19.261474, numObservations: 5
action 2, numVisits=12, meanQ=16.581667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.121676 0.375647 0.609617 0.804397 0.542033 0.896279 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 453
Initial state: 0 0.535731 0.858092 0.37145 0.0161025 0.538147 0.803211 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1108252 episodes
GETTING ACTION FROM:
action 3, numVisits=1108247, meanQ=17.748535, numObservations: 5
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.535731 0.858092 0.37145 0.0161025 0.538147 0.803211 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 454
Initial state: 0 0.571011 0.841445 0.548927 0.861753 0.795484 0.453856 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1137784 episodes
GETTING ACTION FROM:
action 1, numVisits=1137778, meanQ=17.834001, numObservations: 4
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.571011 0.841445 0.548927 0.861753 0.795484 0.453856 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 455
Initial state: 0 0.939042 0.364261 0.512838 0.851639 0.511117 0.825479 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1115224 episodes
GETTING ACTION FROM:
action 3, numVisits=1115220, meanQ=17.855503, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.939042 0.364261 0.512838 0.851639 0.511117 0.825479 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 456
Initial state: 0 0.563772 0.682891 0.521869 0.808098 0.523344 0.846668 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1013490 episodes
GETTING ACTION FROM:
action 3, numVisits=1013486, meanQ=17.753698, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.563772 0.682891 0.521869 0.808098 0.523344 0.846668 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=75274, meanQ=17.267370, numObservations: 5
action 2, numVisits=3, meanQ=12.333333, numObservations: 2
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1332266 episodes
GETTING ACTION FROM:
action 1, numVisits=1407540, meanQ=18.380891, numObservations: 5
action 2, numVisits=3, meanQ=12.333333, numObservations: 2
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 0 0.563772 0.682891 0.521869 0.808098 0.523344 0.846668 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=11691, meanQ=22.548942, numObservations: 3
action 3, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1404152 episodes
GETTING ACTION FROM:
action 2, numVisits=1415843, meanQ=18.779937, numObservations: 3
action 3, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.563772 0.682891 0.521869 0.808098 0.523344 0.846668 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 457
Initial state: 0 0.65143 0.885649 0.67128 0.875393 0.41995 0.1097 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1041740 episodes
GETTING ACTION FROM:
action 1, numVisits=1041736, meanQ=17.727312, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.65143 0.885649 0.67128 0.875393 0.41995 0.1097 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 458
Initial state: 0 0.640819 0.8196 0.525437 0.871171 0.926049 0.337723 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1066300 episodes
GETTING ACTION FROM:
action 3, numVisits=1066294, meanQ=17.859426, numObservations: 3
action 1, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.640819 0.8196 0.525437 0.871171 0.926049 0.337723 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 459
Initial state: 0 0.589358 0.821873 0.647987 0.817928 0.21132 0.449808 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1047895 episodes
GETTING ACTION FROM:
action 2, numVisits=1047889, meanQ=17.867261, numObservations: 5
action 3, numVisits=2, meanQ=10.495000, numObservations: 1
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.589358 0.821873 0.647987 0.817928 0.21132 0.449808 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 460
Initial state: 0 0.662356 0.864834 0.673735 0.879079 0.909655 0.116714 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1066111 episodes
GETTING ACTION FROM:
action 2, numVisits=1066106, meanQ=17.872272, numObservations: 3
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.662356 0.864834 0.673735 0.879079 0.909655 0.116714 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 461
Initial state: 0 0.274717 0.88588 0.565788 0.800345 0.61445 0.829727 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1050159 episodes
GETTING ACTION FROM:
action 3, numVisits=1050155, meanQ=17.852679, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.274717 0.88588 0.565788 0.800345 0.61445 0.829727 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 462
Initial state: 0 0.686012 0.868083 0.79396 0.0564902 0.641651 0.884827 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1048452 episodes
GETTING ACTION FROM:
action 2, numVisits=1048433, meanQ=17.815630, numObservations: 4
action 1, numVisits=16, meanQ=14.047506, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.686012 0.868083 0.79396 0.0564902 0.641651 0.884827 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 463
Initial state: 0 0.512113 0.852032 0.548528 0.343567 0.600371 0.842617 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1054821 episodes
GETTING ACTION FROM:
action 1, numVisits=1054816, meanQ=17.825581, numObservations: 4
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.512113 0.852032 0.548528 0.343567 0.600371 0.842617 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=146784, meanQ=23.333596, numObservations: 5
action 2, numVisits=3, meanQ=14.996667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1312169 episodes
GETTING ACTION FROM:
action 3, numVisits=1458953, meanQ=19.735972, numObservations: 5
action 2, numVisits=3, meanQ=14.996667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.512113 0.852032 0.548528 0.343567 0.600371 0.842617 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 464
Initial state: 0 0.694197 0.801474 0.505346 0.838623 0.428269 0.476714 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1004162 episodes
GETTING ACTION FROM:
action 3, numVisits=1004158, meanQ=17.611094, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.694197 0.801474 0.505346 0.838623 0.428269 0.476714 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=139802, meanQ=23.329786, numObservations: 5
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1324252 episodes
GETTING ACTION FROM:
action 1, numVisits=1464054, meanQ=19.102825, numObservations: 5
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.694197 0.801474 0.505346 0.838623 0.428269 0.476714 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 465
Initial state: 0 0.876658 0.510591 0.679928 0.89998 0.530815 0.85351 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1053678 episodes
GETTING ACTION FROM:
action 2, numVisits=1053674, meanQ=17.845534, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.876658 0.510591 0.679928 0.89998 0.530815 0.85351 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 466
Initial state: 0 0.0253467 0.497966 0.626282 0.804788 0.580769 0.815311 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1067494 episodes
GETTING ACTION FROM:
action 2, numVisits=1067489, meanQ=17.755135, numObservations: 3
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.0253467 0.497966 0.626282 0.804788 0.580769 0.815311 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 467
Initial state: 0 0.417764 0.055751 0.655821 0.824946 0.586328 0.853484 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1035727 episodes
GETTING ACTION FROM:
action 3, numVisits=1035720, meanQ=17.847658, numObservations: 5
action 2, numVisits=4, meanQ=9.997525, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.417764 0.055751 0.655821 0.824946 0.586328 0.853484 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 468
Initial state: 0 0.557265 0.86878 0.53956 0.825534 0.811308 0.48003 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1053167 episodes
GETTING ACTION FROM:
action 2, numVisits=1053159, meanQ=17.793517, numObservations: 4
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action 1, numVisits=4, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.557265 0.86878 0.53956 0.825534 0.811308 0.48003 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 469
Initial state: 0 0.694176 0.885894 0.0100881 0.350527 0.630922 0.87244 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1064966 episodes
GETTING ACTION FROM:
action 1, numVisits=1064960, meanQ=17.840329, numObservations: 3
action 3, numVisits=3, meanQ=12.333333, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.694176 0.885894 0.0100881 0.350527 0.630922 0.87244 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 470
Initial state: 0 0.928325 0.92443 0.514958 0.828415 0.626169 0.826638 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1051657 episodes
GETTING ACTION FROM:
action 2, numVisits=1051649, meanQ=17.757467, numObservations: 4
action 1, numVisits=5, meanQ=11.598000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.928325 0.92443 0.514958 0.828415 0.626169 0.826638 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 471
Initial state: 0 0.853084 0.303691 0.578605 0.812968 0.541603 0.810929 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1049382 episodes
GETTING ACTION FROM:
action 2, numVisits=1049374, meanQ=17.864648, numObservations: 5
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=2, meanQ=-4.004950, numObservations: 1
action: 2
Next state: 1 0.853084 0.303691 0.578605 0.812968 0.541603 0.810929 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 472
Initial state: 0 0.614492 0.800167 0.381504 0.754394 0.633632 0.80534 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1042455 episodes
GETTING ACTION FROM:
action 3, numVisits=1042450, meanQ=17.761727, numObservations: 4
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.614492 0.800167 0.381504 0.754394 0.633632 0.80534 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 473
Initial state: 0 0.93589 0.863485 0.623293 0.887259 0.679821 0.89459 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1049330 episodes
GETTING ACTION FROM:
action 3, numVisits=1049326, meanQ=17.818603, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.93589 0.863485 0.623293 0.887259 0.679821 0.89459 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 474
Initial state: 0 0.953604 0.429745 0.598588 0.802647 0.515883 0.885037 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1043601 episodes
GETTING ACTION FROM:
action 2, numVisits=1043591, meanQ=17.883559, numObservations: 5
action 1, numVisits=7, meanQ=10.141429, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.953604 0.429745 0.598588 0.802647 0.515883 0.885037 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 475
Initial state: 0 0.539355 0.899927 0.561487 0.82721 0.452929 0.266906 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1058579 episodes
GETTING ACTION FROM:
action 2, numVisits=1058575, meanQ=17.724631, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.539355 0.899927 0.561487 0.82721 0.452929 0.266906 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 476
Initial state: 0 0.789943 0.696845 0.61095 0.855994 0.614322 0.84165 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1056344 episodes
GETTING ACTION FROM:
action 2, numVisits=1056337, meanQ=17.767082, numObservations: 4
action 3, numVisits=4, meanQ=9.502525, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.789943 0.696845 0.61095 0.855994 0.614322 0.84165 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 477
Initial state: 0 0.59309 0.859396 0.657738 0.242313 0.699063 0.81477 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1049157 episodes
GETTING ACTION FROM:
action 3, numVisits=1049151, meanQ=17.758357, numObservations: 4
action 1, numVisits=3, meanQ=12.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.59309 0.859396 0.657738 0.242313 0.699063 0.81477 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 478
Initial state: 0 0.573359 0.855311 0.538602 0.802834 0.11656 0.292248 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1036343 episodes
GETTING ACTION FROM:
action 3, numVisits=1036337, meanQ=17.755706, numObservations: 5
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.573359 0.855311 0.538602 0.802834 0.11656 0.292248 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=118852, meanQ=23.505851, numObservations: 3
action 2, numVisits=3, meanQ=14.996667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1331543 episodes
GETTING ACTION FROM:
action 1, numVisits=1450367, meanQ=19.057188, numObservations: 4
action 2, numVisits=31, meanQ=17.483548, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.573359 0.855311 0.538602 0.802834 0.11656 0.292248 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 479
Initial state: 0 0.869496 0.384763 0.637883 0.865802 0.601615 0.89484 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1034464 episodes
GETTING ACTION FROM:
action 1, numVisits=1034449, meanQ=17.730335, numObservations: 5
action 3, numVisits=12, meanQ=10.924175, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.869496 0.384763 0.637883 0.865802 0.601615 0.89484 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 480
Initial state: 0 0.661724 0.880133 0.594583 0.821884 0.268453 0.669476 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1018918 episodes
GETTING ACTION FROM:
action 3, numVisits=1018912, meanQ=17.593808, numObservations: 4
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action 2, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.661724 0.880133 0.594583 0.821884 0.268453 0.669476 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=116220, meanQ=23.516874, numObservations: 3
action 1, numVisits=33, meanQ=21.424245, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1351302 episodes
GETTING ACTION FROM:
action 2, numVisits=1466758, meanQ=18.957638, numObservations: 3
action 1, numVisits=797, meanQ=18.673401, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.661724 0.880133 0.594583 0.821884 0.268453 0.669476 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 481
Initial state: 0 0.420982 0.503452 0.658355 0.808968 0.578132 0.831653 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1053266 episodes
GETTING ACTION FROM:
action 1, numVisits=1053254, meanQ=17.767451, numObservations: 4
action 3, numVisits=9, meanQ=7.885567, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.420982 0.503452 0.658355 0.808968 0.578132 0.831653 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=120479, meanQ=23.503026, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1363149 episodes
GETTING ACTION FROM:
action 2, numVisits=1483628, meanQ=19.404000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.420982 0.503452 0.658355 0.808968 0.578132 0.831653 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 482
Initial state: 0 0.573069 0.867024 0.254129 0.672169 0.69774 0.857139 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1035539 episodes
GETTING ACTION FROM:
action 3, numVisits=1035535, meanQ=17.751248, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.573069 0.867024 0.254129 0.672169 0.69774 0.857139 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 483
Initial state: 0 0.613781 0.880673 0.285873 0.65652 0.583201 0.834814 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1044571 episodes
GETTING ACTION FROM:
action 2, numVisits=1044566, meanQ=17.833766, numObservations: 5
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.613781 0.880673 0.285873 0.65652 0.583201 0.834814 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=145809, meanQ=23.322951, numObservations: 4
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1332433 episodes
GETTING ACTION FROM:
action 3, numVisits=1478242, meanQ=18.983454, numObservations: 4
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.613781 0.880673 0.285873 0.65652 0.583201 0.834814 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 484
Initial state: 0 0.159216 0.89466 0.537478 0.830633 0.572918 0.886402 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1041089 episodes
GETTING ACTION FROM:
action 2, numVisits=1041030, meanQ=17.794255, numObservations: 5
action 3, numVisits=55, meanQ=10.528196, numObservations: 5
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.159216 0.89466 0.537478 0.830633 0.572918 0.886402 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 485
Initial state: 0 0.697033 0.847182 0.383152 0.934362 0.599426 0.882522 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1051762 episodes
GETTING ACTION FROM:
action 1, numVisits=1051754, meanQ=17.711294, numObservations: 4
action 3, numVisits=2, meanQ=10.495000, numObservations: 1
action 2, numVisits=4, meanQ=9.997525, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.697033 0.847182 0.383152 0.934362 0.599426 0.882522 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 486
Initial state: 0 0.557502 0.858763 0.617935 0.805575 0.970477 0.106951 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1048534 episodes
GETTING ACTION FROM:
action 1, numVisits=1048529, meanQ=17.748470, numObservations: 4
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.557502 0.858763 0.617935 0.805575 0.970477 0.106951 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 487
Initial state: 0 0.107065 0.292889 0.537598 0.89936 0.625234 0.851235 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1058579 episodes
GETTING ACTION FROM:
action 1, numVisits=1058562, meanQ=17.856788, numObservations: 4
action 2, numVisits=9, meanQ=13.676667, numObservations: 3
action 3, numVisits=6, meanQ=13.665000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 0 0.107065 0.292889 0.537598 0.89936 0.625234 0.851235 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=147898, meanQ=23.326608, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1358157 episodes
GETTING ACTION FROM:
action 3, numVisits=1506055, meanQ=19.230029, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.107065 0.292889 0.537598 0.89936 0.625234 0.851235 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 488
Initial state: 0 0.545833 0.738614 0.540287 0.892497 0.636606 0.886111 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1052564 episodes
GETTING ACTION FROM:
action 3, numVisits=1052557, meanQ=17.848814, numObservations: 4
action 1, numVisits=4, meanQ=9.997525, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.545833 0.738614 0.540287 0.892497 0.636606 0.886111 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 489
Initial state: 0 0.641599 0.832811 0.137138 0.181204 0.612378 0.804468 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1044897 episodes
GETTING ACTION FROM:
action 2, numVisits=1044893, meanQ=17.827479, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.641599 0.832811 0.137138 0.181204 0.612378 0.804468 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=146099, meanQ=23.321456, numObservations: 4
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1331964 episodes
GETTING ACTION FROM:
action 3, numVisits=1478063, meanQ=18.488886, numObservations: 4
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.641599 0.832811 0.137138 0.181204 0.612378 0.804468 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 490
Initial state: 0 0.571953 0.863398 0.195172 0.572698 0.676022 0.892933 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1037147 episodes
GETTING ACTION FROM:
action 3, numVisits=1037134, meanQ=17.869588, numObservations: 5
action 2, numVisits=10, meanQ=11.598000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.571953 0.863398 0.195172 0.572698 0.676022 0.892933 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=25209, meanQ=22.360619, numObservations: 3
action 1, numVisits=45, meanQ=16.613336, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1360192 episodes
GETTING ACTION FROM:
action 2, numVisits=1385401, meanQ=18.914923, numObservations: 3
action 1, numVisits=45, meanQ=16.613336, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.571953 0.863398 0.195172 0.572698 0.676022 0.892933 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 491
Initial state: 0 0.669604 0.861875 0.665682 0.801132 0.372239 0.187353 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1030859 episodes
GETTING ACTION FROM:
action 3, numVisits=1030855, meanQ=17.858868, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.669604 0.861875 0.665682 0.801132 0.372239 0.187353 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=143876, meanQ=23.315658, numObservations: 4
action 2, numVisits=5, meanQ=18.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1334162 episodes
GETTING ACTION FROM:
action 1, numVisits=1478036, meanQ=19.515055, numObservations: 4
action 2, numVisits=7, meanQ=15.141429, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.669604 0.861875 0.665682 0.801132 0.372239 0.187353 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 492
Initial state: 0 0.618309 0.814236 0.208689 0.521746 0.517281 0.809331 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 722512 episodes
GETTING ACTION FROM:
action 0, numVisits=722507, meanQ=15.593739, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 0
Next state: 0 0.618309 0.814236 0.208689 0.521746 0.517281 0.809331 w: 1
Observation: 0 0 0.874759 0 0.575483 0 0.726703 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=722498, meanQ=17.751979, numObservations: 4
action 1, numVisits=5, meanQ=13.196000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1140753 episodes
GETTING ACTION FROM:
action 3, numVisits=1863251, meanQ=17.473237, numObservations: 4
action 1, numVisits=5, meanQ=13.196000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.618309 0.814236 0.208689 0.521746 0.517281 0.809331 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 493
Initial state: 0 0.106211 0.239833 0.691951 0.852872 0.698594 0.849598 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1041806 episodes
GETTING ACTION FROM:
action 2, numVisits=1041801, meanQ=17.762666, numObservations: 5
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.106211 0.239833 0.691951 0.852872 0.698594 0.849598 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 494
Initial state: 0 0.690558 0.830481 0.00475326 0.385201 0.657723 0.892711 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1058663 episodes
GETTING ACTION FROM:
action 1, numVisits=1058657, meanQ=17.758707, numObservations: 4
action 3, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.690558 0.830481 0.00475326 0.385201 0.657723 0.892711 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 495
Initial state: 0 0.271219 0.160854 0.690901 0.802459 0.564094 0.828349 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1051170 episodes
GETTING ACTION FROM:
action 2, numVisits=1051161, meanQ=17.773773, numObservations: 4
action 1, numVisits=5, meanQ=11.598000, numObservations: 2
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.271219 0.160854 0.690901 0.802459 0.564094 0.828349 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 496
Initial state: 0 0.696812 0.874365 0.2101 0.562696 0.686883 0.82571 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1056540 episodes
GETTING ACTION FROM:
action 2, numVisits=1056535, meanQ=17.740738, numObservations: 4
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.696812 0.874365 0.2101 0.562696 0.686883 0.82571 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=121011, meanQ=23.511022, numObservations: 3
action 1, numVisits=7, meanQ=20.141429, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1337601 episodes
GETTING ACTION FROM:
action 3, numVisits=1458611, meanQ=18.921003, numObservations: 4
action 1, numVisits=8, meanQ=16.248750, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.696812 0.874365 0.2101 0.562696 0.686883 0.82571 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 497
Initial state: 0 0.560181 0.848965 0.565115 0.830478 0.000294823 0.320914 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1046760 episodes
GETTING ACTION FROM:
action 1, numVisits=1046756, meanQ=17.873667, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.560181 0.848965 0.565115 0.830478 0.000294823 0.320914 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 498
Initial state: 0 0.112744 0.62726 0.619897 0.81279 0.505044 0.8549 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1050461 episodes
GETTING ACTION FROM:
action 2, numVisits=1050438, meanQ=17.863274, numObservations: 4
action 3, numVisits=19, meanQ=15.184211, numObservations: 3
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.112744 0.62726 0.619897 0.81279 0.505044 0.8549 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 499
Initial state: 0 0.568142 0.888111 0.485244 0.0840083 0.620361 0.812066 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1051190 episodes
GETTING ACTION FROM:
action 1, numVisits=1051183, meanQ=17.859735, numObservations: 4
action 3, numVisits=4, meanQ=8.497500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.568142 0.888111 0.485244 0.0840083 0.620361 0.812066 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 500
Initial state: 0 0.689165 0.815626 0.631621 0.884302 0.794163 0.516258 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1046612 episodes
GETTING ACTION FROM:
action 2, numVisits=1046607, meanQ=17.801955, numObservations: 4
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.689165 0.815626 0.631621 0.884302 0.794163 0.516258 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
