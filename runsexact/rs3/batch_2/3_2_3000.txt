Run # 1
Initial state: 0 0.505919 0.835952 0.0334605 0.616047 0.59641 0.882991 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 629473 episodes
GETTING ACTION FROM:
action 3, numVisits=629468, meanQ=17.863579, numObservations: 4
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.505919 0.835952 0.0334605 0.616047 0.59641 0.882991 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 2
Initial state: 0 0.00320751 0.476599 0.55113 0.812951 0.635258 0.827835 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 673916 episodes
GETTING ACTION FROM:
action 1, numVisits=673912, meanQ=17.859001, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.00320751 0.476599 0.55113 0.812951 0.635258 0.827835 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=110669, meanQ=23.173229, numObservations: 5
action 2, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 841984 episodes
GETTING ACTION FROM:
action 3, numVisits=952653, meanQ=19.340113, numObservations: 5
action 2, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.00320751 0.476599 0.55113 0.812951 0.635258 0.827835 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 3
Initial state: 0 0.622613 0.869457 0.376904 0.0583131 0.590846 0.870921 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 676830 episodes
GETTING ACTION FROM:
action 3, numVisits=676823, meanQ=17.834933, numObservations: 3
action 1, numVisits=4, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.622613 0.869457 0.376904 0.0583131 0.590846 0.870921 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 4
Initial state: 0 0.817934 0.312225 0.672982 0.835561 0.503659 0.866661 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 668226 episodes
GETTING ACTION FROM:
action 3, numVisits=668220, meanQ=17.836618, numObservations: 4
action 1, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.817934 0.312225 0.672982 0.835561 0.503659 0.866661 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=49405, meanQ=18.641396, numObservations: 3
action 2, numVisits=15, meanQ=13.398667, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 790896 episodes
GETTING ACTION FROM:
action 3, numVisits=840301, meanQ=17.202170, numObservations: 4
action 2, numVisits=15, meanQ=13.398667, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.817934 0.312225 0.672982 0.835561 0.503659 0.866661 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 5
Initial state: 0 0.492292 0.350586 0.558703 0.840956 0.543135 0.809612 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 662285 episodes
GETTING ACTION FROM:
action 2, numVisits=662281, meanQ=17.742839, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.492292 0.350586 0.558703 0.840956 0.543135 0.809612 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 6
Initial state: 0 0.505864 0.805566 0.664608 0.802248 0.897498 0.195197 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666961 episodes
GETTING ACTION FROM:
action 2, numVisits=666939, meanQ=17.726302, numObservations: 4
action 3, numVisits=15, meanQ=13.798673, numObservations: 3
action 1, numVisits=5, meanQ=11.598000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.505864 0.805566 0.664608 0.802248 0.897498 0.195197 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 7
Initial state: 0 0.688053 0.887321 0.599153 0.853344 0.16324 0.298603 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 674854 episodes
GETTING ACTION FROM:
action 2, numVisits=674849, meanQ=17.895942, numObservations: 4
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.688053 0.887321 0.599153 0.853344 0.16324 0.298603 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 8
Initial state: 0 0.651543 0.865153 0.546193 0.868778 0.375435 0.729084 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 457921 episodes
GETTING ACTION FROM:
action 0, numVisits=457916, meanQ=15.566816, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.651543 0.865153 0.546193 0.868778 0.375435 0.729084 w: 1
Observation: 0 0 0.932079 0 0.958264 0 0.703712 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=457892, meanQ=17.724238, numObservations: 4
action 2, numVisits=16, meanQ=12.358763, numObservations: 3
action 3, numVisits=5, meanQ=11.598000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 727153 episodes
GETTING ACTION FROM:
action 1, numVisits=1185045, meanQ=17.705104, numObservations: 4
action 2, numVisits=16, meanQ=12.358763, numObservations: 3
action 3, numVisits=5, meanQ=11.598000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.651543 0.865153 0.546193 0.868778 0.375435 0.729084 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 9
Initial state: 0 0.528415 0.809398 0.55573 0.898803 0.82555 0.563646 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666234 episodes
GETTING ACTION FROM:
action 2, numVisits=666227, meanQ=17.751481, numObservations: 4
action 1, numVisits=4, meanQ=8.497500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.528415 0.809398 0.55573 0.898803 0.82555 0.563646 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 10
Initial state: 0 0.792368 0.492961 0.69752 0.825433 0.512725 0.81596 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 668339 episodes
GETTING ACTION FROM:
action 3, numVisits=668334, meanQ=17.752745, numObservations: 4
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.792368 0.492961 0.69752 0.825433 0.512725 0.81596 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 11
Initial state: 0 0.808009 0.884353 0.592279 0.868962 0.678141 0.865389 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 667081 episodes
GETTING ACTION FROM:
action 1, numVisits=667065, meanQ=17.750001, numObservations: 4
action 2, numVisits=13, meanQ=14.921546, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.808009 0.884353 0.592279 0.868962 0.678141 0.865389 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 12
Initial state: 0 0.608737 0.845303 0.537853 0.849767 0.786842 0.464102 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 665680 episodes
GETTING ACTION FROM:
action 1, numVisits=665676, meanQ=17.781168, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.608737 0.845303 0.537853 0.849767 0.786842 0.464102 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 13
Initial state: 0 0.249853 0.184108 0.676155 0.806873 0.570099 0.871687 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 658661 episodes
GETTING ACTION FROM:
action 3, numVisits=658656, meanQ=17.763321, numObservations: 5
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.249853 0.184108 0.676155 0.806873 0.570099 0.871687 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 14
Initial state: 0 0.742857 0.500729 0.527171 0.800771 0.564551 0.8403 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 663638 episodes
GETTING ACTION FROM:
action 1, numVisits=663628, meanQ=17.753604, numObservations: 5
action 2, numVisits=5, meanQ=4.598000, numObservations: 1
action 3, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 2 0.742857 0.500729 0.527171 0.800771 0.564551 0.8403 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 15
Initial state: 0 0.556219 0.866791 0.651721 0.873497 0.866999 0.21146 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 655377 episodes
GETTING ACTION FROM:
action 2, numVisits=655365, meanQ=17.743328, numObservations: 5
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action 3, numVisits=8, meanQ=9.998762, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.556219 0.866791 0.651721 0.873497 0.866999 0.21146 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 16
Initial state: 0 0.68767 0.884459 0.529917 0.84515 0.732038 0.462843 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 664860 episodes
GETTING ACTION FROM:
action 1, numVisits=664855, meanQ=18.137781, numObservations: 5
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.68767 0.884459 0.529917 0.84515 0.732038 0.462843 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 17
Initial state: 0 0.157184 0.0888241 0.521137 0.857146 0.521984 0.871223 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 671050 episodes
GETTING ACTION FROM:
action 1, numVisits=671046, meanQ=17.823053, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.157184 0.0888241 0.521137 0.857146 0.521984 0.871223 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=94018, meanQ=23.240687, numObservations: 4
action 2, numVisits=9, meanQ=17.997778, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 852993 episodes
GETTING ACTION FROM:
action 3, numVisits=946997, meanQ=19.620367, numObservations: 4
action 2, numVisits=23, meanQ=17.086087, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.157184 0.0888241 0.521137 0.857146 0.521984 0.871223 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 18
Initial state: 0 0.641832 0.848375 0.964172 0.487718 0.503968 0.895174 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 674776 episodes
GETTING ACTION FROM:
action 2, numVisits=674755, meanQ=17.746001, numObservations: 3
action 1, numVisits=18, meanQ=15.722233, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.641832 0.848375 0.964172 0.487718 0.503968 0.895174 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 19
Initial state: 0 0.576476 0.895545 0.759981 0.110598 0.616117 0.822806 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 667512 episodes
GETTING ACTION FROM:
action 3, numVisits=667499, meanQ=17.767305, numObservations: 4
action 1, numVisits=6, meanQ=13.665000, numObservations: 2
action 2, numVisits=5, meanQ=11.598000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.576476 0.895545 0.759981 0.110598 0.616117 0.822806 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 20
Initial state: 0 0.708486 0.695224 0.581672 0.827862 0.575322 0.885336 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 680233 episodes
GETTING ACTION FROM:
action 2, numVisits=680229, meanQ=17.761242, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.708486 0.695224 0.581672 0.827862 0.575322 0.885336 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 21
Initial state: 0 0.790779 0.108258 0.568466 0.833764 0.541401 0.891893 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 669432 episodes
GETTING ACTION FROM:
action 2, numVisits=669411, meanQ=17.797563, numObservations: 4
action 1, numVisits=11, meanQ=12.885464, numObservations: 2
action 3, numVisits=8, meanQ=12.872500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.790779 0.108258 0.568466 0.833764 0.541401 0.891893 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 22
Initial state: 0 0.671865 0.835204 0.035365 0.741538 0.577811 0.817367 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 661862 episodes
GETTING ACTION FROM:
action 1, numVisits=661858, meanQ=17.764208, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.671865 0.835204 0.035365 0.741538 0.577811 0.817367 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 23
Initial state: 0 0.0559206 0.922215 0.541461 0.826022 0.691226 0.823569 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 671737 episodes
GETTING ACTION FROM:
action 2, numVisits=671729, meanQ=17.837087, numObservations: 4
action 3, numVisits=4, meanQ=8.497500, numObservations: 2
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.0559206 0.922215 0.541461 0.826022 0.691226 0.823569 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 24
Initial state: 0 0.631789 0.823437 0.922678 0.331608 0.696082 0.882326 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 659086 episodes
GETTING ACTION FROM:
action 3, numVisits=659078, meanQ=17.764462, numObservations: 5
action 2, numVisits=5, meanQ=11.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.631789 0.823437 0.922678 0.331608 0.696082 0.882326 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 25
Initial state: 0 0.840229 0.481945 0.555302 0.810836 0.608071 0.800113 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 663037 episodes
GETTING ACTION FROM:
action 3, numVisits=663032, meanQ=17.882074, numObservations: 5
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.840229 0.481945 0.555302 0.810836 0.608071 0.800113 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 26
Initial state: 0 0.907896 0.440884 0.641195 0.881061 0.546481 0.867883 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 669431 episodes
GETTING ACTION FROM:
action 1, numVisits=669427, meanQ=17.802781, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.907896 0.440884 0.641195 0.881061 0.546481 0.867883 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 27
Initial state: 0 0.46495 0.945046 0.669965 0.846528 0.615302 0.833681 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 663600 episodes
GETTING ACTION FROM:
action 1, numVisits=663595, meanQ=17.839829, numObservations: 5
action 3, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.46495 0.945046 0.669965 0.846528 0.615302 0.833681 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=15835, meanQ=22.554344, numObservations: 5
action 2, numVisits=3, meanQ=3.330000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 843635 episodes
GETTING ACTION FROM:
action 3, numVisits=859470, meanQ=19.078540, numObservations: 5
action 2, numVisits=3, meanQ=3.330000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.46495 0.945046 0.669965 0.846528 0.615302 0.833681 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 28
Initial state: 0 0.567775 0.852044 0.368834 0.906112 0.662764 0.801269 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 665274 episodes
GETTING ACTION FROM:
action 1, numVisits=665263, meanQ=17.865050, numObservations: 4
action 3, numVisits=6, meanQ=7.183333, numObservations: 2
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.567775 0.852044 0.368834 0.906112 0.662764 0.801269 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 29
Initial state: 0 0.993427 0.707006 0.57415 0.831485 0.626792 0.856064 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 663240 episodes
GETTING ACTION FROM:
action 1, numVisits=663231, meanQ=17.821376, numObservations: 5
action 2, numVisits=6, meanQ=7.831667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.993427 0.707006 0.57415 0.831485 0.626792 0.856064 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 30
Initial state: 0 0.342421 0.206912 0.588446 0.85098 0.506359 0.893061 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 661775 episodes
GETTING ACTION FROM:
action 1, numVisits=661762, meanQ=17.736420, numObservations: 5
action 3, numVisits=10, meanQ=11.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.342421 0.206912 0.588446 0.85098 0.506359 0.893061 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=16239, meanQ=22.555024, numObservations: 5
action 3, numVisits=12, meanQ=19.167508, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 852438 episodes
GETTING ACTION FROM:
action 3, numVisits=334997, meanQ=19.136655, numObservations: 4
action 2, numVisits=533692, meanQ=19.127226, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.342421 0.206912 0.588446 0.85098 0.506359 0.893061 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 31
Initial state: 0 0.651096 0.80318 0.541834 0.898446 0.199415 0.817361 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 662807 episodes
GETTING ACTION FROM:
action 2, numVisits=662796, meanQ=17.758936, numObservations: 5
action 1, numVisits=8, meanQ=13.871250, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.651096 0.80318 0.541834 0.898446 0.199415 0.817361 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 32
Initial state: 0 0.896277 0.658935 0.650217 0.868062 0.576515 0.872309 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 674709 episodes
GETTING ACTION FROM:
action 2, numVisits=674699, meanQ=18.116974, numObservations: 4
action 3, numVisits=7, meanQ=10.998586, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.896277 0.658935 0.650217 0.868062 0.576515 0.872309 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 33
Initial state: 0 0.666092 0.878268 0.681171 0.833812 0.891434 0.536465 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 664911 episodes
GETTING ACTION FROM:
action 2, numVisits=664906, meanQ=17.815710, numObservations: 5
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.666092 0.878268 0.681171 0.833812 0.891434 0.536465 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 34
Initial state: 0 0.664244 0.837905 0.504934 0.840734 0.252483 0.708371 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 660838 episodes
GETTING ACTION FROM:
action 3, numVisits=660823, meanQ=17.759345, numObservations: 5
action 2, numVisits=12, meanQ=10.752517, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.664244 0.837905 0.504934 0.840734 0.252483 0.708371 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=33377, meanQ=22.259235, numObservations: 4
action 2, numVisits=4, meanQ=17.247500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 858992 episodes
GETTING ACTION FROM:
action 1, numVisits=892343, meanQ=19.130965, numObservations: 4
action 2, numVisits=30, meanQ=17.666670, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.664244 0.837905 0.504934 0.840734 0.252483 0.708371 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 35
Initial state: 0 0.545962 0.834555 0.580027 0.884935 0.276081 0.762244 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 679074 episodes
GETTING ACTION FROM:
action 2, numVisits=679070, meanQ=17.806739, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.545962 0.834555 0.580027 0.884935 0.276081 0.762244 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 36
Initial state: 0 0.126686 0.481964 0.593729 0.825208 0.695393 0.831957 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 671730 episodes
GETTING ACTION FROM:
action 3, numVisits=671723, meanQ=17.852975, numObservations: 4
action 1, numVisits=4, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.126686 0.481964 0.593729 0.825208 0.695393 0.831957 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 37
Initial state: 0 0.513356 0.812657 0.620244 0.821981 0.472951 0.902316 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 661288 episodes
GETTING ACTION FROM:
action 1, numVisits=661284, meanQ=17.756222, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.513356 0.812657 0.620244 0.821981 0.472951 0.902316 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 38
Initial state: 0 0.693346 0.393389 0.51593 0.801083 0.686832 0.849796 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 680488 episodes
GETTING ACTION FROM:
action 2, numVisits=680484, meanQ=17.845247, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.693346 0.393389 0.51593 0.801083 0.686832 0.849796 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 39
Initial state: 0 0.312712 0.97985 0.677286 0.849409 0.652349 0.824166 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 648828 episodes
GETTING ACTION FROM:
action 1, numVisits=648823, meanQ=17.622685, numObservations: 5
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.312712 0.97985 0.677286 0.849409 0.652349 0.824166 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=48193, meanQ=17.202689, numObservations: 5
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 845857 episodes
GETTING ACTION FROM:
action 3, numVisits=894050, meanQ=18.643424, numObservations: 5
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.312712 0.97985 0.677286 0.849409 0.652349 0.824166 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 40
Initial state: 0 0.512711 0.82142 0.377383 0.0337609 0.519275 0.831213 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 661690 episodes
GETTING ACTION FROM:
action 1, numVisits=661686, meanQ=17.752178, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.512711 0.82142 0.377383 0.0337609 0.519275 0.831213 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 41
Initial state: 0 0.620769 0.854392 0.671664 0.824485 0.389215 0.984253 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 668090 episodes
GETTING ACTION FROM:
action 2, numVisits=668038, meanQ=17.742109, numObservations: 4
action 1, numVisits=47, meanQ=10.822560, numObservations: 4
action 3, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.620769 0.854392 0.671664 0.824485 0.389215 0.984253 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 42
Initial state: 0 0.513053 0.859883 0.643604 0.808479 0.775729 0.230285 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 676218 episodes
GETTING ACTION FROM:
action 1, numVisits=676214, meanQ=17.829734, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.513053 0.859883 0.643604 0.808479 0.775729 0.230285 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 43
Initial state: 0 0.298589 0.501778 0.541144 0.834425 0.682174 0.899723 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 670606 episodes
GETTING ACTION FROM:
action 2, numVisits=670585, meanQ=17.902124, numObservations: 4
action 3, numVisits=18, meanQ=9.338900, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.298589 0.501778 0.541144 0.834425 0.682174 0.899723 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=42092, meanQ=18.527238, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 793559 episodes
GETTING ACTION FROM:
action 2, numVisits=835651, meanQ=17.432004, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.298589 0.501778 0.541144 0.834425 0.682174 0.899723 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=13336, meanQ=17.157377, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 792446 episodes
GETTING ACTION FROM:
action 2, numVisits=805782, meanQ=16.729787, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.298589 0.501778 0.541144 0.834425 0.682174 0.899723 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 44
Initial state: 0 0.577325 0.809855 0.522956 0.819471 0.115534 0.320925 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 462393 episodes
GETTING ACTION FROM:
action -1, numVisits=462389, meanQ=15.624282, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.577325 0.809855 0.522956 0.819471 0.115534 0.320925 w: 1
Observation: 0 0.614042 0 0.542041 0 0.0933084 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=462384, meanQ=17.826438, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 736680 episodes
GETTING ACTION FROM:
action 3, numVisits=1199064, meanQ=17.664419, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.577325 0.809855 0.522956 0.819471 0.115534 0.320925 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=170233, meanQ=23.230491, numObservations: 4
action 2, numVisits=3, meanQ=14.996667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 853858 episodes
GETTING ACTION FROM:
action 2, numVisits=199326, meanQ=19.225006, numObservations: 3
action 1, numVisits=824768, meanQ=19.161255, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.577325 0.809855 0.522956 0.819471 0.115534 0.320925 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 17.5624
Run # 45
Initial state: 0 0.875583 0.0208884 0.666174 0.861054 0.639179 0.834318 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 672728 episodes
GETTING ACTION FROM:
action 1, numVisits=672724, meanQ=17.889853, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.875583 0.0208884 0.666174 0.861054 0.639179 0.834318 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 46
Initial state: 0 0.543112 0.769343 0.54553 0.815037 0.585851 0.887411 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 658047 episodes
GETTING ACTION FROM:
action 3, numVisits=658036, meanQ=17.746818, numObservations: 5
action 2, numVisits=8, meanQ=11.873750, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.543112 0.769343 0.54553 0.815037 0.585851 0.887411 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 47
Initial state: 0 0.561035 0.853514 0.68611 0.826175 0.90689 0.664336 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666410 episodes
GETTING ACTION FROM:
action 2, numVisits=666406, meanQ=17.870039, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.561035 0.853514 0.68611 0.826175 0.90689 0.664336 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 48
Initial state: 0 0.54556 0.851466 0.741797 0.261473 0.687964 0.827583 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 678986 episodes
GETTING ACTION FROM:
action 2, numVisits=678982, meanQ=17.836910, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.54556 0.851466 0.741797 0.261473 0.687964 0.827583 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 49
Initial state: 0 0.953452 0.347362 0.558048 0.830577 0.533445 0.834384 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 669053 episodes
GETTING ACTION FROM:
action 3, numVisits=669036, meanQ=17.742542, numObservations: 3
action 2, numVisits=8, meanQ=12.872500, numObservations: 2
action 1, numVisits=7, meanQ=10.141429, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.953452 0.347362 0.558048 0.830577 0.533445 0.834384 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 50
Initial state: 0 0.685256 0.806195 0.519966 0.885547 0.34519 0.865241 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 670182 episodes
GETTING ACTION FROM:
action 1, numVisits=670178, meanQ=17.746031, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.685256 0.806195 0.519966 0.885547 0.34519 0.865241 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 51
Initial state: 0 0.571177 0.859395 0.564544 0.865307 0.00651264 0.347657 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 670730 episodes
GETTING ACTION FROM:
action 2, numVisits=670720, meanQ=17.860853, numObservations: 4
action 1, numVisits=3, meanQ=12.333333, numObservations: 1
action 3, numVisits=5, meanQ=10.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.571177 0.859395 0.564544 0.865307 0.00651264 0.347657 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 52
Initial state: 0 0.512091 0.870552 0.69668 0.838282 0.180886 0.564388 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666337 episodes
GETTING ACTION FROM:
action 2, numVisits=666333, meanQ=17.881225, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.512091 0.870552 0.69668 0.838282 0.180886 0.564388 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 53
Initial state: 0 0.977126 0.352241 0.544618 0.817194 0.509753 0.833264 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 678619 episodes
GETTING ACTION FROM:
action 1, numVisits=678604, meanQ=17.850181, numObservations: 3
action 2, numVisits=8, meanQ=9.247513, numObservations: 3
action 3, numVisits=5, meanQ=7.794000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 2 0.977126 0.352241 0.544618 0.817194 0.509753 0.833264 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 54
Initial state: 0 0.142556 0.412551 0.521721 0.873213 0.559056 0.838701 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 664495 episodes
GETTING ACTION FROM:
action 2, numVisits=664491, meanQ=17.764512, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.142556 0.412551 0.521721 0.873213 0.559056 0.838701 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 55
Initial state: 0 0.615184 0.833076 0.66509 0.890827 0.0562332 0.775522 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 665454 episodes
GETTING ACTION FROM:
action 3, numVisits=665448, meanQ=17.773095, numObservations: 4
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.615184 0.833076 0.66509 0.890827 0.0562332 0.775522 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=109171, meanQ=23.128898, numObservations: 4
action 1, numVisits=23, meanQ=20.304352, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 857006 episodes
GETTING ACTION FROM:
action 2, numVisits=966132, meanQ=19.032624, numObservations: 4
action 1, numVisits=68, meanQ=17.775590, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.615184 0.833076 0.66509 0.890827 0.0562332 0.775522 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 56
Initial state: 0 0.579635 0.840832 0.0155772 0.115759 0.505448 0.842548 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666544 episodes
GETTING ACTION FROM:
action 2, numVisits=666529, meanQ=17.778398, numObservations: 3
action 1, numVisits=11, meanQ=10.815464, numObservations: 3
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.579635 0.840832 0.0155772 0.115759 0.505448 0.842548 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=110141, meanQ=23.137586, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 846548 episodes
GETTING ACTION FROM:
action 1, numVisits=956689, meanQ=19.513849, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.579635 0.840832 0.0155772 0.115759 0.505448 0.842548 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 57
Initial state: 0 0.52109 0.876306 0.511389 0.833112 0.387712 0.368359 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 671431 episodes
GETTING ACTION FROM:
action 3, numVisits=671426, meanQ=17.892496, numObservations: 4
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.52109 0.876306 0.511389 0.833112 0.387712 0.368359 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=110568, meanQ=23.165970, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 865155 episodes
GETTING ACTION FROM:
action 2, numVisits=975723, meanQ=19.224583, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.52109 0.876306 0.511389 0.833112 0.387712 0.368359 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 58
Initial state: 0 0.522529 0.813477 0.575748 0.837538 0.340118 0.396094 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 675308 episodes
GETTING ACTION FROM:
action 1, numVisits=675303, meanQ=17.721622, numObservations: 3
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.522529 0.813477 0.575748 0.837538 0.340118 0.396094 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 59
Initial state: 0 0.696687 0.867627 0.214788 0.287482 0.693336 0.897617 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 679153 episodes
GETTING ACTION FROM:
action 1, numVisits=679146, meanQ=17.837547, numObservations: 3
action 2, numVisits=4, meanQ=9.502525, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.696687 0.867627 0.214788 0.287482 0.693336 0.897617 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 60
Initial state: 0 0.0582794 0.493003 0.586194 0.890511 0.695025 0.873286 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 668557 episodes
GETTING ACTION FROM:
action 1, numVisits=668552, meanQ=17.825947, numObservations: 4
action 3, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.0582794 0.493003 0.586194 0.890511 0.695025 0.873286 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=110265, meanQ=23.122376, numObservations: 4
action 2, numVisits=6, meanQ=19.498333, numObservations: 1
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 847785 episodes
GETTING ACTION FROM:
action 3, numVisits=958049, meanQ=19.684419, numObservations: 4
action 2, numVisits=7, meanQ=16.282857, numObservations: 2
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.0582794 0.493003 0.586194 0.890511 0.695025 0.873286 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=26056, meanQ=22.383454, numObservations: 4
action 2, numVisits=3, meanQ=12.333333, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 863931 episodes
GETTING ACTION FROM:
action 3, numVisits=889987, meanQ=19.077411, numObservations: 4
action 2, numVisits=3, meanQ=12.333333, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.0582794 0.493003 0.586194 0.890511 0.695025 0.873286 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 61
Initial state: 0 0.694163 0.888623 0.655514 0.885631 0.934298 0.024887 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 664405 episodes
GETTING ACTION FROM:
action 2, numVisits=664380, meanQ=17.776823, numObservations: 4
action 3, numVisits=21, meanQ=14.046200, numObservations: 4
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.694163 0.888623 0.655514 0.885631 0.934298 0.024887 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 62
Initial state: 0 0.678342 0.841789 0.596072 0.889106 0.788505 0.345028 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 664953 episodes
GETTING ACTION FROM:
action 2, numVisits=664948, meanQ=17.820800, numObservations: 5
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.678342 0.841789 0.596072 0.889106 0.788505 0.345028 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 63
Initial state: 0 0.0707984 0.19648 0.554551 0.888205 0.610229 0.816943 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 464795 episodes
GETTING ACTION FROM:
action -1, numVisits=464791, meanQ=15.855913, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: -1
Next state: 0 0.0707984 0.19648 0.554551 0.888205 0.610229 0.816943 w: 1
Observation: 0 0.100469 0 0.62601 0 0.549839 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=464785, meanQ=18.067924, numObservations: 4
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 742300 episodes
GETTING ACTION FROM:
action 1, numVisits=1207085, meanQ=18.498616, numObservations: 4
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.0707984 0.19648 0.554551 0.888205 0.610229 0.816943 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=163133, meanQ=23.274849, numObservations: 5
action 3, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 850132 episodes
GETTING ACTION FROM:
action 2, numVisits=1013265, meanQ=19.316943, numObservations: 5
action 3, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.0707984 0.19648 0.554551 0.888205 0.610229 0.816943 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 17.5624
Run # 64
Initial state: 0 0.577113 0.830542 0.825736 0.720168 0.62843 0.861566 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 667170 episodes
GETTING ACTION FROM:
action 2, numVisits=667164, meanQ=17.902972, numObservations: 5
action 1, numVisits=3, meanQ=12.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.577113 0.830542 0.825736 0.720168 0.62843 0.861566 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 65
Initial state: 0 0.0798516 0.314726 0.639834 0.824439 0.537996 0.836111 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 650360 episodes
GETTING ACTION FROM:
action 3, numVisits=650356, meanQ=17.604156, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.0798516 0.314726 0.639834 0.824439 0.537996 0.836111 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 66
Initial state: 0 0.509851 0.877977 0.50327 0.824928 0.374457 0.608625 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 660472 episodes
GETTING ACTION FROM:
action 3, numVisits=660468, meanQ=17.764850, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.509851 0.877977 0.50327 0.824928 0.374457 0.608625 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=75471, meanQ=23.518792, numObservations: 3
action 2, numVisits=8, meanQ=16.717500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 867381 episodes
GETTING ACTION FROM:
action 1, numVisits=942852, meanQ=19.514264, numObservations: 3
action 2, numVisits=8, meanQ=16.717500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.509851 0.877977 0.50327 0.824928 0.374457 0.608625 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 67
Initial state: 0 0.596486 0.866066 0.11899 0.236901 0.534591 0.807475 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 668876 episodes
GETTING ACTION FROM:
action 3, numVisits=668868, meanQ=18.104455, numObservations: 4
action 1, numVisits=3, meanQ=12.333333, numObservations: 1
action 2, numVisits=3, meanQ=12.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.596486 0.866066 0.11899 0.236901 0.534591 0.807475 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 68
Initial state: 0 0.545427 0.816552 0.345539 0.973087 0.555426 0.894557 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 661245 episodes
GETTING ACTION FROM:
action 1, numVisits=661241, meanQ=17.808212, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.545427 0.816552 0.345539 0.973087 0.555426 0.894557 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 69
Initial state: 0 0.639546 0.896504 0.759784 0.136428 0.579799 0.82934 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666595 episodes
GETTING ACTION FROM:
action 2, numVisits=666591, meanQ=17.836430, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.639546 0.896504 0.759784 0.136428 0.579799 0.82934 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 70
Initial state: 0 0.563352 0.85747 0.646682 0.273543 0.512162 0.810497 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 667304 episodes
GETTING ACTION FROM:
action 1, numVisits=667299, meanQ=17.752988, numObservations: 4
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.563352 0.85747 0.646682 0.273543 0.512162 0.810497 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=49612, meanQ=17.319634, numObservations: 4
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 859438 episodes
GETTING ACTION FROM:
action 2, numVisits=909050, meanQ=18.997451, numObservations: 4
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.563352 0.85747 0.646682 0.273543 0.512162 0.810497 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=23882, meanQ=23.232723, numObservations: 4
action 1, numVisits=9, meanQ=20.998889, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 881649 episodes
GETTING ACTION FROM:
action 3, numVisits=905493, meanQ=18.990219, numObservations: 4
action 1, numVisits=47, meanQ=17.467872, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.563352 0.85747 0.646682 0.273543 0.512162 0.810497 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 71
Initial state: 0 0.958136 0.860026 0.648991 0.898569 0.56261 0.802282 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 671624 episodes
GETTING ACTION FROM:
action 2, numVisits=671619, meanQ=17.767802, numObservations: 4
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.958136 0.860026 0.648991 0.898569 0.56261 0.802282 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 72
Initial state: 0 0.217674 0.469665 0.675341 0.84462 0.603646 0.842962 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 679130 episodes
GETTING ACTION FROM:
action 1, numVisits=679117, meanQ=17.873843, numObservations: 3
action 2, numVisits=3, meanQ=12.333333, numObservations: 2
action 3, numVisits=8, meanQ=11.873750, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 0 0.217674 0.469665 0.675341 0.84462 0.603646 0.842962 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=111236, meanQ=23.160384, numObservations: 4
action 3, numVisits=4, meanQ=17.247500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 864976 episodes
GETTING ACTION FROM:
action 2, numVisits=976203, meanQ=19.489119, numObservations: 4
action 3, numVisits=13, meanQ=16.537692, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.217674 0.469665 0.675341 0.84462 0.603646 0.842962 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 73
Initial state: 0 0.412137 0.0336162 0.559011 0.851071 0.636978 0.856992 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 649515 episodes
GETTING ACTION FROM:
action 2, numVisits=649506, meanQ=17.960963, numObservations: 5
action 3, numVisits=6, meanQ=7.831667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.412137 0.0336162 0.559011 0.851071 0.636978 0.856992 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 74
Initial state: 0 0.652909 0.84622 0.628114 0.858236 0.259406 0.954245 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 680895 episodes
GETTING ACTION FROM:
action 2, numVisits=680891, meanQ=17.839076, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.652909 0.84622 0.628114 0.858236 0.259406 0.954245 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 75
Initial state: 0 0.36308 0.684703 0.501228 0.828418 0.626282 0.841609 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 454820 episodes
GETTING ACTION FROM:
action -1, numVisits=454816, meanQ=15.720832, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.36308 0.684703 0.501228 0.828418 0.626282 0.841609 w: 1
Observation: 0 0.423362 0 0.512833 0 0.674812 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=454806, meanQ=17.935957, numObservations: 4
action 3, numVisits=6, meanQ=7.831667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 708509 episodes
GETTING ACTION FROM:
action 1, numVisits=1163315, meanQ=17.881301, numObservations: 4
action 3, numVisits=6, meanQ=7.831667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.36308 0.684703 0.501228 0.828418 0.626282 0.841609 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=194339, meanQ=23.162257, numObservations: 4
action 3, numVisits=4, meanQ=17.247500, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 861015 episodes
GETTING ACTION FROM:
action 2, numVisits=1055317, meanQ=19.412393, numObservations: 4
action 3, numVisits=41, meanQ=18.219268, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.36308 0.684703 0.501228 0.828418 0.626282 0.841609 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 17.5624
Run # 76
Initial state: 0 0.676842 0.884719 0.0450185 0.0116333 0.652905 0.875864 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 673040 episodes
GETTING ACTION FROM:
action 1, numVisits=673025, meanQ=17.738622, numObservations: 3
action 3, numVisits=12, meanQ=14.165008, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.676842 0.884719 0.0450185 0.0116333 0.652905 0.875864 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 77
Initial state: 0 0.588559 0.833824 0.0650113 0.215797 0.693638 0.807598 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 670755 episodes
GETTING ACTION FROM:
action 2, numVisits=670746, meanQ=17.836400, numObservations: 4
action 3, numVisits=5, meanQ=11.598000, numObservations: 3
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.588559 0.833824 0.0650113 0.215797 0.693638 0.807598 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=77255, meanQ=23.512897, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 849035 episodes
GETTING ACTION FROM:
action 3, numVisits=926290, meanQ=19.173376, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.588559 0.833824 0.0650113 0.215797 0.693638 0.807598 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 78
Initial state: 0 0.957703 0.891301 0.644881 0.898143 0.602558 0.863562 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666659 episodes
GETTING ACTION FROM:
action 3, numVisits=666647, meanQ=17.757293, numObservations: 4
action 2, numVisits=9, meanQ=10.454456, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.957703 0.891301 0.644881 0.898143 0.602558 0.863562 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=49678, meanQ=17.498127, numObservations: 4
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action 2, numVisits=4, meanQ=8.497500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 851764 episodes
GETTING ACTION FROM:
action 1, numVisits=901442, meanQ=18.927263, numObservations: 4
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action 2, numVisits=4, meanQ=8.497500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.957703 0.891301 0.644881 0.898143 0.602558 0.863562 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 79
Initial state: 0 0.563304 0.882893 0.558651 0.830867 0.807761 0.766968 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 668793 episodes
GETTING ACTION FROM:
action 2, numVisits=668783, meanQ=17.731313, numObservations: 4
action 3, numVisits=7, meanQ=10.141429, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.563304 0.882893 0.558651 0.830867 0.807761 0.766968 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 80
Initial state: 0 0.140523 0.690586 0.568519 0.865432 0.54974 0.874886 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 660967 episodes
GETTING ACTION FROM:
action 2, numVisits=660959, meanQ=17.742558, numObservations: 5
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=2, meanQ=-4.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.140523 0.690586 0.568519 0.865432 0.54974 0.874886 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 81
Initial state: 0 0.707758 0.511093 0.603191 0.841484 0.59298 0.866789 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 659531 episodes
GETTING ACTION FROM:
action 3, numVisits=659527, meanQ=17.743245, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.707758 0.511093 0.603191 0.841484 0.59298 0.866789 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 82
Initial state: 0 0.594072 0.412659 0.653267 0.803845 0.617625 0.85439 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 674817 episodes
GETTING ACTION FROM:
action 2, numVisits=674807, meanQ=17.781481, numObservations: 3
action 3, numVisits=6, meanQ=14.335017, numObservations: 3
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.594072 0.412659 0.653267 0.803845 0.617625 0.85439 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 83
Initial state: 0 0.656849 0.863702 0.619703 0.870023 0.286192 0.529397 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 668238 episodes
GETTING ACTION FROM:
action 3, numVisits=668232, meanQ=17.833640, numObservations: 4
action 1, numVisits=3, meanQ=12.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.656849 0.863702 0.619703 0.870023 0.286192 0.529397 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=110120, meanQ=23.139854, numObservations: 5
action 2, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 850706 episodes
GETTING ACTION FROM:
action 1, numVisits=960826, meanQ=19.165841, numObservations: 5
action 2, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.656849 0.863702 0.619703 0.870023 0.286192 0.529397 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 84
Initial state: 0 0.644325 0.853386 0.0663472 0.93798 0.604564 0.885633 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 655233 episodes
GETTING ACTION FROM:
action 2, numVisits=655222, meanQ=17.708551, numObservations: 4
action 1, numVisits=6, meanQ=7.831667, numObservations: 2
action 3, numVisits=3, meanQ=4.670033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.644325 0.853386 0.0663472 0.93798 0.604564 0.885633 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 85
Initial state: 0 0.189969 0.666338 0.655256 0.886952 0.610684 0.876648 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 455218 episodes
GETTING ACTION FROM:
action -1, numVisits=455214, meanQ=15.349943, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.189969 0.666338 0.655256 0.886952 0.610684 0.876648 w: 1
Observation: 0 0.190153 0 0.701014 0 0.537813 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=455209, meanQ=17.549664, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 721102 episodes
GETTING ACTION FROM:
action 1, numVisits=1176311, meanQ=17.583294, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.189969 0.666338 0.655256 0.886952 0.610684 0.876648 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=134639, meanQ=23.527637, numObservations: 3
action 2, numVisits=261, meanQ=23.110702, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 838384 episodes
GETTING ACTION FROM:
action 3, numVisits=968971, meanQ=18.803662, numObservations: 5
action 2, numVisits=4313, meanQ=18.695882, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.189969 0.666338 0.655256 0.886952 0.610684 0.876648 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 17.5624
Run # 86
Initial state: 0 0.50861 0.847736 0.595275 0.82466 0.864033 0.979135 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 675110 episodes
GETTING ACTION FROM:
action 1, numVisits=675106, meanQ=17.849560, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.50861 0.847736 0.595275 0.82466 0.864033 0.979135 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 87
Initial state: 0 0.681354 0.86699 0.623031 0.866085 0.946958 0.339478 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 675882 episodes
GETTING ACTION FROM:
action 2, numVisits=675876, meanQ=17.768083, numObservations: 3
action 1, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.681354 0.86699 0.623031 0.866085 0.946958 0.339478 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 88
Initial state: 0 0.395943 0.493382 0.545137 0.814483 0.548852 0.855262 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 670052 episodes
GETTING ACTION FROM:
action 3, numVisits=670029, meanQ=17.879766, numObservations: 4
action 2, numVisits=19, meanQ=11.934221, numObservations: 4
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.395943 0.493382 0.545137 0.814483 0.548852 0.855262 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=49656, meanQ=18.696473, numObservations: 3
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action 2, numVisits=3, meanQ=3.330000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 802067 episodes
GETTING ACTION FROM:
action 3, numVisits=851723, meanQ=17.747775, numObservations: 3
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action 2, numVisits=3, meanQ=3.330000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.395943 0.493382 0.545137 0.814483 0.548852 0.855262 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 89
Initial state: 0 0.821062 0.964905 0.637329 0.815078 0.642084 0.816648 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 637487 episodes
GETTING ACTION FROM:
action 2, numVisits=637483, meanQ=17.552626, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.821062 0.964905 0.637329 0.815078 0.642084 0.816648 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=47611, meanQ=18.619104, numObservations: 4
action 1, numVisits=17, meanQ=11.940024, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 798402 episodes
GETTING ACTION FROM:
action 2, numVisits=846013, meanQ=18.026713, numObservations: 4
action 1, numVisits=17, meanQ=11.940024, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.821062 0.964905 0.637329 0.815078 0.642084 0.816648 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 90
Initial state: 0 0.284195 0.0879509 0.608248 0.822205 0.500578 0.877767 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 659912 episodes
GETTING ACTION FROM:
action 3, numVisits=659898, meanQ=17.846674, numObservations: 5
action 1, numVisits=10, meanQ=11.598000, numObservations: 3
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.284195 0.0879509 0.608248 0.822205 0.500578 0.877767 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 91
Initial state: 0 0.902154 0.462674 0.56657 0.888744 0.669669 0.827149 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 676982 episodes
GETTING ACTION FROM:
action 1, numVisits=676978, meanQ=17.870776, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.902154 0.462674 0.56657 0.888744 0.669669 0.827149 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 92
Initial state: 0 0.532896 0.879898 0.636106 0.884146 0.700135 0.63361 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 662732 episodes
GETTING ACTION FROM:
action 2, numVisits=662723, meanQ=18.112915, numObservations: 4
action 1, numVisits=6, meanQ=13.665000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.532896 0.879898 0.636106 0.884146 0.700135 0.63361 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=44048, meanQ=22.086802, numObservations: 3
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 785582 episodes
GETTING ACTION FROM:
action 2, numVisits=829630, meanQ=17.427135, numObservations: 4
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.532896 0.879898 0.636106 0.884146 0.700135 0.63361 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 93
Initial state: 0 0.291017 0.646394 0.516963 0.809854 0.563373 0.86928 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 673513 episodes
GETTING ACTION FROM:
action 1, numVisits=673504, meanQ=18.096611, numObservations: 4
action 3, numVisits=6, meanQ=9.163333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.291017 0.646394 0.516963 0.809854 0.563373 0.86928 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=39097, meanQ=22.485261, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 865597 episodes
GETTING ACTION FROM:
action 2, numVisits=904694, meanQ=19.034341, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.291017 0.646394 0.516963 0.809854 0.563373 0.86928 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=19997, meanQ=20.979218, numObservations: 3
action 2, numVisits=3, meanQ=14.996667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 887473 episodes
GETTING ACTION FROM:
action 3, numVisits=907399, meanQ=19.198287, numObservations: 3
action 2, numVisits=74, meanQ=18.121623, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.291017 0.646394 0.516963 0.809854 0.563373 0.86928 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 94
Initial state: 0 0.518394 0.379854 0.671991 0.81049 0.675499 0.826261 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 673960 episodes
GETTING ACTION FROM:
action 2, numVisits=673956, meanQ=17.864774, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.518394 0.379854 0.671991 0.81049 0.675499 0.826261 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 95
Initial state: 0 0.132911 0.832342 0.672083 0.847174 0.559479 0.882788 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666741 episodes
GETTING ACTION FROM:
action 1, numVisits=666736, meanQ=17.819748, numObservations: 5
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.132911 0.832342 0.672083 0.847174 0.559479 0.882788 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=16038, meanQ=22.536582, numObservations: 5
action 2, numVisits=3, meanQ=14.996667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 842795 episodes
GETTING ACTION FROM:
action 3, numVisits=858825, meanQ=18.879702, numObservations: 5
action 2, numVisits=11, meanQ=15.180909, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.132911 0.832342 0.672083 0.847174 0.559479 0.882788 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 96
Initial state: 0 0.569138 0.891575 0.654277 0.842647 0.392386 0.98033 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 663941 episodes
GETTING ACTION FROM:
action 3, numVisits=663931, meanQ=17.840699, numObservations: 4
action 2, numVisits=7, meanQ=10.141429, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.569138 0.891575 0.654277 0.842647 0.392386 0.98033 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=6159, meanQ=16.745149, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 839633 episodes
GETTING ACTION FROM:
action 1, numVisits=711947, meanQ=18.220095, numObservations: 4
action 0, numVisits=133846, meanQ=3.842705, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.569138 0.891575 0.654277 0.842647 0.392386 0.98033 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 97
Initial state: 0 0.541998 0.868184 0.0746977 0.00168922 0.684648 0.803914 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 665319 episodes
GETTING ACTION FROM:
action 2, numVisits=665313, meanQ=18.087675, numObservations: 4
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.541998 0.868184 0.0746977 0.00168922 0.684648 0.803914 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=75849, meanQ=23.507923, numObservations: 3
action 1, numVisits=18, meanQ=20.888339, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 855381 episodes
GETTING ACTION FROM:
action 3, numVisits=931044, meanQ=19.330611, numObservations: 4
action 1, numVisits=204, meanQ=18.784120, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.541998 0.868184 0.0746977 0.00168922 0.684648 0.803914 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 98
Initial state: 0 0.809871 0.47215 0.57258 0.830592 0.666513 0.862037 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 662423 episodes
GETTING ACTION FROM:
action 3, numVisits=662408, meanQ=17.860131, numObservations: 4
action 2, numVisits=11, meanQ=10.454564, numObservations: 3
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.809871 0.47215 0.57258 0.830592 0.666513 0.862037 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 99
Initial state: 0 0.565765 0.890391 0.695512 0.871135 0.263731 0.602847 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 662018 episodes
GETTING ACTION FROM:
action 3, numVisits=662014, meanQ=17.825988, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.565765 0.890391 0.695512 0.871135 0.263731 0.602847 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=75441, meanQ=23.509723, numObservations: 3
action 2, numVisits=14, meanQ=19.999293, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 855768 episodes
GETTING ACTION FROM:
action 1, numVisits=931195, meanQ=18.892921, numObservations: 4
action 2, numVisits=28, meanQ=17.213936, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.565765 0.890391 0.695512 0.871135 0.263731 0.602847 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 100
Initial state: 0 0.0213161 0.866744 0.641532 0.843408 0.65705 0.86615 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666357 episodes
GETTING ACTION FROM:
action 3, numVisits=666353, meanQ=17.779994, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.0213161 0.866744 0.641532 0.843408 0.65705 0.86615 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 101
Initial state: 0 0.616893 0.842553 0.514408 0.81847 0.101671 0.563144 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 662939 episodes
GETTING ACTION FROM:
action 3, numVisits=662935, meanQ=17.828798, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.616893 0.842553 0.514408 0.81847 0.101671 0.563144 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=92655, meanQ=23.314800, numObservations: 3
action 1, numVisits=8, meanQ=17.247500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 866251 episodes
GETTING ACTION FROM:
action 2, numVisits=958902, meanQ=19.299894, numObservations: 3
action 1, numVisits=12, meanQ=16.581667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.616893 0.842553 0.514408 0.81847 0.101671 0.563144 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 102
Initial state: 0 0.716797 0.591511 0.517574 0.888672 0.507191 0.838777 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 665751 episodes
GETTING ACTION FROM:
action 1, numVisits=665747, meanQ=17.848114, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.716797 0.591511 0.517574 0.888672 0.507191 0.838777 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 103
Initial state: 0 0.589427 0.87418 0.637137 0.895795 0.534736 0.605341 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 671228 episodes
GETTING ACTION FROM:
action 1, numVisits=671218, meanQ=17.773719, numObservations: 3
action 3, numVisits=2, meanQ=10.495000, numObservations: 1
action 2, numVisits=6, meanQ=8.501683, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.589427 0.87418 0.637137 0.895795 0.534736 0.605341 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 104
Initial state: 0 0.68461 0.853421 0.5741 0.819542 0.980033 0.132229 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 462188 episodes
GETTING ACTION FROM:
action -1, numVisits=462184, meanQ=15.694203, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.68461 0.853421 0.5741 0.819542 0.980033 0.132229 w: 1
Observation: 0 0.700275 0 0.594041 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=462174, meanQ=17.868482, numObservations: 4
action 1, numVisits=6, meanQ=9.163333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 735798 episodes
GETTING ACTION FROM:
action 2, numVisits=1197972, meanQ=17.972834, numObservations: 4
action 1, numVisits=6, meanQ=9.163333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.68461 0.853421 0.5741 0.819542 0.980033 0.132229 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 105
Initial state: 0 0.560995 0.875158 0.886158 0.49128 0.56469 0.843016 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 669976 episodes
GETTING ACTION FROM:
action 1, numVisits=669972, meanQ=17.798891, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.560995 0.875158 0.886158 0.49128 0.56469 0.843016 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 106
Initial state: 0 0.512186 0.478001 0.533258 0.896187 0.615032 0.855068 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 672449 episodes
GETTING ACTION FROM:
action 2, numVisits=672444, meanQ=17.768897, numObservations: 3
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.512186 0.478001 0.533258 0.896187 0.615032 0.855068 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 107
Initial state: 0 0.679591 0.858747 0.682984 0.883972 0.292585 0.0237697 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 674290 episodes
GETTING ACTION FROM:
action 3, numVisits=674271, meanQ=17.867352, numObservations: 3
action 1, numVisits=14, meanQ=10.999293, numObservations: 3
action 2, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.679591 0.858747 0.682984 0.883972 0.292585 0.0237697 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=110892, meanQ=23.171883, numObservations: 5
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 855436 episodes
GETTING ACTION FROM:
action 2, numVisits=966328, meanQ=19.305236, numObservations: 5
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.679591 0.858747 0.682984 0.883972 0.292585 0.0237697 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 108
Initial state: 0 0.534537 0.845267 0.761991 0.744044 0.657795 0.845056 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 674128 episodes
GETTING ACTION FROM:
action 2, numVisits=674124, meanQ=17.860726, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.534537 0.845267 0.761991 0.744044 0.657795 0.845056 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 109
Initial state: 0 0.512944 0.889655 0.659659 0.863057 0.103081 0.156017 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 671460 episodes
GETTING ACTION FROM:
action 2, numVisits=671431, meanQ=17.865038, numObservations: 4
action 3, numVisits=25, meanQ=11.530400, numObservations: 3
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.512944 0.889655 0.659659 0.863057 0.103081 0.156017 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 110
Initial state: 0 0.645204 0.873179 0.677427 0.305152 0.522919 0.827302 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 632086 episodes
GETTING ACTION FROM:
action 1, numVisits=632082, meanQ=17.787800, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.645204 0.873179 0.677427 0.305152 0.522919 0.827302 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 111
Initial state: 0 0.510192 0.880528 0.930696 0.335351 0.542295 0.818742 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 669318 episodes
GETTING ACTION FROM:
action 3, numVisits=669309, meanQ=17.872512, numObservations: 4
action 1, numVisits=4, meanQ=2.750025, numObservations: 2
action 2, numVisits=3, meanQ=2.033333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.510192 0.880528 0.930696 0.335351 0.542295 0.818742 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 112
Initial state: 0 0.280041 0.511674 0.609527 0.895191 0.61875 0.853744 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666058 episodes
GETTING ACTION FROM:
action 3, numVisits=666054, meanQ=17.794252, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.280041 0.511674 0.609527 0.895191 0.61875 0.853744 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 113
Initial state: 0 0.741556 0.979234 0.675551 0.801041 0.684217 0.854069 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 667577 episodes
GETTING ACTION FROM:
action 2, numVisits=667572, meanQ=17.843620, numObservations: 5
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.741556 0.979234 0.675551 0.801041 0.684217 0.854069 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 114
Initial state: 0 0.296732 0.444389 0.684122 0.832724 0.545512 0.854576 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 670126 episodes
GETTING ACTION FROM:
action 1, numVisits=670122, meanQ=17.761620, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.296732 0.444389 0.684122 0.832724 0.545512 0.854576 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=109263, meanQ=23.177721, numObservations: 5
action 2, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 845085 episodes
GETTING ACTION FROM:
action 3, numVisits=954348, meanQ=19.316461, numObservations: 5
action 2, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.296732 0.444389 0.684122 0.832724 0.545512 0.854576 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 115
Initial state: 0 0.620877 0.827006 0.613768 0.814424 0.39669 0.399198 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 668360 episodes
GETTING ACTION FROM:
action 1, numVisits=668356, meanQ=17.734193, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.620877 0.827006 0.613768 0.814424 0.39669 0.399198 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 116
Initial state: 0 0.689707 0.836995 0.608628 0.817001 0.79871 0.35769 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 675255 episodes
GETTING ACTION FROM:
action 2, numVisits=675250, meanQ=17.866552, numObservations: 4
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.689707 0.836995 0.608628 0.817001 0.79871 0.35769 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 117
Initial state: 0 0.23857 0.840137 0.602627 0.898739 0.67295 0.849582 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 653077 episodes
GETTING ACTION FROM:
action 3, numVisits=653068, meanQ=17.829966, numObservations: 5
action 2, numVisits=6, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.23857 0.840137 0.602627 0.898739 0.67295 0.849582 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 118
Initial state: 0 0.606571 0.85792 0.704281 0.498707 0.514136 0.875818 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 668492 episodes
GETTING ACTION FROM:
action 1, numVisits=668359, meanQ=17.781104, numObservations: 4
action 2, numVisits=130, meanQ=16.049093, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.606571 0.85792 0.704281 0.498707 0.514136 0.875818 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 119
Initial state: 0 0.499054 0.371028 0.635258 0.867262 0.590647 0.860957 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 673097 episodes
GETTING ACTION FROM:
action 1, numVisits=673093, meanQ=17.836487, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.499054 0.371028 0.635258 0.867262 0.590647 0.860957 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=110347, meanQ=23.177023, numObservations: 4
action 3, numVisits=5, meanQ=17.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 859438 episodes
GETTING ACTION FROM:
action 2, numVisits=969783, meanQ=19.256482, numObservations: 4
action 3, numVisits=7, meanQ=14.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.499054 0.371028 0.635258 0.867262 0.590647 0.860957 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 120
Initial state: 0 0.586017 0.874833 0.528066 0.881502 0.532028 0.0482107 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 669993 episodes
GETTING ACTION FROM:
action 2, numVisits=669989, meanQ=17.764493, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.586017 0.874833 0.528066 0.881502 0.532028 0.0482107 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 121
Initial state: 0 0.537944 0.80109 0.477061 0.484425 0.581046 0.850567 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 667398 episodes
GETTING ACTION FROM:
action 3, numVisits=667391, meanQ=17.805682, numObservations: 4
action 1, numVisits=4, meanQ=8.497500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.537944 0.80109 0.477061 0.484425 0.581046 0.850567 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 122
Initial state: 0 0.689537 0.893893 0.696681 0.566608 0.629127 0.830035 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 660423 episodes
GETTING ACTION FROM:
action 3, numVisits=660402, meanQ=17.738273, numObservations: 5
action 1, numVisits=17, meanQ=12.441182, numObservations: 3
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.689537 0.893893 0.696681 0.566608 0.629127 0.830035 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 123
Initial state: 0 0.681001 0.886156 0.690575 0.850473 0.993303 0.679516 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 670694 episodes
GETTING ACTION FROM:
action 2, numVisits=670689, meanQ=17.799115, numObservations: 4
action 3, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.681001 0.886156 0.690575 0.850473 0.993303 0.679516 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 124
Initial state: 0 0.563378 0.806592 0.922916 0.202709 0.618838 0.866937 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 661647 episodes
GETTING ACTION FROM:
action 3, numVisits=661639, meanQ=17.799132, numObservations: 5
action 2, numVisits=5, meanQ=11.598000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.563378 0.806592 0.922916 0.202709 0.618838 0.866937 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 125
Initial state: 0 0.387681 0.122304 0.686471 0.892998 0.507368 0.895029 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 671316 episodes
GETTING ACTION FROM:
action 2, numVisits=671311, meanQ=17.762709, numObservations: 4
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.387681 0.122304 0.686471 0.892998 0.507368 0.895029 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=49204, meanQ=17.198107, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 858691 episodes
GETTING ACTION FROM:
action 3, numVisits=907895, meanQ=19.127810, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.387681 0.122304 0.686471 0.892998 0.507368 0.895029 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 126
Initial state: 0 0.682481 0.846074 0.386921 0.542218 0.648288 0.875144 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 672794 episodes
GETTING ACTION FROM:
action 3, numVisits=672790, meanQ=17.821325, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.682481 0.846074 0.386921 0.542218 0.648288 0.875144 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 127
Initial state: 0 0.0705811 0.459401 0.635345 0.846716 0.672755 0.858829 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 665679 episodes
GETTING ACTION FROM:
action 2, numVisits=665673, meanQ=17.782915, numObservations: 5
action 3, numVisits=3, meanQ=3.330000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.0705811 0.459401 0.635345 0.846716 0.672755 0.858829 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 128
Initial state: 0 0.665344 0.800211 0.565944 0.765725 0.604758 0.849893 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 672579 episodes
GETTING ACTION FROM:
action 2, numVisits=672561, meanQ=17.853627, numObservations: 4
action 3, numVisits=15, meanQ=6.666013, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.665344 0.800211 0.565944 0.765725 0.604758 0.849893 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=109939, meanQ=23.176345, numObservations: 5
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 844279 episodes
GETTING ACTION FROM:
action 3, numVisits=954218, meanQ=19.076688, numObservations: 5
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.665344 0.800211 0.565944 0.765725 0.604758 0.849893 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 129
Initial state: 0 0.678419 0.873844 0.500167 0.827863 0.403778 0.506435 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 670917 episodes
GETTING ACTION FROM:
action 2, numVisits=670912, meanQ=17.758077, numObservations: 4
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.678419 0.873844 0.500167 0.827863 0.403778 0.506435 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 130
Initial state: 0 0.458676 0.102537 0.676505 0.800269 0.548795 0.812201 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 673755 episodes
GETTING ACTION FROM:
action 2, numVisits=673751, meanQ=17.870309, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.458676 0.102537 0.676505 0.800269 0.548795 0.812201 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 131
Initial state: 0 0.518984 0.815111 0.245003 0.203125 0.57745 0.841178 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 660453 episodes
GETTING ACTION FROM:
action 3, numVisits=660448, meanQ=17.741049, numObservations: 5
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.518984 0.815111 0.245003 0.203125 0.57745 0.841178 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 132
Initial state: 0 0.685956 0.822963 0.891373 0.338405 0.575647 0.839983 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 665681 episodes
GETTING ACTION FROM:
action 2, numVisits=665677, meanQ=17.767540, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.685956 0.822963 0.891373 0.338405 0.575647 0.839983 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=5334, meanQ=23.352954, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 857769 episodes
GETTING ACTION FROM:
action 3, numVisits=863103, meanQ=18.998776, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.685956 0.822963 0.891373 0.338405 0.575647 0.839983 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=15709, meanQ=22.204815, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 880028 episodes
GETTING ACTION FROM:
action 3, numVisits=895737, meanQ=17.513714, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.685956 0.822963 0.891373 0.338405 0.575647 0.839983 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 133
Initial state: 0 0.645493 0.848114 0.347847 0.686 0.586513 0.831013 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 664764 episodes
GETTING ACTION FROM:
action 3, numVisits=664744, meanQ=17.772134, numObservations: 4
action 1, numVisits=16, meanQ=14.436256, numObservations: 4
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.645493 0.848114 0.347847 0.686 0.586513 0.831013 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 134
Initial state: 0 0.663539 0.86693 0.9758 0.291604 0.573941 0.804353 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 462749 episodes
GETTING ACTION FROM:
action -1, numVisits=462745, meanQ=15.657374, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.663539 0.86693 0.9758 0.291604 0.573941 0.804353 w: 1
Observation: 0 0.652109 0 0.91344 0 0.588045 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=462736, meanQ=17.843571, numObservations: 4
action 3, numVisits=5, meanQ=11.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 744189 episodes
GETTING ACTION FROM:
action 2, numVisits=1206925, meanQ=17.641190, numObservations: 4
action 3, numVisits=5, meanQ=11.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.663539 0.86693 0.9758 0.291604 0.573941 0.804353 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 135
Initial state: 0 0.696924 0.818693 0.679689 0.891258 0.714626 0.0354778 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 664091 episodes
GETTING ACTION FROM:
action 1, numVisits=664083, meanQ=17.823254, numObservations: 5
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action 2, numVisits=4, meanQ=9.997525, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.696924 0.818693 0.679689 0.891258 0.714626 0.0354778 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 136
Initial state: 0 0.195318 0.869759 0.62562 0.808367 0.680885 0.898115 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 457456 episodes
GETTING ACTION FROM:
action 0, numVisits=457444, meanQ=15.598654, numObservations: 1
action 1, numVisits=4, meanQ=-0.252500, numObservations: 2
action 3, numVisits=5, meanQ=-0.804000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.195318 0.869759 0.62562 0.808367 0.680885 0.898115 w: 1
Observation: 0 0 0.783875 0 0.733066 0 0.806191 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=457428, meanQ=17.786122, numObservations: 5
action 3, numVisits=11, meanQ=13.817282, numObservations: 3
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 732377 episodes
GETTING ACTION FROM:
action 2, numVisits=1189805, meanQ=17.616270, numObservations: 5
action 3, numVisits=11, meanQ=13.817282, numObservations: 3
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.195318 0.869759 0.62562 0.808367 0.680885 0.898115 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=88552, meanQ=17.780628, numObservations: 5
action 2, numVisits=3, meanQ=12.333333, numObservations: 1
action 3, numVisits=3, meanQ=12.333333, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 851633 episodes
GETTING ACTION FROM:
action 1, numVisits=940185, meanQ=19.258290, numObservations: 5
action 2, numVisits=3, meanQ=12.333333, numObservations: 1
action 3, numVisits=3, meanQ=12.333333, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 0 0.195318 0.869759 0.62562 0.808367 0.680885 0.898115 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=10384, meanQ=21.821938, numObservations: 3
action 3, numVisits=50, meanQ=20.850404, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 890636 episodes
GETTING ACTION FROM:
action 2, numVisits=899093, meanQ=18.816412, numObservations: 3
action 3, numVisits=1977, meanQ=18.649575, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.195318 0.869759 0.62562 0.808367 0.680885 0.898115 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 13.4068
Run # 137
Initial state: 0 0.625686 0.884875 0.506811 0.831015 0.276493 0.392329 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 665662 episodes
GETTING ACTION FROM:
action 2, numVisits=665655, meanQ=17.752348, numObservations: 5
action 1, numVisits=4, meanQ=1.247525, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.625686 0.884875 0.506811 0.831015 0.276493 0.392329 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 138
Initial state: 0 0.620573 0.856851 0.588888 0.819013 0.436279 0.429863 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 664369 episodes
GETTING ACTION FROM:
action 2, numVisits=664364, meanQ=17.733007, numObservations: 5
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.620573 0.856851 0.588888 0.819013 0.436279 0.429863 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 139
Initial state: 0 0.685426 0.800019 0.677265 0.87986 0.288061 0.331887 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 650731 episodes
GETTING ACTION FROM:
action 3, numVisits=650717, meanQ=17.763164, numObservations: 4
action 2, numVisits=11, meanQ=10.635464, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.685426 0.800019 0.677265 0.87986 0.288061 0.331887 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 140
Initial state: 0 0.943756 0.602447 0.625688 0.80179 0.543683 0.871189 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 462746 episodes
GETTING ACTION FROM:
action -1, numVisits=462742, meanQ=15.554454, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.943756 0.602447 0.625688 0.80179 0.543683 0.871189 w: 1
Observation: 0 0.872583 0 0.67987 0 0.568345 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=462736, meanQ=17.745710, numObservations: 4
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 746503 episodes
GETTING ACTION FROM:
action 2, numVisits=1209239, meanQ=17.632970, numObservations: 4
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.943756 0.602447 0.625688 0.80179 0.543683 0.871189 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 141
Initial state: 0 0.62171 0.810472 0.521566 0.898316 0.871318 0.912246 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 667473 episodes
GETTING ACTION FROM:
action 1, numVisits=667467, meanQ=17.723195, numObservations: 4
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.62171 0.810472 0.521566 0.898316 0.871318 0.912246 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 142
Initial state: 0 0.577669 0.862086 0.0939722 0.578291 0.621259 0.834499 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 671662 episodes
GETTING ACTION FROM:
action 1, numVisits=671653, meanQ=17.857949, numObservations: 4
action 3, numVisits=5, meanQ=11.598000, numObservations: 3
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.577669 0.862086 0.0939722 0.578291 0.621259 0.834499 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 143
Initial state: 0 0.930166 0.661954 0.553001 0.886828 0.647526 0.861555 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 668780 episodes
GETTING ACTION FROM:
action 2, numVisits=668776, meanQ=17.877632, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.930166 0.661954 0.553001 0.886828 0.647526 0.861555 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 144
Initial state: 0 0.616154 0.8559 0.673617 0.896073 0.605157 0.401495 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 661861 episodes
GETTING ACTION FROM:
action 3, numVisits=661857, meanQ=17.822167, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.616154 0.8559 0.673617 0.896073 0.605157 0.401495 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=92868, meanQ=23.273476, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 870188 episodes
GETTING ACTION FROM:
action 1, numVisits=963056, meanQ=19.434740, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.616154 0.8559 0.673617 0.896073 0.605157 0.401495 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=23396, meanQ=22.182887, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 871237 episodes
GETTING ACTION FROM:
action 1, numVisits=894633, meanQ=17.523397, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.616154 0.8559 0.673617 0.896073 0.605157 0.401495 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 145
Initial state: 0 0.636643 0.89164 0.351918 0.583453 0.580651 0.864881 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 462392 episodes
GETTING ACTION FROM:
action -1, numVisits=462387, meanQ=15.688681, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.636643 0.89164 0.351918 0.583453 0.580651 0.864881 w: 1
Observation: 0 0.578197 0 0.417327 0 0.517872 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=462376, meanQ=17.860244, numObservations: 5
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action 2, numVisits=6, meanQ=9.163333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 729017 episodes
GETTING ACTION FROM:
action 3, numVisits=1191393, meanQ=17.913794, numObservations: 5
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action 2, numVisits=6, meanQ=9.163333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.636643 0.89164 0.351918 0.583453 0.580651 0.864881 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 146
Initial state: 0 0.424716 0.474075 0.604449 0.80367 0.504913 0.829693 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 670883 episodes
GETTING ACTION FROM:
action 1, numVisits=670879, meanQ=17.853555, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.424716 0.474075 0.604449 0.80367 0.504913 0.829693 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 147
Initial state: 0 0.98525 0.570813 0.619846 0.860277 0.677661 0.86514 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 669940 episodes
GETTING ACTION FROM:
action 1, numVisits=669934, meanQ=17.771707, numObservations: 4
action 2, numVisits=3, meanQ=4.670033, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.98525 0.570813 0.619846 0.860277 0.677661 0.86514 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 148
Initial state: 0 0.682911 0.825311 0.583052 0.860073 0.28612 0.719745 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 658750 episodes
GETTING ACTION FROM:
action 3, numVisits=658746, meanQ=17.741097, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.682911 0.825311 0.583052 0.860073 0.28612 0.719745 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=92221, meanQ=23.247765, numObservations: 5
action 1, numVisits=3, meanQ=14.996667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 848883 episodes
GETTING ACTION FROM:
action 2, numVisits=941104, meanQ=19.490636, numObservations: 5
action 1, numVisits=3, meanQ=14.996667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.682911 0.825311 0.583052 0.860073 0.28612 0.719745 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 149
Initial state: 0 0.798151 0.307893 0.687143 0.865577 0.630185 0.877223 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 669233 episodes
GETTING ACTION FROM:
action 1, numVisits=669122, meanQ=17.859938, numObservations: 5
action 3, numVisits=87, meanQ=15.571495, numObservations: 4
action 2, numVisits=22, meanQ=14.408645, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 2 0.798151 0.307893 0.687143 0.865577 0.630185 0.877223 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 150
Initial state: 0 0.51708 0.800665 0.361029 0.189812 0.601465 0.82796 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 676963 episodes
GETTING ACTION FROM:
action 1, numVisits=676958, meanQ=17.865011, numObservations: 3
action 2, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.51708 0.800665 0.361029 0.189812 0.601465 0.82796 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 151
Initial state: 0 0.576994 0.841755 0.864324 0.209534 0.614144 0.834475 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 677602 episodes
GETTING ACTION FROM:
action 2, numVisits=677592, meanQ=17.840403, numObservations: 3
action 1, numVisits=6, meanQ=7.831667, numObservations: 3
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 2 0.576994 0.841755 0.864324 0.209534 0.614144 0.834475 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 152
Initial state: 0 0.735429 0.336921 0.559522 0.835791 0.674607 0.891024 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 670825 episodes
GETTING ACTION FROM:
action 1, numVisits=670821, meanQ=17.827322, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.735429 0.336921 0.559522 0.835791 0.674607 0.891024 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 153
Initial state: 0 0.882844 0.412575 0.543918 0.897414 0.614109 0.893379 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 663168 episodes
GETTING ACTION FROM:
action 2, numVisits=662863, meanQ=17.749760, numObservations: 5
action 3, numVisits=300, meanQ=17.319236, numObservations: 4
action 1, numVisits=3, meanQ=12.333333, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.882844 0.412575 0.543918 0.897414 0.614109 0.893379 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 154
Initial state: 0 0.526061 0.823874 0.473294 0.398899 0.632405 0.849845 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666657 episodes
GETTING ACTION FROM:
action 3, numVisits=666650, meanQ=17.743606, numObservations: 4
action 2, numVisits=4, meanQ=8.497500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.526061 0.823874 0.473294 0.398899 0.632405 0.849845 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=44062, meanQ=16.605608, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 865618 episodes
GETTING ACTION FROM:
action 2, numVisits=909680, meanQ=18.852080, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.526061 0.823874 0.473294 0.398899 0.632405 0.849845 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=13722, meanQ=23.476473, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 881244 episodes
GETTING ACTION FROM:
action 1, numVisits=894966, meanQ=18.588035, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.526061 0.823874 0.473294 0.398899 0.632405 0.849845 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 155
Initial state: 0 0.626276 0.899921 0.130682 0.668577 0.578637 0.885043 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 663731 episodes
GETTING ACTION FROM:
action 1, numVisits=663710, meanQ=17.796188, numObservations: 4
action 3, numVisits=15, meanQ=11.465340, numObservations: 3
action 2, numVisits=4, meanQ=8.497500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.626276 0.899921 0.130682 0.668577 0.578637 0.885043 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 156
Initial state: 0 0.605399 0.832426 0.621472 0.839939 0.559699 0.595455 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 661887 episodes
GETTING ACTION FROM:
action 2, numVisits=661869, meanQ=17.841320, numObservations: 5
action 1, numVisits=14, meanQ=12.641429, numObservations: 3
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.605399 0.832426 0.621472 0.839939 0.559699 0.595455 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=49248, meanQ=18.590074, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 798445 episodes
GETTING ACTION FROM:
action 2, numVisits=847693, meanQ=17.039075, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.605399 0.832426 0.621472 0.839939 0.559699 0.595455 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=18505, meanQ=20.438056, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 872625 episodes
GETTING ACTION FROM:
action 1, numVisits=891130, meanQ=18.385879, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.605399 0.832426 0.621472 0.839939 0.559699 0.595455 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 157
Initial state: 0 0.0244199 0.651239 0.609227 0.882248 0.672812 0.891224 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666350 episodes
GETTING ACTION FROM:
action 2, numVisits=666346, meanQ=17.748346, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.0244199 0.651239 0.609227 0.882248 0.672812 0.891224 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 158
Initial state: 0 0.673791 0.8908 0.528018 0.839939 0.0339285 0.513012 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 668046 episodes
GETTING ACTION FROM:
action 2, numVisits=668037, meanQ=17.819377, numObservations: 4
action 1, numVisits=5, meanQ=11.598000, numObservations: 3
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.673791 0.8908 0.528018 0.839939 0.0339285 0.513012 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 159
Initial state: 0 0.69929 0.892059 0.623364 0.866506 0.131562 0.282882 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 671651 episodes
GETTING ACTION FROM:
action 3, numVisits=671625, meanQ=17.781744, numObservations: 3
action 1, numVisits=15, meanQ=11.332680, numObservations: 3
action 2, numVisits=9, meanQ=10.886678, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.69929 0.892059 0.623364 0.866506 0.131562 0.282882 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=110987, meanQ=23.150806, numObservations: 3
action 1, numVisits=4, meanQ=17.247500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 868903 episodes
GETTING ACTION FROM:
action 2, numVisits=979755, meanQ=18.761099, numObservations: 3
action 1, numVisits=139, meanQ=18.052376, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.69929 0.892059 0.623364 0.866506 0.131562 0.282882 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 160
Initial state: 0 0.558481 0.827464 0.00013997 0.430063 0.641989 0.819424 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 675857 episodes
GETTING ACTION FROM:
action 3, numVisits=675853, meanQ=17.854279, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.558481 0.827464 0.00013997 0.430063 0.641989 0.819424 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 161
Initial state: 0 0.596607 0.847471 0.688342 0.800272 0.375814 0.586327 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 673530 episodes
GETTING ACTION FROM:
action 3, numVisits=673505, meanQ=17.873591, numObservations: 3
action 1, numVisits=18, meanQ=13.005000, numObservations: 4
action 2, numVisits=5, meanQ=11.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.596607 0.847471 0.688342 0.800272 0.375814 0.586327 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=111818, meanQ=23.163145, numObservations: 4
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 859121 episodes
GETTING ACTION FROM:
action 1, numVisits=970939, meanQ=19.359002, numObservations: 4
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.596607 0.847471 0.688342 0.800272 0.375814 0.586327 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=24615, meanQ=23.007809, numObservations: 3
action 2, numVisits=5, meanQ=18.598000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 887401 episodes
GETTING ACTION FROM:
action 1, numVisits=912006, meanQ=17.524780, numObservations: 3
action 2, numVisits=15, meanQ=15.199333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.596607 0.847471 0.688342 0.800272 0.375814 0.586327 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=6119, meanQ=20.385152, numObservations: 4
action 2, numVisits=7, meanQ=16.282857, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 880914 episodes
GETTING ACTION FROM:
action 2, numVisits=722447, meanQ=19.291047, numObservations: 4
action 1, numVisits=164593, meanQ=17.425510, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.596607 0.847471 0.688342 0.800272 0.375814 0.586327 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 2, numVisits=918, meanQ=23.197874, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 904710 episodes
GETTING ACTION FROM:
action 2, numVisits=905628, meanQ=19.017989, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.596607 0.847471 0.688342 0.800272 0.375814 0.586327 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.29271
Run # 162
Initial state: 0 0.988221 0.0947753 0.549385 0.868532 0.57847 0.820775 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 670344 episodes
GETTING ACTION FROM:
action 1, numVisits=670339, meanQ=17.821960, numObservations: 4
action 2, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.988221 0.0947753 0.549385 0.868532 0.57847 0.820775 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 163
Initial state: 0 0.604986 0.879998 0.376544 0.904358 0.528817 0.862569 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 460179 episodes
GETTING ACTION FROM:
action 0, numVisits=460174, meanQ=15.613127, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.604986 0.879998 0.376544 0.904358 0.528817 0.862569 w: 1
Observation: 0 0 0.922575 0 0.940415 0 0.774768 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=460169, meanQ=17.781147, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 738135 episodes
GETTING ACTION FROM:
action 1, numVisits=1198304, meanQ=17.473256, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.604986 0.879998 0.376544 0.904358 0.528817 0.862569 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 164
Initial state: 0 0.605856 0.843662 0.0904148 0.852519 0.67009 0.89667 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 663891 episodes
GETTING ACTION FROM:
action 1, numVisits=663886, meanQ=17.861220, numObservations: 5
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.605856 0.843662 0.0904148 0.852519 0.67009 0.89667 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 165
Initial state: 0 0.516477 0.876292 0.798071 0.344123 0.582543 0.817624 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666761 episodes
GETTING ACTION FROM:
action 1, numVisits=666747, meanQ=17.874197, numObservations: 5
action 2, numVisits=11, meanQ=13.090918, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.516477 0.876292 0.798071 0.344123 0.582543 0.817624 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=48790, meanQ=18.818819, numObservations: 3
action 3, numVisits=3, meanQ=12.333333, numObservations: 1
action 2, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 784374 episodes
GETTING ACTION FROM:
action 1, numVisits=833164, meanQ=17.420834, numObservations: 4
action 3, numVisits=3, meanQ=12.333333, numObservations: 1
action 2, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.516477 0.876292 0.798071 0.344123 0.582543 0.817624 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 166
Initial state: 0 0.581697 0.846687 0.572192 0.830766 0.879121 0.36379 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 664408 episodes
GETTING ACTION FROM:
action 3, numVisits=664404, meanQ=17.862449, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.581697 0.846687 0.572192 0.830766 0.879121 0.36379 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=49188, meanQ=18.641344, numObservations: 4
action 2, numVisits=7, meanQ=11.857157, numObservations: 3
action 1, numVisits=4, meanQ=10.495000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 778424 episodes
GETTING ACTION FROM:
action 3, numVisits=827612, meanQ=17.672031, numObservations: 5
action 2, numVisits=7, meanQ=11.857157, numObservations: 3
action 1, numVisits=4, meanQ=10.495000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 2 0.581697 0.846687 0.572192 0.830766 0.879121 0.36379 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 167
Initial state: 0 0.650548 0.850271 0.628688 0.818803 0.71429 0.12142 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666123 episodes
GETTING ACTION FROM:
action 3, numVisits=666115, meanQ=17.847677, numObservations: 5
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action 2, numVisits=4, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 2 0.650548 0.850271 0.628688 0.818803 0.71429 0.12142 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 168
Initial state: 0 0.704142 0.124651 0.598165 0.826153 0.505163 0.805061 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 664336 episodes
GETTING ACTION FROM:
action 1, numVisits=664332, meanQ=17.763230, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.704142 0.124651 0.598165 0.826153 0.505163 0.805061 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 169
Initial state: 0 0.574065 0.844685 0.649373 0.853223 0.527504 0.179662 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 662557 episodes
GETTING ACTION FROM:
action 2, numVisits=662552, meanQ=17.862392, numObservations: 5
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.574065 0.844685 0.649373 0.853223 0.527504 0.179662 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 170
Initial state: 0 0.501464 0.803133 0.850172 0.374258 0.523001 0.822531 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666853 episodes
GETTING ACTION FROM:
action 3, numVisits=666838, meanQ=17.762328, numObservations: 4
action 1, numVisits=12, meanQ=7.831667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.501464 0.803133 0.850172 0.374258 0.523001 0.822531 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 171
Initial state: 0 0.558847 0.891549 0.40988 0.0293041 0.626505 0.894156 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 661581 episodes
GETTING ACTION FROM:
action 2, numVisits=661566, meanQ=17.749795, numObservations: 5
action 1, numVisits=11, meanQ=9.362736, numObservations: 2
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.558847 0.891549 0.40988 0.0293041 0.626505 0.894156 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=92453, meanQ=23.285939, numObservations: 5
action 3, numVisits=4, meanQ=17.247500, numObservations: 1
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 846311 episodes
GETTING ACTION FROM:
action 1, numVisits=938760, meanQ=19.422250, numObservations: 5
action 3, numVisits=8, meanQ=16.248750, numObservations: 2
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.558847 0.891549 0.40988 0.0293041 0.626505 0.894156 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 172
Initial state: 0 0.603718 0.824271 0.673901 0.852094 0.947057 0.520423 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 657718 episodes
GETTING ACTION FROM:
action 3, numVisits=657714, meanQ=17.731290, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.603718 0.824271 0.673901 0.852094 0.947057 0.520423 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 173
Initial state: 0 0.818503 0.211963 0.601602 0.869491 0.613111 0.835466 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 661344 episodes
GETTING ACTION FROM:
action 3, numVisits=661335, meanQ=17.873585, numObservations: 5
action 2, numVisits=5, meanQ=13.196000, numObservations: 2
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.818503 0.211963 0.601602 0.869491 0.613111 0.835466 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 174
Initial state: 0 0.557449 0.833549 0.92842 0.372319 0.528479 0.826567 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 667640 episodes
GETTING ACTION FROM:
action 1, numVisits=667636, meanQ=18.152951, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.557449 0.833549 0.92842 0.372319 0.528479 0.826567 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=37082, meanQ=22.808674, numObservations: 4
action 3, numVisits=8, meanQ=17.247500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 786605 episodes
GETTING ACTION FROM:
action 1, numVisits=823686, meanQ=17.747299, numObservations: 4
action 3, numVisits=9, meanQ=14.108889, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.557449 0.833549 0.92842 0.372319 0.528479 0.826567 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 175
Initial state: 0 0.621582 0.858087 0.562371 0.889841 0.235877 0.00457873 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 661963 episodes
GETTING ACTION FROM:
action 1, numVisits=661948, meanQ=17.748902, numObservations: 5
action 2, numVisits=11, meanQ=13.451818, numObservations: 4
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.621582 0.858087 0.562371 0.889841 0.235877 0.00457873 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 176
Initial state: 0 0.639716 0.80647 0.564896 0.882118 0.945329 0.572815 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 658033 episodes
GETTING ACTION FROM:
action 3, numVisits=658000, meanQ=17.850139, numObservations: 5
action 2, numVisits=16, meanQ=11.873750, numObservations: 3
action 1, numVisits=15, meanQ=11.182673, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 2 0.639716 0.80647 0.564896 0.882118 0.945329 0.572815 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 177
Initial state: 0 0.621548 0.860723 0.269127 0.590258 0.581773 0.801108 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 668903 episodes
GETTING ACTION FROM:
action 2, numVisits=668885, meanQ=17.873693, numObservations: 4
action 1, numVisits=8, meanQ=13.375012, numObservations: 3
action 3, numVisits=8, meanQ=12.872500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.621548 0.860723 0.269127 0.590258 0.581773 0.801108 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=110212, meanQ=23.146795, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 849092 episodes
GETTING ACTION FROM:
action 1, numVisits=959304, meanQ=19.224841, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.621548 0.860723 0.269127 0.590258 0.581773 0.801108 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 178
Initial state: 0 0.503198 0.888464 0.358888 0.388443 0.663298 0.872973 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 678572 episodes
GETTING ACTION FROM:
action 2, numVisits=678562, meanQ=17.747587, numObservations: 3
action 3, numVisits=7, meanQ=11.282857, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.503198 0.888464 0.358888 0.388443 0.663298 0.872973 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=110842, meanQ=23.207378, numObservations: 5
action 1, numVisits=3, meanQ=14.996667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 842124 episodes
GETTING ACTION FROM:
action 3, numVisits=952966, meanQ=19.530370, numObservations: 5
action 1, numVisits=3, meanQ=14.996667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.503198 0.888464 0.358888 0.388443 0.663298 0.872973 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 179
Initial state: 0 0.777655 0.386534 0.692217 0.855955 0.69282 0.872773 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 667742 episodes
GETTING ACTION FROM:
action 3, numVisits=667737, meanQ=17.837391, numObservations: 4
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.777655 0.386534 0.692217 0.855955 0.69282 0.872773 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 180
Initial state: 0 0.675051 0.88031 0.598253 0.894271 0.313891 0.454188 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 657442 episodes
GETTING ACTION FROM:
action 3, numVisits=657418, meanQ=18.131682, numObservations: 5
action 1, numVisits=16, meanQ=10.436262, numObservations: 2
action 2, numVisits=6, meanQ=10.163350, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.675051 0.88031 0.598253 0.894271 0.313891 0.454188 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=75661, meanQ=23.512138, numObservations: 3
action 2, numVisits=3, meanQ=14.996667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 870298 episodes
GETTING ACTION FROM:
action 1, numVisits=945959, meanQ=19.491003, numObservations: 3
action 2, numVisits=3, meanQ=14.996667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.675051 0.88031 0.598253 0.894271 0.313891 0.454188 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 181
Initial state: 0 0.100954 0.604487 0.57993 0.885048 0.51916 0.86063 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 675328 episodes
GETTING ACTION FROM:
action 1, numVisits=675323, meanQ=17.754470, numObservations: 3
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.100954 0.604487 0.57993 0.885048 0.51916 0.86063 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=110852, meanQ=23.201868, numObservations: 5
action 3, numVisits=4, meanQ=17.247500, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 855935 episodes
GETTING ACTION FROM:
action 2, numVisits=966785, meanQ=19.288061, numObservations: 5
action 3, numVisits=6, meanQ=13.665000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.100954 0.604487 0.57993 0.885048 0.51916 0.86063 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 182
Initial state: 0 0.142512 0.513315 0.556573 0.823311 0.647016 0.870163 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 663436 episodes
GETTING ACTION FROM:
action 2, numVisits=663422, meanQ=17.842459, numObservations: 5
action 3, numVisits=5, meanQ=11.598000, numObservations: 1
action 1, numVisits=7, meanQ=11.282857, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.142512 0.513315 0.556573 0.823311 0.647016 0.870163 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=48321, meanQ=18.670670, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 784908 episodes
GETTING ACTION FROM:
action 2, numVisits=833229, meanQ=16.965186, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.142512 0.513315 0.556573 0.823311 0.647016 0.870163 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=28995, meanQ=23.219609, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 871404 episodes
GETTING ACTION FROM:
action 3, numVisits=900399, meanQ=18.948430, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.142512 0.513315 0.556573 0.823311 0.647016 0.870163 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 183
Initial state: 0 0.35287 0.965786 0.514194 0.818386 0.688385 0.805231 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 668957 episodes
GETTING ACTION FROM:
action 1, numVisits=668950, meanQ=17.843885, numObservations: 4
action 3, numVisits=3, meanQ=12.333333, numObservations: 1
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 0 0.35287 0.965786 0.514194 0.818386 0.688385 0.805231 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=49429, meanQ=18.685138, numObservations: 4
action 2, numVisits=5, meanQ=13.196000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 780324 episodes
GETTING ACTION FROM:
action 1, numVisits=829753, meanQ=17.484734, numObservations: 4
action 2, numVisits=5, meanQ=13.196000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.35287 0.965786 0.514194 0.818386 0.688385 0.805231 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 184
Initial state: 0 0.583702 0.894846 0.44605 0.0024351 0.662222 0.832047 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666063 episodes
GETTING ACTION FROM:
action 1, numVisits=666055, meanQ=17.742343, numObservations: 4
action 3, numVisits=5, meanQ=10.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.583702 0.894846 0.44605 0.0024351 0.662222 0.832047 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 185
Initial state: 0 0.546047 0.813151 0.32127 0.711509 0.592218 0.894836 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 662550 episodes
GETTING ACTION FROM:
action 2, numVisits=662542, meanQ=17.845966, numObservations: 5
action 1, numVisits=5, meanQ=10.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.546047 0.813151 0.32127 0.711509 0.592218 0.894836 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=75884, meanQ=23.506421, numObservations: 3
action 1, numVisits=3, meanQ=14.996667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 855431 episodes
GETTING ACTION FROM:
action 3, numVisits=931315, meanQ=19.458714, numObservations: 4
action 1, numVisits=3, meanQ=14.996667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.546047 0.813151 0.32127 0.711509 0.592218 0.894836 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 186
Initial state: 0 0.604867 0.888915 0.786649 0.653008 0.504164 0.82794 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 664217 episodes
GETTING ACTION FROM:
action 1, numVisits=664209, meanQ=17.729055, numObservations: 5
action 3, numVisits=4, meanQ=8.497500, numObservations: 1
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.604867 0.888915 0.786649 0.653008 0.504164 0.82794 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 187
Initial state: 0 0.506093 0.808381 0.532531 0.882102 0.721723 0.338023 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 674252 episodes
GETTING ACTION FROM:
action 2, numVisits=674243, meanQ=17.817997, numObservations: 4
action 3, numVisits=6, meanQ=12.333333, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.506093 0.808381 0.532531 0.882102 0.721723 0.338023 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 188
Initial state: 0 0.520085 0.840222 0.16066 0.612066 0.618046 0.836248 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 669249 episodes
GETTING ACTION FROM:
action 3, numVisits=669243, meanQ=17.757070, numObservations: 4
action 1, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.520085 0.840222 0.16066 0.612066 0.618046 0.836248 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 189
Initial state: 0 0.646259 0.814863 0.918628 0.420274 0.627347 0.829787 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 661505 episodes
GETTING ACTION FROM:
action 2, numVisits=661500, meanQ=17.746391, numObservations: 5
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.646259 0.814863 0.918628 0.420274 0.627347 0.829787 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 190
Initial state: 0 0.187949 0.168526 0.659403 0.856061 0.673669 0.811968 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 435929 episodes
GETTING ACTION FROM:
action 0, numVisits=435923, meanQ=15.247872, numObservations: 1
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.187949 0.168526 0.659403 0.856061 0.673669 0.811968 w: 1
Observation: 0 0 0.124518 0 0.94803 0 0.881327 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=435901, meanQ=17.417428, numObservations: 4
action 2, numVisits=17, meanQ=13.646482, numObservations: 3
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 679543 episodes
GETTING ACTION FROM:
action 1, numVisits=1115444, meanQ=17.012338, numObservations: 4
action 2, numVisits=17, meanQ=13.646482, numObservations: 3
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 0 0.187949 0.168526 0.659403 0.856061 0.673669 0.811968 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 0, numVisits=162978, meanQ=21.002442, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 760863 episodes
GETTING ACTION FROM:
action 0, numVisits=923841, meanQ=6.770374, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.187949 0.168526 0.659403 0.856061 0.673669 0.811968 w: 1
Observation: 0 0 0.26161 0 0.894165 0 0.832999 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=293716, meanQ=23.490432, numObservations: 4
action 2, numVisits=5, meanQ=18.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 848279 episodes
GETTING ACTION FROM:
action 3, numVisits=1141993, meanQ=20.265076, numObservations: 4
action 2, numVisits=7, meanQ=15.141429, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.187949 0.168526 0.659403 0.856061 0.673669 0.811968 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.367
Run # 191
Initial state: 0 0.582453 0.88562 0.389436 0.228624 0.66724 0.896975 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 661285 episodes
GETTING ACTION FROM:
action 1, numVisits=661233, meanQ=17.805273, numObservations: 5
action 3, numVisits=36, meanQ=16.312778, numObservations: 3
action 2, numVisits=14, meanQ=14.232857, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.582453 0.88562 0.389436 0.228624 0.66724 0.896975 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 192
Initial state: 0 0.00626082 0.661972 0.544649 0.882515 0.652068 0.874209 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 662812 episodes
GETTING ACTION FROM:
action 3, numVisits=662808, meanQ=17.837572, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.00626082 0.661972 0.544649 0.882515 0.652068 0.874209 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 193
Initial state: 0 0.0177636 0.371488 0.551431 0.881784 0.557288 0.878229 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 670702 episodes
GETTING ACTION FROM:
action 2, numVisits=670698, meanQ=18.169479, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.0177636 0.371488 0.551431 0.881784 0.557288 0.878229 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 194
Initial state: 0 0.580219 0.830072 0.319855 0.854867 0.6504 0.870259 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 672385 episodes
GETTING ACTION FROM:
action 1, numVisits=672380, meanQ=17.845379, numObservations: 4
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.580219 0.830072 0.319855 0.854867 0.6504 0.870259 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 195
Initial state: 0 0.684894 0.839584 0.332184 0.828528 0.685273 0.881721 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 664232 episodes
GETTING ACTION FROM:
action 2, numVisits=664228, meanQ=17.734830, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.684894 0.839584 0.332184 0.828528 0.685273 0.881721 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=33228, meanQ=22.247960, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 851028 episodes
GETTING ACTION FROM:
action 1, numVisits=884256, meanQ=18.962891, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.684894 0.839584 0.332184 0.828528 0.685273 0.881721 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 196
Initial state: 0 0.595223 0.887415 0.656266 0.837341 0.00306784 0.0990853 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 669293 episodes
GETTING ACTION FROM:
action 2, numVisits=669244, meanQ=17.849961, numObservations: 4
action 1, numVisits=42, meanQ=15.626195, numObservations: 3
action 3, numVisits=5, meanQ=12.798020, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.595223 0.887415 0.656266 0.837341 0.00306784 0.0990853 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=16429, meanQ=22.421756, numObservations: 4
action 1, numVisits=13, meanQ=16.846931, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 858013 episodes
GETTING ACTION FROM:
action 3, numVisits=874442, meanQ=18.924735, numObservations: 4
action 1, numVisits=13, meanQ=16.846931, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.595223 0.887415 0.656266 0.837341 0.00306784 0.0990853 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=8943, meanQ=23.465914, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 893289 episodes
GETTING ACTION FROM:
action 1, numVisits=902232, meanQ=18.921255, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.595223 0.887415 0.656266 0.837341 0.00306784 0.0990853 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 197
Initial state: 0 0.503571 0.850093 0.588766 0.896794 0.0241232 0.620297 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 675503 episodes
GETTING ACTION FROM:
action 2, numVisits=675499, meanQ=17.853957, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.503571 0.850093 0.588766 0.896794 0.0241232 0.620297 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=50115, meanQ=18.635458, numObservations: 4
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 791896 episodes
GETTING ACTION FROM:
action 2, numVisits=842011, meanQ=17.548375, numObservations: 4
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.503571 0.850093 0.588766 0.896794 0.0241232 0.620297 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 198
Initial state: 0 0.0221561 0.433048 0.521633 0.883893 0.613803 0.873637 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666326 episodes
GETTING ACTION FROM:
action 1, numVisits=666320, meanQ=17.815127, numObservations: 5
action 3, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.0221561 0.433048 0.521633 0.883893 0.613803 0.873637 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=93779, meanQ=23.174140, numObservations: 4
action 3, numVisits=35, meanQ=20.742863, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 859558 episodes
GETTING ACTION FROM:
action 2, numVisits=953320, meanQ=19.097728, numObservations: 4
action 3, numVisits=52, meanQ=17.918660, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.0221561 0.433048 0.521633 0.883893 0.613803 0.873637 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 199
Initial state: 0 0.543811 0.823471 0.655573 0.819333 0.928874 0.445231 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 678623 episodes
GETTING ACTION FROM:
action 1, numVisits=678618, meanQ=17.791535, numObservations: 3
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.543811 0.823471 0.655573 0.819333 0.928874 0.445231 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 200
Initial state: 0 0.584169 0.85235 0.484567 0.549976 0.56988 0.838249 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 661525 episodes
GETTING ACTION FROM:
action 3, numVisits=661483, meanQ=17.729980, numObservations: 4
action 1, numVisits=23, meanQ=13.217404, numObservations: 3
action 2, numVisits=17, meanQ=12.470006, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.584169 0.85235 0.484567 0.549976 0.56988 0.838249 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 201
Initial state: 0 0.296132 0.414632 0.516679 0.820488 0.688066 0.89752 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 665130 episodes
GETTING ACTION FROM:
action 3, numVisits=665126, meanQ=17.766061, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.296132 0.414632 0.516679 0.820488 0.688066 0.89752 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 202
Initial state: 0 0.583823 0.817571 0.616117 0.877351 0.795564 0.402105 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 664341 episodes
GETTING ACTION FROM:
action 3, numVisits=664337, meanQ=17.734226, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.583823 0.817571 0.616117 0.877351 0.795564 0.402105 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 203
Initial state: 0 0.579677 0.854837 0.0502034 0.12303 0.598823 0.818894 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 643986 episodes
GETTING ACTION FROM:
action 3, numVisits=643979, meanQ=17.587852, numObservations: 4
action 2, numVisits=4, meanQ=8.497500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.579677 0.854837 0.0502034 0.12303 0.598823 0.818894 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 204
Initial state: 0 0.417269 0.651299 0.569202 0.893921 0.528246 0.824605 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 654218 episodes
GETTING ACTION FROM:
action 1, numVisits=654189, meanQ=17.694140, numObservations: 5
action 3, numVisits=26, meanQ=7.229635, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.417269 0.651299 0.569202 0.893921 0.528246 0.824605 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=91648, meanQ=23.245801, numObservations: 4
action 2, numVisits=6, meanQ=19.498333, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 853620 episodes
GETTING ACTION FROM:
action 3, numVisits=945018, meanQ=19.162834, numObservations: 4
action 2, numVisits=256, meanQ=18.663127, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.417269 0.651299 0.569202 0.893921 0.528246 0.824605 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 205
Initial state: 0 0.646237 0.862349 0.514379 0.888066 0.809713 0.0694969 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 663686 episodes
GETTING ACTION FROM:
action 3, numVisits=663677, meanQ=17.859257, numObservations: 4
action 1, numVisits=5, meanQ=11.598000, numObservations: 2
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 2 0.646237 0.862349 0.514379 0.888066 0.809713 0.0694969 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 206
Initial state: 0 0.674461 0.859343 0.910573 0.67402 0.642566 0.813911 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 669452 episodes
GETTING ACTION FROM:
action 2, numVisits=669446, meanQ=17.868815, numObservations: 4
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 2 0.674461 0.859343 0.910573 0.67402 0.642566 0.813911 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 207
Initial state: 0 0.918245 0.320439 0.628016 0.835085 0.676027 0.874383 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 679014 episodes
GETTING ACTION FROM:
action 2, numVisits=679010, meanQ=17.853165, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.918245 0.320439 0.628016 0.835085 0.676027 0.874383 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 208
Initial state: 0 0.571073 0.825278 0.00618046 0.988003 0.551833 0.848314 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 668084 episodes
GETTING ACTION FROM:
action 3, numVisits=668071, meanQ=17.841737, numObservations: 4
action 1, numVisits=6, meanQ=13.665000, numObservations: 2
action 2, numVisits=5, meanQ=11.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.571073 0.825278 0.00618046 0.988003 0.551833 0.848314 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 209
Initial state: 0 0.411002 0.245351 0.567997 0.837502 0.534767 0.844689 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 675092 episodes
GETTING ACTION FROM:
action 3, numVisits=675084, meanQ=17.759393, numObservations: 3
action 1, numVisits=5, meanQ=12.402020, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.411002 0.245351 0.567997 0.837502 0.534767 0.844689 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 210
Initial state: 0 0.575749 0.850667 0.575274 0.842816 0.541205 0.903689 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 674304 episodes
GETTING ACTION FROM:
action 3, numVisits=674295, meanQ=17.852982, numObservations: 3
action 1, numVisits=6, meanQ=14.290000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.575749 0.850667 0.575274 0.842816 0.541205 0.903689 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 211
Initial state: 0 0.693824 0.823178 0.814061 0.609046 0.540552 0.831487 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 675945 episodes
GETTING ACTION FROM:
action 1, numVisits=675926, meanQ=17.770798, numObservations: 3
action 2, numVisits=13, meanQ=14.460000, numObservations: 3
action 3, numVisits=4, meanQ=10.495000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.693824 0.823178 0.814061 0.609046 0.540552 0.831487 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 212
Initial state: 0 0.556253 0.838976 0.675244 0.863448 0.215968 0.416673 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666209 episodes
GETTING ACTION FROM:
action 2, numVisits=666193, meanQ=17.723509, numObservations: 4
action 3, numVisits=9, meanQ=8.861111, numObservations: 2
action 1, numVisits=5, meanQ=7.794000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.556253 0.838976 0.675244 0.863448 0.215968 0.416673 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 213
Initial state: 0 0.621941 0.889511 0.685067 0.874785 0.847973 0.268964 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 661081 episodes
GETTING ACTION FROM:
action 1, numVisits=661068, meanQ=17.760513, numObservations: 5
action 2, numVisits=10, meanQ=11.774010, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.621941 0.889511 0.685067 0.874785 0.847973 0.268964 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 214
Initial state: 0 0.58722 0.54026 0.614483 0.811062 0.623755 0.805525 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666820 episodes
GETTING ACTION FROM:
action 3, numVisits=666816, meanQ=17.763013, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.58722 0.54026 0.614483 0.811062 0.623755 0.805525 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 215
Initial state: 0 0.553963 0.873779 0.816914 0.37386 0.542454 0.814645 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 667121 episodes
GETTING ACTION FROM:
action 3, numVisits=667104, meanQ=17.771366, numObservations: 4
action 2, numVisits=13, meanQ=12.229238, numObservations: 2
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.553963 0.873779 0.816914 0.37386 0.542454 0.814645 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 216
Initial state: 0 0.998289 0.747398 0.677549 0.86241 0.640304 0.823799 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 670952 episodes
GETTING ACTION FROM:
action 1, numVisits=670948, meanQ=17.839225, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.998289 0.747398 0.677549 0.86241 0.640304 0.823799 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 217
Initial state: 0 0.541088 0.845746 0.510383 0.851998 0.143439 0.555541 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 457136 episodes
GETTING ACTION FROM:
action 0, numVisits=457131, meanQ=15.543257, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.541088 0.845746 0.510383 0.851998 0.143439 0.555541 w: 1
Observation: 0 0 0.896772 0 0.8861 0 0.586193 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=457125, meanQ=17.752429, numObservations: 4
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 733328 episodes
GETTING ACTION FROM:
action 3, numVisits=1190453, meanQ=17.897422, numObservations: 4
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.541088 0.845746 0.510383 0.851998 0.143439 0.555541 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=170123, meanQ=23.304648, numObservations: 4
action 1, numVisits=20, meanQ=21.199505, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 859950 episodes
GETTING ACTION FROM:
action 2, numVisits=1029943, meanQ=19.958915, numObservations: 4
action 1, numVisits=150, meanQ=19.230001, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.541088 0.845746 0.510383 0.851998 0.143439 0.555541 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 17.5624
Run # 218
Initial state: 0 0.510739 0.104483 0.615144 0.815171 0.624176 0.863281 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 669622 episodes
GETTING ACTION FROM:
action 3, numVisits=669618, meanQ=17.866016, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.510739 0.104483 0.615144 0.815171 0.624176 0.863281 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=6454, meanQ=17.037544, numObservations: 5
action 3, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 835943 episodes
GETTING ACTION FROM:
action 1, numVisits=842397, meanQ=18.996142, numObservations: 5
action 3, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.510739 0.104483 0.615144 0.815171 0.624176 0.863281 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 219
Initial state: 0 0.574971 0.869595 0.641587 0.850827 0.867127 0.720838 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 646892 episodes
GETTING ACTION FROM:
action 3, numVisits=646888, meanQ=17.603150, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.574971 0.869595 0.641587 0.850827 0.867127 0.720838 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 220
Initial state: 0 0.323324 0.0803672 0.670512 0.807366 0.695972 0.893874 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 665083 episodes
GETTING ACTION FROM:
action 3, numVisits=665079, meanQ=17.808716, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.323324 0.0803672 0.670512 0.807366 0.695972 0.893874 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 221
Initial state: 0 0.66406 0.844 0.658595 0.861997 0.888338 0.466007 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 663804 episodes
GETTING ACTION FROM:
action 2, numVisits=663799, meanQ=17.754179, numObservations: 5
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.66406 0.844 0.658595 0.861997 0.888338 0.466007 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=48969, meanQ=17.439351, numObservations: 5
action 1, numVisits=6, meanQ=13.665000, numObservations: 2
action 2, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 848515 episodes
GETTING ACTION FROM:
action 3, numVisits=897484, meanQ=18.873941, numObservations: 5
action 1, numVisits=6, meanQ=13.665000, numObservations: 2
action 2, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 2 0.66406 0.844 0.658595 0.861997 0.888338 0.466007 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 222
Initial state: 0 0.599336 0.877122 0.298715 0.861133 0.606605 0.857962 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 665988 episodes
GETTING ACTION FROM:
action 1, numVisits=665975, meanQ=17.837162, numObservations: 5
action 2, numVisits=10, meanQ=11.399010, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.599336 0.877122 0.298715 0.861133 0.606605 0.857962 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 223
Initial state: 0 0.408652 0.784306 0.633254 0.856888 0.662863 0.861079 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666942 episodes
GETTING ACTION FROM:
action 3, numVisits=666938, meanQ=17.837310, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.408652 0.784306 0.633254 0.856888 0.662863 0.861079 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 224
Initial state: 0 0.699729 0.824743 0.530772 0.893105 0.285657 0.26944 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 673675 episodes
GETTING ACTION FROM:
action 1, numVisits=673671, meanQ=17.753592, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.699729 0.824743 0.530772 0.893105 0.285657 0.26944 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 225
Initial state: 0 0.512648 0.874396 0.574242 0.845037 0.154891 0.732061 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 670314 episodes
GETTING ACTION FROM:
action 1, numVisits=670309, meanQ=18.100903, numObservations: 4
action 3, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.512648 0.874396 0.574242 0.845037 0.154891 0.732061 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 226
Initial state: 0 0.671858 0.806053 0.781537 0.359092 0.625625 0.827679 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 463006 episodes
GETTING ACTION FROM:
action 0, numVisits=463001, meanQ=15.548708, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.671858 0.806053 0.781537 0.359092 0.625625 0.827679 w: 1
Observation: 0 0 0.70949 0 0.368115 0 0.890511 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=462991, meanQ=17.748786, numObservations: 3
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action 1, numVisits=5, meanQ=10.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 743016 episodes
GETTING ACTION FROM:
action 3, numVisits=1206007, meanQ=17.644853, numObservations: 3
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action 1, numVisits=5, meanQ=10.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.671858 0.806053 0.781537 0.359092 0.625625 0.827679 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 227
Initial state: 0 0.552888 0.860531 0.35391 0.473878 0.52418 0.840458 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 667438 episodes
GETTING ACTION FROM:
action 2, numVisits=667431, meanQ=17.745405, numObservations: 4
action 1, numVisits=4, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.552888 0.860531 0.35391 0.473878 0.52418 0.840458 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 228
Initial state: 0 0.573615 0.811377 0.94522 0.0359868 0.545072 0.854821 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 638629 episodes
GETTING ACTION FROM:
action 1, numVisits=638618, meanQ=17.661780, numObservations: 5
action 3, numVisits=4, meanQ=8.497500, numObservations: 2
action 2, numVisits=5, meanQ=6.196000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.573615 0.811377 0.94522 0.0359868 0.545072 0.854821 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 229
Initial state: 0 0.663533 0.862774 0.481227 0.601298 0.54235 0.862738 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 667584 episodes
GETTING ACTION FROM:
action 1, numVisits=667578, meanQ=17.741665, numObservations: 4
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.663533 0.862774 0.481227 0.601298 0.54235 0.862738 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 230
Initial state: 0 0.640174 0.812019 0.476481 0.638885 0.54006 0.823951 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 670085 episodes
GETTING ACTION FROM:
action 1, numVisits=670080, meanQ=17.850532, numObservations: 3
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.640174 0.812019 0.476481 0.638885 0.54006 0.823951 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 231
Initial state: 0 0.517416 0.878536 0.299522 0.769857 0.574396 0.803467 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 676155 episodes
GETTING ACTION FROM:
action 3, numVisits=676146, meanQ=17.869810, numObservations: 3
action 1, numVisits=6, meanQ=13.665000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.517416 0.878536 0.299522 0.769857 0.574396 0.803467 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 232
Initial state: 0 0.585247 0.851385 0.645993 0.803197 0.88271 0.188303 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 669090 episodes
GETTING ACTION FROM:
action 1, numVisits=669086, meanQ=17.839981, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.585247 0.851385 0.645993 0.803197 0.88271 0.188303 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 233
Initial state: 0 0.019718 0.310258 0.546688 0.88462 0.500106 0.806544 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666831 episodes
GETTING ACTION FROM:
action 2, numVisits=666813, meanQ=17.759556, numObservations: 4
action 1, numVisits=15, meanQ=11.050673, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.019718 0.310258 0.546688 0.88462 0.500106 0.806544 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 234
Initial state: 0 0.29163 0.825689 0.621057 0.860239 0.649562 0.856777 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 677213 episodes
GETTING ACTION FROM:
action 2, numVisits=677208, meanQ=17.838825, numObservations: 3
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.29163 0.825689 0.621057 0.860239 0.649562 0.856777 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 235
Initial state: 0 0.528532 0.842557 0.741868 0.544605 0.564543 0.81572 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 659834 episodes
GETTING ACTION FROM:
action 2, numVisits=659826, meanQ=17.838429, numObservations: 5
action 1, numVisits=5, meanQ=4.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.528532 0.842557 0.741868 0.544605 0.564543 0.81572 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 236
Initial state: 0 0.712051 0.34639 0.684938 0.847856 0.607242 0.836155 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 662081 episodes
GETTING ACTION FROM:
action 2, numVisits=662071, meanQ=17.778462, numObservations: 5
action 1, numVisits=5, meanQ=13.196000, numObservations: 2
action 3, numVisits=3, meanQ=12.333333, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.712051 0.34639 0.684938 0.847856 0.607242 0.836155 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 237
Initial state: 0 0.616958 0.880581 0.673549 0.800445 0.855727 0.411731 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 660244 episodes
GETTING ACTION FROM:
action 2, numVisits=660226, meanQ=17.731764, numObservations: 5
action 1, numVisits=15, meanQ=11.200680, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.616958 0.880581 0.673549 0.800445 0.855727 0.411731 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 238
Initial state: 0 0.396597 0.246697 0.543981 0.812031 0.657271 0.897472 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 673094 episodes
GETTING ACTION FROM:
action 2, numVisits=673090, meanQ=17.858024, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.396597 0.246697 0.543981 0.812031 0.657271 0.897472 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 239
Initial state: 0 0.563291 0.837373 0.940932 0.580476 0.682539 0.85 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 622461 episodes
GETTING ACTION FROM:
action 3, numVisits=622457, meanQ=17.450939, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.563291 0.837373 0.940932 0.580476 0.682539 0.85 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=87336, meanQ=20.987109, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 771173 episodes
GETTING ACTION FROM:
action -1, numVisits=858508, meanQ=5.598009, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: -1
Next state: 0 0.563291 0.837373 0.940932 0.580476 0.682539 0.85 w: 1
Observation: 0 0.571594 0 0.963138 0 0.7545 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=292892, meanQ=21.692355, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 855084 episodes
GETTING ACTION FROM:
action 2, numVisits=1147976, meanQ=19.586891, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.563291 0.837373 0.940932 0.580476 0.682539 0.85 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=40392, meanQ=21.487870, numObservations: 3
action 2, numVisits=5, meanQ=18.598000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 882426 episodes
GETTING ACTION FROM:
action 2, numVisits=329292, meanQ=18.576187, numObservations: 5
action 1, numVisits=593531, meanQ=18.451050, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.563291 0.837373 0.940932 0.580476 0.682539 0.85 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -20.5737
Run # 240
Initial state: 0 0.517485 0.814546 0.625128 0.882604 0.921342 0.769088 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 663149 episodes
GETTING ACTION FROM:
action 2, numVisits=663144, meanQ=17.717091, numObservations: 5
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.517485 0.814546 0.625128 0.882604 0.921342 0.769088 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 241
Initial state: 0 0.58858 0.890633 0.54859 0.805744 0.385713 0.672323 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 663804 episodes
GETTING ACTION FROM:
action 2, numVisits=663796, meanQ=17.884084, numObservations: 5
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action 3, numVisits=4, meanQ=8.497500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.58858 0.890633 0.54859 0.805744 0.385713 0.672323 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 242
Initial state: 0 0.672882 0.846862 0.53374 0.891056 0.243856 0.647638 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 662148 episodes
GETTING ACTION FROM:
action 3, numVisits=662141, meanQ=17.863291, numObservations: 5
action 1, numVisits=4, meanQ=9.502525, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.672882 0.846862 0.53374 0.891056 0.243856 0.647638 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=92834, meanQ=23.208617, numObservations: 4
action 2, numVisits=36, meanQ=21.693892, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 854164 episodes
GETTING ACTION FROM:
action 1, numVisits=946894, meanQ=18.892902, numObservations: 4
action 2, numVisits=140, meanQ=18.062644, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.672882 0.846862 0.53374 0.891056 0.243856 0.647638 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 243
Initial state: 0 0.600743 0.898396 0.128461 0.441428 0.546331 0.836067 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 661262 episodes
GETTING ACTION FROM:
action 1, numVisits=661253, meanQ=17.780131, numObservations: 5
action 2, numVisits=5, meanQ=7.396020, numObservations: 3
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.600743 0.898396 0.128461 0.441428 0.546331 0.836067 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 244
Initial state: 0 0.64496 0.878994 0.57065 0.890607 0.139331 0.873376 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 655298 episodes
GETTING ACTION FROM:
action 2, numVisits=655291, meanQ=17.768069, numObservations: 5
action 1, numVisits=4, meanQ=9.997525, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.64496 0.878994 0.57065 0.890607 0.139331 0.873376 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 245
Initial state: 0 0.600738 0.886141 0.499777 0.909616 0.513844 0.879134 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 660013 episodes
GETTING ACTION FROM:
action 1, numVisits=660007, meanQ=17.747684, numObservations: 5
action 2, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.600738 0.886141 0.499777 0.909616 0.513844 0.879134 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 246
Initial state: 0 0.59341 0.812123 0.610749 0.818083 0.335112 0.664185 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 463434 episodes
GETTING ACTION FROM:
action -1, numVisits=463430, meanQ=15.637809, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.59341 0.812123 0.610749 0.818083 0.335112 0.664185 w: 1
Observation: 0 0.526998 0 0.648163 0 0.399354 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=463416, meanQ=17.762716, numObservations: 4
action 2, numVisits=10, meanQ=10.799000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 738252 episodes
GETTING ACTION FROM:
action 3, numVisits=1201668, meanQ=17.432086, numObservations: 4
action 2, numVisits=10, meanQ=10.799000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.59341 0.812123 0.610749 0.818083 0.335112 0.664185 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=193693, meanQ=23.155671, numObservations: 3
action 1, numVisits=7, meanQ=20.141429, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 866943 episodes
GETTING ACTION FROM:
action 2, numVisits=1060630, meanQ=19.835168, numObservations: 3
action 1, numVisits=13, meanQ=16.537692, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.59341 0.812123 0.610749 0.818083 0.335112 0.664185 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 17.5624
Run # 247
Initial state: 0 0.581845 0.814148 0.504597 0.877777 0.846584 0.396845 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 660273 episodes
GETTING ACTION FROM:
action 3, numVisits=660268, meanQ=17.735010, numObservations: 5
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.581845 0.814148 0.504597 0.877777 0.846584 0.396845 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 248
Initial state: 0 0.656212 0.857669 0.55934 0.911095 0.64496 0.85915 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 663658 episodes
GETTING ACTION FROM:
action 2, numVisits=663651, meanQ=17.839218, numObservations: 5
action 3, numVisits=3, meanQ=12.333333, numObservations: 3
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 2 0.656212 0.857669 0.55934 0.911095 0.64496 0.85915 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 249
Initial state: 0 0.419962 0.0424575 0.683051 0.87202 0.519198 0.882038 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 472426 episodes
GETTING ACTION FROM:
action 0, numVisits=472420, meanQ=20.001059, numObservations: 3
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.419962 0.0424575 0.683051 0.87202 0.519198 0.882038 w: 1
Observation: 0 0 0 0 0.837396 0 0.840014 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=161848, meanQ=22.555228, numObservations: 5
action 2, numVisits=11, meanQ=8.817273, numObservations: 2
action 1, numVisits=4, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 725610 episodes
GETTING ACTION FROM:
action 3, numVisits=887458, meanQ=18.614800, numObservations: 5
action 2, numVisits=11, meanQ=8.817273, numObservations: 2
action 1, numVisits=4, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.419962 0.0424575 0.683051 0.87202 0.519198 0.882038 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 250
Initial state: 0 0.377212 0.138104 0.667025 0.879872 0.585356 0.814212 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 651295 episodes
GETTING ACTION FROM:
action 2, numVisits=651288, meanQ=17.556794, numObservations: 4
action 3, numVisits=4, meanQ=8.497500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.377212 0.138104 0.667025 0.879872 0.585356 0.814212 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 251
Initial state: 0 0.500561 0.884536 0.131244 0.468983 0.689647 0.819826 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 668430 episodes
GETTING ACTION FROM:
action 1, numVisits=668426, meanQ=17.924251, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.500561 0.884536 0.131244 0.468983 0.689647 0.819826 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 252
Initial state: 0 0.651262 0.818833 0.619187 0.812666 0.293712 0.370093 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 672159 episodes
GETTING ACTION FROM:
action 2, numVisits=672148, meanQ=17.769502, numObservations: 3
action 1, numVisits=7, meanQ=10.998586, numObservations: 2
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.651262 0.818833 0.619187 0.812666 0.293712 0.370093 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 253
Initial state: 0 0.54243 0.813507 0.55194 0.862209 0.153422 0.636297 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 672469 episodes
GETTING ACTION FROM:
action 2, numVisits=672463, meanQ=17.867486, numObservations: 4
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.54243 0.813507 0.55194 0.862209 0.153422 0.636297 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 254
Initial state: 0 0.533516 0.884182 0.117223 0.659311 0.558803 0.849966 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 673788 episodes
GETTING ACTION FROM:
action 1, numVisits=673780, meanQ=17.748440, numObservations: 3
action 2, numVisits=4, meanQ=10.495000, numObservations: 4
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.533516 0.884182 0.117223 0.659311 0.558803 0.849966 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 255
Initial state: 0 0.541702 0.816125 0.930454 0.541976 0.61622 0.845496 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 672190 episodes
GETTING ACTION FROM:
action 2, numVisits=672181, meanQ=17.771996, numObservations: 4
action 3, numVisits=6, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.541702 0.816125 0.930454 0.541976 0.61622 0.845496 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 256
Initial state: 0 0.95624 0.465387 0.673269 0.867844 0.621946 0.847831 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 657568 episodes
GETTING ACTION FROM:
action 3, numVisits=657556, meanQ=17.749854, numObservations: 5
action 2, numVisits=8, meanQ=11.343750, numObservations: 4
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.95624 0.465387 0.673269 0.867844 0.621946 0.847831 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 257
Initial state: 0 0.896674 0.528934 0.653969 0.809156 0.648387 0.828432 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 661126 episodes
GETTING ACTION FROM:
action 1, numVisits=660261, meanQ=17.758513, numObservations: 5
action 2, numVisits=861, meanQ=17.222078, numObservations: 4
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 2 0.896674 0.528934 0.653969 0.809156 0.648387 0.828432 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 258
Initial state: 0 0.689212 0.828038 0.641162 0.857697 0.491931 0.67206 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 644135 episodes
GETTING ACTION FROM:
action 3, numVisits=644089, meanQ=17.597726, numObservations: 4
action 1, numVisits=40, meanQ=16.299257, numObservations: 4
action 2, numVisits=4, meanQ=8.497500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.689212 0.828038 0.641162 0.857697 0.491931 0.67206 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=15777, meanQ=22.410269, numObservations: 3
action 2, numVisits=3, meanQ=14.996667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 859224 episodes
GETTING ACTION FROM:
action 1, numVisits=874999, meanQ=18.963850, numObservations: 3
action 2, numVisits=5, meanQ=11.598000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.689212 0.828038 0.641162 0.857697 0.491931 0.67206 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 259
Initial state: 0 0.677409 0.802935 0.818718 0.0755057 0.662987 0.836455 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 663156 episodes
GETTING ACTION FROM:
action 1, numVisits=663152, meanQ=17.859850, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.677409 0.802935 0.818718 0.0755057 0.662987 0.836455 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 260
Initial state: 0 0.692323 0.856004 0.739142 0.95429 0.691319 0.813905 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 671695 episodes
GETTING ACTION FROM:
action 2, numVisits=671691, meanQ=17.731724, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.692323 0.856004 0.739142 0.95429 0.691319 0.813905 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 261
Initial state: 0 0.646904 0.866898 0.56466 0.839306 0.252657 0.656636 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 670622 episodes
GETTING ACTION FROM:
action 1, numVisits=670618, meanQ=17.743756, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.646904 0.866898 0.56466 0.839306 0.252657 0.656636 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 262
Initial state: 0 0.524409 0.857612 0.752988 0.703434 0.557018 0.86226 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 658642 episodes
GETTING ACTION FROM:
action 1, numVisits=658637, meanQ=17.757078, numObservations: 5
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.524409 0.857612 0.752988 0.703434 0.557018 0.86226 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 263
Initial state: 0 0.22348 0.7796 0.622227 0.836517 0.632926 0.861211 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 676206 episodes
GETTING ACTION FROM:
action 1, numVisits=676195, meanQ=17.764183, numObservations: 3
action 2, numVisits=8, meanQ=8.998775, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.22348 0.7796 0.622227 0.836517 0.632926 0.861211 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=111141, meanQ=23.158719, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 857275 episodes
GETTING ACTION FROM:
action 3, numVisits=968416, meanQ=19.238391, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.22348 0.7796 0.622227 0.836517 0.632926 0.861211 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 264
Initial state: 0 0.528781 0.951346 0.577501 0.839045 0.560964 0.874614 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 678506 episodes
GETTING ACTION FROM:
action 2, numVisits=678502, meanQ=17.875865, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.528781 0.951346 0.577501 0.839045 0.560964 0.874614 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 265
Initial state: 0 0.694114 0.821678 0.613418 0.846163 0.581189 0.181182 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 673340 episodes
GETTING ACTION FROM:
action 3, numVisits=673336, meanQ=17.812291, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.694114 0.821678 0.613418 0.846163 0.581189 0.181182 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 266
Initial state: 0 0.577359 0.887305 0.680936 0.895631 0.822359 0.758276 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 664224 episodes
GETTING ACTION FROM:
action 1, numVisits=664218, meanQ=17.740998, numObservations: 5
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.577359 0.887305 0.680936 0.895631 0.822359 0.758276 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 267
Initial state: 0 0.543372 0.834556 0.699056 0.878791 0.110509 0.383902 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 667200 episodes
GETTING ACTION FROM:
action 1, numVisits=667193, meanQ=17.866437, numObservations: 5
action 2, numVisits=4, meanQ=8.497500, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.543372 0.834556 0.699056 0.878791 0.110509 0.383902 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=14142, meanQ=20.493542, numObservations: 5
action 2, numVisits=3, meanQ=14.996667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 845593 episodes
GETTING ACTION FROM:
action 3, numVisits=859733, meanQ=19.090617, numObservations: 5
action 2, numVisits=5, meanQ=11.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.543372 0.834556 0.699056 0.878791 0.110509 0.383902 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=12705, meanQ=22.521012, numObservations: 4
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 866280 episodes
GETTING ACTION FROM:
action 1, numVisits=878985, meanQ=18.552426, numObservations: 5
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.543372 0.834556 0.699056 0.878791 0.110509 0.383902 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 268
Initial state: 0 0.162368 0.756889 0.581045 0.899447 0.55032 0.860408 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666299 episodes
GETTING ACTION FROM:
action 1, numVisits=666294, meanQ=17.772566, numObservations: 4
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.162368 0.756889 0.581045 0.899447 0.55032 0.860408 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 269
Initial state: 0 0.558201 0.871893 0.541314 0.832 0.82521 0.98688 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 658855 episodes
GETTING ACTION FROM:
action 2, numVisits=658850, meanQ=17.754189, numObservations: 5
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.558201 0.871893 0.541314 0.832 0.82521 0.98688 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 270
Initial state: 0 0.748571 0.967354 0.543504 0.883305 0.514908 0.865007 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 670395 episodes
GETTING ACTION FROM:
action 2, numVisits=670387, meanQ=17.769950, numObservations: 4
action 3, numVisits=5, meanQ=6.196000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.748571 0.967354 0.543504 0.883305 0.514908 0.865007 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 271
Initial state: 0 0.5209 0.888759 0.625451 0.847808 0.301573 0.0777609 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 664437 episodes
GETTING ACTION FROM:
action 1, numVisits=664432, meanQ=17.844129, numObservations: 5
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.5209 0.888759 0.625451 0.847808 0.301573 0.0777609 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 272
Initial state: 0 0.62701 0.841527 0.65207 0.848725 0.825069 0.0141784 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 664994 episodes
GETTING ACTION FROM:
action 1, numVisits=664988, meanQ=17.830636, numObservations: 4
action 2, numVisits=3, meanQ=12.333333, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.62701 0.841527 0.65207 0.848725 0.825069 0.0141784 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 273
Initial state: 0 0.532591 0.857534 0.64341 0.842914 0.109794 0.7217 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 656703 episodes
GETTING ACTION FROM:
action 1, numVisits=656699, meanQ=17.735927, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.532591 0.857534 0.64341 0.842914 0.109794 0.7217 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 274
Initial state: 0 0.794139 0.150651 0.683735 0.894888 0.683639 0.820884 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 660445 episodes
GETTING ACTION FROM:
action 2, numVisits=660439, meanQ=17.861258, numObservations: 5
action 1, numVisits=3, meanQ=3.330000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.794139 0.150651 0.683735 0.894888 0.683639 0.820884 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=49219, meanQ=18.496363, numObservations: 3
action 3, numVisits=5, meanQ=11.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 788683 episodes
GETTING ACTION FROM:
action 2, numVisits=837902, meanQ=18.032431, numObservations: 4
action 3, numVisits=5, meanQ=11.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.794139 0.150651 0.683735 0.894888 0.683639 0.820884 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=20278, meanQ=19.111496, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 806843 episodes
GETTING ACTION FROM:
action 2, numVisits=827121, meanQ=17.692988, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.794139 0.150651 0.683735 0.894888 0.683639 0.820884 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 275
Initial state: 0 0.528746 0.813972 0.511121 0.811832 0.244418 0.678549 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 662843 episodes
GETTING ACTION FROM:
action 2, numVisits=662826, meanQ=17.847245, numObservations: 5
action 1, numVisits=11, meanQ=8.179109, numObservations: 4
action 3, numVisits=4, meanQ=6.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.528746 0.813972 0.511121 0.811832 0.244418 0.678549 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 276
Initial state: 0 0.911581 0.394287 0.695052 0.831961 0.601364 0.832332 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 675262 episodes
GETTING ACTION FROM:
action 3, numVisits=675258, meanQ=17.746623, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.911581 0.394287 0.695052 0.831961 0.601364 0.832332 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 277
Initial state: 0 0.688335 0.861978 0.653114 0.825812 0.311985 0.000351596 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 669666 episodes
GETTING ACTION FROM:
action 2, numVisits=669645, meanQ=17.871994, numObservations: 4
action 1, numVisits=17, meanQ=15.115882, numObservations: 4
action 3, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.688335 0.861978 0.653114 0.825812 0.311985 0.000351596 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 278
Initial state: 0 0.572269 0.859537 0.432243 0.794882 0.675208 0.841491 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 656524 episodes
GETTING ACTION FROM:
action 3, numVisits=656512, meanQ=17.769675, numObservations: 5
action 2, numVisits=6, meanQ=10.495000, numObservations: 3
action 1, numVisits=4, meanQ=8.497500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.572269 0.859537 0.432243 0.794882 0.675208 0.841491 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 279
Initial state: 0 0.238839 0.70759 0.511797 0.836362 0.517888 0.886355 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 667025 episodes
GETTING ACTION FROM:
action 2, numVisits=667009, meanQ=17.753046, numObservations: 4
action 3, numVisits=8, meanQ=12.872500, numObservations: 2
action 1, numVisits=6, meanQ=12.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.238839 0.70759 0.511797 0.836362 0.517888 0.886355 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 280
Initial state: 0 0.638707 0.886099 0.804027 0.535792 0.690299 0.865323 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 669291 episodes
GETTING ACTION FROM:
action 3, numVisits=669280, meanQ=17.759729, numObservations: 4
action 1, numVisits=8, meanQ=12.623762, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.638707 0.886099 0.804027 0.535792 0.690299 0.865323 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 281
Initial state: 0 0.758725 0.401089 0.634591 0.856163 0.510767 0.83955 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 673374 episodes
GETTING ACTION FROM:
action 2, numVisits=673369, meanQ=17.735674, numObservations: 4
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.758725 0.401089 0.634591 0.856163 0.510767 0.83955 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 282
Initial state: 0 0.699471 0.827735 0.602141 0.844028 0.923383 0.860281 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 671867 episodes
GETTING ACTION FROM:
action 2, numVisits=671793, meanQ=18.102660, numObservations: 4
action 3, numVisits=61, meanQ=13.529838, numObservations: 4
action 1, numVisits=11, meanQ=12.364555, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.699471 0.827735 0.602141 0.844028 0.923383 0.860281 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 283
Initial state: 0 0.477524 0.406506 0.578198 0.806763 0.620829 0.845637 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 672834 episodes
GETTING ACTION FROM:
action 3, numVisits=672829, meanQ=18.121979, numObservations: 4
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.477524 0.406506 0.578198 0.806763 0.620829 0.845637 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 284
Initial state: 0 0.649659 0.88146 0.373237 0.216915 0.645338 0.821469 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 674272 episodes
GETTING ACTION FROM:
action 1, numVisits=674267, meanQ=17.831992, numObservations: 4
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.649659 0.88146 0.373237 0.216915 0.645338 0.821469 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 285
Initial state: 0 0.582876 0.631272 0.60309 0.851453 0.54542 0.890214 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 671004 episodes
GETTING ACTION FROM:
action 2, numVisits=670999, meanQ=17.871037, numObservations: 4
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.582876 0.631272 0.60309 0.851453 0.54542 0.890214 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 286
Initial state: 0 0.644783 0.803107 0.301727 0.985659 0.524193 0.881151 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 660504 episodes
GETTING ACTION FROM:
action 3, numVisits=660500, meanQ=17.820394, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.644783 0.803107 0.301727 0.985659 0.524193 0.881151 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=48784, meanQ=18.595891, numObservations: 4
action 1, numVisits=9, meanQ=14.108889, numObservations: 4
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 780926 episodes
GETTING ACTION FROM:
action 3, numVisits=829710, meanQ=17.977719, numObservations: 5
action 1, numVisits=9, meanQ=14.108889, numObservations: 4
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.644783 0.803107 0.301727 0.985659 0.524193 0.881151 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 287
Initial state: 0 0.549685 0.891469 0.633838 0.85895 0.333179 0.25137 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666122 episodes
GETTING ACTION FROM:
action 1, numVisits=666116, meanQ=17.861626, numObservations: 5
action 2, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.549685 0.891469 0.633838 0.85895 0.333179 0.25137 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=49079, meanQ=18.568798, numObservations: 4
action 3, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 778982 episodes
GETTING ACTION FROM:
action 1, numVisits=828061, meanQ=17.415336, numObservations: 5
action 3, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.549685 0.891469 0.633838 0.85895 0.333179 0.25137 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 288
Initial state: 0 0.52944 0.897239 0.186307 0.238854 0.685411 0.815964 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666895 episodes
GETTING ACTION FROM:
action 3, numVisits=666891, meanQ=17.833421, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.52944 0.897239 0.186307 0.238854 0.685411 0.815964 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 289
Initial state: 0 0.600675 0.855849 0.563135 0.863209 0.46678 0.557277 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 452512 episodes
GETTING ACTION FROM:
action -1, numVisits=452508, meanQ=15.405507, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.600675 0.855849 0.563135 0.863209 0.46678 0.557277 w: 1
Observation: 0 0.649702 0 0.656579 0 0.408936 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=452485, meanQ=17.574384, numObservations: 4
action 1, numVisits=18, meanQ=15.388894, numObservations: 3
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 709141 episodes
GETTING ACTION FROM:
action 3, numVisits=1161626, meanQ=17.578501, numObservations: 4
action 1, numVisits=18, meanQ=15.388894, numObservations: 3
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.600675 0.855849 0.563135 0.863209 0.46678 0.557277 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=186809, meanQ=23.140223, numObservations: 4
action 2, numVisits=15, meanQ=20.266007, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 858633 episodes
GETTING ACTION FROM:
action 1, numVisits=1045373, meanQ=19.473795, numObservations: 4
action 2, numVisits=84, meanQ=18.428335, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.600675 0.855849 0.563135 0.863209 0.46678 0.557277 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=7134, meanQ=22.046727, numObservations: 3
action 1, numVisits=3, meanQ=14.996667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 890021 episodes
GETTING ACTION FROM:
action 2, numVisits=897119, meanQ=18.844704, numObservations: 3
action 1, numVisits=39, meanQ=17.230256, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.600675 0.855849 0.563135 0.863209 0.46678 0.557277 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 1, numVisits=2651, meanQ=20.551400, numObservations: 4
action 3, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 884573 episodes
GETTING ACTION FROM:
action 1, numVisits=887224, meanQ=19.343870, numObservations: 4
action 3, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.600675 0.855849 0.563135 0.863209 0.46678 0.557277 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9.29271
Run # 290
Initial state: 0 0.665649 0.858254 0.85616 0.859529 0.692118 0.894931 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 667521 episodes
GETTING ACTION FROM:
action 2, numVisits=667516, meanQ=17.870211, numObservations: 5
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.665649 0.858254 0.85616 0.859529 0.692118 0.894931 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 291
Initial state: 0 0.448887 0.555156 0.610813 0.886563 0.623866 0.858452 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 636425 episodes
GETTING ACTION FROM:
action 3, numVisits=636411, meanQ=17.599454, numObservations: 5
action 2, numVisits=10, meanQ=14.701010, numObservations: 3
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.448887 0.555156 0.610813 0.886563 0.623866 0.858452 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=46137, meanQ=15.207551, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 821000 episodes
GETTING ACTION FROM:
action 1, numVisits=469058, meanQ=18.762502, numObservations: 4
action 0, numVisits=398080, meanQ=4.160373, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.448887 0.555156 0.610813 0.886563 0.623866 0.858452 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=7184, meanQ=22.660222, numObservations: 4
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 857254 episodes
GETTING ACTION FROM:
action 3, numVisits=864438, meanQ=18.939668, numObservations: 5
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.448887 0.555156 0.610813 0.886563 0.623866 0.858452 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 292
Initial state: 0 0.58627 0.802589 0.389345 0.180229 0.542935 0.870703 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666711 episodes
GETTING ACTION FROM:
action 2, numVisits=666703, meanQ=17.772413, numObservations: 4
action 1, numVisits=5, meanQ=13.196000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.58627 0.802589 0.389345 0.180229 0.542935 0.870703 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=109396, meanQ=23.166696, numObservations: 5
action 1, numVisits=8, meanQ=20.623750, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 843378 episodes
GETTING ACTION FROM:
action 3, numVisits=952758, meanQ=19.593734, numObservations: 5
action 1, numVisits=24, meanQ=17.041250, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.58627 0.802589 0.389345 0.180229 0.542935 0.870703 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 293
Initial state: 0 0.653862 0.635451 0.519393 0.804538 0.560711 0.822528 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 670829 episodes
GETTING ACTION FROM:
action 2, numVisits=670821, meanQ=17.838896, numObservations: 4
action 1, numVisits=5, meanQ=13.196000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.653862 0.635451 0.519393 0.804538 0.560711 0.822528 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 294
Initial state: 0 0.567586 0.846733 0.800277 0.763997 0.512623 0.844735 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 675001 episodes
GETTING ACTION FROM:
action 1, numVisits=674996, meanQ=17.867717, numObservations: 3
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.567586 0.846733 0.800277 0.763997 0.512623 0.844735 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=50275, meanQ=18.584052, numObservations: 4
action 3, numVisits=15, meanQ=15.449333, numObservations: 3
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 788925 episodes
GETTING ACTION FROM:
action 1, numVisits=839200, meanQ=17.388979, numObservations: 5
action 3, numVisits=15, meanQ=15.449333, numObservations: 3
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.567586 0.846733 0.800277 0.763997 0.512623 0.844735 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 295
Initial state: 0 0.677397 0.857995 0.622766 0.807632 0.0349676 0.110848 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 670766 episodes
GETTING ACTION FROM:
action 2, numVisits=670762, meanQ=17.737841, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.677397 0.857995 0.622766 0.807632 0.0349676 0.110848 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 296
Initial state: 0 0.65804 0.82233 0.570066 0.816642 0.00657552 0.543136 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 622686 episodes
GETTING ACTION FROM:
action 3, numVisits=622680, meanQ=17.492164, numObservations: 4
action 1, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.65804 0.82233 0.570066 0.816642 0.00657552 0.543136 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=102442, meanQ=20.926843, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 770354 episodes
GETTING ACTION FROM:
action 0, numVisits=872796, meanQ=5.723724, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.65804 0.82233 0.570066 0.816642 0.00657552 0.543136 w: 1
Observation: 0 0 0.88075 0 0.751707 0 0.535487 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=300268, meanQ=22.043447, numObservations: 4
action 2, numVisits=3, meanQ=14.996667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 855571 episodes
GETTING ACTION FROM:
action 1, numVisits=1155839, meanQ=19.798248, numObservations: 4
action 2, numVisits=3, meanQ=14.996667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.65804 0.82233 0.570066 0.816642 0.00657552 0.543136 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 17.5424
Run # 297
Initial state: 0 0.626333 0.836204 0.247413 0.653514 0.575168 0.891577 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 656194 episodes
GETTING ACTION FROM:
action 3, numVisits=656173, meanQ=17.733750, numObservations: 5
action 1, numVisits=11, meanQ=9.543636, numObservations: 4
action 2, numVisits=8, meanQ=9.247513, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.626333 0.836204 0.247413 0.653514 0.575168 0.891577 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 298
Initial state: 0 0.584175 0.813776 0.453744 0.568052 0.6375 0.811571 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 670016 episodes
GETTING ACTION FROM:
action 2, numVisits=670011, meanQ=17.808238, numObservations: 4
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.584175 0.813776 0.453744 0.568052 0.6375 0.811571 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=93591, meanQ=23.295860, numObservations: 4
action 1, numVisits=15, meanQ=20.398667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 855588 episodes
GETTING ACTION FROM:
action 3, numVisits=949136, meanQ=18.793254, numObservations: 4
action 1, numVisits=58, meanQ=17.629138, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.584175 0.813776 0.453744 0.568052 0.6375 0.811571 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 299
Initial state: 0 0.591008 0.884984 0.88686 0.896824 0.580826 0.877254 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 671131 episodes
GETTING ACTION FROM:
action 2, numVisits=671123, meanQ=17.829931, numObservations: 4
action 1, numVisits=4, meanQ=10.495000, numObservations: 2
action 3, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 2 0.591008 0.884984 0.88686 0.896824 0.580826 0.877254 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 300
Initial state: 0 0.4884 0.046635 0.605356 0.842304 0.517272 0.818872 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 668192 episodes
GETTING ACTION FROM:
action 1, numVisits=668181, meanQ=17.759114, numObservations: 4
action 2, numVisits=6, meanQ=9.163333, numObservations: 3
action 3, numVisits=3, meanQ=2.033333, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 0 0.4884 0.046635 0.605356 0.842304 0.517272 0.818872 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=109089, meanQ=23.181171, numObservations: 5
action 3, numVisits=40, meanQ=21.974250, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 856418 episodes
GETTING ACTION FROM:
action 2, numVisits=965442, meanQ=19.704401, numObservations: 5
action 3, numVisits=105, meanQ=18.971048, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.4884 0.046635 0.605356 0.842304 0.517272 0.818872 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 301
Initial state: 0 0.305088 0.846347 0.539725 0.869325 0.527356 0.815209 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 658607 episodes
GETTING ACTION FROM:
action 3, numVisits=658603, meanQ=17.734976, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.305088 0.846347 0.539725 0.869325 0.527356 0.815209 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 302
Initial state: 0 0.505348 0.88447 0.2576 0.0197331 0.569898 0.832106 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 662765 episodes
GETTING ACTION FROM:
action 2, numVisits=662757, meanQ=17.739613, numObservations: 5
action 1, numVisits=4, meanQ=10.495000, numObservations: 2
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.505348 0.88447 0.2576 0.0197331 0.569898 0.832106 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=75889, meanQ=23.502868, numObservations: 3
action 3, numVisits=7, meanQ=20.141429, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 870805 episodes
GETTING ACTION FROM:
action 1, numVisits=946688, meanQ=19.598314, numObservations: 3
action 3, numVisits=13, meanQ=16.537692, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.505348 0.88447 0.2576 0.0197331 0.569898 0.832106 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 303
Initial state: 0 0.539521 0.821156 0.648557 0.849871 0.91646 0.0589446 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666255 episodes
GETTING ACTION FROM:
action 3, numVisits=666250, meanQ=17.818397, numObservations: 4
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.539521 0.821156 0.648557 0.849871 0.91646 0.0589446 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 304
Initial state: 0 0.126075 0.589334 0.517224 0.890356 0.586728 0.895541 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 668735 episodes
GETTING ACTION FROM:
action 2, numVisits=668728, meanQ=17.772660, numObservations: 4
action 1, numVisits=4, meanQ=10.495000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.126075 0.589334 0.517224 0.890356 0.586728 0.895541 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 305
Initial state: 0 0.326112 0.315155 0.534303 0.870225 0.642843 0.824602 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 662902 episodes
GETTING ACTION FROM:
action 2, numVisits=662897, meanQ=18.099643, numObservations: 5
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.326112 0.315155 0.534303 0.870225 0.642843 0.824602 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 306
Initial state: 0 0.540979 0.875653 0.567137 0.867879 0.777887 0.969141 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 660975 episodes
GETTING ACTION FROM:
action 1, numVisits=660970, meanQ=17.725660, numObservations: 5
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.540979 0.875653 0.567137 0.867879 0.777887 0.969141 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 307
Initial state: 0 0.451729 0.624245 0.573696 0.832432 0.528187 0.865901 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 665432 episodes
GETTING ACTION FROM:
action 1, numVisits=665425, meanQ=17.837737, numObservations: 4
action 3, numVisits=4, meanQ=8.497500, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.451729 0.624245 0.573696 0.832432 0.528187 0.865901 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=109105, meanQ=23.174395, numObservations: 5
action 2, numVisits=13, meanQ=19.844615, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 840649 episodes
GETTING ACTION FROM:
action 3, numVisits=949753, meanQ=19.619910, numObservations: 5
action 2, numVisits=14, meanQ=17.641429, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.451729 0.624245 0.573696 0.832432 0.528187 0.865901 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 308
Initial state: 0 0.696295 0.896578 0.514551 0.595739 0.520205 0.859621 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 663540 episodes
GETTING ACTION FROM:
action 3, numVisits=663536, meanQ=17.729019, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.696295 0.896578 0.514551 0.595739 0.520205 0.859621 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 309
Initial state: 0 0.564255 0.836925 0.441046 0.223231 0.68624 0.8614 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 657458 episodes
GETTING ACTION FROM:
action 3, numVisits=657453, meanQ=17.814829, numObservations: 5
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.564255 0.836925 0.441046 0.223231 0.68624 0.8614 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 310
Initial state: 0 0.675819 0.83878 0.993749 0.0261628 0.519709 0.895743 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 665459 episodes
GETTING ACTION FROM:
action 2, numVisits=665452, meanQ=17.749735, numObservations: 4
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action 3, numVisits=3, meanQ=4.670033, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 2 0.675819 0.83878 0.993749 0.0261628 0.519709 0.895743 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 311
Initial state: 0 0.560057 0.805124 0.365682 0.874936 0.502291 0.816524 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 664561 episodes
GETTING ACTION FROM:
action 2, numVisits=664537, meanQ=17.871876, numObservations: 5
action 1, numVisits=21, meanQ=13.380005, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.560057 0.805124 0.365682 0.874936 0.502291 0.816524 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=33001, meanQ=22.390759, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 841410 episodes
GETTING ACTION FROM:
action 3, numVisits=874411, meanQ=18.785413, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.560057 0.805124 0.365682 0.874936 0.502291 0.816524 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 312
Initial state: 0 0.528951 0.894365 0.834181 0.481235 0.544827 0.847711 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 661340 episodes
GETTING ACTION FROM:
action 3, numVisits=661333, meanQ=17.830826, numObservations: 5
action 2, numVisits=4, meanQ=8.497500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.528951 0.894365 0.834181 0.481235 0.544827 0.847711 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 313
Initial state: 0 0.653746 0.882138 0.5116 0.883677 0.680157 0.927447 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 662115 episodes
GETTING ACTION FROM:
action 3, numVisits=662111, meanQ=17.828516, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.653746 0.882138 0.5116 0.883677 0.680157 0.927447 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 314
Initial state: 0 0.68315 0.827535 0.658338 0.801623 0.190329 0.159513 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 660342 episodes
GETTING ACTION FROM:
action 1, numVisits=660337, meanQ=17.777546, numObservations: 5
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.68315 0.827535 0.658338 0.801623 0.190329 0.159513 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 315
Initial state: 0 0.547195 0.882771 0.586123 0.80004 0.0340981 0.635576 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 661776 episodes
GETTING ACTION FROM:
action 1, numVisits=661768, meanQ=17.733290, numObservations: 5
action 3, numVisits=4, meanQ=10.495000, numObservations: 2
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.547195 0.882771 0.586123 0.80004 0.0340981 0.635576 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 316
Initial state: 0 0.595428 0.881465 0.615516 0.850883 0.94511 0.079894 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 663487 episodes
GETTING ACTION FROM:
action 2, numVisits=663478, meanQ=17.843955, numObservations: 5
action 1, numVisits=5, meanQ=11.598000, numObservations: 3
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.595428 0.881465 0.615516 0.850883 0.94511 0.079894 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 317
Initial state: 0 0.621284 0.890696 0.355257 0.780781 0.575802 0.836095 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 668904 episodes
GETTING ACTION FROM:
action 1, numVisits=668895, meanQ=17.817821, numObservations: 4
action 2, numVisits=6, meanQ=13.665000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.621284 0.890696 0.355257 0.780781 0.575802 0.836095 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 318
Initial state: 0 0.55495 0.883318 0.552686 0.886721 0.926086 0.454701 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 461765 episodes
GETTING ACTION FROM:
action -1, numVisits=461758, meanQ=15.573770, numObservations: 1
action 1, numVisits=4, meanQ=-0.252500, numObservations: 2
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: -1
Next state: 0 0.55495 0.883318 0.552686 0.886721 0.926086 0.454701 w: 1
Observation: 0 0.618726 0 0.469322 0 0.830242 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=461753, meanQ=17.769114, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 737348 episodes
GETTING ACTION FROM:
action 2, numVisits=1199101, meanQ=17.792621, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.55495 0.883318 0.552686 0.886721 0.926086 0.454701 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 319
Initial state: 0 0.527505 0.896309 0.972005 0.360194 0.608285 0.884623 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 669497 episodes
GETTING ACTION FROM:
action 1, numVisits=669491, meanQ=17.751823, numObservations: 4
action 2, numVisits=3, meanQ=3.330000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.527505 0.896309 0.972005 0.360194 0.608285 0.884623 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 320
Initial state: 0 0.592172 0.811545 0.661768 0.456157 0.567558 0.867142 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 670349 episodes
GETTING ACTION FROM:
action 1, numVisits=670344, meanQ=17.833225, numObservations: 4
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.592172 0.811545 0.661768 0.456157 0.567558 0.867142 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=49098, meanQ=18.651036, numObservations: 4
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 792389 episodes
GETTING ACTION FROM:
action 1, numVisits=841487, meanQ=18.053984, numObservations: 4
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.592172 0.811545 0.661768 0.456157 0.567558 0.867142 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 321
Initial state: 0 0.697137 0.873166 0.254615 0.923511 0.601767 0.815838 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 663092 episodes
GETTING ACTION FROM:
action 2, numVisits=663086, meanQ=17.743101, numObservations: 5
action 3, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.697137 0.873166 0.254615 0.923511 0.601767 0.815838 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=32958, meanQ=22.446117, numObservations: 3
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 868526 episodes
GETTING ACTION FROM:
action 3, numVisits=901484, meanQ=18.756325, numObservations: 3
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.697137 0.873166 0.254615 0.923511 0.601767 0.815838 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 322
Initial state: 0 0.659667 0.891247 0.610941 0.855713 0.191849 0.35303 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 674066 episodes
GETTING ACTION FROM:
action 3, numVisits=674062, meanQ=17.867137, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.659667 0.891247 0.610941 0.855713 0.191849 0.35303 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 323
Initial state: 0 0.699491 0.874155 0.603852 0.803073 0.714719 0.7998 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 656476 episodes
GETTING ACTION FROM:
action 2, numVisits=656455, meanQ=17.746812, numObservations: 5
action 3, numVisits=10, meanQ=15.098000, numObservations: 4
action 1, numVisits=9, meanQ=13.887789, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.699491 0.874155 0.603852 0.803073 0.714719 0.7998 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 324
Initial state: 0 0.634432 0.897084 0.693459 0.852206 0.383765 0.539552 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 665238 episodes
GETTING ACTION FROM:
action 1, numVisits=665234, meanQ=17.762217, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.634432 0.897084 0.693459 0.852206 0.383765 0.539552 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 325
Initial state: 0 0.505128 0.849873 0.534282 0.818596 0.629244 0.539316 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 664181 episodes
GETTING ACTION FROM:
action 3, numVisits=664171, meanQ=17.778917, numObservations: 4
action 2, numVisits=6, meanQ=13.665000, numObservations: 2
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.505128 0.849873 0.534282 0.818596 0.629244 0.539316 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=108890, meanQ=23.164866, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 861284 episodes
GETTING ACTION FROM:
action 2, numVisits=970174, meanQ=19.390092, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.505128 0.849873 0.534282 0.818596 0.629244 0.539316 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 326
Initial state: 0 0.612406 0.837018 0.649701 0.832715 0.421655 0.180803 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 661694 episodes
GETTING ACTION FROM:
action 1, numVisits=661686, meanQ=17.838688, numObservations: 5
action 2, numVisits=5, meanQ=10.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.612406 0.837018 0.649701 0.832715 0.421655 0.180803 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 327
Initial state: 0 0.522759 0.857039 0.571158 0.999254 0.602195 0.895552 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 673557 episodes
GETTING ACTION FROM:
action 2, numVisits=673553, meanQ=17.775473, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.522759 0.857039 0.571158 0.999254 0.602195 0.895552 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 328
Initial state: 0 0.588694 0.856617 0.713607 0.39446 0.663584 0.89963 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 680603 episodes
GETTING ACTION FROM:
action 1, numVisits=680589, meanQ=17.836519, numObservations: 3
action 3, numVisits=11, meanQ=6.000918, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.588694 0.856617 0.713607 0.39446 0.663584 0.89963 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 329
Initial state: 0 0.180483 0.841124 0.52084 0.877462 0.653549 0.822396 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 678372 episodes
GETTING ACTION FROM:
action 2, numVisits=678360, meanQ=17.863955, numObservations: 3
action 1, numVisits=9, meanQ=14.108889, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.180483 0.841124 0.52084 0.877462 0.653549 0.822396 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=50368, meanQ=18.763216, numObservations: 3
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 797080 episodes
GETTING ACTION FROM:
action 2, numVisits=847448, meanQ=18.408597, numObservations: 4
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.180483 0.841124 0.52084 0.877462 0.653549 0.822396 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 330
Initial state: 0 0.767439 0.545851 0.562512 0.849129 0.510391 0.811798 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 678887 episodes
GETTING ACTION FROM:
action 1, numVisits=678879, meanQ=17.870182, numObservations: 3
action 3, numVisits=5, meanQ=4.598000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.767439 0.545851 0.562512 0.849129 0.510391 0.811798 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 331
Initial state: 0 0.524507 0.87263 0.559826 0.979619 0.627046 0.835722 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 671140 episodes
GETTING ACTION FROM:
action 1, numVisits=671131, meanQ=17.854534, numObservations: 4
action 3, numVisits=6, meanQ=13.665000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.524507 0.87263 0.559826 0.979619 0.627046 0.835722 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 332
Initial state: 0 0.536085 0.848188 0.400588 0.598131 0.603162 0.855278 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 668904 episodes
GETTING ACTION FROM:
action 2, numVisits=668899, meanQ=17.758819, numObservations: 4
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.536085 0.848188 0.400588 0.598131 0.603162 0.855278 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=93503, meanQ=23.305255, numObservations: 5
action 1, numVisits=6, meanQ=19.498333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 840377 episodes
GETTING ACTION FROM:
action 3, numVisits=933879, meanQ=19.658513, numObservations: 5
action 1, numVisits=7, meanQ=16.282857, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.536085 0.848188 0.400588 0.598131 0.603162 0.855278 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 333
Initial state: 0 0.0679144 0.0434225 0.640895 0.876617 0.54902 0.853722 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 662472 episodes
GETTING ACTION FROM:
action 1, numVisits=662468, meanQ=17.847932, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.0679144 0.0434225 0.640895 0.876617 0.54902 0.853722 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=93296, meanQ=23.265177, numObservations: 4
action 3, numVisits=3, meanQ=14.996667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 863261 episodes
GETTING ACTION FROM:
action 2, numVisits=956535, meanQ=19.192315, numObservations: 4
action 3, numVisits=25, meanQ=17.639200, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.0679144 0.0434225 0.640895 0.876617 0.54902 0.853722 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 334
Initial state: 0 0.575765 0.886184 0.669526 0.803862 0.287539 0.698326 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 662332 episodes
GETTING ACTION FROM:
action 3, numVisits=662328, meanQ=18.099011, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.575765 0.886184 0.669526 0.803862 0.287539 0.698326 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=74892, meanQ=23.509276, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 863057 episodes
GETTING ACTION FROM:
action 1, numVisits=937949, meanQ=19.278018, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.575765 0.886184 0.669526 0.803862 0.287539 0.698326 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 335
Initial state: 0 0.648894 0.864886 0.20737 0.527015 0.519177 0.877669 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 675944 episodes
GETTING ACTION FROM:
action 1, numVisits=675933, meanQ=17.818573, numObservations: 3
action 3, numVisits=6, meanQ=13.665000, numObservations: 3
action 2, numVisits=3, meanQ=12.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.648894 0.864886 0.20737 0.527015 0.519177 0.877669 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 336
Initial state: 0 0.687406 0.868627 0.871117 0.330629 0.562281 0.824688 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 670947 episodes
GETTING ACTION FROM:
action 1, numVisits=670941, meanQ=17.820339, numObservations: 4
action 2, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.687406 0.868627 0.871117 0.330629 0.562281 0.824688 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 337
Initial state: 0 0.550283 0.89333 0.621174 0.847195 0.768145 0.484623 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 458663 episodes
GETTING ACTION FROM:
action -1, numVisits=458659, meanQ=15.650689, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: -1
Next state: 0 0.550283 0.89333 0.621174 0.847195 0.768145 0.484623 w: 1
Observation: 0 0.584767 0 0.558355 0 0.700818 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=458637, meanQ=17.860236, numObservations: 3
action 2, numVisits=11, meanQ=13.270918, numObservations: 3
action 1, numVisits=8, meanQ=11.873750, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 738756 episodes
GETTING ACTION FROM:
action 3, numVisits=1197393, meanQ=17.923170, numObservations: 3
action 2, numVisits=11, meanQ=13.270918, numObservations: 3
action 1, numVisits=8, meanQ=11.873750, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 2 0.550283 0.89333 0.621174 0.847195 0.768145 0.484623 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 338
Initial state: 0 0.501678 0.818161 0.200896 0.653984 0.563381 0.861904 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 648364 episodes
GETTING ACTION FROM:
action 1, numVisits=648359, meanQ=17.593468, numObservations: 4
action 3, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.501678 0.818161 0.200896 0.653984 0.563381 0.861904 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 339
Initial state: 0 0.812608 0.665423 0.590733 0.825147 0.608415 0.849265 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666710 episodes
GETTING ACTION FROM:
action 3, numVisits=666702, meanQ=17.751916, numObservations: 4
action 1, numVisits=4, meanQ=10.495000, numObservations: 2
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.812608 0.665423 0.590733 0.825147 0.608415 0.849265 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=48590, meanQ=17.348989, numObservations: 4
action 3, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 863583 episodes
GETTING ACTION FROM:
action 2, numVisits=912173, meanQ=18.914905, numObservations: 4
action 3, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.812608 0.665423 0.590733 0.825147 0.608415 0.849265 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=20933, meanQ=20.345258, numObservations: 3
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 896993 episodes
GETTING ACTION FROM:
action 1, numVisits=917926, meanQ=19.088906, numObservations: 3
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.812608 0.665423 0.590733 0.825147 0.608415 0.849265 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -18.7411
Run # 340
Initial state: 0 0.673273 0.816078 0.686095 0.808029 0.650343 0.78716 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 669264 episodes
GETTING ACTION FROM:
action 3, numVisits=669258, meanQ=17.772500, numObservations: 4
action 1, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.673273 0.816078 0.686095 0.808029 0.650343 0.78716 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 341
Initial state: 0 0.517686 0.814976 0.506847 0.341042 0.5771 0.853185 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 463870 episodes
GETTING ACTION FROM:
action -1, numVisits=463866, meanQ=15.546854, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.517686 0.814976 0.506847 0.341042 0.5771 0.853185 w: 1
Observation: 0 0.585793 0 0.546377 0 0.488559 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=463856, meanQ=17.748356, numObservations: 4
action 1, numVisits=6, meanQ=13.665000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 746181 episodes
GETTING ACTION FROM:
action 3, numVisits=1210037, meanQ=17.624286, numObservations: 4
action 1, numVisits=6, meanQ=13.665000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.517686 0.814976 0.506847 0.341042 0.5771 0.853185 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 342
Initial state: 0 0.565074 0.866204 0.571871 0.875244 0.903199 0.542478 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 676591 episodes
GETTING ACTION FROM:
action 1, numVisits=676376, meanQ=17.777722, numObservations: 3
action 2, numVisits=207, meanQ=17.182464, numObservations: 5
action 3, numVisits=6, meanQ=12.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 0 0.565074 0.866204 0.571871 0.875244 0.903199 0.542478 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=6287, meanQ=19.294771, numObservations: 3
action 3, numVisits=10, meanQ=12.397000, numObservations: 4
action 2, numVisits=7, meanQ=10.141429, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 804946 episodes
GETTING ACTION FROM:
action 1, numVisits=811233, meanQ=17.441635, numObservations: 3
action 3, numVisits=10, meanQ=12.397000, numObservations: 4
action 2, numVisits=7, meanQ=10.141429, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.565074 0.866204 0.571871 0.875244 0.903199 0.542478 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 343
Initial state: 0 0.630211 0.345458 0.552529 0.802711 0.659537 0.846068 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 665483 episodes
GETTING ACTION FROM:
action 2, numVisits=665466, meanQ=17.849431, numObservations: 5
action 3, numVisits=10, meanQ=15.098000, numObservations: 2
action 1, numVisits=5, meanQ=12.798020, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.630211 0.345458 0.552529 0.802711 0.659537 0.846068 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 344
Initial state: 0 0.253383 0.82893 0.61713 0.84086 0.679281 0.845457 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 665912 episodes
GETTING ACTION FROM:
action 3, numVisits=665884, meanQ=17.831299, numObservations: 4
action 2, numVisits=25, meanQ=11.758408, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.253383 0.82893 0.61713 0.84086 0.679281 0.845457 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=50053, meanQ=18.589550, numObservations: 3
action 2, numVisits=3, meanQ=12.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 790852 episodes
GETTING ACTION FROM:
action 3, numVisits=840905, meanQ=18.062517, numObservations: 3
action 2, numVisits=3, meanQ=12.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.253383 0.82893 0.61713 0.84086 0.679281 0.845457 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 345
Initial state: 0 0.601218 0.826943 0.665698 0.870479 0.239005 0.289469 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 673171 episodes
GETTING ACTION FROM:
action 2, numVisits=673167, meanQ=17.768044, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.601218 0.826943 0.665698 0.870479 0.239005 0.289469 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 346
Initial state: 0 0.00722389 0.361089 0.630112 0.833942 0.682926 0.861787 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 460690 episodes
GETTING ACTION FROM:
action -1, numVisits=460685, meanQ=15.653707, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: -1
Next state: 0 0.00722389 0.361089 0.630112 0.833942 0.682926 0.861787 w: 1
Observation: 0 0.00908226 0 0.600333 0 0.587343 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=460680, meanQ=17.852659, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 734015 episodes
GETTING ACTION FROM:
action 3, numVisits=1194695, meanQ=17.791887, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.00722389 0.361089 0.630112 0.833942 0.682926 0.861787 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 347
Initial state: 0 0.117793 0.704617 0.678137 0.82266 0.679839 0.810147 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 671757 episodes
GETTING ACTION FROM:
action 1, numVisits=671740, meanQ=17.835961, numObservations: 4
action 2, numVisits=11, meanQ=11.272727, numObservations: 3
action 3, numVisits=4, meanQ=8.497500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 0 0.117793 0.704617 0.678137 0.82266 0.679839 0.810147 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=94391, meanQ=23.262646, numObservations: 3
action 2, numVisits=5, meanQ=18.598000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 856833 episodes
GETTING ACTION FROM:
action 3, numVisits=951222, meanQ=19.530094, numObservations: 3
action 2, numVisits=7, meanQ=15.141429, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.117793 0.704617 0.678137 0.82266 0.679839 0.810147 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 348
Initial state: 0 0.62363 0.848045 0.591165 0.293619 0.617664 0.845821 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 669659 episodes
GETTING ACTION FROM:
action 1, numVisits=669645, meanQ=17.752457, numObservations: 4
action 2, numVisits=11, meanQ=10.815464, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.62363 0.848045 0.591165 0.293619 0.617664 0.845821 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 349
Initial state: 0 0.274471 0.65746 0.602161 0.899209 0.689414 0.854513 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 670444 episodes
GETTING ACTION FROM:
action 2, numVisits=670427, meanQ=17.786135, numObservations: 4
action 1, numVisits=12, meanQ=14.000008, numObservations: 4
action 3, numVisits=3, meanQ=12.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.274471 0.65746 0.602161 0.899209 0.689414 0.854513 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 350
Initial state: 0 0.627068 0.833134 0.666206 0.801191 0.446544 0.609764 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 676511 episodes
GETTING ACTION FROM:
action 3, numVisits=676505, meanQ=17.822137, numObservations: 3
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.627068 0.833134 0.666206 0.801191 0.446544 0.609764 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=110359, meanQ=23.146049, numObservations: 3
action 2, numVisits=3, meanQ=14.996667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 865799 episodes
GETTING ACTION FROM:
action 1, numVisits=976058, meanQ=18.940558, numObservations: 3
action 2, numVisits=103, meanQ=18.096894, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.627068 0.833134 0.666206 0.801191 0.446544 0.609764 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 351
Initial state: 0 0.403095 0.693423 0.653635 0.849972 0.663418 0.844305 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 461566 episodes
GETTING ACTION FROM:
action 0, numVisits=461561, meanQ=15.701567, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.403095 0.693423 0.653635 0.849972 0.663418 0.844305 w: 1
Observation: 0 0 0.694902 0 0.777725 0 0.862426 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=461554, meanQ=17.909034, numObservations: 4
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 743594 episodes
GETTING ACTION FROM:
action 1, numVisits=1205148, meanQ=17.696806, numObservations: 4
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 0 0.403095 0.693423 0.653635 0.849972 0.663418 0.844305 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=135932, meanQ=23.515192, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 865389 episodes
GETTING ACTION FROM:
action 2, numVisits=1001321, meanQ=19.940255, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.403095 0.693423 0.653635 0.849972 0.663418 0.844305 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 17.5624
Run # 352
Initial state: 0 0.648212 0.86645 0.0535051 0.3032 0.585253 0.8357 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 677505 episodes
GETTING ACTION FROM:
action 2, numVisits=677501, meanQ=17.871738, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.648212 0.86645 0.0535051 0.3032 0.585253 0.8357 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=110904, meanQ=23.173633, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 868501 episodes
GETTING ACTION FROM:
action 3, numVisits=979405, meanQ=19.610799, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.648212 0.86645 0.0535051 0.3032 0.585253 0.8357 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 353
Initial state: 0 0.391868 0.731747 0.689731 0.861 0.531588 0.898137 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 662896 episodes
GETTING ACTION FROM:
action 1, numVisits=662892, meanQ=17.781400, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.391868 0.731747 0.689731 0.861 0.531588 0.898137 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=92995, meanQ=23.265095, numObservations: 3
action 3, numVisits=3, meanQ=14.996667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 878350 episodes
GETTING ACTION FROM:
action 2, numVisits=971340, meanQ=19.212747, numObservations: 3
action 3, numVisits=8, meanQ=16.248750, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.391868 0.731747 0.689731 0.861 0.531588 0.898137 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 354
Initial state: 0 0.612889 0.842098 0.0171714 0.940642 0.669947 0.860701 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 663478 episodes
GETTING ACTION FROM:
action 2, numVisits=663469, meanQ=18.098814, numObservations: 5
action 1, numVisits=6, meanQ=6.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.612889 0.842098 0.0171714 0.940642 0.669947 0.860701 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=43559, meanQ=21.961235, numObservations: 4
action 3, numVisits=4, meanQ=17.247500, numObservations: 2
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 796954 episodes
GETTING ACTION FROM:
action 2, numVisits=840510, meanQ=18.100739, numObservations: 4
action 3, numVisits=7, meanQ=15.141429, numObservations: 2
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.612889 0.842098 0.0171714 0.940642 0.669947 0.860701 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=19877, meanQ=20.644232, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 875117 episodes
GETTING ACTION FROM:
action 1, numVisits=894994, meanQ=18.539319, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.612889 0.842098 0.0171714 0.940642 0.669947 0.860701 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 355
Initial state: 0 0.512714 0.885676 0.0704467 0.370694 0.636439 0.859861 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 669181 episodes
GETTING ACTION FROM:
action 2, numVisits=669171, meanQ=17.800466, numObservations: 4
action 1, numVisits=5, meanQ=6.196000, numObservations: 3
action 3, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.512714 0.885676 0.0704467 0.370694 0.636439 0.859861 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=94061, meanQ=23.281365, numObservations: 3
action 1, numVisits=4, meanQ=17.247500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 870793 episodes
GETTING ACTION FROM:
action 3, numVisits=964762, meanQ=19.518163, numObservations: 3
action 1, numVisits=96, meanQ=18.520731, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.512714 0.885676 0.0704467 0.370694 0.636439 0.859861 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 356
Initial state: 0 0.560139 0.820195 0.830223 0.339407 0.55976 0.845198 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 674685 episodes
GETTING ACTION FROM:
action 3, numVisits=674680, meanQ=17.740879, numObservations: 3
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.560139 0.820195 0.830223 0.339407 0.55976 0.845198 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 357
Initial state: 0 0.552564 0.837272 0.570308 0.881649 0.697341 0.356821 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 659959 episodes
GETTING ACTION FROM:
action 2, numVisits=659955, meanQ=17.831087, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.552564 0.837272 0.570308 0.881649 0.697341 0.356821 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 358
Initial state: 0 0.591422 0.811412 0.921016 0.197915 0.681658 0.877551 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 656812 episodes
GETTING ACTION FROM:
action 3, numVisits=656797, meanQ=17.743068, numObservations: 5
action 2, numVisits=12, meanQ=8.997508, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.591422 0.811412 0.921016 0.197915 0.681658 0.877551 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 359
Initial state: 0 0.627584 0.821229 0.208364 0.0968882 0.537483 0.832377 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 671333 episodes
GETTING ACTION FROM:
action 2, numVisits=671328, meanQ=17.836887, numObservations: 4
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.627584 0.821229 0.208364 0.0968882 0.537483 0.832377 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=110064, meanQ=23.151435, numObservations: 4
action 1, numVisits=25, meanQ=20.679204, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 856068 episodes
GETTING ACTION FROM:
action 3, numVisits=966083, meanQ=19.777442, numObservations: 4
action 1, numVisits=74, meanQ=18.564055, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.627584 0.821229 0.208364 0.0968882 0.537483 0.832377 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 360
Initial state: 0 0.608438 0.842088 0.648191 0.831031 0.892985 0.158047 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 679088 episodes
GETTING ACTION FROM:
action 1, numVisits=679071, meanQ=17.853053, numObservations: 3
action 3, numVisits=10, meanQ=14.701010, numObservations: 3
action 2, numVisits=5, meanQ=13.196000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.608438 0.842088 0.648191 0.831031 0.892985 0.158047 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 361
Initial state: 0 0.917626 0.10091 0.561192 0.860115 0.651992 0.842304 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 448124 episodes
GETTING ACTION FROM:
action -1, numVisits=448120, meanQ=15.481136, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.917626 0.10091 0.561192 0.860115 0.651992 0.842304 w: 1
Observation: 0 0.831328 0 0.602899 0 0.571569 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=448113, meanQ=17.685864, numObservations: 5
action 3, numVisits=2, meanQ=10.495000, numObservations: 1
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 698015 episodes
GETTING ACTION FROM:
action 2, numVisits=1146128, meanQ=17.479256, numObservations: 5
action 3, numVisits=2, meanQ=10.495000, numObservations: 1
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.917626 0.10091 0.561192 0.860115 0.651992 0.842304 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 362
Initial state: 0 0.658865 0.848048 0.674815 0.862818 0.838584 0.0426025 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 662757 episodes
GETTING ACTION FROM:
action 3, numVisits=662752, meanQ=17.850333, numObservations: 5
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.658865 0.848048 0.674815 0.862818 0.838584 0.0426025 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 363
Initial state: 0 0.861992 0.682691 0.650641 0.863539 0.552353 0.844905 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 673100 episodes
GETTING ACTION FROM:
action 2, numVisits=673096, meanQ=17.761438, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.861992 0.682691 0.650641 0.863539 0.552353 0.844905 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 364
Initial state: 0 0.558573 0.806231 0.224305 0.429632 0.586451 0.897052 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 677336 episodes
GETTING ACTION FROM:
action 1, numVisits=677328, meanQ=17.743715, numObservations: 3
action 2, numVisits=4, meanQ=10.495000, numObservations: 3
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.558573 0.806231 0.224305 0.429632 0.586451 0.897052 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 365
Initial state: 0 0.697748 0.889331 0.196891 0.63249 0.517527 0.874058 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 662826 episodes
GETTING ACTION FROM:
action 3, numVisits=662822, meanQ=17.838695, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.697748 0.889331 0.196891 0.63249 0.517527 0.874058 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 366
Initial state: 0 0.554289 0.872449 0.52643 0.882849 0.185207 0.577925 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 665105 episodes
GETTING ACTION FROM:
action 3, numVisits=665099, meanQ=17.874408, numObservations: 4
action 2, numVisits=3, meanQ=12.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.554289 0.872449 0.52643 0.882849 0.185207 0.577925 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=92879, meanQ=23.304493, numObservations: 3
action 2, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 866811 episodes
GETTING ACTION FROM:
action 1, numVisits=959690, meanQ=19.483354, numObservations: 3
action 2, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.554289 0.872449 0.52643 0.882849 0.185207 0.577925 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 367
Initial state: 0 0.595923 0.899009 0.841084 0.0407805 0.541123 0.824579 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 665970 episodes
GETTING ACTION FROM:
action 1, numVisits=665962, meanQ=17.867542, numObservations: 5
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.595923 0.899009 0.841084 0.0407805 0.541123 0.824579 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 368
Initial state: 0 0.679247 0.870806 0.0369477 0.560616 0.621838 0.874222 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 674131 episodes
GETTING ACTION FROM:
action 2, numVisits=674119, meanQ=17.848541, numObservations: 4
action 3, numVisits=9, meanQ=9.998900, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.679247 0.870806 0.0369477 0.560616 0.621838 0.874222 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=77384, meanQ=23.490677, numObservations: 3
action 1, numVisits=4, meanQ=17.247500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 849684 episodes
GETTING ACTION FROM:
action 3, numVisits=927065, meanQ=19.141857, numObservations: 4
action 1, numVisits=7, meanQ=15.141429, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.679247 0.870806 0.0369477 0.560616 0.621838 0.874222 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=22055, meanQ=22.032580, numObservations: 4
action 3, numVisits=15, meanQ=17.806000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 882795 episodes
GETTING ACTION FROM:
action 1, numVisits=904534, meanQ=19.078127, numObservations: 4
action 3, numVisits=331, meanQ=18.634804, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.679247 0.870806 0.0369477 0.560616 0.621838 0.874222 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 369
Initial state: 0 0.543152 0.822535 0.525505 0.849929 0.0186124 0.245577 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 462561 episodes
GETTING ACTION FROM:
action -1, numVisits=462555, meanQ=15.588725, numObservations: 1
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.543152 0.822535 0.525505 0.849929 0.0186124 0.245577 w: 1
Observation: 0 0.472784 0 0.516995 0 0 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=462550, meanQ=17.748116, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 732936 episodes
GETTING ACTION FROM:
action 3, numVisits=1195486, meanQ=17.670662, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.543152 0.822535 0.525505 0.849929 0.0186124 0.245577 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 370
Initial state: 0 0.59514 0.848332 0.89517 0.941891 0.553601 0.854209 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 660531 episodes
GETTING ACTION FROM:
action 1, numVisits=660525, meanQ=17.748728, numObservations: 5
action 3, numVisits=3, meanQ=4.670033, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.59514 0.848332 0.89517 0.941891 0.553601 0.854209 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 371
Initial state: 0 0.681346 0.815132 0.331303 0.247238 0.539908 0.870186 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 648448 episodes
GETTING ACTION FROM:
action 3, numVisits=648444, meanQ=17.638154, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.681346 0.815132 0.331303 0.247238 0.539908 0.870186 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 372
Initial state: 0 0.691693 0.837318 0.51284 0.860802 0.307945 0.840565 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 660546 episodes
GETTING ACTION FROM:
action 1, numVisits=660540, meanQ=17.780972, numObservations: 5
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.691693 0.837318 0.51284 0.860802 0.307945 0.840565 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 373
Initial state: 0 0.564736 0.816666 0.503072 0.865311 0.390368 0.926482 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666012 episodes
GETTING ACTION FROM:
action 1, numVisits=666008, meanQ=17.838450, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.564736 0.816666 0.503072 0.865311 0.390368 0.926482 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 374
Initial state: 0 0.567034 0.896678 0.33294 0.494852 0.603964 0.829742 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 663246 episodes
GETTING ACTION FROM:
action 1, numVisits=663239, meanQ=17.778229, numObservations: 5
action 3, numVisits=4, meanQ=8.497500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.567034 0.896678 0.33294 0.494852 0.603964 0.829742 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 375
Initial state: 0 0.523381 0.847823 0.547025 0.855688 0.770921 0.417572 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 669010 episodes
GETTING ACTION FROM:
action 3, numVisits=669006, meanQ=17.864732, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.523381 0.847823 0.547025 0.855688 0.770921 0.417572 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 376
Initial state: 0 0.613795 0.875367 0.651541 0.822212 0.654027 0.0207293 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666714 episodes
GETTING ACTION FROM:
action 1, numVisits=666709, meanQ=17.734048, numObservations: 4
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.613795 0.875367 0.651541 0.822212 0.654027 0.0207293 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 377
Initial state: 0 0.666352 0.870334 0.535967 0.845459 0.714801 0.391576 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 667137 episodes
GETTING ACTION FROM:
action 2, numVisits=667115, meanQ=17.770880, numObservations: 4
action 1, numVisits=17, meanQ=14.998829, numObservations: 4
action 3, numVisits=3, meanQ=12.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.666352 0.870334 0.535967 0.845459 0.714801 0.391576 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 378
Initial state: 0 0.640383 0.163856 0.507588 0.826535 0.591833 0.837614 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666575 episodes
GETTING ACTION FROM:
action 2, numVisits=666571, meanQ=17.750596, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.640383 0.163856 0.507588 0.826535 0.591833 0.837614 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 379
Initial state: 0 0.661994 0.874921 0.690663 0.877725 0.839332 0.625826 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 673021 episodes
GETTING ACTION FROM:
action 2, numVisits=673012, meanQ=17.849448, numObservations: 4
action 3, numVisits=6, meanQ=8.831683, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.661994 0.874921 0.690663 0.877725 0.839332 0.625826 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 380
Initial state: 0 0.534113 0.838943 0.50664 0.867499 0.328251 0.525515 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 672824 episodes
GETTING ACTION FROM:
action 1, numVisits=672819, meanQ=17.860216, numObservations: 4
action 3, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.534113 0.838943 0.50664 0.867499 0.328251 0.525515 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=41689, meanQ=18.298053, numObservations: 4
action 3, numVisits=9, meanQ=14.108889, numObservations: 3
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 785739 episodes
GETTING ACTION FROM:
action 1, numVisits=827428, meanQ=17.424829, numObservations: 4
action 3, numVisits=9, meanQ=14.108889, numObservations: 3
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.534113 0.838943 0.50664 0.867499 0.328251 0.525515 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 381
Initial state: 0 0.687277 0.836261 0.534681 0.837064 0.24484 0.0724906 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 673566 episodes
GETTING ACTION FROM:
action 2, numVisits=673562, meanQ=17.857300, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.687277 0.836261 0.534681 0.837064 0.24484 0.0724906 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 382
Initial state: 0 0.515494 0.889734 0.840614 0.399754 0.583986 0.822523 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666844 episodes
GETTING ACTION FROM:
action 3, numVisits=666823, meanQ=17.838259, numObservations: 4
action 2, numVisits=14, meanQ=15.141429, numObservations: 4
action 1, numVisits=5, meanQ=13.196000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.515494 0.889734 0.840614 0.399754 0.583986 0.822523 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 383
Initial state: 0 0.523478 0.854123 0.508116 0.813676 0.907842 0.741884 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 651898 episodes
GETTING ACTION FROM:
action 2, numVisits=651894, meanQ=17.866964, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.523478 0.854123 0.508116 0.813676 0.907842 0.741884 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 384
Initial state: 0 0.699269 0.873301 0.313688 0.577368 0.515155 0.815302 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 458409 episodes
GETTING ACTION FROM:
action -1, numVisits=458405, meanQ=15.568588, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.699269 0.873301 0.313688 0.577368 0.515155 0.815302 w: 1
Observation: 0 0.740602 0 0.280164 0 0.576648 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=458398, meanQ=17.746114, numObservations: 5
action 2, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 717393 episodes
GETTING ACTION FROM:
action 3, numVisits=1175791, meanQ=17.802561, numObservations: 5
action 2, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.699269 0.873301 0.313688 0.577368 0.515155 0.815302 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 385
Initial state: 0 0.501899 0.816869 0.608775 0.863432 0.515455 0.540733 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 660542 episodes
GETTING ACTION FROM:
action 2, numVisits=660526, meanQ=17.811974, numObservations: 4
action 1, numVisits=13, meanQ=6.844623, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.501899 0.816869 0.608775 0.863432 0.515455 0.540733 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 386
Initial state: 0 0.696823 0.815454 0.540541 0.860008 0.900885 0.384803 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 670096 episodes
GETTING ACTION FROM:
action 1, numVisits=670092, meanQ=17.855521, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.696823 0.815454 0.540541 0.860008 0.900885 0.384803 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 387
Initial state: 0 0.550327 0.877506 0.260546 0.122184 0.515767 0.80067 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666877 episodes
GETTING ACTION FROM:
action 2, numVisits=666872, meanQ=17.783606, numObservations: 5
action 3, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.550327 0.877506 0.260546 0.122184 0.515767 0.80067 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=33688, meanQ=22.319481, numObservations: 3
action 3, numVisits=10, meanQ=18.201010, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 870276 episodes
GETTING ACTION FROM:
action 3, numVisits=670821, meanQ=19.181429, numObservations: 3
action 1, numVisits=233153, meanQ=18.972126, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.550327 0.877506 0.260546 0.122184 0.515767 0.80067 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 388
Initial state: 0 0.68417 0.864105 0.44873 0.707507 0.502861 0.822272 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 663166 episodes
GETTING ACTION FROM:
action 2, numVisits=663143, meanQ=18.067176, numObservations: 5
action 1, numVisits=16, meanQ=15.749375, numObservations: 3
action 3, numVisits=5, meanQ=11.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 2 0.68417 0.864105 0.44873 0.707507 0.502861 0.822272 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 389
Initial state: 0 0.477645 0.137524 0.544452 0.806111 0.627558 0.806066 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 462438 episodes
GETTING ACTION FROM:
action 0, numVisits=462433, meanQ=15.645955, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.477645 0.137524 0.544452 0.806111 0.627558 0.806066 w: 1
Observation: 0 0 0.228968 0 0.720639 0 0.897559 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=462428, meanQ=17.833419, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 748521 episodes
GETTING ACTION FROM:
action 2, numVisits=1210949, meanQ=17.725173, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.477645 0.137524 0.544452 0.806111 0.627558 0.806066 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 390
Initial state: 0 0.694988 0.871683 0.570323 0.817916 0.603963 0.580221 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 661420 episodes
GETTING ACTION FROM:
action 3, numVisits=661416, meanQ=17.749324, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.694988 0.871683 0.570323 0.817916 0.603963 0.580221 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 391
Initial state: 0 0.63518 0.636218 0.670809 0.868263 0.679086 0.817417 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 669870 episodes
GETTING ACTION FROM:
action 1, numVisits=669866, meanQ=18.085059, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.63518 0.636218 0.670809 0.868263 0.679086 0.817417 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 392
Initial state: 0 0.651754 0.756066 0.599488 0.873442 0.617216 0.821714 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 660151 episodes
GETTING ACTION FROM:
action 3, numVisits=660144, meanQ=17.766180, numObservations: 5
action 2, numVisits=4, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.651754 0.756066 0.599488 0.873442 0.617216 0.821714 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 393
Initial state: 0 0.655614 0.814103 0.621966 0.845987 0.930328 0.895028 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 662580 episodes
GETTING ACTION FROM:
action 1, numVisits=662565, meanQ=17.779561, numObservations: 5
action 3, numVisits=12, meanQ=11.918358, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.655614 0.814103 0.621966 0.845987 0.930328 0.895028 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 394
Initial state: 0 0.698114 0.814893 0.500616 0.853063 0.764183 0.471924 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 667192 episodes
GETTING ACTION FROM:
action 3, numVisits=667186, meanQ=17.825979, numObservations: 4
action 2, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.698114 0.814893 0.500616 0.853063 0.764183 0.471924 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 395
Initial state: 0 0.596146 0.802585 0.861935 0.865914 0.534217 0.846043 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 675962 episodes
GETTING ACTION FROM:
action 2, numVisits=675958, meanQ=17.828616, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.596146 0.802585 0.861935 0.865914 0.534217 0.846043 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 396
Initial state: 0 0.698444 0.820584 0.995739 0.348158 0.573009 0.884466 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 664934 episodes
GETTING ACTION FROM:
action 3, numVisits=664928, meanQ=17.784357, numObservations: 4
action 2, numVisits=3, meanQ=12.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.698444 0.820584 0.995739 0.348158 0.573009 0.884466 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 397
Initial state: 0 0.517546 0.849488 0.965653 0.126769 0.630616 0.841098 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 661081 episodes
GETTING ACTION FROM:
action 2, numVisits=661068, meanQ=17.754883, numObservations: 5
action 1, numVisits=6, meanQ=14.335017, numObservations: 2
action 3, numVisits=5, meanQ=11.598000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 2 0.517546 0.849488 0.965653 0.126769 0.630616 0.841098 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 398
Initial state: 0 0.631621 0.839661 0.585918 0.846164 0.273353 0.196923 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 663517 episodes
GETTING ACTION FROM:
action 1, numVisits=663513, meanQ=17.771376, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.631621 0.839661 0.585918 0.846164 0.273353 0.196923 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 399
Initial state: 0 0.634174 0.854806 0.383932 0.064298 0.68058 0.89705 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 669399 episodes
GETTING ACTION FROM:
action 1, numVisits=669391, meanQ=17.743255, numObservations: 4
action 3, numVisits=5, meanQ=6.196000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.634174 0.854806 0.383932 0.064298 0.68058 0.89705 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 400
Initial state: 0 0.580231 0.861683 0.602959 0.866346 0.892574 0.279691 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 667700 episodes
GETTING ACTION FROM:
action 1, numVisits=667677, meanQ=17.814729, numObservations: 4
action 3, numVisits=14, meanQ=13.640721, numObservations: 4
action 2, numVisits=7, meanQ=10.141429, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.580231 0.861683 0.602959 0.866346 0.892574 0.279691 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 401
Initial state: 0 0.319911 0.252537 0.530836 0.86349 0.595544 0.824881 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 667222 episodes
GETTING ACTION FROM:
action 3, numVisits=667217, meanQ=17.760513, numObservations: 3
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.319911 0.252537 0.530836 0.86349 0.595544 0.824881 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 402
Initial state: 0 0.639987 0.826052 0.530707 0.852586 0.408159 0.69899 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 667799 episodes
GETTING ACTION FROM:
action 1, numVisits=667793, meanQ=17.786602, numObservations: 4
action 2, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.639987 0.826052 0.530707 0.852586 0.408159 0.69899 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 403
Initial state: 0 0.577002 0.897735 0.527371 0.842755 0.89813 0.358776 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 672672 episodes
GETTING ACTION FROM:
action 2, numVisits=672656, meanQ=17.716528, numObservations: 4
action 3, numVisits=13, meanQ=11.468462, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.577002 0.897735 0.527371 0.842755 0.89813 0.358776 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 404
Initial state: 0 0.21427 0.0632643 0.556153 0.802283 0.53238 0.811073 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 670672 episodes
GETTING ACTION FROM:
action 2, numVisits=670660, meanQ=17.824542, numObservations: 4
action 1, numVisits=9, meanQ=11.333356, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.21427 0.0632643 0.556153 0.802283 0.53238 0.811073 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 405
Initial state: 0 0.266666 0.0331184 0.691107 0.819542 0.613943 0.894317 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 665917 episodes
GETTING ACTION FROM:
action 1, numVisits=665913, meanQ=17.767147, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.266666 0.0331184 0.691107 0.819542 0.613943 0.894317 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=93941, meanQ=23.236451, numObservations: 4
action 2, numVisits=5, meanQ=18.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 857263 episodes
GETTING ACTION FROM:
action 3, numVisits=951203, meanQ=19.108382, numObservations: 4
action 2, numVisits=6, meanQ=13.665000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.266666 0.0331184 0.691107 0.819542 0.613943 0.894317 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 406
Initial state: 0 0.537891 0.827353 0.461335 0.405491 0.5606 0.891633 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 670147 episodes
GETTING ACTION FROM:
action 1, numVisits=670143, meanQ=17.844722, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.537891 0.827353 0.461335 0.405491 0.5606 0.891633 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 407
Initial state: 0 0.614412 0.870247 0.628135 0.856624 0.69253 0.282088 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666205 episodes
GETTING ACTION FROM:
action 3, numVisits=666179, meanQ=17.858041, numObservations: 4
action 1, numVisits=22, meanQ=13.499550, numObservations: 4
action 2, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 2 0.614412 0.870247 0.628135 0.856624 0.69253 0.282088 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 408
Initial state: 0 0.220307 0.152052 0.593023 0.89672 0.520072 0.820641 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 669261 episodes
GETTING ACTION FROM:
action 2, numVisits=669252, meanQ=17.730823, numObservations: 4
action 1, numVisits=6, meanQ=9.163333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.220307 0.152052 0.593023 0.89672 0.520072 0.820641 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 409
Initial state: 0 0.706251 0.48626 0.623827 0.853247 0.593986 0.819844 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 676132 episodes
GETTING ACTION FROM:
action 1, numVisits=676123, meanQ=17.758114, numObservations: 3
action 2, numVisits=6, meanQ=14.335017, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.706251 0.48626 0.623827 0.853247 0.593986 0.819844 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=49627, meanQ=17.383472, numObservations: 4
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 863265 episodes
GETTING ACTION FROM:
action 2, numVisits=912892, meanQ=18.503431, numObservations: 4
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.706251 0.48626 0.623827 0.853247 0.593986 0.819844 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 410
Initial state: 0 0.612716 0.805044 0.612026 0.511006 0.582637 0.811166 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 646790 episodes
GETTING ACTION FROM:
action 3, numVisits=646782, meanQ=17.610374, numObservations: 4
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action 2, numVisits=4, meanQ=9.502525, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.612716 0.805044 0.612026 0.511006 0.582637 0.811166 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 411
Initial state: 0 0.397411 0.449038 0.660307 0.864302 0.610609 0.876797 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 678316 episodes
GETTING ACTION FROM:
action 1, numVisits=678309, meanQ=17.902201, numObservations: 3
action 2, numVisits=4, meanQ=9.502525, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.397411 0.449038 0.660307 0.864302 0.610609 0.876797 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=111482, meanQ=23.165287, numObservations: 3
action 3, numVisits=3, meanQ=14.996667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 873016 episodes
GETTING ACTION FROM:
action 2, numVisits=984498, meanQ=19.361235, numObservations: 3
action 3, numVisits=3, meanQ=14.996667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.397411 0.449038 0.660307 0.864302 0.610609 0.876797 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=25489, meanQ=21.723732, numObservations: 3
action 2, numVisits=4, meanQ=17.247500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 887538 episodes
GETTING ACTION FROM:
action 3, numVisits=913026, meanQ=18.744883, numObservations: 3
action 2, numVisits=5, meanQ=11.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.397411 0.449038 0.660307 0.864302 0.610609 0.876797 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 412
Initial state: 0 0.376655 0.990289 0.674463 0.802093 0.600873 0.829623 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 665899 episodes
GETTING ACTION FROM:
action 3, numVisits=665891, meanQ=17.767648, numObservations: 4
action 1, numVisits=5, meanQ=11.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.376655 0.990289 0.674463 0.802093 0.600873 0.829623 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 413
Initial state: 0 0.0876213 0.838311 0.694208 0.864923 0.591764 0.884384 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 667049 episodes
GETTING ACTION FROM:
action 1, numVisits=667043, meanQ=17.864127, numObservations: 5
action 3, numVisits=2, meanQ=10.495000, numObservations: 1
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 2 0.0876213 0.838311 0.694208 0.864923 0.591764 0.884384 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 414
Initial state: 0 0.968396 0.165623 0.601165 0.819327 0.573482 0.805971 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666957 episodes
GETTING ACTION FROM:
action 3, numVisits=666953, meanQ=17.722557, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.968396 0.165623 0.601165 0.819327 0.573482 0.805971 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 415
Initial state: 0 0.519574 0.802649 0.699728 0.875 0.274154 0.873739 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 660008 episodes
GETTING ACTION FROM:
action 2, numVisits=659995, meanQ=17.877247, numObservations: 5
action 3, numVisits=10, meanQ=11.999020, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.519574 0.802649 0.699728 0.875 0.274154 0.873739 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 416
Initial state: 0 0.641749 0.258282 0.580961 0.850992 0.5472 0.836123 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 667893 episodes
GETTING ACTION FROM:
action 3, numVisits=667886, meanQ=18.100473, numObservations: 4
action 1, numVisits=4, meanQ=10.495000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.641749 0.258282 0.580961 0.850992 0.5472 0.836123 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 417
Initial state: 0 0.393274 0.483668 0.657744 0.893742 0.611763 0.865617 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 671059 episodes
GETTING ACTION FROM:
action 1, numVisits=671053, meanQ=17.767396, numObservations: 4
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 0 0.393274 0.483668 0.657744 0.893742 0.611763 0.865617 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=93568, meanQ=23.292969, numObservations: 3
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 872051 episodes
GETTING ACTION FROM:
action 2, numVisits=965619, meanQ=19.283699, numObservations: 3
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.393274 0.483668 0.657744 0.893742 0.611763 0.865617 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 418
Initial state: 0 0.524821 0.807303 0.637399 0.816052 0.488547 0.969559 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 673649 episodes
GETTING ACTION FROM:
action 2, numVisits=673644, meanQ=17.862333, numObservations: 4
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.524821 0.807303 0.637399 0.816052 0.488547 0.969559 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 419
Initial state: 0 0.616387 0.862795 0.0854529 0.70802 0.549764 0.836022 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666243 episodes
GETTING ACTION FROM:
action 1, numVisits=666237, meanQ=17.867662, numObservations: 5
action 2, numVisits=2, meanQ=10.495000, numObservations: 1
action 3, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.616387 0.862795 0.0854529 0.70802 0.549764 0.836022 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 420
Initial state: 0 0.413573 0.0446204 0.656318 0.841924 0.524314 0.805549 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 646814 episodes
GETTING ACTION FROM:
action 3, numVisits=646809, meanQ=17.655813, numObservations: 4
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.413573 0.0446204 0.656318 0.841924 0.524314 0.805549 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 421
Initial state: 0 0.506782 0.829402 0.597434 0.848612 0.378111 0.611539 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 644593 episodes
GETTING ACTION FROM:
action 3, numVisits=644587, meanQ=17.600357, numObservations: 4
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.506782 0.829402 0.597434 0.848612 0.378111 0.611539 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=106741, meanQ=23.137227, numObservations: 4
action 2, numVisits=3, meanQ=12.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 857517 episodes
GETTING ACTION FROM:
action 1, numVisits=964258, meanQ=19.560513, numObservations: 4
action 2, numVisits=3, meanQ=12.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.506782 0.829402 0.597434 0.848612 0.378111 0.611539 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 422
Initial state: 0 0.745748 0.698068 0.554059 0.888196 0.606917 0.84844 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 669683 episodes
GETTING ACTION FROM:
action 1, numVisits=669679, meanQ=17.845991, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.745748 0.698068 0.554059 0.888196 0.606917 0.84844 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 423
Initial state: 0 0.188541 0.772078 0.689279 0.872276 0.590197 0.810413 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 670217 episodes
GETTING ACTION FROM:
action 1, numVisits=670209, meanQ=17.836692, numObservations: 4
action 3, numVisits=5, meanQ=10.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.188541 0.772078 0.689279 0.872276 0.590197 0.810413 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=110308, meanQ=23.145784, numObservations: 4
action 3, numVisits=3, meanQ=14.996667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 862536 episodes
GETTING ACTION FROM:
action 2, numVisits=972829, meanQ=19.272416, numObservations: 4
action 3, numVisits=18, meanQ=16.666111, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.188541 0.772078 0.689279 0.872276 0.590197 0.810413 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 424
Initial state: 0 0.614455 0.818421 0.427194 0.521078 0.508184 0.804027 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 669647 episodes
GETTING ACTION FROM:
action 1, numVisits=669643, meanQ=17.843355, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.614455 0.818421 0.427194 0.521078 0.508184 0.804027 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=49583, meanQ=18.608730, numObservations: 4
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 789882 episodes
GETTING ACTION FROM:
action 1, numVisits=839465, meanQ=17.592881, numObservations: 4
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.614455 0.818421 0.427194 0.521078 0.508184 0.804027 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 425
Initial state: 0 0.649562 0.816618 0.664024 0.775553 0.63184 0.801093 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 675556 episodes
GETTING ACTION FROM:
action 1, numVisits=675544, meanQ=17.851047, numObservations: 3
action 3, numVisits=7, meanQ=7.140014, numObservations: 2
action 2, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.649562 0.816618 0.664024 0.775553 0.63184 0.801093 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 426
Initial state: 0 0.8606 0.439381 0.595548 0.850017 0.545687 0.827575 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 668435 episodes
GETTING ACTION FROM:
action 3, numVisits=668427, meanQ=17.744098, numObservations: 4
action 1, numVisits=5, meanQ=12.798020, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.8606 0.439381 0.595548 0.850017 0.545687 0.827575 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 427
Initial state: 0 0.482863 0.462197 0.689821 0.858616 0.525216 0.818978 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 662307 episodes
GETTING ACTION FROM:
action 2, numVisits=662291, meanQ=17.817372, numObservations: 5
action 1, numVisits=12, meanQ=11.248342, numObservations: 3
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.482863 0.462197 0.689821 0.858616 0.525216 0.818978 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 428
Initial state: 0 0.464776 0.0513299 0.644233 0.821275 0.535289 0.819688 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 667793 episodes
GETTING ACTION FROM:
action 3, numVisits=667789, meanQ=17.739120, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.464776 0.0513299 0.644233 0.821275 0.535289 0.819688 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 429
Initial state: 0 0.539638 0.82608 0.572389 0.864162 0.0664864 0.921659 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 654294 episodes
GETTING ACTION FROM:
action 1, numVisits=654280, meanQ=17.716538, numObservations: 5
action 3, numVisits=11, meanQ=9.909100, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.539638 0.82608 0.572389 0.864162 0.0664864 0.921659 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 430
Initial state: 0 0.450467 0.603721 0.573468 0.879892 0.580032 0.835194 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 647151 episodes
GETTING ACTION FROM:
action 1, numVisits=647145, meanQ=17.721279, numObservations: 4
action 2, numVisits=3, meanQ=5.330033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.450467 0.603721 0.573468 0.879892 0.580032 0.835194 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 431
Initial state: 0 0.669311 0.815567 0.931025 0.454371 0.514267 0.884001 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 660578 episodes
GETTING ACTION FROM:
action 3, numVisits=660555, meanQ=17.753651, numObservations: 5
action 2, numVisits=20, meanQ=9.825515, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.669311 0.815567 0.931025 0.454371 0.514267 0.884001 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 432
Initial state: 0 0.69636 0.823645 0.521739 0.855564 0.419832 0.719479 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 673093 episodes
GETTING ACTION FROM:
action 2, numVisits=673086, meanQ=17.757267, numObservations: 4
action 3, numVisits=4, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.69636 0.823645 0.521739 0.855564 0.419832 0.719479 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 433
Initial state: 0 0.678775 0.819181 0.512082 0.808327 0.160698 0.926229 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 669790 episodes
GETTING ACTION FROM:
action 3, numVisits=669782, meanQ=17.783551, numObservations: 4
action 1, numVisits=5, meanQ=11.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.678775 0.819181 0.512082 0.808327 0.160698 0.926229 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=50151, meanQ=17.397496, numObservations: 3
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 870115 episodes
GETTING ACTION FROM:
action 1, numVisits=920266, meanQ=18.585640, numObservations: 3
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.678775 0.819181 0.512082 0.808327 0.160698 0.926229 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 434
Initial state: 0 0.607555 0.833212 0.637507 0.866097 0.166909 0.70359 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 670976 episodes
GETTING ACTION FROM:
action 1, numVisits=670966, meanQ=17.736838, numObservations: 4
action 3, numVisits=7, meanQ=11.282857, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.607555 0.833212 0.637507 0.866097 0.166909 0.70359 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 435
Initial state: 0 0.51018 0.877505 0.459807 0.191941 0.637206 0.897226 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 654801 episodes
GETTING ACTION FROM:
action 2, numVisits=654794, meanQ=17.706925, numObservations: 5
action 1, numVisits=4, meanQ=9.997525, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.51018 0.877505 0.459807 0.191941 0.637206 0.897226 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=15779, meanQ=22.547918, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 864700 episodes
GETTING ACTION FROM:
action 3, numVisits=880479, meanQ=18.996951, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.51018 0.877505 0.459807 0.191941 0.637206 0.897226 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 436
Initial state: 0 0.638529 0.859514 0.593423 0.890579 0.483017 0.247066 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 663023 episodes
GETTING ACTION FROM:
action 2, numVisits=662975, meanQ=17.852744, numObservations: 5
action 1, numVisits=42, meanQ=12.642152, numObservations: 4
action 3, numVisits=4, meanQ=8.497500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.638529 0.859514 0.593423 0.890579 0.483017 0.247066 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 437
Initial state: 0 0.685939 0.803769 0.54451 0.899138 0.130952 0.731342 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 661732 episodes
GETTING ACTION FROM:
action 2, numVisits=661723, meanQ=17.756321, numObservations: 5
action 3, numVisits=3, meanQ=12.333333, numObservations: 2
action 1, numVisits=4, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.685939 0.803769 0.54451 0.899138 0.130952 0.731342 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 438
Initial state: 0 0.985807 0.542641 0.510059 0.86581 0.53684 0.85458 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 658084 episodes
GETTING ACTION FROM:
action 3, numVisits=658077, meanQ=17.755370, numObservations: 5
action 2, numVisits=4, meanQ=8.497500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.985807 0.542641 0.510059 0.86581 0.53684 0.85458 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 439
Initial state: 0 0.621996 0.863165 0.519865 0.84391 0.874911 0.0253855 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 657918 episodes
GETTING ACTION FROM:
action 3, numVisits=657914, meanQ=17.766944, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.621996 0.863165 0.519865 0.84391 0.874911 0.0253855 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 440
Initial state: 0 0.698653 0.836557 0.162535 0.188398 0.689143 0.859674 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 664088 episodes
GETTING ACTION FROM:
action 1, numVisits=664075, meanQ=17.859785, numObservations: 5
action 2, numVisits=5, meanQ=10.000000, numObservations: 2
action 3, numVisits=6, meanQ=9.163333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.698653 0.836557 0.162535 0.188398 0.689143 0.859674 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 441
Initial state: 0 0.663728 0.836047 0.30778 0.899122 0.66234 0.871559 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 665718 episodes
GETTING ACTION FROM:
action 2, numVisits=665697, meanQ=17.750409, numObservations: 4
action 1, numVisits=18, meanQ=11.943344, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.663728 0.836047 0.30778 0.899122 0.66234 0.871559 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=16311, meanQ=22.323116, numObservations: 4
action 1, numVisits=3, meanQ=14.996667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 858656 episodes
GETTING ACTION FROM:
action 3, numVisits=874938, meanQ=19.251591, numObservations: 4
action 1, numVisits=32, meanQ=17.936875, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.663728 0.836047 0.30778 0.899122 0.66234 0.871559 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 442
Initial state: 0 0.680645 0.875031 0.565386 0.852093 0.181582 0.103465 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 459598 episodes
GETTING ACTION FROM:
action -1, numVisits=459594, meanQ=15.532904, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: -1
Next state: 0 0.680645 0.875031 0.565386 0.852093 0.181582 0.103465 w: 1
Observation: 0 0.623671 0 0.582295 0 0.128955 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=459586, meanQ=17.717572, numObservations: 5
action 3, numVisits=4, meanQ=8.497500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 737169 episodes
GETTING ACTION FROM:
action 2, numVisits=1196755, meanQ=17.963022, numObservations: 5
action 3, numVisits=4, meanQ=8.497500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.680645 0.875031 0.565386 0.852093 0.181582 0.103465 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 443
Initial state: 0 0.609123 0.813399 0.602402 0.809417 0.427706 0.30976 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 661634 episodes
GETTING ACTION FROM:
action 2, numVisits=661623, meanQ=18.079640, numObservations: 4
action 1, numVisits=8, meanQ=12.376262, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.609123 0.813399 0.602402 0.809417 0.427706 0.30976 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 444
Initial state: 0 0.55148 0.823085 0.526649 0.847303 0.198113 0.035808 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 678422 episodes
GETTING ACTION FROM:
action 1, numVisits=678416, meanQ=17.863745, numObservations: 3
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.55148 0.823085 0.526649 0.847303 0.198113 0.035808 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 445
Initial state: 0 0.594317 0.870409 0.671323 0.838597 0.568524 0.281453 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666624 episodes
GETTING ACTION FROM:
action 2, numVisits=666619, meanQ=17.732679, numObservations: 5
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.594317 0.870409 0.671323 0.838597 0.568524 0.281453 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 446
Initial state: 0 0.529146 0.876465 0.758576 0.949762 0.661744 0.824801 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 662375 episodes
GETTING ACTION FROM:
action 1, numVisits=662371, meanQ=17.811459, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.529146 0.876465 0.758576 0.949762 0.661744 0.824801 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 447
Initial state: 0 0.504825 0.836845 0.38244 0.369432 0.599607 0.853458 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 672724 episodes
GETTING ACTION FROM:
action 1, numVisits=672719, meanQ=17.869444, numObservations: 4
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.504825 0.836845 0.38244 0.369432 0.599607 0.853458 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 448
Initial state: 0 0.0916591 0.144152 0.680907 0.868281 0.568484 0.837369 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 664138 episodes
GETTING ACTION FROM:
action 2, numVisits=664133, meanQ=17.847132, numObservations: 5
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.0916591 0.144152 0.680907 0.868281 0.568484 0.837369 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 449
Initial state: 0 0.613161 0.261715 0.533988 0.836343 0.500895 0.871556 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 667107 episodes
GETTING ACTION FROM:
action 3, numVisits=667079, meanQ=17.771793, numObservations: 4
action 2, numVisits=25, meanQ=14.669600, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.613161 0.261715 0.533988 0.836343 0.500895 0.871556 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 450
Initial state: 0 0.510119 0.808885 0.554614 0.828419 0.599316 0.430317 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 660653 episodes
GETTING ACTION FROM:
action 3, numVisits=660636, meanQ=17.719369, numObservations: 5
action 1, numVisits=14, meanQ=15.267150, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.510119 0.808885 0.554614 0.828419 0.599316 0.430317 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 451
Initial state: 0 0.268555 0.409 0.669033 0.866277 0.64105 0.884544 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 668386 episodes
GETTING ACTION FROM:
action 2, numVisits=668367, meanQ=17.730652, numObservations: 4
action 3, numVisits=15, meanQ=11.465340, numObservations: 3
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.268555 0.409 0.669033 0.866277 0.64105 0.884544 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 452
Initial state: 0 0.587178 0.801616 0.289862 0.747801 0.638026 0.856103 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666122 episodes
GETTING ACTION FROM:
action 2, numVisits=666118, meanQ=17.844238, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.587178 0.801616 0.289862 0.747801 0.638026 0.856103 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=93436, meanQ=23.285154, numObservations: 4
action 1, numVisits=3, meanQ=14.996667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 859157 episodes
GETTING ACTION FROM:
action 3, numVisits=952593, meanQ=19.585201, numObservations: 4
action 1, numVisits=3, meanQ=14.996667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.587178 0.801616 0.289862 0.747801 0.638026 0.856103 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 453
Initial state: 0 0.119516 0.775394 0.550012 0.839395 0.565817 0.889535 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 672825 episodes
GETTING ACTION FROM:
action 2, numVisits=672821, meanQ=17.780465, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.119516 0.775394 0.550012 0.839395 0.565817 0.889535 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 454
Initial state: 0 0.113388 0.532274 0.55372 0.826918 0.645374 0.806311 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 663721 episodes
GETTING ACTION FROM:
action 3, numVisits=663707, meanQ=17.833334, numObservations: 5
action 2, numVisits=10, meanQ=12.798020, numObservations: 2
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.113388 0.532274 0.55372 0.826918 0.645374 0.806311 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=49012, meanQ=18.623177, numObservations: 4
action 2, numVisits=8, meanQ=11.873750, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 781095 episodes
GETTING ACTION FROM:
action 3, numVisits=830107, meanQ=17.630029, numObservations: 5
action 2, numVisits=8, meanQ=11.873750, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.113388 0.532274 0.55372 0.826918 0.645374 0.806311 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 455
Initial state: 0 0.555896 0.878474 0.534143 0.892386 0.339362 0.13545 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 669289 episodes
GETTING ACTION FROM:
action 1, numVisits=669280, meanQ=17.728868, numObservations: 4
action 2, numVisits=5, meanQ=11.598000, numObservations: 1
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.555896 0.878474 0.534143 0.892386 0.339362 0.13545 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 456
Initial state: 0 0.536416 0.879831 0.734359 0.824416 0.667757 0.811273 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 645272 episodes
GETTING ACTION FROM:
action 1, numVisits=645262, meanQ=17.595820, numObservations: 4
action 2, numVisits=4, meanQ=10.495000, numObservations: 4
action 3, numVisits=4, meanQ=9.997525, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.536416 0.879831 0.734359 0.824416 0.667757 0.811273 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 457
Initial state: 0 0.583528 0.823821 0.343266 0.621976 0.540662 0.801017 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 669280 episodes
GETTING ACTION FROM:
action 1, numVisits=669257, meanQ=17.727000, numObservations: 4
action 3, numVisits=20, meanQ=11.399010, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.583528 0.823821 0.343266 0.621976 0.540662 0.801017 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 458
Initial state: 0 0.577218 0.894452 0.908685 0.543081 0.682623 0.822173 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 681697 episodes
GETTING ACTION FROM:
action 2, numVisits=681693, meanQ=17.845274, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.577218 0.894452 0.908685 0.543081 0.682623 0.822173 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 459
Initial state: 0 0.633085 0.893169 0.655782 0.801543 0.153268 0.148308 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 661135 episodes
GETTING ACTION FROM:
action 1, numVisits=661126, meanQ=17.749027, numObservations: 4
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action 2, numVisits=5, meanQ=10.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.633085 0.893169 0.655782 0.801543 0.153268 0.148308 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 460
Initial state: 0 0.668964 0.82394 0.578714 0.855537 0.577966 0.100614 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 662445 episodes
GETTING ACTION FROM:
action 3, numVisits=662440, meanQ=17.810031, numObservations: 5
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.668964 0.82394 0.578714 0.855537 0.577966 0.100614 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 461
Initial state: 0 0.91717 0.537537 0.52376 0.86414 0.508099 0.888854 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 659056 episodes
GETTING ACTION FROM:
action 3, numVisits=659051, meanQ=17.778126, numObservations: 5
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.91717 0.537537 0.52376 0.86414 0.508099 0.888854 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 462
Initial state: 0 0.68569 0.896373 0.676873 0.827609 0.611119 0.317962 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666347 episodes
GETTING ACTION FROM:
action 2, numVisits=666343, meanQ=17.825731, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.68569 0.896373 0.676873 0.827609 0.611119 0.317962 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 463
Initial state: 0 0.627163 0.851226 0.440454 0.62172 0.555374 0.864814 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 671172 episodes
GETTING ACTION FROM:
action 3, numVisits=671166, meanQ=17.858480, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.627163 0.851226 0.440454 0.62172 0.555374 0.864814 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 464
Initial state: 0 0.649182 0.525386 0.691137 0.844125 0.501415 0.864203 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 661632 episodes
GETTING ACTION FROM:
action 3, numVisits=661616, meanQ=17.775131, numObservations: 5
action 2, numVisits=10, meanQ=11.174000, numObservations: 3
action 1, numVisits=4, meanQ=9.997525, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.649182 0.525386 0.691137 0.844125 0.501415 0.864203 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 465
Initial state: 0 0.565015 0.84369 0.479433 0.934338 0.669272 0.800365 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 665416 episodes
GETTING ACTION FROM:
action 2, numVisits=665411, meanQ=17.743869, numObservations: 4
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.565015 0.84369 0.479433 0.934338 0.669272 0.800365 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 466
Initial state: 0 0.57835 0.833995 0.681567 0.810049 0.0252356 0.194181 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 667559 episodes
GETTING ACTION FROM:
action 3, numVisits=667544, meanQ=17.769567, numObservations: 4
action 1, numVisits=6, meanQ=13.665000, numObservations: 2
action 2, numVisits=7, meanQ=12.140014, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 2 0.57835 0.833995 0.681567 0.810049 0.0252356 0.194181 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 467
Initial state: 0 0.506235 0.8197 0.832585 0.36294 0.690574 0.814127 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 677713 episodes
GETTING ACTION FROM:
action 1, numVisits=677705, meanQ=17.839094, numObservations: 3
action 3, numVisits=4, meanQ=10.495000, numObservations: 2
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.506235 0.8197 0.832585 0.36294 0.690574 0.814127 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 468
Initial state: 0 0.507494 0.894241 0.663664 0.834292 0.478042 0.432682 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 677567 episodes
GETTING ACTION FROM:
action 1, numVisits=677554, meanQ=17.721977, numObservations: 3
action 3, numVisits=10, meanQ=14.299000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.507494 0.894241 0.663664 0.834292 0.478042 0.432682 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=50248, meanQ=17.383050, numObservations: 5
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 839826 episodes
GETTING ACTION FROM:
action 3, numVisits=890074, meanQ=18.485703, numObservations: 5
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.507494 0.894241 0.663664 0.834292 0.478042 0.432682 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 469
Initial state: 0 0.514672 0.89851 0.512486 0.622558 0.565244 0.897963 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 644286 episodes
GETTING ACTION FROM:
action 2, numVisits=644279, meanQ=17.649312, numObservations: 5
action 1, numVisits=3, meanQ=12.333333, numObservations: 1
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 2 0.514672 0.89851 0.512486 0.622558 0.565244 0.897963 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 470
Initial state: 0 0.683257 0.838228 0.532867 0.802754 0.769579 0.645199 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 664897 episodes
GETTING ACTION FROM:
action 1, numVisits=664893, meanQ=17.808540, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.683257 0.838228 0.532867 0.802754 0.769579 0.645199 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 471
Initial state: 0 0.62057 0.896552 0.610121 0.830246 0.312851 0.271671 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 665059 episodes
GETTING ACTION FROM:
action 2, numVisits=665051, meanQ=17.861290, numObservations: 5
action 3, numVisits=4, meanQ=9.502525, numObservations: 3
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.62057 0.896552 0.610121 0.830246 0.312851 0.271671 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 472
Initial state: 0 0.58852 0.890056 0.488057 0.5401 0.667939 0.80453 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666012 episodes
GETTING ACTION FROM:
action 3, numVisits=666005, meanQ=17.772182, numObservations: 4
action 2, numVisits=4, meanQ=9.502525, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.58852 0.890056 0.488057 0.5401 0.667939 0.80453 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 473
Initial state: 0 0.726969 0.590171 0.565897 0.87782 0.574667 0.88472 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 645461 episodes
GETTING ACTION FROM:
action 2, numVisits=645457, meanQ=17.607751, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.726969 0.590171 0.565897 0.87782 0.574667 0.88472 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 474
Initial state: 0 0.895055 0.622078 0.62629 0.881286 0.670741 0.802399 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 676079 episodes
GETTING ACTION FROM:
action 2, numVisits=676075, meanQ=17.886342, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.895055 0.622078 0.62629 0.881286 0.670741 0.802399 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=49080, meanQ=18.907854, numObservations: 3
action 3, numVisits=32, meanQ=13.405641, numObservations: 4
action 1, numVisits=6, meanQ=9.163333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 803740 episodes
GETTING ACTION FROM:
action 2, numVisits=852820, meanQ=17.103980, numObservations: 4
action 3, numVisits=32, meanQ=13.405641, numObservations: 4
action 1, numVisits=6, meanQ=9.163333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.895055 0.622078 0.62629 0.881286 0.670741 0.802399 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 475
Initial state: 0 0.554028 0.893317 0.351812 0.773385 0.61012 0.815709 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666479 episodes
GETTING ACTION FROM:
action 2, numVisits=666470, meanQ=17.758784, numObservations: 3
action 1, numVisits=6, meanQ=13.665000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.554028 0.893317 0.351812 0.773385 0.61012 0.815709 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=109825, meanQ=23.121805, numObservations: 5
action 3, numVisits=10, meanQ=18.598000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 846947 episodes
GETTING ACTION FROM:
action 1, numVisits=956694, meanQ=19.038272, numObservations: 5
action 3, numVisits=88, meanQ=18.167500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.554028 0.893317 0.351812 0.773385 0.61012 0.815709 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 476
Initial state: 0 0.783443 0.0650593 0.527094 0.896587 0.545023 0.859 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 457007 episodes
GETTING ACTION FROM:
action -1, numVisits=457003, meanQ=15.492490, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: -1
Next state: 0 0.783443 0.0650593 0.527094 0.896587 0.545023 0.859 w: 1
Observation: 0 0.714921 0 0.43201 0 0.511631 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=456995, meanQ=17.734417, numObservations: 5
action 2, numVisits=4, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 727251 episodes
GETTING ACTION FROM:
action 3, numVisits=1184246, meanQ=17.865781, numObservations: 5
action 2, numVisits=4, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.783443 0.0650593 0.527094 0.896587 0.545023 0.859 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=88654, meanQ=17.177512, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 851559 episodes
GETTING ACTION FROM:
action 1, numVisits=940213, meanQ=17.939524, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.783443 0.0650593 0.527094 0.896587 0.545023 0.859 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -16.7411
Run # 477
Initial state: 0 0.225048 0.0570075 0.595595 0.891742 0.547635 0.809653 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 670808 episodes
GETTING ACTION FROM:
action 1, numVisits=670803, meanQ=17.833774, numObservations: 4
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.225048 0.0570075 0.595595 0.891742 0.547635 0.809653 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 478
Initial state: 0 0.703204 0.200101 0.630878 0.845558 0.529395 0.825218 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 655462 episodes
GETTING ACTION FROM:
action 3, numVisits=655447, meanQ=17.710828, numObservations: 4
action 2, numVisits=12, meanQ=12.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.703204 0.200101 0.630878 0.845558 0.529395 0.825218 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 479
Initial state: 0 0.681859 0.874228 0.333642 0.00656376 0.670521 0.888201 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 659080 episodes
GETTING ACTION FROM:
action 3, numVisits=659074, meanQ=17.801671, numObservations: 5
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.681859 0.874228 0.333642 0.00656376 0.670521 0.888201 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 480
Initial state: 0 0.63696 0.821853 0.14124 0.679848 0.554552 0.845772 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 457281 episodes
GETTING ACTION FROM:
action -1, numVisits=457277, meanQ=15.651495, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.63696 0.821853 0.14124 0.679848 0.554552 0.845772 w: 1
Observation: 0 0.710886 0 0.0551811 0 0.50458 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=457270, meanQ=17.846682, numObservations: 5
action 1, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 728434 episodes
GETTING ACTION FROM:
action 3, numVisits=1185704, meanQ=17.617658, numObservations: 5
action 1, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.63696 0.821853 0.14124 0.679848 0.554552 0.845772 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=26813, meanQ=22.355276, numObservations: 4
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 863219 episodes
GETTING ACTION FROM:
action 1, numVisits=890032, meanQ=18.714214, numObservations: 4
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.63696 0.821853 0.14124 0.679848 0.554552 0.845772 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 17.5624
Run # 481
Initial state: 0 0.13268 0.676024 0.623044 0.856402 0.605808 0.864374 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 670079 episodes
GETTING ACTION FROM:
action 1, numVisits=670073, meanQ=17.759699, numObservations: 4
action 2, numVisits=3, meanQ=3.330000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.13268 0.676024 0.623044 0.856402 0.605808 0.864374 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 482
Initial state: 0 0.649533 0.837628 0.663608 0.87448 0.142412 0.560083 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 668733 episodes
GETTING ACTION FROM:
action 3, numVisits=668729, meanQ=17.775359, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.649533 0.837628 0.663608 0.87448 0.142412 0.560083 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 483
Initial state: 0 0.570672 0.8658 0.595545 0.87028 0.383771 0.477701 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 660440 episodes
GETTING ACTION FROM:
action 1, numVisits=660430, meanQ=17.757095, numObservations: 5
action 3, numVisits=5, meanQ=13.196000, numObservations: 2
action 2, numVisits=3, meanQ=12.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.570672 0.8658 0.595545 0.87028 0.383771 0.477701 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 484
Initial state: 0 0.206608 0.718055 0.686011 0.87629 0.553529 0.832635 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 664300 episodes
GETTING ACTION FROM:
action 2, numVisits=664291, meanQ=17.713328, numObservations: 5
action 3, numVisits=6, meanQ=12.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.206608 0.718055 0.686011 0.87629 0.553529 0.832635 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 485
Initial state: 0 0.560196 0.807095 0.540164 0.856448 0.986432 0.207965 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666641 episodes
GETTING ACTION FROM:
action 1, numVisits=666637, meanQ=17.715943, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.560196 0.807095 0.540164 0.856448 0.986432 0.207965 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 486
Initial state: 0 0.638174 0.845409 0.735989 0.212608 0.513108 0.880296 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 664912 episodes
GETTING ACTION FROM:
action 3, numVisits=664904, meanQ=17.850136, numObservations: 5
action 1, numVisits=4, meanQ=10.495000, numObservations: 2
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.638174 0.845409 0.735989 0.212608 0.513108 0.880296 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 487
Initial state: 0 0.67541 0.814863 0.635899 0.806943 0.564516 0.408719 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 678207 episodes
GETTING ACTION FROM:
action 2, numVisits=678194, meanQ=17.764346, numObservations: 3
action 3, numVisits=10, meanQ=15.098000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.67541 0.814863 0.635899 0.806943 0.564516 0.408719 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 488
Initial state: 0 0.570361 0.801567 0.603806 0.820977 0.373429 0.275042 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 661746 episodes
GETTING ACTION FROM:
action 1, numVisits=661731, meanQ=17.722634, numObservations: 4
action 3, numVisits=10, meanQ=15.098000, numObservations: 4
action 2, numVisits=3, meanQ=12.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.570361 0.801567 0.603806 0.820977 0.373429 0.275042 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 489
Initial state: 0 0.592018 0.859997 0.574722 0.815347 0.898332 0.678915 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 461132 episodes
GETTING ACTION FROM:
action 0, numVisits=461127, meanQ=15.523784, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.592018 0.859997 0.574722 0.815347 0.898332 0.678915 w: 1
Observation: 0 0 0.82203 0 0.887044 0 0.770497 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=461122, meanQ=17.714788, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 732253 episodes
GETTING ACTION FROM:
action 1, numVisits=1193375, meanQ=17.620733, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.592018 0.859997 0.574722 0.815347 0.898332 0.678915 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 490
Initial state: 0 0.509269 0.851701 0.946819 0.40394 0.638331 0.87745 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 458391 episodes
GETTING ACTION FROM:
action 0, numVisits=458386, meanQ=15.582437, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.509269 0.851701 0.946819 0.40394 0.638331 0.87745 w: 1
Observation: 0 0 0.777777 0 0.410252 0 0.897955 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=458378, meanQ=17.764496, numObservations: 5
action 3, numVisits=4, meanQ=9.997525, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 729917 episodes
GETTING ACTION FROM:
action 1, numVisits=1188295, meanQ=17.806471, numObservations: 5
action 3, numVisits=4, meanQ=9.997525, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.509269 0.851701 0.946819 0.40394 0.638331 0.87745 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 491
Initial state: 0 0.931299 0.790725 0.653333 0.887986 0.687137 0.867611 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 671626 episodes
GETTING ACTION FROM:
action 1, numVisits=671586, meanQ=17.774303, numObservations: 4
action 2, numVisits=36, meanQ=15.860558, numObservations: 3
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 0 0.931299 0.790725 0.653333 0.887986 0.687137 0.867611 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=49450, meanQ=17.430946, numObservations: 3
action 1, numVisits=47, meanQ=15.452060, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 864827 episodes
GETTING ACTION FROM:
action 2, numVisits=914277, meanQ=18.651946, numObservations: 3
action 1, numVisits=47, meanQ=15.452060, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.931299 0.790725 0.653333 0.887986 0.687137 0.867611 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 492
Initial state: 0 0.598339 0.875991 0.722561 0.404596 0.608009 0.835912 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 671509 episodes
GETTING ACTION FROM:
action 3, numVisits=671504, meanQ=18.094235, numObservations: 4
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.598339 0.875991 0.722561 0.404596 0.608009 0.835912 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 493
Initial state: 0 0.743443 0.755973 0.656113 0.859933 0.535378 0.853937 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 635085 episodes
GETTING ACTION FROM:
action 3, numVisits=635062, meanQ=17.623036, numObservations: 5
action 2, numVisits=17, meanQ=13.646482, numObservations: 4
action 1, numVisits=4, meanQ=8.497500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.743443 0.755973 0.656113 0.859933 0.535378 0.853937 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 494
Initial state: 0 0.568963 0.805998 0.655889 0.602686 0.613822 0.899617 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 473817 episodes
GETTING ACTION FROM:
action 0, numVisits=473811, meanQ=20.313770, numObservations: 3
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.568963 0.805998 0.655889 0.602686 0.613822 0.899617 w: 1
Observation: 0 0 0.726793 0 0.554254 0 0.814824 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=199242, meanQ=21.929723, numObservations: 5
action 3, numVisits=6, meanQ=14.335017, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 733228 episodes
GETTING ACTION FROM:
action 1, numVisits=932470, meanQ=18.222203, numObservations: 5
action 3, numVisits=6, meanQ=14.335017, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.568963 0.805998 0.655889 0.602686 0.613822 0.899617 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 495
Initial state: 0 0.159843 0.482971 0.569678 0.838553 0.643104 0.847484 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 665625 episodes
GETTING ACTION FROM:
action 1, numVisits=665566, meanQ=17.850997, numObservations: 5
action 2, numVisits=36, meanQ=13.847228, numObservations: 3
action 3, numVisits=21, meanQ=13.285719, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 0 0.159843 0.482971 0.569678 0.838553 0.643104 0.847484 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=76666, meanQ=23.498830, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 873736 episodes
GETTING ACTION FROM:
action 2, numVisits=950402, meanQ=18.715970, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.159843 0.482971 0.569678 0.838553 0.643104 0.847484 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 496
Initial state: 0 0.138356 0.337066 0.573107 0.803237 0.563768 0.883163 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 673731 episodes
GETTING ACTION FROM:
action 1, numVisits=673721, meanQ=17.845830, numObservations: 4
action 2, numVisits=5, meanQ=5.402020, numObservations: 3
action 3, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 0 0.138356 0.337066 0.573107 0.803237 0.563768 0.883163 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=77001, meanQ=23.508471, numObservations: 3
action 3, numVisits=11, meanQ=18.728191, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 861009 episodes
GETTING ACTION FROM:
action 2, numVisits=938008, meanQ=19.503095, numObservations: 4
action 3, numVisits=13, meanQ=16.846931, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.138356 0.337066 0.573107 0.803237 0.563768 0.883163 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 497
Initial state: 0 0.52946 0.825456 0.679152 0.349462 0.571734 0.887895 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 671437 episodes
GETTING ACTION FROM:
action 1, numVisits=671432, meanQ=17.844465, numObservations: 4
action 3, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.52946 0.825456 0.679152 0.349462 0.571734 0.887895 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 498
Initial state: 0 0.503897 0.818657 0.382371 0.450134 0.5447 0.822187 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 667796 episodes
GETTING ACTION FROM:
action 3, numVisits=667791, meanQ=17.870630, numObservations: 4
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.503897 0.818657 0.382371 0.450134 0.5447 0.822187 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 499
Initial state: 0 0.585808 0.849006 0.851273 0.543024 0.548204 0.85499 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 663478 episodes
GETTING ACTION FROM:
action 1, numVisits=663470, meanQ=17.759320, numObservations: 5
action 2, numVisits=5, meanQ=7.396020, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.585808 0.849006 0.851273 0.543024 0.548204 0.85499 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 500
Initial state: 0 0.529258 0.823236 0.618211 0.849681 0.836154 0.377536 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 665353 episodes
GETTING ACTION FROM:
action 2, numVisits=665348, meanQ=17.779058, numObservations: 4
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.529258 0.823236 0.618211 0.849681 0.836154 0.377536 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
